{
  "metadata": {
    "title": "Game Programming Gems 8",
    "source_file": "Game Programming Gems 8_metadata.json"
  },
  "chapters": [
    {
      "chapter_number": 1,
      "title": "Segment 1 (pages 1-13)",
      "start_page": 1,
      "end_page": 13,
      "summary": "Game Programming Gems 8 \nWelcome to the eighth edition of the Game Programming Gems series, started by Mark \nSince then, other Gems series have started, including AI Gems and a new \nMany readers think of the Game Programming Gems series as a collection of articles with \nthe diverse subsystems used to create games and stay abreast of the latest techniques.\nthe horsepower we need to create games, so innovations by hardware companies are not \nadvancements in graphical realism in academia, in R&D labs, and in the film industry that \ndevelopment costs, fueling the next generation of interactive experiences.\nprocess has changed and will continue to evolve, but game development will continue to \nThe ingenuity of the game developer, when brought to the task of leveraging new \ninteracting socially with longtime friends when playing multiplayer games.\nUltimately, whether we are discussing our individual game experiences with others or \ninteracting directly while playing, games do what they have always done across generations \npress by those out of touch with the multiplayer, socially interactive game experiences that \nThe graphics section in this edition covers several topics of recent interest, leveraging new \nfeatures of graphics APIs such as Compute Shader, tessellation using DirectX 11, and two \nphysics and animation section, we have selected a number of gems that advance beyond \ngems go deeper with improvements to existing published techniques based on real-world \nArtificial intelligence, AI, is one of the hottest areas in game development these days.\nGame \nGems in the AI section are diverse, covering \ngems.\ndevelopment, performance, and testing of our game engines.\nThe gems in the networking and multiplayer section cover \nIn one of the articles in the audio section, we discuss a relatively \nincreasing computational horsepower Moore‘s Law continues to deliver to game developers.\nI‘m excited to introduce a new section in this edition of Game Programming Gems 8 that I‘m \ncalling ―General Purpose Computing on GPUs.‖ This is a new area for the Gems series, and \nwe wanted to have a real-world case study of a game developer using the GPU for non-\nWe‘ve collected three gems for this section.\ntwo gems that leverage PhysX for collision detection and fluid simulation.\ncomputing capabilities of the platform evolve, I expect game developers will face the \ngames.\nWhile we all have our areas of specialty, I think it‘s fair to say game developers are a \nThe cover of Game Programming Gems 8 features the Engineer from Valve‘s Team Fortress \nnovel art style and rendering techniques of Team Fortress 2 allowed Valve‘s designers to \nvisually separate the character classes from each other and from the game‘s environments \nI‘d like to take a moment to acknowledge the section editors that I worked with to create \nbook together, and I thank them for their time and expertise.\nimage for this edition of Game Programming Gems.\nG. Michael Youngblood \nSection 1: Graphics \nFast Font Rendering with Instancing \nTechniques for Effective Vertex and Fragment Shading on the SPUs \nIn this edition of the Game Programming Gems series, we explore a wide range of \nimportant real-time graphics topics, from lynchpin systems such as font rendering to \non optimally exploiting graphics hardware to create high-quality visuals for games.\naccelerating font rendering by exploiting GPU instancing, settling on a constant-buffer-\nvery latest graphics hardware, from DirectX 11‘s tessellator and compute shader to \nDirectX 11 compute shader architecture, using Screen Space Ambient Occlusion as a case \nand light pre-pass rendering systems in the racing game Blur from Bizarre Creations.\nFast Font Rendering with Instancing \nFont rendering is an essential component of almost all interactive applications, and while \ntechniques exist to allow for fully scalable vector-based font rendering using modern GPUs, \nWhen implemented on typical graphics APIs, however, this technique uses run-\ntime updated vertex buffers to store per-glyph geometry, resulting in inefficient rendering \nsystem rendering techniques that were developed previously, it is possible to render \nthousands of glyphs in a single batch without ever touching the vertex buffer.\nIn this article, I propose a simple and efficient method to render fonts utilizing modern \ngraphics hardware when compared to other similar methods.\nthat it can be generalized for use in rendering other 2D elements, such as sprites and \nfont glyphs (in other words, alphabetic characters and other symbols) as vector data, \nvector font, however, is that it is not straightforward to directly render this type of data on \ngraphics hardware.\nrepresentation to a form that graphics hardware can render.\nOne way is to generate geometry directly from the vector curves, as shown in Figure 1.1.1.\nHowever, while modern GPUs are quite efficient at rendering large numbers of triangles, the \nSome optimizations to this way of rendering \nthis approach is still prohibitively high on older graphics hardware (and that of the current \ngenerated with an additional UV offset table that maps glyphs to a location in that texture \nwhich leads to distortion when rendering a font at a non-native resolution.\ndrawbacks, because rendering bitmap fonts is incredibly easy and efficient.\nA font page and a glyph rendered on a quad.\nTo draw glyphs for a bitmap font, the program must bind the texture page matching the \nintended glyph set and draw a quad for each glyph, taking into account spacing for kerning \nstill be inefficient, as the buffers containing the geometry for each batch of glyphs must be \nConstantly touching these buffers is a sure way to cause GPU stalls, \nOne way to draw the glyphs for the GUI is to create a GUI model that maintains buffers on \nthe graphics card for drawing a predefined maximum number of indexed triangles as quads.\nWhenever a new glyph is to be drawn, its quad is inserted into a list, and the vertex buffer \nWhen the time comes to render the GUI model, assuming the same \nfew draw batches as possible are needed, as the font texture page should contain all the \nindividual glyphs that would need to be rendered, but on occasion (such as for high-\nresolution fonts or Asian fonts with many glyphs), it‘s not possible to fit them all on one \nIn the situation where a font glyph must be rendered from a different page, the batch \ngraphics card.\nhints) helps, but locking and unlocking vertex buffers can still be quite expensive.\nalleviate the expense, it is possible to use a buffer that is marked to ―discard‖ its existing \nrendered at the same time).\nThe vertex structure for sending a quad looks something like this \nand takes 28 bytes per vertex (and 112 bytes for each quad): \nstruct GPU_QUAD_VERTEX_POS_TC_COLOR \ncosts is to use an additional vertex stream to update only that information that has changed \nUnfortunately, the three essential quad attributes (position, texture \nTraditionally, each vertex represents a corner of a quad.\ntechnique is attractive, as it puts the computation of offsetting the vertices on the GPU and \npotentially limits the need for vertex buffer locks to update the quad positions.\nBy using a separate vertex stream that contains unique data, it is possible to represent the \nwidth and height of the quad corners as a 4D unsigned byte vector.\ngo as small as a Bool if that was supported on modern hardware.) In the vertex declaration, \nit is possible to map the position information to specific vertex semantics, which can then be \naccessed directly in the vertex shader.\nstruct GPU_QUAD_VERTEX \nInstancing Quad Geometry \nvertex buffer containing the instance geometry and an additional vertex buffer with the per-\nThis buffer is directly hooked up to the vertex shader via input semantics \nThis is likely attributed to the fact that the graphics hardware must still point to \nthis data in some way or another, and while space is saved, additional logic is required to \nAnother way to achieve similar results with better performance is to perform shader \nBy creating a constant array for each of the separate quad \nA number of glyphs referencing their data from a constant array.\neach group of four vertices required to render a quad, as shown in Figure 1.1.4.\nvalue for the current vertex, all that is needed is to index into the constant array using this \n4 hardware, this index can be packed directly as an additional element in the vertex offset \ninstancing to just pass in the quad ID/index in order to bypass the need for a large buffer of ",
      "keywords": [
        "Talbot Marketing Manager",
        "Heather Talbot Marketing",
        "Sarah Panella Manager",
        "Brandon Penticuff Indexer",
        "Katherine Stimson Proofreader",
        "Jordan Castellani Senior",
        "Hiquet Associate Director",
        "Castellani Senior Acquisitions",
        "Game Programming Gems",
        "Shawn Morningstar Cover",
        "Marketing Manager",
        "Senior Acquisitions Editor",
        "Small Interior Layout",
        "Cengage Learning",
        "Panella Manager"
      ],
      "concepts": [
        "graphic",
        "graphical",
        "vertex",
        "game",
        "gaming",
        "instancing",
        "instance",
        "rendering",
        "render",
        "buffers"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 8",
          "chapter": 46,
          "title": "",
          "score": 0.661,
          "base_score": 0.511,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 45,
          "title": "",
          "score": 0.536,
          "base_score": 0.386,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 6,
          "title": "",
          "score": 0.447,
          "base_score": 0.447,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 31,
          "title": "",
          "score": 0.422,
          "base_score": 0.422,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 47,
          "title": "",
          "score": 0.412,
          "base_score": 0.412,
          "topic_boost": 0.0,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "vertex",
          "gems",
          "font",
          "quad",
          "glyphs"
        ],
        "semantic": [],
        "merged": [
          "vertex",
          "gems",
          "font",
          "quad",
          "glyphs"
        ]
      },
      "topic_id": 5,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.25032116845802965,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:05:51.408763+00:00"
      }
    },
    {
      "chapter_number": 2,
      "title": "Segment 2 (pages 14-22)",
      "start_page": 14,
      "end_page": 22,
      "summary": "quads can be rendered per batch.\nuse of clip-space position and a cheap but effective sorting method.\nscreen-space coordinate to clip space, we can just use the equation [cx = –1 + x * (2 / \nSpecial Effects.‖ Course on Advanced Real-Time Rendering in 3D Graphics and Games.\nPrinciples and Practice of Screen Space Ambient Occlusion \nGlobal illumination is based on simulating the effects of light bouncing around a scene \nthe problem space by assuming all indirect light is equally distributed throughout the scene.\nWith this assumption, the amount of indirect light hitting a point on a surface will be directly \nproportional to how much that point is exposed to the scene around it.\nA point on a plane \nsurface can receive light from a full 180-degree hemisphere around that point and above \ncrude approximation of global illumination that enhances depth in the scene by shrouding \naround the sampling point is blocked by the environment.\nEvery point on every scene \nblocking the light, and an ambient occlusion term is computed based on how many rays \nScreen Space Ambient Occlusion \nwhether a given surface point is occluded by nearby geometry.\nstandard depth buffer, which graphics engines already use to perform hidden surface \ndefinition, the depth buffer contains the depth of every visible point in the scene.\nthese depths, we can reconstruct the 3D positions of the visible surface points.\nPoints that \ncan potentially occlude other points are located close to each other in both screen space and \nhemisphere around each point‘s upper hemisphere as defined by its normal.\nneed a normal buffer that will encode the normal of every corresponding point in the depth \nbuffer in screen space.\nIf it does lie within the hemisphere, then the closer the neighbor point‘s \ndepth is to the target point, the higher the odds it is an occluder.\nbehind the point being tested for occlusion, then no occlusion is assumed to occur.\nthese calculations can be performed using the screen space buffer of normals and depths, \nhence the name Screen Space Ambient Occlusion (SSAO).\nSSAO Samples neighbor points to discover the likelihood of occlusion.\nLighter arrows are behind the center point and are considered occluded samples.\nAmbient Occlusion.\nWe will first need to have a depth buffer and a normal buffer at our disposal from \nspace will generate a corresponding ambient occlusion value for that pixel and store \nFor each pixel in our depth buffer, we \nextract that point‘s position and sample n neighboring pixels within the hemisphere \naligned around the point‘s normal.\nThe ratio of occluding versus non-occluding points will be our ambient occlusion term \nThe ambient occlusion render target can then be blended with the color output from \nI will now describe our Screen Space Ambient Occlusion algorithm in greater detail.\nThe SSAO algorithm can then generate the ambient occlusion \napproach, the ambient occlusion map (in screen space) can be sampled by direct lights from \nthe scene to have their contribution modulated by the ambient occlusion term as well, which \nA different approach is to render the scene only once, using multiple render targets bound \nas output to generate the depth and normal information as the scene is first rendered \nlimitation to allow the entire lighting setup to be configurable to use ambient occlusion per \nstore the depth and normal information.\nWhen supported, a 16-bit floating-point format will \nScreen Space Ambient Occlusion is very bandwidth intensive, and minimizing sampling \na 16-bit floating-point buffer at the same time won‘t be possible.\nencoding and decoding the normal and depth values is shown in Listing 1.2.1.\nHLSL code used to encode and decode the 16-bit depth value \nWith the input data in hand, we can begin the ambient occlusion generation process itself.\nAt any visible point on a surface on the screen, we need to explore neighboring points to \ndetermine whether they could occlude our current point.\nfrom neighboring points in the scene using a filtering process described by the HLSL shader \nScreen Space Ambient Occlusion filter described in HLSL code \nfloat3 vSamplePointDelta = p_vSSAOSamplePoints[i]; \nWe start with the current point, p, whose occlusion we are computing.\nWe have the point‘s \nSampling the depth buffer at the corresponding UV \ncoordinates, we can retrieve that point‘s depth.\n3D position of the point within can be reconstructed using the shader code shown in Listing \nHLSL shader code used to map a pixel from screen space to view \nfloat2 p_vRecipDepthBufferSize; \nfloat2 p_vCameraFrustrumSize; \nfloat2 vViewSpaceUV = i_VPOS * p_vRecipDepthBufferSize; \nWe will need to sample the surrounding area of the point p along multiple offsets from its \nfall within point p‘s upper hemisphere.\nthe normal vector at that point and to flip the offset vector if the dot product is negative, as \nrejected due to falling behind the plane of the surface of the point p.",
      "keywords": [
        "Space Ambient Occlusion",
        "Screen Space Ambient",
        "Ambient Occlusion",
        "Screen Space",
        "point",
        "Space Ambient",
        "occlusion",
        "ambient occlusion term",
        "Ambient",
        "space",
        "depth",
        "screen",
        "depth buffer",
        "scene",
        "normal"
      ],
      "concepts": [
        "floating",
        "occlusion",
        "sampling",
        "samples",
        "rendered",
        "render",
        "lighting",
        "space",
        "point",
        "performance"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 8",
          "chapter": 4,
          "title": "",
          "score": 0.85,
          "base_score": 0.7,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 8,
          "title": "",
          "score": 0.708,
          "base_score": 0.558,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 3,
          "title": "",
          "score": 0.702,
          "base_score": 0.552,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 6,
          "title": "",
          "score": 0.568,
          "base_score": 0.568,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 57,
          "title": "",
          "score": 0.506,
          "base_score": 0.356,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "ambient",
          "occlusion",
          "ambient occlusion",
          "point",
          "screen"
        ],
        "semantic": [],
        "merged": [
          "ambient",
          "occlusion",
          "ambient occlusion",
          "point",
          "screen"
        ]
      },
      "topic_id": 3,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.2255782292205621,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:05:51.408840+00:00"
      }
    },
    {
      "chapter_number": 3,
      "title": "Segment 3 (pages 23-30)",
      "start_page": 23,
      "end_page": 30,
      "summary": "depth of the neighbor point can be sampled from the depth buffer.\nHLSL code used to test occlusion by a neighboring pixel \nfloat3 vSamplePointDelta, \nfloat fFullOcclusionThreshold, \nfloat fNoOcclusionThreshold, \nfloat fOcclusionPower ) \nfloat2 vSamplePointUV; \nvSamplePointUV = vSamplePointUV + float2( 1.0f, -1.0f ); \nvSamplePointUV = vSamplePointUV * float2( 0.5f, -0.5f ); \nfloat fSampleDepth = tex2D( p_sDepthBuffer, vSamplePointUV \nthe sampled neighboring points.\nClearly, if the depth di is behind the sampled point‘s depth, \nit cannot occupy the space at the sampled point.\nThe further in front of the sample point the depth is, the less likely it is to occupy that \nThe difference between the sampled depth di and the depth of the point qi \nFor the first relationship, we can formulate an occlusion function to map the depth deltas to \nocclusion values.\nReally, the occlusion function can \nNegative depth deltas should give zero occlusion.\nthe sample point.) \nSmaller depth deltas should give higher occlusion values.\nThe occlusion value needs to fall to zero again beyond a certain depth delta value, as \nA graph of our occlusion function is shown in Figure 1.2.4.\na full-occlusion threshold where every positive depth delta smaller than this value gets \nfloat fNoOcclusionThreshold, \nfloat fFullOcclusionThreshold, \nfloat fOcclusionPower ) \nOnce we have gathered an occlusion value for each sample point, we can take the average \nof these, weighted by the distance of each sample point to p, and the average will be our \nambient occlusion value for that pixel.\nSampling neighboring pixels at regular vector offsets will produce glaring artifacts to the \nand reflecting these vectors through the sampled random vector, resulting in a semi-\npattern and produces a more even distribution of the samples inside the occlusion \nfloat fS; \nfloat fC; \nfloat fXS       = vAxis.x * fS; \nfloat fYS       = vAxis.y * fS; \nfloat fOneC      = 1.0f - fC; \nconst float c_scalingConstant = 256.0f; \nfloat3 vRandomNormal = ( \nfurther blurring of the ambient occlusion result becomes necessary.\nThe ambient occlusion \nTo smooth out the noise, a separable Gaussian blur can be applied to the ambient occlusion \nfloat4 cValue        = tex2D( p_sSrcMap, vCenterTap.xy ); \nfloat4 cResult       = cValue * p_fBlurWeights[0]; \nfloat fTotalWeight   = p_fBlurWeights[0]; \n// Sample normal & depth for center tap \nfloat4 vNormalDepth = tex2D( p_sNormalDepthMap, \nfloat4 vSampleNormalDepth = tex2D( p_sNormalDepthMap, ",
      "keywords": [
        "occlusion",
        "float",
        "depth",
        "ambient occlusion",
        "occlusion function",
        "point",
        "Gaussian",
        "sample point",
        "vSamplePointUV",
        "Gaussian sample",
        "function",
        "sample",
        "depth deltas",
        "vectors",
        "ambient"
      ],
      "concepts": [
        "occlusion",
        "sampled",
        "sample",
        "depth",
        "results",
        "point",
        "object",
        "randomization",
        "randomized",
        "vector"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 8",
          "chapter": 4,
          "title": "",
          "score": 0.732,
          "base_score": 0.582,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 2,
          "title": "",
          "score": 0.702,
          "base_score": 0.552,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 8,
          "title": "",
          "score": 0.601,
          "base_score": 0.451,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 7,
          "title": "",
          "score": 0.591,
          "base_score": 0.591,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 57,
          "title": "",
          "score": 0.446,
          "base_score": 0.296,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "float",
          "occlusion",
          "depth",
          "vsamplepointuv",
          "sample point"
        ],
        "semantic": [],
        "merged": [
          "float",
          "occlusion",
          "depth",
          "vsamplepointuv",
          "sample point"
        ]
      },
      "topic_id": 3,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.18259789455669945,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:05:51.408886+00:00"
      }
    },
    {
      "chapter_number": 4,
      "title": "Segment 4 (pages 31-40)",
      "start_page": 31,
      "end_page": 40,
      "summary": "using an insufficient number of samples at close-up pixels, resulting in a noisier result for \nthese pixels.\ndepth buffer sampled by the SSAO algorithm to be at full-screen resolution.\nbuffer can be generated at screen resolution, since the depth information is generally \nThe edge-enhancing component of the ambient occlusion does not require as many samples \nThough SSAO provides for important lighting cues to enhance the depth of the scene, there \nIt should be noted the depth buffer can only contain one depth value per pixel, and thus \nThe top-left pane shows lighting without the ambient occlusion, while the top-right pane \nColor Plate 2 shows the contrast between the large-area, low-contrast SSAO sampling \nThis gem has described the Screen Space Ambient Occlusion technique used at Blizzard and \n―Image-Space Horizon-Based Ambient Occlusion.‖ \n<http://developer.download.nvidia.com/presentations/2009/SIGGRAPH/Bavoil_MultiLayerD\n―Ambient Occlusive Crease Shading.‖ Game Developer.\nand Cartoon Rendering on Graphics Hardware.‖ n.d. Brett Lajzer.\nUnsharp Masking the Depth Buffer.‖ Course on Non-Photorealistic Rendering.\n―Variance Methods for Screen-Space Ambient Occlusion.‖ ShaderX7: \n―Real-Time Depth Buffer Based Ambient Occlusion.‖ Game \nMulti-Resolution Deferred Shading \nRecently, deferred shading has become a popular rendering technique for real-time games.\nDeferred shading enables game engines to handle many local lights without repeated \nto optimize the pixel processing necessary to handle many local lights, soft shadows, and \nIn this gem, we present a technique that we call multi-resolution \ndeferred shading, which provides adaptive sub-sampling using a hierarchical approach to \nMulti-resolution deferred shading \nefficiently reduces pixel shading costs as compared to traditional deferred shading without \nexpensive full-resolution deferred shading approach.\nDeferred shading (left: 20 fps), multi-resolution deferred shading \nUnlike traditional forward rendering approaches, deferred shading costs are independent of \nThis is because deferred shading techniques store geometry information \nin textures, often called G-buffers, replacing geometry processing with pixel processing \nDeferred shading techniques start by rendering the scene into a G-buffer, which is typically \nsystems render a screen-aligned quad to invoke a pixel shader at all pixels in the output \nThe pixel shader retrieves the geometry information from the G-buffer and performs \nHowever, material buffers are not necessary if we separate lighting \nand material phases from the shading phase using light pre-pass rendering [Engel09].\nUnlike traditional deferred shading, light pre-pass rendering first computes lighting results \ngeometry rendering pass, such separation of lighting and material phases gives added \nflexibility during material shading and is compatible with hardware multi-sample anti-\nA related technique, inferred lighting, stores lighting results in a single low-\nresolution buffer instead of the full-resolution buffer [Kircher09].\ndiscontinuity problems using a multi-resolution approach during the lighting (or shading) \nMulti-Resolution Deferred Shading \nAlthough deferred shading improves lighting efficiency, computing illumination for every \ndeveloped a multi-resolution deferred shading approach to exploit the low-frequency nature \nWe perform lighting in a lower-resolution buffer for spatially coherent areas \nand then interpolate results into a higher-resolution buffer.\nThe algorithm has three steps, as shown in Color Plate 4: geometry pass, multi-resolution \nThe next step is multi-resolution rendering, which consists of resolution selection (non-edge \ndetection), shading (lighting), and interpolation (up-sampling).\nrendering results at various resolutions.\nthe resolutions of the R-buffers even more drastically than just one-quarter resolution in \nMulti-resolution rendering uses rendering iterations from lower-resolution to higher-\nresolution R-buffers.\nskip pixels processed in earlier iterations using lower-resolution R-buffers [Mitchell04].\nstart shading our R-buffers, we set the lowest-resolution R-buffer as the current render \nrendered in this resolution by rendering a screen-aligned quad with Zi = 1.0 – i * 0.1, \nlow for the current pixel, we should use a higher-resolution R-buffer for better quality, and \nAfter this pass, pixels \nwhose spatial proximity is high (in other words, non-edge) in the current resolution contain \nWe then perform shading (or lighting) by rendering a screen-aligned quad with Zi = 1.0 – i \npixels in this resolution will pass the Z-test, as illustrated in Color Plate 4.\nIn the pixel \nshader, we read geometric data from G-buffers and compute illumination as in light pre-\nresults instead of full shading results into R-buffers, and we handle material properties with \nstored illumination in R-buffers in the composite pass.\nAfter shading, we copy the current shading/lighting results and depth to the next higher-\nresolution R-buffer, allowing the hardware‘s bilinear units to do a simple interpolation as we \nproximity and writing Z and computing illumination until we reach the full-resolution R-\nIf a given pixel was shaded on \na prior iteration in a lower-resolution R-buffer, that pixel is not shaded again at the higher \nshading operations at the appropriate resolution for different regions of the screen.\nFigure 1.3.2, we visualize the distribution of pixels shaded at each level of our hierarchy.\nNon-black pixels were shaded in the first pass at 1/16th resolution as in the image on the \nThe middle image shows the pixels shaded in the second iteration at one-quarter \nresolution, and only the pixels in the image on the right were shaded at full image \naddress this issue during the multi-resolution rendering phase.\nchannel of R-buffer pixels that are lit; otherwise, we write zero.\nwe interpolate these pixels to a higher-resolution buffer.\nIf a pixel is lit by a light, we add one \nalpha for this pixel in the lighting phase.\nothers, and thus we use a higher-resolution buffer without interpolation.\nIn the composite pass, we render a screen-aligned quad, reading shading results from the \nfull-resolution R-buffer and material properties such as albedo to compute the final shading \nto light pre-pass rendering.\nIn contrast to traditional deferred shading and light pre-pass rendering, multi-resolution \ndeferred shading reduces rendering costs for low-frequency pixels.\ndeferred shading is also more efficient than inferred lighting due to the hierarchical \nMulti-resolution deferred shading can also be used for other rendering \nstill requires hundreds of lights for each pixel.\ncombination of Light Pyramids and multi-resolution deferred shading.\ntraditional deferred shading (left) and multi-resolution deferred shading (right: \nWe have presented a multi-resolution deferred shading technique that performs lighting and \nshading computations at appropriate screen-space frequency in order to improve the \nlighting but also other rendering operations with high per-pixel overhead, such as per-pixel \n―A GPU-Based Light Hierarchy for Real-Time Approximate Illumination.‖ ",
      "keywords": [
        "Deferred Shading",
        "Multi-Resolution Deferred Shading",
        "Ambient Occlusion",
        "Shading",
        "Screen Space Ambient",
        "SSAO",
        "Space Ambient Occlusion",
        "Advanced Rendering Techniques",
        "Rendering",
        "Ambient",
        "Deferred",
        "deferred shading techniques",
        "Multi-Resolution Deferred",
        "pixel",
        "SSAO samples"
      ],
      "concepts": [
        "lighting",
        "shading",
        "pixel",
        "render",
        "rendering",
        "resolution",
        "resolutions",
        "buffers",
        "image",
        "samples"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 8",
          "chapter": 2,
          "title": "",
          "score": 0.85,
          "base_score": 0.7,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 3,
          "title": "",
          "score": 0.732,
          "base_score": 0.582,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 57,
          "title": "",
          "score": 0.717,
          "base_score": 0.567,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 8,
          "title": "",
          "score": 0.708,
          "base_score": 0.558,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 6,
          "title": "",
          "score": 0.593,
          "base_score": 0.593,
          "topic_boost": 0.0,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "shading",
          "resolution",
          "deferred",
          "deferred shading",
          "multi resolution"
        ],
        "semantic": [],
        "merged": [
          "shading",
          "resolution",
          "deferred",
          "deferred shading",
          "multi resolution"
        ]
      },
      "topic_id": 3,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.20891679535781654,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:05:51.408930+00:00"
      }
    },
    {
      "chapter_number": 5,
      "title": "Segment 5 (pages 41-49)",
      "start_page": 41,
      "end_page": 49,
      "summary": "View Frustum Culling of Catmull-Clark Patches in DirectX 11 \npatches with displacements are of prime interest to game developers, and we would like to \ngiven patch avoids higher-order surface evaluation of domain points in that patch as well as \npatches coupled with displacements and animation make the process of culling them non-\ncull a given patch.\nbounding boxes for displaced approximate Catmull-Clark subdivision surface patches at run \ntime, allowing us to perform view frustum culling on the patches.\nsubdivision surfaces, displacement mapping, and the methods that are currently in use to \nDisplaced Subdivision Surfaces and Catmull-Clark Surfaces \npatch.\nextraordinary faces (or patches).\nApproximate Catmull Clark (ACC) subdivision surfaces, which maps very naturally to the \noriginal control mesh to a bi-cubic Bezier patch.\npatches, the bi-cubic Bezier corresponds exactly to the Catmull-Clark limit surface.\nExtraordinary patches do not correspond exactly to the limit surface, but Loop and Schaefer \npatches, ACC generates separate normal and bi-tangent patches in order to impose GN \nThe ACC scheme describes the normals and bi-tangents using additional Bezier patches, \nwhich results in a continuous normal field even across edges of extraordinary patches.\npatch.\nThis basis conversion process that generates the Bezier patch control points is SIMD \nthe topology of the incoming patch, but the output control points are always a 4×4 Bezier \nIn addition to the computation of the Bezier control points, the hull shader can optionally \narbitrary tessellation factors to the edges of a patch (within some constraints, defined by \nThe final stage of hull shader is called the join phase (or patch \nThe tessellator accepts edge LODs of a patch and other tessellator-specific states that \nIn the case of quadrilateral patch rendering, the domain shader is invoked at domain values \norder surface at these domain locations using the control points provided by the hull shader \nAfter evaluating the surface, the domain shader can perform arbitrary \nnormal calculation is different for ordinary and extraordinary patches.\nFor ordinary patches, \nsmooth surfaces with adaptive tessellation and displacement mapping, resulting in a \ntessellation, and hull shading of all patches submitted to the graphics pipeline, including \nthose patches that are completely outside of the view frustum.\nculling patches early in the pipeline in order to avoid unnecessary computations.\nwe must account for mesh animation and displacement, both of which deform a given patch \nAn elegant generalized solution to surface patch culling \nideas discussed in their work to cull the approximate Catmull-Clark patches against view \nWe perform a pre-processing step on a given control mesh and displacement map in order \nto find the maximum displacement for each patch.\nClark surface and the global uv-parameterization done while creating the displacement map \nFigure 1.4.3 shows one such patch.\nwill be sampled in the domain shader for that patch.\ngiven patch can be found by calculating the maximum displacement in the region confined \nby patch boundaries in the displacement map.\nmaximum displacement for a given patch.\nentire mesh that stores this maximum displacement per patch.\nThe figure on the left shows (u,v) parameterization that is used for patch \nAt run time, the patch vertices of the control mesh go through the vertex shader, which \nThe hull shader then operates on each quad patch, performing \nis that they always stay within the convex hull of the control mesh defining the patch.\ngiven patch outward by the maximum displacement, resulting in conservative bounds \nsuitable for culling a given patch.\nThe proposed scheme culls the patches in the \nhull shader, and all the associated triangles from that patch get culled as a result, \nlines (inner bounding box), and conservative AABB for the displaced Bezier curve \nAt this point, we have a conservative patch AABB that takes displacements into account.\nthe AABB for a patch is outside the view frustum, we know that the entire patch is outside \noutside the view frustum, we set the edge LODs for that patch to be negative, which \nindicates to the graphics hardware that the patch should be culled.\ntest during the join phase (a.k.a. patch constant phase) of the hull shader because this \nFor each culled patch, we eliminate unnecessary tessellator and domain shader work for \nthat patch.\nAll patches, whether or not they‘re culled, take on the additional computational \nculling a very small number of patches (around the character‘s feet) start offsetting the \nfps measured when culling code was running in the patch constant phase of \nWhen about half of the patches in our test model are outside of the view frustum (see \nThe gains from culling patches are more noticeable at higher levels of \nfps changes with the edge tessellation factor (edge LOD) when about half of the patches are \nCulling benefits go up with the level of tessellation, except at the \nsuper-high levels of tessellation where culling patches doesn’t help.\nIncrease in the frame rate was due to view frustum culling patches.\nthis algorithm increase with domain shader complexity and tessellation level, whereas the \nper-patch overhead of the culling tests remains constant.\ndetermine whether patch culling should be performed at all for a given object, thus avoiding \nWe have presented a method for culling Catmull-Clark patches against the view frustum \nto account for occluded and back-facing patches with displacements.\nPre-Tessellation Culling.‖ ACM Transactions on Graphics 28.2 (April 2009): n.p. ACM Portal.\nSurfaces with Bicubic Patches.‖ ACM Transactions on Graphics 27.1 (March 2008): n.p. ACM ",
      "keywords": [
        "Catmull-Clark subdivision surfaces",
        "subdivision surfaces",
        "patch",
        "Jason and Pedro",
        "Pedro Sander",
        "hull shader",
        "shader",
        "Patches",
        "subdivision surface patches",
        "domain shader",
        "Culling",
        "displacement",
        "control mesh",
        "Bezier",
        "control"
      ],
      "concepts": [
        "patches",
        "patch",
        "culling",
        "tessellation",
        "figures",
        "displacements",
        "displaced",
        "computation",
        "compute",
        "computations"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 8",
          "chapter": 20,
          "title": "",
          "score": 0.619,
          "base_score": 0.469,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 49,
          "title": "",
          "score": 0.615,
          "base_score": 0.465,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 24,
          "title": "",
          "score": 0.566,
          "base_score": 0.416,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 48,
          "title": "",
          "score": 0.463,
          "base_score": 0.463,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 13,
          "title": "",
          "score": 0.424,
          "base_score": 0.424,
          "topic_boost": 0.0,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "patch",
          "patches",
          "culling",
          "displacement",
          "shader"
        ],
        "semantic": [],
        "merged": [
          "patch",
          "patches",
          "culling",
          "displacement",
          "shader"
        ]
      },
      "topic_id": 4,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.22063156622921418,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:05:51.408975+00:00"
      }
    },
    {
      "chapter_number": 6,
      "title": "Segment 6 (pages 50-58)",
      "start_page": 50,
      "end_page": 58,
      "summary": "Ambient Occlusion Using DirectX Compute Shader \nDirect3D 11 provides the ability to perform multi-threaded rendering calls, a shader \nOne of these new shader stages is the compute \nSpecifically, the compute shader allows for a \ncontrollable threading model, sharing memory between processing threads, synchronization \nThis gem will provide an introduction to the compute shader and its new features.\naddition, we will take an in-depth look at a Screen Space Ambient Occlusion (SSAO) \nalgorithm implemented on the compute shader to show how to take advantage of this new \nimplementation to demonstrate how the compute shader can work together with the \nThe Compute Shader \nlet‘s take a closer look at the compute shader itself and the general concepts needed to \nThe compute shader is a new programmable shader stage that is actually not simply \nRather, the compute shader is conceptually a \nshader invocation and new synchronization primitives that allow threads to synchronize.\nthreads also have read/write access to a common memory pool, which provides the \nCompute Shader Threading Model \nTo use the compute shader, we need to understand its threading model.\nis that of a Thread Group.\nthe layout provides a simple addressing scheme used in the compute shader code to have \neach thread perform an operation on a particular portion of the input resources.\nparticular thread is running, it executes the compute shader code and has access to several \nTo actually execute the compute shader, we tell the API to execute a given number of \nscheme of the compute shader.\ncompute shader: \nThe individual threads running the compute shader have access to these system values and \nFor example, if we wanted a compute shader to perform an \noperation on each pixel of an input texture, we would define the thread group to be of size \nprocess the image with a total of 4×4 (m = 4, n = 4) Thread Groups as shown, then we \ngives us the total number of threads needed to process all 32×32 (x*m and y*n) pixels of \nCompute Shader Thread Interactions \nIn addition to providing an easy-to-use thread addressing scheme, the compute shader also \nallows each Thread Group to declare a block of Group Shared Memory (GSM).\nthe sequences of access, the compute shader introduces several atomic functions for thread \nblocks of creating a mutex system in the compute shader, where a shared variable serves \nSince the compute shader is intended \nCompute Shader Resources \nbuffers of structures available in your shader code.\nshader to consume the elements of a buffer one at a time and append results to an output \nTo further facilitate the compute shader‘s parallel-processing capabilities, Direct3D 11 \nallows the compute shader (as well as the pixel shader) to have read and write access to a \nWith a general understanding of the new capabilities of the compute shader, we can now \nthe general concepts of the SSAO algorithm and then describe how we can use the compute \nScreen Space Ambient Occlusion is a relatively recently developed technique for \nbe computed by sampling the area around the pixel in screen space.\nvariants of the original algorithm provide improvements in image quality or performance, \ncompute shader should be applicable in general.\nunderlying algorithm that can benefit from the compute shader‘s new capabilities.\nAmbient occlusion techniques have been around for some time and have found uses \nocclusion calculations, such as [Bunnell05], which generalizes the geometric object into \ndisks to reduce the computational complexity of the occlusion calculations.\naddition, the cost of performing the occlusion calculation scales with increased scene \nThe Screen Space Ambient Occlusion algorithm provides an interesting alternative technique \nfor determining an approximate occlusion value.\nInstead of computing an occlusion value \nbased on the geometric representation of a scene by performing ray casting, the occlusion \nSince it operates at the screen space level, the algorithm‘s performance is less \nhow the buffer is generated, the algorithm performs a processing pass that uses the depth \nbuffer as an input and generates an output texture that holds the occlusion values for the \nWhen the final scene rendering is performed, the occlusion buffer is sampled based \nScreen Space Ambient Occlusion has provided a significant improvement over previous \nambient occlusion algorithms.\nthe current frame, saving a significant amount of computation and allowing the algorithm to \nSince the depth buffer only records one depth sample per pixel, \nneeded, depth peeling can be used to perform multiple occlusion queries, as described in \nsample results per pixel while reducing the overall number of calculations that need to be \nto perform a filtering pass over the entire occlusion buffer that blurs the occlusion values \nThe depth buffer and/or the occlusion buffer can be generated at a decreased resolution.\noverall factor of 4 reduction in the number of occlusion pixels that need to be calculated.\nThen the occlusion buffer can either be upsampled with a bilateral filter or just directly used \nSSAO Meets the Compute Shader \ncompare these high-level operations with the new capabilities of the compute shader to see \nalgorithm and discuss potential strategies for mapping to the compute shader.",
      "keywords": [
        "Compute Shader",
        "Thread Group",
        "Shader",
        "Compute",
        "Compute Shader Thread",
        "Space Ambient Occlusion",
        "thread",
        "Occlusion",
        "Dennis and Peter",
        "Peter Schroder",
        "Ambient Occlusion",
        "occlusion buffer",
        "depth buffer",
        "buffer",
        "Screen Space Ambient"
      ],
      "concepts": [
        "threading",
        "sample",
        "sampling",
        "occlusion",
        "buffers",
        "rendering",
        "render",
        "algorithms",
        "processing",
        "process"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 8",
          "chapter": 7,
          "title": "",
          "score": 0.719,
          "base_score": 0.569,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 53,
          "title": "",
          "score": 0.673,
          "base_score": 0.523,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 54,
          "title": "",
          "score": 0.622,
          "base_score": 0.472,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 4,
          "title": "",
          "score": 0.593,
          "base_score": 0.593,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 2,
          "title": "",
          "score": 0.568,
          "base_score": 0.568,
          "topic_boost": 0.0,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "shader",
          "compute shader",
          "compute",
          "occlusion",
          "ambient"
        ],
        "semantic": [],
        "merged": [
          "shader",
          "compute shader",
          "compute",
          "occlusion",
          "ambient"
        ]
      },
      "topic_id": 0,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.23908331599603272,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:05:51.409022+00:00"
      }
    },
    {
      "chapter_number": 7,
      "title": "Segment 7 (pages 59-68)",
      "start_page": 59,
      "end_page": 68,
      "summary": "This entails sampling the depth buffer to obtain the pixel‘s depth.\nthe possibility to share texture samples among the entire Thread Group.\nmemory is supposed to be significantly faster than a direct texture sample, if each thread \nrequests a depth sample to initialize its own calculations, then it can also write that depth \nvalue to the shared memory for use later on by other threads.\nthread in a Thread Group doing this is to have a copy of the complete local depth data in \nLater, as each thread begins calculating the relative occlusion \nagainst the local area, it can read the needed depth values from the Group Shared Memory \nassociated with reading the depth values and then storing them to the Group Shared \nRandomize Sampling Kernel \nrandom vector and then performing a ―reflect‖ operation on each of the sampling kernel \nThis eliminates the need for a texture sample and the repeating texture of normalized \nOnce the sampling kernel has been randomized, we can acquire each individual depth \nsample.\ncoordinates of the current sampling kernel vector to offset from the current pixel location.\nIf we utilize the Group Shared Memory as described previously, then the depth values that \nof the block will need access to the depth samples within our sampling radius, and they \naround each block may end up increasing the number of depth samples to the point that it \nprovided by using the GSM instead of direct sampling.\nIf you wanted to filter the depth values for each depth sample \nbased on the floating-point values of the kernel offset vector, then you would need to \nPerform Partial Occlusion Calculation (per Sample) \nOnce we have obtained a depth sample to compare to our current pixel depth, we can move \nIn this step, we determine whether our sample depth \ncompute shader introduces if the calculation is only a function of the depth delta—sharing \nocclusion calculations between pixels.\noperations, a single thread can calculate the occlusion for one pair of locations and then \nboth occlusion buffer values.\nAt the same time, these occlusion values can be accumulated in the GSM \nThe final step in this process is to calculate the final occlusion value that will end up in the \nsamples used to calculate the occlusion according to the performance level of the target \nbuffer after all pixels have a final occlusion value calculated.\nthe filtering pass in one direction, store the result into the GSM, then perform the second \nfiltering pass in the other direction over the values in the GSM without ever writing the \nThis implementation will utilize two different-size thread groups, 16×16 and 32×32, to \nThread Group size has any effect on the performance of the algorithm.\ndemonstrate the use of the GSM as a cache for the depth values and compare how well this \ntactic performs relative to directly loading samples from the depth buffer.\nusing the GSM, we also utilize the Gather sampling function for filling the GSM with depth \nStored along with the depth value is the view space normal \nvector, which will be used during the occlusion calculations.\nas the primary input to the compute shader to calculate a raw, unfiltered occlusion buffer.\nFinally, we use the depth/normal buffer and the raw occlusion buffer to perform separable \nbilateral filtering to produce a final occlusion buffer suitable for rendering the scene with the \nDepth/Normal Buffer Generation \nThe depth/normal buffer will consist of a four-component floating-point texture, and each of \nthe occlusion buffers will consist of a single floating-point component.\nvectors are generated by rendering the linear view space depth and view space normal \nvectors into the depth/normal buffer.\nThe depth value is calculated by simply scaling the \nGeneration of the view space depth and normal vector buffer \nNext, we generate the raw occlusion buffer in the compute shader.\nThe occlusion calculations will be performed in Thread Groups of size 16×16×1 \nEach thread will calculate a single pixel of the raw \nocclusion buffer that corresponds to the thread‘s Dispatch thread ID system value.\nDispatch thread ID is also used to determine the appropriate location in the depth/normal \nThe depth value and normal vector are loaded from the texture and \nDepth Value Cache with the GSM \nWe will also set up the compute shader to cache local depth values in the GSM.\ndepth values of the surrounding area are loaded into the GSM, all subsequent depth \nsampling can be performed on the GSM instead of loading directly from texture memory.\nEach of the Thread Groups requires the corresponding depth \nThread Group‘s boundary is also needed to allow the occlusion calculations for the border \nThis requires each thread to sample not only its own \ndepth/normal vector, but also some additional depth values to properly load the GSM for \nIf we stipulate that each thread will load four depth values into the GSM, then our \nthat are sampled for each thread.\nThis effectively increases the number of depth samples per \nsamples are obtained by having each thread perform the Gather instruction and store the \nresults in the GSM for all other threads within the group to utilize.\nDeclaring and populating the Group Shared Memory with depth data \nThe number of depth values loaded into the GSM can be increased as needed by having \nthe depth values have been loaded, we introduce a synchronization among threads in the \nGSM to use the cached depth values or to directly access the depth texture.\nThis provides a different sampling kernel for each \ndepth value at the location determined by the randomized sampling kernel offsets.\nsample location is found by determining the current pixel‘s view space 3D position and then \nadding the reoriented sampling kernel vectors as offsets from the pixel‘s location.\npair that can then be used to select the depth sample from either the GSM or the \nfloat3 Sample3D = PixelPosVS + vFlippedOffset * scale; \nto provide an additional sample that is more relevant for determining occlusion.\nlook up the depth sample either directly from the texture or from the GSM by calling the \nAfter the depth has been loaded, the occlusion at the current pixel from this sample is \nThe partial occlusion calculation is repeated for a given number of samples, implemented as \nvalues are averaged and then stored in the raw occlusion buffer for further processing.\nThe final step in our occlusion value generation is to perform the bilateral blur.\ncolumn into the GSM, and then each thread can directly read its neighbor values from it.\nThis should minimize the cost of sampling a texture for filtering and allow larger filter sizes \nLoading and storing the depth and occlusion values into the GSM for \n// Each thread will load its own depth/occlusion values \nvalue out of the raw occlusion buffer and stores that value in the GSM.\nvalue stored in the occlusion buffer represents visibility, and thus can be directly used as \nThe sample implementation provides its \nThe following image was generated using 32 depth samples for each occlusion pixel ",
      "keywords": [
        "Group Shared Memory",
        "Thread Group",
        "Shared Memory",
        "Group Shared",
        "Thread Group size",
        "depth",
        "GSM",
        "Thread",
        "occlusion buffer",
        "Group",
        "occlusion",
        "raw occlusion buffer",
        "depth buffer",
        "compute shader",
        "buffer"
      ],
      "concepts": [
        "floating",
        "sampling",
        "sample",
        "performing",
        "performance",
        "filtering",
        "filter",
        "vector",
        "implement",
        "implementation"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 8",
          "chapter": 6,
          "title": "",
          "score": 0.719,
          "base_score": 0.569,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 54,
          "title": "",
          "score": 0.653,
          "base_score": 0.503,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 37,
          "title": "",
          "score": 0.638,
          "base_score": 0.488,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 36,
          "title": "",
          "score": 0.593,
          "base_score": 0.443,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 3,
          "title": "",
          "score": 0.591,
          "base_score": 0.591,
          "topic_boost": 0.0,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "depth",
          "occlusion",
          "gsm",
          "thread",
          "buffer"
        ],
        "semantic": [],
        "merged": [
          "depth",
          "occlusion",
          "gsm",
          "thread",
          "buffer"
        ]
      },
      "topic_id": 0,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.22268219878004525,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:05:51.409069+00:00"
      }
    },
    {
      "chapter_number": 8,
      "title": "Segment 8 (pages 69-86)",
      "start_page": 69,
      "end_page": 86,
      "summary": "Eye-View Pixel Anti-Aliasing for Irregular Shadow Mapping \nThe irregular shadows algorithm (also known as Irregular Z-Buffer shadows) combines the \nimage quality and sampling characteristics of ray-traced shadows with the performance \nIrregular shadows are \neye-view sample is evaluated at sub-pixel precision in the light view.\nshadow mapping suffers from pixel aliasing in the final shadowed image due to the fact that \nBrute-force super-sampling of eye-view pixels decreases shadow \nRather than brute-force super-sampling all pixels, we propose adaptively adding shadow \nshadow samples are then inserted into the irregular Z-buffer based on the footprint of the \nlight-view projection of potentially aliased pixels.\nFinally, the individual shadow sample \nalgorithm requires minimal additional storage and shadow evaluation cost but results in \nOur implementation of anti-aliased irregular shadow mapping \nproblem of screen-space shadow edge aliasing, which affects many current algorithms.\nPixel-Perfect Shadows with the Irregular Z-Buffer \nConventional shadow mapping renders the scene from the eye and the light, and in the final \ncompositing pass, the two views are compared to identify points that are in shadow \neliminate sampling and self-shadowing artifacts [Fernando01, Stamminger02, Sen03, \npatterns between the eye and light views, which is the root cause of most shadow mapping \nConventional versus irregular shadow mapping.\nshadow mapping (left), both the eye-view and light-view images are rendered \nsample locations in the shadow map.\nIrregular shadow mapping (right) avoids this \nmismatch by rendering the light-view image with the irregular Z-buffer.\nIrregular shadow mapping addresses the root cause of visual artifacts in conventional \nshadow mapping by basing the light-view sampling pattern on the positions of pixels in the \ncompared occluder surface point with the projection of the shadow sample, as illustrated in \nIrregular shadow mapping (d) eliminates aliasing \nartifacts typically associated with conventional shadow mapping (c).\nIrregular shadow mapping utilizes the irregular Z-buffer in this context.\nas in conventional shadow mapping, irregular shadow mapping projects triangles onto the \nUnlike conventional shadow mapping, this determination is made by querying the \nFinally, for each sample inside a triangle, irregular shadow mapping \nrasterization [Akenine-Möller05]), since irregular Z-buffer samples may lie anywhere within \nWhile irregular shadow mapping is free of light-view aliasing, it still suffers from eye-view \neye-view shadow aliasing, is caused by the fact that a single bit occlusion value is not \nnovel shadow mapping techniques [Brabec01, Lauritzen06, Salvi08] have addressed this \nThe most obvious approach to produce anti-aliased shadows with irregular shadow mapping \nis super-sampling of the entire screen by generating and evaluating multiple shadow \nsamples for each eye-view pixel.\nof the irregular Z-buffer are proportional to the number of shadow samples, making real-\ntime performance impossible on current hardware for even as little as four shadow samples \nA four-times super-sampled irregular shadow mapping result image \nThe recent method by [Robison09] provides a solution to compute anti-aliased shadows \nfrom the (aliased) output of irregular shadow mapping, but in essence it is also a brute-\nSolution: Adaptive Multi-Sampling of Irregular Shadows \nsamples per eye-view pixels provides a nice anti-aliased shadow and that potentially \nshadow-aliased pixels are those pixels that lie on a projected shadow edge.\npropose an efficient algorithm for anti-aliased irregular shadow mapping by adaptive multi-\nsampling of only those pixels that potentially lie on a shadow edge.\nfraction of all screen pixels are shadow-edge pixels, this approach results in substantial \nEssentially, our method is an extension of the original irregular shadow mapping algorithm, \nacceleration structure for the projected eye-view shadow samples.\nirregular Z-buffer construction, potential shadow edge pixels are detected using a \nconservative shadow edge stencil buffer.\nSuch pixels generate multiple shadow samples \ndistributed over the pixel‘s extent and are inserted in the irregular Z-buffer (shadow sample \nNon-shadow-edge pixels are treated just as in the original irregular shadow \nmapping algorithm—a single shadow sample is sufficient to detect the occlusion value of the \neach eye-view pixel‘s sample, resulting in a properly anti-aliased fractional occlusion value.\nAlgorithm: Anti-Aliased Irregular Shadow Mapping \nwhich pixels are potentially aliased by constructing a conservative shadow edge stencil \n1.  Render the scene conservatively from the light‘s point of view to a variance shadow \n3.  Construct a conservative shadow edge stencil buffer using a variance shadow map and \n4.  Using the stencil in Step 3, generate N extra eye-view samples Pi for potential shadow \n5.  Transform eye-view samples Pi to light space P‘i (shadow sample splatting).\n7.  Render the scene from the light‘s point of view while testing against samples in the \nshadow edge stencil buffer.\nMulti-sampled eye-view pixels accumulate shadow sample \nConservative Shadow Edge Stencil Buffer \nTo adaptively add shadow samples at shadow-edge pixels, we construct a special stencil \nconservative shadow edge stencil buffer.\nWe employ a technique called Variance Shadow Mapping [Lauritzen06].\nVariance shadow \nconstructed through mip-mapping of the variance shadow map.\nshadow map, we use these moments to compute an upper bound on the fraction of the \ncan be used to cull eye-view pixels that have very little probability to be in shadow.\nwe can determine that it is almost certain that a projected eye-view sample with light depth \nIn summary, the conservative shadow edge stencil buffer can be constructed in the \n1.  Render the scene from the light‘s point of view, writing out depth x and depth squared \nx2 to a variance shadow map texture (VSM).\n3.  Render the scene from the eye point, computing for each sample: \nConservative shadow edge stencil buffer construction HLSL shader \nNote that while conventional rasterization of the scene from the light‘s point of view in Step \n1 earlier is sufficient for generating a conventional variance shadow map, it is not sufficient \nillustrated in Figure 1.6.7, which depicts potential shadow-edge pixels in overlay but misses \nquite a few due to the low resolution of the variance shadow map.\nConservative shadow edge stencil map with regular rasterization.\nMany potential shadow-edge pixels (overlay) are missed due to low resolution of \nthe variance shadow map.\nlight-view render of Step 1, just as we do during the light-view render of irregular shadow \nshadow-edge pixels in overlay, regardless of the variance shadow map resolution.\nConservative shadow edge stencil map with conservative \nAll potential shadow-edge pixels are detected (overlay), regardless \nof the variance shadow map resolution.\nShadow Sample Splatting \nsamples for potentially aliased pixels, as defined by the conservative shadow edge stencil \nbuffer, we insert the eye-view samples in each light-view grid cell that is touched by the \nmultiple samples per eye-view pixel.\n2. Project all samples into light space as in the original irregular shadow algorithm.\nshadowing algorithm.\nparticularly hard for many shadow mapping algorithms.\nIrregular shadow mapping shows its \nstrength in the tunnel scene because no shadow map resolution management is required to \nsingle-sample irregular shadow algorithm (see Figures 1.6.10(a) and 1.6.11(a)).\n1.6.9 illustrates the result of computing the conservative shadow edge stencil buffer on both \nscenes: Potential shadow edge pixels are rendered with an overlay.\nsingle-sample irregular shadows with 4× rotated grid multi-sampling on potential shadow \nfrequency shadows cause significant aliasing when using only a single eye-view shadow \nResult of the conservative shadow edge stencil buffer on the tower \nPotential shadow edge pixels are rendered with an \nTower scene: (a) Single-sample irregular shadows and (b) 4× \nrotated grid multi-sampling on potential shadow edge pixels only.\nTunnel scene: (a) Single-sample irregular shadows and (b) 4× \nrotated grid multi-sampling on potential shadow edge pixels only.\nfrequency shadows caused significant anti-aliasing when using only a single eye-\nview shadow sample.\nirregular shadowing algorithm; therefore, it could be implemented as in [Arvo07] as well.\nhigh-quality shadows in real time in game scenes [Johnson05].\nSince only a marginal fraction of all screen pixels are shadow-edge pixels, this approach \nCompared to the single-sample irregular shadow maps, the additional \nshadow-edge pixels is ~10 percent of all eye-view pixels, and that we generate N additional \nsamples per potential shadow-edge pixel.\ntimes are proportional to the number of shadow map samples, this means an additional cost \ninto the variance shadow map.\nview pixel and can easily be packed into one of the existing eye-view buffers of the irregular \nshadowing algorithm.\nadaptively samples potential shadow edge pixels multiple times with conventional multi-\nsoft irregular shadow mapping, where the concept of anti-aliasing is implicit, as both the \nsoft and hard irregular shadow mapping algorithms share the same algorithmic framework \nThe main advantage of irregular shadow maps with respect to conventional shadow maps is \nHowever, irregular shadow maps are affected by eye-\nview aliasing of the shadow result.\nRecent pre-filterable shadow mapping algorithms and \nbrute-force eye-view techniques have provided solutions for anti-aliased shadows, but none \nchapter is an extension of irregular shadow mapping, exploits the same irregular data \nstructure, and is therefore the first algorithm to produce anti-aliased shadows by means of \nadaptive multi-sampling of irregular shadow maps, while keeping all its other positive \n―Alias-Free Shadow Maps using Graphics Hardware.‖ Journal of \nZ-Buffer and its Application to Shadow Mapping.‖ April 2004.\n―Soft Irregular Shadow Mapping: Fast, High-Quality, and \nRobust Soft Shadows.‖ Proceedings of the 2009 Symposium on Interactive 3D Graphics and \n―Variance Shadow Maps.‖ \nMatched Shadow Maps.‖ ACM Transactions on Graphics 26.4 (Oct. 2007): 20.\n―Logarithmic Perspective Shadow Maps.‖ ACM Transactions on Graphics \n―Rendering Filtered Shadows with Exponential Shadow Maps.‖ \nSoft Shadows using Alias-free Shadow Maps.‖ Computer Graphics Forum: Proceedings of \n―Perspective Shadow Maps.‖ \nIntroduction to Irregular Z-Buffer Shadows \nThe simplest shadow mapping algorithm requires two passes.\nview positions in the light-view grid, enabling accurate shadow determination from the eye \nShadow mapping with an irregular Z-buffer is a \nthe data structure marking this point as in shadow (occluded).\n4.  Create a standard shadow map by traversing the data structure and scattering out the \n5.  Render the scene from the eye view again, using the shadow map.",
      "keywords": [
        "Irregular Shadow Mapping",
        "Irregular Shadow",
        "Shadow",
        "Shadow Mapping",
        "Irregular Z-Buffer",
        "shadow edge pixels",
        "conservative shadow edge",
        "shadow edge stencil",
        "Shadow Edge",
        "variance shadow map",
        "Irregular Z-Buffer shadows",
        "irregular shadow maps",
        "shadow map",
        "Irregular",
        "shadow sample"
      ],
      "concepts": [
        "shadow",
        "samples",
        "mapping",
        "map",
        "maps",
        "pixel",
        "algorithm",
        "algorithmic",
        "render",
        "rendering"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 8",
          "chapter": 2,
          "title": "",
          "score": 0.708,
          "base_score": 0.558,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 4,
          "title": "",
          "score": 0.708,
          "base_score": 0.558,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 3,
          "title": "",
          "score": 0.601,
          "base_score": 0.451,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 57,
          "title": "",
          "score": 0.533,
          "base_score": 0.383,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 7,
          "title": "",
          "score": 0.363,
          "base_score": 0.363,
          "topic_boost": 0.0,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "shadow",
          "irregular",
          "shadow mapping",
          "shadow edge",
          "irregular shadow"
        ],
        "semantic": [],
        "merged": [
          "shadow",
          "irregular",
          "shadow mapping",
          "shadow edge",
          "irregular shadow"
        ]
      },
      "topic_id": 3,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.16420933971198332,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:05:51.409110+00:00"
      }
    },
    {
      "chapter_number": 9,
      "title": "Segment 9 (pages 87-94)",
      "start_page": 87,
      "end_page": 94,
      "summary": "(Tasks are completed in the order they are \nA programmable graphics device, such as a software rasterizer, would build a dependency \ngraph of rendering tasks to complete (which we will call a render graph).\nrendering tasks to be roughly divided between front end (for example, vertex \nenables independent tasks to run concurrently; for example, if a core completes pixel \nDependencies can be defined in terms of resources—for example, a render task may \nsignal that it has completed writing to a render target resource (write dependency) or wait \nThe task \nSuch a task system leverages a thread \nThe ability to create individual tasks or sets of tasks (task sets).\nA task set calls the \nTasks and task sets may depend upon each other.\nSpecifically, a task or task set will \nnot start until the tasks or task sets it depends on have completed.\nTasks and task sets may also depend upon user-defined events.\nindependent tasks.\nTask sets call a user function with user data and a number indicating which \nNon-rendering tasks typically function more opportunistically, executing \nHence, we design our tasks to be independent of the \nCombining Render Graphs and Task Graphs \nThe ability to create non-rendering task sets that depend on, or are dependencies of, \nrendering tasks is the key to achieving maximum hardware utilization for these mixed-\nFollowing is a method to inject a non-rendering task into the render \nWe then need a way to notify the render system that the render task and its read and write \nNow we have a way for tasks created using our task system to define dependencies with \nrendering tasks and for rendering tasks to very finely interact with our task system.\ndependency of a user task, the front end of the render pass can start (transform/ bin), but \nFollowing, we show how an event that waits on a task set can \ncall NotifyRenderTaskComplete() to enable dependent render work.\nFirst, create a task set that does some client work, such as builds a data structure.\nNext, create a render task with the data structure (resource) written to by the task set as a \nFinally, create a task that depends on \nthe task set that will call NotifyRenderTaskComplete().\nuntil the task set is complete.\nDetail of connecting client task sets to render passes via render \ntasks.\nFirst, create an event that we will signal and a task set that depends on the \n(It would do work on the render target.) Next, create the render pass, which in this \nFinally, create a render task with the \nrender target as a read dependency and a callback that will set the event.\nThe task set \nrendering and non-rendering tasks.\nTasks or task sets must have their dependencies described at creation time.\nTasks or tasks sets can depend on tasks, task sets, or events.\nSince a task \n2. Create a build data structure task set that depends on event (1).\n4. Create a deswizzle task set that depends on event (3).\na. Rasterization depends on resource from task set (2).\n6. Create a final eye-view render pass where rasterization depends on the shadow map \nresource from task set (4).\n7. Create a depth-only eye-view render pass that signals event (1) when its render \ndepth-only pass (7) completes, it signals the build event (1), which enables the build task \nCompletion of the build task set (2) enables the light-view rasterization (5) \n(5) completes, it signals the deswizzle event (3), which enables the deswizzle task set (4) to \nWhen the deswizzle task set (4) completes, it enables the final eye-view rasterization \nOrder of creation of events, task sets, and render graph nodes for \nend (rasterization + pixel shading) for a total of eight stages, or task sets.\nIZB dependency graph with render stages expanded into front and \nnon-dependent front-end rendering tasks if we start all three render passes immediately.\nfront-end rendering tasks.\nXform/bin tasks can complete as threads become available from non-\nrendering tasks, filling in gaps in execution.\nachieved by enabling flexible hardware to execute whatever tasks are available, rather than \nand non-rendering tasks.\ntasks and task sets to manage parallel computation.\nsuch as Larrabee, a similar system of task dependencies can be used to identify ",
      "keywords": [
        "task",
        "task set",
        "task sets",
        "render",
        "create",
        "render task",
        "rendering tasks",
        "Larrabee",
        "render pass",
        "task system",
        "dependency graph",
        "work",
        "deswizzle task set",
        "sets",
        "render target"
      ],
      "concepts": [
        "tasks",
        "dependency",
        "dependencies",
        "depend",
        "dependent",
        "rendering",
        "render",
        "graphics",
        "work",
        "void"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 8",
          "chapter": 6,
          "title": "",
          "score": 0.449,
          "base_score": 0.449,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 54,
          "title": "",
          "score": 0.415,
          "base_score": 0.415,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 53,
          "title": "",
          "score": 0.383,
          "base_score": 0.383,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 45,
          "title": "",
          "score": 0.375,
          "base_score": 0.375,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 47,
          "title": "",
          "score": 0.37,
          "base_score": 0.37,
          "topic_boost": 0.0,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "task",
          "tasks",
          "task set",
          "render",
          "task sets"
        ],
        "semantic": [],
        "merged": [
          "task",
          "tasks",
          "task set",
          "render",
          "task sets"
        ]
      },
      "topic_id": null,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.2242864252623508,
        "topic_boost": 0.0,
        "timestamp": "2025-12-17T23:05:51.409164+00:00"
      }
    },
    {
      "chapter_number": 10,
      "title": "Segment 10 (pages 95-103)",
      "start_page": 95,
      "end_page": 103,
      "summary": "The Cell contains two distinctly different types of processor: the PowerPC Processing \nProcessing Unit (SPU) and the Memory Flow Controller (MFC).\nThe SPU \nDetailed knowledge of the SPU instruction set and internal execution model are critical to \nLoads and stores, branch hints, channel operations \nThe SPU has a particularly large register file to facilitate the execution of pipelined, unrolled \nregister file of the SPU is unified.\nAs the SPU is a vector \nprocessing unit at its heart, its Instruction Set Architecture (ISA) is designed specifically for \nvector processing [IBM08a].\nAll 128 of the SPU‘s registers are 16 bytes in size, allowing for \nup to four 32-bit floating-point values or eight 16-bit integers to be processed with each \nprogramming of the SPU.\nFor each bit of a quadword, this instruction uses the mask register (rm) to \nThe shuffle bytes instruction, shufb, is the key instruction in data manipulation on the \nSPU.\nThe shufb instruction takes four operands, all of which are registers.\nA shuffle pattern is a quadword value that works on a byte level.\nquadword controls the contents of the corresponding byte in the target register.\nexample, the 0th byte of the pattern quadword controls the value that will ultimately be \nThe above pattern performs a perfect shuffle, but on a byte level.\nother value of the lower 4 bits of the byte) would index into the contents of the ra register, \nqword ra = si_ilhu(0x3f80); // ra contains: 1.0f, 1.0f, 1.0f, \nqword rb = si_ilhu(0x4000); // rb contains: 2.0f, 2.0f, 2.0f, \nqword result = si_shufb(ra, rb, pattern); \nIn many programs, simply inlining of shuffle patterns for data manipulation requirements \nData can be copied into and out of the local store by way of the DMA engine \nstores to and from the local store are always 16-byte aligned and sized.\ndata smaller than 16 bytes requires use of a less-than-efficient load-modify-store pattern.\nAccesses to the local store are arbitrated by the SPU Store and Load unit (SLS) based on a \npriority; the DMA engine always has priority over the SXU for local store accesses.\ngroup is able to contain multiple DMAs. The tag group is denoted by a 5-bit value internally, \nof data management strategies and their tradeoffs in the context of the SPU.\nMulti-Buffering \n1.8.3 shows the concept of multi-buffering.\nMulti-buffering data to hide latency (modeled after [Bader07]).\nBader suggests that each buffer should use a separate tag group in order to prevent \nunnecessary stalling of the SPU waiting for data that will be processed sometime in the \nMulti-buffering can yield significant performance increases, \nBecause the buffers are resident in the local store, it does \nUsing a reasonable size for each of the buffers in your multi-buffer (about 16 KB) in order to \nallow the SPU to process several vertices or pixels before requiring more data from the main \ncomplicated if one‘s goal is to support a list of arbitrarily sized (and hence aligned) vertex \ncontrolled by carefully selecting a reasonably sized unit of work when processing pixels.\nThe design of data is paramount when hoping to write performant software for the SPU.\nSince the SPU is a SIMD vector processor, concepts familiar to those who have programmed \nThe first assumes Array-of-Structures data layout, and the second \n[3] SPU-initiated DMAs are performed by the writing of special-purpose registers in the MFC using the \nThere are six such registers that must be written in order to initiate a DMA.\nHowever, a little knowledge of the MFC can help avoid the branch in this case.\nThis queue contains SPU-initiated commands to the MFC‘s \nBranch-free issue of DMA \nqword cmp         = si_andi(cmp_mask, 0x1); // bottom bit only.\nqword dma_size    = si_mpy(size, cmp);    // size < 2^16 \nsi_to_uint(dma_size), \nwhen the DMA engine attempts to process this element of the queue.\nThe SPUs can also lend a hand in various vertex processing tasks and, because of their \nIn Blur, we were able to use the SPU to deal with awkward vertex sizes and to \nVertex data comes in all shapes and sizes, and, as a result, multi-buffering this type of data \nWhen vertex buffers are created, contiguous vertices are packed \nThis presents an SPU programmer with a challenge when \nattempting to process buffers whose per-vertex alignment may not be a multiple of 16 \nFirst, the DMA engine in the MFC transfers 1, 2, 4, \nSecond, loads and stores performed by the SXU itself \nThere are a lot of cases where a single vertex will straddle the boundary of two multi-\nbuffers, due to vertex structures that have alignments that are sub-optimal from an SPU \nend of a multi-buffer to its nearest 16-byte boundary into the start of the second multi-\nbuffer and offset the pointer to the element you are currently processing.\nwhen the second multi-buffer is transferred back to the main address space, it will not \nThis is then sampled based on the position of a vertex being processed relative to \nfunction of the volume texture and the undamaged vertex data.\nperformance of rendering cars in Blur was heavily vertex limited.\nThe damage offsets are a function of the vertex‘s position and the state of the node lattice.\nGiven the need for original position, we must transfer the vertex data for the cars to the \nlocal store via DMA and read the position data corresponding to each vertex.\nusing a multi-buffering strategy.\nWith the vertex data of the car in the SPU local \nstore, we are able to calculate a position and normal offset for each vertex and write these \nout to a separate vertex buffer.\nThe data in its 32-bytes-per-vertex form is ideal for the DMA engine \nbecause the MFC natively works in 16-byte chunks, meaning from the point of view of other \nprocessing elements (in our case, the GPU), a given vertex is either deformed or it is not.\nfloating-point formats for this data type on their GPUs. Fortunately, almost all GPU vendors ",
      "keywords": [
        "SPU",
        "DMA",
        "local store",
        "data",
        "vertex",
        "DMA engine",
        "Synergistic Execution Unit",
        "MFC",
        "Synergistic Processing Element",
        "processing",
        "GPU",
        "SPU local store",
        "instruction",
        "dot",
        "Cell Broadband Engine"
      ],
      "concepts": [
        "vertex",
        "data",
        "instruction",
        "instructions",
        "processing",
        "process",
        "byte",
        "performing",
        "performance",
        "bit"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 8",
          "chapter": 11,
          "title": "",
          "score": 0.747,
          "base_score": 0.597,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 37,
          "title": "",
          "score": 0.644,
          "base_score": 0.494,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 54,
          "title": "",
          "score": 0.636,
          "base_score": 0.486,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 53,
          "title": "",
          "score": 0.611,
          "base_score": 0.461,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 38,
          "title": "",
          "score": 0.567,
          "base_score": 0.417,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "spu",
          "vertex",
          "dma",
          "local store",
          "mfc"
        ],
        "semantic": [],
        "merged": [
          "spu",
          "vertex",
          "dma",
          "local store",
          "mfc"
        ]
      },
      "topic_id": 0,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.22203621965762038,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:05:51.409208+00:00"
      }
    },
    {
      "chapter_number": 11,
      "title": "Segment 11 (pages 104-112)",
      "start_page": 104,
      "end_page": 112,
      "summary": "qword val_lo           = si_lqd(target, 0x00); \nqword val_hi           = si_lqd(target, 0x10); \nqword sign_bit_mask    = si_ilhu(0x0); \nqword mant_bit_mask    = si_ilhu(0x0); \nqword expo_bias        = si_ilhu(0x3800); \nqword lo_byte_pat      = si_ilh(0x0303); \nqword result           = si_shufb(val, val, loader); // \nqword sign_bit         = si_and(result, sign_bit_mask); \nqword significand      = si_and(result, mant_bit_mask); \nqword is_zero_mask     = si_cgti(significand, 0x0); \nqword final_result     = si_or(exponent_bias, sign_bit); \nProcessing vertex data on the SPUs has a number of advantages; one of the most \nsignificant is that the rigidity of the GPU‘s processing model is largely circumvented as you \nare performing processing on a general-purpose CPU.\nimpossible under the rigid processing model adopted by GPUs. The ability to split workloads \nprocessing on the SPU can in many cases require that vertex buffers are double buffered, \nArbitrarily ―hooking into‖ the graphics pipeline to have the SPUs perform general-\ndo not necessarily require the use of the rasterizer, or even helping out the GPU with some \npre-processing as in [Swoboda09], is certainly feasible and in our experience has yielded \nsignificant performance benefits in real-world applications [Tovey10].\nsome of the techniques that will help you get the most out of the SPUs when shading \nIt might be tempting with initial implementations of pixel processing code on the SPU to \nwords, program code that contains little dependency between operations that follow one \ntime that could be better spent performing pixel shading, while larger batches cause high \nsetup cost for each processing batch, you are doing more work for little to no extra setup \nSo, what is the upper bound on the number of pixels to process in a single batch of work?\ndepends on a number of factors, including the complexity of your fragment program and the \nthe compiler to multiplex all live variables in your program onto a limited register file[5].\nthat one can reasonably process without spilling any registers back to the local store and \n[5] The process of mapping multiple live variables onto a limited register file is known as register \nAn efficient, well-written program will be limited by the number of instructions issued to the \nperformance with SPU programs.\nWe will now discuss the requirements for instruction dual-\nProgrammers writing code with intrinsics rarely need to worry about instruction alignment.\nbetter align your code for dual-issue, and, in many cases, the compiler will do a reasonable \nof nop (and its odd-pipeline equivalent, lnop) will be useful in ensuring that code is \nCase Study: Light Pre-Pass Rendering in Blur \nLight pre-pass rendering is a variant of deferred shading first introduced by Wolfgang Engel \ntechniques behind light pre-pass rendering are well understood and are discussed elsewhere \nAs with all deferred rendering, the shading of pixels is decoupled from scene complexity by \nrendering out ―fat‖ frame buffers for use in an image space pass [Deering88, Saito90].\npre-pass rendering differs slightly from traditional deferred shading in that only the data \nrequired for lighting calculations is written to the frame buffer during an initial rendering \nbe equipped to handle a large number of dynamic lights, the light pre-pass renderer was a \nAfter implementing a light pre-pass renderer for Blur (which ran on \noffloading the screen-space lighting pass to the SPUs[6].\nwhich he moved a fully deferred renderer to the SPUs in [Swoboda09]; Matt‘s work and willingness to \ncommunicate with us was useful in laying the ground work for our implementation in Blur.\nThe lighting calculations in Blur are performed on the SPU in parallel with other non-\nProcessing of the lighting \nWhen the tiles are processed, the RSX is free to access the lighting buffer \nduring the rendering of the main pass.\nThe SPUs are powerful enough to perform fragment processing.\ndemonstrated by developers with deferred shading, post-processing, and so on \npossible, it is possible to perform a plethora of image-space techniques on the SPUs, \nrelated rendering work on the GPU can provide an extra gain if one‘s goal is to minimize \nRasterization on the SPUs has been achieved by a number of studios with good results, but \nthe most serious drawback to performing fragment shading on the SPUs is the lack of \nimprove the feasibility of some graphics techniques on the SPUs.\nGPU along with the SPUs. Running two to four copies of the same SPU program (albeit with \nThe SPUs are fast enough to perform high-end vertex and fragment processing.\nsupplement processing activities traditionally associated with rendering.\nwork between the two processing elements makes them great tools for optimizing the \nBlur demonstrate the potential of the SPUs to work harmoniously with the GPU to produce \nimpressive improvements to the latency of a frame and allow game developers to get closer \ndiscussions about SPU coding, to Matt Swoboda of SCEE R&D for our useful discussions \n<http://www.insomniacgames.com/tech/articles/0208/files/insomniac_spu_programming_g\n―Cell Programming Tips & Techniques.‖ One-Day IBM Cell \nDrake‘s Fortune.‖ Game Developers Conference.\nVLSI System for High Performance Graphics.‖ Proceedings of the 15th Annual Conference on \nComputer Graphics and Interactive Techniques (1988): 21–30.\n―Light Pre-Pass Renderer.‖ Diary of a Graphics Programmer.\n<http://diaryofagraphicsprogrammer.blogspot.com/2008/03/light-pre-pass-renderer.html>.\n―Designing a Renderer for Multiple Lights: The Light Pre-Pass \nRenderer.‖ ShaderX7: Advanced Rendering Techniques.\n―The Light Pre-Pass Renderer Mach III.‖ To appear in \n[IBM08] ―Cell Broadband Engine Programming Handbook.‖ IBM.\n[IBM08a] ―Synergistic Processing Unit Instruction Set Architecture.‖ IBM.\nReal-Time Rendering, \nWellesley, MA: A.K. Peters, Ltd, 2008.\nShapes.‖ ACM SIGGRAPH Computer Graphics 24.4 (1990): 197-206.\n―Deferred Lighting and Post Processing on PLAYSTATION®3.‖ \n―Parallelized Light Pre-Pass Rendering with \nthe Cell Broadband Engine™.‖ GPU Pro: Advanced Rendering Techniques.\nKILLZONE2 Case Study.‖ Game Developers Conference 2009.\nA Versatile and Interactive Anatomical Human Face Model \nParticle Swarm Optimization for Game Programming \nOur games need to be much more real \nNowhere is this more evident than in the character performances and physical simulations \nThey now expect a game‘s characters to react to the worlds around them in an intelligent \nway, as well as interact with the world in a way that models the physical interactions in our \nThe gems in this section represent the intersection of the physical interactions and animated \nIn ―A Versatile and Interactive Anatomical Human Face Model,‖ Marco \nanimation systems with physical simulation.\napplying easy-to-use particle simulation techniques to a variety of optimization problems.\nanimation on a hierarchical character or how to simulate and detect a collision between two \nIn ―Curved Paths for Seamless Character Animation,‖ \nAs our animated characters become more physically \naware and grounded in our game environments, and our simulated worlds become inhabited \nA Versatile and Interactive Anatomical Human Face Model \nHowever, creation of the facial blend shapes is a difficult and time-consuming task, and, \nback the results in real time, allowing the artist to tune the anatomical parameters \nOur objective is to build a virtual model of the human head that simulates its anatomy and \nstatic face mesh, and then the anatomical simulation is used to generate its blend shapes.\naccuracy of the individual muscles in a real anatomical model is not the goal.\nThe anatomical simulation must also be fast enough to be interactive (in other \nThen, the face is bound to the muscles and to the skull, and thus it is animated through a ",
      "keywords": [
        "Light Pre-Pass Rendering",
        "qword",
        "SPUs",
        "Rendering",
        "Light Pre-Pass",
        "SPU",
        "GPU",
        "Game Developers Conference",
        "Processing",
        "qword val",
        "bit",
        "game",
        "Pre-Pass Rendering",
        "Advanced Rendering Techniques",
        "techniques"
      ],
      "concepts": [
        "processing",
        "processes",
        "process",
        "program",
        "programming",
        "game",
        "rendering",
        "performing",
        "performance",
        "light"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 8",
          "chapter": 10,
          "title": "",
          "score": 0.747,
          "base_score": 0.597,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 54,
          "title": "",
          "score": 0.582,
          "base_score": 0.432,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 53,
          "title": "",
          "score": 0.567,
          "base_score": 0.417,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 6,
          "title": "",
          "score": 0.52,
          "base_score": 0.37,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 38,
          "title": "",
          "score": 0.503,
          "base_score": 0.353,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "pre pass",
          "spus",
          "qword",
          "pass",
          "light pre"
        ],
        "semantic": [],
        "merged": [
          "pre pass",
          "spus",
          "qword",
          "pass",
          "light pre"
        ]
      },
      "topic_id": 0,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.22276970086127362,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:05:51.409262+00:00"
      }
    },
    {
      "chapter_number": 12,
      "title": "Segment 12 (pages 113-120)",
      "start_page": 113,
      "end_page": 120,
      "summary": "influence a particle‘s position through forces.\nposition of particles can be directly set according to a customizable set of geometrical \nconstraints \nthe constraints could cause the resulting position to change slightly, the velocity must be \nSteps (3) and (4) solve the set of constraints in an iterative way.\nThat is, each constraint is \nmost of the cases to solve the set of constraints.\nThe set of constraints defined over \nthe particles defines the dynamics of a deformable body represented by the triangulated \nconstraints; thus, the remaining particles will displace accordingly.\nIn our model, muscles are represented by rectangular parallelepipeds, which are deformed \nTo define the shape of the muscles, we draw a \nclosed contour directly on the skull surface and the already-made muscles.\nDefining the shape of a muscle on the skull.\nThe intersection points form the basis of the muscle geometry, the so-called action lines.\naction lines is twofold: (1) They define the bottom contour of the muscle geometry during \nmuscle itself.\n(a) A surface point sp in A1A2A3 is defined by the homogeneous \nThe relevant attributes of a surface point are position and normal; both of them are \nby two surface points; thus, an action line is completely described by the ordered list of its \nsurface points.\nWhen the underlying surfaces deform, the surface points displace, and \nSoft Model for a Facial Muscle \nnetwork of distance constraints, as shown in Figure 2.1.6.\nDistance constraints used in the muscle model.\nThese constraints replicate some aspects of the dynamic behavior of a real face muscle, in \ncompleting the muscle model, we add bending constraints among the triangular faces of the \nparticles, which makes the muscle thicker due to compression and thinner due to \nThe Muscle Map \nDifferent layers forming the muscle map used in the experiments.\nmuscle model, which has simplified dynamics compared to the real musculoskeletal system.\nHowever, even though there may be not a one-to-one mapping with the muscle map in a \nFor instance, on the forehead area of a real head, there is a single large, flat sheet muscle, \ndegree of visual realism, even though the single linear muscle models have simple dynamics \nEach simulated muscle is linked to the underlying structures through position constraints \nfollowing the position of surface points.\nentire set of surface points lying on it moves as well, which in turn influences the motion of \nActive contraction of a muscle is achieved by simply moving the surface points along the \nGiven that the bottom surface of the muscles is anchored to the surface points \nthrough position constraints, when the latter move, the muscle contracts or elongates, \ndepending on the direction of motion of the surface points.\nThe example muscle map is deformed by rotating the jaw and \nMorphing the Muscle Map into the Target Face Mesh \nOnce the skull and the muscle map are ready, they can be morphed to fit inside the target \ndefine two sets of 3D points, P and Q.\nP is a set of points defined over the surface of the \nskull and the muscles, and Q is a set of points defined over the skin mesh.\nThe position of the points in P and Q are \nG(p) is defined, we apply it to all the vertices of the skull and muscle meshes, fitting them \n(a) The set of points P and Q picked on the skull and on the face \nWhere n is the number of points in each set, di is the distance of pi from pj, ri is a positive \nFigure 2.1.9 (b) shows an example of fitting the skull into a target skin mesh.\nSkin is modeled as a deformable body; its properties are defined by geometrical constraints \nAfter the skull and the muscle map are fitted onto the skin mesh, further constraints are \nafter the fitting, portions of some muscles may stay outside the skin.\nouter direction, the skin vertices are first bound to these muscles.\nIf the ray does not intersect any muscle, then the skull is tested.\nIf an intersection is found, then it is defined as a surface point sp on the intersected \nsystem, and it is bound through a position constraint to sp.\nWhen the skull and the muscles move, the position of the \nsurface points will change accordingly.\nbecause it is bound to the surface points through the corresponding position constraint and \nconstraints.\nanatomical model is adaptive enough to animate directly the face mesh provided by the ",
      "keywords": [
        "muscle",
        "surface points",
        "Muscle Map",
        "position",
        "surface",
        "constraints",
        "points",
        "Skull",
        "mesh",
        "particle",
        "muscle model",
        "publicly available SIGGRAPH",
        "skin",
        "Model",
        "position constraints"
      ],
      "concepts": [
        "constraints",
        "muscles",
        "point",
        "mesh",
        "meshes",
        "deformed",
        "particles",
        "position",
        "positions",
        "positive"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 8",
          "chapter": 55,
          "title": "",
          "score": 0.658,
          "base_score": 0.508,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 16,
          "title": "",
          "score": 0.553,
          "base_score": 0.403,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 14,
          "title": "",
          "score": 0.539,
          "base_score": 0.389,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 13,
          "title": "",
          "score": 0.5,
          "base_score": 0.35,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 19,
          "title": "",
          "score": 0.5,
          "base_score": 0.35,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "muscle",
          "constraints",
          "surface",
          "points",
          "skull"
        ],
        "semantic": [],
        "merged": [
          "muscle",
          "constraints",
          "surface",
          "points",
          "skull"
        ]
      },
      "topic_id": 2,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.17566421168288968,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:05:51.409323+00:00"
      }
    },
    {
      "chapter_number": 13,
      "title": "Segment 13 (pages 121-128)",
      "start_page": 121,
      "end_page": 128,
      "summary": "Curved Paths for Seamless Character Animation \nrotation or translation to an animation that does not correspond to the way the character‘s \nEntertainment that uses cubic Bezier curves to allow the AI system to be more closely \ncoupled with dynamics and animation, considering the constraints of the character‘s \n[Johnson06] describes a method for fitting Bezier curves inside the cells of a navigation \nmesh to create a smooth path.\nThis gem describes in a more general way that Bezier curves \ncan be fitted to any piecewise linear path.\nThe vast majority of pathfinding solutions create a piecewise linear path first and then fit a \ncurved path to it.\npath.\nThe various methods of creating a piecewise linear path: (a) regular \ndifferent paths.\ndefine paths around the space provided that all edges that pass through an obstacle are \nclose to the corners of obstacles (this is known as a corner graph), so that the character can \nSmoothing the Path \nThe AI programmer‘s challenge is to create a piecewise linear path through the environment \nAs Figure 2.2.2 illustrates, the control points P0 and P3 define the start and end points, \nrespectively, while the control points P1 and P2 define the curvature at the end points.\nBezier curves are well suited to path fitting.\ndefine the curve’s position, shape, and curvature.\nThe curve will always be \nHaving constructed a piecewise linear path, we can fit cubic Bezier curves to it for a smooth \npath.\nBy choosing the control points so that for each consecutive pair of curves the output \nOur objective is to adhere to the linear path only as much as \nIf the character‘s momentum is high and a large sweeping curve looks most \nnatural, and provided there are no obstacles in the way of that path, we want to select such \nobstacles and there is little room to maneuver, we want a path that is as curved as possible \ncreate a Bezier curve from startPos to endPos, \nusing startVel and endVel to define the control points \nwhile the curve intersects an obstacle: \nrecalculate the Bezier curve \nif the curve still intersects an obstacle: \ndivide the path in two by choosing a point newPos along path \nThe whole process of calculating the piecewise linear path and fitting the curved path to it is \nsame piecewise linear path that we began with.\nA piecewise linear path is created that avoids an obstacle.\nThen a single cubic Bezier curve is fitted to it, which takes into account the character‘s \nBut this curve intersects with another obstacle, so a new path is \ncreated, using two cubic Bezier curves, that passes through another point on the piecewise \nlinear path.\nFitting a curve that accounts for character momentum.\nBezier curve A (light dashed line) is fitted to the piecewise linear curve (light filled \nBut this passes through another obstacle, so a new path B (heavy dashed \nline) is constructed from two cubic Bezier curves that passes through an \nintermediate point on the piecewise linear path.\nIn order for a character to walk along the Bezier path, we need to choose the maximum and \npoint of a single Bezier curve.\nthe Bezier curve.\nThus we have created a smooth path to the end point that avoids any obstacles in the \nAll that remains is to select the appropriate animation for the character that \nwill take it along this path.\nTo test the system, I created a character with a family of hand-designed animations for \nanimations had the same duration and path length but different amounts of rotation (for \nsame path length but a different amount of rotation (0, 22.5, 45, and 90 degrees).\ncharacter‘s position and orientation do not perfectly match the curved path.\nchoose an animation that will return the character to the path, but if his orientation is \narcs, and the full line, made of four cubic Bezier curves.\nIn conclusion, this gem has presented a simple and effective way to generate a curved path \nfrom any piecewise linear path that facilitates animation selection and promotes interaction \nbetween the AI and animation layers of a character.\n―Smoothing a Navigation Mesh Path.‖ AI Game Programming \n―An Algorithm for Automatically Fitting Digitized Curves.‖ \n―A Bezier Curve-Based Root-Finder.‖ Graphics Gems.\n―Building a Near-Optimal Navigation Mesh.‖ AI Game Programming ",
      "keywords": [
        "piecewise linear path",
        "cubic Bezier curves",
        "path",
        "Bezier curves",
        "linear path",
        "Charles River Media",
        "Bezier",
        "Character",
        "Game Programming Wisdom",
        "piecewise linear",
        "curve",
        "cubic Bezier",
        "Animation",
        "points",
        "Game Programming"
      ],
      "concepts": [
        "animation",
        "animations",
        "paths",
        "curved",
        "curve",
        "character",
        "points",
        "obstacles",
        "dynamics",
        "different"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 8",
          "chapter": 12,
          "title": "",
          "score": 0.5,
          "base_score": 0.35,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 14,
          "title": "",
          "score": 0.489,
          "base_score": 0.339,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 16,
          "title": "",
          "score": 0.447,
          "base_score": 0.297,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 18,
          "title": "",
          "score": 0.437,
          "base_score": 0.287,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 5,
          "title": "",
          "score": 0.424,
          "base_score": 0.424,
          "topic_boost": 0.0,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "path",
          "bezier",
          "piecewise linear",
          "curve",
          "linear path"
        ],
        "semantic": [],
        "merged": [
          "path",
          "bezier",
          "piecewise linear",
          "curve",
          "linear path"
        ]
      },
      "topic_id": 2,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.18831705538561294,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:05:51.409368+00:00"
      }
    },
    {
      "chapter_number": 14,
      "title": "Segment 14 (pages 129-138)",
      "start_page": 129,
      "end_page": 138,
      "summary": "The problem of solving a two-bone chain is often reduced to a two-dimensional problem by \nchains with more than two bones, there are several well-known algorithms used to solve \nFor the purpose of this gem, a bone is defined as containing a position and an orientation.\nWithout considering hands, feet, or any other child bones of the chain, a solution is defined \nas solving the chain such that the tip of the last bone touches, or comes as close to \nIn both cases, we have a bone chain with animation applied and a desired goal \nOne-Bone IK \nthe desired angle between the bone length vector and the bone-to-goal vector as the IK \nWhen solving a chain comprising one bone, the best that can be achieved is to adjust the \nbone‘s pose such that the bone length vector is aimed at the IK goal, as shown in Figure \nAiming a bone at an IK goal position.\nTwo-Bone IK \nrespective transforms with bones prior to it and after it in the chain.\nbones in the chain all lie on one plane prior to solving, then after solving the bones should \nThe first step to solving a chain is to offset the orientation of each bone by the shortest arc \nCalculating Bone 0 in a Two-Bone Chain \nThe vector from a bone to the tip of the chain prior to solving is called the bone-to-chain-tip \nvector, and the angle between the bone length vector and the bone-to-chain tip is the FK \nTo calculate the IK angle for Bone 0, we use the law of \nSolving the first bone in a two-bone chain.\nbone length vector and the bone-to-goal vector to get a delta angle, which we will use to \nthe bone-to-goal vector and the bone-to-chain-tip vector.\nSolving the Last Bone \nBone 1, or the last bone in any chain, is solved using the one-bone \nsolution described previously in the section ―One-Bone IK.‖ \nThree-Bone IK Solver \nThree-bone chain.\nMaximum Bone Angles \nCalculating the bone angle and the maximum FK and IK bone angles.\nWe can use the law of cosines to calculate a value that defines the angle of Bone 0 if the \ndistance to the FK chain tip, and the bone length are used to calculate the max bone angle.\nThe bone angle fraction is defined relative to the initial shape of the chain and is a \ncorrelation between the bone‘s orientation and the rest of the chain pose.\nremaining bone length can also be used to calculate the maximum possible angle that the \nThis maximum IK bone angle is multiplied by the bone angle \nfraction value to determine the new IK bone angle.\nFour-Bone IK Solver \nFigure 2.3.7 illustrates that with chains comprising three or more bones, the bones before \nthe bone length, the remaining bone lengths, the distance to the FK chain tip, and the \ndistance to the IK goal, a bone angle can be calculated.\nOnce the IK bone angle has been \ncalculated for Bone 0, then we simply continue down the chain, and Bone 0 can be solved in \nApplying the method to a four-bone chain.\nAn N-bone chain consists of three categories of problems.\nusing the method described previously of calculating maximum IK and FK bone angles to \nderive an IK bone angle.\nfor each bone in chain \napply chain target alignment to bone \ndetermine FK bone angle \ndetermine maximum FK bone angle \ndetermine maximum IK bone angle \nIK bone angle = ( FK bone angle / maximum FK bone \nmaximum IK bone angle \nIn some cases, the remaining chain length is greater than the bone length plus the distance \nmax IK bone angles hit this limit.\nAs shown in Figure 2.3.8, if the distance between the bone and the chain tip is greater than \nbone angle values can be calculated.\nThe following pseudocode describes how to calculate the maximum FK bone angle for a long \nangles for the maximum FK/IK bone angle values, while maintaining the important limits \nThe local position offset of a joint can be used as the bone length vector of the parent bone, \nThe FK bone angle and max FK/IK bone angles are all calculated \nAside from limiting the overall extension of the chain, it may be required that certain bones \nA simple way to do this is to limit the angle generated for each bone.\nDepending on the bone count, a chain ",
      "keywords": [
        "bone",
        "bone angle",
        "chain",
        "bone length vector",
        "bone length",
        "angle",
        "Maximum Bone Angles",
        "vector",
        "pose",
        "goal",
        "length",
        "remaining chain length",
        "chain length",
        "position",
        "length vector"
      ],
      "concepts": [
        "bones",
        "chain",
        "angles",
        "pose",
        "joint",
        "position",
        "limits",
        "vector",
        "local",
        "calculating"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 8",
          "chapter": 12,
          "title": "",
          "score": 0.539,
          "base_score": 0.389,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 13,
          "title": "",
          "score": 0.489,
          "base_score": 0.339,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 55,
          "title": "",
          "score": 0.385,
          "base_score": 0.235,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 16,
          "title": "",
          "score": 0.369,
          "base_score": 0.219,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 18,
          "title": "",
          "score": 0.368,
          "base_score": 0.218,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "bone",
          "chain",
          "ik",
          "bone angle",
          "angle"
        ],
        "semantic": [],
        "merged": [
          "bone",
          "chain",
          "ik",
          "bone angle",
          "angle"
        ]
      },
      "topic_id": 2,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.14886566787910535,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:05:51.409410+00:00"
      }
    },
    {
      "chapter_number": 15,
      "title": "Segment 15 (pages 139-147)",
      "start_page": 139,
      "end_page": 147,
      "summary": "Particle Swarm Optimization for Game Programming \nThis gem presents the foundations of Particle Swarm Optimization (PSO), a simple yet \nPSO is related to other population-based search strategies, such as Genetic \nOptimization problems are typically modeled as finding the maximum or minimum value of \nvector notation, the optimization problem is reduced to finding the roots (solutions) of the \ntechniques have been successful at solving many optimization problems common in industry \nproblems with a discrete set of solutions from which we want to find the optimal one—and \nstrategies used for guiding different heuristics in search problems).\nOptimizing can be regarded as a search problem where the selected optimization method \nperformance of all search (optimization) algorithms averaged over all possible objective \nThe PSO search strategy is based on an exchange of information between members \nPSO is a stochastic, population-based computer algorithm modeled on swarm intelligence.\nsocial behavior to continuous non-linear optimization problems.\noptimizes results.\ninitial PSO algorithm was presented, most of them resemble closely the original formulation.\nThe way PSO works is by ―flying‖ a swarm of collision-free particles over the search space \nEach particle represents a candidate solution of the \noptimization problem, and each element (dimension) of the particle represents a parameter \nto be optimized.\nThe movement of each particle in the swarm is dictated by the equations of \nwhere x(t) and V(t) represent respectively the particle‘s position and velocity at time t.\nAt t = 0, the position of each particle is selected from a uniform random \nsearch space boundaries for the j-th dimension.\nAs Equation (2) shows, the search process is driven by the velocity update, based on: \nExperience gained during the particle‘s search, expressed \nas the best location ever visited by the particle xCognitive_Best.\nthe particle‘s social network (xSocial_Best).\nby any particle in the swarm, hence called global best (gBest).\nfully connected xSocial_Best becomes the best position found by any particle in its local \nThe neighborhood is typically defined based on the particles‘ indices, although spatial \nProvides certain continuity to the motion of the particle.\nparticle‘s exploration and exploitation.\nparticle toward unexplored areas of the problem space.\nIn general, the PSO strategy is to use the cognitive and social best positions as attractors in \nthe search space of the particle.\nIt achieves that by defining the particle‘s velocity vectors \nAlgorithm 1 details the basic canonical PSO formulation implementing the gBest strategy, \nand Figure 2.4.2 illustrates graphically the position and velocity update of one particle based \n1: // Create a swarm of N randomly distributed particles \n2: FOR EACH particle(P) i=1,...,N do \n12:    FOR EACH particle(P) i=1,...,N do \n13:          IF Eval(P[i].X) BETTER_THAN Eval(g_Best.X) \n21:    FOR EACH particle i=1,...,N do \n24:              V_social = c1*rand(0,1)*(g_Best.X[j] - \nP[i].X[j]); \n25:              V_cognitive = c2*rand(0,1)*(P[i].x_best[j] - \nP[i].X[j]); \n30:                     Clamp(P[i].X[j]); // or any other \nIllustration of the velocity and position updates of a particle during \nthe optimization of a simple 2D parabolic function f(x,y).\nThe position update may take the particle outside of the predefined boundary.\nbeen proven that in high-dimensional swarms, most of the particles will leave the search \nSome strategies to constrain the particles to the \nMoving the particle to its closest boundary and setting its velocity to zero.\nReinitializing all components whose values are outside of the search space.\nEvaluating the Particles: The Objective Function \nis initialized within the size of the search space boundaries, in other words, V j max = κ · | x j \nSetting Vmax to the dynamic range of the particle.\nexploitation (fine-grained searches) of the area around the best particle(s).\nThe inertia coefficient has a clear influence in the particle‘s search strategy.\nthe optimum, we could decrease the value of ω in order to perform finer-grain searches.\ntheoretical optimal values for the PSO parameters to control both convergence and the \nThe velocity update could include both the global best and the local best particle: \nIn an optimization scenario, the constraints define feasible subspaces within the search \nAs a result, neither a simple circular search space (x2 + y2 ≤ radius 2), \nAfter evaluating the population, only particles within the feasible region can update \nAlthough PSO deals natively with optimization problems of continuous variables, it can also \nallowed in permutation problems), and particles need to be ―fixed‖ after every position \nelements of a particle different, while keeping their values within a certain range.\nA common problem in numerical optimization is premature convergence—in other words, \nparticles in the swarm.\nsmall subset of particles in the swarm.\ninformation (for example, gBest) and/or particles between swarms.\nswarm could use different search strategies (for example, some could use IBest, some \nPSO is a stochastic optimization technique that initializes its particles by placing them \nrandomly in the search space.\nlocation of the optimum, it is best to distribute the particles randomly, covering as much of \nThe spatial uniformity of the randomized particles can be improved by \nOne instance of two sets of 25 particles initialized in a two-",
      "keywords": [
        "PSO",
        "Particle",
        "PSO algorithm",
        "search space",
        "Particle Swarm Optimization",
        "Optimization",
        "search",
        "Optimization problems",
        "original PSO algorithm",
        "Velocity Update",
        "canonical PSO",
        "space",
        "velocity",
        "problem",
        "canonical PSO algorithm"
      ],
      "concepts": [
        "optimization",
        "optimal",
        "optimizes",
        "optimized",
        "particle",
        "algorithms",
        "values",
        "iteration",
        "iterations",
        "iterative"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 8",
          "chapter": 56,
          "title": "",
          "score": 0.358,
          "base_score": 0.358,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 27,
          "title": "",
          "score": 0.327,
          "base_score": 0.327,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 29,
          "title": "",
          "score": 0.32,
          "base_score": 0.32,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 28,
          "title": "",
          "score": 0.319,
          "base_score": 0.319,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 16,
          "title": "",
          "score": 0.319,
          "base_score": 0.319,
          "topic_boost": 0.0,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "particle",
          "pso",
          "search",
          "particles",
          "optimization"
        ],
        "semantic": [],
        "merged": [
          "particle",
          "pso",
          "search",
          "particles",
          "optimization"
        ]
      },
      "topic_id": null,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.16369728542254747,
        "topic_boost": 0.0,
        "timestamp": "2025-12-17T23:05:51.409450+00:00"
      }
    },
    {
      "chapter_number": 16,
      "title": "Segment 16 (pages 148-160)",
      "start_page": 148,
      "end_page": 160,
      "summary": "Case Study 2: Optimization of Physical Parameters for In-Game \ngait could be optimized individually by using specialized objective functions and running \noptimization‘s parameters list.\noptimization parameters.\nOnce the robot design is finished and the gait parameters optimized, the gait controller of \nflavor of proportional-integral-derivative controller, or PID) could also be optimized using \nConstrained Parameter Optimization Problems.‖ Evolutionary Computation 4 (1996): 1–32.\nImproved Numerical Integration with Analytical Techniques \nUsually the integration technique is based on the Symplectic Euler \nSuch integration methods are useful when the exact nature of the forces \nobject, we usually know the exact nature of forces that are currently acting on an object.\nforces, then we might expect to decrease the error of the integration dramatically.\nThe numerical integration steps the state of the body \neffect of acceleration acting over the course of the current time step.\ndetail the differences and implications of the integration techniques to aid the physics \nclassifying errors of integration techniques.\nOften, the method for classifying errors in integration techniques is to label them as first \nError can also be classified in terms of how well an integrator conserves energy.\nIntegrators \nSome integrators can conserve energy on \nIf an integrator adds energy to the system, \nbased on the fact that the stepping equations usually assume that the acceleration is \nThe kinematics of constant acceleration are a \nconstant acceleration with the results of a numerical method provides qualitative insight into \ndifference of positions implies that the velocity is constant over the course of the time step.\nnumerical methods do not involve any such equation, we are safe in making the comparison \nwith the kinematic equations for constant acceleration, at least over the course of a single \nKinematics of Constant Acceleration \nacceleration.\nWe can compare this set of equations to the results of common numerical methods in order \nmethod: \nmethod.\nThe Kinematic Integrator \nIf we are trying to find an integration method that when converted to a kinematic form is \nintegration method?\nassumption that acceleration is constant over the course of the time step.\nWe could use the acceleration averaged over the time step, \nBy inserting the average acceleration into the kinematic equations, we \nachieve a method that we will refer to as the average acceleration method.\ncalculate this average exactly, we must analytically integrate the acceleration over the time \nThe average acceleration method \ntherefore represents a blend between numerical and analytic integration.\nnumerically integrating the current position and velocity from the previous position and \nvelocity, but we are analytically integrating accelerations that are acting during the current \nOf course, calculating the average acceleration exactly requires that we know how to \nintegrate the particular force in question.\nphysics are analytic models that are easily integrated.\nfrom an analytic model of a force is usually just as easy as calculating the acceleration at an \nIf the average acceleration is calculated analytically, then the velocity portion of the \ndouble integral in order to achieve an exact result.\nfollow simple analytic models, then calculating a double integral is usually just as easy as \ncalculating a single integral.\nWe will generalize the idea of the average acceleration method in order to introduce the \nkinematic integrator.\nThe kinematic integrator is a set of stepping equations that allow for \nexact analytic calculation of both the velocity integral and the position integral.\nThe exact method uses the following definitions for dv and dx: \nIf we are using the average acceleration method, then we define dv and dx as: \nIn the case of constant acceleration, it is very easy to perform both the single and the \nThe integral contributions of a constant acceleration are given as: \nIf there are multiple forces acting on a body, we can express the integral contributions as a \nThus for the kinematic integrator we accumulate dv‘s and dx‘s rather than accelerations.\nforces acting on a body provide contributions to dv and dx.\nis dependent on the nature of the force and can usually be calculated exactly.\nacting on a body are integrable, then every contribution is exact.\nThe kinematic integrator can be used to perform the Symplectic Euler method with the \nfollowing integral contributions: \nThis method is useful if the acceleration is not integrable (or if we are too lazy to calculate \nthe integrals).\nThe kinematic integrator does not represent a specific integration method, but rather the \nability to isolate the portions of the stepping equations that actually require integration.\nSince the method used to evaluate the integral contributions is not explicitly specified, we \nuse the exact method.\nacceleration method.\nOr we could use the Symplectic Euler method if the force in question is \nIntegral Contributions Due to a Spring Force \nUsing this exact trajectory, we can determine the integral contributions: \nThe components of this matrix depend on the size of the time step Δt, the mass of the body \ncalculation of the integral contributions of a spring is relatively trivial—in other words, six \nslightly more complicated to calculate the integral contributions due to a spring that \nBefore discussing the integral contributions of other possible forces, we need to discuss \nIf all of the forces acting on a body depend only on time, then the result of accumulating \nexact integral contributions will be exact.\nforces depends on the position of the body, such as the spring force.\nThe integral contribution of the spring takes into account the position of the body at \nThe acceleration becomes: \nIf we are to handle these forces separately, then we would exactly calculate the integral \nIn this case, only a single integral contribution would be calculated.\nfunction of the position, which in turn is a function of the acceleration, then the integrals \nIf the acceleration only depends on time, there is no feedback, and the integrals can safely \ntime and accumulate their integral contributions as a group.\nThe integral contributions of \nSince we can integrate exactly the system with two springs, we can use this example to \ngauge the error present in the different methods for calculating the integral contributions.\nresults of integrating one spring; the second figure represents errors due to integrating two \nThe integration takes place over one half of the period of the two-spring system.\nNeither the average acceleration method nor the exact \nmethod conserve energy over long intervals of time.\nThe average acceleration method will eventually dampen \nFor this reason, the average acceleration method is preferred if the integration is going \nIntegral Contributions of a Pulse \nA pulse is a force that acts very briefly over the course of the time step.\nPulses acting at the beginning of the time step do not \nIntegrating the delta function is very \nTo represent the force as a pulse, we define the acceleration as: \nIntegrating this acceleration is easy to do: \nIntegrating the position contribution is now just integrating a constant.\nto pack all of the acceleration due to an arbitrary force into the pulse, then we use the \nIf you make the assumption that the acceleration is constant over the time interval, then \nIt is a method that assumes that the acceleration is constant over the course \nof the time step and delivers all of the acceleration in an instantaneous pulse at the \nSymplectic Euler method can be considered to be an exact solution to forces of an \nthe method is entirely due to the differences between the actual form of the force and the \nIntegral Contributions of Collision Forces ",
      "keywords": [
        "Symplectic Euler method",
        "average acceleration method",
        "Euler method",
        "method",
        "acceleration",
        "Symplectic Euler",
        "acceleration method",
        "integral contributions",
        "time step",
        "forces",
        "constant acceleration",
        "average acceleration",
        "time",
        "integral",
        "parameters"
      ],
      "concepts": [
        "integration",
        "integrating",
        "integrator",
        "integral",
        "parameters",
        "force",
        "optimization",
        "optimize",
        "optimized",
        "figures"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 8",
          "chapter": 12,
          "title": "",
          "score": 0.553,
          "base_score": 0.403,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 55,
          "title": "",
          "score": 0.506,
          "base_score": 0.356,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 18,
          "title": "",
          "score": 0.462,
          "base_score": 0.312,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 13,
          "title": "",
          "score": 0.447,
          "base_score": 0.297,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 17,
          "title": "",
          "score": 0.428,
          "base_score": 0.278,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "acceleration",
          "integral",
          "method",
          "integral contributions",
          "contributions"
        ],
        "semantic": [],
        "merged": [
          "acceleration",
          "integral",
          "method",
          "integral contributions",
          "contributions"
        ]
      },
      "topic_id": 2,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.15760992031241633,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:05:51.409493+00:00"
      }
    },
    {
      "chapter_number": 17,
      "title": "Segment 17 (pages 161-171)",
      "start_page": 161,
      "end_page": 171,
      "summary": "determine the force that is applied in order to resolve the collision, we need to apply a pulse \nforce that reflects the component of velocity vf about the contact plane.\nThe velocity of \nThus, all of the velocity is reflected.\nThe integral contributions of this force in the limit that df → 0 are given by: \nSince this force pulse does not contribute anything to the position integral, the application \nWe need to apply a second force pulse, which moves the position of the body out of the \nAdding these two sets of contributions together gives the final result for the collision force.\nIntegral Contributions of Viscous Forces \nA viscous force is a force that is related to, and usually opposing, the velocity of an object.\nThe equation can be solved for the velocity in terms of the constant k and the mass m.\nThis equation can be integrated to get: \nThe integral contributions of this force can be determined exactly and are given by: \nforce in the event that a collision is determined.\nIntegral Contributions of Constraint Forces \nforces for a collision can apply to all constraints.\ndetermine the direction of the force, the magnitude is calculated in order to bring the \nvelocity vn+1 into compliance with the constraint.\n3. If needed, another force pulse is applied in the same direction in order to bring the \nvelocity vn at the beginning of the current time step tn.\nThe state of a body is stepped forward in time using the kinematic integration equations: \nanalytically integrated per force and accumulated.\nmore than one force applied that depends on position, then the average acceleration \nThe contribution of a viscous force, with a viscosity constant v, is: \nFor a collision response force, the integral contributions are defined as: \ndetermine the direction of the force, the magnitude is calculated in order to bring the \nvelocity vn+1 into compliance with the constraint.\n3. If needed, another force pulse is applied in the same direction in order to bring the \nachieve exact trajectories for some force models.\nMost games simulate drag physics with a simple linear model, if they simulate it \nparameters of drag physics, such as the terminal velocity and the characteristic decay time.\nsmaller guns, golf ball trajectories, car racing games (air resistance is the main force that \nThe forces for the linear model are: \nAnd the forces for the quadratic model are given by: \nThe first term of both equations is the force due to gravity, and in my representation down \nThe velocity in these equations is the velocity of the object \nalong the current direction of velocity; thus, we can treat it as a one-dimensional problem.\nThe unit vector in the direction of the velocity is given by \nWe can update the velocity along the current direction of motion as well as \nIf the force is a \nfunction of the velocity alone, then these two equations can be combined to get time as a \nThe force equations that are relevant to the present matter are F = mg cos(θ)– αv, the \nlinear fluid resistance equation, and F = mg cos(θ)±βv2, the quadratic fluid resistance \nFor the linear equation, the negative sign in front of the velocity \nterm means the force always opposes the direction of motion.\nIf the velocity is positive, \nthen the force is in the negative direction.\nIf the velocity is negative, then the force is in the \nquadratic equation, the different sign must be applied based on which way the object is \nvelocity, and it shows up in the equations after we integrate.\ndrag model‘s terminal velocity and characteristic time is different than the linear drag \nmodel‘s characteristic time and terminal velocity.\nAnother way to calculate the terminal velocity is to set the force equation to \nzero and solve for the velocity.\nFor the quadratic case, we solve the equations in the same way.\nFrom this equation we define the terminal velocity, \nFirst, let us do the integral when the terminal velocity term (labeled with subscript 2s for \nthe quadratic model) and the velocity square terms have the same sign.\nwhere the force of gravity and the fluid resistance are in the same direction, which happens \nsolve for the time as a function of initial and final velocity to obtain: \nNow we solve this equation for the final velocity and obtain: \nSecondly, we solve for the case where the terminal velocity and velocity squared terms \nThe absolute value bars from the integral are important in order to get the equation to \nterminal velocity?\nand solving for the final velocity: \nand solving for the final velocity: \nFor the third case, v0 = vt2, where the object begins traveling at the terminal velocity in the \nsame direction as the force of gravity, we get: \ncases, Equations (3a) and (3b), or if we look at the force in the quadratic force equation, it \nis zero, hence the object must travel at a constant velocity.\nAnd lastly is the case when the terminal velocity is identically zero, Vt2 = 0.",
      "keywords": [
        "velocity",
        "force",
        "terminal velocity",
        "equation",
        "integral contributions",
        "Drag",
        "direction",
        "equations",
        "integral",
        "quadratic drag model",
        "contributions",
        "time",
        "quadratic force equation",
        "quadratic drag",
        "force equation"
      ],
      "concepts": [
        "force",
        "velocity",
        "velocities",
        "equations",
        "equation",
        "integral",
        "integrated",
        "integrator",
        "integration",
        "integrate"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 8",
          "chapter": 55,
          "title": "",
          "score": 0.601,
          "base_score": 0.451,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 19,
          "title": "",
          "score": 0.552,
          "base_score": 0.402,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 18,
          "title": "",
          "score": 0.506,
          "base_score": 0.356,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 12,
          "title": "",
          "score": 0.444,
          "base_score": 0.294,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 16,
          "title": "",
          "score": 0.428,
          "base_score": 0.278,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "velocity",
          "force",
          "terminal velocity",
          "terminal",
          "integral"
        ],
        "semantic": [],
        "merged": [
          "velocity",
          "force",
          "terminal velocity",
          "terminal",
          "integral"
        ]
      },
      "topic_id": 2,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.12029613553834355,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:05:51.409534+00:00"
      }
    },
    {
      "chapter_number": 18,
      "title": "Segment 18 (pages 172-180)",
      "start_page": 172,
      "end_page": 180,
      "summary": "The solutions of the three different velocity equations are: \nThe terminal velocities in the horizontal direction are zero.\nIf we integrate these equations with respect to time, then we get the position as a function \nThe complete distance equations are useful for AI targeting, AI pathfinding, and calculating \nIn general, the distance equations are well approximated for most video games with x \n= x0 + vt, since the time for most games is very small and is much faster than updating \nthe opposite direction as the current velocity.\nthe current velocity.\nAnd if the velocity is completely horizontal, the perpendicular force is \nFor the motion along the velocity normal, there are three different cases to consider: nz> 0, \nIf nz > 0, the object is moving upwards, the opposite direction from \nIf nz< 0, then the object \nLastly, if nz= 0, then the object is moving horizontally, and gravity has \n, and sign = – 1 The velocity is: \nThe velocity update is: \nFor the force perpendicular to the initial velocity, the updated velocity is the same as \nEquation (3) with v0= 0 and its own distinct terminal velocity, \nthe update time is usually small for games) as: \nterminal velocity or the characteristic time for the perpendicular motion if the mentioned \nIf this case is not handled, then the object \nthe object for the time it takes to get to the top with Equation (2) and then for the rest of \nthe time propagate with Equation (3a).\nFrom Equation (2), we can calculate the time it \ntakes to stop moving in the positive velocity direction.\nThen use the downward velocity update for the time \nVt, where the time, t, in the equation is the time since the last update and is not the global \nThis is the pseudocode for a function that calculates the final velocity, velocityFinal, \ngiven the initial velocity, velocityInitial, of an object by the time, deltaTime.\ndoes not update the position of the object, which should be updated separately but with the \nCalculate Velocity Normal or zero it.\nCalculate terminal velocity and characteristic time along \nvelocity \nFor objects going up use Equation (2), but first check \nFor objects going down use either Equation (3a), (3b), \nUpdate the velocity perpendicular to the initial velocity \nhardly prohibitive, especially if there are not too many objects updated with the quadratic \nThere are several advantages to the linear solution: There are exact velocity and position \nequations for all time, which is useful for AI and targeting; it is faster computationally; and \nespecially if there are many objects; there is no analytic solution for all time, thus it is not \nobjects and then use the quadratic for the more important, or highly visible, objects.\nintegration to update the object position.\nmany objects, especially for the quadratic case.\nPhysics in real-time simulations as well as in computer games has been gaining importance.\nsurface of the object.\nThe total pressure affecting the body surface in a given medium point can be represented \nfluid velocity V [m/s] at a selected position (applicable for subsonic speed).\nand the vector of the actual velocity in a selected point (see Figure 2.7.1).\nrepresented as a scalar product of the normal surface and the normalized velocity vector.\nNormal vector of the surface and normal vector of velocity and the \ncomputation of dynamic pressure based on velocity and assumes that we use a rigid body.\nthe immersion, velocity, surface area, and normal of each of the triangles that form the \nobject.\nFor calculations of the static pressure affecting the object, it is necessary to define the \nCalculating the Point Velocity \nTherefore, it is required to include the velocities of each of the object \nmesh points (Equation (9)) as a sum of the mass center‘s linear velocity Vobj and the \nobject‘s angle velocity (Figure 2.7.3).\nTo calculate the dynamic pressure, the local velocity \nvector, which is equal to the negative global point velocity, is required [Padfield96].\nVelocity of the arbitrary point belonging to the moving object.",
      "keywords": [
        "velocity",
        "equation",
        "object",
        "time",
        "equations",
        "direction",
        "surface",
        "Quadratic",
        "current velocity",
        "initial velocity",
        "velocity equations",
        "velocity normal",
        "Solution",
        "terminal velocity",
        "update"
      ],
      "concepts": [
        "equations",
        "equation",
        "game",
        "gaming",
        "object",
        "surface",
        "pressure",
        "pointing",
        "model",
        "time"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 8",
          "chapter": 17,
          "title": "",
          "score": 0.506,
          "base_score": 0.356,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 19,
          "title": "",
          "score": 0.468,
          "base_score": 0.318,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 16,
          "title": "",
          "score": 0.462,
          "base_score": 0.312,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 55,
          "title": "",
          "score": 0.451,
          "base_score": 0.301,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 13,
          "title": "",
          "score": 0.437,
          "base_score": 0.287,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "velocity",
          "object",
          "equation",
          "update",
          "time"
        ],
        "semantic": [],
        "merged": [
          "velocity",
          "object",
          "equation",
          "update",
          "time"
        ]
      },
      "topic_id": 2,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.14003944903472657,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:05:51.409576+00:00"
      }
    },
    {
      "chapter_number": 19,
      "title": "Segment 19 (pages 181-188)",
      "start_page": 181,
      "end_page": 188,
      "summary": "objects, when calculating the point velocity, it is necessary to take the so-called morphing \nand new local positions of the mesh points (see Figure 2.7.4), followed by the velocity \ndivided into three triangles calculated by cutting points of the edges that cross the medium \nBy applying Equation (11), we obtain PAB, PAC, and dividing the triangle ABC, we \nnormal, it is still necessary to recalculate the current surface area of each of those triangles.\nThis surface area can then be used to calculate the pressure \nCalculation of the Pressure on the Triangle Surface \nTo calculate the pressure force exerted on the arbitrary triangle of the body, the pressure at \neach of the triangle vertices should be taken into consideration.\nthe distance of each vertex from the medium surface for static pressure (Equation (6)) and \nthe vertex local velocity, taking the angle between the velocity and the triangle surface \nnormal into account, for dynamic pressure (Equation (7)).\ncomplete pressure of the triangle vertices is calculated.\nsome simplifications are possible for cases when any mesh vertex has the velocity \nlinear, and the calculation of the complete pressure exerted on the triangle surface is \nreduced to obtaining the pressure in the triangle center (based on h and Vp).\npressure force is a product of a triangle normal, its surface area, and pressure (Equation \ncomes down to summing the pressure forces from each surface fragment, as well summing \ntriangles.\nSimple Correction of Dynamic Pressure \nThe method for computing the static pressure presented in this gem is based solely on \ndynamic pressure, it is beneficial to introduce a correction in accordance with the velocity \ndynamic pressure force vector of the selected triangle has to be summed with the static \npressure force vector occurring on its surface.\nthe results of the real object (for example, an airplane) for which the dynamic pressure is \nThe simplified method of computing the flow around an arbitrary closed body presented \ndynamic pressure.\nobtained, by morphing the shape of the object‘s surface, or by moving or rotating the object \nAll of this is simulated based on the object mesh only.\nApproximate Convex Decomposition for Real-Time Collision \ndevelopers usually approximate the 3D models, such as game characters and static objects, \nconcave surfaces and generate false collision detections (see Figure 2.8.1).\nConvex hull versus approximate convex decomposition.\nIn this gem, we present a simple and efficient approach to decomposing a 3D mesh into a \nset of nearly convex surfaces.\napproximation of the original 3D mesh, particularly adapted to collision detection.\nintroduce the approximate convex decomposition problem.\nApproximate Convex Decomposition \nlinear surface composed of a set of triangles stitched along their edges.\nof triangles.) \nsurface normals to the vertices of k.\nA surface S is convex if it is a subset of the boundary \nexact convex decomposition of an arbitrary surface S consists of partitioning it into a \nminimal set of convex sub-surfaces.\nimpractical since they produce a high number of clusters, as shown in Figure 2.8.2 [Lien04].\nconsider instead the problem of computing an approximate convex decomposition (ACD) of \nExact convex decomposition versus approximate convex \nOther methods avoid this limitation by considering the original 3D mesh directly \nThey propose instead to compute the maximal distance between the mesh vertices and the \nHierarchical Approximate Convex Decomposition \nOur proposed hierarchical approximate convex decomposition (HACD) proceeds as follows.\nFirst, the dual graph of the mesh is computed.\nboundary of its convex hull [Preparata77], a faithful approximation of the original mesh is \nThis surface approximation is piecewise convex and has a low number of \nThe dual graph S* associated with the mesh S is defined as follows.\nby an edge of the dual graph) if and only if their corresponding triangles in S share an edge.\nFigure 2.8.4 illustrates an example of a dual graph for a simple 3D mesh.",
      "keywords": [
        "Approximate Convex Decomposition",
        "Convex Decomposition",
        "pressure",
        "dynamic pressure",
        "Convex",
        "Triangle",
        "Equation",
        "surface",
        "Approximate Convex",
        "pressure force",
        "Triangle Surface",
        "pressure force vector",
        "mesh",
        "dual graph",
        "Decomposition"
      ],
      "concepts": [
        "triangle",
        "surface",
        "mesh",
        "meshes",
        "convex",
        "pressure",
        "approximate",
        "approximations",
        "approximation",
        "approximating"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 8",
          "chapter": 17,
          "title": "",
          "score": 0.552,
          "base_score": 0.402,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 55,
          "title": "",
          "score": 0.54,
          "base_score": 0.39,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 12,
          "title": "",
          "score": 0.5,
          "base_score": 0.35,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 18,
          "title": "",
          "score": 0.468,
          "base_score": 0.318,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 16,
          "title": "",
          "score": 0.377,
          "base_score": 0.227,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "pressure",
          "convex",
          "surface",
          "convex decomposition",
          "decomposition"
        ],
        "semantic": [],
        "merged": [
          "pressure",
          "convex",
          "surface",
          "convex decomposition",
          "decomposition"
        ]
      },
      "topic_id": 2,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.14173438842143185,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:05:51.409618+00:00"
      }
    },
    {
      "chapter_number": 20,
      "title": "Segment 20 (pages 189-196)",
      "start_page": 189,
      "end_page": 196,
      "summary": "describing the concavity and the aspect ratio of the surface S(v,w) resulting from the \nAs in [Garland01], we define the aspect ratio Eshape(V,W) of the surface S (v,w) as follows: \nThe cost EShape(v,w) was introduced in order to favor the generation of compact clusters.\nInspired by [Lien08], we define the concavity C(v,w) of S(v,w), as follows (see Figure \nConcavity measure for a 3D mesh.\nwhere P(M) represents the projection of the point M on the convex hull CH(u,w) of S(v,w), \nwith respect to the half ray with origin M and direction normal to the surface S(v,w) at M.\nThis choice guarantees, for disk-shaped clusters, that the cost (α.EShape) is 10 times lower \nfrom the original mesh S to its piecewise convex approximation S′.\nComparative evaluation: (a,d,g,j,m,p) original meshes, (b,e,h,k,n,q) \npiecewise convex approximations generated by [Ratcliff06], and (c,f,i,l,o,r) \npiecewise convex approximations generated by the proposed HACD technique.\nColor Plate 8 presents the segmentation results and the approximate convex \ndecompositions generated by our approach for different 3D meshes.\ngenerated segmentations ensure a concavity lower than ε and guarantee that the maximal \nconvex approximations provide faithful approximations of the original meshes with a small \nFor all of the models shown in Color Plate 8, the piecewise convex approximations were \ncomputed by considering an approximation of the clusters‘ convex hulls with a maximum of \nWe have presented a hierarchical segmentation approach for approximate convex \nfaithful approximations of the original mesh by a set of convex surfaces.\nproposed technique efficiently decomposes a concave 3D model into a small set of nearly \n―Hierarchical Convex Approximation of 3D Shapes for Fast \n―Approximate Convex Decomposition.‖ Symposium on \n―Approximate Convex Decomposition.‖ John Ratcliff‘s Code \nSection 3: AI \nAI Level of Detail for Really Large Worlds \nA Pattern-Based Approach to Modular AI for Games \nAutomated Navigation Mesh Generation Using Advanced Growth-Based Techniques \nApplying Control Theory to Game AI and Physics \nWith recent advances in graphics and animation, AI is one of the areas of game \nsome of the most troublesome and encouraging future areas for game AI development.\nAdvances in AI architecture, believable decision-making, more detailed character \nsimulation, and player modeling all offer the possibility of creating new or improved aspects \ndevelopment of new AI gameplay on a project to a halt.\nworlds with high numbers of NPCs in their gem, ―AI Level of Detail for Really Large Worlds,‖ \nmanaging multiple simulation levels for each area of the game world.\nusing patterns in AI decision-making code in his gem ―A Pattern-Based Approach to Modular \nAI for Games.‖ The more effective an AI programmer is in creating reusable and scalable \nBased Techniques,‖ by D.\napplied to an agent‘s steering in ―Applying Control Theory to Game AI and Physics.‖ \nDecision-making is the aspect of AI that affects players most directly.\nallow NPCs to adapt better to players‘ combat behavior over time with their gem ―Adaptive \ncomplexity in building AI decision-making models in ―Embracing Chaos Theory: Generating \nZubek breaks down an AI decision-making approach used in games such as the Sims series \nin his gem, ―Needs-Based AI.‖ Phil Carlisle takes a look at how we can easily add emotional \nPlayer modeling is a burgeoning area of game AI.\nmodeling players in massively multiplayer games (MMOs).\nAs game AI programmers, we are now in the spotlight to create the next level of innovative \nAI Level of Detail for Really Large Worlds \nOne challenge for games featuring large worlds with many non-player characters (NPCs) is \nTo compromise between these two extremes, a number of level-of-detail AI techniques \nThis gem presents a LOD AI technique tailored for simulations of large worlds featuring \ndetail (LOD) based on the distance from the player or important places (Figure 3.1.1).\nThree types of level-of-detail AI techniques.",
      "keywords": [
        "piecewise convex approximations",
        "convex",
        "convex approximations",
        "convex approximations generated",
        "piecewise convex",
        "approximate convex",
        "Equation",
        "cost",
        "generated piecewise convex",
        "approximate convex decomposition",
        "cost EShape",
        "cost function describing",
        "convex surfaces",
        "Large Worlds",
        "NPCs"
      ],
      "concepts": [
        "games",
        "based",
        "player",
        "technique",
        "convex",
        "models",
        "cost",
        "worlds",
        "decimation",
        "decimated"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 8",
          "chapter": 5,
          "title": "",
          "score": 0.619,
          "base_score": 0.469,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 24,
          "title": "",
          "score": 0.565,
          "base_score": 0.415,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 49,
          "title": "",
          "score": 0.396,
          "base_score": 0.246,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 19,
          "title": "",
          "score": 0.368,
          "base_score": 0.368,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 2,
          "title": "",
          "score": 0.358,
          "base_score": 0.358,
          "topic_boost": 0.0,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "convex",
          "ai",
          "approximations",
          "convex approximations",
          "piecewise convex"
        ],
        "semantic": [],
        "merged": [
          "convex",
          "ai",
          "approximations",
          "convex approximations",
          "piecewise convex"
        ]
      },
      "topic_id": 4,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.1708202421921629,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:05:51.409661+00:00"
      }
    },
    {
      "chapter_number": 21,
      "title": "Segment 21 (pages 197-204)",
      "start_page": 197,
      "end_page": 204,
      "summary": "following LODs ranging from the full simulation to almost no simulation.\nwith LOD 5.\nLOD 3 will be used if the player is at \nThroughout, we will assume that LOD increases or decreases just by 1; larger changes can \nThe LOD AI technique is only related to the higher layer.\nSince the position of the player‘s avatar forces the maximum LOD AI in correctly designed \nIn our example, LOD AI Detail 5 takes \nthe whole world at the full AI LOD and that we need not care about animation.\nto think about what happens in the AI layer is in terms of a discrete-event simulation \nsimulation events, which are ordered in an event list.\nThese simulation events are abstract \nevery simulation event can generate a new simulation event to the event list or remove an \n1. Take the first simulation event from the event list and remove it from the list.\nb. Insert new simulation events to the event list at appropriate places.\nc. Remove some simulation events from the event list.\nFor more on discrete-event simulations and event \nThe simulation paradigm per se says nothing about how the simulation events relate to \nsimulation events around those changes in the state of the game that the AI layer should be \nIn a sense, the simulation events present the AI layer‘s window into the virtual \nOne class of simulation events is story-important events (for example, the dungeon‘s gate \nlist from the beginning or hooked into the event list by a trigger in run time (for example, \nbe represented by simulation events in the event list.\nrepresent each of them by a start event and an end event.\nDuring processing of a start event, first, \nlong the action will last, and its end event is hooked to the event list at the appropriate \nWhen this time comes and the end event is processed, states of some \nof this NPC is, hooking the start event of that action to the event list.\nAtomic action of sipping a beer is represented in the event list by a \nstart event and an end event.\nClassic discrete-event simulations typically work only with simulation events hooked into the \nevent list.\nanother part of the game can generate an event that has to be propagated to the AI layer \nThus, the AI layer must delete its end event and \ngenerate the start event of spilling action instead.\nAnother issue is that the time of actions‘ ends (thus, the time of end events) is only \nEnd events of these actions need to be \nToward LOD AI: Hierarchical Behavior \nThe question of this gem is how to make the mechanism of start events and end events \nfor tasks).\nThis is the level of the LOD that corresponds to the detail of the \nAtomic tasks are in \n3. Execute this task as atomic, approximating what would happen when the simulation \nWhat Does It Mean to Execute a Task as Atomic?\nFirst, every task to be executed atomically must be \nrepresented in the event list by a start event and an end event, similar to atomic actions.\nFor instance, assume that there is LOD 4 in the pub.\ncontains the task of drinking at a table.\nWhen a task is simulated in full detail, its particular runs can have different durations.\nexactly how long the task would have lasted had the simulation run in the full detail.\n1) at the beginning of the task (that is, when the start event is processed); 2) at the end (in \nother words, when the end event is processed); or 3) during the task.\nwhole simulation from scratch at each LOD, though programming more abstract levels is \nbetween its start event and end event.\nminers are drinking at a table atomically.\n1. Remove the end event of the expanded task from the event list.\n2. Compute the partial effect of the task stub, if needed.\nsimulation (in other words, as if the task was running from the beginning until the moment \ndrinkers would start with a full glass at the time of the LOD increase, but this may be fine if \nWhen you need to compute the partial effect of a task stub, what are the options?\nis desirable to avoid simulation of the task stub at the higher detail.\nstate variables the task changes predictably (see Figure 3.1.6, left and middle) and which it \nAlthough the final outcome of three tasks being executed atomically \nFor instance, think of the LOD increase from Detail 3 to 4 in the pub.\natomic actions) corresponding to detail n are being pruned away, whereas tasks \nSince the LOD decrease must apply to a whole area, as detailed later, more tasks may need \nto be pruned away—for example, drinking tasks of all individual miners in the pub.\nthe area will end up in an inconsistent state, with some tasks being simulated at detail n \nAn important point of any LOD AI is that, by definition, some information is lost during a \nLOD decrease.\nFirst, the partial effect of tasks and actions being \nsimulation at LOD n-1.\nLOD decrease.\nsimulation runs on the LOD 4, the walking barman is engaged in the task ―go-to-next-\nNow, consider the LOD decrease from 5 to 4 at time t2 —that is, around the middle of the \ninconsistencies due to a simplified determination of the initial state of the simulation at LOD \nA simple mechanism for avoiding early LOD increase will be shown later.",
      "keywords": [
        "LOD",
        "event",
        "event list",
        "simulation events",
        "end event",
        "Detail",
        "simulation",
        "task",
        "start event",
        "LOD increase",
        "LOD decrease",
        "end",
        "list",
        "atomic actions",
        "fantasy RPG setting"
      ],
      "concepts": [
        "events",
        "simulated",
        "simulation",
        "simulator",
        "simulate",
        "simulations",
        "level",
        "tasks",
        "time",
        "layer"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 8",
          "chapter": 22,
          "title": "",
          "score": 0.634,
          "base_score": 0.484,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 28,
          "title": "",
          "score": 0.598,
          "base_score": 0.448,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 31,
          "title": "",
          "score": 0.533,
          "base_score": 0.383,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 29,
          "title": "",
          "score": 0.444,
          "base_score": 0.294,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 27,
          "title": "",
          "score": 0.426,
          "base_score": 0.276,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "event",
          "lod",
          "simulation",
          "event list",
          "events"
        ],
        "semantic": [],
        "merged": [
          "event",
          "lod",
          "simulation",
          "event list",
          "events"
        ]
      },
      "topic_id": 1,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.20037694404716844,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:05:51.409704+00:00"
      }
    },
    {
      "chapter_number": 22,
      "title": "Segment 22 (pages 205-213)",
      "start_page": 205,
      "end_page": 213,
      "summary": "So far, we have spoken about how to simplify behavior given a LOD, but we also need to \ninformation about children, parents, and neighbors of every location except for the leaves \nFor simplification, assume now that the number of LODs equals the number of spatial levels.\nwhich LOD is where.\nthat is at the membrane at a particular instant is simulated as an abstract point.\nNo location \nEvery NPC is simulated at the LOD equal to the level on \nwhich the membrane is touching the area in which that NPC is located; spatial LOD \ndetermines behavioral LOD.\nLOD membrane.\nFormally, the membrane is nothing more than a list of locations that are simulated as \n1. If a location or an atomic place X is at the membrane, every location or atomic place \n2. If a location Y is above the membrane, every location with the same parent as Y is \nis above the membrane in this case, all rooms from the pub must be simulated at \nBecause LODs of two adjacent locations can differ (that is, when they do not have \ntwo neighboring locations may have different parents, thus their LODs can differ by more \ndetail, the second kingdom may still have just LOD 1; the houses do not have a common \nPositions of Objects and NPCs \nWe know that the pub is abstracted to a single point at LOD 3.\nWhat happens with their positions during LOD changes?\nBecause the pub‘s rooms do not exist at LOD 3, both the barman and the miner are, so to \nAssume further that the LOD decreases to 2.\nLOD increase.\nThe problem is that we need to narrow down object and NPC positions after the detail \nWhen the LOD goes from 2 to 3, we know that the barman has to be collapsed \nproblem arises for the LOD increase from Detail 3 to 4.\nWe now introduce a basic mechanism dealing with generation of positions of objects.\n1. Objects in every location should be divided into two groups—those that are location-\nnative, for objects owned by the location, and those that are location-foreign, for \nobjects owned by other locations.\n(A glass is location-native in the pub, as opposed \nto a mine truck.) An object can be location-native in more locations.\n2. Every location from the nth level of the spatial hierarchy should have a method \nimplementing where to generate location-native objects if the detail elevates from n \n3. When LOD decreases in a particular location, the detailed positional information for \nall the location-foreign objects having been ―lifted up‖ is memorized, but not for the \nlocation-native objects having been ―lifted up‖ (due to Point 2).\n4. When location-native objects ―fall through‖ the membrane, only their total number in \nlocation-foreign objects, the exact positions are remembered.\n5. When LOD increases, location-foreign objects are generated based on their stored \nobjects are native in which locations and implement placing algorithms appropriately.\nWhen a location-foreign object is simulated, it can hold its own positional information.\nrecords about location-foreign non-simulated objects‘ positions and about numbers of \nlocation-native non-simulated objects can be kept by parent locations.\nOften, when the parent location ceases to exist, the player is so far away that the records \ndesign phase, specify the information level denoting the LOD at which this particular kind of \nAt run time, after the location ―falls through‖ the membrane, \nattach your record to the upper location (in our case, the village) provided the new LOD is \nLOD is lower in the hierarchy!) \na location-native object.\nIf the player moves a table a bit, and the pub‘s LOD goes to and \nobjects‘ positions when the objects move between locations.\nAssume the pub is simulated at LOD 4, meaning all the pub‘s \nNow, the LOD elevates to 5.\nwould find useful a general placing mechanism that groups objects based on their typical \nConsider now that LOD \nexample on the CD, is to assign an existence level and a view level to every object.\ndetail decreases below the existence level, the object ceases to exist; otherwise, it is to be \nThe view level then determines the detail required by the object after it starts to \nFor many common objects, these levels will be equal, but not for story-important objects or \nBecause this may create new objects demanding additional LOD \nappropriate view level to ensure the player will see the AI behavior.\nWhat Is the Radius of LODs?\nnumber of locations between the object/NPC and the edge of the crater.\nFirst, the LOD does not change all the time, as would be the case \nProcessor consumption during the LOD increase.\nThe LOD increases at 10:15 p.m.; this time is \nsimulated for a while, disguising inconsistencies caused due to lower LODs.\nThere is a problem with reshaping the LOD membrane when an object moves between two \nThe LOD may start to oscillate, increasing the resources‘ consumption.\ndetermining when to decrease the LOD.\nthat enforces the LOD increase.\nWith the garbage mechanism, you do not decrease LOD until the resources are needed for \nIn practice, it rarely makes sense to have more LODs than levels of the spatial hierarchy.\nthis would increase the overhead for a LOD change.\nRecall that LODs also have to be assigned to the behavioral hierarchy.\nFor instance, if LOD 3 is assigned to watering a garden, it should also be \nlevels in behavioral hierarchy than LODs, as demonstrated on the CD example.\nAnother aspect to keep in mind is that after assigning LODs to tasks, objects required for \nLOD 3, and the garden is an abstract point at LOD 3.\nwatering a garden has to run with a watering can at this LOD, meaning the gardener has to \nthe can at LOD 3; the task‘s outcome would be the same, only the can would not be \nIn the latter case, you would need to generate the can after the LOD increase.\nNote that the technique does not allow for two existence levels for one object kind—for \ndifferent object kinds with two different existence levels.\nThe application included on the CD is a simulator of virtual worlds with LOD AI (in other \nimplemented demo world, which features five LODs and three kinds of NPCs: miners, \nThe code is in Java, and the documentation that is included details the LOD \nHowever, every LOD technique \nThe different number of LODs helps not \nLOD changes.\nSystems.‖ AI Game Programming Wisdom IV.\nAs an example of the latter advantage, imagine that we wanted to select a location for a ",
      "keywords": [
        "LOD",
        "Objects",
        "LOD increase",
        "LODs",
        "location",
        "membrane",
        "LOD membrane",
        "locations",
        "level",
        "Game Programming Wisdom",
        "Charles River Media",
        "pub",
        "LOD decreases",
        "game",
        "detail"
      ],
      "concepts": [
        "objects",
        "location",
        "locations",
        "located",
        "levels",
        "game",
        "simulated",
        "simulator",
        "behavior",
        "behavioral"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 8",
          "chapter": 21,
          "title": "",
          "score": 0.634,
          "base_score": 0.484,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 28,
          "title": "",
          "score": 0.517,
          "base_score": 0.367,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 32,
          "title": "",
          "score": 0.484,
          "base_score": 0.334,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 31,
          "title": "",
          "score": 0.46,
          "base_score": 0.31,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 25,
          "title": "",
          "score": 0.377,
          "base_score": 0.377,
          "topic_boost": 0.0,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "lod",
          "location",
          "objects",
          "membrane",
          "lods"
        ],
        "semantic": [],
        "merged": [
          "lod",
          "location",
          "objects",
          "membrane",
          "lods"
        ]
      },
      "topic_id": 1,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.18415605193592838,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:05:51.409745+00:00"
      }
    },
    {
      "chapter_number": 23,
      "title": "Segment 23 (pages 214-221)",
      "start_page": 214,
      "end_page": 221,
      "summary": "individual considerations was complete.\nfunctional point of view, finite state machines have a Boolean decision-maker attached to \nfor our considerations and then decide how to combine the results of their evaluation into a \n// Evaluate this consideration \nEvery consideration will inherit from this interface and therefore will be required to specify \nwhatever information might be needed to make a decision.\nGames are rife with examples of considerations that can be encoded in this way.\nexample, we might have a health consideration that will only allow an action to be taken if a \nA time-of-day consideration might only allow \ndown consideration could prevent an action from being taken if it has been executed in the \nThe simplest approach for combining Boolean considerations into a final decision is to give \neach consideration veto power on the overall decision.\nby the decision if and only if every consideration returns true.\nAs an example of this approach in a game environment, consider the simple state machine \nIn this AI, Chase is our default state.\nHere are the considerations we might \nHere are the considerations used above: \nLine of Sight Consideration.\nAiming at Consideration.\nCool-down Consideration.\nAbsolute Health Consideration.\nHealth Comparison Consideration.\nCompletion Consideration.\nthis specific example, but also in a great many decisions in a great many games.\n(in this case, one behavior per state), we know all of the decisions that need to be made \n(represented by the transitions), and we know the considerations that go into each decision.\neach transition contains a list of considerations.\nKeep in mind that the considerations don‘t always do the same thing.\nChase ⇒ Shoot and Chase ⇒ Dodge contain an Absolute Health consideration, but those \nconsiderations are expected to return true under very different conditions.\nShoot, we return true if the health of the player is above 0 percent.\nthe other hand, we return true if the health of our actor is below 60 percent.\ngenerally, each decision that includes this condition also needs to specify whether it should \nexamine the health of the player or our actor, whether it should return true when that value \nhow each instance of a consideration should evaluate the world is obtained through the \n// If true we check the player’s health, otherwise \nEvaluate() function will need from our data node.\nEach consideration is simple \nNow that we have built a functional core AI for our shiny new FPS game, it‘s time to start \nHere are the considerations for our new transitions: \nnew behaviors, but all of the considerations needed to decide whether to execute those \nOf course, not all changes can be made using existing considerations.\nto go through the entire AI for every character, find every place that these considerations \nconsideration took a single argument to specify the length of the cool-down.\ncontinue to work (with an exact value specified), but our Cool-Down consideration will now \ndo that, we simply implement an Is Weapon Drawn consideration and add it to the \nOne thing to notice is that all of the values required to specify our AI are selected at game \nThat is, we determine up front what decisions our AI needs to make, what \nconsiderations are necessary to support those decisions, and what tuning values we should \nspecify for each consideration.\nexample, our actor‘s hit points might go up or down, but if a decision uses an Absolute \nHealth consideration, then the threshold at which we switch between true and false never \nconsiderations, and each consideration contains the tuning values used for that portion of \nthe decisions are made, we only have to change data, not code.\nconsideration, will require code changes, but much of the tuning and tweaking—and \nFurther, since many of these considerations are \nbroadly applicable to a variety of games, not only the considerations but also the tools for \nMeta-Considerations \nFor example, if there are seven different decisions that evaluate the player‘s hit points, \nAbsolute Health consideration.\nCool-Down consideration, and a Distance to Player consideration.\nor two static values that are specified in data.\nconsiderations inherit from a Float Comparison consideration base class, then the data for \nsame way as every other Float Comparison consideration that he‘s used before.\nWhile nearly all decisions are ultimately Boolean (that is, an AI either takes an action or it \nOur next step should be to find a way for each of these considerations to evaluate the \nevaluations into a single score, which can be used to make our final decision.\nmodify our Evaluate() function so that it returns two values: a base priority and a final \nWhen every consideration has been evaluated, we first add all of the base \nComing back to our example, the considerations for economic value and strategic value \nthe strategic consideration.\nThese considerations could return a final multiplier of 1.\nThe consideration for the military situation, however, could be multiplicative in nature.\nIf we have no military units to attack with, then this consideration might \nof the base priorities add up to a negative value, or if any consideration returns a final \nsingle consideration can effectively veto an action by returning a final multiplier of zero.\nconsiderations can be reused elsewhere in the AI.\nOne weakness of the aforementioned approach is that it only allows considerations to have \nincluding an exponent to the set of values returned by our Evaluate() function and \ncomplexity of our AI, however, because this new value needs to be taken into account with \nevery consideration we implement and every decision we make.\ndecisions (such as those in an FPS game or an action game), we can often have the \nEvaluate() function return a base priority as before, but instead of returning a multiplier, \nit can simply return a Boolean value that specifies whether it wants to veto this action.",
      "keywords": [
        "consideration",
        "Absolute Health Consideration",
        "health",
        "health consideration",
        "Chase",
        "player",
        "decisions",
        "Boolean Decisions",
        "Evaluate",
        "Boolean",
        "decision",
        "action",
        "game",
        "Absolute Health",
        "Cool-down Consideration"
      ],
      "concepts": [
        "considerations",
        "consideration",
        "value",
        "decision",
        "decisions",
        "base",
        "based",
        "state",
        "stating",
        "health"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 8",
          "chapter": 27,
          "title": "",
          "score": 0.598,
          "base_score": 0.448,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 29,
          "title": "",
          "score": 0.538,
          "base_score": 0.388,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 28,
          "title": "",
          "score": 0.519,
          "base_score": 0.369,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 31,
          "title": "",
          "score": 0.463,
          "base_score": 0.313,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 21,
          "title": "",
          "score": 0.426,
          "base_score": 0.276,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "consideration",
          "considerations",
          "health",
          "decisions",
          "decision"
        ],
        "semantic": [],
        "merged": [
          "consideration",
          "considerations",
          "health",
          "decisions",
          "decision"
        ]
      },
      "topic_id": 1,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.1841389691516275,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:05:51.409788+00:00"
      }
    },
    {
      "chapter_number": 24,
      "title": "Segment 24 (pages 222-231)",
      "start_page": 222,
      "end_page": 231,
      "summary": "Instead of using a triangulation-based navigation mesh generation technique, we \napproached the problem using the Space Filling Volume (SFV) algorithm [Tozour04] as a \nSFV is a growth-based technique that first seeds the empty areas of a game world \nusing quads as the core shape in the algorithm, the problem of many regions coming \nbut produces low-coverage navigation meshes when applied to non-axis-aligned worlds or \nThe first is a 2D algorithm called Planar Adaptive Space \nOur new decomposition algorithms seed the world with growing quads, \nbetter approximate the shape the growing region intersected.\nThe second algorithm, Volumetric Adaptive Space Filling Volumes (VASFV), is, as the name \nThis algorithm, like its 2D cousin, generates a high-coverage decomposition of the \nVASFV will generate a single navigation mesh per level, removing a potentially \npre-seeded regions in a game environment to fill all of the available negative space.\ndetermining whether a growing region has intruded into a positive space area.\nthe negative space regions in the world must be convex; otherwise, the collision detection \nregion has ended a growth cycle covering an area of the level, it must continue to cover \nOur algorithm begins in a state we refer to as the initial seeding state, where the world is \n―seeded‖ with a user-defined grid at specified intervals of negative space regions.\nregions will grow and decompose the world.\nThe initial placement of these regions in the world is such that they are axis-aligned.\nbeing seeded in the world, each of the placed regions is iteratively provided a chance to \nGrowth is defined for a region as a chance to move each edge outward individually in \nThe first case occurs when all of the positive space regions are axis-aligned.\nmore advanced decomposition case occurs if there is non-axis-aligned geometry.\nFirst, we will examine the base case or axis-aligned case for a spatial decomposition in \nGrowth occurs in the direction of the normal for each of the edges of a region and is \nAfter an edge has advanced, we verify the new regional coverage \nexpanded region have intruded into any of the other regions or any positive space \nbe contained within the growing region.\nthat the region is still convex.\naligned world and can be omitted if there are no non-axis-aligned collision objects.\nthe region finalizes its current shape, and the next region grows.\nFirst, the growing region \nAt this point, since both the region and the obstruction it \ncollided with are axis-aligned, we know the region is parallel and adjacent to the object, as \niterative growth proceeds until no region is able to grow.\nThe growing negative space regions are shown as white boxes, and the direction \nPositive space regions are drawn in gray.\n(a) we see the most basic axis-aligned collision case.\ncase that occurs when a vertex of a positive space object intersects a growing \nnegative space region.\nnegative space region is subdivided into a higher-order polygon to better adapt to \nThe advanced case algorithm for PASFV is able to deal with a much wider variety of world \nit needs to deal with non-axis-aligned positive space regions, it incorporates several new \nWhen a collision with a positive space object \nthe positive space object is parallel to the edge of the growing negative space region.\nparticular obstruction is axis-aligned, so we revert to the base case.\nThe second case occurs when a single vertex of an obstruction collides with a growing edge, \nthe negative space around the object will have to be covered by additional seeding passes, \nThe final, most complex, collision case occurs when a vertex of the growing region collides \nwith a non-axis-aligned edge of a positive space obstruction, as shown in Figure 3.3.1(c).\nlong as this newly generated non-axis-aligned edge is adjacent to positive space, no other \nregion can interact with it, and we limit region-to-region collisions to the base case.\nworld, the algorithm stops once all of the regions present in the world are unable to grow \nplaces new regions (seeds) in any adjacent unclaimed free space, and then we flag the \nregions.\nThe growing negative space regions are \nPositive space regions are drawn in gray.\nThe Volumetric Adaptive Space Filling Volume (VASFV) algorithm [Hale09] is a natural \ndecomposed areas remain decomposed and that all regions always end a growth step in a \nseeding a grid of initial regions throughout the world.\nand allows the ground-based regions to grow up to the maximum allowable height.\nseeds are initially spawned as unit cubes represented as regions with four faces listed in a \nAt this point, the regions may grow and expand.\nAs with the planar version of this algorithm, there are two main cases to deal with: axis-\nThe base case for the axis-aligned world proceeds in a \nand that the region is still convex.\nAs with the planar version of this algorithm, this base case will produce a \nLike the planar version of the algorithm, the advanced growth case for dealing with \ncollisions with non-axis-aligned geometry can be broken down into four cases (shown in \ngrowing cubic region has intersected one or more vertices of a positive space obstruction.\nThe growing negative space regions are shown in white.\nIn order to clearly show how the negative space region reacts to a \npositive space collision, the positive space object is not drawn, and the colliding \nwhere a new triangular face is inserted into the negative space region.\ninserted into a negative space region to better approximate the object it collided \nThe next three collision cases occur when vertices from a single face of the growing \nnegative space region intersect positive space.\nwhen three or more vertices of a negative space region intersect the same face of a positive \nWhen this happens, it means that the growing face of the negative space \nThis tells us that since the negative space face is axis-aligned, the positive space face \nThe final two collision cases require the insertion of a new face into the negative space \nregion so that it adapts to the face of the collided object.\nvertex of the region intersects an obstruction.\nThe final collision case occurs when exactly two vertices of a negative space region intersect \nThis means that a single edge of the region is in contact with the shape it \nface to the region and by subdividing each colliding vertex into two vertices.\nWith the last two special collision cases, it is possible to generate navigation meshes with a \nalgorithm iteratively provides each region a chance to create new seeds in adjacent \nnegative space regions.\nHowever, instead of immediately growing the new regions, the \n3D, but it serves an important purpose in orienting region growth to better accommodate \nregion that grows up adjacent to the bottom of the stairs will generate a single seed midway \nspace regions are marked in white.\nNegative space regions in this illustration are \ngravity-assisted seeding, when a seed is generated from the initial region at the bottom of \nseeding is also applicable to other methods of world space traversal, such as flight, because \nAll of the negative space regions should be examined for zero-\nnegative space regions.\nAside from which negative space regions connect to each other, \nIn this gem, we have presented two new growth-based methods of generating navigation \nobstructions, while the variously colored regions show negative space.\nimage shows a navigation mesh generated by VASFV on a non-axis-aligned \nfour different negative space regions can come together at a point, since all negative-space-\nto-negative-space collisions will be axis-aligned, and the angles involved in these collisions \nBy presenting both 2D and 3D algorithms for generating spatial decompositions, we are \nproducing a navigation mesh and into advanced growth-based techniques.\nRegion Decomposition for Real-time Spatial Agent Navigation in Virtual Worlds.‖ Artificial \nStanford University, Stanford, CA.",
      "keywords": [
        "negative space regions",
        "space regions",
        "negative space",
        "space",
        "Space Filling Volumes",
        "positive space regions",
        "positive space",
        "region",
        "Adaptive Space Filling",
        "Space Filling",
        "growing negative space",
        "Navigation Mesh",
        "algorithm",
        "positive space object",
        "case"
      ],
      "concepts": [
        "region",
        "regional",
        "algorithm",
        "seeds",
        "space",
        "cases",
        "base",
        "based",
        "collision",
        "collisions"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 8",
          "chapter": 5,
          "title": "",
          "score": 0.566,
          "base_score": 0.416,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 20,
          "title": "",
          "score": 0.565,
          "base_score": 0.415,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 49,
          "title": "",
          "score": 0.529,
          "base_score": 0.379,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 48,
          "title": "",
          "score": 0.454,
          "base_score": 0.454,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 13,
          "title": "",
          "score": 0.379,
          "base_score": 0.379,
          "topic_boost": 0.0,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "region",
          "regions",
          "negative space",
          "space",
          "space regions"
        ],
        "semantic": [],
        "merged": [
          "region",
          "regions",
          "negative space",
          "space",
          "space regions"
        ]
      },
      "topic_id": 4,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.23773906186524119,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:05:51.409856+00:00"
      }
    },
    {
      "chapter_number": 25,
      "title": "Segment 25 (pages 232-239)",
      "start_page": 232,
      "end_page": 239,
      "summary": "A Practical Spatial Architecture for Animal and Agent Navigation \nthat animals and agents use as locomotion in the real world.\nThe architectonics[1] of space relative to an animal‘s or agent‘s motion \nan environment is that it is this spatial vacuum that frames our interactions (be they \nlocomotion or a simple idle animation) within that environment.\nsystem between objects in our environments.\nbecause we desired our animals‘ motion to be credible.\nAn important aspect of any animal‘s believability is that they are not only aware of their \n2 contain examples of WOZ‘s environment) in a spatially appropriate and consistent \nThis maxim had to hold true whether the animal was locomoting over land, over \nTo help facilitate the representation of our spatial environments, \nThe primary element for constructing a spatial representation in WOZ was the sphere, \nnavigable representation of the world (see below), but more importantly, it defines the \nwhere an animal can go, not just where it cannot.\nthat an animal is nearing the edge of navigable representation.\ncan augment the animal‘s behavior to slow down, start to turn away, or skid to a stop.\nIt should be noted that the navsphere is an approximation of space, and it is not an exact \ndiscovered to be applicable for a spatially accurate representation of an environment was \nanimals would move.\nAs an animal moves through an environment, there need to be mechanisms in place to help \ncontrol an animal‘s interaction with navspheres—we do this by assigning properties to the \ndefining the type of animal locomotion allowed in that navshape (whether it be land, water, \nor air) and spatial parameters for certain animal sizes.\ncapable of generating a navigable representation—a navrep—of the environment.\nFigure 3.4.2 shows the overlapping navspheres for \nthe overlapping navspheres in Figure 3.4.2.\nThe primary reason to construct a connectivity graph from the spatial representation is that \nway links by embedding directed connectivity information in the navsphere itself; this \nAs we move on to discussing the spatial aspects of the WOZ navigation system, it will help \nthe WOZ game is the navigation manager.\nanimal (noted as an entity in Figure 3.4.4) needs to route through an environment, it will \nissue a call through the animal planner into the navigation manager.\nmanager will then access its own world planner, and using the navrep it generates a coarse \nThis coarse route is then returned to the animal‘s planner \nAs you‘ll notice in Figure 3.4.4, WOZ has two planners: the navigation planner and \nthe animal planner.\nThe animal planner handles any immediate spatial or interanimal tasks, \nwhile the navigation planner handles the more rudimentary routing operations (for example, \nauthor disparate navreps based upon differing navrep types (for example, land or water), as \nLinking multiple, non-overlapping navreps in the navigation system \ntwo disparate navreps with the final result, on the right, of a navigable navrep.\nNavfeelers allow the level authors to link these navreps together.\nLocomotion in WOZ is executed by root accumulation of multiple animations that form a \nBy root accumulation, we mean that the animators author with full displacement; \nbe lost in the typical engineer-centric approach, where the animators are required to author \nanimations on the spot.\nWhile root motion is very necessary for exhibiting animator-\nallowed the animators to avoid generating a host of different turn animations.\nturn angle, an animal selects a target point, such as the next point along a route or a game \nIf we had an animal with a \nof progression through our navigation system: locomotion and turning.\nwas generated from the navspheres), we turn to the spatial representation of the world in \nEach animal has associated with itself \nEach animal has an occupancy shape.\nis used to denote the rough spatial representation relative to the navigation \nOne key differentiation in the navigation system implemented for WOZ versus other games \nis that during normal locomotion an animation could and generally would deviate from the \nThis is not dissimilar to how real animals or humans move through the world.\nidentify boundaries and make use of the relationships between the space and objects we are \nSo it made sense to ensure that WOZ‘s animals respect the spatial \nTo help influence the turning of an animal, we implemented a system that uses a series of \nspheres projected around an animal in order to determine the suggested turn angles.\nFor example, if an animal‘s motion wanted to move it into a wall, we \nthe current animation.\nBy projecting these spheres around the animal, we could make turns that \nwould take the animal away from objects according to their spatial proximity to the navrep \nWhile there are many navigable representations that can be used in a game, very few of \nanimal or agent as it occurs in the real world.\nAnimals or agents don‘t follow exact routes; \nrethink an animal‘s or agent‘s interactions inside an environment.\n―Search Space Representations.‖ AI Game Programming Wisdom 2.",
      "keywords": [
        "Animal",
        "Navigation System",
        "system",
        "environment",
        "Spatial",
        "WOZ",
        "Navigation",
        "Blue Fang Games",
        "space",
        "WOZ navigation system",
        "Navigation Michael Ramsey",
        "Spatial Representation",
        "Game",
        "navspheres",
        "navrep"
      ],
      "concepts": [
        "spatial",
        "spatially",
        "animal",
        "animation",
        "animations",
        "animators",
        "games",
        "motion",
        "turn",
        "navigation"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 8",
          "chapter": 22,
          "title": "",
          "score": 0.377,
          "base_score": 0.377,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 13,
          "title": "",
          "score": 0.356,
          "base_score": 0.356,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 28,
          "title": "",
          "score": 0.345,
          "base_score": 0.345,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 24,
          "title": "",
          "score": 0.342,
          "base_score": 0.342,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 12,
          "title": "",
          "score": 0.321,
          "base_score": 0.321,
          "topic_boost": 0.0,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "animal",
          "navigation",
          "spatial",
          "woz",
          "planner"
        ],
        "semantic": [],
        "merged": [
          "animal",
          "navigation",
          "spatial",
          "woz",
          "planner"
        ]
      },
      "topic_id": null,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.1810259012213311,
        "topic_boost": 0.0,
        "timestamp": "2025-12-17T23:05:51.409899+00:00"
      }
    },
    {
      "chapter_number": 26,
      "title": "Segment 26 (pages 240-247)",
      "start_page": 240,
      "end_page": 247,
      "summary": "oscillations die out (or grow) exponentially according to a damping coefficient ζ (zeta).\nsingle harmonic oscillator looks something like Figure 3.5.1.\ndamping coefficient, as in Equation (1), look like Figure 3.5.2.\nproduce linear equations.\nWe did not say what the units of Equation (1) are or how you should implement the result.\na circle (which doesn‘t look like Equation (1) at all) is consistent with linear control theory: \ntemplate of Equation (1).\nLinear Systems \nlinear dynamic system is one whose defining equations of motion follow the form: \nEquation 3  \ncertainty that all linear systems follow the form of Equation (1) is that the result is a \nthen the results don‘t look like those sinusoidal functions.\nnon-linearities in their systems; this usually means that the coefficients A in the equations \nis not linear.) When engineers try to apply linear control theory to systems \nwith non-linearities (and they always do; a good part of controls engineering consists of \nfinding ways to approximate non-linear reality with linear equations), the results often look \nsimilar to Equation (1) but the ω, ζ, and A values of the different modes keep changing, or \nSystems oscillate the way they do because of internal feedback among components.\nthe damping coefficients ζ in Equation (1) is negative, then the entire system is unstable (in \nexponential part of the equation is positive, so the sinusoidal oscillations expand \nSecond-Order Linear Differential Equations \nLet‘s look at how Equation (2) is derived for a couple of simple harmonic oscillators.\nEquation (2) is the general solution of the second-order linear differential equation (LDE); \nfirst- and second-order differential equations.\nEquation 4  \nthe imaginary part of the result oscillates in a sine-like way while the real part either grows \nEquation 5  \nNow for the solution to the equation resulting from Examples 1 and 2: \nFind all equations y(t) that obey the differential relation \nEquation 6  \nSolving a differential equation, solving an exponential \nEquation 7  \nEquation 8  \n[1] It would be a fair question to ask what the meaning is of the imaginary part of the equation, since \njust ignore the imaginary part and read only the real part of the equation.\nwithout going back through the differential equation.\nEquation 9  \ndiagramming, but a block diagram can help explain how control inputs apply to the \nEquations (1) and (2) are what are called transfer functions.\nfunction is the conversion between input and output.\ninto one that accounts for the effects of steering or other control inputs.\ngame: H(s), which represents the internal dynamics of the steering system, is modeled as a \ncontrols, is also linear and can be redrawn as a single ―black box‖ transfer function.\ntransfer function where the input is the desired course and the output is the actual motions \nThis does not work for a real person but can represent any linear controls, \nthe implied control responses from a system transfer function.\nThe block diagram of Figure 3.5.6 replaces differential equations with Laplace transforms.\nFor our examples, G(s) is the Laplacian L of Equation (6), which is As2 + Bs + C.\nLaplace transform is a clever mathematical trick that converts differential equations to more \nEquation 10  \nEquation 11  \nmeasurement transform to the same s, it is possible to mix transfer functions whose \noutputs are in different units in the same block diagram.\nEquation 12  ",
      "keywords": [
        "Equation",
        "system",
        "equations",
        "linear",
        "Differential Equations",
        "linear equations",
        "Linear Differential Equations",
        "control",
        "block diagram",
        "Laplace Transform",
        "Linear Systems",
        "complex",
        "functions",
        "Block",
        "units"
      ],
      "concepts": [
        "equation",
        "equations",
        "functions",
        "function",
        "linear",
        "engineers",
        "oscillations",
        "oscillate",
        "oscillators",
        "mathematical"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 8",
          "chapter": 16,
          "title": "",
          "score": 0.356,
          "base_score": 0.206,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 18,
          "title": "",
          "score": 0.339,
          "base_score": 0.189,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 13,
          "title": "",
          "score": 0.322,
          "base_score": 0.172,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 14,
          "title": "",
          "score": 0.317,
          "base_score": 0.167,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 12,
          "title": "",
          "score": 0.312,
          "base_score": 0.162,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "equation",
          "differential",
          "equations",
          "linear",
          "differential equations"
        ],
        "semantic": [],
        "merged": [
          "equation",
          "differential",
          "equations",
          "linear",
          "differential equations"
        ]
      },
      "topic_id": 2,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.04565333502145552,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:05:51.409939+00:00"
      }
    },
    {
      "chapter_number": 27,
      "title": "Segment 27 (pages 248-260)",
      "start_page": 248,
      "end_page": 260,
      "summary": "roots of the characteristic equation of the system correspond to the n harmonic modes in \nAdaptive Tactic Selection in First-Person Shooter (FPS) Games \nThe ability of a human player to adapt to opponents‘ tactics is an \nto adapting an NPC‘s selection of combat tactics.\nA Dynamic Approach to Adaptive Tactic Selection \nTo achieve successful in-game (that is, run-time) tactic selection in FPS games, we \nscripted tactic selection techniques used in commercial FPS games.\nto the selection of tactics rather than rules for scripts, so it has a number of differences \nFirst, the library of tactics in the developed system \nsuited to FPS games, as the selection of player-versus-player tactics greatly depends on the \nfunctions to evaluate the success of a tactic and the encounter with an opponent.\ncontribution is the development of a tactic selection process that makes use of a prioritized \nOverview of the Adaptive Tactic Selection Architecture \n3.6.1, the upper layer determines which tactic library should be selected according to an \nFor example, an ―engage enemy‖ library of tactics could be defined \napproach should allow the tactic selection architecture to be easily integrated with existing \nAs illustrated in Figure 3.6.2, the lower state space contains instances of a library‘s tactics \nThe feature space and the number of tactic \ninstances within a tactic library are kept relatively small in order to maintain performance.\nOnce the upper layer has determined the current tactic library, the K closest library \ninstance(s) to the current game state are selected and used to determine the NPC‘s current \nlist of tactics.\nIf the closest library instance to the query state (in other words, the NPC‘s current \nstate) is equal or below a predefined threshold, it is used to determine a prioritized tactic \nIf the closest library instance is above a predefined query threshold, the K closest tactic \ninstances to the current environment state are used for tactic selection.\napproach to selection allows tactics to be associated with detailed game states, while also \nOverview of the tactic selection process and the state organization.\nThe weights of each tactic are combined using \nAll tactics have an associated weight that influences the order in which they are selected in \nThe weights reflect the success or failure of a tactic during previous \nLearning only occurs between the tactics in each library \ninstance, and one library does not affect the learning in another, even if the same tactic is \nTactic selection is achieved through a prioritized list [Isla05], which \nIf K > 1 and the closest tactic instance is above a query threshold, \nthe tactic‘s weights are combined using the distance-weighted K-NN algorithm.\nindividual or combined tactic library instance is used to create the prioritized list.\ninstance are found and used to determine a combined weight for a tactic.\nThe position of a tactic within the prioritized list is determined by ordering tactics according \n(For example, the tactics with the largest weights have the highest priority \nof selection.) A new prioritized list of tactics is generated whenever an upper layer state \ncan interrupt the current tactic on the next game loop.\nelapsed, the next tactic in the list that is capable of running is selected.\nWhen a tactic is \nchange occurs, the tactic has its weight updated according to a weight-update and fitness \nthreshold, the weight update is applied to the tactics in each K close library instance \nThe weight-update function alters the weights associated with tactics in response to a \nreinforcement signal that is supplied by tactic and encounter fitness functions.\nthe fitness function is to reward tactics that defeated an opponent or improved the NPC‘s \nThe fitness functions for the tactic and the encounter are \nThe equation above evaluates the fitness of a tactic and contains two components.\nequation, f refers to the fitness of the tactic t that is being evaluated.\nA(t) ∊ [–1,1] determines the difference in life caused by the tactic [Andrade04].\ntactic.\nIn the tactic selection architecture, the experience is the average value \nEach component of the tactic fitness function is weighted according to its contribution as in \nThe two components of the tactic fitness function are determined using Equations (2) and \naverage difference in life caused by the tactic from the previous n weight updates.\nEquation (4) evaluates the fitness of an encounter, that is, the tactics used by the adapting \nstate, the tactics used during the encounter are updated according to whether the NPC won \nperformance of tactic t.\nperformance of tactic t.\n1. Equation (4) divides health lost by 125 in order to give the tactic a guaranteed reward or \nThe weight update function uses the tactic and encounter fitness functions to generate a \nweight adaptation for the library tactics (i.e. an amount to adjust the current weight of a \ntactic).\nreturn a value between [–1, 1], where a negative fitness value indicates a losing tactic, \nwhile a positive fitness value indicates a winning tactic.\nmaximum reward, F is the fitness of the tactic, and b is set to 0 and is the break-even point \nfor the tactic‘s fitness.\nAbove this point, the tactic‘s fitness is considered to be winning, \nWhen multiple tactic library instances are used to create a combined prioritized list, the \nAdapting Tactic Selection \nTo illustrate the tactic selection architecture, we describe the example of an NPC learning to \nadapt its selection of combat tactics.\ndetermine whether a tactic is capable of running.\nFor example, the circle strafe tactic may \nFor clarity, only one tactic library is used in this example.\nthe selection of tactic libraries using conventional techniques, and adaptation occurs \nindependently within each tactic library instance; therefore, additional tactic libraries can be \nAfter a library has been defined, the default weight of the tactics needs to be \nTactics can be given the same initial weight, or a weight can be selected based on \nIn this example, all the tactic weights are initially set to the same \ndefault weight; therefore, the position of tactics within the initial prioritized list is randomly \nOnce a tactic library has been defined, the next step is to determine the instances of the \nfactor in the selection of FPS tactics.\nThe position of tactic instances in the state space can be \nsuch as: if s > r, then create a new instance of the tactic library, where s is the distance \nbetween the current state and the closest tactic instance and r is a predefined distance \nFigure 3.6.3 illustrates an example of tactic library instances and state space organization.\nAt the start of a combat encounter, the tactic selection architecture generates a list of \ntactics that are ordered by their associated weight.\nopponent by executing the first tactic in the list.\nIf the tactic is not capable of running, the \nnext tactic in the list is selected.\nThe list of tactics is generated by determining the closest K library instances to the NPC‘s \nOnce a tactic and encounter are complete, the weight of \nthe tactics used are updated using Equations (1) and (4).\nthe initial weights of tactics are the same; therefore, only the closest library instance is \nA prioritized list of tactics is generated, and the melee attack tactic is selected for \nThe encounter finishes with the death of the adapting NPC; therefore, the tactic and \nThe tactic‘s weight is updated based on its \nThe first step in the process is to determine a tactic‘s fitness—in this \nOnce the fitness of the tactic has been determined, the weights of all the tactics in \nthis example, the weight adjustment for the performed tactic is determined as \nlooping through the tactics used during the encounter, determining their encounter \ntactic used during the encounter and its performance.\nAfter the tactic weights have been updated, the adapting NPC can generate a new \nIn this example, the melee attack tactic will be at the end of the list \nThis gem has outlined an approach to the in-game adaptation of scripted tactical behavior in \nof tactics in a given state based on their experience of the tactics‘ success.",
      "keywords": [
        "Tactic",
        "Tactic Selection",
        "tactic library",
        "equation",
        "NPC",
        "Tactic Selection Architecture",
        "tactic library instance",
        "library instance",
        "state",
        "characteristic equation",
        "library",
        "state space",
        "tactic fitness function",
        "Adaptive Tactic Selection",
        "weight"
      ],
      "concepts": [
        "tactic",
        "tactical",
        "game",
        "gaming",
        "stating",
        "state",
        "roots",
        "weight",
        "equation",
        "equations"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 8",
          "chapter": 28,
          "title": "",
          "score": 0.599,
          "base_score": 0.449,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 23,
          "title": "",
          "score": 0.598,
          "base_score": 0.448,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 31,
          "title": "",
          "score": 0.524,
          "base_score": 0.374,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 29,
          "title": "",
          "score": 0.522,
          "base_score": 0.372,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 21,
          "title": "",
          "score": 0.426,
          "base_score": 0.276,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "tactic",
          "tactics",
          "library",
          "weight",
          "fitness"
        ],
        "semantic": [],
        "merged": [
          "tactic",
          "tactics",
          "library",
          "weight",
          "fitness"
        ]
      },
      "topic_id": 1,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.1958877405135734,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:05:51.409983+00:00"
      }
    },
    {
      "chapter_number": 28,
      "title": "Segment 28 (pages 261-272)",
      "start_page": 261,
      "end_page": 272,
      "summary": "[Spronck05] Spronck, P.\n[Spronck06] Spronck, P.\nUniversity, Bielefeld.\nOne of the challenges of creating deep, interesting behaviors in games and simulations is to \ntheory, we can achieve complex-looking behaviors that are reasonable yet not immediately \nchaotic-looking systems through purely deterministic rules.\nsample, purely deterministic behavior systems that exhibit complex, observably \nalgorithms can be easily integrated into game AI and simulation models to generate deeper, \nrandomness in games.\nGame players, on the other hand, have a different perspective on the situation.\nFrom the standpoint of the player, predictability in game characters can lead to \nthis approach provides a realistic depth of behavior that can be attractive to the game \nplayer, it is this same abandonment of a predictable environment that makes the analysis, \nlead to player frustration, as they are unable to progress in the game by learning complex \nagent behavior.\nbehaviors is through tight selection of random seeds.\nthe juxtaposition of random selection of AI with the unpredictable nature of the player‘s \nexperience of the players is improved through the inclusion of randomness in the decision \nmodels of the agent AI.\nthat the experience that the player has is based on the actual random number call in the \nThe random number generation in the agent AI is merely a tool in a greater process.\nWhat is important is that the player cannot perceive excessive predictable regularity in the \nactions of the agent.\nthat developers need in order to confidently craft their agent code.\nfail to determine the rule set that was in effect that led to the next momentary state (the \nrandom seed to provide interesting variation—the player.) Additionally, we don‘t have to \nagents and world data that are beyond the ability of the player to adequately perceive, we \ncan generate purely deterministic cause/effect chains that look either random or at least \non emergent behavior and, more to the point of this gem, the appearance of seemingly \napplying simple, deterministic rules produce this seemingly random behavior.\nany given time slice is based on the states of the eight cells in its immediate neighborhood.\nThe number of possible combinations of the cells in the local neighborhood is 28 or 256.\nFigure 3.7.1 shows a very simple example of these rules in action.\nA simple example of the rule set in Conway’s Game of Life.\nover time, the ―behavior‖ of the entire ―colony‖ of cells starts to look random.\ncomplex-looking behaviors.\nWhile each cell’s state is purely deterministic, it is \nconfirm that the resulting state change is performing exactly as designed.\nWhat sets Conway‘s Life apart from many game scenarios is not the complexity of the rule \ninputs through four rules to receive a new binary state does not seem terribly complex.\nWhen we compare it to what a typical AI entity in a game may use as its decision model, we \nFor instance, imagine a very simple AI agent in a first-person shooter game (see Figure \nIt may take into account the distance to the player and the direction in which the \nplayer lies.\nWhen the player enters a specified range, the NPC ―wakes up,‖ turns, and \nmoves toward the player.\nand ―move toward player.‖ While this seems extraordinarily simple, as recently as 10 to 15 \nPlayers could perceive both the cause and the \nsimple for the player to determine not only what the criterion is, but what the \ncritical threshold value is for that criterion to trigger the behavior.\nFor example, we could add a criterion stating that the \nagent will only attack the player when he is in range and carrying a weapon.\nOther factors can be added to a decision model, however, which could obscure the point at \nwhich a behavior change should occur.\nthe states of the cells in Life) can complicate things quickly for the observer if they aren‘t \nFor instance, imagine that the rule for attacking the player was no \nlonger ―if the distance from player to enemy < n‖ but rather ―if the player‘s distance to two \nAs the player approaches the first enemy, there would be \nThe player will most certainly \nThe inclusion of a second criterion can obscure the threshold value \nenemy is included, the player is not attacked as he enters the normal decision \nThe player may not be able to adequately determine what the trigger conditions are \nbecause we have masked the existence of the second criterion from the player.\nis no intuitive link between the player‘s distance to the second enemy and the actions of the \nfirst, the player will be at a loss to determine when the first enemy will attack.\nthe player.\nAs mentioned, the inclusion of the player‘s distance to the second agent as a criterion for \nthe decisions of the first agent is a little contrived.\nIf the second agent was far away, it is possible that the player could \ncase, the first agent would check his decision criteria and determine that the player was not \nin range of two people and, as a result, would not attack the player.\nbased on the position of the second agent—and, more specifically, the player‘s proximity to \nIt was not directly related to the decision that the agent is \nThe solution to this is to include factors on which it is reasonable for an agent to base his \nIn this example, the factors may include items such as: \nDistance to player \nAgent‘s health \nPlayer‘s distance to sensitive location \nIf the player is too close to it, the agent will \nThis is different than the example with two agents above in that the distance to a \ndetonator is presumably more relevant to the agent‘s job than the player‘s proximity to two \nthe number of configurations of cells in Life is 28 or 256.) In our initial example, it would \ntake only a short amount of time to determine the distance threshold at which the agent \nBy the inclusion of so many relevant factors into the agent‘s behavior model, the \nplayer.\nMuch of the difficulty that a player would have in knowing exactly what reaction the \nagent will have is due to the fact that the player cannot perceive all the data.\nfrom the point of the player.\nIf the agent‘s behavior changes from one moment to the next, \nthe player may not be able to determine which of the aforementioned factors crossed one of \nexample, if the player draws his weapon and the agent attacks, the player can make the \nHowever, if the agent does not attack \nand, for instance, runs away instead, the player may not be able to determine whether it \nSimilarly, if the player is moving near the agent with his weapon drawn, and the agent \nagent, a secondary point (for example, a detonator), or a change in the agent‘s alertness \nThe player may not know exactly when the agent is \ngoing to change behaviors, but he should be able to offer a reasonable guess as to why it \ncompared against the decision code, the developer can confirm whether the agents are \nseven aforementioned factors to select from a variety of behaviors.\ndetermining whether the agent will attack the player, for example, we could include actions \nFor example, if we were to arrange two factors on two axes and determine a threshold \nIn this case, using only two factors and two \nthreshold values, we can arrive at four distinct behaviors.\nUsing our two-axis example, by increasing the threshold values \nnumber of potential results increases exponentially as a factor of the number of \nBy combining the factors prior to partitioning (Panel 3), thresholds \nWe can visualize how this would affect behaviors if we imagine the values of our two factors \nIf Factor 1‘s value were to change, we could expect to see \nBehaviors F and H—and even E—depending on the amount of change in Factor 1.\nIf Factor 2 \nchanges were occurring in only Factor 1 or 2, by observing the changes in behavior that \noccurred, we could eventually determine where those thresholds between behaviors are.\npossibly see any one of the 16 behaviors.\nexactly predict the cause-and-effect chain between factors and behaviors.\nwitnessing a reduction in Factor 1, we may see a state change to B, C, F, J, or K.\nthose states can be reached from G if Factor 1 is decreasing.\nis that the ultimate state is decided by Factor 2 as well—for example, G→C could happen if \ngeneral statement about where our data point may end up while Factor 1 is decreasing, we \ncan‘t know the eventual result state without also knowing the behavior of Factor 2.\nusing each potential factor in our decision model and defining one or more thresholds of \nmeaning, we can create a complex state space of potential results.\nFor example, we may want our agent to consider a combination of its distance to the player \nplayer is closer.\nthose factors moves from one end to the other, it has less effect on the outcome than if \ncombined, however, they create a new directed axis in the state space— in this case shown \nbe used to determine where the behavior changes.\nplayer, he cannot determine at what point on Factor 1 the behavior changes without taking \ninto account changes in Factor 2 as well.\ndeterministic fashion—that is, we could verify that any given combination of factors is \nWhile there is still no random factor being included in \nlooking, yet not inherently predictable results.\nlooking but slightly unpredictable behaviors, we do not have to resort to randomness in \nagents, we must be careful to select criteria that are relevant to the decision being made.\nimmersive behaviors for our agents.\n―Multi-Axial, Dynamic Threshold Fuzzy State Machine.‖ AI Game \nBehavioral Mathematics for Game AI.",
      "keywords": [
        "player",
        "agent",
        "factor",
        "Game",
        "Behavior",
        "state",
        "Game Programming Wisdom",
        "decision",
        "number",
        "cell",
        "Deterministic",
        "system",
        "Chaos Theory",
        "point",
        "Life"
      ],
      "concepts": [
        "behavior",
        "behavioral",
        "random",
        "agents",
        "cells",
        "complexity",
        "state",
        "stating",
        "predictable",
        "predictability"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 8",
          "chapter": 31,
          "title": "",
          "score": 0.66,
          "base_score": 0.51,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 29,
          "title": "",
          "score": 0.602,
          "base_score": 0.452,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 27,
          "title": "",
          "score": 0.599,
          "base_score": 0.449,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 21,
          "title": "",
          "score": 0.598,
          "base_score": 0.448,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 23,
          "title": "",
          "score": 0.519,
          "base_score": 0.369,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "player",
          "agent",
          "factor",
          "behaviors",
          "factors"
        ],
        "semantic": [],
        "merged": [
          "player",
          "agent",
          "factor",
          "behaviors",
          "factors"
        ]
      },
      "topic_id": 1,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.1934197846880174,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:05:51.410034+00:00"
      }
    },
    {
      "chapter_number": 29,
      "title": "Segment 29 (pages 273-280)",
      "start_page": 273,
      "end_page": 280,
      "summary": "Needs-Based AI \nNeeds-based AI is a general term for action selection based on attempting to fulfill a set of \nagainst each other, trying to find the best one given the agent‘s needs at the given \nThis gem presents some technical details of needs-based AI.\nIn terms of its historical context, the needs-based AI approach is related to the family of \nNeeds-Based AI Overview \nThere are many ways to drive an artificial agent; some games use finite state machines, \nNeeds-based AI is an alternative with an exciting \nbenefit: The smarts for picking the next action configure themselves automatically, based \nEach agent has some set of ever-changing needs that demand to be satisfied.\nscore, finds what concrete sequence of actions it requires, and pushes those onto its action \nIf you run out of actions, perform action selection, based on current needs, to find \nmore actions.\n2. Score each advertisement based on your current needs.\n3. Pick the best advertisement and get its action sequence.\nNeeds \nPerforming an appropriate action then refills the need, raising it back to a higher \nFor example, we simulate agents getting hungry if they don‘t eat by decaying the hunger \nAdvertisements and Action Selection \nWhen the time comes to pick a new set of actions, the agent looks at what can be done in \nEach object in the world advertises a set of action/reward tuples—some actions to be taken \nmight advertise a ―prepare food‖ action with a reward of +30 hunger and ―clean‖ with the \nTo pick an action, the agent examines the various objects around them and finds out what \nThe agent then picks the best advertisement using the \nscore and adds its actions to their pending action queue.\namong them: The agent ―asks‖ each object what it advertises, and only then scores what‘s \nactions based on object state.\nFor example, in a later section we will describe how to use advertisement \nAdvertisement Scoring \nOnce we have an object‘s advertisements, we need to score them and stack them against \nbased on the reward it promises (for example, +10 environment) and the agent‘s current \nneeds.\nscore = ∑ all needs (future valueneed) \nFor example, if the agent‘s hunger is at 70, an advertisement of \nneeds.\nB. Attenuated need scoring \nscore = ∑ all needs Aneed (future valueneed) \nAn action that increases \nhunger to 90 will have a score of 1/9, while an action that increases thirst to 30 will \nThese attenuation functions are a major tuning knob in needs-\nC. Attenuated need-delta scoring \nscore based on need level difference: \nAction Selection \nWinner-takes-all: The highest-scoring action always gets picked.\nAction Selection Additions \nGiven two objects with identical advertisements, an agent should tend to pick the \nWe can do this by attenuating each object‘s score based on \nscore = D ( ∑ all needs ( … ) ) \nagent always prefers a much worse action nearby rather than a better one farther \nable to operate stoves, so the stove should not advertise the ―cook‖ action to them.\nadvertisement; action selection would only consider advertisements whose mask \nAgents‘ need levels should decay over time.\nFor example, if an agent‘s hunger doesn‘t decay as quickly, \nD. Tuning advertisement scores \na set of tuning parameters, one for each need, that modify that need‘s score: \nFor example, by tuning down the +hunger advertisement‘s score, we‘ll get an agent \nAttenuation functions map from low need levels to high scores.\nEach need can be \nAction Performance \nHaving chosen something to do, we push the advertisement‘s actions on the agent‘s action \nexample, the stove‘s ―clean‖ action might be small script that: \nIt‘s important that the actual reward be granted manually as part of the action, and not be \nInterrupted actions will not be rewarded.\nThis may seem like a useful way to force agents to perform an action.\nFalse advertisements create action loops that are \ndesired action on the agent‘s action queue.\nentire sequence of actions right away and push the whole thing on the agent‘s queue.\nFor example, a failed ―cook food‖ action sequence could create a new ―burned food‖ object \nadvertisement would specify only one action: ―take food.‖ That action, toward the end, \nLazy action chaining makes it possible to modify the chain based on what objects are \nSince all actions are done on objects, one way to do this is to mutate the state of the object \ncleanness value on an object, which gets continuously increased while the action is running.\nthe original Sims: The action of prepping food creates a ―prepped food‖ object, cooking then \nDesign Consequences of Needs-Based AI \nWith the technical details of needs-based AI behind us, let‘s also consider some of the \nneeds, their decay rates, score attenuation functions, and other such elements will apply to \ntry to implement that using just needs and advertisements, but the result will be brittle.\nmanufacture appropriate action sequences and forcibly push them on the agent‘s action \nBut in general, this overall approach is not very good for games that need a lot of \nNeeds-based AI works \ninternals are very easy to understand; by just inspecting the agent‘s internal needs values, ",
      "keywords": [
        "action",
        "Henri Poincaré.",
        "agent",
        "action selection",
        "score",
        "advertisement",
        "action queue",
        "based",
        "hunger",
        "food",
        "objects",
        "tuning",
        "Sims",
        "action sequence",
        "attenuation function"
      ],
      "concepts": [
        "actions",
        "needs",
        "advertisements",
        "advertise",
        "advertisement",
        "advertising",
        "agent",
        "scores",
        "scored",
        "tuning"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 8",
          "chapter": 28,
          "title": "",
          "score": 0.602,
          "base_score": 0.452,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 31,
          "title": "",
          "score": 0.549,
          "base_score": 0.399,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 23,
          "title": "",
          "score": 0.538,
          "base_score": 0.388,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 27,
          "title": "",
          "score": 0.522,
          "base_score": 0.372,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 32,
          "title": "",
          "score": 0.457,
          "base_score": 0.307,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "action",
          "agent",
          "score",
          "advertisement",
          "needs"
        ],
        "semantic": [],
        "merged": [
          "action",
          "agent",
          "score",
          "advertisement",
          "needs"
        ]
      },
      "topic_id": 1,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.16928591067906656,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:05:51.410078+00:00"
      }
    },
    {
      "chapter_number": 30,
      "title": "Segment 30 (pages 281-288)",
      "start_page": 281,
      "end_page": 288,
      "summary": "emotions can be easily implemented and can enhance the behavior and expression of game \nemotion itself.\nThe first section of this gem will describe models of personality, mood, and emotion derived \nModels of Emotion, Mood, and Personality \nIn addition to emotion, we need to represent both personality and mood in order to have a \nEmotion \nThere are many theories of emotion and models of personality associated with them.\nexample, [Eyesenck65] describes models of personality and emotion often cited in academic \nOne model of emotion used in a large volume of academic literature is the OCC \nuse a subset of the OCC model for our emotional representation.\nThe OCC model typically represents 22 discrete emotional categories.\ndown emotions into three categories: emotional reaction to objects, events, and agents.\nAgent A likes apples.\nAgent B likes apples and Agent A.\nAgent C likes apples but not Agent A.\napple, we then have the following emotional reactions: \nAgent A is happy (due to acquiring the apple).\nAgent C is unhappy at not acquiring the apple and is even less happy at seeing \nAgent A acquire the apple.\nchanges as different emotional events occur.\nInterestingly, mood can color our perception of emotional events.\nnegative mood may view all emotional events as negative, even if the event is generally to \nFor instance, if Agent A is in a highly negative \navailable apple to the agent‘s blackboard when it has a mood that is higher than a given \napple for oneself or allowing Agent A to obtain the apple, the personality model can be used \nAn agent with high agreeability would choose to allow Agent \nThus, the personality model allows us to create unique behavior for each agent without the \nneed for per-agent behavior trees.\nThe Emotional Framework \nGiven the emotional model described in the previous section, we need to be able to \nIn this example, we will incorporate the emotional model by \na simple behavior tree in order to incorporate the emotional values within the characters‘ \ncycle if the emotional mood is negative.\nbehavior trees and emotional models is the work of the Oz project group at Carnegie Mellon \nTypically, emotion is broken up into appraisal, where goals are created and events and \nthe agent‘s emotional variables and blackboard data.\nsuccess or failure of the agent‘s goals, which may again alter the agent‘s blackboard or \nabout new objects we have not encountered before, new events that happen, or new agents \nwe build up an emotional picture relating to these objects, events, and agents.\nexplicitly determine all possible known objects/events/agents a priori and simply load that \nsystem such that instead of storing a reaction to an individual object/event/agent, we \nper-agent data in a generic structure that allows access from all of our actor‘s systems.\nTypically, this is used to store agent goals or attributes, such as the currently selected \ncreation of emotional agents.\nretrieve a particular value associated with a new sensed object/agent/ event—must be as \nFor convenience, each agent‘s blackboard and behavior tree configurations are parsed from \nThis allows for run-time configuration of each agent, using a unique blackboard, a \nHere we can see a simple blackboard specification for an agent.\ntag of <agent>, < object>, or <event> defines a unique structure that is stored within \nTo modify our behavior based on the emotional framework, we need to consider the steps \nAn agent‘s perception system typically responds to queries instigated by its behavior tree \nthis case is to determine the agent‘s emotional reaction to each sensed object—specifically, \nthe more useful case of allowing the agent to determine the selection of which food object \nFor example, an agent may \nIn practical terms, in the case of our object queries, we first use the appraisal class to \nThe first is that the agent must consider his own \nallows attaining of objects by other means—for example, by allowing agents to simply give \nattainment of an object is with respect to other agents.\nAn agent who obtains an object that \nconsider the attainment goals of other agents for the object, or we can consider the general \nexample, an object that is attained may allow us to accomplish a goal for another agent if \nor dispose of the object if it denies a goal of an agent we have negative affect towards.\nSensing a New Agent \nThe term ―agent‖ in the OCC model does not describe an AI agent, but instead describes an \nagent of change.\nIn the most common case, the agents in our emotional \nuse the term ―agent‖ to mean both the OCC model of an agent and the AI game character \nagent.\nModeling of inter-agent affect affords us some unique social interactions, such as the \nThe most obvious use of agent knowledge \nagents are stored by name with a valence value associated with them within the \nThis value is useful for when any opportunities are presented to the agent, such \nhumans interact, they create mental models of the motivations of the interacting agent in \nThis agent mental modeling is important for social interactions; however, it is \nA great deal of an agent‘s behavior will generally stem from sensing some event that occurs \navailable events to create the associated knowledge within the agent‘s blackboard.\nIn the case of the grenade event, the appraisal class simply adds a threat object with a high \nappraisal class is that the importance of an event can change over time as an agent \nresponse over time as the agent adds positive or negative arousal to the event depending \nemotionally, but that if the event has not occurred for some time, the arousal may once \nof any given emotional stimulus and then apply the results of these functions to the agent‘s \nThe personality model acts to bias available choices within the behavior tree.\nFor example, when given the choice to interact in a conversation with another agent or to \nobtain a required item, an agent with an introverted personality would choose the latter.\nThis simply scales the emotional valence of input senses, \nFor example, if we perceive an object that is beneficial to another agent, we calculate \na valence for the goal of attaining the apple for the other agent.\nfor the other agent is cancelled out, and we simply never add the apple to the blackboard.\nagent?\nAgent update loop.\nThis appraisal class is used to then map the input into changes in the agent blackboard.\nmay affect the emotional values associated with agents, objects, or events stored within the \nexample, to alter walk-cycle blending to allow for a display of mood, an agent with a \nemotion in order to add some personality to individual agents.\nto consider deeper models of agent emotion and memory, which in turn should lead to a \nmore effective display of an agent‘s emotional state.",
      "keywords": [
        "Agent",
        "object",
        "Emotional",
        "event",
        "personality",
        "blackboard",
        "mood",
        "appraisal class",
        "appraisal",
        "model",
        "emotion",
        "apple",
        "Behavior",
        "behavior tree",
        "OCC model"
      ],
      "concepts": [
        "emotional",
        "emotions",
        "emotion",
        "agents",
        "events",
        "modeling",
        "simply",
        "values",
        "valence",
        "personality"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 8",
          "chapter": 31,
          "title": "",
          "score": 0.66,
          "base_score": 0.51,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 28,
          "title": "",
          "score": 0.505,
          "base_score": 0.355,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 29,
          "title": "",
          "score": 0.444,
          "base_score": 0.294,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 23,
          "title": "",
          "score": 0.405,
          "base_score": 0.255,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 33,
          "title": "",
          "score": 0.403,
          "base_score": 0.253,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "agent",
          "emotional",
          "emotion",
          "apple",
          "blackboard"
        ],
        "semantic": [],
        "merged": [
          "agent",
          "emotional",
          "emotion",
          "apple",
          "blackboard"
        ]
      },
      "topic_id": 1,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.12787857616664103,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:05:51.410120+00:00"
      }
    },
    {
      "chapter_number": 31,
      "title": "Segment 31 (pages 289-299)",
      "start_page": 289,
      "end_page": 299,
      "summary": "Personality and Emotion Simulation for Conversational Agents.‖ Computer Animation and \nCambridge University Press, 1988.\nIt has been a goal of many a game to create a large city filled with people you can talk to.\nthousands, or more!) of agents, each of which acts like an individual.\nintelligent, conversational non-player characters (NPCs) until we find a way to create these \nhelp you create large groups of agents much faster.\nConversational Agents Today \nprofessionalism, earning trust through culturally appropriate small talk and asking the \nTypical Methods for Building Conversational Agents \nThere are a few ways to make conversational agents, one of the more common (and \nwhere one node is what the NPC says, the nodes under that are things the player can say in \nYou say, ―Do you like football?‖ and the NPC will \nwrites the input text (player choice), the output text (from the NPC), and for each possible \nIf you want an NPC‘s response to change based on the player‘s shoes, \nbuild a professional dialog tree, you not only have to decide which topics an agent can \nfactors (NPC personality, NPC culture, NPC state, world state, player state, conversational \nhistory, history with player, and so on) that should affect a conversation and make sure the \nFor one of the games I worked on in 2009, creating the full dialog \nagent in any game is still measured in days and weeks, not minutes or hours.\nworking on nothing but conversations a full year to make 100 individual (non-cloned) NPCs, \nimpossible to make large worlds filled with unique, believable agents using current \nOur primary goal is to reduce the time it takes to create a conversational agent.\nof making the game or to create significantly more agents for the same cost.\nWe have already said we want agents with better conversational breadth and situational \n(In other words, responses are based on the NPC‘s personality, state, job, \nthey are, two agents will give different answers when it makes sense and the same answer \nAnother desirable feature (already present in some games) is for the player to be able to \nchange an agent‘s attitude and behavior toward them.\nearn the trust of an NPC.\nBeing able to win an agent‘s trust is often the key to a mission, and being \nCulture describes how a group of people behave in certain circumstances.\nof cultures (groups, roles, character types, and so on), the sheer volume of dialog data \nmakes it hard to verify that agents behave consistently or behave the way the lead designer \nculture or group of people.\nmaking a new city filled with conversational agents would be as easy as cloning an existing \nIt needs to be data driven in a way that makes it quick to create easy-to-use tools, as well \nconversational agents.\nWe‘ll use topics, concept trees, response types, trust \nlevels, rapport modifiers, temperament stats, explicitly modeled cultural groups, sets of \nIn the old days, this was a simple problem—if the designer decides the NPC should \ninsult the player, the response type Insult would map to one or more insults.\nintent is Answer, the response type and topic can be used to look up a specific answer, \nBeing able to add entirely new responses or whole topics to hundreds of NPCs in a matter of \nnow use voice actors, meaning each statement a designer adds to an NPC must be \nThe topic of \nthe set of lines an NPC can say are fixed, considerable time must still be spent mapping the \nplayer‘s input to the NPC‘s output.\nThe goal of this gem is to describe a way to scale how one authors conversational agents.\nRather than linking the player‘s input directly to the NPC‘s output, \nwe use the player‘s input to determine the NPC‘s intention and then use the intention to \nselect the NPC‘s behavior.\nAll inputs are mapped to a Topic.\nThe Topic is checked against the NPC‘s \nCulturalGroup and current level of Trust toward the player to determine a \nin the NPC‘s dialog specification, the system moves up a level and checks for a \nCulturalGroup is a sparse set of {Trust-Topic-ResponseType} mappings.\nCulture represents not just nationality, but any group membership that affects how the \nagent will respond to a topic.\ngroups.\nmatching group.\nThroughout this gem, we‘ll use the example of a U.S. soldier (the player) in an Iraqi city.\nTable 3.10.1 lists seven NPCs the player might interact with—a typical civilian, a policeman, \nImagine a game in which there are 100 NPCs, and the player can insult any of them.\npersonality, intelligence, culture, and preferred insult.\nexample) there are only three intentions (insult, ignore, attack).\nplayer‘s action (the input) is hard-coded directly to the NPC‘s behavior (the output).\ndesigner‘s life easier, we‘ll have them map inputs to intentions (a much easier task) and \nseparately map intentions to behaviors.\nTopics, Response Types, and Trust \nIn our approach, for a given culture (which we‘ll discuss a little later), a Topic and Trust \nTopic is the subject the player is asking about \nThe ResponseType represents the responding NPC‘s intention.\nAnswer (give the player the information they‘re looking for, if possible), Refuse, Evade, \nplayer has made a mistake in what they asked for; this is more useful in educational \nThe player stops a person on the \nShakir, an insurgent, will insult the player, while Zuhair, a \nWhat an NPC Says Depends on Their Intention \nPlayer asks: Where is the market?\nWhat an NPC Says Depends on Their Intention \nPlayer asks: Where is the market?\nTrust is the amount of trust the NPC has in the player.\nResponseType for that cultural group.\nUsing the example in Table 3.10.1, let‘s assume that the player has insulted Anwar the \nTopic=insult, \n{Trust >=  0, Insult} \nWhen the player insults Anwar, Anwar will decide to insult the player.\nlowers Trust by 1, if the player insults Anwar again, Anwar will threaten him.\nIf the player \nKnowing that an NPC will insult the player does not automatically determine what the NPC \nat the group level (all policemen), but the behavior could be different for each individual \ndesigners can be assigned to intent (say, someone familiar with personality or social \n(important when striving for consistency across agents and designers).\nthe behavior system, you only have to map behaviors to a small set of intents, not the \npossibly adding bugs to) individual NPC dialog trees.\nTrust levels help designers remember which conditions they need to handle.\nthis is not required: One can create a group Person that returns Answer for all topics at \nIf the player asked \nabout murders and the NPC‘s group didn‘t have an entry for Murder, the system would \ncheck the parent topic (say, Problems).\nanswer to anything the player asks.\nSecond, it allows a designer to add new topics through extension, which is \nIt should also be noted that the {Topic-Trust-ResponseType} mappings do not have \nAn NPC can be set up to talk about local crime when Trust is \nthe system would then use the parent topic.\nWhen designers specify intent, they do so at the group level, not for individual NPCs. We \nwill refer to these groups as CulturalGroups.\nDesigners can also use the cultural group \nTopic: \nTopic: \nA cultural group contains one or more {Topic-Trust-ResponseType} mapping.\nAgents belong to one or more groups.\nTypically, one of those groups will be Person, which \nOther groups specialize the agent.\ngroups.\nWhen designing agents, two design principles are used: design by composition and design \nDesign by composition says that the designer should build the agent by selecting pieces \n(cultural groups) rather than writing the agent from scratch.\nand Person, and Agent B is a GovernmentRepresentative, Insurgent, \nlist, and assigning the groups fully specifies how the agents will react to any dialog option in \n(Note that if per-agent behavior is used, that work will still need to be done, \nDesign by exception speeds up the group authoring process.\ndesign by exception, default values should be set up in the base group (in our example, \ngroups.\nFor example, you could have the group LittleGirl love to talk to complete \nAssigning those three groups to an agent produces an agent that will \nThe group \nRabbitPhobe does not contain mappings for any Topic other than Rabbit, making it \nfast to create, and the designer is not forced to create hundreds of combination groups, \nIf you ask the agent about the \nHow one handles the cultural group conflicts depends on \nprioritized group list (referred to as Cultural Wrappers).\nWhen setting up the agent, the \ndesigner must select the order of the groups.\nover GovernmentRepresentative, while Halema has the same groups but in a \nAn NPC’s Answer Is Based on the Order (Prioritization) of Their \nGroups \naround people he trusts (as a terrorist) but be polite to the player (as a policeman).\nthese instances, a simple solution is to create a new group that contains only those Topics \npurpose group, such as Undercover-Insurgent, but it can also represent that specific \ncaptured by any group, so modeling the things that are truly specific to an individual is \nUnless the agent is \ngroups.\nagent‘s intent, if a match on the Topic isn‘t found, the parent Topic is used, moving up \ngroup list [USCitizen, PingPongFan].\nAssuming a Trust level of 0, the program first checks for a match on {USCitizen, \nIf the system moved up the topic heirarchy before checking the next group, any group with \nEach combination (and ordering) of groups results in an individual who is unique.\nWe could design them to do so, but the agents wouldn‘t appear realistic, they‘d \nThe number of unique individuals you can create by combining groups grows quickly with \nthe number of groups.\nWith three groups, 15 unique individuals can be made.\ngroups, the number is 325.\nAdd one more group, and you can cover all cities and most \nThe process of assigning and ordering groups is not the only way to create unique NPCs.\nIntent can be tweaked at the NPC level using the TrustModifier property.\nmore trusting than normal—the agent needs only a Trust of four to trigger responses that \nother agents with the same group list require a six for.\nFor example, if the agent \nwildcard when topic is irrelevant, such as when insulting or ignoring the player) can map to ",
      "keywords": [
        "NPC",
        "topic",
        "Iraqi",
        "trust",
        "player",
        "NPCs",
        "group",
        "answer",
        "Anwar Zuhair Scott"
      ],
      "concepts": [
        "groups",
        "topic",
        "cultures",
        "culturally",
        "cultural",
        "game",
        "conversational",
        "conversations",
        "dialog",
        "agents"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 8",
          "chapter": 30,
          "title": "",
          "score": 0.66,
          "base_score": 0.51,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 28,
          "title": "",
          "score": 0.66,
          "base_score": 0.51,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 29,
          "title": "",
          "score": 0.549,
          "base_score": 0.399,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 21,
          "title": "",
          "score": 0.533,
          "base_score": 0.383,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 27,
          "title": "",
          "score": 0.524,
          "base_score": 0.374,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "npc",
          "player",
          "topic",
          "trust",
          "groups"
        ],
        "semantic": [],
        "merged": [
          "npc",
          "player",
          "topic",
          "trust",
          "groups"
        ]
      },
      "topic_id": 1,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.17373816571968476,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:05:51.410174+00:00"
      }
    },
    {
      "chapter_number": 32,
      "title": "Segment 32 (pages 300-308)",
      "start_page": 300,
      "end_page": 308,
      "summary": "Typically, player movements in the world can be logged as the location of the player in 3D \nplayer moves in the world, and assuming that we are logging data at every second, (x1, y1, \nA lot of value is placed on advertisement coverage, as the clients placing the advertisement \nAdvertisements can be placed in different locations in the world, but \nGiven a set of preprocessed walks, as described in the previous section, advertisements \ncould be placed at any of the locations in the walks.\nlocations as the number of walks that contain the specified locations divided by the total \nnumber of walks.\nunlikely, that a player will get close to a location but not see the advertisement because he \n(d) illustrate four different location selections for this graph.\nillustrated in Subfigure (a), two locations are selected, which cover Walks 2, 3, and 4.\nBecause there are a total of four walks, this amounts to coverage of 75 percent.\ntwo locations are selected, which covers all four walks, which amounts to coverage of 100 \nIn such a setting, our task is to maximize the coverage while minimizing the number of \ntraining data, suppose that we select a set of locations that maximize coverage on this data.\nThen, our selected set of locations should achieve the required level of coverage on future \ncoverage on training data will most likely achieve high coverage on unseen data.\ntraining sets on which to base advertisement placement, some data needs to be collected.\nAnother approach is to simply log the number of players that visit a particular location, \nFrequency-based placement is a relatively simple approach that selects locations based on \nthe number of walks passing through a particular location.\nWalks in the training data are \nprocessed sequentially to count the number of walks passing through each location, and \nB has already been selected, the frequency maximizing approach will select Location A over \nThe Markov steady-state probability-based placement approach is based on computing the \nprobability of a player visiting a particular location based on the transition probabilities.\nfirst step in this approach is to process the walks to generate a transition probability matrix.\nprobabilities, advertisements can be placed by selecting locations with the highest \ntransitions and requires space constant with respect to the number of walks.\nThis approach is based on selecting locations in a greedy manner, maximizing the marginal \nand evaluating the coverage of the newly formed set of locations (previously selected \nlocation that maximizes the coverage is added to the set.\nNote that this approach considers the marginal coverage \nnecessary data grows linearly with the length of the walk as well as the number of walks.\nWe experimentally compared the three approaches to advertisement placement on a \n(Advertisement placements were selected based on the walks in the training set, \nFigure 3.11.9 shows the coverage achieved by each of the three approaches for different \nnumbers of advertisements, with 5 percent of the data used for training, on the training set.\nFigure 3.11.10 shows coverage on the test set.\nadvertisements are placed, there is very little improvement in coverage.\nComparison of approaches to advertisement placement.\npercent of the data used for training, coverage on the training set.\nComparison of approaches to advertisement placement.\npercent of the data used for training, coverage on the test set.\nThe closeness between the coverage on the training sets and the coverage on the test sets \nimplies that our advertisement placement generalizes well to unseen data.\neach of the three approaches for various budgets on the number of advertisements placed \nwith 0.25 percent of the data used for training, on the training set.\ncoverage on the test set.\nFor such a small size of training set, 100-percent coverage is \ntraining set depends on the size of the world and the variability in the walks, and we are \nComparison of approaches to advertisement placement.\npercent of the data used for training, coverage on the training set.\nComparison of approaches to advertisement placement.\npercent of the data used for training, coverage on the test set.\nEach of the three approaches generalizes well to future data given a sufficient size of the ",
      "keywords": [
        "coverage",
        "Data",
        "walks",
        "locations",
        "training",
        "location",
        "Player",
        "advertisement",
        "approach",
        "training set",
        "Advertisement Placement",
        "number",
        "training data",
        "player trace data",
        "Maximizing Approach"
      ],
      "concepts": [
        "location",
        "locations",
        "figures",
        "coverage",
        "data",
        "approaches",
        "approach",
        "player",
        "walk",
        "setting"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 8",
          "chapter": 22,
          "title": "",
          "score": 0.484,
          "base_score": 0.334,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 33,
          "title": "",
          "score": 0.482,
          "base_score": 0.332,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 29,
          "title": "",
          "score": 0.457,
          "base_score": 0.307,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 28,
          "title": "",
          "score": 0.383,
          "base_score": 0.233,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 21,
          "title": "",
          "score": 0.372,
          "base_score": 0.222,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "training",
          "coverage",
          "walks",
          "advertisement",
          "locations"
        ],
        "semantic": [],
        "merged": [
          "training",
          "coverage",
          "walks",
          "advertisement",
          "locations"
        ]
      },
      "topic_id": 1,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.155331055623552,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:05:51.410231+00:00"
      }
    },
    {
      "chapter_number": 33,
      "title": "Segment 33 (pages 309-316)",
      "start_page": 309,
      "end_page": 316,
      "summary": "Building Player Profiles with Clustering \nThe idea behind clustering is partitioning a given set of examples into subsets (referred to \nas clusters) such that examples in each subset are similar to other examples in the subset \nIn the case of player trace analysis, we are interested in building player profiles that group \nplayers into categories such that players in a group have similar behaviors.\nWhen player traces become \nClustering player traces serves as an important step in analyzing traces because it \nreduces the data from individual player traces to groups of player traces.\nfewer groups than individual traces, it becomes possible to perform a visual analysis of \nVisualizing player traces in 3D space.\nThe key challenge in applying clustering algorithms to player trace data is that typically \nclustering algorithms are designed for attribute-valued data (data represented as a single \ntable), and player trace data is structured and cannot be represented as a single table \nA simple example of such data can be a table \nTo produce such a grouping, a similarity measure between two examples (in this case, \ncustomer data (represented as a table) with player trace data introduced earlier, which \nmeasure the similarity between two player traces.\nonly be used on data points represented as n-dimensional vectors of equal length, and \nTo address this difficulty, we introduce a similarity measure between two player walks in the \nUsing this similarity measure, any of the standard clustering algorithms can be \napplied to clustering player trace data.\nThe largest common subsequence (LCS) is used to measure the similarity between two \nLCS accounts for fragments of similarity between two walks.\nnot common to all the walks.\nWalks 3 and 4 also have two behaviors in common.\nIf we group the walks in Figure 3.11.15 based on \nFor example, in Figure 3.11.15, Walks 3 and 4 have much longer chunks of portions \nHence, Walks 3 and 4 are much more similar to each other than Walks 1 and 2.\nTo take this into consideration, we define the similarity measure as: \nNote that this similarity measure is \nIdentical walks will have a similarity measure of 1, \nwhile completely dissimilar walks will have a similarity measure of 0.\nAn O(mn) time algorithm (where m and n are the lengths of the input \nUsing the distance measure for player trace walks specified earlier, it is now possible to \nextend any of the standard clustering algorithms for the task of clustering player traces.\nthe distance measure based on LCS.\nMany clustering algorithms can operate on such a similarity \nthat depicts the similarity between the examples.\nalgorithms for supervised learning only deal with attribute valued data.\nearlier, player traces cannot be represented as attribute valued data, and hence applying \nAn important class of supervised learning algorithms is support vector machines (SVMs), \nA kernel function basically computes a similarity measure between two examples.\nbased similarity measure used for clustering can also be used as a kernel function, allowing \nus to apply SVMs to classify player traces.\nUsing an LCS-Based Similarity Measure with K-NN \nWe begin by discussing the use of the LCS-based similarity measure with the K-Nearest \nallow the reader to develop an intuition for the task of player trace classification.\nprediction is to be made on an unseen example, it first computes the K nearest neighbors \nusing some measure of similarity and predicts the class of the unseen example as the \nTypically, in the case of attribute valued data, Euclidian distance is \nused to measure the similarity between two examples.\nTo extend the K-NN algorithm to operate on player trace data, we use the LCS-based \nTo predict whether a given player trace is a bot \nTo see why the LCS similarity measure serves the purpose of distinguishing between bots \nexperience points.) A set of player traces that represent bots (or gold farmers) will have \nneighbors, we have to compute the LCS similarity measure of the unseen examples with all \nThe LCS-similarity measure can be computed in \nprocessing (offline classification and analysis of player traces); however, when bot detection \nUsing an LCS-Based Similarity Measure with SVMs \nThe LCS-based similarity measure can also be used in conjunction with SVMs. SVMs \ntypically operate on attribute valued data and, given a set of training examples (categorized \nThe key point to note here is that in order to classify an unseen example, the LCS measure \nonly needs to be computed against the support vectors, and not the entire set of examples.\nadded value of logging player data.\nTransfer Learning Using a Game Testbed.‖ IEEE Transactions on Knowledge and Data \nUsing Player Traces and Interactive Player Graphs.‖ Game Programming Gems 7.",
      "keywords": [
        "player trace data",
        "player traces",
        "similarity measure",
        "LCS similarity measure",
        "walks",
        "Player",
        "data",
        "measure",
        "similarity",
        "Clustering player traces",
        "Markov steady-state probability-based",
        "player trace walks",
        "traces",
        "trace data",
        "LCS-Based Similarity Measure"
      ],
      "concepts": [
        "data",
        "player",
        "based",
        "base",
        "common",
        "examples",
        "important",
        "game",
        "walks",
        "programming"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 8",
          "chapter": 32,
          "title": "",
          "score": 0.482,
          "base_score": 0.332,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 31,
          "title": "",
          "score": 0.462,
          "base_score": 0.312,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 30,
          "title": "",
          "score": 0.403,
          "base_score": 0.253,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 28,
          "title": "",
          "score": 0.364,
          "base_score": 0.214,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 22,
          "title": "",
          "score": 0.349,
          "base_score": 0.199,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "similarity",
          "measure",
          "similarity measure",
          "player",
          "traces"
        ],
        "semantic": [],
        "merged": [
          "similarity",
          "measure",
          "similarity measure",
          "player",
          "traces"
        ]
      },
      "topic_id": 1,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.15920173439156524,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:05:51.410274+00:00"
      }
    },
    {
      "chapter_number": 34,
      "title": "Segment 34 (pages 317-324)",
      "start_page": 317,
      "end_page": 324,
      "summary": "Given a class hierarchy, we need to be able to determine whether Class A is a subclass of \nClass B.\nA typical class hierarchy might look like Figure 4.1.1.\nAn example class hierarchy.\nbool IsA(Class *pA, Class *pB) \nleaf to root of the class tree, which can be very expensive if you are frequently doing IsA \nanywhere in memory, and if one of the classes we traverse is not currently in the cache, \nBalanced Class Hierarchies \ntwice, such as in the class hierarchy displayed in Figure 4.1.2.\nA balanced binary class hierarchy.\nI will refer to this index as the class index for the rest of the gem.\ntable, the class index is the second row.\ncreate a heap or store the classes in it.\nordering for the classes.\nThe function for getting the parent‘s class index of a node is trivial: \nIf we take the class index of Sword (6) and right shift it by 1, we get the result 3, which is \nthe class index of the parent node, Weapon.\nGiven this perfectly balanced tree, we can easily rewrite our IsA function to use the class \nindices in the storage array to determine whether a class is a subclass of another.\nbool IsA_Balanced2Tree(Class *pA, Class *pB) \nparent classes of A.\nunnecessary cache misses for intermediary classes between A or B or, in the worst-case \nscenario where A is not a child of B, all of the parent classes of A.\nbool IsA_Balanced2Tree_V2(Class   *pA, Class   *pB) \nThe class indices have an additional property that allows us to remove the while loop from \nHere is the child function for our nodes in our class tree: \nThis works because we started our class hierarchy at Index 1, so we know that all indices \nbool IsA_Balanced2Tree_V3(Class *pA, Class *pB) \nand store it in the Class object along with the array index (GetArrayIndexMSB()).\nAnd since we start our class hierarchy with \nan index of 1, no class will match 0.\nbool FastIsA(Class *pA, Class *pB) \nAll of the previous work has been built upon the notion that our class hierarchy is a perfectly \nBecause of this, there is no reason why we cannot insert phantom classes to balance our \nIn the case of these two class trees, every possible IsA relationship is maintained.\ncan insert a number of phantom class nodes between the parent and the \nlarge numbers of phantom nodes to balance the tree does nothing except use up our index \nFor most games, a 32-bit DWORD will contain more than enough space for the class \nThe simplest implementation for building the class tree is the following algorithm.\nvoid BuildTree(Class *pA) \nClass *pChild = pA->GetChildClass(i); \nThe heart of implementing a more complicated class tree construction algorithm is realizing \nBoth of these class trees have the exact same IsA relationship, so to the Fast-IsA algorithm \nIf our class tree was very complex (or deep), we could balance the \ntree based on the number of subclasses or the maximum depth of any subclass of a class.\nThis leads to an algorithm similar to Huffman encoding to optimize the class tree such that \nWith more than 3,700 script classes in This Is \nIf your class tree is greater than 32 levels deep, there is no reason why you cannot simply \nchange your class index from a DWORD to a QWORD.\nallows systems to define a set of inputs or control variables that can be seamlessly linked to \nvarious systems without requiring blind casts, global variables, or a flat class hierarchy.\ndata types, such as arrays, classes, and other user-defined types.\nwrapped, the registered variable will walk the chain of linked variables and provide access \nAllow one registered variable to be linked to another.\nProvide a way to link registered variables directly.\nProvide a way to link registered variables indirectly.\ncomplexity, we want to allow for variables to be generically linked together without ",
      "keywords": [
        "class hierarchy",
        "class tree",
        "class index",
        "nAIndex",
        "index",
        "Variables",
        "Level",
        "tree",
        "int",
        "variable",
        "hierarchy",
        "BSR",
        "Registered Variables",
        "nBIndex",
        "int nAIndex"
      ],
      "concepts": [
        "classes",
        "variable",
        "variables",
        "tree",
        "bits",
        "bit",
        "nodes",
        "systems",
        "algorithm",
        "returns"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 8",
          "chapter": 38,
          "title": "",
          "score": 0.479,
          "base_score": 0.329,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 36,
          "title": "",
          "score": 0.418,
          "base_score": 0.268,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 37,
          "title": "",
          "score": 0.394,
          "base_score": 0.244,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 35,
          "title": "",
          "score": 0.372,
          "base_score": 0.222,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 54,
          "title": "",
          "score": 0.367,
          "base_score": 0.217,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "class",
          "class hierarchy",
          "tree",
          "index",
          "hierarchy"
        ],
        "semantic": [],
        "merged": [
          "class",
          "class hierarchy",
          "tree",
          "index",
          "hierarchy"
        ]
      },
      "topic_id": 0,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.1390913249741045,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:05:51.410316+00:00"
      }
    },
    {
      "chapter_number": 35,
      "title": "Segment 35 (pages 325-332)",
      "start_page": 325,
      "end_page": 332,
      "summary": "variables.\nmeans by which registered variables are given unique names for linking.\nThe base class from which all registered variables will be derived is the RegisteredVar \nclass.\nThis class provides all of the support for linking registered variables together and \nFName GetFName() const { return m_Name; } \nreturn m_pRedirector ?\nFName m_Name; \nRegisteredVar* m_pRedirector; \nTArray<RegisteredVar*> m_References; \nlinking up registered variables blindly between systems, we do not want to end up pointing \nto a registered variable that has been deleted.\nlink back to the referencing registered variable so that we can clean it up when the \nreferenced registered variable is deleted.\nhowever, in our case it is common for multiple registered variables to redirect to a single \nregistered variable, thus creating the need for an array of pointers as illustrated in Figure \nThis diagram illustrates how registered variables will be linked \ntogether and how we will also be tracking referencing registered variables to \nThe second key to keep in mind is that anytime you access a registered variable, you need \nyou decide that the correct answer is to work on the redirected registered variable, the \nGetBaseVariable() routine will retrieve the base registered variable that should be \nThe next step is to divide all the variables into two distinct classifications: single value types \n99 percent of the functionality required by any variable type.\nT Get() { return GetBaseVariable<RegVar>()->m_Value; } \n>m_Value; } \n>m_Value; } \noperator T&() { return GetBaseVariable<RegVar>()->m_Value; } \nif (m_Value != InValue) \nm_Value = InValue; \nT m_Value; \noverloaded operators to allow the programmer to seamlessly use registered variables.\nor a registered variable.\nThis ensures that the registered variable is used correctly and \nIt also makes it easy to add and remove registered variables from a system \nsince only the variable definition and linking code needs to be updated.\nHowever, another variable might also be \nlinked registered variables.\nevent that a registered variable clears its redirector either explicitly or if the redirector is \nthrough a list of linked variables.\nType-Specific Registered Variable \nAt this point we have built all the base classes required, and creating registered variables is \nDECLARE_REGISTERED_VARIABLE( RegisteredVarBOOL, \nDECLARE_REGISTERED_VARIABLE(RegisteredVarFLOAT, \nSetting a Registered Variable Directly \nWe‘ll now look at a simple example to illustrate what registered variables can do.\nIf we create a Boolean registered variable within the vehicle and link it to the weapon, \nIn contrast, without using registered variables we \nThe registered variable approach has the advantage that once the variables are correctly \nThe DECLARE_REGISTERED_VARIABLE macro requires further explanation to assist in \nfor the registered variable.\nIt ensures that we do not link two registered variables together \nvariable that we have given only a pointer to the base class RegisteredVar.\n#define DECLARE_REGISTERED_VARIABLE( InClass, InBaseClass )            \nDECLARE_REGISTERED_VARIABLE( InClass, InClass )                     \ntemplate<class T> bool IsA() const                                  \nWhile this code is being utilized here to provide IsA functionality for registered variables, it \nSetting a Registered Variable Indirectly \nNow that we have basic RTTI information, we can safely link registered variables together \nsystem in which a high-level object can register a variable with another object and have it \nWe want a vehicle class to provide a variable to control ",
      "keywords": [
        "registered variable",
        "VARIABLE",
        "registered",
        "variables",
        "const",
        "redirected registered variable",
        "void",
        "types",
        "Boolean registered variable",
        "base registered variable",
        "RegisteredVar",
        "Registered Variable Directly",
        "FName",
        "pRedirector",
        "single registered variable"
      ],
      "concepts": [
        "variables",
        "variable",
        "classes",
        "registered",
        "register",
        "type",
        "void",
        "links",
        "values",
        "operator"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 8",
          "chapter": 38,
          "title": "",
          "score": 0.508,
          "base_score": 0.358,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 39,
          "title": "",
          "score": 0.494,
          "base_score": 0.344,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 11,
          "title": "",
          "score": 0.399,
          "base_score": 0.249,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 7,
          "title": "",
          "score": 0.392,
          "base_score": 0.242,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 10,
          "title": "",
          "score": 0.383,
          "base_score": 0.233,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "registered",
          "variable",
          "registered variable",
          "variables",
          "registered variables"
        ],
        "semantic": [],
        "merged": [
          "registered",
          "variable",
          "registered variable",
          "variables",
          "registered variables"
        ]
      },
      "topic_id": 0,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.13189111155547772,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:05:51.410366+00:00"
      }
    },
    {
      "chapter_number": 36,
      "title": "Segment 36 (pages 333-342)",
      "start_page": 333,
      "end_page": 342,
      "summary": "writing multi-threaded code: data sharing, synchronization, deadlocks, efficiency, and \nIn this gem, we‘ll see how to write efficient and scalable multi-threaded code.\nEfficient Multi-Threaded Programming \ncertain operations can lead to additional overheads in a multi-threaded program.\nThe main problem with multi-threaded programming is concurrent access to the same \ntwo threads execute this function slightly at the same time, what will happen?\nThread 1 read Count and store it into register R1 \nThread 2 read Count and store it into register R1 \nThread 1 store the value of R1 into Count \nThread 2 store the value of R1 into Count \nWhile the expected value is 7, the resulting value would be 6, because each thread has a \nan atomic manner; that is, when executed by more than one core on the same memory \nthread-safe and lock-free.\nthread during the operation.\nsingle thread is executing a certain piece of code.\nby another thread.\nOn the other hand, most operating systems will make sure the thread \nthat has a critical section locked will not be preempted by another thread while it holds the \nWhat it does is simple: It uses the CAS function to try to gain access to the lock variable.\nby a thread when it gets interrupted by the operating system scheduler, other threads will \nbe left spinning trying to acquire the lock, while the thread holding it is not making progress \nThread 1 \nThread 2 \nThread 1.\nmemory to complete, so other threads can access the memory safely.\nValueIsReady, ensuring that other threads will see the new GlobalValue before \nMemory allocators can rapidly become a bottleneck in multi-threaded applications.\noften see from a person writing multi-threaded code for the first time: \nThe Sleep(0) will make the thread give up the remainder of its time slice for other \ntells the operating system scheduler that the thread is waiting and shouldn‘t get any CPU \nor for custom memory allocators that can operate on a per-thread basis, effectively \nEssentially, these algorithms are pieces of code that can be executed by multiple threads \nScalable Multi-Threaded Programming \nindependent parts of the code and run them in their own thread (for example, rendering or \nTask Scheduler Requirements \n2. Keep worker threads‘ idle time at a minimum.\n3. Keep CPU usage low for internal task scheduling.\nThe scheduler is lock-free, which means that it will never block the worker threads or the \nthreads that push tasks to it.\ncustom spin lock and by never allocating memory for its internal execution.\nTasks \nA task is the base unit of the scheduler; this is what gets scheduled and executed.\nA task needs to implement the Execute function, which is what gets called when it is \nA task is considered as fully executed when its Execute function has been called and when \nWorker Threads \nThe scheduler automatically creates one worker thread per logical core.\nillustrates how the worker threads behave: Each worker thread is initially pushed in a lock-\nfree queue of idle threads and waits for a wakeup event.\nworker thread by the scheduler, it wakes up and executes the task.\nOnce the task is done, \nthe worker thread does several things.\nby another thread.\nThen, it tries to pop a waiting task from the scheduler.\nIf a task is \nit pushes itself in the lock-free queue of idle threads and waits for the wakeup event again.\nThe scheduler is responsible for assigning tasks to the worker threads and performing \nTo schedule a task, any thread simply needs to call a \nfunction that will push the task pointer in the lock-free queue of unscheduled tasks.\nAt this point, pending tasks are simply queued in a lock-free queue, waiting to be scheduled \n2. Schedule ready tasks.\n3. Delete executed tasks.\nDuring this phase, the scheduler pops the pending tasks and registers them internally.\nIf a task is dependent on previously scheduled \nOtherwise, the task is kept as pending until the next scheduling slice.\nScheduling Ready Tasks \nThe second phase of the scheduling slice is to assign tasks that are ready to be executed to \nworker threads.\nThe scheduler first tries to pop an idle thread from a lock-free queue of idle \nthreads.\nIf it succeeds, the task is directly assigned to that thread, and the thread waiting \nIf all threads are working, the task is queued in the lock-free queue of \nThe scheduler then repeats the process until there are no more tasks to \nDeleting Executed Tasks \nThe last phase of the scheduling slice handles the tasks that are considered fully executed \nachieve this, each task would have a way to package all the data it needs to execute.\nthe scheduler would dispatch the task to other computers or co-processors though a simple \nHere, using per-worker thread task \nthe front of the worker thread‘s queue that generated the task, as these are likely to be \nAs we have just seen, the scheduler is completely lock-free; its internal CPU usage is kept \nto a minimum, the worker threads are either executing a task or waiting for one, and most ",
      "keywords": [
        "Thread",
        "task",
        "memory",
        "worker threads",
        "lock",
        "scheduler",
        "thread task queues",
        "Count",
        "registered variables",
        "multiple threads",
        "data",
        "code",
        "Thread Local Storage",
        "worker",
        "function"
      ],
      "concepts": [
        "thread",
        "tasks",
        "memory",
        "cores",
        "function",
        "functions",
        "value",
        "lock",
        "executed",
        "execution"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 8",
          "chapter": 39,
          "title": "",
          "score": 0.61,
          "base_score": 0.46,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 54,
          "title": "",
          "score": 0.598,
          "base_score": 0.448,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 7,
          "title": "",
          "score": 0.593,
          "base_score": 0.443,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 37,
          "title": "",
          "score": 0.572,
          "base_score": 0.422,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 6,
          "title": "",
          "score": 0.542,
          "base_score": 0.392,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "thread",
          "worker",
          "scheduler",
          "task",
          "threads"
        ],
        "semantic": [],
        "merged": [
          "thread",
          "worker",
          "scheduler",
          "task",
          "threads"
        ]
      },
      "topic_id": 0,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.18243161649029496,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:05:51.410412+00:00"
      }
    },
    {
      "chapter_number": 37,
      "title": "Segment 37 (pages 343-350)",
      "start_page": 343,
      "end_page": 350,
      "summary": "Game Optimization through the Lens of Memory and Data \ngoes to waste as CPUs wait for data to work on.\nkeeping the CPU well fed with data.\nOnce we better understand the cache and the memory architecture, it will become apparent \nthat we need to respect the cache by shrinking the size of data and keeping it better \nUnderstand the Cache \ncache memory that sits on the CPU die.\nL1 cache is the smallest and fastest.\ninstructions, it‘s commonly split into an L1 data cache and an L1 instruction cache (typically \nL2 cache is slightly slower and is usually shared between data and instructions \nL3 cache is a relatively new \ncache sizes for various platforms [AMD09, Bell08, Lanterman07, Shimpi09, Wikipedia09].\nCache Sizes for Various Platforms \nL1 Instruction/Data \nCache \nL2 Cache \nCache \nCache Line \nBut how do these multiple levels of cache work?\nmemory, it will first ask the L1 cache.\nIf the data is there, it‘s a hit in the L1 cache, and the \ndata will be delivered very quickly to the CPU.\nIf the data isn‘t in the L1 cache, then it is a \nIf the data is in the L2 cache, it is a \nhit, and the data is delivered to the L1 cache and the CPU.\nIf it is a miss in the L2 cache, \ndata will be delivered to the L2, the L1, and the CPU.\nlevels of cache in bytes or words.\nin each cache, the entire cache line is copied from main memory into each cache level.\ncache line copy is the reason why spatial coherency is so important for the working data \nTable 4.4.1 shows cache line sizes for various platforms.\nKnowing that main memory is slow and the cache is fast, our goal will be to keep data and \nthrashing, where the working set of data and instructions can‘t fit inside the cache at the \nIn this case, memory is brought into the cache only to be thrown out because \ncontinually operates on 512 KB of data when the L2 cache size is only 256 KB.\nWith the limited size of cache and the importance of our data being in the cache, it becomes \nthe CPU is waiting for data?\nwhen the CPU is spinning, waiting for data.\nperformance counter is the percentage of loads or stores that resulted in an L2 cache miss \nmisses is high, then the cache isn‘t working well for this piece of code, perhaps because of \nOnce you know which code or data needs to be optimized, you can go to work with the \nSince the cache copies memory in cache line chunks, \nwasting a majority of the data you‘re bringing in from main memory.\nonly operate on 30 percent of the struct, then as much as 70 percent of the data you‘re \nAgain, since memory is copied in cache line chunks, it is important to read and write \nIt would be wasteful to read the same data \nShrink the Data \nOur first main strategy is simple: If your data is smaller, more of it will fit in the cache.\nis as easy as carefully managing your data type sizes.\nAn easy way to manage your data type sizes is by defining them inside a structure.\nsame data: \nCode is data!\nThe smaller your code is, the more code will persist in the L1 instruction cache \nand in the shared instruction/data L2 cache.\nSince both code and data compete for L2 \ncache, smaller code also helps keep data in the cache.\nOrganize the Data \nThe second main strategy is to better organize your data to be cache-conscious.\ncreating contiguous data structures (rather than scattered around memory) and grouping \nis that they waste space by storing pointers to the next node, thus bloating the data \nA much more efficient data structure is either \nSeparate Hot and Cold Data \nbetter cache utilization since the hot data is adjacent and more likely to be in the cache.\nHowever, it‘s not enough to just separate hot and cold data within a struct or class.\nConsider what happens with an array of structs that have both hot and cold data.\nOn the left, an array of structs containing a mix of hot and cold data.\nThe middle image shows splitting the hot and cold data for each struct, with a \npointer linking data from the same struct.\nClearly, we need to further distill the hot and cold data even between structs or classes.\nstructure, but then reference the cold data with a pointer (with the cold data living in some \nThe link between the hot and cold data is \nManipulate the Cache \nwith the cache.\nPrefetch Data \nSince the CPU will spin while waiting for data, it can be advantageous to prefetch data so \nthat it‘s in the cache when the CPU is ready to use it.\ninstructions, but if these aren‘t available, you might have to cleverly prefetch the data \nWhen prefetching data, timing is of the essence.\nYou must not get the data too early, since \nLock the Cache \ncache.\nmemory access, waste comes in several forms: from waiting for bloated data structures \nfrom main memory, not using everything that is read into the cache, and redundantly \npulling the same data into the cache.",
      "keywords": [
        "Fibonacci Sequence Perlin",
        "Data",
        "cache",
        "Sequence Perlin Noise",
        "Fibonacci sequence test",
        "Fibonacci Sequence",
        "Cold Data",
        "Perlin Noise",
        "Memory",
        "CPU",
        "Perlin noise test",
        "Sequence Perlin",
        "hot data",
        "Main memory",
        "Perlin Noise QuickSort"
      ],
      "concepts": [
        "data",
        "cache",
        "bytes",
        "memory",
        "waste",
        "wasted",
        "bit",
        "bits",
        "access",
        "code"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 8",
          "chapter": 10,
          "title": "",
          "score": 0.644,
          "base_score": 0.494,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 7,
          "title": "",
          "score": 0.638,
          "base_score": 0.488,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 54,
          "title": "",
          "score": 0.578,
          "base_score": 0.428,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 36,
          "title": "",
          "score": 0.572,
          "base_score": 0.422,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 39,
          "title": "",
          "score": 0.554,
          "base_score": 0.404,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "cache",
          "data",
          "cold data",
          "cold",
          "l1"
        ],
        "semantic": [],
        "merged": [
          "cache",
          "data",
          "cold data",
          "cold",
          "l1"
        ]
      },
      "topic_id": 0,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.19794592794279192,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:05:51.410475+00:00"
      }
    },
    {
      "chapter_number": 38,
      "title": "Segment 38 (pages 351-358)",
      "start_page": 351,
      "end_page": 358,
      "summary": "Stack Allocation \nThe standard way of doing rapid allocation is to use a linked list of sorts, either single or \nWell, you could use indices instead of pointers to do your linked list with, but they \nSo, in steps the stack allocator.\nThis system uses a pre-allocated list of items, with \narbitrary-sized indices—be that pointers, INTs, WORDs, BYTEs, or even BITs!\nnormal list, we use a simple stack concept and position the stack pointer (SP) at the end.\nWe can then pop the next free item off the stack and return it with minimal fuss or code, \n(where SP is the current stack pointer).\nThe ability to easily use varying sizes of indices, bits, pointers, or even POD types directly \nyou pre-fill it with your object‘s pointers, indexes (INTs, SHORTs, BYTEs, or even bits), or \nexample we‘ll use basic pointer allocation.\nParticle*    Stack[MAX_OBJECT];            // Our object stack \nint          SP;                           // The Stack Pointer \n// Inititialise the stack with object indexes from 0 to \n// Pre-Fill stack with indexes (or pointers) \nfor(int i=0;i<MAX_OBJECT;i++){ \n// Initialise the stack pointer \nSP = MAX_OBJECT; \nsetting up a stack pointer.\nNext, allocation and releasing of a particle object: \nASSERT( SP>=0, \"Error: Stack pointer has gone negative!\"); \nASSERT( SP>=0, \"Error: Stack pointer has gone negative\"); \nstack.\ncalled Alloc() and Free(), but for the sake of clarity when dealing with a stack method, \nindex as a handle to an object rather than a pointer to the object.\n256 sprites that we wish to allocate from, and rather than allocating an object and returning \na whole pointer, we‘ll simply allocate and return the BYTE index, thereby saving memory.\nunsigned char     Stack[MAX_SPRITES]; \n// Inititialise the stack with object indexes from 0 to \n// Initialise the stack pointer \nwe were able to allocate an index and keep our memory footprint down.\nnormally be hard to allocate, as you would normally either opt for a full INT index or use a \nHowever, using the stack method, you can easily store 3 bytes per entry, \nof the Push/Pop, bit allocation can be processed fairly simply, either by masking and shifting \nFirst, we need to allocate the arrays and create the \nunsigned   short                        Stack_short[MAX_OBJ]; \nunsigned   int                          Stack_bits[MAX_OBJ/16]; \n///  Function:<summary> \n/// Function:<summary> \n///             Push an 18bit index onto the object stack \nStack_short[SP] = (unsigned short)_value&0xffff; \nint index = SP>>4; \nStack_bits[index] &= ~(3<<shift); \nStack_bits[index] |= ((_value>>16)&0x3) << shift; \nWhile much slower than a linked list or using the stack with a straight array of pointers, it‘s \nstoring the whole 32-bit pointer.\n///  Function:<summary> \n///                Return the next free index (an 18bit number) \n///                Return the next free 18bit index, or -1 for \nint val = Stack_short[—SP]; \nval |= ( (Stack_bits[SP>>4]>>((SP&0xf)<<1)) &0x3)<<16; \nThe ease and speed at which you can adapt the stack allocation system to your needs is a \nreal strength, and the ability to rapidly allocate not only pointers, BYTEs, SHORTs, and INTs, \ntime on far more complex methods; after all, how else could you easily allocate using 18-bit \nIf we had 10 texture pages, this would mean 40,960 tiles we need to allocate from.\nCalling a standard allocator would then return a pointer to this structure, allowing us \nFirst, let‘s remove the pointer, as we know the stack system \nstructure, and while we could use the very first example to allocate using a pointer to the \nSince this data fits inside 4 bytes, we can actually allocate and return the whole structure‘s \nNow our Pop() command doesn‘t return a pointer, but a structure, like so: \n/// Function:<summary> \nSTileCoordinate (without the need for a pointer) and save yourself 163,840 bytes of \nThe beauty of the stack allocator is that it doesn‘t care what it returns; it will return pretty \neasily define the type as plain UNSIGNED INT and mask out bits of information as you need ",
      "keywords": [
        "Stack",
        "stack pointer",
        "MAX",
        "Object",
        "pointer",
        "int",
        "push",
        "object stack int",
        "Data",
        "BITs",
        "index",
        "Stack Pointer Particle",
        "object stack",
        "POD",
        "POD types"
      ],
      "concepts": [
        "bit",
        "bits",
        "allocation",
        "allocates",
        "allocator",
        "allocated",
        "indexes",
        "index",
        "data",
        "stack"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 8",
          "chapter": 39,
          "title": "",
          "score": 0.709,
          "base_score": 0.559,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 10,
          "title": "",
          "score": 0.567,
          "base_score": 0.417,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 54,
          "title": "",
          "score": 0.51,
          "base_score": 0.36,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 35,
          "title": "",
          "score": 0.508,
          "base_score": 0.358,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 37,
          "title": "",
          "score": 0.507,
          "base_score": 0.357,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "stack",
          "pointer",
          "stack pointer",
          "sp",
          "allocate"
        ],
        "semantic": [],
        "merged": [
          "stack",
          "pointer",
          "stack pointer",
          "sp",
          "allocate"
        ]
      },
      "topic_id": 0,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.18766150772442156,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:05:51.410519+00:00"
      }
    },
    {
      "chapter_number": 39,
      "title": "Segment 39 (pages 359-367)",
      "start_page": 359,
      "end_page": 367,
      "summary": "One of the few drawbacks to the stack allocation method is that you currently can‘t do it \ndisposal or use per-thread stacks.\n6. It requires either the same or less memory than a 1D linked list system.\nyou could even return a pointer into the stack that holds the allocated block so you \nimplement, usually uses less memory than most other methods, and is very easy to adapt \nDesign and Implementation of an In-Game Memory Profiler \nmemory profiler with multi-threading support.\nmemory allocation distribution of a running game in a call-stack-style table in real time.\nThese statistics can be extremely valuable for performing memory usage optimization and \nnumber of memory profiling tools available for C++ in both the open-source and \nMimics the program structure as a call stack, where the name of the function \nTotal number of allocations currently made in the calling function and its \nNumber of allocations currently made in the calling function without \nTotal amount of memory currently allocated in the calling function and its \nAmount of memory currently allocated in the calling function.\nSCount / F.\nNumber of allocations performed by this function per frame.\non memory allocation/deallocation.\nTells you how many times a function is invoked in a single rendering frame.\nA view of the memory profiling remote client.\nMemory Profiling Basics \nThe memory profiling mechanism can be divided into three main parts: collect memory \nallocation information, relate the collected information with the program structure, and, \nBut the challenge is yet to come, because memory allocated within a \nblock the current memory operation is related to by intercepting every memory allocation \nThe remaining sections of this gem will discuss how to utilize function hooking to intercept \nallocation operations and how to get their corresponding call-stack information and \nFunction Hooking \nOne simple way of intercepting memory allocation is defining your own new/delete operator \nInstead, we use a more low-level approach called function hooking, \nother processes‘ functions as those standalone profiling applications do, in this memory \nprofiler we only need to do some patching on the memory that a function is resident in.\nanywhere else in the program tries to invoke it, a proxy function myHookedMalloc is \nlet‘s get our hands dirty and examine what the assembly of the malloc function looks like \nThe above assembly shows the first four assembly instructions of the malloc function, \nwhich prepare the stack and register for use with that function, commonly called the \nWhat the proxy function does is simple: It invokes the original malloc function to perform \nthe actual allocation and log the memory size along with the allocated memory pointer for \nmalloc function.\nTo get back the original function, we need to back up the first assembly \ninstruction before we perform the patching and store it in an executable memory location.\nsecond instruction of the original function.\nsame function signature as malloc does.\nrestoring the patched function when the memory profile gets shut down.\ncode, even for the same function.\nlow-level point of view, it is just a simple memory block with some integer offsets giving the \nstack size; while at a higher-level point of view, we can use a graph structure to represent \nTo collect the full call stack of a running program, a stack-walker [Gaurav08] with debug \nHowever, generating a full call stack is not only time \nmemory profiler by combining the scope variable/macro.\nwhile each of these nodes contains the necessary memory profiling statistic and the link to \nprogram, usually the main function.\nFunction A invokes B, a linear search for all the child nodes under A with the name B is \nFor the hooked memory allocation function to make use of the call-stack information, the \ncall tree will store a variable that points to the current call-stack node.\nbetween the current allocation and the current call stack is made.\nThe exclusive allocation count and size will be updated whenever the hooked functions are \nApart from simply updating the statistics, the hooked functions need to perform \nsome bookkeeping in order to retrieve the corresponding call-stack node for a particular \nallocated memory block during the deallocation operation.\nhigh run time and memory overhead; therefore, we use the approach of embedding the \ncall-stack node pointer with the allocated memory block.\nvoid* p = (*originalMalloc)(sizeof(Node*)+sizeof(int)+size); \n*(int*)((char*)p + sizeof(Node*)) = size; \nOther statistics that take into account the child function calls can be calculated on the fly \nthe pointer to its corresponding call-stack root node and another pointer to the current node \nmay operate on a call-stack node that doesn‘t belong to the current thread.\ncompile and execute several demo programs related to the memory profiler.\nA CPU profiler based on the same code base as the memory profiler is also supplied as a \nBoston: Charles River Media, 2000.\nYou may need to know which function passed in bad data or \nIn this gem, we‘ll present a new error logging function that automatically generates useful \nStack Information (RTSI).\nthe program‘s function stack at run time.\nWhen the compiler reaches the breakpoint in function C(), and the programmer requests \nthe program‘s run-time stack information, it would return something like this: \nsystem functions called have been omitted from this example.\nIt then details what function main() called, A(), and recursively what \nfunction A() called, and so on until it reaches the current function where the breakpoint \nuseful for tracking stack-overflow bugs, as well as taking a snapshot of the program‘s \nC/C++ does not have a standard function to call to print the program‘s RTSI, so it‘s up to \nthe operating system and hardware vendors to distribute a set of functions in an API to \nSince the RTSI resource will probably be used in several different spots in the game code, ",
      "keywords": [
        "memory",
        "function",
        "memory allocation",
        "node",
        "call stack",
        "size",
        "memory profiling",
        "memory allocation function",
        "stack",
        "call",
        "malloc function",
        "code",
        "RTSI",
        "allocation",
        "functions"
      ],
      "concepts": [
        "memory",
        "function",
        "functions",
        "functional",
        "profile",
        "void",
        "allocate",
        "allocating",
        "allocations",
        "stacks"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 8",
          "chapter": 38,
          "title": "",
          "score": 0.709,
          "base_score": 0.559,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 36,
          "title": "",
          "score": 0.61,
          "base_score": 0.46,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 54,
          "title": "",
          "score": 0.581,
          "base_score": 0.431,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 37,
          "title": "",
          "score": 0.554,
          "base_score": 0.404,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 7,
          "title": "",
          "score": 0.548,
          "base_score": 0.398,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "memory",
          "stack",
          "function",
          "allocation",
          "memory allocation"
        ],
        "semantic": [],
        "merged": [
          "memory",
          "stack",
          "function",
          "allocation",
          "memory allocation"
        ]
      },
      "topic_id": 0,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.19714795473356087,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:05:51.410571+00:00"
      }
    },
    {
      "chapter_number": 40,
      "title": "Segment 40 (pages 368-375)",
      "start_page": 368,
      "end_page": 375,
      "summary": "To load our RTSI API function calls, we use the following code: \n//and look at each function call \n//function was called from \n//function names.\nWe need to set up an access point to the RTSI with the required function pointers.\nThere are a couple of important pieces of code in that function.\nfunctions on the run-time stack.\nfor programmers to create a set of functions that display an error message when something \nThe problem with a generic error log function is that the \nprogrammer has to keep track of where he is in the code in order for the error message to \n\"Problem with function A()\" ) ; \n\"Problem with function B()\" ) ; \nthe context in which these functions are called.\nfunction could ―know‖ its current context and report accordingly, which is exactly what RTSI \nWith the given code sample, the programmer could then bind the error log to the in-game \nthe game‘s code) as well as not have to resort to an error check table.\nBoston: Charles River Media, 2000.\nCode Coverage for QA \nWhen working on a rapidly developing code base, a good QA team is a highly versatile \na high-level form of testing that it can be hard to relate it to low-level changes in the code.\ngiven piece of low-level code, a programmer may have little idea where and when in the \nare rarely absolutely sure whether they worked and the code was actually executed; in \nThis gem describes a framework that combines code coverage analysis and conventional QA \nIt addresses these issues and improves the testing process for \ninsight to the low-level programmer about where the code is actually used.\nBefore examining the approach of this gem, let‘s consider some of the established testing \nUnit testing.\ncode, may be that unit testing is considered to add too much development overhead.\nIf unit tests are not present in the original code, then restructuring to add them is \nAutomated functional testing.\nyou are testing is currently under development, it may change so quickly that a \nQA testing.\nPlain old QA is essentially a manual form of functional testing.\nIn all of these approaches, we might ask: How complete is their testing?\nassessing this is through code coverage analysis.\nAn Analogy: Breakpoint Testing \nWe might call it breakpoint testing.\nIn refactoring a function/class/file/blob, one systematic approach to testing on the \ncode path and then run the game, removing each breakpoint as it is hit.\nThis can be a good minimal test of changes, as it ensures the developer has executed all the \ncode he changed and has observed the overall results.\nHowever, note that breakpoint testing works for new code as well as refactored code and \nthat it directly couples high-level functional tests to low-level details in the source.\nand manual testing.\nCode Coverage \nConventional code coverage analysis is used to quantify how completely a testing procedure \nthe number of unique lines (or functions, branches, code paths, and so on) that have been \nThe first is what kind of testing procedure we should use, since code coverage is only useful \nin analyzing tests.\nUnit testing is the standard in the wider software industry, but for games \nwe propose QA testing of real levels.\nsoon as the source code changes.\nThe result most commonly quoted from code coverage is a single figure: a percentage \nrepresenting the completeness of testing, where targets are commonly 90- to 100-percent \nNote that if we use real levels as tests, in most games \nIf we accept that we will only test a fraction of our code, we have an ambiguity: \nIt may also beg the question: Much of the code may have been tested, \nbut was this piece of code tested?\nFinally, if we use human testers to perform the tests, our results may vary wildly with \nThere are various code coverage packages already available, but without addressing these \nprogrammer places his own markers into the code using a simple macro.\nimplementation of the marker code—avoids slowdown and code-bloat.\nWe use a unique string to label each marker.\nand calls its Hit() function: \nFunctions can be renamed or moved into a different class or file, but while marker \nlabels are preserved, code coverage results remain undisrupted.\nC++ compilers include predefined macros that could generate marker labels automatically, \nbased on function names, line numbers, and so on.\nsomeone copied and pasted code somewhere else, but it could also occur if a single marker \nscript to scan the source code for duplicate labels.\nmarker at the end, where the ―meat‖ of the code has already been used: ",
      "keywords": [
        "code",
        "Code Coverage",
        "function",
        "error log function",
        "RTSI API function",
        "RTSI",
        "game",
        "NULL",
        "Error",
        "ASSERT",
        "Coverage",
        "CONTEXT",
        "code coverage analysis",
        "Unit testing",
        "dllHandle"
      ],
      "concepts": [
        "code",
        "tested",
        "function",
        "functions",
        "functional",
        "game",
        "line",
        "levels",
        "coverage",
        "label"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 8",
          "chapter": 41,
          "title": "",
          "score": 0.384,
          "base_score": 0.384,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 47,
          "title": "",
          "score": 0.313,
          "base_score": 0.313,
          "topic_boost": 0.0,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "code",
          "testing",
          "code coverage",
          "coverage",
          "function"
        ],
        "semantic": [],
        "merged": [
          "code",
          "testing",
          "code coverage",
          "coverage",
          "function"
        ]
      },
      "topic_id": null,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.14778980680904297,
        "topic_boost": 0.0,
        "timestamp": "2025-12-17T23:05:51.410610+00:00"
      }
    },
    {
      "chapter_number": 41,
      "title": "Segment 41 (pages 376-394)",
      "start_page": 376,
      "end_page": 394,
      "summary": "list of expected marker labels for each level.\nthe results from code coverage—in particular, adding any ―unexpected‖ markers that were \nThis also smoothly assimilates new code: The markers will appear in results as \nThe manager class loads the per-level input file containing the set of ―expected‖ marker \nThe list of expected markers for each level is stored as a separate file in the level folder \nshould easily hit 90 percent of markers reachable in a given level, but guidance on the last \nthey form the vocabulary of a common language between testers and programmers, \nallowing testers to find out how they might hit that specific marker and to communicate that \nCode coverage within CryENGINE, when 93 percent of markers for \nResults are output as a list of labels of the markers hit, either dumped to a log file or sent \nOutput from a code-coverage testing run should contain at least the following data: \ncheck that good coverage was achieved, check that specific code was tested, and look out \nFurther, merge the results of all your levels, looking for code that is not \nmarkers hit to form a new list of expected markers for subsequent runs of the level.\nBuild a history of results for each level over time.\nAssigning priority levels to markers could help with test \ninside out—the levels of Crysis formed the subject of code coverage tests.\nand where markers were first hit during their own testing, and with this information allowing \nor more tests of each level of the game) in one pass, merging results, updating the label \nlabel files and verify that this was the first test of that code, or to see that the code really \nThis gem presented an adaptation of the code coverage methodology specifically for \nDomain-Specific Languages in Game Engines \nDomain-specific languages, DSLs for short, are computer languages used to solve problems \nThey help by separating domain-related code from application code; they let domain \nexperts solve problems using a language they understand; they can have multiple outputs, \nspecific languages usually tighten relations between programmers and experts.\nwill dig into domain-specific languages, answering the following questions: What is a DSL?\nDomain-Specific Languages in Depth \nDomain-Specific Languages: Definitions and Examples \nSeveral definitions have been proposed for domain-specific languages.\nof expertise, a specific domain.\nThese computer languages are sometimes referred to as \nprogramming languages, or GPLs, provide generic solutions to a broad range of problems \nDomain-specific languages have existed for a long time, and their use in computer science \nSuccessful examples include Lex and Yacc, programming languages intended \nto create lexers and parsers to help in building compilers; SQL, a computer language \ntargeted at relational databases; and LaTeX, a document markup language providing a \nprovide appropriate notations to the domain model and a very limited set of instructions.\nThis limits what problems users can solve but at the same time allows the language to be \nspecification languages, providing domain experts with the capability of writing \nspecifications that will become new tools, solve problems, and encode domain knowledge.\nBecause they encode domain knowledge as perceived by domain experts, DSLs are usually \nData mining is a domain that could be used as an example illustrating how domain-specific \nlanguages help.\nin any GPL, but it is much easier to write with a language that is appropriate to the domain.\nListings 4.9.1 and 4.9.2 show SQL and C++ code snippets that provide the same feature to \ndomain and thus is harder to use in this specific case than SQL.\nare referred to as language noise, and programming interfaces that minimize this noise are \nDomain-specific languages do not always provide a fluent interface \nto their users, but this can be a useful feature to provide when end users do not have a \nThe Different Types of Domain-Specific Languages \nproduced by their compilers, domain-specific languages are distinguished by the methods \nas building a new general-purpose language: Programmers have to design the language and \nOn the other hand, internal DSLs are built from general programming languages \nthat offer syntaxes malleable enough to build new language from them.\nthe amount of work needed to implement the language as programmers rely on the existing \ntool chain and language‘s features.\ndomain-specific language is Unreal Engine‘s Kismet, which allows designers to control \nDomain experts may not be able to write code but are usually able to review code written \ndomain experts, achieving end user programming.\nDSLs concentrate on domain knowledge, \ndomain.\nJust like good APIs, DSLs provide users the ability to program at a \nThere are also several drawbacks to using domain-specific languages.\nis the cost of building and maintaining a new language.\nAnother alternative is to embed the DSL in a host language.\nAs the language evolves \nand requirements change, language maintenance can become a burden.\nusually leads to building general-purpose languages with some domain-specific keywords.\nof using multiple languages to build an application is that programmers need to learn more \nthan a few languages to control the whole pipeline, and thus they need to quickly learn and \nOne last problematic aspect of using domain-specific languages is that it introduces \nGame development provides a wide variety of challenges in many different domains.\ntake up these challenges, programmers usually use a few general-purpose languages and \nbuild frameworks that will help resolve domain-related issues.\nThinking in terms of modeling problem domains and user experience helps to define what \nWhen to Create a New Language \nCreating new languages is a difficult and time-consuming task, so deciding when to use a \nThe need for a domain-specific language usually arises \ncode level, in programs, subroutines, or data, as well as at the application level, building \nDomain-\nspecific languages stress staying domain-focused, so it is important to deeply understand \nrequirements, then it may be impossible to design the language.\ndomain language, whereas if they are too broad, the language may lose its focus.\nBoundaries also influence the language interface by defining which variants are to be \nLastly, because creating a new language is a difficult task, it is important to know whether \nsuch a language will be reused.\nlanguage, but if domain knowledge needs to be encoded multiple times, solve multiple \nissues, or requires a lot of effort to be encoded using a GPL, then creating a new domain-\nspecific language may be a good option.\nThe process applied when creating a domain-specific language can be summed in six steps, \nThis leads to a user-centric approach and designing the language \ninternal and external DSLs and the type of interface the language will provide to the end \nInterfaces are usually driven by the domain model to represent end user ability to use \nIn the language design phase, the specifications of the \nlanguage are laid down.\nimplement the language are created.\nDetermining the user interface of a new language is a decisive factor for its adoption as a \nIf the domain can be modeled using text, then both internal and external DSLs can satisfy \na host language that is malleable enough to let a DSL emerge from its own syntax.\nsuch a language is available, its syntax and tool chain will influence the look and feel of the \nto create a new textual DSL, as it will provide needed tools for the language.\nhand, external DSLs do not rely on another language, allowing for a better customization of \ninterpreters, or compilers to support the new language.\nIn this case, the domain-specific \nlanguage can rely on a graphical interface to help end users encode their knowledge.\nAs domain-specific languages become more and more popular, several programming \nLuckily, most programming tips used to build domain-\nspecific languages are easy to understand and use, but some may not be available from all \nhost languages.\nbuild fluent interfaces that generate complex code at pre-processing time.\nmethod call returns an object that provides a part of the language interface.\nNested functions are another way to call functions while removing language noise as much \nAnother frequently used technique for building domain-specific languages on top of an \nfeature that only recently became widespread in many mainstream languages.\nevaluating code, with minimal language noise, in a predetermined context.\ndomain-specific languages.\nOther languages, such as Python, can provide similar features using other internal \nIt allows creating new modeling languages with very little \nListing 4.9.6 shows a domain-specific language where animation identifiers are keywords \nnested functions using the Ruby programming language.\ndomain-specific language, define_animation_set creates an animation set object and \nhow Listing 4.9.6 is implemented using the Ruby programming language is provided on the \nIt requires the language to handle everything, \ntree after the code has been parsed by the host-language parser.\ntranslating code from one language to another or when the DSL needs to rely on a wider \nTools Easing Language Construction \nExternal domain-specific languages have fewer constraints than internal ones but need \ntime and are still a great help to build languages, but they tend to be replaced by new tools, \ndevelopment environments focused on creating domain-specific languages.\nan integrated development environment for creating languages using ANTLR V3 grammars.\nANTLRWorks uses textual grammars to create external textual DSLs, Microsoft‘s DSL tools \nprovide a way to create visual domain-specific languages to be integrated into Microsoft \nThe Microsoft DSL tools help design the language and its graphical interface \nby providing wizards and tools easing domain modeling, specifying classes and \ntools for domain-specific languages can‘t be used for building run-time DSLs, they offer \nopportunities for integrating a custom visual domain-specific language inside Visual Studio.\nMulti-Language Game Engine Development \nThis section presents domain-specific languages for two domains related to low-level engine \nThe first example of a domain-specific language in a game engine relates to data structure \nabout data structures as possible using a domain-specific language that handles tasks such \nas generating code for serializing and accessing data in all languages used in the pipeline.\nAcquiring knowledge about the domain of data management is easy because programmers \nThe language will encode structures \nLastly, this domain-specific language will be used \nby programmers, and thus it is acceptable to use a textual interface with low language \nlanguage.\nSimple structure layout using a domain-specific language \nThe second use case for domain-specific languages targets the engine‘s threading model.\nAgain, a language focused on task dependencies and \nlanguage has to expose to the user variants such as number of cores, number of threads \nThe output of such a language can be either code or data that would drive \nLike the previous domain-specific language \npresented, this language is targeted at programmers, and an internal DSL‘s properties \nThreading a domain-specific language \nThe quickest and easiest way to integrate a domain-specific language into an engine is to \nlanguage seems to be an evident way to provide domain-specific languages from the game \nBut, with C++ being the preferred language for building game engines, it is difficult \nto provide a domain-specific language that allows for rapid iterations.\ncompilation process that may disturb domain experts without any programming \nDevelopers who create DSLs using C++ as a host language must be careful about build \nIntegrating a DSL that relies on a language other than the one used by the engine is made \nIn this case, the domain-specific language \nis used to input domain knowledge and transform these high-level specifications to low-level \nany other code generation technique: End users can easily input data without worrying \nAlthough this technique has the advantage of separating the domain-specific language from \nthe language used to implement the engine, it has the major drawback of increasing the \nexecute domain-specific code at run time.\nDSLs on top of such languages.\nlanguage and also helping reduce iteration cycles, but it sacrifices run-time performances.\nprovide tools that will assist the debugging phase, since this new language will add an extra \nAn interesting way to integrate DSLs in an engine is a hybrid approach where DSL code can \nlanguage and used to translate DSL code to native code relying on the engine‘s framework.\nTools that help domain experts input their knowledge into the pipeline usually provide an \ninterface relying on domain-specific languages.\nTools providing DSLs integrated into game \nDSLs let users encode domain knowledge using custom syntax and usually help centralize \neasing knowledge transfer across multiple languages and applications.\nsuch as Google‘s protocol buffers or Facebook‘s thrift provide domain-specific languages \nDomain-specific languages have been around for a long time and are successfully employed \ncosts associated with creating and learning several languages, but because video game \nfor domain-specific languages.",
      "keywords": [
        "language",
        "Domain-Specific Languages",
        "DSLs",
        "DSL",
        "code",
        "domain",
        "Domain-Specific",
        "code coverage",
        "markers",
        "domain knowledge",
        "results",
        "Engine",
        "provide domain-specific languages",
        "DSL code",
        "internal DSLs"
      ],
      "concepts": [
        "language",
        "code",
        "domain",
        "dsls",
        "provide",
        "provided",
        "markers",
        "list",
        "level",
        "requires"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 8",
          "chapter": 40,
          "title": "",
          "score": 0.384,
          "base_score": 0.384,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 48,
          "title": "",
          "score": 0.318,
          "base_score": 0.318,
          "topic_boost": 0.0,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "language",
          "domain",
          "languages",
          "domain specific",
          "specific languages"
        ],
        "semantic": [],
        "merged": [
          "language",
          "domain",
          "languages",
          "domain specific",
          "specific languages"
        ]
      },
      "topic_id": null,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.1476916834755069,
        "topic_boost": 0.0,
        "timestamp": "2025-12-17T23:05:51.410648+00:00"
      }
    },
    {
      "chapter_number": 42,
      "title": "Segment 42 (pages 395-402)",
      "start_page": 395,
      "end_page": 402,
      "summary": "screen size, from the perspective of the user interface (UI) layout.\nThe more UI elements (widgets) you have in your game, and the smaller the screen size of \ndesigning the UI layout, you may need to consider more than the widget‘s size, position, \nexample, textures, which you put on the widgets in order to have a crisply rendered widget.\nThe first solution makes use of virtual screen coordinates (see Figure 4.10.1).\nAll widgets are \nThe second solution works for designs with only a few widgets.\nwidget that is bound to the lower and right screen borders, the widget will stick to the \nmake use of a large number of screen resolutions without non-uniform-scaled widgets or \nThe drawback here is that with increasing screen resolutions, the widgets \nbelow a given screen resolution the widgets may start overlapping each other, which may \nuse different scaled UI effects for different screen resolutions).\nWidgets are defined by a set of properties (position, size, texture, font style, and so on) \nMany applications make use of XML to define widgets.\na widget that defines the widget‘s name, position, and size.\n<Widget \nwidget in larger screen resolutions.\nsimpler form in our last project is the use of conditional modifiers (CM).\nA conditional \nmodifier is a node in a widget‘s XML definition that contains an additional set of widget \nYou can attach a CM to any widget.\nA CM always contains a set of conditions \nAn example of a CM inside a widget‘s XML definition is presented \n<Widget \n<Conditions> \n</Conditions> \n</Widget> \nIn this example the widget is created with the properties defined in the Widget node.\nchild node of the widget, we added a CM node.\nFor each CM whose conditions evaluate to true, we apply the specified properties to \nSo in the example above on a PC, the widget would be \nthis example, you could, for example, only change the size of the widget if needed.\nUsing only a single CM or a single condition inside a CM is not that useful.\n<Widget \ncm_name = \"above_minspec_screen_size_pc\" \n<Conditions> \n<Condition_Operator_And/> \n<Condition_Operator_And/> \n</Conditions> \n</Widget> \nHere we apply the properties inside the CM only in the case that screen width is greater \nIn this case we change the widget‘s position.\nsecond CM that changes the widget‘s texture to a low-resolution variant when \nchange different properties of the widget in a different environment.\ntwo different CMs to change the same widget property in different cases.\ndifferent conditions only depends on the needs you have to obtain the desired UI layout for \nCMs and that each CM contains at least one condition.\nspecific property (cm_conditions_reference) to the CM definition that references an \n<Widget \ncm_conditions_reference = \"conditions_xbox360.xml\" \n</Widget> \nFollowing are the corresponding definitions from conditions_xbox360.xml.\n<Conditions> \n<Condition_Operator_And/> \n<Condition_Operator_And/> \n</Conditions> ",
      "keywords": [
        "Aleksey Kadukin",
        "widget",
        "condition",
        "conditions",
        "Abstract State Machines.",
        "screen",
        "Game Programming Wisdom",
        "condition operators",
        "Layout",
        "Charles River Media",
        "operator",
        "screen resolutions",
        "System",
        "Conditional Modifier Condition",
        "size"
      ],
      "concepts": [
        "conditional",
        "conditions",
        "condition",
        "widgets",
        "screen",
        "differences",
        "different",
        "differ",
        "layout",
        "textures"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 8",
          "chapter": 43,
          "title": "",
          "score": 0.915,
          "base_score": 0.765,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 44,
          "title": "",
          "score": 0.404,
          "base_score": 0.254,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "widget",
          "cm",
          "screen",
          "widgets",
          "conditions"
        ],
        "semantic": [],
        "merged": [
          "widget",
          "cm",
          "screen",
          "widgets",
          "conditions"
        ]
      },
      "topic_id": 6,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.12493150327734072,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:05:51.410687+00:00"
      }
    },
    {
      "chapter_number": 43,
      "title": "Segment 43 (pages 403-417)",
      "start_page": 403,
      "end_page": 417,
      "summary": "We can further improve the way we define widgets, especially if we make use of many \nFor these cases you can make use of widget templates (see Figure \nA widget template defines a widget with a default set of properties.\ninstance from the specified template XML definition, apply all properties found in the widget \nexample shows how you can make use of widget templates.\nThe property template_filename refers to the widget template and contains all default \nMany situations require assets such as textures or UI effects to be loaded at run time.\nThis requires the specific UI effects that fit the current widget shape and size \non different widget sizes you may want to apply textures with different resolutions, and on \ndifferent widget shapes and widget sizes you have to use different UI effects.\ndecouple these problems from the source code, you can make use of proxy assets.\ntexture or some UI effects file) and some CMs that control which asset to use in which \neffectively three different UI layouts we used for all different screen resolutions.\nthan the ones defined use the large screen resolution layout.\nyou run into the problem described earlier (widgets become small in relation to screen size).\nsupported screen resolution of 1024×768 and let the UI Editor create CMs with a \nRoad Creation for Projectable Terrain Meshes \nRoads are becoming an increasingly important part of large environments in modern games.\nIn this gem, we explore several techniques that are useful for modeling roads in a large \nWe start by building a trajectory for a road on a projectable mesh using elements of \nvariational calculus and describe an algorithm for creating optimal paths on the terrain \nnatural design requirements for the local road geometry.\nRoads as Geodesic Curves \nMany roads in the real world exhibit certain optimal properties in a sense that they were \nconsider an ideal road between two points A and B on a horizontal plane, which is a straight \nWhen placing roads between two locations on a terrain model, we can use the same \nroad.\nVariation Problem for Roads \nWe will represent a road between points A and B on a terrain with a smooth curve γ(t) \nThen we can define the cost of moving from A to B along such curve as the length of the \ncorrespond to our desire to provide natural-looking roads, and in particular they ignore the \nAn important observation is that actual roads also minimize variation of altitude along the \nshortest path across a hill, roads tend to bend around while trying to maintain the same \nwhich will provide a better approximation to the behavior of actual roads.\nThe method can be relatively expensive for a detailed representation of a road curve with \nwhen the length of the road segment reaches a minimal allowed length.\nA final touch for the created curve could be node resolution optimization.\nThe branching of roads requires a little extra work.\none of the Points A or B in the presence of an already-built road from A to B can be reduced \nto the same variational problem with any movement along the existing road being negligibly \nsmall in comparison to the movement across terrain without roads.\nboundary condition: The end point D of the new curve will belong to the existing road rather \nroad.\nRoad Grading Techniques for The Sims 3 Worlds \nAfter creating a trajectory for a road, we need to deliver a road mesh that is consistent with \nthe terrain—this means the terrain mesh also needs to be locally modified around the road.\nBlending Roads with Terrain in The Sims 3 \nThe Sims 3 worlds were designed without grid-based placement restrictions for roads.\nroads could be placed anywhere with respect to the mesh, and the road segments were not \nRoad segments were the spline-based curves connected to each other by connection ports.\nroads in an in-house build tool.\nimage height map, which played a critical role in road network construction algorithms.\nThe road mesh is generated using a base spline and world terrain geometry that is covered \nby the road segment.\nThis provides a relatively easy and intuitive way to lay down the road \nHowever, as shown in Figure 4.11.3, the road surface generated in such way \nThe road segment placed on the uneven terrain.\nRoad Grade and Road Slope \nThe road surface must satisfy a number of conditions enforced by the road-grading tool.\nThe most important characteristics controlled by this tool are road grade and road slope.\nroad slope is defined as a road surface tilt (the gradient perpendicular to the road), and a \nroad grade is defined as steepness of the road (the gradient parallel to the road) [Wiest98].\nThe tool allows designers to set up the road grade and slope limits and automatically modify \nthe road surface to create a realistic look and improve the routable functionality of roads.\nThe algorithm adjusts individual or connected road segments‘ tilt and steepness using \nFlattening Road Slope \nThe purpose of the road slope flattening algorithm is to set to zero the slope across a road \nThe same technique can be applied to the connected road segments.\nThe actual road mesh modification is accomplished by a world terrain height map data \nThe advantage of this method is a smooth coupling of road surface with the \nThe disadvantage is that the road surface geometry will become \nMoving the graded road will leave a modified terrain \nAlternatively, the road network surface could be managed by a separate height map, and \nterrain data and road network maps.\nThe road segment spline defines a road profile.\nAt the first step, we divide a road segment \nThe road segment divided by sub-dividers.\nThe distance between sub-dividers depends on the terrain height map resolution and the \nroad edges‘ lengths.\nFor example, if each height map point represents a 1×1 unit in world \nand minimum road edge lengths.\nintersection between the sub-divider and a road spline) to set zero road slope.\nThe third step is applying a new height to each height map point inside of a sub-quad \nTriangulated road segment.\nThe fourth and final step is to create a smooth road surface.\ncan leave visual artifacts between road sub-quads.\ninterpolation between neighboring height map points across the entire road segment.\ncase of connected road segments, the bilinear interpolation should be performed across the \nentire road network.\nSmoothed road segment.\nLimiting Road Grade Angle \nTo limit a road segment grade, we use a modified road slope flattening technique.\nroad segment subdivision, we calculate an inclination angle for each sub-quad.\ndetermine which road direction should be used for raising or lowering each end.\nThe road grade limit difference for opposed road directions.\nsystem also benefited from flattened road slopes and reasonably limited road grades.\nrivers) or can be modified to achieve more complex road surfaces, such as road banking on \nrequire different approaches for sub-quad height calculation, surface triangle flattening, and \nThese techniques cover a relatively complete set of road creation tasks for large \nAn abstract definition of a road as a geodesic curve may not be sufficient to \ndeliver fully automated road creation, but it can provide a good starting point for the world \ndesigners, from which they can tweak road layout to their liking.\nThe road-grading tool \nrequired after the road was created and imprinted into the terrain.\n―A Landowner‘s Guide to Building Forest Access Roads.‖ July \nEquipped with this knowledge, you will be able to make full use of tablet features directly in \nThe pen-based interface devices we find in game development are typically digitizer tablets, \nindirect interaction—the user moves the pen on a tablet on their desk to move the pointer \nTablet PCs and tablet displays provide direct interaction by allowing the user \nLow-level studies, such as [MacKenzie91], have shown that pen tablets perform as well as \nIn addition to pen position and touch detection, a modern tablet offers features a mouse \nTwo-dimensional drawing is one of the archetypal applications of pen tablets.\nFor example, terrain height-map editing—tip pressure can control height \nResearchers have found that pen-based interfaces are good for encouraging users to focus \nstripping our early design tools down to little more than the pen and the user, removing \nSince most tools will not be designed exclusively for tablets, a comparison to the mouse is a \nDirect-input setups, such as tablet PCs, introduce additional challenges for \nrequire the user to pay attention to pen location.",
      "keywords": [
        "Road",
        "road segment",
        "Widget",
        "widget template",
        "road surface",
        "Road Slope",
        "Terrain",
        "Road Grade",
        "height",
        "height map",
        "tablet",
        "curve",
        "default button",
        "road network",
        "template"
      ],
      "concepts": [
        "road",
        "tablets",
        "designers",
        "base",
        "based",
        "terrain",
        "user",
        "directly",
        "direction",
        "directions"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 8",
          "chapter": 42,
          "title": "",
          "score": 0.915,
          "base_score": 0.765,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 44,
          "title": "",
          "score": 0.316,
          "base_score": 0.166,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "road",
          "roads",
          "terrain",
          "road segment",
          "widget"
        ],
        "semantic": [],
        "merged": [
          "road",
          "roads",
          "terrain",
          "road segment",
          "widget"
        ]
      },
      "topic_id": 6,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.11752752447363338,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:05:51.410726+00:00"
      }
    },
    {
      "chapter_number": 44,
      "title": "Segment 44 (pages 418-425)",
      "start_page": 418,
      "end_page": 425,
      "summary": "is the use of shortcut keys to directly invoke commands.\nFor example, listing shortcut keys with their menu items makes the shortcuts \nYou can similarly show gesture marks next to menu items or draw the \ngestures on the screen briefly when the user invokes the command.\nrevealing gestural shortcuts has also evolved into an elegant menu solution—marking \nGestures and Pie Menus: Marking Menus \nThe user touches the pen down \nOnce the correct command is highlighted, the user lifts the pen to \nareas of the workspace, similar to right-click context menus in mouse interfaces.\nPie menus present several advantages to tablet users.\nthe effective size of the menu items, simply by making larger gestures.\nthe handedness of the user, it‘s also a good idea to provide an option to flip the menu \nMarking menus take pie menus and combine them with gestural shortcuts to create a highly \nThe basic marking menu implementation is very similar \nThe menu is pressure activated, and the user‘s pen motions are shown as a \nThe user can move \nWhat makes marking menus so effective is that using the pie-menu interface is also a \nSince the gestures created by the marking menus are all \nrecognition systems that use non-linear gestures.\nTablet Programming \nA high-level point about adding tablet support to your tools is that it‘s highly advisable to \npackage your tablet code into a reusable toolkit.\ngesture-recognition system, custom UI widgets, and low-level tablet interface code.\nhelps provide consistency across applications and makes it easier and therefore more likely \nFor Windows applications, Wintab is the industry-standard API for accessing tablet devices.\nOn the CD-ROM, you will find an example program that uses Wintab to read and display the \nvarious types of tablet data discussed in this gem.\nTablets generally have a wide variety of device capabilities, much like PC joysticks.\nNow that we‘re up and running, let‘s see how to get position data from the tablet.\nWintab, we get data from the tablet via packets in a message queue.\nthe context parameters, we had to set CXO_MESSAGES in lcOptions.\nto send our application WT_PACKET messages through the standard Windows messaging \nWT_PACKET signals our code when the tablet has data queued up for the \nWT_PACKET messages, and the tablet will stop sending state information.\nWintab to move the system cursor, rather than depending on our code to do it.\nsimplest way to handle tablet versus mouse positioning.\nto track mouse and tablet positions separately.\nBy default, the tablet will deliver position information in tablet units (in other words, at the \nresolution of the tablet).\nKeep in mind that the origin of the default tablet coordinate system is in the \nlower-left corner of the tablet.\nIf you also want to translate the tablet origin—for example, to match the origin of \ncompatibility with non-tablet-aware applications, since pen-down is usually equivalent to \nOur code is tablet aware, though, so it can ignore the button messages and \ninstead process the tablet‘s button and pressure values directly from the packet queue.\nThis code listing extracts the button number and button state from the packet.\nRemember that more than one application can be running that uses the tablet for input.\nWith Wintab, tablet contexts are layered so that usually only the application with the top-\nmost context receives tablet events.\ngets minimized, you should push your tablet context to the bottom of the context stack with \nLet‘s start adding some more advanced tablet features to the application.\nA key part of the tablet system is the cursor.\nThe cursor is the physical device that the user \nuses to interact with the tablet surface.\nThe cursor does not have to be touching the tablet surface for it to be detected.\ntablets sense the cursor from about half a centimeter above the actual surface.\nwhen a cursor comes within proximity of the tablet by setting CXO_CSRMESSAGES in \nIf you‘re not interested in the details of the cursor being used with the tablet, \n// use pkt.pkCursor with WTInfo() to get properties of the \nPressure is a common and very useful pen feature.\npressure axis,‖ which tells you how many levels of pressure the device reports.\nyou access the pressure data this way, this will all be transparent to your application.\nThis is pressure parallel to the tablet surface, which can come \nbeing held at relative to the tablet surface.\nthe pressure values, the orientation values should be scaled based on the device \nare given to your application through pkt.pkButtons, just like the tip.\nSome tablets \nhave additional buttons on the tablet itself.\nresearch community and learned how to use the Wintab API to interact with tablets.\nexample code on the CD-ROM can serve as a starting point for creating your own tablet-\nimplementation of the various pen-based solutions we touched on.\nrich and powerful tablet functionality to your next game tool project.\n2-D Control Devices.‖ Proceedings of the 15th Annual Conference on Computer Graphics and \nInput.‖ Proceedings of Graphics Interface (2004): 221–230.\n―Potentials and Limitations of Pen-Based Computers.‖ Proceedings of the \nCreating a Multi-Threaded Actor-Based Architecture Using \nrobert.jay.gould@gmail.com \nprocessing cores, developers will have to redesign the architecture of their game engines to \ngameplay systems capable of scaling through high concurrency.\nis a multi-threaded message passing actor architecture, which uses engineering tradeoffs \nThus, finding concurrency patterns in gameplay systems should be the \nsystems like graphics and physics that are almost entirely data-driven can be easily \ndecomposition patterns can be applied to gameplay systems to increase their concurrency.\ninto atomic tasks that can be processed concurrently, without compromising the state of the \ntechniques, generally applicable to any sort of system, is to use immutable data like pure \nbe compromised; instead, state changes are implemented through data copying and \nscale on multi-cored environments, implementing lightweight processing units that can work \nconcurrently is the way to go, and these techniques can be found in actor-based ",
      "keywords": [
        "marking menus",
        "tablet",
        "menus",
        "Pie Menus",
        "system",
        "Wintab",
        "PACKET",
        "marking",
        "cursor",
        "pressure",
        "makes marking menus",
        "user",
        "state",
        "data",
        "context"
      ],
      "concepts": [
        "tablet",
        "data",
        "menu",
        "useful",
        "uses",
        "gestural",
        "gesture",
        "users",
        "based",
        "cursor"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 8",
          "chapter": 42,
          "title": "",
          "score": 0.404,
          "base_score": 0.254,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 43,
          "title": "",
          "score": 0.316,
          "base_score": 0.166,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "tablet",
          "menus",
          "marking",
          "menu",
          "cursor"
        ],
        "semantic": [],
        "merged": [
          "tablet",
          "menus",
          "marking",
          "menu",
          "cursor"
        ]
      },
      "topic_id": 6,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.13300466713752973,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:05:51.410765+00:00"
      }
    },
    {
      "chapter_number": 45,
      "title": "Segment 45 (pages 426-433)",
      "start_page": 426,
      "end_page": 433,
      "summary": "message-pump design commonly used in games (as if the entire game were a single actor).\nThe actor-based architecture in this gem is in great part inspired by the Erlang language, \nwhich is the most successful actor-oriented language in use and also one of the most \nThe actor-based architecture in this gem is \nImplementing an Actor Engine \nThe first concern of implementing an actor engine is to fulfill the need to support the ability \nof each actor to process its own work individually and concurrently.\nprocess) for each actor.\nErlang does, so we can support thousands of concurrent actors with near linear scalability.\nThe actor \nactors, based on task-processing algorithms.\nprocessing workhorse for the actor engine of this gem.\nat first, allowing messages to be handled out of order is just what Erlang‘s message passing \nThe Message Class \nWith the processing implementation decided, we‘ll quickly look at the messages that will be \nused to allow actors to interact.\nFor this reason, the message type that actors \nThe Actor Class \nIn implementing the actor class, we can divide its functionality into four fundamental \nThe message queue and message processing are the critical core features that are \nwith little overhead, and as such, they are implemented in the base actor class.\nstate and the message handling are the extensible features of the actor, so they are derived \nby subclasses of the base actor class.\nThe Message Queue \nAs one of the core features of the actor class, the message queue is important because it is \nthe only contention point in the actor‘s architecture where several threads may interact on \nthe actor and the scalability of system at large.\nmessage queue is tbb::concurrent_queue.\nallows several actors to add messages to it concurrently, with a relatively low overhead \nHowever, our actors only need a \nthe actor itself.\nperformance of the message queue is to the actor engine.\nActor Hierarchies \nIn this architecture, any number of root actors can be spawned, and all actors are allowed \nhowever, actors within a single hierarchy will likely be processed in closer temporal \nActor construction \nAs seen in Listing 4.13.1, root actors keep circular references to their own TBB processing \nMessage Processing \nThe message processing cycle is the heart of the actor engine, and most of the important \nAs in Erlang, message passing between actors in our design is totally asynchronous.\nbetween actors.\nsynchronous by requiring handshakes, message passing would not be scalable as Erlang‘s \nBy decoupling actor interactions, the message handling can be decomposed into a great \nlinearly as long as actors outnumber the number of processing cores.\nSo unless most message \nhandling is quite heavy, assigning one task per message can become quite wasteful.\nWhen an actor places a message into another actor‘s inbox, the processing thread kick-\nMessage passing \nvoid Actor::inbox(Actor*   sender,   const   MESSAGE_TYPE&  msg) \nvoid Actor::tryProcessing(tbb::task* processing_unit) \nactor will consume the entirety of its message queue, as well as any messages that arrive \nAlso of note is the error handling logic employed for message processing.\nIn an actor-based \narchitecture, when an actor encounters an exception or error it cannot handle, it doesn‘t \nthe actor having problems.\nMessage Handling \nLike actors in Erlang, our actors have a receive method, which can be seen in Listing \nThe receive method is called whenever a message needs handling; the actual \nimplementation of this method is the responsibility of the derived actor classes.\nthis gem is that of a scripted actor, which matches message signatures directly to Lua \nfunctions registered to the actor.\nLua-based actor API \nproxy, not an actual actor reference.\nfunction calls and its arguments into a message that gets sent to the C++ actor.\nLua actor proxies \nmt_actor.__index = function(self,message,...) \nself._class.name,message)) \nreturn send(self) → a C-function connected to the actor \nMessage-Passing Patterns \nWhen working with asynchronous actors and message passing, some issues may appear.\nAt times an actor may need to query the state of another actor, not just send it a message.\nBecause actor message passing is asynchronous, this can be an issue.\ncommonly used by actor-based architectures, is to handle this scenario using a future or \nPromises are implemented by sending along with the message the address of the \nUsing promises to query an actor for state \nSequential Message Processing \nAnother special case that requires consideration because the actor-based system is \nThe typical actor-based \nsolution is to use a sequencer actor that works in conjunction with the door.\nmessage.\nOne more common scenario is that it is possible for an actor to receive a message that, say, \nand went into the details of implementing one viable alternative, based on the actor model \nreference implementation in the form of an actor-based Lua console, along with sample ",
      "keywords": [
        "actor",
        "message",
        "message passing",
        "message queue",
        "TBB",
        "task",
        "message processing",
        "Erlang",
        "processing",
        "Actor Engine",
        "Actor Class",
        "Listing",
        "queue",
        "task scheduler",
        "message handling"
      ],
      "concepts": [
        "message",
        "actors",
        "processing",
        "process",
        "task",
        "based",
        "base",
        "thread",
        "scalable",
        "scalability"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 8",
          "chapter": 1,
          "title": "",
          "score": 0.536,
          "base_score": 0.386,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 46,
          "title": "",
          "score": 0.534,
          "base_score": 0.384,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 47,
          "title": "",
          "score": 0.516,
          "base_score": 0.516,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 31,
          "title": "",
          "score": 0.443,
          "base_score": 0.443,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 36,
          "title": "",
          "score": 0.42,
          "base_score": 0.42,
          "topic_boost": 0.0,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "actor",
          "message",
          "actors",
          "message passing",
          "processing"
        ],
        "semantic": [],
        "merged": [
          "actor",
          "message",
          "actors",
          "message passing",
          "processing"
        ]
      },
      "topic_id": 5,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.20563980448278124,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:05:51.410806+00:00"
      }
    },
    {
      "chapter_number": 46,
      "title": "Segment 46 (pages 434-447)",
      "start_page": 434,
      "end_page": 447,
      "summary": "Social Networks in Games: Playing with Your Facebook Friends \nAsynchronous I/O for Scalable Game Servers \nIntroduction to 3D Streaming Technology in Massively Multiplayer Online Games \nsocializing through online games.\nmultiplayer architecture: security, scalability, social network harvesting, and streaming.\nnetworked gaming environment.\nNext, leveraging social network APIs to obtain player data \nis discussed in the gem ―Social Networks in Games: Playing with Your Facebook Friends.‖ \nThis allows a game developer, with the user‘s permission, to gain access to a player‘s \n―Asynchronous I/O for Scalable Game Servers,‖ deals with the issues of scaling the I/O \nMassively Multiplayer Online Games,‖ was written by Kevin He at Blizzard and includes \nsource code to a terrain streaming application.\nIt is our hope that you will find these gems useful in your own applications and that you will \nThis gem is an overview of creating secure networking protocols.\nOnline games must prevent cheaters from using tools and hacks to their advantage, often \ndenial-of-service attacks, making the game unresponsive for others‘ requests, such as gold, \ngame source code.\nThe main reason game and network security is often broken is that security designers must \nimplementing secure networking protocols.\nnetworking, do play a role in an overall security of game networking by making it harder to \nThe most important decision when designing a gaming networking protocol is to decide how \nnetworking architecture, and code security.\nthe game around these choices.\nMost online games are a client/server architecture, where a central server is the authority \non game state, and clients send player input to and receive game state back from the \nthe server contains the definitive game state, and clients work on approximate and limited \ngame state supports the security principle of least privilege, covered later.\nHence, more security is needed for a triple-A title than for a casual game.\nKernel mode is the security layer that operating system code runs in (for the Windows PC \nand many other protected OSes), and most games run in user mode.\nkernel mode attacks on your code, you need kernel mode services, likely your own driver or \nA game must protect against employee cheating.\neasy it is to cheat online for chess, checkers, Scrabble, and similar games where \nGame design can be exploited.\nFor example, on a game with scoring, \nthe server (or perhaps other clients in a peer-to-peer setting) send snippets of script code \ngame process memory for problems, and so on, returning the answer to the server for \nthe introduction of false positives getting players banned from games.\nAn operating system may ban access to kernel mode code for gaming in the \nthe computer, not just the game process, so code must be extremely well tested before \nplayers should be kept and logged by username, including time online and game stats such \ncheat lists, and evolve the game as cheats evolve.\npreventing cheating in online games.\ninto each topic will make protecting the game much easier by making cheats much harder \nGame creators should monitor common cheat sites, such as \nwww.gamexploits.com, and per-game forums looking for cheats and techniques.\ngames and anti-cheat systems currently ban accounts either temporarily, permanently, or \nHere are two examples of current online game security features.\nTo develop a secure networking protocol for gaming, securing all game assets from code to \nSecuring an online game is a constantly evolving war, and whatever methods are used \nFinally, throughout the game development process, keep a list of security checkpoints and \n―Authentication for Online Games.‖ Games Programming Gems 7 \nSocial Networks in Games: Playing with Your Facebook Friends \nin online games, developers have to understand more about a player‘s ties with people, \nThis gem describes how to access the web services of social networks from your game.\nan example of how this might be put to use, the application developed in this gem will \ndemonstrate how your game can get access to a player‘s friends on Facebook.\nstandalone, desktop-style game as opposed to a game executed in a web browser.\nStandalone applications pose unique challenges because web services are primarily \napplications.\nIn practice, a RESTful service means that you‘ll send HTTP requests to send and receive \nAs an example of accessing data from a social network, consider the following request that \ncURL [cURL09] is a tool that allows you to issue network requests on the command line.\nprevious example sends an HTTP GET request to Twitter‘s servers to retrieve the most \naccess to web services, however, it‘s a good idea to learn how to use cURL because it has \nallows you to send HTTP POST requests and use HTTP‘s basic access authentication \nanyway because of other application requirements.\nPeople are understandably cautious to give applications access to their private data.\npassword, which your application sends to the web service.\ninto your application requires users to trust your application not to collect passwords and \nThis fear might stop users from trying out new applications \nApplications on the web have answered this need by offering authentication mechanisms \nIdentifying Your Application \nApart from authenticating the user on whose behalf your application signs in to the service, \nTwitter, on the other hand, doesn‘t use an application identifier.\nApplication identifiers allow for application-specific configurations on the service provider‘s \nWhen developing my applications, I find it useful to see the data that is sent and received in \nthe requests to a web service.\nHTTP proxies require a system-specific configuration so that the debugged application uses \nrequest to the real server at search.twitter.com and record all data that goes back and forth \nAs an example of how to integrate social networks into your game, this gem demonstrates \nSetting Up a Facebook Application \nBefore starting with your Facebook application, you have to register as a developer with \nDeveloper Application to your profile [Facebook09].\nWithin the Developer Application, you‘ll find a link to set up your own Facebook application.\nFinishing this process will give you an API key that identifies your application when \nexchanging data with Facebook and a configuration page that contains your application‘s \nwhere Facebook pulls the content of your application if you were to display a page within \nMore importantly, you have to switch the Application Type from Web to Desktop.\nchanges the authentication process when accessing Facebook‘s REST server to better suit \ndesktop applications.\nFacebook’s REST Server \nFacebook runs a RESTful service at the URL http://api.facebook.com/restserver.php.\norder to exchange data with this server, you have to send an HTTP POST request with at \nThis is the API key you get when registering your application with \nFor Facebook‘s server to accept a request, you also have to send a signature that identifies \nyour application.\napplication know the secret key, Facebook‘s server can create the same signature and check \nthat the request is indeed coming from your application.\napplication secret that you can look up in your application‘s configuration page on Facebook.\nAuthenticating Facebook Users \nFacebook forbids you to receive user names and passwords directly in your applications.\nInstead, users have to go through Facebook‘s website to log in.\nlikely, but not impossible, that applications will capture and hijack the user‘s password \nObviously, displaying a website for login purposes is easy for web applications.\napplications, on the other hand, you essentially have two choices: You can use the browser \nthat‘s installed on the user‘s system, or you can integrate a web browser, such as WebKit, \ninto your application.\nLoading Facebook‘s login page in a browser separate from your application means that the \nuser has to leave your application until the Facebook login is complete.\nuser returns to your application and confirms the authentication.\nAuthenticating a Facebook user through an external web browser.\nTo start with, your application has to request an authentication token from Face-book.\nsession yet, you use the application secret to sign this request.\nsession for your application.\nFinally, the user returns to your application and confirms the login process, whereupon your \napplication sends an auth.getSession request to Facebook.\nparameters, and the session secret replaces the application secret in subsequent requests.\nlogin process, so you can see exactly what data needs to be sent to Facebook.\nAuthentication with an Application-Integrated Browser \nYou can achieve a better user experience by integrating a browser into your application.\npage is displayed as part of your application.\nAuthenticating a Facebook user through an application-integrated \nuser has successfully logged in to Facebook by checking the URL that‘s currently being \nFor games, however, it might be better to render a web \nBecause the process starts off with Facebook‘s website when using an integrated browser, \nyour application never needs the application secret.\nauthentication process with an external browser because it means the application secret can \nuse these two values again the next time your application needs it.\nrequest to Facebook every time you start the application.\nAlso, if a friend hasn‘t played the game yet, \nyour application could send out invitations to try out the game.\ngame.\nIn this gem, I have shown you how Facebook can provide social context to your game.\nintegrating a player‘s friends network, you can make your games a more personal \nshould provide enough information to extend your games with features from other web \nSend messages to a player‘s Facebook friends to invite them for a game.\n[Charles09] ―Charles: Web Debugging Proxy Application.‖ n.d. Karl von Randow.\n[Facebook09] Website of Facebook‘s developer application.\n<http://www.facebook.com/developers>.",
      "keywords": [
        "Introduction Craig Tiller",
        "Facebook",
        "application",
        "Game",
        "Games Introduction Craig",
        "Craig Tiller",
        "Tiller and Adam",
        "Adam Lake",
        "Facebook Application",
        "Scalable Game Servers",
        "user",
        "Online Games",
        "web",
        "code",
        "Facebook user"
      ],
      "concepts": [
        "games",
        "gaming",
        "application",
        "applications",
        "secure",
        "security",
        "networks",
        "cheating",
        "code",
        "coding"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 8",
          "chapter": 1,
          "title": "",
          "score": 0.661,
          "base_score": 0.511,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 47,
          "title": "",
          "score": 0.569,
          "base_score": 0.569,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 45,
          "title": "",
          "score": 0.534,
          "base_score": 0.384,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 33,
          "title": "",
          "score": 0.327,
          "base_score": 0.327,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 31,
          "title": "",
          "score": 0.305,
          "base_score": 0.305,
          "topic_boost": 0.0,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "application",
          "facebook",
          "web",
          "online",
          "game"
        ],
        "semantic": [],
        "merged": [
          "application",
          "facebook",
          "web",
          "online",
          "game"
        ]
      },
      "topic_id": 5,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.17633667301990724,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:05:51.410850+00:00"
      }
    },
    {
      "chapter_number": 47,
      "title": "Segment 47 (pages 448-460)",
      "start_page": 448,
      "end_page": 460,
      "summary": "Asynchronous I/O for Scalable Game Servers \nnumber of players, the ability to run additional game instances on a single server has \nThis gem explores asynchronous I/O as a technique for improving the scalability of \nmultiplayer game servers.\nfor Windows and POSIX and demonstrate their use in a sample game server.\nwith an analysis of asynchronous I/O and its applicability to building scalable game servers.\nInput/output (I/O) operations have always posed a challenge to game developers and to \nI/O operations are often among the most time \nconsuming and unpredictable functions that game code will use.\nactual I/O systems reside deep in the operating system.\nFurthermore, I/O \nthe real world ripples back up to the application code in the form of failed operations and \nproblem we encounter with I/O operations is that our process sits idle while synchronous \nI/O operations execute.\nBlocking and Non-Blocking Synchronous I/O \nMost standard I/O APIs operate synchronously.\nThey keep us synchronized with the I/O \nsystem by blocking further execution of our code until the current I/O operation is \nI/O, such as an FTP client, these APIs can be perfectly adequate.\nHowever, for real-time games, we generally have a game-world simulation running at 30 to \nSome game architectures may be more event-driven on the server \nI/O.\nThe biggest delay we want to avoid is making blocking I/O requests when the OS is not \nmany CPU cycles polling for I/O readiness.\nA game server must handle multiple connections, and a scalable server must handle many \nperform non-blocking I/O operations for each client in turn.\nRather than polling one socket at a time, an alternative approach is to use an I/O \nof sockets and unblock with a set of sockets ready for I/O, which we can then process \ncode performs I/O with it.\nTo allow the main game loop to execute while I/O operations are being processed and to \ntake advantage of the OS‘s ability to handle many parallel I/O streams, we could introduce \nA more practical approach is to dedicate one thread (or a pool of threads) to I/O operations, \nallowing the main thread to proceed while the new thread deals with the I/O operations.\n(a) Thread per-client versus (b) I/O thread with multiplexing.\nessentially emulates asynchronous I/O—the main thread (or threads) submit I/O requests \nto a queue for the I/O thread, which processes the requests and then notifies the callers of \nAsynchronous I/O uses native OS services to deliver similar functionality without crossing \nthe system call boundary as often and without introducing additional I/O threads.\noptimize I/O.\nAsynchronous I/O APIs \nThe two main APIs for asynchronous I/O are Windows Overlapped I/O and the AIO API in \nAs you would expect, there are also functions for cancelling active I/O operations and for \nThe code accompanying this gem on the CD-ROM includes a sample asynchronous game \nserver implemented with both POSIX AIO and Windows Overlapped I/O.\nsimple game server that runs multiple GameInstance objects, each with a collection of \nFor portability, the server uses synchronous I/O to accept incoming connections.\nAsynchronous I/O server overview.\nexpected amount of data in a single I/O call.\nAfter the game sessions are updated, the server calls GameInstance::update-\nsend regular state updates to the clients at a rate that is less than the game‘s main loop \nI/O spikes caused by all of the sessions updating all of their clients at once.\nvalid for the entire duration of the I/O operations.\nbuffers, and other I/O request-related information and are stored in the SocketImpl \nterms of time spent executing application code) of asynchronous I/O over synchronous \nfast as the server, give synchronous I/O an advantage.\nasynchronous I/O excels.\nTo summarize, the main advantages of asynchronous I/O for game server design are: \nIt eliminates the need for multi-threading to handle I/O.\nIt leverages the OS for tricky subsystems that handle concurrent I/O processing and \nThe main disadvantages of asynchronous I/O are: \nI/O-related code may be harder to understand and debug.\nAsynchronous I/O capabilities can vary across platforms.\nlarger I/O requests when working with asynchronous I/O.\nAsynchronous I/O code can be more difficult to understand, particularly when the \nImplemented using synchronous I/O, the code for this exchange could read almost exactly \nFigure 5.3.3, when implemented using asynchronous I/O, it is necessary to store various \napplicable this is to real-world game servers is highly design-dependent.\nmodel server code, asynchronous I/O actually simplifies the implementation, because the \nand because of the non-deterministic behavior of the I/O notifications.\nmulti-threaded server will contain comparable levels of complexity in both the code and \nThe variability in platforms‘ asynchronous I/O support is a concern for the long-term \nIf we want to port our game server to a new platform, we \nasynchronous I/O.\nAsynchronous I/O is a tool for network programmers to use to improve scalability.\nemulate similar functionality already using threads, so asynchronous I/O can be a \nas a starting point for evaluating the applicability of asynchronous I/O to your project.\nWhether we choose to use it for network I/O or even for other server I/O tasks, such as \nwriting log files, asynchronous I/O can offer significant benefits to the scalability of our \nBy adopting this approach, we can also hope to see asynchronous I/O \nimplementations mature on game server platforms and someday perhaps become the de \nGame streaming will deliver the game world incrementally and on \nSending only the portion of the game world that players are interacting \nAs a result, 3D game streaming will give MMOG \nThis gem will give an introduction to the 3D game streaming technology and its challenges.\nIt will also dive into the key components of a 3D streaming engine, including the renderer, \ntechniques to partition, stream, and re-integrate the 3D world data, including the terrain \nreal implementation of a 3D terrain streaming engine will be provided to serve the purpose \nThis is the fundamental process of 3D game streaming technology.\nunderstand how to stream game content, let‘s quickly review how video is streamed over \nMost of today‘s video streaming clients and servers employ prefetching optimization at \nGame Streaming \nThus, we cannot prefetch 3D content according to the time \ninstead of temporal locality when streaming 3D content.\nAs a result, 3D world streaming \nintegrate them to build a fully functional 3D streaming demo, the 3DStreamer.\nout the code and experiment with it to fully understand how 3D streaming works.\nBefore we can stream a 3D world from an MMO content server to the clients, we have to \nWhat Constitutes a 3D World \nIn this gem we will focus on streaming the artistic content of a 3D world, because artistic \no \no \no \no \no \no \nterrain objects in this gem because they form the foundation of a 3D world streaming \ninto the need of slicing 3D terrain data in a virtual world.\nthe world for streaming, the first step is slicing it into pieces that we can progressively send \n3D world coordinate.",
      "keywords": [
        "Game",
        "game server",
        "server",
        "Asynchronous",
        "code",
        "world",
        "content",
        "asynchronous game server",
        "Game streaming",
        "Streaming",
        "game content",
        "Scalable Game Servers",
        "game code",
        "operations",
        "game world"
      ],
      "concepts": [
        "game",
        "gaming",
        "servers",
        "content",
        "world",
        "code",
        "time",
        "streams",
        "asynchronous",
        "operating"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 8",
          "chapter": 46,
          "title": "",
          "score": 0.569,
          "base_score": 0.569,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 45,
          "title": "",
          "score": 0.516,
          "base_score": 0.516,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 36,
          "title": "",
          "score": 0.498,
          "base_score": 0.498,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 1,
          "title": "",
          "score": 0.412,
          "base_score": 0.412,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 53,
          "title": "",
          "score": 0.41,
          "base_score": 0.41,
          "topic_boost": 0.0,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "asynchronous",
          "server",
          "streaming",
          "game",
          "game server"
        ],
        "semantic": [],
        "merged": [
          "asynchronous",
          "server",
          "streaming",
          "game",
          "game server"
        ]
      },
      "topic_id": null,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.2208428500886139,
        "topic_boost": 0.0,
        "timestamp": "2025-12-17T23:05:51.410893+00:00"
      }
    },
    {
      "chapter_number": 48,
      "title": "Segment 48 (pages 461-471)",
      "start_page": 461,
      "end_page": 471,
      "summary": "Figure5.4.4 shows a few terrain patches rendered by 3DStreamer.\nterrain (32×32 patches) is located between the X-axis (x‘ axis of 2D space) and –Z-axis (y‘ \npatches, tiles, and vertices.\n#define TILES_PER_PATCH_X 32 \n#define TILES_PER_PATCH_Y 32 \n#define PATCHES_PER_TERRAIN_X 32 \n#define PATCHES_PER_TERRAIN_Y 32 \n#define TILES_PER_TERRAIN_X (TILES_PER_PATCH_X * \nPATCHES_PER_TERRAIN_X) \n#define TILES_PER_TERRAIN_Y (TILES_PER_PATCH_Y * \nPATCHES_PER_TERRAIN_Y) \n#define VERTICES_PER_TERRAIN_X (TILES_PER_TERRAIN_X + 1) \n#define VERTICES_PER_TERRAIN_Y (TILES_PER_TERRAIN_Y + 1) \n3DStreamer has a random terrain generator that will generate random terrain data and \nTerrain_y_x.dat: The terrain patch (x,y) \nTerrain_BB.dat: The bounding boxes for all patches \nThe reason that we need Terrain_BB.dat is for collision detection before the patches are \nthe patches is streamed over.\nHere is the process of how to generate random terrain data and deploy it using \n2. Upload the terrain data to an HTTP server (such as Apache).\nand render the terrain incrementally based on a user‘s input.\nthough, you probably won‘t use procedurally generated terrain with streaming because it‘s \nTerrain Mesh \nfor(int  x = patch_x * TILES_PER_PATCH_X, x0 = 0; \nx<= (patch_x+1) * TILES_PER_PATCH_X; \nVERTICES_PER_TERRAIN_X, \nVERTICES_PER_TERRAIN_Y); \nD3DXVECTOR2 colorUV = alphaUV * TILES_PER_TERRAIN_X / \nFor each tile (x,y) of the patch \nterrain textures and alphaUV for sampling the alpha blending values of the terrain \nThe total size of vertex data of our demo terrain is about 40 \nWith the mesh set up for each patch, we‘ll be able to render a wireframe terrain as shown in \ntextures on top of the mesh to represent different terrain features (for example, dirt, grass, \nThree common methods exist for multi-texturing terrain.\nPer-Tile Texturing \n512×512 and then tile them across the terrain.\nmesh of a patch into three subsets, assign each subset a unique texture, and render the \ntexture, thus we‘ll have the shape of the tile show up at the border between different \nAs a result, we will have a tile-wide blending zone between different textures, which \nVERTICES_PER_TERRAIN_Y, \nfor(int x = 0; x < VERTICES_PER_TERRAIN_X; x++) \n// tile->m_type has procedually generated texture types \nThe total size of our terrain‘s alpha-blending data is about 3 bytes * (32 * 32) ^ 2 \nTo create a dynamic 3D terrain, we need to draw shadows of the mountains.\nWe can determine whether a vertex is in shadow by creating a ray from the terrain \nvertex to the light source and test whether the ray intersects with the terrain mesh.\nThe cost of storing the shadow texture of our terrain is not much—only 1 byte * \n(32 * 32) ^ 2 = 1 MB for the entire terrain.\nTerrain Objects \nWithout any objects, the terrain looks boring.\nobjects (stones and trees) to the terrain.\nThe mesh of each terrain object is stored in a .X \nshould stream the model files of terrain objects as well.\nWe need to save the terrain objects‘ placement information with the per-patch terrain \nexample of writing terrain object placement information to the disk for each tile during \nAssuming 20 percent of tiles have objects on them, the disk space taken by terrain objects‘ \nterrain data.\nTerrain mesh \nTerrain object \nstreaming we cannot start rendering the terrain for eight minutes!\nstart rendering the terrain in just a few seconds, and we will continuously stream the terrain \nTo this point we have generated our terrain, partitioned it into patches, and stored the \npatches in Terrain_y_x.dat and the bounding boxes of all the patches in Terrain_BB.dat.\nalso know how to render the terrain based on these patches of data.\nData Source and File Object \nabstraction layer that allows us to source 3D terrain data from both the local disk and a \n// Wait until the file object is loaded \nSchedule a file object to be loaded according to a specified priority.\nWait for a file object to be completely loaded.\nStream data out of the file after it is loaded to memory.\nWhen a file object is downloaded to the client, the render loop calls Read() \nFileObject::Load() virtual method to perform the actual download from the data \nencapsulate details of downloading a file object from the specific data source.\nWhen we request the loading of a file object, such as a terrain patch, the request \nWe only render the patches when they are available and skip the patches not loaded \nOptimize the predictive loading algorithm so that the patches needed for rendering \nTo support asynchronous loading (the first requirement), the render thread only enqueues a \nspecific Load method to download the FileObject from the corresponding data source.\nfunction, when data is read into memory of the client, the FileObject::m_Loaded is \nloaded to the file buffer (p->m_fileObject->m_loaded is TRUE), we call \nPuntPatchToGPU() to fill vertex/index/texture buffers with the data and then render the \nvoid TERRAIN::Render(CAMERA &camera) \nPATCH* p = m_patches[y * m_numPatches.x + x]; \nWith the above multi-priority asynchronous queueing system, we can load patches \nper-patch bounding box data we loaded during startup.",
      "keywords": [
        "terrain",
        "patch",
        "Terrain Objects",
        "terrain data",
        "tile",
        "data",
        "patches",
        "texture",
        "object",
        "File Object",
        "terrain patch",
        "random terrain data",
        "file",
        "render",
        "vertices"
      ],
      "concepts": [
        "terrains",
        "texture",
        "data",
        "loaded",
        "tiles",
        "render",
        "rendering",
        "patch",
        "files",
        "read"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 8",
          "chapter": 49,
          "title": "",
          "score": 0.53,
          "base_score": 0.53,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 5,
          "title": "",
          "score": 0.463,
          "base_score": 0.463,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 24,
          "title": "",
          "score": 0.454,
          "base_score": 0.454,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 11,
          "title": "",
          "score": 0.448,
          "base_score": 0.448,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 7,
          "title": "",
          "score": 0.413,
          "base_score": 0.413,
          "topic_boost": 0.0,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "terrain",
          "patches",
          "patch",
          "file object",
          "tile"
        ],
        "semantic": [],
        "merged": [
          "terrain",
          "patches",
          "patch",
          "file object",
          "tile"
        ]
      },
      "topic_id": null,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.2175005985195177,
        "topic_boost": 0.0,
        "timestamp": "2025-12-17T23:05:51.410943+00:00"
      }
    },
    {
      "chapter_number": 49,
      "title": "Segment 49 (pages 472-480)",
      "start_page": 472,
      "end_page": 480,
      "summary": "patch for collision detection between the avatar and the terrain.\ndownloading each patch.\nloading algorithms accordingly, or we want to use the local hard disk as a data source to \nrelatively low bandwidth cap, there are some patches being downloaded in the four queues, \nincluding one critical patch close to the camera.\nThe predictive loading algorithm is at the heart of a 3D streaming engine because it impacts \nfor faraway terrain patches.) \nWe designed a very simple prefetching algorithm for 3DStreamer following the guidelines.\nSome common camera controls supported by 3D games are: \nimplementation of the predictive loading algorithm, as you can see next.\nWhen do we need a patch of terrain to be loaded?\nways to calculate when the patches are needed in the following sections and compare them.\nWe should preload a patch before it is needed for rendering.\nfrustum is used by the terrain renderer to cull invisible patches, so it‘s natural to preload \nevery patch that falls in the viewing frustum.\nthat there is no patch except the current patch we are standing on in the frustum.\nmean we need to preload nothing except the current patch in this case?\nWhat about the patches immediately to our left \nTo answer the question of when a patch is needed more precisely, we need to define a \nD(p) = distance of patch p to the camera \nIntuitively, the farther away the patch is from the camera, the less likely the avatar will \nThus, we can calculate the distance of each patch to the \navatar and prefetch the ones in the ascending order of their distances.\n(x0, z0) are the coordinates of the center of the patch projected to the XZ plane, and (x1, \ndistance into several ranges and preload the patches in the following order: \nCritical-priority queue: Prefetch D(p) < 1 * size of a patch \nHigh-priority queue: Prefetch D(p) < 2 * size of a patch \nMedium-priority queue: Prefetch D(p) < 4 * size of a patch \nLow-priority queue: Prefetch D(p) < 8 * size of a patch \ncircular bands to different priority queues according to their distance from the camera.\nThe patch immediately in \nfront of the avatar and the patch immediately behind the avatar are treated the same as \nmoving speed than forward moving, thus it‘s unfair to prefetch the patch in front of a \ncamera at the same priority as the patch behind it.\nAn avatar can move from its current location to the destination patch in different ways.\n1. Walk forward one patch and left shift one patch.\n2. Turn left 45 degrees and walk forward 1.4 patch.\n3. Turn right 45 degrees and left-shift 1.4 patch.\n4. Take a portal connected to the patch directly.\n5. Take a mount, turn left 45 degrees, and ride forward 1.4 patch.\nas a distance function, the avatar must walk to the destination on the terrain at a constant \npatch, and they may or may not involve walking on the terrain.\nmeasured by the physical length of the route the avatar takes to get to the patch in some \n1. Assuming forward speed is 0.2 patch/second and left-shift speed is 0.1 \npatch/second, it takes the avatar 5 + 10 = 15 seconds to get there.\nto patch p are: 0.2, 0.6, 0.0 (it‘s kind of brain-dead to do 3), 0.1, and 0.1, respectively.\nThe probability-based distance D(p) will then be given by: 15 * 0.2 + 8 * 0.6 + 10 * 0.1 + \nwhere p(i) is the probability of the avatar taking way i to get to patch p, and t(i) is the time \nSecond, as in most games, 3DStreamer defines the speeds for left/right \nAlpha is the horizontal angle the camera needs to rotate to look at the center of p directly.\n3DStreamer based on the simplified distance function.\nfloat linearTime = distance / camera.Velocity(); \nfloat patchTraverseTime = TILES_PER_PATCH_X / camera.Velocity(); \nIf (patch->m_loaded) \npatch->Unload(); \nelse if (patch->m_fileObject->GetQueue() != \nCancelTerrainPatch(patch); \nFor each frame, we reevaluate the distance function of each patch and move the patch to \nsharp turn and the high-priority patch in front of the avatar suddenly becomes less \nIn an extreme case, a patch earlier in one of the priority queues could be \nUnload the patch and free memory for mesh and terrain objects.\nWith this predictive loading algorithm, 3DStreamer can render a terrain of one million tiles \ntiles/second, we still get enough time to prefetch most nearby patches in the avatar‘s \n1-Mbps bandwidth to the HTTP streaming server.\nThe mini-map shows which patches of the \npriority patches are loaded already, which corresponds to all the nearby patches in the \nviewing frustum plus patches to the side of and behind the player.\npriority queues have 80 patches to download, which are mostly the faraway patches in front \nPredictive loading under 1-Mbps bandwidth at 15 tiles/s.\n3DStreamer is a demo 3D terrain walker that implements most of the concepts and \nRunning the 3DStreamer with the following command will generate a random 32 × 32-patch \nFor HTTP streaming, upload the data (terrain_XX_YY.dat and terrain_BB.dat) to your HTTP \nBy default, 3DStreamer runs in DISK streaming mode with a default data path \nTo run it in HTTP streaming mode, you need to give the -s argument for the host name.\nhttp://192.168.11.11/3dstreamer/32x32, just run it with the following command line: \nIn the process, we defined the distance function–based predictive loading algorithm \nbuild a 3DStreamer demo that streams a large terrain of a million tiles that has multiple ",
      "keywords": [
        "patch",
        "Distance Function",
        "Distance",
        "avatar",
        "predictive loading algorithm",
        "terrain",
        "camera",
        "predictive loading",
        "HTTP streaming",
        "data",
        "function",
        "patches",
        "loading algorithm",
        "queue",
        "prefetch"
      ],
      "concepts": [
        "patch",
        "patches",
        "camera",
        "terrain",
        "distance",
        "streaming",
        "bandwidth",
        "data",
        "float",
        "left"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 8",
          "chapter": 5,
          "title": "",
          "score": 0.615,
          "base_score": 0.465,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 48,
          "title": "",
          "score": 0.53,
          "base_score": 0.53,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 24,
          "title": "",
          "score": 0.529,
          "base_score": 0.379,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 20,
          "title": "",
          "score": 0.396,
          "base_score": 0.246,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 6,
          "title": "",
          "score": 0.359,
          "base_score": 0.359,
          "topic_boost": 0.0,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "patch",
          "avatar",
          "patches",
          "camera",
          "terrain"
        ],
        "semantic": [],
        "merged": [
          "patch",
          "avatar",
          "patches",
          "camera",
          "terrain"
        ]
      },
      "topic_id": 4,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.21316800484090567,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:05:51.410986+00:00"
      }
    },
    {
      "chapter_number": 50,
      "title": "Segment 50 (pages 481-489)",
      "start_page": 481,
      "end_page": 489,
      "summary": "Section 6: Audio \nFor a good deal of its lifetime, advances in game audio have been focused on creating more \naudio processing.\ngreater audio signal processing capabilities in a never-ending goal to create realistic video \ngame sounds.\nthe composer and the sound designer.\nGame audio development, from a programming perspective, has therefore focused on two \nAt the very high level, game audio development was radicalized by the introduction of high-\nlevel authoring tools and matching game audio engines.\nit was clear that one of the largest obstacles to great game audio was the ability for sound \nparty game audio engines.\nIndeed, creating cooler game audio technology was of limited \nComposers and sound designers weren‘t \nAudio Creation Tool) for Xbox and SCREAM for Sony platforms.\ncomposer could use a graphical interface to create game audio content that was then \nplayable by the matching high-level game audio engine.\na way that the composer or sound designer could try, modify, tweak, and otherwise \nlevel audio capabilities, but simply by packaging up the existing technologies into a \nbetter game audio came from programming better tools with better work-flows and better \nNote the UIs created for the sound designer.\nAlso, pay particular attention to the mixing portion; game audio mixing and post-production \nThe emphasis on high-level tools and content-driven audio systems notwithstanding, the \ncutting edge of game programming has no shortage of low-level problems to be solved.\nAudio signal processing down at the sample level still provides many challenges for great \ngame audio.\nAudio DSP in games is sometimes compared to pixel shaders in graphics; in fact, the term \nsystems has greatly lowered the bar for custom-written DSP tailored for a specific audio \nThe DSP effects are sometimes used to take a sound and modify it for a certain \nAudio DSP is also used to process the final output of the audio \nother audio/visual medium to put final polish on the sound.\nIn addition to audio DSP designed to process existing audio data, further low-level audio \neither create audio or drive parameters of a sophisticated audio engine.\nSo there remains no shortage of high-level and low-level challenges for game audio \nBetter tools that enable composers and sound designers to work more \nAnd physical modeling, together with other procedurally generated audio, \nkeynote address, he postulated that, but for a bit more CPU, game audio was ―basically \nimmersive audio.\nSo you carefully place all of the sound effects in the world, making sure \nwhen it‘s far away, it sounds like it‘s coming to you over the airwaves.\neasy solution is to just apply a radio effect offline in your favorite audio editing application.\nBut taking the easy way out in this case is going to double your storage budget for audio, \nsignal sound tinny and distorted, with maybe a little static thrown in for good measure.\nDistortion is the most interesting part of the effect from the programmer‘s point of view.\nneed to go back and change all your sound levels.\nTo understand how we go about making nice-sounding distortion, let‘s start by taking a look \nat why our naïve distortion technique sounds so bad.\nFigure 6.1.4 shows the same sine wave with the gain turned up to 1.1.\nSpectral (frequency) plot of a clipped sine wave with gain = 1.1.\nSpectral (frequency) plot of a clipped sine wave with gain = 11.\ninput sample values versus output values for a hard-clipping algorithm, it would look \nsomething like the graph in Figure 6.1.6, with input values on the X-axis and corresponding \nTransfer function for hard-clipping algorithm.\nHere‘s what we want our function to look like: \n1. The value of the function at x = 0 is 0, and the slope of the function is 1 to begin \n3. At x = 1, the slope of the function is the compression ratio, which we‘ll call r.\nlet‘s start by defining that function: \nThat‘s the function we‘ll run on each input value (x) to get the output value we‘re looking \nparameters so that the function sounds nice for normal-range audio, it starts to behave \nnormal hard-knee compressor function when the input is higher than t + k and ignoring the \ndistortion function completely when the input is less than t.\nBut in the audio domain, where a \nwave‘s frequency content is far more important than its shape, it sounds much better.\nTake a look at the spectrum of our turned-up-to-11 sine wave, once we‘ve run its output \nthrough our new function (see Figure 6.1.10).\nTransfer function with t = 0.2, k = 0.4, r varying from 0.9 to 0.4.",
      "keywords": [
        "Introduction Brian Schmidt",
        "Bodies Introduction Brian",
        "Brian Schmidt",
        "Rigid Bodies Introduction",
        "Brian Schmidt Studios",
        "game audio",
        "Audio",
        "Founder and Executive",
        "Executive Director",
        "Rigid Bodies",
        "game audio engines",
        "game",
        "great game audio",
        "Audio DSP",
        "Xbox audio chip"
      ],
      "concepts": [
        "audio",
        "sound",
        "game",
        "effect",
        "tools",
        "function",
        "gets",
        "getting",
        "level",
        "designer"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 8",
          "chapter": 51,
          "title": "",
          "score": 0.67,
          "base_score": 0.52,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 52,
          "title": "",
          "score": 0.643,
          "base_score": 0.493,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 1,
          "title": "",
          "score": 0.399,
          "base_score": 0.399,
          "topic_boost": 0.0,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "audio",
          "game audio",
          "sound",
          "game",
          "dsp"
        ],
        "semantic": [],
        "merged": [
          "audio",
          "game audio",
          "sound",
          "game",
          "dsp"
        ]
      },
      "topic_id": 7,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.14300620566439826,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:05:51.411027+00:00"
      }
    },
    {
      "chapter_number": 51,
      "title": "Segment 51 (pages 490-498)",
      "start_page": 490,
      "end_page": 498,
      "summary": "So we‘ve got a decent-sounding distortion, but it has one major downside: The quality of \nall dialog samples, so some lines of dialog will sound more distorted than others.\naverage volume of samples to feed into the distortion effect.\nOn the way out of the distortion effect, we want to readjust the volume to where it was \nsound guy will not be happy with you.\nyour sound designer wants, it can be cheaper and more effective just to create your own.\nDrop that down to about –24 dB below the main outputs, and it sounds like a mixture of \ndigital-age sound to it, so I wouldn‘t suggest it for games set much earlier than 1990.\nThe sound has to be \nThis configuration puts the band-pass filter at the end, so that the sound is easier to fit into \nor the only sound playing, you‘ll get a fuller sound by putting the filter directly after the \nOr you can double the filter for that extra-tinny sound.\nThe best part about applying a radio effect in-game, rather than baking it into your audio \nIncrease the distortion AGC’s gain target as the sound source gets further \nThe effect is to add another distance/occlusion cue to the sound.\nbecause it adds motion to the sound in a subtle and non-obvious way.\nThe polynomial waveshaper gives it a unique sound, and the dual AGCs make it easy to \ngiven poor audio, and the best music will sound out of place given poor technology.\naudio engine that drives Halo, from the basic building blocks the sound designers use to the \nThe sound engine starts with the s_sound_source.\nenum e_sound_spatialization_mode \n_sound_spatialization_mode_none, \n_sound_spatialization_mode_absolute, \n_sound_spatialization_mode_relative \nstruct s_sound_source \nThe scale value is used to parameterize data from the game engine to the audio engine.\nEverything that can play a sound in our game exports at least one scale value, if not \nAs a simple example, sounds that get generated from particle impacts receive a scale \nsounds that play when a Banshee banks sharply and forms contrails at the wing.\nAn object function from the Warthog for the engine sound.\nand combines them into a single value that can be sent to the sound system.\nexplore later, we tend to parameterize only a few properties of a sound based on scale, and \nSound Parameterization \nSound content breaks down into one of two categories: impulse sounds and looping \nsounds.\nImpulse Sounds \nFor impulse sounds, such as impacts, gunshots, and footsteps, we allow the audio designers \nFrom the sound source origin to the ―don‘t play distance,‖ the sound is silent.\nplay‖ to ―attack distance,‖ the sound scales from silence to full volume.\ndistance‖ and ―minimum distance,‖ the sound plays at full volume.\ndistance‖ to ―maximum distance,‖ the sound scales from full volume back to silence.\nThe audio designers use the attack distance primarily for sound LODs. You can hear this for \nImpulse sounds can also be parameterized based on the total number of instances of that \nsound playing.\nA lot of glass hitting a concrete floor sounds much different than a little; \nattempting to replicate that sound by playing a lot of the same glass impact sound does not \nFor glass, the sound tag can specify a set of promotion rules \nrule, you can specify which kind of sound to play (for example, few glass pieces, many glass \nUsing the rules from Figure 6.2.5, if we played five glass sounds at once, we would play four \ninstances of the breakable_glasspieces_single sounds.\nWhen the fifth sound \nplayed, we would play a breakable_glass_few sound and stop the previous four \nbreakable_glasspieces_single sounds.\nbreakable_glass_few sounds in the same way (such that they were all playing at \nonce), we would play a breakable_glass_many sound, stop the previous \nplaying a prohibitive number of sounds at once.\nLooping Sounds \nambience) is created using looping sounds.\nBecause looping sounds are dynamic, we allow \nstate transitions, we need just two more bits for playing looping sounds: one bit for whether \ndesigners can specify a sound.\nIn the steady state when a looping sound is playing, we \nsimply keep playing the loop sound.\nduring alternate), those sounds either can be queued up to play after the loop or can play \nLooping sound state diagram.",
      "keywords": [
        "sound",
        "audio",
        "volume",
        "RMS",
        "effect",
        "looping sounds",
        "distortion",
        "play",
        "distortion effect",
        "AGC",
        "Scale",
        "glass",
        "distance",
        "impulse sounds",
        "incoming RMS"
      ],
      "concepts": [
        "sound",
        "values",
        "scale",
        "scaled",
        "audio",
        "parameters",
        "game",
        "float",
        "distance",
        "effect"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 8",
          "chapter": 50,
          "title": "",
          "score": 0.67,
          "base_score": 0.52,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 52,
          "title": "",
          "score": 0.507,
          "base_score": 0.357,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "sound",
          "sounds",
          "play",
          "looping",
          "playing"
        ],
        "semantic": [],
        "merged": [
          "sound",
          "sounds",
          "play",
          "looping",
          "playing"
        ]
      },
      "topic_id": 7,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.08054280559099185,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:05:51.411066+00:00"
      }
    },
    {
      "chapter_number": 52,
      "title": "Segment 52 (pages 499-510)",
      "start_page": 499,
      "end_page": 510,
      "summary": "Vehicle engines are implemented with looping sounds; however, in order to capture more \ncascade system to select different sounds to play based on scale: the pitch range.\nexample, only play this pitch range when the sound is playing from –1200 cents to 1200 \nplaying the sound with a scale-based pitch of 55 cents, the idle pitch range sounds would \nbend to play sounds from that pitch range.\nThe looping sound system has been powerful enough to add novel uses of sound without \n(for example, the sound a boulder makes rolling or sliding down a hill) from Havok by \ngenerating a looping sound at run time whenever we registered an object rolling or sliding; \na scale value, you can easily add either an impulse or a looping sound to whatever it may \ngame engine; everything that should make a sound can make a sound, from weapons firing, \nto objects rolling and bouncing, to the various sounds in the HUD based on in-game events.\nOne daunting aspect of the Halo audio engine is that almost everything makes a sound in \nTo make it easier to manage sound across the entirety of a game, we assign every sound a \nThe properties in the sound class \nwill be applied to all sounds with that sound class by default, so the audio designers only \nhave to tweak a few sounds here and there.\nA non-exhaustive listing of sound classes \nWe also use sound classes to control the mix dynamically at run time.\nFor each sound class, \nwe store an additional attenuation to apply at run time—essentially, a sound class mix.\nambience sound classes to silence with the following script call: \n(sound_class_set_gain \"amb\" 0 0) \nWith the sound_class script commands, \nwe use the string as a sound class substring match, so this script command would affect the \nIf we had a sound class called \na predefined sound class mix.\nWarthog jump into the ship.) Each trigger can specify what looping sound to play, whether \nOnce all the sound is finally in place, \nfinal mix and make sure everything sounds great.\nenvelope to support sound LODs.\nAny programmer who wants to add sound \nto their feature just needs to use the s_sound_source.\nThe trifecta of lots of content, a fully integrated sound engine, and an effective audio \nReal-Time Sound Synthesis for Rigid Bodies \nHowever, without sound induced by these interactions, \nto add realistic sound that corresponds well to some specified interactions (for example, \nSound that is synthesized in real time and based on the ongoing physics simulation can \nIn this gem, we explore an approach to synthesize contact sounds induced by different \ncontent resources in games, such as triangle meshes and normal maps, to generate sound \nfor each arbitrary triangle mesh of any sounding object given as an input, we use a modal \nclassify contact events reported from physics engines and transform them into an impulse \nAs a result, sound that closely corresponds to the visual \nrendering is automatically generated as the audio hardware mixes the impulse responses of \nModal Analysis and Impulse Responses \nIn this section, we give a brief overview on the core sound synthesis processes: modal \nGems 4 [O‘Brien04], and the impulse response to sound calculation (modal synthesis) is \nFigure 6.3.2 shows the pipeline of the sound synthesis module.\nIn pre-processing, a triangle mesh is converted into a spring-mass \nDuring run time, impulses are fed to excite the modal \nbank, and sound is generated as a linear combination of the modes.\nmass representations that are used for sound synthesis.\nThe physical properties of the sounding objects are expressed in the spring \ninformation for approximating the sound of a large plane.\nthe detailed mesh for further sound computation.\ncontinue with sound synthesis–related computation.\ndirectly played out as the synthesized sound.\nΔt, we say that there is an impulse fΔt applied to the object.\nobject to oscillate or changes the way it oscillates; we say that the impulse excites the \nWhenever an impulse acts on an object, we can \nquickly compute the summation of weighted mode shapes of the sounding object at any \nIn conclusion, we can synthesize sound caused by applying impulses on preprocessed 3D \nFrom Physics Engine to Contact Sounds \nHowever, directly applying this information as excitation to a sound \nsynthesis module does not generate good-quality sound.\nscheme that integrates the contact information and data from normal maps to generate \nimpulses that produce sound that closely correlates with visual rendering in games.\nWe can imagine that transient contacts can be easily approximated with single impulses, \nwhile lasting contacts are more difficult to represent with impulses.\nFrom Transient Contacts to Impulses \ncontact sound‘s volume.\nThe direction of the impulse is the same as that of the contact \nFrom Lasting Contacts to Impulses: Using Normal Maps \ncontact reports from common real-time physics engines fall short for directly providing us \nwith the contact forces for simulating the sliding sound.\nmodulated with the contact force, we would not hear continuous sound that corresponds to \nWe generate audio from this commonly used image representation for sound \nNormal maps can add very detailed visual rendering to games, while the underlying \nThis pixel-level information allows us to generate impulses that correspond closely to \nNormal maps are easy to create and exist in almost every 3D game.\nplanes no longer sound flat after we take the normal map information as input to our \nimpulse generation for sound synthesis.\nWe take the normal maps and calculate impulses in the following way.\nImagine an object in sliding contact with another object, whose surface F is shown in Figure \n6.3.4; the contact point traverses the path P within a time step.\nF, the object must also have a time-varying momentum along the normal direction of F, \nimpulse along the normal direction JN that applies on the object is just the change of its \nwhen the object moves from pixel i to pixel j on the normal map.\nimpulses actually model the force applied by the normal variation on the surface of one \nobject to another, generating sound that naturally correlates with the visual appearance of \nagainst another object within one physics simulation time step.\n(c) The impulse along the normal direction can be recovered \nAt the end of each time step, we collect impulses that should have taken place in this time \nfollowing time step by adding them into our impulse queue at the end of this time step.\n// Compute the impulse from the normal map value \nimpulseEvent.impulse = \nimpulses played at different time in one time step.\napproximation of the sound responses to the visual cues.\nWe refer our readers to [Ren10] for more details on contact sound synthesis for normal-\nand sound synthesis modules.\nThe sound synthesis module consists of the modal analysis \nand modal synthesis processes and the interaction handling, which converts a contact event \ninto impulses.\nThe sound synthesis module calculates the mode shapes at audio sampling \nHowever, the impulses generated from normal maps are played back at a ",
      "keywords": [
        "sound",
        "audio",
        "Sound Synthesis",
        "impulse",
        "contact",
        "Equation",
        "time",
        "normal",
        "normal maps",
        "pitch range",
        "pitch",
        "object",
        "sound class",
        "time step",
        "audio engine"
      ],
      "concepts": [
        "sounds",
        "audio",
        "impulse",
        "object",
        "time",
        "contact",
        "game",
        "normal",
        "float",
        "process"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 8",
          "chapter": 50,
          "title": "",
          "score": 0.643,
          "base_score": 0.493,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 51,
          "title": "",
          "score": 0.507,
          "base_score": 0.357,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 27,
          "title": "",
          "score": 0.339,
          "base_score": 0.339,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 13,
          "title": "",
          "score": 0.313,
          "base_score": 0.313,
          "topic_boost": 0.0,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "sound",
          "synthesis",
          "impulse",
          "impulses",
          "sound synthesis"
        ],
        "semantic": [],
        "merged": [
          "sound",
          "synthesis",
          "impulse",
          "impulses",
          "sound synthesis"
        ]
      },
      "topic_id": 7,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.17610493500538965,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:05:51.411106+00:00"
      }
    },
    {
      "chapter_number": 53,
      "title": "Segment 53 (pages 511-519)",
      "start_page": 511,
      "end_page": 519,
      "summary": "[Sreng07] Sreng, J., F.\nAdam Lake, Sr. Graphics Software Architect, Advanced Visual Computing, Intel \nOpenCL contains APIs and a programming model that allows developers to \nOpen Compute Language (OpenCL) [Munshi09] is an open standard for data-and task-\nprogramming on heterogeneous compute platforms.\nIf W and H are the width and height, respectively, the run time is O(W2 \nIn game programming, histograms improve the dynamic range of rendered frames through \nFast on-GPU histogram computation is essential, since the image data \nOpenCL.\nOpenCL is based on the notion of a host API, which consists of a platform and run-time \nlayer and a C-like language (OpenCL C) for programming compute devices; these devices \nmodel, with queues of commands, reading/writing data, and executing kernels for specific \nshare data within what OpenCL calls a context.\nOpenCL host/device architecture.\nThe devices are capable of running data- and task-parallel work; a kernel can be executed \ncontext, allocate memory, create device-specific command queues used to submit work to a \nspecific device, and perform computations.\nGiven these devices and a corresponding context, the application \nCreate programs to run on one or more associated devices.\nCreate kernels within those programs.\nAllocate memory buffers or images, either on the host or on the device(s).\nThe relationship between context(s), device(s), buffer(s), program(s), kernel(s), and \nint a[10] = {1,2,3,4,5,6,7,8,9,10}; \nstd::vector<cl::Device> devices = \ncl::CommandQueue queue(context, devices[0]); \nprogram.build(devices); \ncl::Kernel kernel(program, \"hello\"); \ncl::Buffer inA(context,CL_MEM_READ_ONLY,10 * sizeof(int)); \ncl::Buffer inB(context,CL_MEM_READ_ONLY,10 * sizeof(int)); \nqueue.enqueueReadBuffer(out,CL_TRUE,0,10 * sizeof(int),o); \nfor (int i = 0; i < 10; i++) { \nTips for Optimizing OpenCL C Kernels \nOpenCL kernels.\nConvolution Kernel \nThe OpenCL C kernel for convolution is given below.\nThe output image dimensions are width by height, the input \n__kernel void Convolve(__global float * input, \nsum += filter[idxFtmp+c]*input[idxIntmp+c]; \nint idxOut = yOut * width + xOut; \nFigure 7.1.2 shows the computation time for an output image of size 8192×8192.\nFor a filter width of 2, \nthe input image size is 8193×8193; for a filter of width 32, the input image is 8223×8223.\nComputation time for various filter widths for an 8192×8192 output \nThe following kernel has four iterations of the innermost loop unrolled.\nint c = 0; \nsum += filter[idxFtmp+c] *input[idxIntmp+c]; \nsum += filter[idxFtmp+c+1]*input[idxIntmp+c+1]; \nsum += filter[idxFtmp+c+2]*input[idxIntmp+c+2]; \nsum += filter[idxFtmp+c+3]*input[idxIntmp+c+3]; \nsum += filter[idxFtmp+c1]*input[idxIntmp+c1]; \nFigure 7.1.3 shows the results of the unrolled kernel.\nFor the aforementioned kernels, filter widths were passed as an argument.\nfor (int r = 0; r < FILTER_WIDTH; r++) { \nint idxFtmp = r * FILTER_WIDTH; \nfor (int c = 0; c < FILTER_WIDTH; c++) \nAs the filter width is static, FILTER_WIDTH, it can be defined when building the OpenCL \nprogram.build(devices, options); \ncl::Kernel kernel = cl::Kernel(program, kernelName.c_str()); \nFigure 7.1.4 shows that defining the filter width as an invariant helps the DefConvolve \nkernel sizes.\nUsing the filter width as an invariant in the Convolve and the \nUnroll_If kernels.\nSince the inner loop of the unrolled kernel has four products and four additions, it is \nBut how do we use vectors in an OpenCL kernel?\nvector data type in the kernel.\nThe following kernel body uses the vector type float4.\nNote the additional loop at the end to handle any remaining iterations when filter width is \nsum4.x += filter[idxFtmp+c1]*input[idxIntmp+c1]; \nint idxOut = yOut * width + xOut; \nThe second inner loop can be unrolled (kernel ConvolveFloat4_If), and invariants can \nshows the results for the vectorized kernel.\nDefFloat4 and DefFloat4_If use the filter width as an invariant.\nOptimizing Memory-Bound OpenCL Kernels \nkernels limited by memory performance.",
      "keywords": [
        "int",
        "filter width",
        "filter",
        "kernel",
        "width",
        "OpenCL",
        "Devices",
        "Game Programming Gems",
        "loop",
        "game",
        "input",
        "GPUs",
        "program",
        "context",
        "Game Programming"
      ],
      "concepts": [
        "kernels",
        "programming",
        "programs",
        "computing",
        "compute",
        "computations",
        "devices",
        "context",
        "memory",
        "memories"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 8",
          "chapter": 54,
          "title": "",
          "score": 0.73,
          "base_score": 0.58,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 6,
          "title": "",
          "score": 0.673,
          "base_score": 0.523,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 10,
          "title": "",
          "score": 0.611,
          "base_score": 0.461,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 11,
          "title": "",
          "score": 0.567,
          "base_score": 0.417,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 7,
          "title": "",
          "score": 0.566,
          "base_score": 0.416,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "kernel",
          "filter",
          "opencl",
          "width",
          "int"
        ],
        "semantic": [],
        "merged": [
          "kernel",
          "filter",
          "opencl",
          "width",
          "int"
        ]
      },
      "topic_id": 0,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.24553768520313402,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:05:51.411162+00:00"
      }
    },
    {
      "chapter_number": 54,
      "title": "Segment 54 (pages 520-528)",
      "start_page": 520,
      "end_page": 528,
      "summary": "Number of Work-Groups \nWhen choosing the optimal number of work-items and work-groups, some constraints follow \n__local memory is shared within a single work-group.\ngroups would require costly flushing of __local sub-histograms to __global memory \nTo maximize the use of __local memory, the number of work-groups should be as close \nThe actual number of compute units, typically in the tens per GPU, can be queried at run \nWork-Group Size \nA work-group should be at least as big as the basic hardware unit for scheduling.\nGPUs, a wavefront is a hardware unit of work-items executing concurrently on a given \nOpenCL work-groups are executed as a collection of wavefronts.\nsize cannot be queried via OpenCL—on current high-end AMD GPUs, it is 64 work-items.\nAlso, a total of two wavefronts can be scheduled to run on a single compute unit at a time.\nThis sets an absolute minimum for the total work-item number: Multiply two times the \nwavefront size with the number of work-groups.\nthreads is given by the maximum work-group size times the chosen number of work-\nThe maximum work-group size can be queried using: \nclGetDeviceInfo( ..., CL_DEVICE_MAX_WORK_GROUP_SIZE, ...\nregisters, the size of the __local buffer, and the number of instructions.\nparameters influence how the kernel is scheduled on the GPU at run time.\nknobs include the number of groups, the group size, and the number of work-items.\n__global Read/Write Access Patterns \nis the read bandwidth from __global memory, as the input image originates from there.\neach work-item‘s read pattern to that which is best supported by the GPU or CPU.\nThe CPU/GPU memory subsystem and the compiler tool chain are optimized for 128-bit \nwork-items read adjacent 128-bit quantities, so that these can be combined to larger \nThis leads to the following access pattern: Each thread reads unsigned integer quantities \npacked into four-wide vectors (uint4) quantities, starting at its global work-item index and \nwork-item number of NT, the resulting pattern is: \nAs many of the work-items execute this step at the same time, it results in a large number \nHere, NI is the number of uint4 items per thread: \nitems with large numbers of NI.\nEach work-item reads sequentially through its own portion \na rule of thumb, it is desirable to use per-thread column-major access on the GPU and per-\noverall number of uint4 elements in the input buffer, divided by the number of threads: \n__kernel void singleBinHistogram (__global uint4 *Image, \n__global uint *Histogram, \nuint nWItems = get_global_size(0); \nuint i, idx; uint bin = 0; \nWhen executed with at least 8192 work-items and a work-group size of 64, this kernel \nBandwidth per number of work-items.\n__global memory, as in the following code example, scatter turns out to be a bottleneck.\n__kernel void multiBinHistogram ( __global uint4 *Image, \n__global uint *Histogram, \nuint nWItems = get_global_size(0); \nuint i, idx; \nHistogram[ id * NBINS + Image[idx].x ]++; \nHistogram[ id * NBINS + Image[idx].y ]++; \nHistogram[ id * NBINS + Image[idx].z ]++; \nHistogram[ id * NBINS + Image[idx].w ]++; \nOptimizing __local Memory Access \nThis memory is available to all work-items in a work-group, and its lifetime is that \nIt supports a large number of concurrent data paths: one for each compute unit and \nThe __local memory size per work-group (and by extension, per compute unit) is given \nclGetDeviceInfo( ..., CL_DEVICE_LOCAL_MEM_SIZE, ...\nThis gives a total __local size per GPU device as CL_MAX_COMPUTE_UNITS * \nCL_DEVICE_LOCAL_MEM_SIZE.\nsub-histogram instance per __local memory and to let all threads in that group \n__kernel void histogramLocal( __global uint4 *Image, \n__global uint *Histogram, \n__local uint *subhists, \nuint nWItems = get_global_size(0); \nThe resulting simultaneous atomic read-modify-write access by many threads \nlocal work-item ID to steer simultaneous writes to the same logical bin, but into separate \n// subhists is of size: (number of histogram bins) * NBANKS \n__kernel void histogramKernel( __global uint4 *Image, \n__global uint *Histogram, \n__local uint *subhists, \nuint ltid = get_local_id(0); \nuint nWItems = get_global_size(0); \nPhysX GPU Rigid Bodies in Batman: Arkham Asylum \nFor GPU acceleration of cloth and fluids, we were able to use NVIDIA PhysX, which already \ndeveloped a GPU rigid body engine (GRB) implementing the subset of PhysX features we \nBatman made use of NVIDIA‘s APEX destruction module to author and simulate destructible \nbreaks, with APEX doing the dirty work of creating, splitting, and destroying PhysX rigid \nengine to accelerate the subset of PhysX rigid body features used by APEX destruction.\nThe system must be designed to use thousands of GPU threads to get \nThe game will use PhysX (CPU) rigid bodies for game-play \nBatman uses a single scene for the whole game and streams in adjacent ",
      "keywords": [
        "local memory",
        "GPU",
        "Number",
        "local",
        "uint",
        "idx",
        "AMD GPUs",
        "global",
        "memory",
        "size",
        "image",
        "histogram",
        "compute unit",
        "global memory",
        "thread"
      ],
      "concepts": [
        "threads",
        "histogram",
        "performance",
        "performed",
        "work",
        "scatter",
        "destruction",
        "destructible",
        "memory",
        "large"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 8",
          "chapter": 53,
          "title": "",
          "score": 0.73,
          "base_score": 0.58,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 7,
          "title": "",
          "score": 0.653,
          "base_score": 0.503,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 10,
          "title": "",
          "score": 0.636,
          "base_score": 0.486,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 6,
          "title": "",
          "score": 0.622,
          "base_score": 0.472,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 36,
          "title": "",
          "score": 0.598,
          "base_score": 0.448,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "uint",
          "work",
          "__global",
          "__local",
          "histogram"
        ],
        "semantic": [],
        "merged": [
          "uint",
          "work",
          "__global",
          "__local",
          "histogram"
        ]
      },
      "topic_id": 0,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.22833710471956736,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:05:51.411206+00:00"
      }
    },
    {
      "chapter_number": 55,
      "title": "Segment 55 (pages 529-536)",
      "start_page": 529,
      "end_page": 536,
      "summary": "shapes in Batman are represented by voxel-generated spheres in GRB.\nAlthough spheres \nIn this method, spring and damper forces are applied at contact points \nmany threads as contacts.\nconstraints are fed into a constraint solver, which iteratively finds a new set of velocities for \nthe bodies.\nIts goal is to find velocities that won‘t move the bodies into penetration (violate \nmethod has the additional complexity of parallelizing a constraint solver.\nTransform spheres into world space using body transformation matrices.\nFind sphere-sphere overlaps, producing contacts.\nFind sphere-mesh overlaps, producing contacts.\nUpdate body velocities by applying force fields and gravity.\nGenerate constraints from contacts.\nSolve constraints producing modified velocities and position corrections.\nThe spheres are rigidly attached to the rigid body reference frame.\nparticle with position r belonging to a rigid body with transformation matrix M, we calculate \nThe dynamic objects are represented by grids of spheres, so we use sphere-sphere tests to \nto test for sphere-triangle contact.\ncontact in this case helps avoid the situation where some of a body‘s spheres are trapped \nGiven sphere center ps, triangle vertices (v0, v1, v2), and triangle normal nt, \nthe sphere center is behind the triangle if: \nIf a sphere and triangle survive this test, then we next need to calculate world coordinates \npt of the closest point on the triangle to the center of the sphere ps.\nWe generate a contact for a sphere and triangle if |ps – pt| ≤ ζ.\nThe contact normal, position, and separation are given by the following: \nIn the case that the sphere center is on the triangle |ps – pt| ≤ ε, we set the contact normal \nFor a body with velocity v, we step the acceleration due to force fields af and gravity ag \nEach body‘s inertia matrix I is calculated in its local frame, so we need to transform it to the \nGenerate Constraints \nFor each contact, the constraint solver needs a coordinate frame [b0 b1 b2] in which to \napply the constraint forces.\ncontact relative to the center of masses of body a and body b be ra and rb, their final \nEach non-penetration constraint has the following form, known as the velocity Signorini \nHere, v0 is the component of relative velocity of the two bodies at the contact point along \nthe contact normal, and f0 is the magnitude of the impulse calculated by the constraint \nsolver to satisfy the constraint.\nAdditionally, if the bodies are separating, then the solver must not apply any \nimpulse; and if the bodies are resting, then the solver must apply a non-adhesive impulse.\nThe task of the solver is as follows: Given a set of bodies with unconstrained velocities v* \nand a set of constraints, find impulses to apply to the bodies such that the resulting \nvelocities will (approximately) satisfy the constraints.\nApply impulse to update the velocities of the constrained bodies \nCalculate Impulse Required to Prevent Relative Motion Along Constraint Direction i \nby constraint i, and ra and rb, the position of the contact in the frames of body a and body \nb, the relative velocity along the constraint direction bi is given by the following: \nIn other words, vrel is the velocity of the contact point on body a minus the velocity of the \ncontact point on body b projected onto the direction bi.\neffective mass ai to get fd, the additional impulse required to satisfy the constraint in \nApply Impulse to Update the Velocities of the Constrained Bodies \nWe now apply the clamped impulse to the two bodies involved in the constraint.\nThe solver calculates a new velocity for each body.\nTo apply velocity (vlin, vang) to a body \nexcept for force field calculation to the GPU.\nThe stages in the first category are transform particles, find sphere-sphere contacts, \nfind sphere-mesh contacts, update velocities, generate constraints, and update body \nfinding nearby particles; and in the sphere-triangle stage, each thread looks at nearby \nof contacts per thread.\nWe used four contacts per sphere in Batman.\nThe only pipeline stage that is not easily parallelized is the constraint solver, and that will be \nspheres, we use voxelization to generate an approximate sphere representation of the \nsphere.\nOne issue was that the original voxelizer would sometimes generate overlapping spheres for \nnearby spheres and triangles.\nSo for each sphere, we can find \nreason for this is that each constraint reads and writes the velocities of two bodies, and \neach body can be affected by more than one constraint.\nEach body is affected by two constraints, except for \nthe top body.\nIf the constraints were executed in parallel by separate threads, then each \nvelocity of each body would depend on the exact order in which the constraints accessed \nthe body, and the effect of one constraint would not be taken into account in the calculation \neach batch, all bodies are modified by just one constraint.\nin sequence, using one thread for each constraint in each batch.\ndoesn‘t modify either body, so the constraint can be processed in this batch.\natomic set fails (because another thread has allocated the body to the batch in the \nbodies are run on the CPU, and when the level is run with GRB, the game-play bodies are \nnot simulated on the GPU in either PhysX or GRB, the force field calculation is excluded in \nGRB physics frame time (1,600 bodies) \nPhysX physics frame time (1,600 bodies) 49.5ms ",
      "keywords": [
        "constraint",
        "body",
        "spheres",
        "GRB",
        "GPU",
        "constraint solver",
        "contact",
        "bodies",
        "triangle",
        "impulse",
        "solver",
        "friction constraint",
        "velocities",
        "contact normal",
        "force fields"
      ],
      "concepts": [
        "sphere",
        "constraint",
        "bodies",
        "velocities",
        "velocity",
        "contact",
        "triangle",
        "solver",
        "position",
        "positions"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 8",
          "chapter": 12,
          "title": "",
          "score": 0.658,
          "base_score": 0.508,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 17,
          "title": "",
          "score": 0.601,
          "base_score": 0.451,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 19,
          "title": "",
          "score": 0.54,
          "base_score": 0.39,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 16,
          "title": "",
          "score": 0.506,
          "base_score": 0.356,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 18,
          "title": "",
          "score": 0.451,
          "base_score": 0.301,
          "topic_boost": 0.15,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "constraint",
          "sphere",
          "body",
          "bodies",
          "contact"
        ],
        "semantic": [],
        "merged": [
          "constraint",
          "sphere",
          "body",
          "bodies",
          "contact"
        ]
      },
      "topic_id": 2,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.18205320623970847,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:05:51.411248+00:00"
      }
    },
    {
      "chapter_number": 56,
      "title": "Segment 56 (pages 537-549)",
      "start_page": 537,
      "end_page": 549,
      "summary": "―CUDA Particles.‖ NVIDIA Corporation.\nSimulating fluids and particles on the GPU \nenables games to incorporate complex fluids and particle effects with tens of thousands of \nCPU to accelerate physically based simulation of particle systems, fluids, cloth, and rigid \nIn this gem, we present the algorithms and implementation details for the particle and fluid \nReal-time GPU-accelerated Smoothed Particle Hydrodynamics (SPH) \nThere are more than 60,000 particles in the simulation.\nParticle Systems \nParticles can \nParticle effects in games \nparticles in a way that doesn‘t require any intersection tests or collision detection.\ngaseous and liquid fluids by adding support for particle-particle interactions to its particle \nPhysX fluid simulation is built on top of the particle system component, sharing the same \nLike particle systems, fluid motion \nis not practically limited to a box domain; particles and fluids can spread throughout a game \nRobust Particle Collisions \nPhysX particles are allowed to interact with arbitrary triangle meshes in a game scene, and \ntherefore we need an algorithm that can robustly handle particle collisions with these \nRight: Particles don’t fall through static meshes when pushed by dynamic objects.\nto the distance a fast particle travels per time step.) \nParticles on thin static objects cannot be pushed through by dynamic objects \nThe PhysX particle collision algorithm is based on a mixed approach that makes use of both \nRight: A discrete collision detection test between a particle and geometry.\nThe linear path of the particle motion is tested for intersection with any dynamic or static \nEach particle‘s original position p is transformed into the \nPractically, this means that a particle-\nIn addition to the continuous collision test, the sphere defined by the target particle position \nBoth results are combined to calculate an appropriate collision response for the particle.\nThe collision algorithm must gracefully handle cases in which particles could get trapped \nParticles are often continuously pushed against scene geometry by gravity or fluid forces.\ncontinuous collision detection will prevent a particle from sliding along object boundaries.\nthe time step is reached and the final position of the particle is found.\nFor a particle in a \nthe surfaces a particle collided with in the previous time step and uses them in the current \ntime step to correct the particle velocity in a pre-process to collision detection.\nFluid Simulation with Smoothed Particle Hydrodynamics \nexample, by using particles.\nIn PhysX, using particles has several advantages.\nParticles enable seamless collisions with static geometry and rigid bodies with no \nparticle.\nThe approach we use in PhysX is called Smoothed Particle Hydrodynamics (SPH), which is a \nThe mass of each particle is constant over time.\nkernel functions are used to reconstruct smooth fields from the discrete particle samples, \nhence the name Smoothed Particle Hydrodynamics.\nfunctions at each nearby particle are summed up, as shown in Figure 7.3.5.\noverlapping kernels for each particle.\nTo compute the acceleration on each particle in the fluid, we need to evaluate Equation (1) \nat the particle position by summing up the kernel contributions from all overlapping \nparticles.\nposition of the particle over the time step.\nupdate the particle velocity.\nThe particle collision phase uses the output of the broad phase \nFinally, the positions of all particles are \nParticle Bounds Generation and the Broad Phase \nTo support efficient collision detection between particles and static geometry and rigid \nbodies present in the scene, we need to avoid testing all possible particle-object pairs for \nThe particle collision algorithm uses the output of the broad \nphase, a set of pairs of overlapping particle groups and scene objects, to find the \nintersections of individual particles with scene objects.\nThe SPH phase computes the density and force at each particle position xi.\ncomputation evaluates the influence of all other particles in a neighborhood around xi.\norder to find neighboring particles efficiently, we use a hashed regular grid to accelerate \nindex for each particle such that all particles in the same grid cell have the same hash \nThe second step sorts all particle data by hash index so that the data for all particles \nTo compute the hash index, each particle position (x, y, z) is discretized onto a virtual (and \nThe hash values for each particle are computed in a CUDA C kernel that outputs an array of \nhash indices and an array of corresponding particle indices.\nparticle in the cell, to enable constant-time queries of the particles in each hash cell.\nthe key-index pairs are sorted, we use the sorted indices to reorder the particle position and \nit directly (in other words, by appending each particle to a list for each grid cell) in parallel, \nWe simply process the particles of all fluids \nThen when we sort the particles, they will be sorted first by fluid ID and then by hash index.\nNaturally, in a widely dispersed fluid, particles \nIf many non-interacting particles hash to \nOnce the hashed grid is built, it can be used to quickly find all particles near to each \nparticle.\nThus, we can evaluate the density and force by finding the cell each particle resides \nhash table lookup to find the list of particles in each cell.\nUsing these particles, we can \ncompute the sum of the influences of each neighboring particle, as shown in Listing 7.3.2.\nPseudocode for evaluating a smoothing kernel at a particle’s position \nparticles = hashTableLookup(hash(gridPosition)) \nto compute the particle hash, the density, and the force at each particle, plus a radix sort, \nkernel that finds the starting and ending indices of particles in each cell and reorders the \nparticle position and velocity arrays using the sorted indices.\nThe particle hash kernel simply computes the hash index for each particle given its 3D \nparticles in the scene and compute one hash per thread.\nAfter sorting the particles by hash \nindex using the radix sort, we launch another kernel, again with one thread per particle, to \nreorder the particle position and velocity arrays.\nThis kernel also compares each particle‘s \nindex before it, then we know this is the first particle in a cell, so we store this particle‘s \nThe density and force kernels also process one particle per thread.\nin [Müller03] as its support function to compute a scalar density per particle.\nthe cell start and cell end arrays to get a range of particle indices to read from the sorted \nparticle position and velocity arrays.\npack together the data for all active particle systems or fluids into large batches so that the \nCUDA kernels can process all particles at once.\narrays of structures for the particle data.\nparticle structures containing particle position, velocity, and other data, we have an array of \nall particle positions, an array of all velocities, and so on.\nParticle Collision Phase \nThe collision phase uses the particle positions and updated velocities from the SPH phase \nCUDA thread per particle.\nmultiple particle systems together in one batch.\nstep for each particle, if available.\nFrom the current particle position and velocity, we \nThen, for each loaded batch, each thread tests one particle for intersection with all shapes \nthere are more triangles than particles in the spatial group.\nparticle, it is more efficient to parallelize across triangles (in other words, run one thread \nFor each triangle, all particles are \nCollision Response and Particle Update \nAfter the dynamic shape collision detection, a CUDA kernel computes a collision response \nfrom the aggregated surface contact information and updates particle target positions \nexecuted again, providing the final particle position.\nDisplaying materials in games that are represented as particles requires very different \nGaseous fluids are typically displayed using a billboard per particle and various blending \nRendering liquids based on particle simulation is \ndiscrete particles.\nWe measured the performance of the PhysX particle fluid demo shown in Figure 7.3.1 and \nparticles.\nThis can be improved by moving all of the per-particle \nSPH, the summation passes over particle neighbors that compute density and force take \n―Particles.‖ and ―Smoke Particles.‖ n.d. NVIDIA CUDA SDK version 2.3.",
      "keywords": [
        "particle",
        "Collision Detection",
        "Collision",
        "particle position",
        "NVIDIA CUDA SDK",
        "CUDA",
        "Johnny Costello",
        "James Dolan",
        "Dane Johnston",
        "Johnston and Johnny",
        "particle collision phase",
        "particle collision algorithm",
        "Smoothed Particle Hydrodynamics",
        "particle collision",
        "Fluid"
      ],
      "concepts": [
        "particles",
        "fluid",
        "collision",
        "collisions",
        "kernel",
        "grid",
        "computing",
        "compute",
        "computations",
        "time"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 8",
          "chapter": 1,
          "title": "",
          "score": 0.406,
          "base_score": 0.406,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 55,
          "title": "",
          "score": 0.372,
          "base_score": 0.372,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 15,
          "title": "",
          "score": 0.358,
          "base_score": 0.358,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 24,
          "title": "",
          "score": 0.344,
          "base_score": 0.344,
          "topic_boost": 0.0,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 53,
          "title": "",
          "score": 0.34,
          "base_score": 0.34,
          "topic_boost": 0.0,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "particle",
          "particles",
          "hash",
          "collision",
          "particle position"
        ],
        "semantic": [],
        "merged": [
          "particle",
          "particles",
          "hash",
          "collision",
          "particle position"
        ]
      },
      "topic_id": null,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.20113556582154418,
        "topic_boost": 0.0,
        "timestamp": "2025-12-17T23:05:51.411288+00:00"
      }
    },
    {
      "chapter_number": 57,
      "title": "Segment 57 (pages 550-557)",
      "start_page": 550,
      "end_page": 557,
      "summary": "Color Plate 2: Comparison of large- versus small-area SSAO samples from Gem 1.2.\nColor Plate 3: Output of rendering stages and final image from the deferred rendering \nColor Plate 4: The deferred shading technique presented in Gem 1.2 has three steps: \npresented in Gem 1.8.\nColor Plates 9 and 10: From Gem 3.4, examples of characters in World of Zoo’s (WOZ’s) \nColor Plate 11: Example output from Gem 4.8 demonstrating an approach to testing code \nGem 7.2.\nGaussian blur (left) and curvature flow (right) from Gem 7.3.",
      "keywords": [
        "Color Plate",
        "versus small-area SSAO",
        "small-area SSAO samples",
        "Gem",
        "Plate",
        "Color",
        "Comparison of large",
        "SSAO samples",
        "higher-contrast SSAO samples",
        "SSAO samples apparent",
        "small-area SSAO",
        "presented in Gem",
        "SSAO",
        "low-contrast SSAO sampling",
        "SSAO sampling component"
      ],
      "concepts": [
        "plate",
        "rendering",
        "color",
        "surface",
        "gem",
        "technique",
        "right",
        "space",
        "images",
        "sampling"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 8",
          "chapter": 4,
          "title": "",
          "score": 0.717,
          "base_score": 0.567,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 8,
          "title": "",
          "score": 0.533,
          "base_score": 0.383,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 2,
          "title": "",
          "score": 0.506,
          "base_score": 0.356,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 3,
          "title": "",
          "score": 0.446,
          "base_score": 0.296,
          "topic_boost": 0.15,
          "method": "sbert"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 6,
          "title": "",
          "score": 0.394,
          "base_score": 0.394,
          "topic_boost": 0.0,
          "method": "sbert"
        }
      ],
      "enriched_keywords": {
        "tfidf": [
          "ssao",
          "color",
          "plate",
          "color plate",
          "ssao samples"
        ],
        "semantic": [],
        "merged": [
          "ssao",
          "color",
          "plate",
          "color plate",
          "ssao samples"
        ]
      },
      "topic_id": 3,
      "chapter_provenance": {
        "methods_used": [
          "sbert",
          "tfidf",
          "bertopic"
        ],
        "sbert_score": 0.17332708109661504,
        "topic_boost": 0.15,
        "timestamp": "2025-12-17T23:05:51.411755+00:00"
      }
    }
  ],
  "total_chapters": 57,
  "enrichment_provenance": {
    "taxonomy_id": "none",
    "taxonomy_version": "none",
    "taxonomy_path": "none",
    "taxonomy_checksum": "sha256:none",
    "source_metadata_file": "Game Programming Gems 8_metadata.json",
    "enrichment_date": "2025-12-17T23:05:51.422239+00:00",
    "enrichment_method": "msep",
    "model_version": "ai-agents-msep-v1",
    "processing_time_ms": 4600.851752000381,
    "total_similar_chapters": 264
  }
}