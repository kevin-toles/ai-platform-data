{
  "metadata": {
    "title": "Game Programming Gems 2",
    "author": "Unknown Author",
    "publisher": "Unknown Publisher",
    "edition": "1st Edition",
    "isbn": "",
    "total_pages": 551,
    "conversion_date": "2025-11-23T10:57:05.784757",
    "conversion_method": "PyMuPDF + OCR fallback",
    "source_pdf": "Game Programming Gems 2.pdf"
  },
  "chapters": [
    {
      "number": 1,
      "title": "Segment 1 (pages 1-8)",
      "start_page": 1,
      "end_page": 8,
      "detection_method": "topic_boundary",
      "content": "GameGems II\nConverted by Borz\nborzpro @yahoo .com\n2002.12.01\n\n\nOptimization for C++ Games\nAndrew Kirmse, LucasArts Entertainment\nark@alum.mit.edu\nW\nell-written C++ games are often more maintainable and reusable than their\nplain C counterparts are—but is it worth it? Can complex C++ programs hope\nto match traditional C programs in speed?\nWith a good compiler and thorough knowledge of the language, it is indeed pos-\nsible to create efficient games in C++. This gem describes techniques you can use to\nspeed up games in particular. It assumes that you're already convinced of the benefits\nof using C++, and that you're familiar with the general principles of optimization (see\nFurther Investigations for these).\nOne general principle that merits repeating is the absolute importance of profil-\ning. In the absence of profiling, programmers tend to make two types of mistakes.\nFirst, they optimize the wrong code. The great majority of a program is not perfor-\nmance critical, so any time spent speeding it up is wasted. Intuition about which code\nis performance critical is untrustworthy—only by direct measurement can you be\nsure. Second, programmers sometimes make \"optimizations\" that actually slow down\nthe code. This is particularly a problem in C++, where a deceptively simple line can\nactually generate a significant amount of machine code. Examine your compiler's out-\nput, and profile often.\nObject Construction and Destruction\nThe creation and destruction of objects is a central concept in C++, and is the main\narea where the compiler generates code \"behind your back.\" Poorly designed pro-\ngrams can spend substantial time calling constructors, copying objects, and generat-\ning costly temporary objects. Fortunately, common sense and a few simple rules can\nmake object-heavy code run within a hair's breadth of the speed of C.\n• Delay construction of objects until they're needed.\nThe fastest code is that which never runs; why create an object if you're not\ngoing to use it? Thus, in the following code:\nvoid Function(int arg)\n5\nG\n1.1\nm \n\"'\n\n\nSection 1 General Programming\nObject obj;\nif (arg *= 0)\nreturn;\neven when arg is zero, we pay the cost of calling Object's constructor and destruc-\ntor. If arg is often zero, and especially if Object itself allocates memory, this waste\ncan add up in a hurry. The solution, of course, is to move the declaration of obj\nuntil after the //check.\nBe careful about declaring nontrivial objects in loops, however. If you delay con-\nstruction of an object until it's needed in a loop, you'll pay for the construction\nand destruction of the object on every iteration. It's better to declare the object\nbefore the loop and pay these costs only once. If a function is called inside an\ninner loop, and the function creates an object on the stack, you could instead cre-\nate the object outside the loop and pass it by reference to the function.\nUse initializer lists.\nConsider the following class:\nclass Vehicle\n{\npublic:\nVehicle(const std::string &name) // Don't do this!\n{\nmName = name;\n}\nprivate:\nstd: : string mName;\nBecause member variables are constructed before the body of the constructor is\ninvoked, this code calls the constructor for the string mName, and then calls the\n= operator to copy in the object's name. What's particularly bad about this exam-\nple is that the default constructor for string may well allocate memory — in fact,\nmore memory than may be necessary to hold the actual name assigned to the\nvariable in the constructor for Vehicle. The following code is much better, and\navoids the call to operator =. Further, given more information (in this case, the\nactual string to be stored), the nondefault string constructor can often be more\nefficient, and the compiler may be able to optimize away the Vehicle constructor\ninvocation when the body is empty:\nclass Vehicle\n{\npublic:\nVehicle(const std::string &name) : mName(name)\n{\n}\nprivate:\n\n\n1.1 Optimization for C++ Games\nstd::string mName;\nPrefer preincrement to postincrement.\nThe problem with writing x = y++ is that the increment function has to make a\ncopy of the original value of y, increment y, and then return the original value.\nThus, postincrement involves the construction of a temporary object, while\npreincrement doesn't. For integers, there's no additional overhead, but for user-\ndefined types, this is wasteful. You should use preincrement whenever you have\nthe option. You almost always have the option in for loop iterators.\nAvoid operators that return by value.\nThe canonical way to write vector addition in C++ is this:\nVector operator+(const Vector &v1, const Vector &v2)\nThis operator must return a new Vector object, and furthermore, it must return\nit by value. While this allows useful and readable expressions like v = v 1 + z>2, the\ncost of a temporary construction and a Vector copy is usually too much for some-\nthing called as often as vector addition. It's sometimes possible to arrange code so\nthat the compiler is able to optimize away the temporary object (this is known\nas the \"return value optimization\"), but in general, it's better to swallow your\npride and write the slightly uglier, but usually faster:\nvoid Vector::Add(const Vector &v1, const Vector &v2)\nNote that operator+= doesn't suffer from the same problem, as it modifies its\nfirst argument in place, and doesn't need to return a temporary. Thus, you should\nuse operators like += instead of + when possible.\nUse lightweight constructors.\nShould the constructor for the Vector class in the previous example initialize its\nelements to zero? This may come in handy in a few spots in your code, but it\nforces every caller to pay the price of the initialization, whether they use it or not.\nIn particular, temporary vectors and member variables will implicitly incur the\nextra cost.\nA good compiler may well optimize away some of the extra code, but why take\nthe chance? As a general rule, you want an object's constructor to initialize each of\nits member variables, because uninitialized data can lead to subtle bugs. However,\nin small classes that are frequently instantiated, especially as temporaries, you\nshould be prepared to compromise this rule for performance. Prime candidates in\nmany games are the Vector and Matrix classes. These classes should provide medi-\nods (or alternate constructors) to set themselves to zero and the identity, respec-\ntively, but the default constructor should be empty.\n\n\nSection 1 General Programming\nAs a corollary to this principle, you should provide additional constructors to\nclasses where this will improve performance. If the Vehicle class in our second\nexample were instead written like this:\nclass Vehicle\n{ \n.\npublic:\nVehicle ()\nvoid SetName(const std: :string &name)\n{\nmName = name;\nprivate:\nstd: : string mName;\nwe'd incur the cost of constructing mName, and then setting it again later via Set-\nName(). Similarly, it's cheaper to use copy constructors than to construct an\nobject and then call operator=. Prefer constructing an object this way — Vehicle\nvl(v2) — to this way — Vehicle vl; vl = v2;.\nIf you want to prevent the compiler from automatically copying an object for\nyou, declare a private copy constructor and operator= for the object's class, but\ndon't implement either function. Any attempt to copy the object will then result\nin a compile-time error. Also get into the habit of declaring single-argument con-\nstructors as explicit, unless you mean to use them as type conversions. This pre-\nvents the compiler from generating hidden temporary objects when converting\ntypes.\nPreallocate and cache objects.\nA game will typically have a few classes that it allocates and frees frequently, such\nas weapons or particles. In a C game, you'd typically allocate a big array up front\nand use them as necessary. With a little planning, you can do the same thing in\nC++. The idea is that instead of continually constructing and destructing objects,\nyou request new ones and return old ones to a cache. The cache can be imple-\nmented as a template, so that it works for any class, provided that the class has a\ndefault constructor. Code for a sample cache class template is on the accompany-\ning CD.\nYou can either allocate objects to fill the cache as you need them, or preallocate\nall of the objects up front. If, in addition, you maintain a stack discipline on the\nobjects (meaning that before you delete object X, you first delete all objects allo-\ncated after X), you can allocate the cache in a contiguous block of memory.\n\n\n1.1 Optimization for C++Games \n9\nMemory Management \n—•\nC++ applications generally need to be more aware of the details of memory manage-\nment than C applications do. In C, all allocations are explicit though mallocQ and\nfreeQ, while C++ can implicitly allocate memory while constructing temporary\nobjects and member variables. Most C++ games (like most C games) will require their\nown memory manager.\nBecause a C++ game is likely to perform many allocations, it must be especially\ncareful about fragmenting the heap. One option is to take one of the traditional\napproaches: either don't allocate any memory at all after the game starts up, or main-\ntain a large contiguous block of memory that is periodically freed (between levels, for\nexample). On modern machines, such draconian measures are not necessary, if you're\nwilling to be vigilant about your memory usage.\nThe first step is to override the global new and delete operators. Use custom imple-\nmentations of diese operators to redirect the game's most common allocations away\nfrom mallocQ and into preallocated blocks of memory. For example, if you find that you\nhave at most 10,000 4-byte allocations outstanding at any one time, you should allocate\n40,000 bytes up front and issue blocks out as necessary. To keep track of which blocks\nare free, maintain a. free list by pointing each free block to the next free block. On allo-\ncation, remove the front block from the list, and on deallocation, add the freed block to\nthe front again. Figure 1.1.1 illustrates how the free list of small blocks might wind its\nway through a contiguous larger block after a sequence of allocations and frees.\nused\nfree\nused\nused\nt\nfree\nfree\n_ _ \nA .\n~ .~ \nT\nFIGURE 1.1.1 \nA linked free list.\nYou'll typically find that a game has many small, short-lived allocations, and thus\nyou'll want to reserve space for many small blocks. Reserving many larger blocks\nwastes a substantial amount of memory for those blocks that are not currently in use;\nabove a certain size, you'll want to pass allocations off to a separate large block alloca-\ntor, or just to mallocQ.\nVirtual Functions\nCritics of C++ in games often point to virtual functions as a mysterious feature\nthat drains performance. Conceptually, the mechanism is simple. To generate a virtual\nfunction call on an object, the compiler accesses the objects virtual function table,\n\n\n10 \nSection 1 General Programming\nretrieves a pointer to the member function, sets up the call, and jumps to the member\nfunction's address. This is to be compared with a function call in C, where the com-\npiler sets up the call and jumps to a fixed address. The extra overhead for the virtual\nfunction call is die indirection to die virtual function table; because the address of the\ncall isn't known in advance, there can also be a penalty for missing the processor's\ninstruction cache.\nAny substantial C++ program will make heavy use of virtual functions, so the idea\nis to avoid these calls in performance-critical areas. Here is a typical example:\nclass BaseClass\n{\npublic:\nvirtual char *GetPointer() = 0;\n};\nclass Class\"! : public BaseClass\n{\nvirtual char *GetPointer();\n>;\nclass Class2 : public BaseClass\n{\nvirtual char *GetPointer();\n}|\nvoid Function(BaseClass *pObj)\n{\nchar *ptr = pObj->GetPointer();\n}\nIf FunctionQ is performance critical, we want to change die call to GetPointer\nfrom virtual to inline. One way to do this is to add a new protected data member to\nBaseClass, which is returned by an inline version of GetPointerQ, and set the data\nmember in each class:\nclass BaseClass\n{\npublic:\ninline char *GetPointerFast()\n{\nreturn mpPointer;\n}\nprotected:\ninline void SetPointer(char *pData)\n{\nmpData = pData;\n}\nprivate:\nchar *mpData;\n\n\n1.1 \nOptimization for C++Games \n, \n. \n11\n// classl and class2 call SetPointer as necessary\n//in member functions\nvoid Function(BaseClass *pObj)\n{\nchar *ptr = pObj->GetPointerFast();\n}\nA more drastic measure is to rearrange your class hierarchy. If Classl and Class2\nhave only slight differences, it might be worth combining them into a single class,\nwith a flag indicating whether you want the class to behave like Classl or Class2 at\nruntime. With this change (and the removal of the pure virtual BaseClass), the Get-\nPointer function in the previous example can again be made inline. This transforma-\ntion is far from elegant, but in inner loops on machines with small caches, you'd be\nwilling to do much worse to get rid of a virtual function call.\nAlthough each new virtual function adds only the size of a pointer to a per-class\ntable (usually a negligible cost), the yzrtf virtual function in a class requires a pointer to\nthe virtual function table on a pet-object basis. This means that you don't want to have\nany virtual functions at all in small, frequently used classes where this extra overhead\nis unacceptable. Because inheritance generally requires the use of one or more virtual\nfunctions (a virtual destructor if nothing else), you don't want any hierarchy for small,\nheavily used objects.\nCode Size\nCompilers have a somewhat deserved reputation for generating bloated code for C++.\nBecause memory is limited, and because small is fast, it's important to make your exe-\ncutable as small as possible. The first thing to do is get the compiler on your side. If\nyour compiler stores debugging information in the executable, disable the generation\nof debugging information. (Note that Microsoft Visual C++ stores debugging infor-\nmation separate from the executable, so this may not be necessary.) Exception handling\ngenerates extra code; get rid of as much exception-generating code as possible. Make\nsure the linker is configured to strip out unused functions and classes. Enable the com-\npiler's highest level of optimization, and try setting it to optimize for size instead of\nspeed—sometimes this actually produces faster code because of better instruction\ncache coherency. (Be sure to verify that intrinsic functions are still enabled if you use\nthis setting.) Get rid of all of your space-wasting strings in debugging print statements,\nand have the compiler combine duplicate constant strings into single instances.\nInlining is often the culprit behind suspiciously large functions. Compilers are\nfree to respect or ignore your inline keywords, and they may well inline functions\nwithout telling you. This is another reason to keep your constructors lightweight, so\nthat objects on the stack don't wind up generating lots of inline code. Also be careful\nof overloaded operators; a simple expression like ml = m2 * m3 can generate a ton of\n",
      "page_number": 1,
      "chapter_number": 1,
      "summary": "This chapter covers segment 1 (pages 1-8). Key topics include object, function, and functions. Can complex C++ programs hope\nto match traditional C programs in speed.",
      "keywords": [
        "Object",
        "Function",
        "virtual function",
        "code",
        "Virtual",
        "virtual function call",
        "vector",
        "Vehicle",
        "Functions",
        "Games",
        "constructor",
        "memory",
        "objects virtual function",
        "function call",
        "compiler"
      ],
      "concepts": [
        "object",
        "function",
        "functions",
        "code",
        "block",
        "allocates",
        "allocations",
        "virtual",
        "generate",
        "generating"
      ],
      "similar_chapters": [
        {
          "book": "More Effective C++",
          "chapter": 32,
          "title": "Segment 32 (pages 320-329)",
          "relevance_score": 0.77,
          "method": "sentence_transformers"
        },
        {
          "book": "More Effective C++",
          "chapter": 29,
          "title": "Segment 29 (pages 293-301)",
          "relevance_score": 0.73,
          "method": "sentence_transformers"
        },
        {
          "book": "Computer Systems A Programmer’s Perspective",
          "chapter": 1,
          "title": "Segment 1 (pages 1-20)",
          "relevance_score": 0.72,
          "method": "sentence_transformers"
        },
        {
          "book": "More Effective C++",
          "chapter": 31,
          "title": "Segment 31 (pages 312-319)",
          "relevance_score": 0.72,
          "method": "sentence_transformers"
        },
        {
          "book": "More Effective C++",
          "chapter": 14,
          "title": "Segment 14 (pages 133-140)",
          "relevance_score": 0.71,
          "method": "sentence_transformers"
        }
      ]
    },
    {
      "number": 2,
      "title": "Segment 2 (pages 9-16)",
      "start_page": 9,
      "end_page": 16,
      "detection_method": "topic_boundary",
      "content": "12 \nSection 1 General Programming\ninline code if m2 and m3 are matrices. Get to know your compiler's settings for inlin-\ning functions thoroughly.\nEnabling runtime type information (RTTI) requires the compiler to generate\nsome static information for (just about) every class in your program. RTTI is typically\nenabled so that code can call dynamic_cast and determine an object's type. Consider\navoiding RTTI and dynamic_cast entirely in order to save space (in addition,\ndynamic_cast is quite expensive in some implementations). Instead, when you really\nneed to have different behavior based on type, add a virtual function that behaves dif-\nferently. This is better object-oriented design anyway. (Note that this doesn't apply to\nstatic_cast, which is just like a C-style cast in performance.)\nThe Standard Template Library\nThe Standard Template Library (STL) is a set of templates that implement common\ndata structures and algorithms, such as dynamic arrays (called vectors), sets, and\nmaps. Using the STL can save you a great deal of time that you'd otherwise spend\nwriting and debugging these containers yourself. Once again, though, you need to be\naware of the details of your STL implementation if you want maximum efficiency.\nIn order to allow the maximum range of implementations, the STL standard is\nsilent in the area of memory allocation. Each operation on an STL container has cer-\ntain performance guarantees; for example, insertion into a set takes O(log n) time.\nHowever, there are no guarantees on a container's memory usage.\nLet's go into detail on a very common problem in game development: you want\nto store a bunch of objects (we'll call it a list of objects, though we won't necessarily\nstore it in an STL list). Usually you want each object to appear in a list only once, so\nthat you don't have to worry about accidentally inserting the object into the collection\nif it's already there. An STL set ignores duplicates, has O(log n) insertion, deletion,\nand lookup—the perfect choice, right?\nMaybe. While it's true that most operations on a set are O(log n), this notation\nhides a potentially large constant. Although the collection's memory usage is imple-\nmentation dependent, many implementations are based on a red-black tree, where\neach node of the tree stores an element of the collection. It's common practice to allo-\ncate a node of the tree every time an element is inserted, and to free a node every time\nan element is removed. Depending on how often you insert and remove elements, the\ntime spent in the memory allocator can overshadow any algorithmic savings you\ngained from using a set.\nAn alternative solution uses an STL vector to store elements. A vector is guaran-\nteed to have amortized constant-time insertion at the end of the collection. What this\nmeans in practice is that a vector typically reallocates memory only on occasion, say,\ndoubling its size whenever it's full. When using a vector to store a list of unique ele-\nments, you first check the vector to see if the element is already there, and if it isn't,\nyou add it to the back. Checking the entire vector will take O(n) time, but the con-\nstant involved is likely to be small. That's because all of the elements of a vector are\n\n\n1.1 Optimization for C++Games \n13\ntypically stored contiguously in memory, so checking the entire vector is a cache-\nfriendly operation. Checking an entire set may well thrash the memory cache, as indi-\nvidual elements of the red-black tree could be scattered all over memory. Also\nconsider that a set must maintain a significant amount of overhead to set up the tree.\nIf all you're storing is object pointers, a set can easily require three to four times the\nmemory of a vector to store the same objects.\nDeletion from a set is O(log n), which seems fast until you consider that it prob-\nably also involves a call to free(). Deletion from a vector is O(n), because everything\nfrom the deleted element to the end of the vector must be copied over one position.\nHowever, if the elements of the vector are just pointers, the copying can all be done in\na single call to memcpyO, which is typically very fast. (This is one reason why it's usu-\nally preferable to store pointers to objects in STL collections, as opposed to objects\nthemselves. If you store objects directly, many extra constructors get invoked during\noperations such as deletion.)\nIf you're still not convinced that sets and maps can often be more trouble than\nthey're worth, consider the cost of iterating over a collection, specifically:\nfor (Collection::iterator it = collection.begin();\nit != collection.end(); ++it)\nIf Collection is a vector, then ++it is a pointer increment—one machine instruc-\ntion. But when Collection is a set or a map, ++it involves traversing to the next node\nof a red-black tree, a relatively complicated operation that is also much more likely to\ncause a cache miss, because tree nodes may be scattered all over memory.\nOf course, if you're storing a very large number of items in a collection, and doing\nlots of membership queries, a set's O(log n) performance could very well be worth the\nmemory cost. Similarly, if you're only using the collection infrequently, the perfor-\nmance difference may be irrelevant. You should do performance measurements to\ndetermine what values of n make a set faster. You may be surprised to find that vectors\noutperform sets for all values that your game will typically use.\nThat's not quite the last word on STL memory usage, however. It's important to\nknow if a collection actually frees its memory when you call the clear() method. If not,\nmemory fragmentation can result. For example, if you start a game with an empty\nvector, add elements to the vector as the game progresses, and then call clear() when\nthe player restarts, the vector may not actually free its memory at all. The empty vec-\ntor's memory could still be taking up space somewhere in the heap, fragmenting it.\nThere are two ways around this problem, if indeed your implementation works this\nway. First, you can call reserveQ when the vector is created, reserving enough space for\nthe maximum number of elements that you'll ever need. If that's impractical, you can\nexplicitly force the vector to free its memory this way:\nvector<int> v;\n// ... elements are inserted into v here\nvector<int>().swap(v); // causes v to free its memory\n\n\n14 \nSection 1 General Programming\nSets, lists, and maps typically don't have this problem, because they allocate and\nfree each element separately.\nAdvanced Features\nJust because a language has a feature doesn't mean you have to use it. Seemingly sim-\nple features can have very poor performance, while other seemingly complicated fea-\ntures can in fact perform well. The darkest corners of C++ are highly compiler\ndependent — make sure you know the costs before using them.\nC++ strings are an example of a feature that sounds great on paper, but should be\navoided where performance matters. Consider the following code:\nvoid Function (const std: :string &str)\nFunction (\"hello\");\nThe call to FunctionQ invokes a constructor for a string given a const char *. In\none commercial implementation, this constructor performs a mallocQ, a strlenQ, and\na memcpyO, and the destructor immediately does some nontrivial work (because this\nimplementation's strings are reference counted) followed by a freeQ- The memory\nthat's allocated is basically a waste, because the string \"hello\" is already in the pro-\ngram's data segment; we've effectively duplicated it in memory. If FunctionQ had\ninstead been declared as taking a const char *, there would be no overhead to the call.\nThat's a high price to pay for the convenience of manipulating strings.\nTemplates are an example of the opposite extreme of efficiency. According to the\nlanguage standard, the compiler generates code for a template when the template is\ninstantiated with a particular type. In theory, it sounds like a single template declara-\ntion would lead to massive amounts of nearly identical code. If you have a vector of\nClassl pointers, and a vector of Class2 pointers, you'll wind up with two copies of vec-\ntor in your executable.\nThe reality for most compilers is usually better. First, only template member\nfunctions that are actually called have any code generated for them. Second, the com-\npiler is allowed to generate only one copy of the code, if correct behavior is preserved.\nYou'll generally find that in the vector example given previously, only a single copy of\ncode (probably for vector<void *>) will be generated. Given a good compiler, tem-\nplates give you all the convenience of generic programming, while maintaining high\nperformance.\nSome features of C++, such as initializer lists and preincrement, generally increase\nperformance, while other features such as overloaded operators and RTTI look\nequally innocent but carry serious performance penalties. STL collections illustrate\nhow blindly trusting in a function's documented algorithmic running time can lead\nyou astray. Avoid the potentially slow features of the language and libraries, and spend\n\n\n1.1 Optimization for C++Games \n15\nsome time becoming familiar with the options in your profiler and compiler. You'll\nquickly learn to design for speed and hunt down the performance problems in your\ngame.\nFurther Investigations\nThanks to Pete Isensee and Christopher Kirmse for reviewing this gem.\nGormen, Thomas, Charles Leiserson, and Ronald Rivest, Introduction to Algorithms,\nCambridge, Massachusetts, MIT Press, 1990.\nIsensee, Peter, C++ Optimization Strategies and Techniques, www.tantalon.com/\npete/cppopt/main.htm.\nKoenig, Andrew, \"Pre- or Postfix Increment,\" The C++ Report, June, 1999.\nMeyers, Scott, Effective C++, Second Edition, Reading, Massachusetts: Addison-\nWesley Publishing Co., 1998.\nSutter, Herb, Guru of the Week #54: Using Vector and Deque, www.gotw.ca/\ngotw/054.htm.\n\n\n1.2\nInline Functions Versus Macros\nPeter Dalton, Evans & Sutherland\npdalton@xmission.com\nien it comes to game programming, the need for fast, efficient functions cannot\nbe overstated, especially functions that are executed multiple times per frame.\nMany programmers rely heavily on macros when dealing with common, time-critical\nroutines because they eliminate the calling/returning sequence required by functions\nthat are sensitive to the overhead of function calls. However, using the tfdefine directive\nto implement macros diat look like functions is more problematic than it is worth.\nAdvantages of Inline Functions\nThrough the use of inline functions, many of the inherent disadvantages of macros\ncan easily be avoided. Take, for example, the following macro definition:\n#define max(a,b) ((a) > (b) ? (a) : (b))\nLet's look at what would happen if we called the macro with die following para-\nmeters: max(++x, y). If x = 5 and j/ = 3, the macro will return a value of 7 rather than\nthe expected value of 6. This illustrates the most common side effect of macros, the\nfact that expressions passed as arguments can be evaluated more than once. To avoid\nthis problem, we could have used an inline function to accomplish die same goal:\ninline int max(int a, int b) { return (a > b ? a : b); }\nBy using the inline method, we are guaranteed that all parameters will only be\nevaluated once because they must, by definition, follow all the protocols and type\nsafety enforced on normal functions.\nAnother problem that plagues macros, operator precedence, follows from die\nsame problem presented previously, illustrated in the following macro:\n#define square(x) (x*x)\nIf we were to call this macro with the expression 2+1, it should become obvious\nthat die macro would return a result of 5 instead of the expected 9. The problem here\nis that the multiplication operator has a higher precedence than the addition operator\n16\n\n\n1.2 Inline Functions Versus Macros \n17\nhas. While wrapping all of the expressions within parentheses would remedy this\nproblem, it could have easily been avoided through the use of inline functions.\nThe other major pitfall surrounding macros has to deal with multiple-statement\nmacros, and guaranteeing that all statements within the macro are executed properly.\nAgain, let's look at a simple macro used to clamp any given number between zero and\none:\n#define clamp(a) \n\\\nif (a > 1.0) a = 1.0; \\\nif (a < 0.0) a = 0.0;\nIf we were to use the macro within the following loop:\nfor (int ii = 0 ; ii < N; ++ii)\nclamp( numbersToBeClamped[ii] );\nthe numbers would not be clamped if they were less than zero. Only upon termina-\ntion of the for loop when « == N would the expression if(numbersToBeClamped[ii] <\n0.0) be evaluated. This is also very problematic, because the index variable « is now\nout of range and could easily result is a memory bounds violation that could crash the\nprogram. While replacing the macro with an inline function to perform the same\nfunctionality is not the only solution, it is the cleanest.\nGiven these inherent disadvantages associated with macros, let's run through the\nadvantages of inline functions:\n• Inline functions follow all the protocols of type safety enforced on normal func-\ntions. This ensures that unexpected or invalid parameters are not passed as\narguments.\n• Inline functions are specified using the same syntax as any other function, except\nfor the inline keyword in the function declaration.\n• Expressions passed as arguments to inline functions are evaluated prior to enter-\ning the function body; thus, expressions are evaluated only once. As shown previ-\nously, expressions passed to macros can be evaluated more than once and may\nresult in unsafe and unexpected side effects.\n• It is possible to debug inline functions using debuggers such as Microsoft's Visual\nC++. This is not possible with macros because the macro is expanded before the\nparser takes over and the program's symbol tables are created.\n• Inline functions arguably increase the procedure's readability and maintainability\nbecause they use the same syntax as regular function calls, yet do not modify para-\nmeters unexpectedly.\nInline functions also outperform ordinary functions by eliminating the overhead\nof function calls. This includes tasks such as stack-frame setup, parameter passing,\nstack-frame restoration, and the returning sequence. Besides these key advantages,\ninline functions also provide the compiler with the ability to perform improved code\n\n\n18 \nSection 1 General Programming\noptimizations. By replacing inline functions with code, the inserted code is subject to\nadditional optimizations that would not otherwise be possible, because most compil-\ners do not perform interprocedural optimizations. Allowing the compiler to perform\nglobal optimizations such as common subexpression elimination and loop invariant\nremoval can dramatically improve both speed and size.\nThe only limitation to inline functions that is not present within macros is the\nrestriction on parameter types. Macros allow for any possible type to be passed as a\nparameter; however, inline functions only allow for the specified parameter type in\norder to enforce type safety. We can overcome this limitation through the use of inline\ntemplate functions, which allow us to accept any parameter type and enforce type\nsafety, yet still provide all the benefits associated with inline functions.\nWhen to Use Inline Functions\njj^.,,.,..^.....™,...,....,,,..,...........,,,........... \n.....,..,.„.,_,.,_.....„,,„„,.,....„„...._„„..,,..,...„„_.„„„,,„,„,„„..,.....,,„.,„ \n.,..,...,.„.,„., ,,,^... ..;„„..,,,....,.....™?i[.^,,.,.,.,..„,..,... ;.,..,^,:rr,.„,..-,,,...,,„,.,. ...s^ \n•.•..-\"!••!\nWhy don't we make every function an inline function? Wouldn't this eliminate the\nfunction overhead for the entire program, resulting in faster fill rates and response\ntimes? Obviously, the answer to these questions is no. While code expansion can\nimprove speed by eliminating function overhead and allowing for interprocedural\ncompiler optimizations, this is all done at the expense of code size. When examining\nthe performance of a program, two factors need to be weighed: execution speed\nand the actual code size. Increasing code size takes up more memory, which is a pre-\ncious commodity, and also bogs down the execution speed. As the memory require-\nments for a program increase, so does the likelihood of cache misses and page faults.\nWhile a cache miss will cause a minor delay, a page fault will always result in a major\ndelay because the virtual memory location is not in physical memory and must\nbe fetched from disk. On a Pentium II 400 MHz desktop machine, a hard page fault\nwill result in an approximately 10 millisecond penalty, or about 4,000,000 CPU\ncycles [Heller99].\nIf inline functions are not always a win, then when exactly should we use them?\nThe answer to this question really depends on the situation and thus must rely heav-\nily on the judgment of the programmer. However, here are some guidelines for when\ninline functions work well:\n• Small methods, such as accessors for private data members.\n• Functions returning state information about an object.\n• Small functions, typically three lines or less.\n• Small functions that are called repeatedly; for example, within a time-critical ren-\ndering loop.\nLonger functions that spend proportionately less time in the calling/returning\nsequence will benefit less from inlining. However, used correctly, inlining can greatly\nincrease procedure performance.\n\n\n1.2 Inline Functions Versus Macros \n19\nWhen to Use Macros\nDespite the problems associated with macros, there are a few circumstances in which\nthey are invaluable. For example, macros can be used to create small pseudo-languages\nthat can be quite powerful. A set of macros can provide the framework that makes cre-\nating state machines a breeze, while being very debuggable and bulletproof. For an\nexcellent example of this technique, refer to the \"Designing a General Robust AI\nEngine\" article referenced at the end of this gem [RabinOO]. Another example might\nbe printing enumerated types to the screen. For example:\ntfdefine CaseEnum(a) \ncase(a) : PrintEnum( #a )\nswitch (msg_passed_in) {\nCaseEnum( MSG_YouWereHit );\nReactToHit();\nbreak;\nCaseEnum( MSG_GameReset );\nResetGameLogic();\nbreak;\n}\nHere, PrintEnumQ is a macro that prints a string to the screen. The # is the\nstringizing operator that converts macro parameters to string constants [MSDN].\nThus, there is no need to create a look-up table of all enums to strings (which are usu-\nally poorly maintained) in order to retrieve invaluable debug information.\nThe key to avoiding the problems associated with macros is, first, to understand\nthe problems, and, second, to know the alternative implementations.\nMicrosoft Specifics\nBesides the standard inline keyword, Microsoft's Visual C++ compiler provides sup-\nport for two additional keywords. The \ninline keyword instructs the compiler to\ngenerate a cost/benefit analysis and to only inline the function if it proves beneficial.\nThe \nforceinline keyword instructs the compiler to always inline the function.\nDespite using these keywords, there are certain circumstances in which the compiler\ncannot comply as noted by Microsoft's documentation [MSDN].\nReferences\n[Heller99] Heller, Martin, Developing Optimized Code with Microsoft Visual C++ 6.0,\nMicrosoft MSDN Library, January 2000.\n[McConnell93] McConnell, Steve, Code Complete, Microsoft Press, 1993.\n[MSDN] Microsoft Developer Network Library, http://msdn.microsoft.com.\n[Myers98] Myers, Scott, Effective C++, Second Edition, Addison-Wesley Longman,\nInc., 1998.\n[RabinOO] Rabin, Steve, \"Designing a General Robust AI Engine,\" Game Program-\nming Gems. Charles River Media, 2000; pp. 221-236.\n",
      "page_number": 9,
      "chapter_number": 2,
      "summary": "This chapter covers segment 2 (pages 9-16). Key topics include functions, function, and functionality. Covers function. Get to know your compiler's settings for inlin-\ning functions thoroughly.",
      "keywords": [
        "Inline Functions",
        "functions",
        "inline",
        "Inline Functions Versus",
        "Functions Versus Macros",
        "vector",
        "function",
        "memory",
        "Macros",
        "STL",
        "code",
        "inline template functions",
        "function calls",
        "collection",
        "Functions Versus"
      ],
      "concepts": [
        "functions",
        "function",
        "functionality",
        "macros",
        "performance",
        "perform",
        "memory",
        "type",
        "operation",
        "operations"
      ],
      "similar_chapters": [
        {
          "book": "Effective_Modern_C++",
          "chapter": 30,
          "title": "Segment 30 (pages 317-324)",
          "relevance_score": 0.78,
          "method": "sentence_transformers"
        },
        {
          "book": "More Effective C++",
          "chapter": 32,
          "title": "Segment 32 (pages 320-329)",
          "relevance_score": 0.75,
          "method": "sentence_transformers"
        },
        {
          "book": "More Effective C++",
          "chapter": 31,
          "title": "Segment 31 (pages 312-319)",
          "relevance_score": 0.71,
          "method": "sentence_transformers"
        },
        {
          "book": "More Effective C++",
          "chapter": 29,
          "title": "Segment 29 (pages 293-301)",
          "relevance_score": 0.7,
          "method": "sentence_transformers"
        },
        {
          "book": "C++ Concurrency in Action",
          "chapter": 53,
          "title": "Segment 53 (pages 582-589)",
          "relevance_score": 0.69,
          "method": "sentence_transformers"
        }
      ]
    },
    {
      "number": 3,
      "title": "Segment 3 (pages 17-24)",
      "start_page": 17,
      "end_page": 24,
      "detection_method": "topic_boundary",
      "content": "1.3\nProgramming with\nAbstract Interfaces\nNoel Llopis, Meyer/Glass Interactive\nnllopis@mgigames.com\nT\nhe concept of abstract interfaces is simple yet powerful. It allows us to completely\nseparate the interface from its implementation. This has some very useful\nconsequences:\n• It is easy to switch among different implementations for the code without affect-\ning the rest of the game. This is particularly useful when experimenting with dif-\nferent algorithms, or for changing implementations on different platforms.\n• The implementations can be changed at runtime. For example, if the graphics\nTenderer is implemented through an abstract interface, it is possible to choose\nbetween a software Tenderer or a hardware-accelerated one while the game is\nrunning.\n• The implementation details are completely hidden from the user of the interface.\nThis will result in fewer header files included all over the project, faster recompile\ntimes, and fewer times when die whole project needs to be completely recompiled.\n• New implementations of existing interfaces can be added to the game effortlessly,\nand potentially even after it has been compiled and released. This makes it possi-\nble to easily extend the game by providing updates or user-defined modifications.\nAbstract Interfaces\nIn C++, an abstract interface is nothing more than a base class that has only public\npure virtual functions. A pure virtual function is a type of virtual member function\nthat has no implementation. Any derived class must implement those functions, or\nelse the compiler prevents instantiaton of that class. Pure virtual functions are indi-\ncated by adding = 0 after their declaration.\nThe following is an example of an abstract interface for a minimal sound system.\nThis interface would be declared in a header file by itself:\n//In SoundSystem.h\nclass ISoundSystem {\npublic:\n20\n\n\n1.3 Programming with Abstract Interfaces \n21\nvirtual ~ISoundSystem() {};\nvirtual bool PlaySound ( handle hSound ) = 0;\nvirtual bool StopSound ( handle hSound ) = 0;\nThe abstract interface provides no implementation whatsoever. All it does is\ndefine the rules by which the rest of the world may use the sound system. As long as\nthe users of the interface know about ISoundSystem, they can use any sound system\nimplementation we provide.\nThe following header file shows an example of an implementation of the previous\ninterface:\n/ / I n \nSoundSystemSoftware.h\n#include \"SoundSystem.h\"\nclass SoundSystemSoftware : public ISoundSystem {\npublic:\nvirtual -SoundSystemSoftware () ;\nvirtual bool PlaySound ( handle hSound ) ;\nvirtual bool StopSound ( handle hSound ) ;\n// The rest of the functions in the implementation\n};\nWe would obviously need to provide the actual implementation for each of those\nfunctions in the corresponding .cpp file.\nTo use this class, you would have to do the following:\nISoundSystem * pSoundSystem = new SoundSystemSoftware () ;\n// Now we're ready to use it\npSoundSystem->PlaySound ( hSound );\nSo, what have we accomplished by creating our sound system in this roundabout\nway? Almost everything that we promised at the start:\n• It is easy to create another implementation of the sound system (maybe a hard-\nware version). All that is needed is to create a new class that inherits from\nISoundSystem, instantiate it instead of SoundSystemSoftwareQ, and everything else\nwill work the same way without any more changes.\n• We can switch between the two classes at runtime. As long as pSoundSystem\npoints to a valid object, the rest of the program doesn't know which one it is\nusing, so we can change them at will. Obviously, we have to be careful with spe-\ncific class restrictions. For example, some classes will keep some state information\nor require initialization before being used for the first time.\n• We have hidden all the implementation details from the user. By implementing\nthe interface we are committed to providing the documented behavior no matter\nwhat our implementation is. The code is much cleaner than the equivalent code\n\n\n22 \nSection 1 General Programming\nfull of //\"statements checking for one type of sound system or another. Maintain-\ning the code is also much easier.\nAdding a Factory\nThere is one detail that we haven't covered yet: we haven't completely hidden the spe-\ncific implementations from the users. After all, the users are still doing a new on the\nclass of the specific implementation they want to use. The problem with this is that\nthey need to #include the header file with the declaration of the implementation.\nUnfortunately, the way C++ was designed, when users #include a header file, they can\nalso get a lot of extra information on the implementation details of that class that they\nshould know nothing about. They will see all the private and protected members, and\nthey might even include extra header files that are only used in the implementation of\nthe class.\nTo make matters worse, the users of the interface now know exactly what type of\nclass their interface pointer points to, and they could be tempted to cast it to its real\ntype to access some \"special features\" or rely on some implementation-specific behav-\nior. As soon as this happens, we lose many of the benefits we gained by structuring\nour design into abstract interfaces, so this is something that should be avoided as\nmuch as possible.\nThe solution is to use an abstract factory [Gamma95], which is a class whose sole\npurpose is to instantiate a specific implementation for an interface when asked for it.\nThe following is an example of a basic factory for our sound system:\n/ / I n SoundSystemFactory.h\nclass ISoundSystem;\nclass SoundSystemFactory {\npublic:\nenum SoundSystemType {\nSOUND_SOFTWARE,\nSOUND_HARDWARE,\nSOUND_SOMETH I NGE LSE\n};\nstatic ISoundSystem * CreateSoundSystem(SoundSystemType type);\n//In SoundSystemFactory. cpp\n^include \"SoundSystemSof tware . h\"\n^include \"SoundSystemHardware . h\"\n#include \"SoundSYstemSomethingElse . h\"\nISoundSystem * SoundSystemFactory: :CreateSoundSystem ( SoundSystemType\n_type )\n{\nISoundSystem * pSystem;\n\n\n1.3 Programming with Abstract Interfaces \n23\nswitch ( type ) {\ncase SOUND_SOFTWARE:\npSystem = new SoundSystemSoftwaref);\nbreak;\ncase SOUND_HARDWARE:\npSystem = new SoundSystemHardwareO;\nbreak;\ncase SOUND_SOMETHINGELSE:\npSystem = new SoundSystemSomethingElse();\nbreak;\ndefault:\npSystem = NULL;\nreturn pSystem;\nNow we have solved the problem. The user need only include SoundSystemFac-\ntory. h and SoundSystem.h. As a matter of fact, we don't even have to make the rest of\ndie header files available. To use a specific sound system, the user can now write:\nISoundSystem * pSoundSystem;\npSoundSystem = SoundSystemFactory::CreateSoundSystem\n(SoundSystemFactory::SOUND_SOFTWARE);\n// Now we're ready to use it\npSoundSystem->PlaySound ( hSound );\nWe need to always include a virtual destructor in our abstract interfaces. If\nwe don't, C++ will automatically generate a nonvirtual destructor, which\nwill cause the real destructor of our specific implementation not to be called\n(and that is usually a hard bug to track down). Unlike normal member\nfunctions, we can't just provide a pure virtual destructor, so we need to create\nan empty function to keep the compiler happy.\nAbstract Interfaces as Traits\nA slightly different way to think of abstract interfaces is to consider an interface as a\nset of behaviors. If a class implements an interface, that class is making a promise that\nit will behave in certain ways. For example, the following is an interface used by\nobjects that can be rendered to the screen:\nclass IRenderable {\npublic:\nvirtual -IRenderable() {};\nvirtual bool Render () = 0;\nWe can design a class to represent 3D objects that inherits from IRenderable and\nprovides its own method to render itself on the screen. Similarly, we could have a\n\n\nSection 1 General Programming\nterrain class that also inherits from IRenderable and provides a completely different\nrendering method.\nclass GenericSDObject : public IRenderable {\npublic:\nvirtual ~Generic3DObject() ;\nvirtual bool Render();\n// Rest of the functions here\n};\nThe render loop will iterate through all the objects, and if they can be rendered,\nit calls their RenderQ function. The real power of the interface comes again from hid-\ning the real implementation from the interface: now it is possible to add a completely\nnew type of object, and as long as it presents the IRenderable interface, the rendering\nloop will be able to render it like any other object. Without abstract interfaces, the\nrender loop would have to know about the specific types of object (generic 3D object,\nterrain, and so on) and decide whether to call their particular render functions. Cre-\nating a new type of render-capable object would require changing the render loop\nalong with many other parts of the code.\nWe can check whether an object inherits from IRenderable to know if it can be\nrendered. Unfortunately, that requires that the compiler's RTTI (Run Time Type\nIdentification) option be turned on when the code is compiled. There is usually a per-\nformance and memory cost to have RTTI enabled, so many games have it turned off\nin their projects. We could use our own custom RTTI, but instead, let's go the way of\nCOM (Microsoft's Component Object Model) and provide a Querylnterface function\n[Rogerson97] .\nIf the object in question implements a particular interface, then Querylnterface\ncasts the incoming pointer to the interface and returns true. To create our own Query-\nInterface function, we need to have a base class from which all of the related objects\nthat inherit from a set of interfaces derive. We could even make that base class itself an\ninterface like COM's lUnknown, but that makes things more complicated.\nclass GameObject {\npublic:\nenum GamelnterfaceType \n{\nIRENDERABLE,\nIOTHERINTERFACE\nvirtual bool Querylnterface (const GamelnterfaceType type,\nvoid ** pObj ) ;\n// The rest of the GameObject declaration\nThe implementation of Querylnterface for a plain game object would be trivial.\nBecause it's not implementing any interface, it will always return false.\n\n\n1.3 Programming with Abstract Interfaces \n25\nbool GameObject: :QueryInterface (const GamelnterfaceType type,\nvoid ** pObj ) {\nreturn false;\nThe implementation of a 3D object class is different from that of GameObject,\nbecause it will implement the IRenderable interface.\nclass 3DObject : public GameObject, public IRenderable {\npublic:\nvirtual -3DObject();\nvirtual bool Querylnterface (const GamelnterfaceType type,\nvoid ** pObj ) ;\nvirtual bool Render();\n// Some more functions if needed\nbool SDObject: :QueryInterface (const GamelnterfaceType type,\nvoid ** pObj ) {\nbool bSuccess = false;\nif ( type == GameObject:: IRENDERABLE ) {\n*pObj = static_cast<IRenderable *>(this);\nbSuccess = true;\n}\nreturn bSuccess;\nIt is the responsibility of the 3DObject class to override Querylnterface, check for\nwhat interfaces it supports, and do the appropriate casting.\nNow, let's look at the render loop, which is simple and flexible and knows noth-\ning about the type of objects it is rendering.\nIRenderable * pRenderable;\nfor ( all the objects we want to render ) {\nif ( pGameObject->QueryInterface (GameObject: : IRENDERABLE,\n(void**)&pRenderable) )\n{\npRenderable->Render ( ) ;\nNow we're ready to deliver the last of the promises of abstract interfaces listed at\nthe beginning of this gem: effortlessly adding new implementations. With such a ren-\nder loop, if we give it new types of objects and some of them implemented the IRen-\nderable interface, everything would work as expected without the need to change the\nrender loop. The easiest way to introduce the new object types would be to simply re-\nlink the project with the updated libraries or code that contains the new classes.\nAlthough beyond the scope of this gem, we could add new types of objects at runtime\nthrough DLLs or an equivalent mechanism available on the target platform. This\nenhancement would allow us to release new game objects or game updates without\n\n\n26 \nSection 1 General Programming\nthe need to patch the executable. Users could also use this method to easily create\nmodifications for our game.\nNotice that nothing is stopping us from inheriting from multiple interfaces. All it\nwill mean is that the class that inherits from multiple interfaces is now providing all\nthe services specified by each of the interfaces. For example, we could have an IColl-\nidable interface for objects that need to have collision detection done. A 3D object\ncould inherit from both IRenderable and ICollidable, but a class representing smoke\nwould only inherit from IRenderable.\nA word of warning, however: while using multiple abstract interfaces is a power-\nful technique, it can also lead to overly complicated designs that don't provide any\nadvantages over designs with single inheritance. Also, multiple inheritance doesn't\nwork well for dynamic characteristics, and should rather be used for permanent char-\nacteristics intrinsic to an object.\nEven though many people advise staying away from multiple inheritance, this is a\ncase where it is useful and it does not have any major drawbacks. Inheriting from at\nmost one real parent class and multiple interface functions should not result in the\ndreaded diamond-shaped inheritance tree (where the parents of both our parents are\nthe same class) or many of the other usual drawbacks of multiple inheritance.\nEverything Has a Cost\nSo far, we have seen that abstract interfaces have many attractive features. However, all\nof these features come at a price. Most of the time, the advantages of using abstract\ninterfaces outweigh any potential problems, but it is important to be aware of the\ndrawbacks and limitations of this technique.\nFirst, the design becomes more complex. For someone not used to abstract inter-\nfaces, the extra classes and the querying of interfaces could look confusing at first\nsight. It should only be used where it makes a difference, not indiscriminately all over\nthe game; otherwise, it will only obscure the design and get in the way.\nWith the abstract interfaces, we did such a good job hiding all of the private\nimplementations that they actually can become harder to debug. If all we have is a\nvariable of type IRenderable*, we won't be able to see the private contents of the real\nobject it points to in the debugger's interactive watch window without a lot of tedious\ncasting. On the other hand, most of the time we shouldn't have to worry about it.\nBecause the implementation is well isolated and tested by itself, all we should care\nabout is using the interface correctly.\nAnother disadvantage is that it is not possible to extend an existing abstract inter-\nface through inheritance. Going back to our first example, maybe we would have\nliked to extend the SoundSystemHardware class to add a few functions specific to the\ngame. Unfortunately, we don't have access to the class implementation any more, and\nwe certainly can't inherit from it and extend it. It is still possible either to modify the\nexisting interface or provide a new interface using a derived class, but it will all have to\nbe done from the implementation side, and not from within the game code.\n\n\n1.3 Programming with Abstract Interfaces \n27\nFinally, notice that every single function in an abstract interface is a virtual func-\ntion. This means that every time one of these functions is called through the abstract\ninterface, the computer will have to go through one extra level of indirection. This is\ntypically not a problem with modern computers and game consoles, as long as we\navoid using interfaces for functions that are called from within inner loops. For exam-\nple, creating an interface with a DrawPolygonQ or SetScreenPointQ function would\nprobably not be a good idea.\nConclusion\nAbstract interfaces are a powerful technique that can be put to good use with very lit-\ntle overhead or structural changes. It is important to know how it can be best used,\nand when it is better to do things a different way. Perfect candidates for abstract inter-\nfaces are modules that can be replaced (graphics Tenderers, spatial databases, AI\nbehaviors), or any sort of pluggable or user-extendable modules (tool extensions,\ngame behaviors).\nReferences\n[Gamma95] Gamma, Eric et al, Design Patterns, Addison-Wesley, 1995.\n[Lakos96] Lakos, John, Large Scale C++ Software Design, Addison-Wesley, 1996.\n[Rogerson97] Rogerson, Dale, Inside COM. Microsoft Press, 1997.\n",
      "page_number": 17,
      "chapter_number": 3,
      "summary": "This chapter covers segment 3 (pages 17-24). Key topics include interfaces, classes, and implementation. This has some very useful\nconsequences:\n• It is easy to switch among different implementations for the code without affect-\ning the rest of the game.",
      "keywords": [
        "Abstract Interfaces",
        "interface",
        "Abstract",
        "implementation",
        "virtual",
        "sound",
        "IRenderable",
        "type",
        "sound system",
        "object",
        "virtual bool",
        "Render",
        "functions",
        "virtual bool Render",
        "game"
      ],
      "concepts": [
        "interfaces",
        "classes",
        "implementation",
        "implement",
        "object",
        "virtual",
        "type",
        "game",
        "functions",
        "function"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 8",
          "chapter": 53,
          "title": "Segment 53 (pages 511-519)",
          "relevance_score": 0.72,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 7",
          "chapter": 63,
          "title": "Segment 63 (pages 609-616)",
          "relevance_score": 0.71,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 3",
          "chapter": 26,
          "title": "Segment 26 (pages 243-252)",
          "relevance_score": 0.68,
          "method": "sentence_transformers"
        },
        {
          "book": "More Effective C++",
          "chapter": 29,
          "title": "Segment 29 (pages 293-301)",
          "relevance_score": 0.67,
          "method": "sentence_transformers"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 36,
          "title": "Segment 36 (pages 719-740)",
          "relevance_score": 0.66,
          "method": "sentence_transformers"
        }
      ]
    },
    {
      "number": 4,
      "title": "Segment 4 (pages 25-33)",
      "start_page": 25,
      "end_page": 33,
      "detection_method": "topic_boundary",
      "content": "1.4\nExporting C++ Classes from DLLs\nHerb Marselas, Ensemble Studios\nhmarselas@ensemblestudios.com\nE\nxporting a C++ class from a Dynamic Link Library (DLL) for use by another\napplication is an easy way to encapsulate instanced functionality or to share\nderivable functionality without having to share the source code of the exported class.\nThis method is in some ways similar to Microsoft COM, but is lighter weight, easier\nto derive from, and provides a simpler interface.\nExporting a Function\nAt the most basic level, there is little difference between exporting a function or a class\nfrom a DLL. To export myExportedFunction from a DLL, the value _BUILDING_\nMY_DLL is defined in the preprocessor options of the DLL project, and not in the\nprojects that use the DLL. This causes DLLFUNCTION to be replaced by\n__decbpec(dllexport) when building the DLL, and __deckpec(dllimport) when build-\ning the projects that use the DLL.\n#ifdef _BUILDING_MY_DLL\ntfdefine DLLFUNCTION _declspec(dllexport) // defined if building the\n// DLL\n#else\ntfdefine DLLFUNCTION _declspec(dllimport) // defined if building the\n// application\n#endif\nDLLFUNCTION long myExportedFunction(void);\nExporting a Class\nExporting a C++ class from a DLL is slightly more complicated because there are sev-\neral alternatives. In the simplest case, the class itself is exported. As before, the DLL-\nFUNCTION macro is used to declare the class exported by the DLL, or imported by\nthe application.\n28\n\n\n1.4 Exporting C++ Classes from DLLs \n29\ntfifdef \n_BUILDING_MY_DLL\ntfdefine DLLFUNCTION _declspec(dllexport)\n#else\ntfdefine DLLFUNCTION _ declspec(dllimport)\ntfendif\nclass DLLFUNCTION CMyExportedClass\n{\npublic:\nCMyExportedClass(void) : mdwValue(O) { }\nvoid setValue(long dwValue) { mdwValue = dwValue; }\nlong getValue(void) { return mdwValue; }\nlong clearValue(void) ;\nprivate:\nlong mdwValue;\nIf the DLL containing the class is implicitly linked (in other words, the project\nlinks with the DLL's lib file), then using the class is as simple as declaring an instance\nof the class CMyExportedClass. This also enables derivation from this class as if it were\ndeclared directly in the application. The declaration of a derived class in the applica-\ntion is made normally without any additional declarations.\nclass CMyApplicationClass : public CMyExportedClass\n{\npublic:\nCMyApplicationClass ( void )\nThere is one potential problem with declaring or allocating a class exported from\na DLL in an application: it may confuse some memory-tracking programs and cause\nthem to misreport memory allocations or deletions. To fix this problem, helper func-\ntions that allocate and destroy instances of the exported class must be added to the\nDLL. All users of the exported class should call the allocation function to create an\ninstance of it, and the deletion function to destroy it. Of course, the drawback to this\nis that it prevents deriving from the exported class in the application. If deriving an\napplication-side class from the exported class is important, and the project uses a\nmemory-tracking program, then this program will either need to understand what's\ngoing on or be replaced by a new memory-tracking program.\n\n\n30 \nSection 1 General Programming\n#ifdef _BUILDING_MY_DLL\n#define DLLFUNCTION _declspec(dllexport)\n#else\n#define DLLFUNCTION _declspec(dllimport)\n#endif\nclass DLLFUNCTION CMyExportedClass\n{\npublic:\nCMyExportedClass(void) : mdwValue(O) { }\nvoid setValue(long dwValue) { mdwValue = dwValue; }\nlong getValue(void) { return mdwValue; }\nlong clearValue(void);\nprivate:\nlong mdwValue;\n};\nCMyExportedClass *createMyExportedClass(void) {\nreturn new CMyExportedClass; }\nvoid deleteMyExportedClass(CMyExportedClass *pclass) {\ndelete pclass; }\nExporting Class Member Functions\nEven with the helper functions added, because the class itself is being exported from\nthe DLL, it is still possible that users could create instances of the class without calling\nthe createMyExportedCLtss helper function. This problem is easily solved by moving the\nexport specification from the class level to the individual functions to which the users\nof the class need access. Then the application using the class can no longer create an\ninstance of the class itself. Instead, it must call the createMyExportedCLtss helper func-\ntion to create an instance of the class, and deleteMyExportedClass when it wishes to\ndestroy the class.\nclass CMyExportedClass\n{\npublic:\nCMyExportedClass(void) : mdwValue(O) { }\nDLLFUNCTION void setValue(long dwValue) { mdwValue = dwValue; }\nDLLFUNCTION long getValue(void) { return mdwValue; }\nlong clear-Value (void);\nprivate:\nlong mdwValue;\n};\nCMyExportedClass *createMyExportedClass(void) {\nreturn new CMyExportedClass; }\nvoid deleteMyExportedClass(CMyExportedClass *pclass) {\ndelete pclass; }\n\n\n1.4 Exporting C++ Classes from DLLs \n31\nIt should also be noted that although CMyExportedClass::clearValue is a public\nmember function, it can no longer be called by users of the class outside the DLL, as\nit is not declared as dllexported. This can be a powerful tool for a complex class that\nneeds to make some functions publicly accessible to users of the class outside the\nDLL, yet still needs to have other public functions for use inside the DLL itself. An\nexample of this strategy in practice is the SDK for Discreet's 3D Studio MAX. Most\nof the classes have a mix of exported and nonexported functions. This allows die user\nof the SDK to access or derive functionality as needed from the exported member\nfunctions, while enabling the developers of the SDK to have their own set of inter-\nnally available member functions.\nExporting Virtual Class Member Functions\nOne potential problem should be noted for users of Microsoft Visual C++ 6. If you\nare attempting to export the member functions of a class, and you are not linking\nwith the lib file of the DLL that exports the class (you're using LoadLibrary to load\nthe DLL at runtime), you will get an \"unresolved external symbol\" for each function\nyou reference if inline function expansion is disabled. This can happen regardless of\nwhether the function is declared completely in the header. One fix for this is to\nchange the inline function expansion to \"Only \ninline\" or \"Any Suitable.\" Unfortu-\nnately, this may conflict with your desire to actually have inline function expansion\ndisabled in a debug build. An alternate fix is to declare the functions virtual. The vir-\ntual declaration will cause the correct code to be generated, regardless of the setting of\nthe inline function expansion option. In many circumstances, you'll likely want to\ndeclare exported member functions virtual anyway, so that you can both work around\nthe potential Visual C++ problem and allow the user to override member functions as\nnecessary.\nclass CMyExportedClass\n{\npublic:\nCMyExportedClass(void) : mdwValue(O) { }\nDLLFUNCTION virtual void setValue(long dwValue) { mdwValue =\ndwValue; }\nDLLFUNCTION virtual long getValue(void) { return mdwValue; }\nlong clearValue(void);\nprivate:\nlong mdwValue;\n};\nWith exported virtual member functions, deriving from the exported class on the\napplication side is the same as if the exported class were declared completely in the\napplication itself.\n\n\n32 \nSection 1 General Programming\nclass CMyApplicationClass : public CMyExportedClass\n{\npublic:\nCMyApplicationClass (void) \n{ }\nvirtual void setValue(long dwValue);\nvirtual long getValue(void) ;\nSummary\nExporting a class from a DLL is an easy and powerful way to share functionality with-\nout sharing source code. It can give the application all the benefits of a structured C++\nclass to use, derive from, or overload, while allowing the creator of the class to keep\ninternal functions and variables safely hidden away.\n\n\n1.5\nProtect Yourself from DLL Hell\nand Missing OS Functions\nHerb Marselas, Ensemble Studios\nhmarselas@ensemblestudios.com\nD\nynamic Link Libraries (DLLs) are a powerful feature of Microsoft Windows.\nThey have many uses, including sharing executable code and abstracting out\ndevice differences. Unfortunately, relying on DLLs can be problematic due to their\nstandalone nature. If an application relies on a DLL that doesn't exist on the user's\ncomputer, attempting to run it will result in a \"DLL Not Found\" message that's not\nhelpful to the average user. If the DLL does exist on the user's computer, there's no\nway to tell if the DLL is valid (at least as far as the application is concerned) if it's\nautomatically loaded when the application starts up.\nBad DLL versions can easily find their way onto a system as the user installs and\nuninstalls other programs. Alternatively, there can even be differences in system DLLs\namong different Windows platforms and service packs. In these cases, the user may\neither get the cryptic \"DynaLink Error!\" message if the function being linked to in the\nDLL doesn't exist, or worse yet, the application will crash. All of these problems with\nfinding and loading the correct DLL are often referred to as \"DLL Hell.\" Fortunately,\nthere are several ways to protect against falling into this particular hell.\nImplicit vs. Explicit Linking\nThe first line of defense in protecting against bad DLLs is to make sure that the nec-\nessary DLLs exist on the user's computer and are a version with which the application\ncan work. This must be done before attempting to use any of their functionality.\nNormally, DLLs are linked to an application by specifying their eponymous lib\nfile in the link line. This is known as implicit DLL loading, or implicit linking. By link-\ning to the lib file, the operating system will automatically search for and load the\nmatching DLL when a program runs. This method assumes that the DLL exists, that\nWindows can find it, and that it's a version with which the program can work.\nMicrosoft Visual C++ also supports three other methods of implicit linking. First,\nincluding a DLL's lib file directly into a project is just like adding it on the link line.\nSecond, if a project includes a subproject that builds a DLL, the DLL's lib file is\n33\n\n\n34 \nSection 1 General Programming\nautomatically linked with the project by default. Finally, a lib can be linked to an\napplication using the #pragma comment (lib \"libname\") directive.\nThe remedy to this situation of implicit linking and loading is to explicitly load\nthe DLL. This is done by not linking to the DLL's lib file in the link line, and remov-\ning any #pragma comment directives that would link to a library. If a subproject in\nVisual C++ builds a DLL, the link property page of the subproject should be changed\nby checking the \"Doesn't produce .LIB\" option. By explicitly loading the DLL, the\ncode can handle each error that could occur, making sure the DLL exists, making sure\nthe functions required are present, and so forth.\nLoadLibrary and GetProcAddress\nWhen a DLL is implicitly loaded using a lib file, the functions can be called directly\nin the application's code, and the OS loader does all the work of loading DLLs and\nresolving function references. When switching to explicit linking, the functions must\ninstead be called indirectly through a manually resolved function pointer. To do this,\nthe DLL that contains the function must be explicitly loaded using the LoadLibrary\nfunction, and then we can retrieve a pointer to the function using GetProcAddress.\nHMODULE LoadLibrary(LPCTSTR IpFileName);\nFARPROC GetProcAddress(HMODULE hModule, LPCSTR IpProcName);\nBOOL FreeLibrary(HMODULE hModule);\nLoadLibrary searches for the specified DLL, loads it into the applications process\nspace if it is found, and returns a handle to this new module. GetProcAddress is then\nused to create a function pointer to each function in the DLL that will be used by the\ngame. When an explicitly loaded DLL is no longer needed, it should be freed using\nFreeLibrary. After calling FreeLibrary, the module handle is no longer considered valid.\nEvery LoadLibrary call must be matched with a FreeLibrary call. This is necessary\nbecause Windows increments a reference count on each DLL per process when it is\nloaded either implicitly by the executable or another DLL, or by calling LoadLibrary.\nThis reference count is decremented by calling FreeLibrary, or unloading the exe-\ncutable or DLL that loaded this DLL. When the reference count for a given DLL\nreaches zero, Windows knows it can safely unload the DLL.\nGuarding Against DirectX\nOne of the problems we have often found is that the required versions of DirectX\ncomponents are not installed, or the install is corrupt in some way. To protect our\ngame against these problems, we explicitly load the DirectX components we need. If\nwe were to implicitly link to Directlnput in DirectX 8, we would have added the din-\nputS.lib to our link line and used the following code:\n\n\n1.5 Protect Yourself from DLL Hell and Missing OS Functions \n35\nIDirectlnputS *pDInput;\nHRESULT hr = DirectInput8Create(hInstance, DIRECTINPUT_VERSION,\nIID_IDirectInput8,\n(LPVOID*) & pDInput, 0);\nif \n(FAILED(hr))\n{\n// handle error - initialization error\n}\nThe explicit DLL loading case effectively adds two more lines of code, but the\napplication is now protected against dinput8.dll not being found, or of it being cor-\nrupt in some way.\ntypedef HRESULT (WINAPI* DirectInput8Create_PROC)\n(HINSTANCE hinst, DWORD dwVersion, REFIID riidltf,\nLPVOID* ppvOut,\nLPUNKNOWN punkOuter);\nHMODULE hDInputLib = LoadLibrary( \"dinput8.dll\") ;\nif (! hDInputLib)\n{\n// handle error - DInput 8 not found. Is it installed incorrectly\n// or at all?\nDirectInput8Create_PROC diCreate;\ndiCreate = (DirectInput8Create_PROC)\nGetProcAddress(hDInputLib, \"DirectlnputSCreate\") ;\nif (! diCreate)\n{\n// handle error - DInput 8 exists, but the function can't be\n// found.\nHRESULT hr = (diCreate) (hlnstance, DIRECTINPUT_VERSION,\nI ID_IDirect Inputs,\n(LPVOID*) &mDirectInput, NULL);\nif \n(FAILED(hr))\n{\n// handle error - initialization error\nFirst, a function pointer typedef is created that reflects the function Direct-\nlnputSCreate. The DLL is then loaded using LoadLibrary. If the dinput8.dll was\nloaded successfully, we then attempt to find the function DirectlnputSCreate using\nGetProcAddress. GetProcAddress returns a pointer to the function if it is found, or\nNULL if the function cannot be found. We then check to make sure the function\npointer is valid. Finally, we call DirectlnputSCreate through the function pointer to\ninitialize Directlnput.\n\n\n36 \nSection 1 General Programming\nIf there were more functions that needed to be retrieved from the DLL, a func-\ntion pointer typedefand variable would be declared for each. It might be sufficient to\nonly check for NULL when mapping the first function pointer using GetProcAddress.\nHowever, as more error handling is usually not a bad thing, checking every Get-\nProcAddress for a successful non-NULL return is probably a good thing to do.\nUsing OS-Specific Features \n_\nAnother issue that explicit DLL loading can resolve is when an application wants to\ntake advantage of a specific API function if it is available. There is an extensive num-\nber of extended functions ending in \"Ex\" that are supported under Windows NT or\n2000, and not available in Windows 95 or 98. These extended functions usually pro-\nvide more information or additional functionality than the original functions do .\nAn example of this is the CopyFileEx function, which provides the ability to can-\ncel a long file copy operation. Instead of calling it directly, kernel32.dll can be loaded\nusing LoadLibrary and the function again mapped with GetProcAddress. If we load\nkernel32.dll and find CopyFileEx, we use it. If we don't find it, we can use the regular\nCopyFile function. One other problem that must be avoided in this case is that Copy-\nFileEx is really only a #define replacement in the winbase.h header file that is replaced\nwith CopyFileExA or CopyFileExW if compiling for ASCII or wide Unicode charac-\nters, respectively.\ntypedef BOOL (WINAPI *CopyFileEx_PROC) (LPCTSTR IpExistingFileName,\nLPCTSTR IpNewFileName , \nLPPROGRESS_ROUTINE IpProgressRoutine, \nLPVOID\nIpData, LPBOOL pbCancel, DWORD dwCopyFlags) ;\nHMODULE hKerne!32 = LoadLibrary(\"kernel32.dH\") ;\nif \n(!hKerne!32)\n{\n// handle error - kernel32.dll not found. Wow! That's really bad\n}\nCopyFileEx_PROC pfnCopyFileEx;\npfnCopyFileEx = (CopyFileEx_PROC) GetProcAddress(hKernel32,\n\"CopyFileExA\") ;\nBOOL bReturn;\nif (pfnCopyFileEx)\n{\n/ / use CopyFileEx to copy the file\nbReturn = (pfnCopyFileEx) (pExistingFile, pDestinationFile, ...);\nelse\n// use the regular CopyFile function\nbReturn = CopyFilefpExistingFile, pDestinationFile, FALSE);\n",
      "page_number": 25,
      "chapter_number": 4,
      "summary": "This method is in some ways similar to Microsoft COM, but is lighter weight, easier\nto derive from, and provides a simpler interface Key topics include functionality, function, and functions.",
      "keywords": [
        "DLL",
        "Function",
        "DLL tfdefine DLLFUNCTION",
        "DLLs",
        "DLL lib file",
        "Functions",
        "class DLLFUNCTION CMyExportedClass",
        "DLL lib",
        "DLLFUNCTION",
        "void",
        "Member Functions",
        "DLL Hell",
        "exported class",
        "Class Member Functions",
        "long"
      ],
      "concepts": [
        "functionality",
        "function",
        "functions",
        "classes",
        "void",
        "exporting",
        "link",
        "windows",
        "long",
        "programs"
      ],
      "similar_chapters": [
        {
          "book": "C++ Templates_ The Complete Guide",
          "chapter": 26,
          "title": "Segment 26 (pages 815-849)",
          "relevance_score": 0.58,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 40,
          "title": "Segment 40 (pages 368-375)",
          "relevance_score": 0.57,
          "method": "sentence_transformers"
        },
        {
          "book": "More Effective C++",
          "chapter": 29,
          "title": "Segment 29 (pages 293-301)",
          "relevance_score": 0.57,
          "method": "sentence_transformers"
        },
        {
          "book": "Python Distilled",
          "chapter": 38,
          "title": "Segment 38 (pages 345-352)",
          "relevance_score": 0.57,
          "method": "sentence_transformers"
        },
        {
          "book": "A Philosophy of Software Design",
          "chapter": 5,
          "title": "Segment 5 (pages 36-43)",
          "relevance_score": 0.56,
          "method": "sentence_transformers"
        }
      ]
    },
    {
      "number": 5,
      "title": "Segment 5 (pages 34-41)",
      "start_page": 34,
      "end_page": 41,
      "detection_method": "topic_boundary",
      "content": "1.5 Protect Yourself from DLL Hell and Missing OS Functions \n37\nThe use of LoadLibrary and GetProcAddress can also be applied to game DLLs.\nOne example of this is the graphics support in a game engine currently under devel-\nopment at Ensemble Studios, where graphics support for Direct3D and OpenGL has\nbeen broken out into separate DLLs that are explicitly loaded as necessary. If\nDirect3D graphics support is needed, the Direct3D support DLL is loaded with\nLoadLibrary and the exported functions are mapped using GetProcAddress. This setup\nkeeps the main executable free from having to link implicitly with either dddS.lib or\nopengl32.lib.\nHowever, the supporting Direct3D DLL links implicitly with dddS.lib, and the\nsupporting OpenGL DLL links implicitly with opengl32. lib. This explicit loading of\nthe game's own DLLs by the main executable, and implicit loading by each graphics\nsubsystem solves several problems. First, if an attempt to load either library fails, it's\nlikely that that particular graphics subsystem files cannot be found or are corrupt. The\nmain program can then handle the error gracefully. The other problem that this\nsolves, which is more of an issue with OpenGL than Direct3D, is that if the engine\nwere to link explicitly to OpenGL, it would need a typedef and function pointer for\nevery OpenGL function it used. The implicit linking to the support DLL solves this\nproblem.\nSummary\nExplicit linking can act as a barrier against a number of common DLL problems that\nare encountered under Windows, including missing DLLs, or versions of DLLs that\naren't compatible with an application. While not a panacea, it can at least put the\napplication in control and allow any error to be handled gracefully instead of with a\ncryptic error message or an outright crash.\n\n\n1.6\nDynamic Type Information\nScott Wakeling, Virgin Interactive\nscott@chronicreality.com\nA\ns developers continue to embrace object orientation, the systems that power\ngames are growing increasingly flexible, and inherently more complex. Such sys-\ntems now regularly contain many different types and classes; counts of over 1000 are\nnot unheard of. Coping with so many different types in a game engine can be a chal-\nlenge in itself. A type can really mean anything from a class, to a struct, to a standard\ndata type. This gem discusses managing types effectively by providing ways of query-\ning their relations to other types, or accessing information about their type at runtime\nfor query or debug purposes. Toward the end of the gem, an approach for supporting\npersistent objects is suggested with some ideas about how the method can be\nextended.\nIntroducing the Dynamic Type Information Class\nIn our efforts to harness the power of our types effectively, we'll be turning to the aid\nof one class in particular: the dynamic type information (DTI) class. This class will\nstore any information that we may need to know about the type of any given object or\nstructure. A minimal implementation of the class is given here:\nclass dtiClass\n{\nprivate:\nchar* szName;\ndtiClass* pdtiParent;\npublic:\ndtiClass();\ndtiClass( char* szSetName, dtiClass* pSetParent );\nvirtual -dtiClass();\nconst char* GetName();\nbool SetName( char* szSetName );\ndtiClass* GetParent();\nbool SetParent( dtiClass* pSetParent );\n38\n\n\n1.6 Dynamic Type Information \n39\nIn order to instill DTI into our engine, all our classes will need a dtiClass as a sta-\ntic member. It's this class that allows us to access a class name for debug purposes and\nquery the dtiClass member of the class's parent. This member must permeate the class\ntree all the way from the root class down, thus ensuring that all game objects have\n'~^J^__J) \naccess to information about themselves and their parents. The implementation ofdti-\nONTHICO \nClass can be found in the code on the accompanying CD.\nExposing and Querying the DTI\nLet's see how we can begin to use DTI by implementing a very simple class tree as\ndescribed previously. Here is a code snippet showing a macro that helps us define our\nstatic dtiClass member, a basic root class, and simple initialization of the class's type\ninfo:\n#define EXPOSE_TYPE \\\npublic: \\\nstatic dtiClass Type;\nclass CRootClass\n{public:\nEXPOSE_TYPE;\nCRootClass() \n{};\nvirtual -CRootClass() {};\n};\ndtiClass CRootClass::Type( \"CRootClass\", NULL );\nBy including the EXPOSE_TYPE macro in all of our class definitions and initial-\nizing the static Type member correctly as shown, we've taken the first step toward\ninstilling dynamic type info in our game engine. We pass our class name and a pointer\nto the class's parent's dtiClass member. The dtiClass constructor does the rest, setting\nup the szName and pdtiParent members accordingly.\nWe can now query for an object's class name at runtime for debug purposes of\nother type-related cases, such as saving or loading a game. More on that later, but for\nnow, here's a quick line of code that will get us our class name:\n// Let's see what kind of object this pointer is pointing to\nconst char* szGetName = pSomePtr->Type.GetName();\nIn the original example, we passed NULL in to the dtiClass constructor as the\nclass's parent field because this is our root class. For classes that derive from others, we\njust need to specify the name of the parent class. For example, if we were to specify a\nchild class of our root, a basic definition might look something like this:\nclass CChildClass : public CRootClass\n{\nEXPOSE TYPE;\n\n\n40 \nSection 1 General Programming\n// Constructor and virtual Destructor go here\n};\ndtiClass CChildClass::Type( \"CChildClass\", &CRootClass::Type );\nNow we have something of a class tree growing. We can access not only our class's\nname, but the name of its parent too, as long as its type has been exposed with the\nEXPOSE_TYPE macro. Here's a line of code that would get us our parent's name:\n// Let's see what kind of class this object is derived from\nchar* szParentName = pSomePtr->Type.GetParent()->GetName();\nNow that we have a simple class tree with DTI present and know how to use that\ninformation to query for class and parent names at runtime, we can move on to\nimplementing a useful method for safeguarding type casts, or simply querying an\nobject about its roots or general type.\nInheritance Means \"IsA\"\nObject orientation gave us the power of inheritance. With inheritance came polymor-\nphism, the ability for all our objects to be just one of many types at any one time. In\nmany cases, polymorphism is put to use in game programming to handle many types\nof objects in a safe, dynamic, and effective manner. This means we like to ensure that\nobjects are of compatible types before we cast them, thus preventing undefined\nbehavior. It also means we like to be able to check what type an object conforms to at\nruntime, rather than having to know from compiler time, and we like to be able to do\nall of these things quickly and easily.\nImagine that our game involves a number of different types of robots, some\npurely electronic, and some with mechanical parts, maybe fuel driven. Now assume\nfor instance that there is a certain type of weapon the player may have that is very\neffective against the purely electronic robots, but less so against their mechanical\ncounterparts. The classes that define these robots are very likely to be of the same\nbasic type, meaning they probably both inherit from the same generic robot base\nclass, and then go on to override certain functionality or add fresh attributes. To cope\nwith varying types of specialist child classes, we need to query their roots. We can\nextend the dtiClass introduced earlier to provide us with such a routine. We'll call the\nnew member function IsA, because inheritance can be seen to translate to \"is a type\nof.\" Here's the function:\nbool dtiClass::IsA( dtiClass* pType )\n{\ndtiClass* pStartType = this;\nwhile( pStartType )\n{\nif ( pStartType == pType )\n\n\n1.6 Dynamic Type Information \n41\nreturn true;\nelse\npStartType = pStartType->GetParent();\nreturn false;\nIf we need to know whether a certain robot subclass is derived from a certain root\nclass, we just need to call IsA from the object's own dtiClass member, passing in the\nstatic dtiClass member of the root class. Here's a quick example:\nCRootClass* pRoot;\nCChildClass* pChild = new CChildClass();\nif ( pChild->Type.IsA( &CRootClass::Type ) )\npRoot = (CRootClass*)pChild;\nWe can see that the result of a quick IsA check tells us whether we are derived,\ndirectly or indirectly, from a given base class. Of course, we might use this fact to go\non and perform a safe casting operation, as in the preceding example. Or, maybe we'll\njust use the check to filter out certain types of game objects in a given area, given that\ntheir type makes them susceptible to a certain weapon or effect. If we decide that a\nsafe casting operation is something we'll need regularly, we can add the following\n^-—_1-^ \nfunction to the root object to simplify matters. Here's the definition and a quick\nexample; the function's implementation is on the accompanying CD:\n// SafeCast member function definition added to CRootClass\nvoid* SafeCast( dtiClass* pCastToType );\n// How to simplify the above operation\npRoot = (CRootClass*)pChild->SafeCast( &CRootClass::Type );\nIf the cast is not safe (in other words, the types are not related), dien the value will\nevaluate to nothing, and pRoot will be NULL.\nHandling Generic Objects\nGoing back to our simple game example, let's consider how we might cope with so\nmany different types of robot effectively. The answer starts off quite simple: we can\nmake use of polymorphism and just store pointers to them all in one big array of\ngeneric base class pointers. Even our more specialized robots can be stored here, such\nas CRobotMech (derived from CRobof), because polymorphism dictates that for any\ntype requirement, a derived type can always be supplied instead. Now we have our\nvast array of game objects, all stored as pointers to a given base class. We can iterate\n\n\n42 \nSection 1 \nGeneral Programming\nover them safely, perhaps calling virtual functions on each and getting the more spe-\ncialized (overridden) routines carried out by default. This takes us halfway to han-\ndling vast numbers of game objects in a fast, safe, and generic way.\nAs part of our runtime type info solution, we have the IsA and SafeCast routines\nthat can query what general type an object is, and cast it safely up the class tree. This\nis often referred to as up-casting, and it takes us halfway to handling vast numbers of\ngame objects in a fast, safe, and generic way. The other half of the problem comes\nwith down-casting—casting a pointer to a generic base class safely down to a more spe-\ncialized subclass. If we want to iterate a list of root class pointers, and check whether\neach really points to a specific type of subclass, we need to make use of the dynamic\ncasting operator, introduced by C++.\nThe dynamic casting operator is used to convert among polymorphic types and is\nboth safe and informative. It even returns applicable feedback about the attempted\ncast. Here's the form it takes:\ndynamic_cast< type-id >(expression)\nThe first parameter we must pass in is the type we wish expression to conform to\nafter the cast has taken place. This can be a pointer or reference to one of our classes.\nIf it's a pointer, the parameter we pass in as expression must be a pointer, too. If we pass\na reference to a class, we must pass a modifiable l-value in the second parameter. Here\nare two examples:\n// Given a root object (RootObj), on pointer (pRoot) we\n// can down-cast like this\nCChildClass* pChild = dynamic_cast<CChildClass*>(pRoot);\nCChildClass& ChildObj = dynamic_cast<CChildClass&>(RootObj);\nTo gain access to these extended casting operators, we need to enable embedded\nruntime type information in the compiler settings (use the /GR switch for Microsoft\nVisual C++). If the requested cast cannot be made (for example, if the root pointer\ndoes not really point to anything more derived), the operator will simply fail and the\nexpression will evaluate to NULL. Therefore, from the preceding code snippet,\n(f :,js*:*:*'% pChild would evaluate to NULL IfpRoot really did only point to a CRootClass object.\nON me a> \nIf the cast of RootObj failed, an exception would be thrown, which could be contained\nwith a try I catch block (example is included on the companion CD-ROM).\nThe dynamic_cast operator lets us determine what type is really hidden behind a\npointer. Imagine we want to iterate through every robot in a certain radius and deter-\nmine which ones are mechanical models, and thus immune to the effects of a certain\nweapon. Given a list of generic CRobot pointers, we could iterate through these and\nperform dynamic casts on each, checking which ones are successful and which resolve\nto NULL, and thus exacting which ones were in fact mechanical. Finally, we can now\nsafely down-cast too, which completes our runtime type information solution. The\n\n\n1.6 Dynamic Type information \n43\n/ c \n-., \ncode on the companion CD-ROM has a more extended example of using the\non m CD dynamic casting operator.\nImplementing Persistent Type Information\nNow that our objects no longer have an identity crisis and we're managing them effec-\ntively at runtime, we can move on to consider implementing a persistent object solu-\ntion, thus extending our type-related capabilities and allowing us to handle things\n,- c \") such as game saves or object repositories with ease. The first thing we need is a bare-\nmtmco \nbones implementation of a binary store where we can keep our object data. An exam-\nple implementation, CdtiBin can be found on the companion CD-ROM.\nThere are a number of utility member functions, but the two important points\nare the Stream member function, and the friend « operators that allow us to write\nout or load die basic data types of the language. We'll need to add an operator for each\nbasic type we want to persist. When Stream is called, the data will be either read from\nthe file or written, depending on the values of m_bLoading and m_bSaving.\nTo let our classes know how to work with the object repositories we need to add\nthe Serialize function, shown here:\nvirtual void Serialize( CdtiBin& ObjStore );\nNote that it is virtual and needs to be overridden for all child classes that have\nadditional data over their parents. If we add a simple integer member to CRootClass,\nwe would write the Serialize function like this:\nvoid CRootClass::Serialize( CdtiBin& ObjStore )\n{\nObjStore « iMemberlnt;\n}\nWe would have to be sure to provide the friend operator for integers and CdtiBin\nobjects. We could write object settings out to a file, and later load them back in and\nrepopulate fresh objects with die old data, thus ensuring a persistent object solution\nfor use in a game save routine. All types would thus know how to save themselves,\nmaking our game save routines much easier to implement.\nHowever, child classes need to write out their data and that of their parents.\nInstead of forcing the programmer to look up all data passed down from parents and\nadding it to each class's Serialize member, we need to give each class access to its par-\nent's Serialize routine. This allows child classes to write (or load) their inherited data\nbefore their own data. We use the DECLAREJSUPER macro for this:\n#define DECLARE_SUPER(SuperClass) \\\npublic: \\\ntypedef Superclass Super;\n\n\n44 \nSection 1 General Programming\nclass CChildClass\nDECLARE_SUPER(CRootClass);\nThis farther extends our type solution by allowing our classes to call their imme-\ndiate parents' versions of functions, making our class trees more extensible.\nCRootClass doesn't need to declare its superclass because it doesn't have one, and\nthus its Serialize member only needs to cope with its own data. Here's how CChild-\nClass::Serialize calls CRootClass:Serialize before dealing with some of its own data\n(added specifically for the example):\nvoid CChildClass::Serialize( CdtiBin& ObjStore )\n{\nSuper::Serialize( ObjStore );\nObjStore « fMemberFloat « iAnotherlnt;\n}\nA friend operator for the float data type was added to support the above. Note\nthat the order in which attributes are saved and loaded is always the same. Code\nshowing how to create a binary store, write a couple of objects out, and then repopu-\nlate the objects' attributes can be found on the companion CD-ROM.\nAs long as object types are serialized in the same order both ways, their attributes\nwill remain persistent between saves and loads. Adding the correct friend operators to\nthe CdtiBin class adds support for basic data types. If we want to add user-defined\nstructures to our class members, we just need to write an operator for coping with that\nstruct. With this in place, all objects and types in the engine will know precisely how\nto save themselves out to a binary store and read themselves back in.\nApplying Persistent Type Information to a Game\nSave Database\nAs mentioned previously, objects need to be serialized out and loaded back in the\nsame order. The quickest and easiest method is to only save out one object to the\ngame saves, and then just load that one back in. If we can define any point in\nthe game by constructing some kind of game state object that knows precisely how to\nserialize itself either way, then we can write all our game data out in one hit, and read\nit back in at any point. Our game state object would no doubt contain arrays of\nobjects. As long as the custom array type knows how to serialize itself, and we have all\nthe correct CdtiBin operators written for our types, everything will work. Saving and\nloading a game will be a simple matter of managing the game from a high-level, all-\nencompassing containment class, calling just the one Serialize routine when needed.\n",
      "page_number": 34,
      "chapter_number": 5,
      "summary": "This gem discusses managing types effectively by providing ways of query-\ning their relations to other types, or accessing information about their type at runtime\nfor query or debug purposes Key topics include type, classes, and object.",
      "keywords": [
        "Type",
        "Dynamic Type Information",
        "Type Information",
        "Dynamic Type",
        "game",
        "object",
        "dtiClass",
        "DLL Hell",
        "Type Information Class",
        "Serialize",
        "Persistent Type Information",
        "Dynamic",
        "Information",
        "runtime type information",
        "CRootClass"
      ],
      "concepts": [
        "type",
        "classes",
        "object",
        "member",
        "functions",
        "functionality",
        "game",
        "data",
        "examples",
        "mechanical"
      ],
      "similar_chapters": [
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 23,
          "title": "Segment 23 (pages 220-231)",
          "relevance_score": 0.49,
          "method": "sentence_transformers"
        },
        {
          "book": "Designing Data-Intensive Applications",
          "chapter": 8,
          "title": "Segment 8 (pages 62-70)",
          "relevance_score": 0.48,
          "method": "sentence_transformers"
        },
        {
          "book": "Effective-Python",
          "chapter": 20,
          "title": "Segment 20 (pages 198-208)",
          "relevance_score": 0.47,
          "method": "sentence_transformers"
        },
        {
          "book": "Fluent Python 2nd",
          "chapter": 20,
          "title": "Segment 20 (pages 392-414)",
          "relevance_score": 0.47,
          "method": "sentence_transformers"
        },
        {
          "book": "Fluent Python 2nd",
          "chapter": 29,
          "title": "Segment 29 (pages 576-595)",
          "relevance_score": 0.47,
          "method": "sentence_transformers"
        }
      ]
    },
    {
      "number": 6,
      "title": "Segment 6 (pages 42-52)",
      "start_page": 42,
      "end_page": 52,
      "detection_method": "topic_boundary",
      "content": "1.6 Dynamic Type Information \n45\nConclusion\nThere is still more that could be done than just the solution described here. Support-\ning multiple inheritance wouldn't be difficult. Instead of storing just the one parent\npointer in our static dtiClass, we would store an array of as many parents a class had,\nspecifying the count and a variable number of type classes in a suitable macro, or by\nextending the dtiClass constructor. An object flagging system would also be useful,\nand would allow us to enforce special cases such as abstract base classes or objects we\nonly ever wanted to be contained in other classes, and never by themselves (\"con-\ntained classes\").\nReferences\n[Meyers98] Meyers, Scott D., Effective C++ 2ndEdition, Addison-Wesley, 1998.\n[Wilkie94] Wilkie, George, Object-Oriented Software Engineering, Addison-Wesley,\n1994.\n[EberlyOO] Eberly, David H., 3D Game Engine Design, Morgan Kauffman,\n1999-2000.\n[WakelingOl] Wakeling, Scott J., \"Coping with Class Trees,\" available online at\nwww.chronicreality.com/articles, March 12, 2001.\n\n\n1.7\nA Property Class for Generic\nC++ Member Access\nCharles Cafrelli\nskywise@iquest.net\nP\nractically every game has a unique set of game objects, and any code that has to\nmanipulate those objects has to be written from scratch for each project. Take,\nfor example, an in-game editor, which has a simple purpose: to create, place, display,\nand edit object properties. Object creation is almost always specific to the game, or\ncan be handled by a class factory. Object placement is specific to the visualization\nengine, which makes reuse difficult, assuming it is even possible to visually place an\nobject on the map. In some cases, a generic map editor that can be toggled on and off\n(or possibly superimposed as a heads-up display) can be reused from game to game.\nTherefore, in theory, it should be possible to develop a core editor module that can be\nreused without having to rewrite the same code over and over again for each project.\nHowever, given that all games have unique objects, how does the editor know what to\ndisplay for editing purposes without rewriting the editor code?\nWhat we need is a general object interface that allows access to the internals of a\nclass. Borland's C++ Builder provides an excellent C++ declaration type called ^prop-\nerty that does this very thing, but alas, it is a proprietary extension and unusable out-\nside of Borland C++. Interestingly enough, C#, Microsoft's new programming\nlanguage developed by the creator of Borland C++ Builder, contains the same feature.\nMicrosoft's COM interface allows runtime querying of an object for its members, but\nit requires that we bind our objects to the COM interface, making them less portable\nthan straight C++. This leaves a \"roll-your-own\" solution, which can be more light-\nweight than COM, and more portable than proprietary extensions to the C++ lan-\nguage. This will allow code modules such as the in-game editor to be written just\nonce, and used across many engines.\nThe Code\nThe interface is broken into two classes: a Property class and a PropertySet class. Prop-\nerty is a container for one piece of data. It contains a union of pointers to different\ndata types, an enumeration for the type of data, and a string for the property name.\nThe full source code can be found on the companion CD.\n46\n\n\n1.7 A Property Class for Generic C++ Member Access \n47\nclass Property\n{\nprotected:\nunion Data\n{\nint* m_int;\nfloat* m_float;\nstd::string* m_string;\nbool* m_bool;\nenum Type\n{\nINT,\nFLOAT,\nSTRING,\nBOOL,\nEMPTY\nData \nm_data;\nType \nm_type;\nstd:: string m_name;\nprotected:\nvoid EraseType() ;\nvoid Register(int* value);\nvoid Registerffloat* value);\nvoid Registerfstd: :string* new_string);\nvoid Registerfbool* value);\npublic:\nProperty () ;\nProperty(std: :string const& name);\nProperty(std: :string const& name, int* value);\nProperty (std :: string const& name, float* value);\nProperty (std :: string const& name, std::string* value);\nProperty (std :: string const& name, bool* value);\n-Property () ;\nbool SetUnknownValue(std: :string const& value);\nbool Set (int value) ;\nbool Set(float value);\nbool Set(std: :string const& value);\nbool Set(bool value);\nvoid SetNamefstd: :string const& name);\nstd:: string GetName() const;\nint Getlnt();\nfloat GetFloatf);\nstd:: string GetString();\nbool GetBool() ;\n\n\n48 \nSection 1 General Programming\nThe example code shows basic data types being used and stored, although these\ncould be easily expanded to handle any data type. Properties store only a pointer back\nto the original data. Properties do not actually declare their own objects, or allocate\ntheir own memory, so manipulating a property's data results in the original data's\nmemory being handled. Setting a value via the Set function automatically defines the\ntype of the property.\nProperties are constructed and manipulated through a PropertySet class. The\nPropertySet class contains the list of registered properties, the registration methods,\nand the lookup method.\nclass PropertySet\n{\nprotected:\nHashTable<Property>m_properties;\npublic:\nPropertySet();\nvirtual -PropertySet();\nvoid Register(std::string const& name, int* value);\nvoid Register(std::string const& name, float* value);\nvoid Register(std::string const& name, std::string* value);\nvoid Register(std::string const& name, bool* value);\n// look up a property\nProperty* Lookup(std::string const& name);\n// get a list of available properties\nbool SetValue(std::string const& name, std::string* value);\nbool Set(std::string const& name, std::string const& value);\nbool Set(std::string const& name, int value);\nbool Set(std::string const& name, float value);\nbool Set(std::string const& name, bool value);\nbool Set(std::string const& name, char* value);\n};\nThe PropertySet is organized around a HashTable object that organizes all of the\nstored properties using a standard hash table algorithm. The HashTable itself is a tem-\nplate that can be used to hash into different objects, and is included on the compan-\nONIHfCD \n• \nf^r-~.\nion UJ.\nWe derive the game object from the PropertySet class:\nclass GameObject : public PropertySet\n{\nint \nm_test;\n};\nAny properties or flags that need to be publicly exposed or used by other objects\nshould be registered, usually at construction time. For example:\nRegister(\"test_value\",&m_test);\n\n\n1.7 A Property Class for Generic C++ Member Access \n49\nCalling objects can use the Lookup method to access the registered data.\nvoid Update(PropertySet& property_set)\n{\nProperty* test_value_property=\nproperty_set.Lookup(\"test_value\");\nint test_value = test_value_property->GetInt();\n// etc\n}\nAs all of the game objects are now of type PropertySet, and as all objects are usu-\nally stored in a master update list, it is a simple matter of handing the list pointer off\nto the in-game editor for processing. New derived object types simply have to register\ntheir additional properties to be handled by the editor. No additional coding is neces-\nsary because the editor is not concerned with the derived types. It is sometimes help-\nful to specify the type in a property name (such as \"Type\") to assist the user when\nvisually editing the object. It's also useful to make the property required, so that the\neditor could, for example, parse the property list into a \"tree\" style display.\nThis process also provides the additional benefit of decoupling the data from its\nname. For instance, internally, the data may be referred to as m_colour, but can be\nexposed as \"color.\"\nAdditional Uses\nThese classes were designed around a concentric ring design theory. The PropertySet\ncannot be used without the Property class. However, the Property class can be used on\nits own, or with another set type (for example, MultiMatrixedPropertySef) without\nrewriting the Property class itself. This is true of the HashTable inside the PropertySet\nclass as well. Smaller classes with distinct and well-defined purposes and uses are much\nmore reusable than large classes with many methods to handle every possible use.\nThe Property class can also be used to publicly expose methods that can be called\nfrom outside code via function pointers. With a small amount of additional coding,\nthis can also be used as a save state for a save game feature as well. It could also be used\nfor object messaging via networks. With the addition of a Send(std::string xml) and\nReceive(std::stringxml), the PropertySet could easily encode and decode XML messages\nthat contain the property values, or property values that need to be changed. The\nProperty!PropertySet classes could also be rewritten as templates to support different\nproperty types.\nIsolating the property data using \"get\" and \"set\" methods will allow for format\nconversion to and from the internal stored format. This will free the using code from\nneeding to know anything about the data type of the property, making it more versa-\ntile at the cost of a small speed hit when the types differ.\n\n\n50 \nSection 1 General Programming\nAdditional Reading\nFowler, Martin, Kent Beck, John Brant, William Opdyke, Don Roberts, Refactoring,\nAddison-Wesley, ISBN: 0201485672.\nGamma, Erich, Richard Helm, Ralph Johnson, John Vlissides, Grady Booch, Design\nPatterns, Addison-Wesley, ISBN: 0201633612.\nLakos, John, Large-Scale C++ Software Design, Addison-Wesley, ISBN: 0201633620.\nMcConnell, Steve C., Code Complete: A Practical Handbook of Software Construction,\nMicrosoft Press, ISBN: 1556154844 (anything by McConnell is good).\nMeyers, Scott, Effective C++: 50 Specific Ways to Improve Your Programs and Design\n(2ndEdition), Addison-Wesley, ISBN: 0201924889.\nMeyers, Scott, More Effective C++: 35 New Ways to Improve Your Programs and\nDesigns, Addison-Wesley, ISBN: 020163371X.\n\n\n1.8\nA Game Entity Factory\nFrangois Dominic Laramee\nfrancoislaramee@videotron.ca\nI\nn recent years, scripting languages have proven invaluable to the game development\ncommunity. By isolating the elaboration and refinement of game entity behavior\nfrom the core of the code base, they have liberated level designers from the code-\ncompile-execute cycle, speeding up game testing and tweaking by orders of magni-\ntude, and freed senior programmers' time for more intricate assignments.\nHowever, for the data-driven development paradigm to work well, the game's\nengine must provide flexible entity construction and assembly services, so that the\nscripting language can provide individual entities with different operational strategies,\nreaction behaviors, and other parameters. This is the purpose of this gem: to describe\na hierarchy of C++ classes and a set of techniques that support data-driven develop-\nment on the engine side of things.\nThis simple framework was designed with the following goals in mind:\n• A separation of logical behavior and audio-visual behavior. A single Door class\ncan support however many variations of the concept as required, without concern\nfor size, number of key frames in animation sequences, etc.\n• Rapid development. Once a basic library of behaviors has been defined (which\ntakes surprisingly little time), new game entity classes can be added to the frame-\nwork with a minimum of new code, often in 15 minutes or less.\n• Avoiding code duplication. By assembling bits and pieces of behavior into new\nentities at runtime, the framework avoids the \"code bloat\" associated with script-\ning languages that compile to C/C++, for example.\nSeveral of the techniques in this gem are described in terms of patterns, detailed\nin the so-called \"Gang of Four's\" book Design Patterns [GoF94].\nComponents\nThe gem is built around three major components: flyweight objects, behavioral\nclasses and an object factory method. We will examine each in turn, and then look at\nhow they work together to equip the engine with the services required by data-driven\ndevelopment. Finally, we will discuss advanced ideas to make the system even more\n51\n\n\n52 \nSection 1 General Programming\nflexible (at the cost of some code complexity) if a full-fledged scripting language is\nrequired by the project.\nFlyweight, Behavior, and Exported Classes\nBefore we go any further, we must make a distinction between the three types of\n\"classes\" to which a game entity will belong in this framework: its flyweight, behav-\nioral, and exported classes.\n• The flyweight class is the look and feel of the entity. In the code, the relationship\nbetween an entity and its flyweight class is implemented through object composi-\ntion: the entity owns a pointer to a flyweight that it uses to represent itself audio-\nvisually.\n• The behavioral class defines how the object interacts with the rest of the game\nworld. Behavioral classes are implemented as a traditional inheritance hierarchy,\nwith class Entity serving as abstract superclass for all others.\n• The exported class is how the object represents itself to the world. More of a con-\nvenience than a requirement, the exported class is implemented as an enum con-\nstant and allows an entity to advertise itself as several different object classes\nduring its lifetime.\nLet us now look at each in turn.\nFlyweight Objects\n[GoF94] describes flyweights as objects deprived of their context so that they can be\nshared and used in a variety of situations simultaneously; in other words, as a template\nor model for other objects. For a game entity, the flyweight-friendly information con-\nsists of:\n• Media content: Sound effects, 3D models, textures, animation files, etc.\n• Control structure: Finite state machine definition, scripts, and the like.\nAs you can see, this is just about everything except information on the current\nstatus of the entity (position, health, FSM state). Therefore, in a gaming context, the\n\\&iv\\ fly weight is rather unfortunate, because the flyweight can consume megabytes of\nmemory, while the context information would be small enough to fit within a crip-\npled toaster's core memory.\nSAMMy, Where Are You?\nMuch of a game entity's finite state machine deals with animation loops, deciding\nwhen to play a sound byte, and so forth. For example, after the player character is\nkilled in an arcade game, it may enter the resurrecting state and be flagged as invulner-\nable while the \"resurrection\" animation plays out; otherwise, an overeager monster\n\n\n1 .8 A Game Entity Factory \n53\nmight hover about and score another kill during every frame of animation until the\nplayer resumes control over it. I call the part of the flyweight object that deals with\nthis the State And Media Manager, or SAMMy for short:\nclass StateAndMediaManager\n{\n// The various animation sequences available for the family\n//of entities\nAnimSequenceDescriptionStruct * sequences;\nint numAnimSequences;\n// A table of animation sequences to fire up when the entity's FSM\n// changes states out of SAMMy 's control\nint * stateToAnimTransitions;\nint numStateToAnimTransitions;\npublic:\n// Construction and destruction\n// StateAndMediaManager is always constructed by its owner entity,\n// which is in charge of opening its description file. Therefore,\n// the only parameter the constructor needs is a reference to an\n// input stream from which to read a set of animation sequence\n// descriptions.\nStateAndMediaManager () : sequences( 0 ), numAnimSequences ( 0 ),\nnumStateToAnimTransitions ( 0 ), stateToAnimTransitions ( 0 ) {}\nStateAndMediaManager ( istream & is ) ;\nvirtual -StateAndMediaManager () ;\nvoid Cleanup() ;\n// Input-output functions\nvoid Load( istream & is ) ;\nvoid Save( ostream & os ) ;\n// Look at an entity's current situation and update it according\n// to the description of its animation sequences\nvoid FC UpdateEntityStatef EntityStateStruct * state );\n// If the entity's FSM has just forced a change of state, the media\n// manager must follow suit, interrupt its current animation\n// sequence and choose a new one suitable to the new FSM state\nvoid FC AlignWithNewFSMState( EntityStateStruct * state );\n};\nTypically, SAMMy is the product of an entity-crafting tool, and it is loaded into\n(-*-^_^ the engine from a file when needed. The sample on the companion CD-ROM is built\nON mat\nSAMMy can be made as powerful and versatile as desired. In theory, SAMMy\ncould take care of all control functions: launching scripts, changing strategies, and so\nforth. However, this would be very awkward and require enormous effort; we will\ninstead choose to delegate most of the high-level control structure to the behavioral\nclass hierarchy, which can take care of it with a minute amount of code. (As a side\n\n\n54 \nSection 1 General Programming\neffect of this sharing of duties, a single behavioral class like SecurityGuard, Door or\nExplosionFX will be able to handle entities based on multiple related flyweights, mak-\ning the system more flexible.)\nBehavioral Class Hierarchy\nThese are the actual C++ classes to which our entities will belong. The hierarchy has\n(at least) two levels:\n• An abstract base class Entity that defines the interface and commonalities\n• Concrete subclasses that derive from Entity and implement actual objects\nHere is a look at Entity's interface:\nclass Entity\n{\n// Some application-specific data\n// Flyweight and Exported Class information\nint exportedClassID;\nStateAndMediaManager * sammy;\npublic:\n// Constructors\n// Accessors\nint GetExportedClass() { return exportedClassID; }\nStateAndMediaManager * GetFlyweight() { return sammy; }\nvoid SetExportedClass( int newval ) { exportedClassID = newval; }\nvoid SetFlyweight( StateAndMediaManager * ns ) { sammy = ns; }\n// Factory method\nstatic Entity * EntityFactory( int exportedClassRequested );\nvirtual Entity * CloneEntityO = 0;\nvirtual bool Updateself()\n{\n//Do generic stuff here; looping through animations, etc.\nreturn true;\n}\nvirtual bool Handlelnteractions( Entity * target ) = 0;\n};\nAs you can see, adding a new class to the hierarchy may require very little work:\nin addition to constructors, at most three, and possibly only two, of the base class\nmethods must be overridden—and one of them is a one-liner.\n• Clone () is a simple redirection call to the copy constructor.\n• UpdateSelf () runs the entity's internal mechanics. For some, this may be as sim-\nple as calling the corresponding method in SAMMy to update the current anima-\ntion frame; for others, like the player character, it can be far more elaborate.\n\n\n1.8 A Game Entity Factory \n55\n• Handlelnteractions() is called when the entity is supposed to determine\nwhether it should change its internal state in accordance to the behaviors and\npositions of other objects. The default implementation is empty; in other words,\nthe object is inert window-dressing.\n'\\^_^J \nThe companion CD-ROM contains examples of Entity subclasses, including one\nm m co \nof a player character driver.\nUsing the Template Method Pattern for\nBehavior Assignment\nIf your game features several related behavioral classes whose differences are easy to\ncircumscribe, you may be able to benefit from a technique known as the Template\nMethod pattern [GoF94]. This consists of a base class method that defines an algo-\nrithm in terms of subclass methods it calls through polymorphism.\nFor example, all types of PlayerEntity objects will need to query an input device\nand move themselves as part of their UpdateSelf () method, but how they do it may\ndepend on the input device being used, the character type (a FleetingRogue walks\nfaster than a OneLeggedBuddha), and so forth. Therefore, the PlayerEntity class may\ndefine UpdateSelf () in terms of pure virtual methods implemented only in its sub-\nclasses.\nclass PlayerDevice : public Entity\n{\n// ...\nvoid UpdateYourself();\nvoid QuerylnputDeviceO = 0; // No implementation in PlayerDevice\n};\nclass JoystickPlayerDevice : public PlayerDevice\n{\n// ...\nvoid QuerylnputDeviceO;\n};\nvoid PlayerDevice::UpdateYourself()\n{\n//do stuff common to all types of player devices\nQuerylnputDeviceO;\n//do more stuff\n}\nvoid JoystickPlayerDevice::QueryInputDevice()\n{\n//Do the actual work\n}\nUsed properly, the Template Method pattern can help minimize the need for the\ndreaded cut-and-paste programming, one of the most powerful \"anti-patterns\" leading\nto disaster in software engineering [Brown98]!\n",
      "page_number": 42,
      "chapter_number": 6,
      "summary": "Borland's C++ Builder provides an excellent C++ declaration type called ^prop-\nerty that does this very thing, but alas, it is a proprietary extension and unusable out-\nside of Borland C++ Key topics include classes, object, and void.",
      "keywords": [
        "string const",
        "Property",
        "Property Class",
        "Entity",
        "string",
        "std",
        "Game Entity",
        "bool Set",
        "Game Entity Factory",
        "Game",
        "const",
        "object",
        "bool",
        "void",
        "Dynamic Type Information"
      ],
      "concepts": [
        "classes",
        "object",
        "void",
        "entity",
        "entities",
        "property",
        "properties",
        "code",
        "coding",
        "type"
      ],
      "similar_chapters": [
        {
          "book": "More Effective C++",
          "chapter": 3,
          "title": "Segment 3 (pages 17-24)",
          "relevance_score": 0.54,
          "method": "sentence_transformers"
        },
        {
          "book": "C++ Templates_ The Complete Guide",
          "chapter": 19,
          "title": "Segment 19 (pages 584-615)",
          "relevance_score": 0.5,
          "method": "sentence_transformers"
        },
        {
          "book": "Effective_Modern_C++",
          "chapter": 4,
          "title": "Segment 4 (pages 25-35)",
          "relevance_score": 0.5,
          "method": "sentence_transformers"
        },
        {
          "book": "Effective_Modern_C++",
          "chapter": 8,
          "title": "Segment 8 (pages 81-89)",
          "relevance_score": 0.5,
          "method": "sentence_transformers"
        },
        {
          "book": "C++ Templates_ The Complete Guide",
          "chapter": 63,
          "title": "Segment 63 (pages 2016-2049)",
          "relevance_score": 0.49,
          "method": "sentence_transformers"
        }
      ]
    },
    {
      "number": 7,
      "title": "Segment 7 (pages 53-62)",
      "start_page": 53,
      "end_page": 62,
      "detection_method": "topic_boundary",
      "content": "56 \nSection 1 General Programming\nExported Classes\nThe exported class is a convenience trick that you can use to make your entities' inter-\nnal state information transparent to the script writer. For example, let's say that you\nare programming Pac-Man's Handlelnteractions( ) method. You might start by look-\ning for a collision with one of the ghosts; what happens if one is found then depends\non whether the ghost is afraid (it gets eaten), returning to base after being eaten\n(nothing happens at all), or hunting (Pac-Man dies).\nvoid PacMan: :HandleInteractions( Entity * target )\n{\nif ( target ->GetClass() == GHOST && target ->GetState() == AFRAID )\n{\nscore += 100;\ntarget ->SendKillSignal( ) ;\nHowever, what if you need to add states to the Ghost object? For example, you\nmay want the ghost's SAMMy to include a \"Getting Scared\" animation loop, which is\nactive for one second once Pac-Man has run over a power pill. SAMMy would handle\nthis cleanly if you added a GettingScared state. However, you would now need to add\na test for the GettingScared state to the event handler.\nvoid PacMan: :HandleInteractions( Entity * target )\n{\nif ( target ->GetClass() == GHOST &&\n( target->GetState() == AFRAID ||\ntarget ->GetState() == GETTINGSCARED ) )\nThis is awkward, and would likely result in any number of updates to the event\nhandlers as you add states (none of which introduce anything new from the outside\nworld's perspective) to SAMMy during production. Instead, let's introduce the con-\ncept of the exported class, a value that can be queried from an Entity object and\ndescribes how it advertises itself to the world. The value is maintained within Update -\nSelf () and can take any number of forms; for simplicity's sake, let's pick an integer\nconstant selected from an enum list.\nenum { SCAREDGHOST, ACTIVEGHOST, DEADGHOST };\nThere is no need to export any information on transient, animation-related states\nlike GettingScared. To Pac-Man, a ghost can be dead, active, or scared — period.\nWhether it has just become scared two frames ago, has been completely terrified for a\nwhile, or is slowly gathering its wits back around itself is irrelevant. By using an\nexported class instead of an actual internal FSM state, a Ghost object can advertise\n\n\n1.8 A Game Entity Factory \n57\nitself as a dead ghost, scared ghost, or active ghost, effectively shape-shifting into three\ndifferent entity classes at will from the outside world's perspective, all for the cost of\nan integer. Pac-Man's interaction handler would now look like this:\nvoid PacMan: :HandleInteractions( Entity * target )\n{\nif ( target ->GetExportedClass() == SCAREDGHOST )\n{\nscore += 100;\ntarget->SendKillSignal() \n;\nThe result is cleaner and will require far less maintenance work, as the number of\npossible exported classes for an Entity is usually small and easy to determine early on,\nwhile SAMMy's FSM can grow organically as new looks and effects are added to the\nobject during development.\nThe Entity Factory\nNow that we have all of these tools, it is time to put them to good use in object creation.\nA level file will contain several entity declarations, each of which may identify the\nentity's behavioral class, flyweight class, exported class, starting position and velocity,\nand any number of class-specific parameters (for example, hit points for monsters, a\nstarting timer for a bomb, a capacity for the players inventory, etc.) To keep things\nsimpler for us and for the level designer, let's make the fairly safe assumption that,\nwhile a behavioral class may advertise itself as any number of exported classes, an\nexported class can only be attached to a single behavioral class. This way, we eliminate\nthe need to specify the behavioral class in the level file, and isolate the class hierarchy\nfrom the tools and level designers. A snippet from a level file could therefore look like:\n<ENTITY Blinky>\n<EXPORTEDCLASS ActiveGhOSt>\n<XYZ_POSITION \n...>\nPARAMETERS \n...>\n</ENTITY>\nNow, let's add a factory method to the Entity class.\nA factory is a function whose job consists of constructing instances of any num-\nber of classes of objects on demand; in our case, the factory will handle requests for all\n(concrete) members of the behavioral class hierarchy. Programmatically, our factory\nmethod is very simple:\n• It owns a registry that describes the flyweights that have already been loaded into\nthe game and a list of the exported classes that belong to each behavioral class.\n• It loads flyweights when needed. If a request for an instance belonging to a fly-\nweight class that hasn't been seen yet is received, the first order of business is to\ncreate and load a SAMMy object for this flyweight.\n\n\n58 \nSection 1 General Programming\n• If the request is for an additional instance of an already-loaded flyweight class, the\nfactory will clone the existing object (which now serves as a Prototype; yes, another\nGang of Four pattern!) so that it and its new brother can share flyweights effec-\ntively.\nHere is a snippet from the method:\nEntity * Entity::EntityFactory( int whichType )\n{\nEntity * ptr;\nswitch( whichType )\n{\ncase SCAREDGHOST:\nptr = new Ghost( SCAREDGHOST );\nbreak;\ncase ACTIVEGHOST:\nptr = new Ghost( ACTIVEGHOST );\nbreak;\nreturn ptr;\nSimple, right? Calling the method with an exported class as parameter returns a\npointer to an Entity subclass of the appropriate behavioral family.\nEntity * newEntity = Entity::EntityFactory( ACTIVEGHOST );\nThe code located on the companion CD-ROM also implements a simple trick\nused to load levels from standard text files: an entity's constructor receives the level file\nuimca \n^ an jstream parameter, and it can read its own class-specific parameters directly from\nit. The factory method therefore does not need to know anything about the internals\nof the subclasses it is responsible for creating.\nSelecting Strategies at Runtime\nThe techniques described so far work fine when a game contains a small number of\nbehavioral classes, or when entity actions are easy enough to define without scripts.\nHowever, what if extensive tweaking and experimentation with scripts is required?\nWhat if you need a way to change an entity's strategy at runtime, without necessarily\ninfluencing its behavioral classmates? This is where the Strategy pattern comes into\nplay. (It's the last one, I promise. I think.)\nLet's assume that your script compiler produces C code. What you need is a way\nto connect the C function created by the compiler with your behavioral class (or indi-\nvidual entity). This is where function pointers come into play.\n\n\n1.8 A Game Entity Factory\nUsing Function Pointers within C++ Classes\nThe simplest and best way to plug a method into a class at runtime is through a func-\ntion pointer. A quick refresher: A C/C++ function pointer is a variable containing a\nmemory address, just like any other pointer, except that the object being pointed to is\na typed function defined by a nameless signature (in other words, a return type and a\nparameter list). Here is an example of a declaration of a pointer to a function taking\ntwo Entity objects and returning a Boolean value:\nbool (*interactPtr) (Entity * source, Entity * target);\nAssuming that there is a function with the appropriate signature in the code, for\nexample:\nbool TypicalRabbitInteractions( Entity * source, Entity * target )\nthen the variable interactPtr can be assigned to it, and the function called by deref-\nerencing the pointer, so that the following snippets are equivalent:\nOk = TypicalRabbitInteractions( BasilTheBunny, BigBadWolf );\nand\ninteractPtr = TypicalRabbitlnteractions;\nOk = (*interactPtr) ( BasilTheBunny, BigBadWolf );\nUsing function pointers inside classes is a little trickier, but not by much. The key\nidea is to declare the function generated by the script compiler to be a friend of the\nclass, so that it can access its private data members, and to pass it the special pointer\nthis, which represents the current object, as its first parameter.\nclass SomeEntity : public Entity\n{\n// The function pointer\nvoid ( * friendptr )( Entity * me, Entity * target );\npublic:\n// Declare one or more strategy functions as friends,\nfriend void Strategy! ( Entity * me, Entity * target );\n// The actual operation\nvoid Handlelnteractions( Entity * target )\n{\n(*friendptr) ( this, target );\n\n\n60 \nSection 1 General Programming\nBasically, this is equivalent to doing by hand what the C++ compiler does for you\nwhen calling class methods: the C++ viable secretly adds \"this\" as a first parameter to\nevery method. Because any modern compiler will inline the function calls, there\nshould be no performance differential between calling a compiled script with this\nscheme and calling a regular method.\nNote that picking and choosing strategies at runtime through function pointers is\nalso a good way to reduce the number of behavioral classes in the hierarchy. In\nextreme cases, a single Entity class containing nothing but function pointer derefer-\nences for strategy elements may even be able to replace the entire hierarchy. This,\nhowever, runs the risk of obfuscating the code to a point of total opacity—proceed\nwith caution.\nFinally, if an entity is allowed to switch back and forth between several alternative\nstrategies depending on runtime considerations, this scheme allows each change to be\nimplemented through a simple pointer assignment: clean, fast, no hassles.\nFinal Notes\nIn simple cases, the techniques described in this gem can even provide a satisfactory\nalternative to scripting altogether. Smaller projects that do not require the full power\nof a scripting language and/or cannot afford the costs associated with it may be able to\nget by with a set of hard-coded strategy snippets, a simple GUI-based SAMMy editor,\nand a linear level-description file format containing key-value tuples for the behaviors\nattached to each entity.\n<EntityName BasilTheBunny>\n<ExportedClass Rabbit>\n<StrategyVsEntity BigBadWolf Avoid>\n<HandleCollision BigBadWolf Die>\n• i •\nThe companion CD-ROM contains several component classes and examples of\nthe techniques described in this gem. You will, however, have to make significant\nON THE co \nmodifications to them (for example, add your own 3D models to SAMMy) to turn\nthem into something useful in your own projects.\nFinally, the text file formats used to load SAMMy and other objects in the code\nare assumed to be the output of a script compiler, level editor, or other associated\ntools. As such, they have a rather inflexible structure and are not particularly human\nfriendly. If they seem like gibberish to you, gentle readers, please take a moment to\ncommiserate with the poor author who had to write and edit them by hand. ;-)\nReferences\n[Brown98] Brown, W.H., Malveau, R.C., McCormick III, H.W., Mowbray, T.J.,\nAnti Patterns: Refactoring Software, Architectures and Projects in Crisis, Wiley Com-\nputer Publishing, 1998.\n\n\n1.8 A Game Entity Factory \n61\n[GoF94] Gamma, E., Helm, R., Johnson, R., & Vlissides, J. (1994), Design Patterns:\nElements of Reusable Object—Oriented Software, Addison-Wesley, \n1994.\n[Rising98] Rising, L. ed., The Patterns Handbook: Techniques, Strategies and Applica-\ntions, Cambridge University Press, 1998.\n\n\n1.9\nAdding Deprecation Facilities\nto C++\nNoel Llopis, Meyer/Glass Interactive\nnllopis@mgigames.com\n*\nuring the lifetime of a piece of software, function interfaces are bound to change,\nbecome outdated, or be completely replaced by new ones. This is especially true\nfor libraries and engines that are reused across multiple projects or over several years.\nWhen a function that interfaces to the rest of the project changes, the game (or tools,\nor both!) may not compile any more. On a team working on a large project, the situa-\ntion is even worse because many people could be breaking interfaces much more often.\nPossible Solutions\nThere are different ways of dealing with this situation:\n• Don't do anything about it. Every time something changes, everybody has to\nupdate the code that calls the changed functions before work can proceed. This\nmight be fine for a one-person team, but it's normally unacceptable for larger teams.\n• Don't change any interface functions. This is not usually possible, especially in\nthe game industry where things change so quickly. Maybe the hardware changed,\nmaybe the publisher wants something new, or perhaps the initial interface was\njust flawed. Trying to stick to this approach usually causes more harm than good,\nand ends up resulting in functions or classes with names completely unrelated to\nwhat they really do, and completely overloaded semantics.\n• Create new interface versions. This approach sticks to the idea that an interface\nwill never change; instead, a new interface will be created addressing all the issues.\nBoth the original and the new interface will remain in the project. This is what\nDirectX does with each new version. This approach might be fine for complete\nchanges in interface, or for infrequent updates, but it won't work well for frequent\nor minor updates. In addition, this approach usually requires maintaining the full\nimplementation of the current interface and a number of the older interfaces,\nwhich can be a nightmare.\nIn modern game development, these solutions are clearly not ideal. We need\nsomething else to deal with this problem.\n62\n\n\n1.9 Adding Deprecation Facilities to C++ \n63\nThe Ideal Solution\nWhat we really want is to be able to write a new interface function, but keep the old\ninterface function around for a while. Then the rest of the team can start using the\nnew function right away. They may change their old code to use the new function\nwhenever they can, and, after a while, when nobody is using it anymore, the old func-\ntion can be removed.\nThe problem with this is how to let everybody know which functions have\nchanged and which functions they are supposed to use. Even if we always tell them\nthis, how are they going to remember it if everything compiles and runs correctly?\nThis is where deprecating a function comes in. We write the new function, and then\nflag the old function as deprecated. Then, every time the old function is used, the\ncompiler will generate a message explaining that a deprecated function is being called\nand mentioning which function should be used in its place.\nUsing and Assigning Deprecated Functions\nJava has a built-in way to do exactly what we want. However, most commercial games\nthese days seem to be written mostly using C++, and unfortunately C++ doesn't con-\ntain any deprecation facilities. The rest of this gem describes a solution implemented\nin C++ to flag specific functions as deprecated.\nLet's start with an example of how to use it. Say we have a function that every-\nbody is using called FunctionAQ. Unfortunately, months later, we realize that the\ninterface of FunctionAQ has to change, so we write a new function called NeivFunc-\ntionAQ. By adding just one line, we can flag FunctionAQ as deprecated.\nint FunctionA ( void )\n{\nDEPRECATE ( \"FunctionA()\", \"NewFunctionA()\" )\n// Implementation\n}\nint NewFunctionA ( void )\n{\n// Implementation\n}\nThe line DEPRECATE(\"FunctionA()\", \"NewFunctionAQ\") indicates that Func-\ntionAQ is deprecated, and that it has been replaced with NewFunctionAQ.\nThe users of FunctionAQ don't have to do anything special at all. Whenever users\nuse FunctionA() they will get the following message in the debug window when they\nexit the program:\nWARNING. You are using the following deprecated functions:\n- Function FunctionA() called from 3 different places.\nInstead use NewFunctionA().\n\n\n64 \nSection 1 General Programming\nImplementing Deprecation in C++\nEverything is implemented in one simple singleton class [Gamma95]: Deprecation-\nMgr. The full source code for the class along with an example program is included on\n(^rs*- >^; j \nthe companion CD-ROM. In its simplest form, all DeprecationMgr does is keep a list\nonma> \nof the deprecated functions found so far. Whenever the singleton is destroyed (which\nhappens automatically when the program exits), the destructor prints out a report in\nthe debug window, listing what deprecated functions were used in that session.\nclass DeprecationMgr\n{\npublic:\nstatic DeprecationMgr * Getlnstance ( void ) ;\n-DeprecationMgr ( void );\nbool AddDeprecatedFunction (const char * OldFunctionName,\nconst char * NewFunctionName,\nunsigned int CalledFrom ) ;\n// Rest of the declaration here\nUsually, we won't have to deal with this class directly because the DEPRECATE\nmacro will do all of the work for us.\n#ifdef _DEBUG\n#define DEPRECATE ( a, b) { \\\nvoid * fptr; \n\\\n_asm { mov fptr, ebp } \n\\\nDeprecationMgr: :GetInstance()->AddDeprecatedFunction(a, b, fptr);\n\\\n}\n#else\n#define DEPRECATE(a,b)\n#endif\nIgnoring the first few lines, all the DEPRECATE macro does is get an instance to\nthe DeprecationMgr and add the function that is being executed to the list. Because\nDeprecationMgr is a singleton that won't be instantiated until the GetlmtanceQ func-\ntion is called, if there are no deprecated functions, it will never be created and it will\nnever print any reports at the end of the program execution. Internally, Deprecation-\nMgr keeps a small structure for each deprecated function, indexed by the function\nname through an STL map collection. Only the first call to a deprecated function will\ninsert a new entry in the map.\nThe DeprecationMgr class has one more little perk: it will keep track of the num-\nber of different places from which each deprecated function was called. This is useful\nso we know at a glance how many places in the code we need to change when we\ndecide to stop using the deprecated function. Unfortunately, because this trick uses\nassembly directly, it is platform specific and only works on the x86 family of CPUs.\nThe first two lines of the DEPRECATE macro get the EBP register (from which it is\nusually possible to retrieve the return address), and pass it on to AddDeprecatedFunc-\n\n\n1.9 Adding Deprecation Facilities to C++ \n65\ntionQ. Then, if a function is called multiple times from the same place (in a loop for\nexample), it will only be reported as being called from one place.\nThere is a potential problem with this approach for obtaining the return address.\nTypically, the address [EBP-4] contains the return address for the current function.\nHowever, under some circumstances the compiler might not set the register EBP to its\nexpected value. In particular, this happens under VC++ 6.0, when compiler optimiza-\ntions are turned on, for particularly simple functions. In this case, trying to read from\n[EBP-4] will either return an incorrect value or crash the program. There will be no\nproblems in release mode, which is when optimizations are normally turned on,\nbecause the macro does no work. However, sometimes optimizations are also used in\ndebug mode, so inside the function AddDeprecatedFunctionQ we only try to read the\nreturn address if the address contained in [EBP-4] is readable by the current process.\nThis is accomplished by either using exception handling or calling the Windows-\nspecific function IsBadReadPtrQ. This will produce an incorrect count of functions\nthat deprecated functions were called from when optimizations are turned on, but at\nleast it won't cause the program to crash, and all the other functionality of the depre-\ncation manager will still work correctly.\nWhat Could Be Improved?\nOne major problem remains: the deprecation warnings are generated at runtime, not\nat compile or link time. This is necessary because the deprecated functions may exist\nin a separate library, rather than in the code that is being compiled. The main draw-\nback of only reporting the deprecated functions at runtime is that it is possible for the\nprogram to still be using a deprecated function that gets called rarely enough that it\nnever gets noticed. The use of the deprecated function might not be detected until it\nis finally removed and the compiler reports an error.\nAcknowledgments\nI would like to thank David McKibbin for reviewing this gem, and for identifying the\nproblems caused by compiler optimizations and finding a workaround.\nReferences\n[Gamma95] Gamma, Eric, et al, Design Patterns, Addison-Wesley. 1995.\n[Rose] Rose, John, \"How and When to Deprecate APIs,\" available online at\njava.sun.com/products/jdk/1.1 /docs/guide/misc/deprecation/deprecation.html.\n",
      "page_number": 53,
      "chapter_number": 7,
      "summary": "This chapter covers segment 7 (pages 53-62). Key topics include entities, entity, and function. Covers function. For example, let's say that you\nare programming Pac-Man's Handlelnteractions( ) method.",
      "keywords": [
        "Entity",
        "function",
        "Game Entity Factory",
        "Deprecated Functions",
        "Entity Factory",
        "functions",
        "deprecated",
        "Game Entity",
        "target",
        "Entity class",
        "ghost",
        "behavioral class",
        "entity behavioral class",
        "function pointers",
        "exported class"
      ],
      "concepts": [
        "entities",
        "entity",
        "function",
        "functions",
        "functionality",
        "classes",
        "deprecation",
        "deprecating",
        "deprecate",
        "void"
      ],
      "similar_chapters": [
        {
          "book": "More Effective C++",
          "chapter": 14,
          "title": "Segment 14 (pages 133-140)",
          "relevance_score": 0.7,
          "method": "sentence_transformers"
        },
        {
          "book": "Python Distilled",
          "chapter": 38,
          "title": "Segment 38 (pages 345-352)",
          "relevance_score": 0.7,
          "method": "sentence_transformers"
        },
        {
          "book": "Generative AI with LangChain_2e",
          "chapter": 27,
          "title": "Segment 27 (pages 222-231)",
          "relevance_score": 0.67,
          "method": "sentence_transformers"
        },
        {
          "book": "Python Distilled",
          "chapter": 14,
          "title": "Segment 14 (pages 116-123)",
          "relevance_score": 0.67,
          "method": "sentence_transformers"
        },
        {
          "book": "Fluent Python 2nd",
          "chapter": 49,
          "title": "Segment 49 (pages 993-1010)",
          "relevance_score": 0.66,
          "method": "sentence_transformers"
        }
      ]
    },
    {
      "number": 8,
      "title": "Segment 8 (pages 63-70)",
      "start_page": 63,
      "end_page": 70,
      "detection_method": "topic_boundary",
      "content": "1.10\nA Drop-in Debug Memory\nManager\nPeter Da/ton, Evans & Sutherland\npdalton@xmission.com\nW\nith the increasing complexity of game programming, the minimum memory\nrequirements for games have skyrocketed. Today's games must effectively deal\nwith the vast amounts of resources required to support graphics, music, video, anima-\ntions, models, networking, and artificial intelligence. As the project grows, so does the\nlikelihood of memory leaks, memory bounds violations, and allocating more memory\nthan is required. This is where a memory manager comes into play. By creating a few\nsimple memory management routines, we will be able to track all dynamically allo-\ncated memory and guide the program toward optimal memory usage.\nOur goal is to ensure a reasonable memory footprint by reporting memory leaks,\ntracking the percentage of allocated memory that is actually used, and alerting die pro-\ngrammer to bounds violations. We will also ensure that die interface to die memory\nmanager is seamless, meaning that it does not require any explicit function calls or class\ndeclarations. We should be able to take diis code and effortlessly plug it into any other\nmodule by including die header file and have everything else fall into place. The disad-\nvantages of creating a memory manager include die overhead time required for die man-\nager to allocate memory, deallocate memory, and interrogate die memory for statistical\ninformation. Thus, this is not an option that we would like to have enabled for the final\nbuild of our game. In order to avoid these pitfalls, we are going to only enable the mem-\nory manager during debug builds, or if the symbol ACTIVATE_MEMORY_MANAGER\nis defined.\nGetting Started\nThe heart of the memory manager centers on overloading the standard new and delete\noperators, as well as using #define to create a few macros that allow us to plug in our\nown routines. By overloading the memory allocation and deallocation routines, we\nwill be able to replace the standard routines with our own memory-tracking module.\nThese routines will log the file and line number on which the allocation is being\nrequested, as well as statistical information.\n66\n\n\n1.10 A Drop-in Debug Memory Manager \n67\nThe first step is to create the overloaded new and delete operators. As mentioned\nearlier, we would like to log the file and line number requesting the memory alloca-\ntion. This information will become priceless when trying to resolve memory leaks,\nbecause we will be able to track the allocation to its roots. Here is what the actual\noverloaded operators will look like:\ninline void*\noperator new(size_t size, const char *file, int line);\ninline void*\noperator new[](size_t size, const char *file, int\nline);\ninline void operator delete( void *address );\ninline void operator delete[]( void *address );\nIt's important to note that both the standard and array versions of the new and\ndelete operators need to be overloaded to ensure proper functionality. While these dec-\nlarations don't look too complex, the problem that now lies before us is getting all of\nthe routines that will use the memory manager to seamlessly pass the new operator the\nadditional parameters. This is where the #define directive comes into play.\n#define new new( FILE , \nLINE )\ntfdefine delete setOwner(_FILE_,_LINE_) .false ? setOwner(\"\",0)\n: delete\n#define \nmalloc(sz) \nAllocateMemory(_FILE_,_LINE_,sz,MM_MALLOC)\ntfdefine calloc(num,sz)\nAllocateMemory(_FILE_1_LINE_,sz*num,MM_CALLOC)\n#define realloc(ptr,sz) AllocateMemory( \nFILE , \nLINE , sz,\nMM_REALLOC, ptr )\ntfdefine free(sz) deAllocateMemory( \nFILE , \nLINE , sz,\nMM_FREE )\nThe #define new statement will replace all new calls with our variation of new that\ntakes as parameters not only the requested size of the allocation, but also the file and\nline number for tracking purposes. Microsoft's Visual C++ compiler provides a set of\npredefined macros, which include our required __FILE_ and \nLINE__ symbols\n[MSDN]. The #define delete macro is a little different from the #define new macro. It\nis not possible to pass additional parameters to the overloaded delete operator without\ncreating syntax problems. Instead, the setOwnerQ method records the file and line\nnumber for later use. Note that it is also important to create the macro as a condi-\ntional to avoid common problems associated with multiple-line macros [DaltonOl].\nFinally, to be complete, we have also replaced the mallocQ, callocQ, reallocQ, and the\nfreeO methods with our own memory allocation and deallocation routines.\nThe implementations for these functions are located on the accompanying CD.\nt \nI \nThe AllocateMemoryO and deAllocateMemoryO routines are solely responsible for all\non m CD \nmemory allocation and deallocation. They also log information pertaining to the\ndesired allocation, and initialize or interrogate the memory, based on the desired\n\n\n68 \nSection 1 General Programming\naction. All this information will then be available to generate the desired statistics to\nanalyze the memory requirements for any given program.\nMemory Manager Logging\nNow that we have provided the necessary framework for replacing the standard mem-\nory allocation routines with our own, we are ready to begin logging. As stated in the\nbeginning of this gem, we will concentrate on memory leaks, bounds violations, and\nthe actual memory requirements. In order to log all of the required information, we\nmust first choose a data structure to hold the information relevant to memory alloca-\ntions. For efficiency and speed, we will use a chained hash table. Each hash table entry\nwill contain the following information:\nstruct MemoryNode\n{\nsize_t \nactualSize;\nsize_t \nreportedSize;\nvoid \n*actualAddress;\nvoid \n*reportedAddress;\nchar \nsourceFile[30];\nunsigned short sourceLine;\nunsigned short \npaddingSize;\nchar \noptions;\nlong \npredefinedBody;\nALLOC_TYPE \nallocationType;\nMemoryNode \n*next, *prev;\n};\nThis structure contains the size of memory allocated not only for the user, but\nalso for the padding applied to the beginning and ending of the allocated block. We\nalso record the type of allocation to protect against allocation/deallocation mis-\nmatches. For example, if the memory was allocated using the new[] operator and deal-\nlocated using the delete operator instead of the delete[] operator, a memory leak may\noccur due to object destructors not being called. Effort has also been taken to mini-\nmize the size of this structure while maintaining maximum flexibility. After all, we\ndon't want to create a memory manager that uses more memory than the actual appli-\ncation being monitored.\nAt this point, we should have all of the information necessary to determine if\nthere are any memory leaks in the program. By creating a MemoryNode within the\nAllocateMemoryO routine and inserting it into the hash table, we will create a history\nof all the allocated memory. Then, by removing the MemoryNode within the deAllo-\ncateMemoryO routine, we will ensure that the hash table only contains a current list-\ning of allocated memory. If upon exiting the program there are any entries left within\nthe hash table, a memory leak has occurred. At this point, the MemoryNode can be\ninterrogated to report the details of the memory leak to the user. As mentioned previ-\nously, within the deAllocateMemoryO routine we will also validate that the method\n\n\n1.10 A Drop-in Debug Memory Manager \n69\nused to allocate the memory matches the deallocation method; if not, we will note the\npotential memory leak.\nNext, let's gather information pertaining to bounds violations. Bounds violations\noccur when applications exceed the memory allocated to them. The most common\nplace where this happens is within loops that access array information. For example, if\nwe allocated an array of size 10, and we accessed array location 11, we would be exceed-\ning the array bounds and overwriting or accessing information that does not belong to\nus. In order to protect against this problem, we are going to provide padding to the front\nand back of the memory allocated. Thus, if a routine requests 5 bytes, the AllocateMem-\noryO routine will actually allocate 5 + sizeofllong)*2*paddmgSize bytes. Note that we are\nusing longs for the padding because they are defined to be 32-bit integers. Next, we must\ninitialize the padding to a predefined value, such as OxDEADCODE. Then, upon deal-\nlocation, if we examine the padding and find any value except for the predefined value,\nwe know that a bounds violation has occurred. At this point, we would interrogate die\ncorresponding MemoryNode and report die bounds violation to the user.\nThe only information remaining to be gathered is the actual memory require-\nment for the program. We would like to know how much memory was allocated, how\nmuch of the allocated memory was actually used, and perhaps peak memory alloca-\ntion information. In order to collect this information we are going to need another\ncontainer. Note that only the relevant members of the class are shown here.\nclass MemoryManager\n{\npublic:\nunsigned int m_totalMemoryAllocations;\nunsigned int m_totalMemoryAllocated; \n//In bytes\nunsigned int m_totalMemoryUsed; \n/ / I n bytes\nunsigned int m_peakMemoryAllocation;\n}|\nWithin the AllocateMemoryO routine, we will be able to update all of the Memo-\nryManager information except for the m_totalMemory Used variable. In order to deter-\nmine how much of the allocated memory is actually used, we will need to perform a\ntrick similar to the method used in determining bounds violations. By initializing the\nmemory within the AllocateMemoryO routine to a predefined value and interrogating\nthe memory upon deallocation, we should be able to get an idea of how much mem-\nory was actually utilized. In order to achieve decent results, we are going to initialize\nthe memory on 32-bit boundaries, once again, using longs. We will also use a prede-\nfined value such as OxBAADCODE for initialization. For all remaining bytes that do\nnot fit within our 32-bit boundaries, we will initialize each byte to OxE or\nstatic_cast<char>(OxBAADCODE). While this method is potentially error prone\nbecause there is no predefined value to which we could initialize the memory and\nensure uniqueness, initializing the memory on 32-bit boundaries will generate far bet-\nter results than initializing on byte boundaries.\n\n\n70 \nSection 1 General Programming\nReporting the Information\nNow that we have all of the statistical information, let's address the issue of how\nwe should report it to the user. The implementation that is included on the CD\nrecords all information to a log file. Once the user has enabled the memory manager\nand run the program, upon termination a log file is generated containing a listing of\nall the memory leaks, bounds violations, and the final statistical report.\nThe only question remaining is: how do we know when the program is terminat-\ning so that we can dump our log information? A simple solution would be to require\nthe programmer to explicitly call the dumpLogReport() routine upon termination.\nHowever, this goes against the requirement of creating a seamless interface. In order\nto determine when the program has terminated without the use of an explicit func-\ntion call, we are going to use a static class instance. The implementation is as follows:\nclass Initialize\n{ public: Initialize() { InitializeMemoryManager(); } };\nstatic Initialize InitMemoryManager;\nbool InitializeMemoryManager() {\nstatic bool hasBeenlnitialized = false;\nif (sjnanager) \nreturn true;\nelse if (hasBeenlnitialized) return false;\nelse {\ns_manager = (MemoryManager*)malloc(sizeof(MemoryManager));\ns_manager->intialize();\natexit( releaseMemoryManager );\nhasBeenlntialized = true;\nreturn true;\n}\n}\nvoid releaseMemoryManager() {\nNumAllocations = sjnanager->m_numAllocations;\ns_manager->release(); \n// Releases the hash table and calls\nfree( sjnanager ); \n// the dumpLogReport() method\nsjnanager = NULL;\n}\nThe problem before us is to ensure that the memory manager is the first object to\nbe created and the very last object to be deallocated. This can be difficult due to the\norder in which objects that are statically defined are handled. For example, if we cre-\nated a static object that allocated dynamic memory within its constructor, before the\nmemory manager object is allocated, the memory manager will not be available for\nmemory tracking. Likewise, if we use the ::atexit() method to call a function that is\nresponsible for releasing allocated memory, the memory manager object will be\nreleased before the ::atexit() method is called, thus resulting in bogus memory leaks.\nIn order to resolve these problems, the following enhancements need to be added.\nFirst, by creating the InitMemoryManager object within the header file of the memory\nmanager, it is guaranteed to be encountered before any static objects are declared.\n\n\n1.10 A Drop-In Debug Memory Manager \n71\nThis holds true as long as we #include that memory manager header before any static\ndefinitions. Microsoft states that static objects are allocated in the order in which they\nare encountered, and are deallocated in the reverse order [MSDN]. Second, to ensure\nthat the memory manager is always available we are going to call the InitializeMemo-\nryManager() routine every time within the AllocateMemoryO and DeallocateMemoryQ\nroutines, guaranteeing that the memory manager is active. Finally, in order to ensure\nthat the memory manager is the last object to be deallocated, we will use the ::atexit()\nmethod. The ::atexit() method works by calling the specified functions in the reverse\norder in which they are passed to the method [MSDN1]. Thus, the only restriction\nthat must be placed on the memory manager is that it is the first method to call the\n::atexit() function. Static objects can still use the ::atexit() method; they just need to\nmake sure that the memory manager is present. If, for any reason, the InitializeMem-\noryManagerQ function returns false, then this last condition has not been met and as a\nresult, the error will be reported in the log file.\nGiven the previous restriction, there are a few things to be aware of when using\nMicrosoft's Visual C++. The ::atexit() method is used extensively by internal VC++\nprocedures in order to clean up on shutdown. For example, the following code will\ncause an ::atexit() to be called, although we would have to check the disassembly to\nsee it.\nvoid Foo() { static std::string s; }\nWhile this is not a problem if the memory manager is active before the declara-\ntion of s is encountered, it is worth noting. Despite this example being completely\nVC++ specific, other compilers might differ or contain additional methods that call\n::atexit() behind the scenes. The key to the solution is to ensure that the memory\nmanager is initialized first.\nThings to Keep in Mind\nBesides the additional memory and time required to perform memory tracking, there\nare a few other details to keep in mind. The first has to deal with syntax errors that\ncan be encountered when #induding other files. In certain situations, it is possible to\ngenerate syntax errors due to other files redefining the new and delete operators. This\nis especially noticeable when using STL implementations. For example, if we #include\n\"MemoryManager.h\"a.nd then #include <map>, we will generate all types of errors. To\nresolve this issue, we are going to be using two additional header files: new_on.h and\nnew_off.h. These headers will simply #define and #undefine the new!'delete macros that\nwere created earlier. The advantage of this method includes the flexibility that we\nachieve by not forcing the user to abide by a particular #include order, and avoids the\ncomplexity when dealing with precompiled headers.\ntfinclude \"new_off.h\"\n#include <map>\n\n\n72 \nSection 1 General Programming\n^include <string>\n#include <A11 other headers overloading the new/delete operators>\n#include \"new_on.h\"\n^include \"MemoryManager.h\" \n// Contains the Memory Manager Module\ntfinclude \"Custom header files\"\nAnother issue we need to address is how to handle libraries that redefine the new\nand delete operators on their own. For example, MFC has its own system in place for\nhandling the new and delete operators [MSDN2]. Thus, we would like to have MFC\nclasses use their own memory manager, and have non-MFC shared game code use our\nmemory manager. We can achieve this by inserting the #indude \"new_off.h\" header\nfile right after the #//2&/'created by the ClassWizard.\n#ifdef _DEBUG\n^include \"new_off.h\" \n// Turn off our memory manager\ntfdefine \nnew \nDEBUG_NEW\ntfundef THIS_FILE\nstatic char THIS_FILE[] = _FILE__;\n#endif\nThis method will allow us to keep the advantages of MFC's memory manager,\nsuch as dumping CC%>rt-derived classes on memory leaks, and still provide the rest\nof the code with a memory manager.\nFinally, keep in mind the requirements for properly implementing'the setOwnerQ\nmethod used by the delete operator. It is necessary to realize that the implementation\nis more complicated than just recording the file and line number; we must create a\nstack implementation. This is a result of the way that we implemented the delete\nmacro. Take, for example, the following:\nFile 1: line 1: class B { B() {a = new int;} ~B() {delete a;} };\nFile 2: line 1: B *objectB = new B;\nFile 2: line 2: delete objects;\nThe order of function calls is as follows:\n1. new( objects, File2, 1\n2. new( a, \nFilel, 1\n3. setOwner( File2, 2 );\n4. setOwner( Filel, 1 );\n5. delete( a );\n6. delete( objects );\nAs should be evident from the preceding listing, by the time the delete operator is\ncalled to deallocate objectB, we will no longer have the file and line number informa-\ntion unless we use a stack implementation. While the solution is straightforward, the\nproblem is not immediately obvious.\n\n\n1.10 A Drop-in Debug Memory Manager \n73\nFurther Enhancements\n, \nc \n, \nWithin the implementation provided on the CD accompanying this book, there are\non m CD \nseveral enhancements to the implementation discussed here. For example, there is the\noption for the user to set flags to perform more comprehensive memory tests.\nOptions also exist for setting breakpoints when memory is deallocated or reallocated\nso that the programs stack can be interrogated. These are but a few of the possibilities\nthat are available. Other enhancements could easily be included, such as allowing a\nprogram to check if any given address is valid. When it comes to memory control, the\noptions are unlimited.\nReferences\n[DaltonOl] Dalton, Peter, \"Inline Functions versus Macros,\" Game Programming\nGems II, Charles River Media. 2001.\n[McConnell93] McConnell, Steve, Code Complete, Microsoft Press. 1993.\n[MSDN1] Microsoft Developer Network Library, http://msdn.microsoft .com/\nIibrary/devprods/vs6/visualc/yclang/_pluslang_initializing_static_objects.htm\n[MSDN2] \nMicrosoft \nDeveloper \nNetwork \nLibrary, \nhttp://msdn.microsoft\n.com/library/devprods/vs6/visualc/vccore/core_memory_management_with_mf\nc.3a_.overview.htm\n[Myers98] Myers, Scott, Effective C++, Second Edition, Addison-Wesley Longmont,\nInc. 1998.\n",
      "page_number": 63,
      "chapter_number": 8,
      "summary": "By creating a few\nsimple memory management routines, we will be able to track all dynamically allo-\ncated memory and guide the program toward optimal memory usage Key topics include memory, information, and files.",
      "keywords": [
        "memory manager",
        "Memory",
        "Debug Memory Manager",
        "Drop-in Debug Memory",
        "Manager",
        "file",
        "memory manager object",
        "memory leaks",
        "Debug Memory",
        "allocated memory",
        "line",
        "delete",
        "MFC memory manager",
        "information",
        "die memory manager"
      ],
      "concepts": [
        "memory",
        "information",
        "files",
        "manager",
        "routines",
        "die",
        "including",
        "include",
        "method",
        "line"
      ],
      "similar_chapters": [
        {
          "book": "operating_systems_three_easy_pieces",
          "chapter": 17,
          "title": "Segment 17 (pages 154-161)",
          "relevance_score": 0.66,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 7",
          "chapter": 6,
          "title": "Segment 6 (pages 48-56)",
          "relevance_score": 0.65,
          "method": "sentence_transformers"
        },
        {
          "book": "operating_systems_three_easy_pieces",
          "chapter": 21,
          "title": "Segment 21 (pages 193-203)",
          "relevance_score": 0.63,
          "method": "sentence_transformers"
        },
        {
          "book": "Computer Systems A Programmer’s Perspective",
          "chapter": 30,
          "title": "Segment 30 (pages 601-619)",
          "relevance_score": 0.61,
          "method": "sentence_transformers"
        },
        {
          "book": "Computer Systems A Programmer’s Perspective",
          "chapter": 1,
          "title": "Segment 1 (pages 1-20)",
          "relevance_score": 0.6,
          "method": "sentence_transformers"
        }
      ]
    },
    {
      "number": 9,
      "title": "Segment 9 (pages 71-80)",
      "start_page": 71,
      "end_page": 80,
      "detection_method": "topic_boundary",
      "content": "1.11\nA Built-in Game Profiling Module\nJeffEvertt, Lithtech, Inc.\njeff@evertt.com\nT\nhis gem describes the architecture and implementation of a profiling module for\nlow-overhead, real-time analysis that supports performance counter organization\nso that many consumers can work together in harmony. It is designed from a game\nengine perspective, with many of its requirements specifically pertaining to things\ntypically found in games. At the time of this writing, the described module is in use\nby a commercially available game engine.\nProfiling the performance of a game or engine is one of those things that everyone\nagrees is important, but just as often as not guesswork or quick hacks are substituted\nfor a real game system that can gather solid data. In the long run, the time it takes to\nimplement a clean profiling system is a wise investment. And, as with everything else,\nthe earlier we plan for it, the easier it will be.\nProfiling Basics\nThe basic profiling mechanism is simple: take a timestamp at the beginning of the\ncode of interest and again at the end. Subtract the first from the second, and voila,\nthat's how long the code took to run. We need a high-resolution counter - the Win-\ndows multimedia timer and its millisecond resolution will not cut it. If the platform\nis Windows on a PC, there are two high-resolution API calls we can use: QueryPerfor-\nmanceCounter and QueryPerformanceFrequency. However, because the overhead of\nthese functions is fairly high, we will roll our own, which only requires a few lines of\ninline assembly:\nvoid CWin32PerfCounterMgr::GetPerfCounter(\nLARGE_INTEGER SdCounter) {\nDWORD dwLow.dwHigh;\nasm {\nrdtsc\nmov dwLow, eax\nmov dwHigh, edx\n}\niCounter.QuadPart = ((unsigned \nint64)dwHigh « 32)\n| (unsigned \nint64)dwLow; }\n74\n\n\n1.11 A Built-in Game Profiling Module\nTo convert this number into seconds, we need to know the counter frequency. In\nthis case it is equal to the CPU cycles per second. We can measure it once when the\ncounters are enabled — take a time sample, sleep for at least 500ms, and then take\nanother sample. Note that similar counters are available if the target platform is a\ngame console.\nCommercially Available Tools\nPerformance tuning is definitely a case where choosing the right tool for the job can\nmake all the difference. There are many time-tested commercial tools available for the\nPC that sample an application as it runs, then offline allow profile data to be viewed\nmodule-by-module, function-by-function, and just about any other imaginable way.\nIntel® VTune™ and Metrowerks® Analysis Tools both make use of the built-in\nCPU hardware counters to generate post-processed profiles of runtime sections of a\ngame. Tuning assembly code by instruction ordering or pairing prediction is defi-\nnitely a strength of VTune™.\nThe Intel® Graphics Performance Toolkit (GPT) provides some powerful scene\nanalysis tools. It hooks in and snoops traffic at the layer between your application and\nDirect3D/OpenGL. Knowing exactly what is being drawn can at times be very help-\nful. Changing the order or the way in which the game renders can sometimes signifi-\ncantly affect performance. However, the GPT is written to a specific version of\nDirectX, so its releases usually trail that of DirectX. Also, taking any significant scene\ndata will slow down the application, so relying on the performance characteristics of\ndata taken when using the GPT can be dangerous.\nStatistics-gathering drivers for graphics cards and hardware counters can be\ninvaluable. Nvidia releases special drivers and a real-time data viewing application\nthat hooks all of the function entry points of the drivers. If the graphics driver is tak-\ning a significant percentage of CPU time, this application will allow us to look inside\nand break it down further. Intel® provides counters in its drivers and hardware for its\ni740 chip, allowing optimization for stalls all the way down to the graphics chip level.\nSome of the game consoles also provide this ability. It can be very useful, as it is the\nonly way to break down performance at this low level. It does, however, require a fair\namount of knowledge about how the drivers and chips operate, and what the counters\nreally mean.\nWhy Roll Our Own?\nReason one: frame-based analysis. Games typically have a fairly high frame-to-frame\ncoherency, but in just a matter of seconds can drastically change. Imagine a 3D\nshooter—a player starts facing a wall, runs down a long corridor, then ends it all in a\nbloody firefight with five Al-driven enemies. The game engine is running through\nmany potentially different bottlenecks that can only really be identified with a frame-\nby-frame analysis. Looking at a breakdown of an accumulated sample over the entire\n\n\n76 \nSection 1 General Programming\ninterval gives an inaccurate view of what is really going on. Frame-based analysis\nallows focusing on one problem at a time.\nReason two: it can be done anytime and anywhere. At the end of a PC game\ndevelopment cycle, someone will probably be faced with performance problems that\nonly manifest themselves on someone's brother's machine, on odd Tuesdays. There\nare typically a significant number of these types of problems. They can cost a lot of\ntime and can very easily slip the release date. Although this type of problem is unique\nto PC games, console games still have to deal with the \"shooting a missile in the cor-\nner of level three grinds the game to a slow crawl\" types of problems. Once the prob-\nlem is understood, figuring out the solution is usually the easy part. If we could walk\nover to that test machine and pop up a few counter groups, we would quickly nail\ndown the culprit.\nReason three: customizability. Modern game engines are complicated. The ability\nto ignore all the other modules in the engine except for the one being working on is\npowerful. In addition, the only person that can organize the data exactly how they\nwant it is the engineer actually doing the work.\nProfile Module Requirements\nRequirement one: allow users to quickly and accurately profile the application.\nRequirement two: be non-obtrusive (that is, have very low overhead). When the\ncost for taking samples and displaying the results becomes a significant portion of die\nframe time, it can actually change the application's behavior within the system. In gen-\neral, slowing down the CPU will tend to hide stalls caused by graphics cards. While\neven a very small percentage can in some rare cases drastically change game perfor-\nmance, as a general rule, when the profiler is enabled, it should take less than five per-\ncent of the total CPU cycles. When disabled, it should be much less dian one percent.\nRequirement three: allow multiple users to work independently on their respec-\ntive systems without having to worry about other engine modules.\nRequirement four: when it's not needed, it should be well out of the way.\nArchitecture and Implementation\nA performance counter manager (IPerfCounterMan) keeps track of all active and inac-\ntive counters. The counters are organized into groups of similar type (for example,\nmodel render, world render, AI, physics) that are enabled and disabled together. This\nsupports the notion of multiple groups working independently in an easy to under-\nstand grouping concept. Groups are useful for two reasons: for quickly determining if\na counter needs to be sampled, and for enabling and disabling groups of counters to\nbe displayed. We will make use of four-character codes (FourCC's) for the group ID\nand full text strings for counter names.\nThe entire system is organized into a module with an interface to the rest of the\nsystem. The basic component is a counter that is identified by a group ID (its\n\n\n1.11 A Built-in Game Profiling Module \nJ77\nFourCC) and its string name. Each counter is given an integer ID on creation that\nuniquely identifies it. In typical usage, the game code creates counters on initializa-\ntion and puts start/stop counter calls around the code to be profiled.\nThe basic functional unit interface for the module is as follows:\nclass IPerfCounterMan {\npublic:\n// Add new counter (returns the ID, 0 is failure)\nint32 \nAddCounter(uint32 CounterGroup,\nconst char* szCounterName);\n// Forget your counter's ID? (Zero is failure)\nint32 \nGetCounterID(uint32 CounterGroup,\nconst chan* szCounterName);\n// Delete the counter\nbool \nDeleteCounter(uint32 Counter-ID);\n// Start and Stop a counter.\nvoid \nStartCounter(uint32 Counter-ID);\nvoid \nStopCounter(uint32 CounterlD);\n// Draw the Counters onto the Screen (to be called once\n// per frame near the end of the scene)\nvoid \nDrawCounters();\n};\nStopCounter calculates the difference between the StartCounter and StopCounter\ncalls and keeps a running total. On DrawCounters, all the running counters are\ncleared. A maximum value is also maintained and is set at the end of the frame in\nDrawCounters. Let's assume that our engine has a debug console that accepts text\ncommands. It is a very convenient way to enable and disable counter groups and to\nallow customization of the display.\nIt is very helpful to allow as much configuration in the counter display as possi-\nble. We will most likely not want to refresh the counter display every frame (updates\nevery 30 frames should be sufficient), but depending on what is being debugged, the\nability to customize the refresh time can be very handy. In addition, displaying both\nthe current percentage and the maximum percentage since last displayed is useful.\nA bar graph is a good way to display the result. It gives the consumer a quick feel\nfor the numbers and isn't hard to code. The ability to switch from percentage to actual\ntime (in milliseconds), display the time or percentage as text values, and auto-scale the\naxes is also very useful. Be careful about switching the axis scale very often, especially\nwithout some kind of warning, because it will likely just confuse people.\n\n\n78 \nSection 1 General Programming\nImplementation Details\nThe interface to the performance counter manager should be flexible and easy to use.\nConsumers of the profile manager will often find it easier to simply call Add-\nCounter(...) with the full string, get the ID, and start it up all at once instead of sav-\ning the counter ID at some one-time initialization point. Providing this mechanism\ncan help out when doing some quick profiling. However, it's not as efficient, and call-\ning it many times in a frame will add up quickly. Also, supplying a class that can be\nplaced at the beginning of a function that calls StartCounter in the constructor and\nStopCounter in the destructor (when it goes out of focus) can be a handy way to\ninstrument the counters.\nWhen writing the profiling manager, it's best to provide some kind of #define\nmacro that completely removes the profiler. When it comes down to getting peak per-\nformance out of a game, profiling code is often one of the first things to go. We need\nto provide macros for AddCounter, StartCounter, and StopCounter that completely\ncompile out on an #ifdefdnan%t.\nAlso, it's best to use colors for visual cues. When the counters are being displayed,\nit's easier to read if we use different colors on each line.\nData Analysis\nBe sure to profile the release build, because it can have a very different set of bottle-\nnecks from the debug version. If the target platform is the PC, it is also a good idea to\npick two or three typical system configurations (low to high end) and profile each of\nthem. Bottlenecks can vary greatly across system configurations.\nThe game should be profiled in the areas that have performance problems as well\nas during typical game play. We must break the problem down, try to focus on one\nthing at a time, and focus on the areas that will give the biggest bang for the buck. Just\nbecause a function is called the most often or takes the most CPU time doesn't mean\nit is the only place we should focus our efforts. Often, the only thing we can compare\nour cycle times with is our expectations, and realistic expectations are usually gained\nonly through experience.\nThe profiler itself should also be profiled. If the act of profiling is intrusive, it\nchanges the behavior of your game. There should be a counter around the profiler's\ndraw routines.\nImplementation Notes\nThe described module has been implemented across multiple platforms. However,\nparts of it require platform-dependent functions. The actual timestamp query and the\ndraw functions will mostly likely need to be implemented in platform-dependent\ncode, so it's best to design a level of abstraction around those functions. The described\nimplementation uses a set of debug geometry and text (which has a platform-\n\n\n1.11 A Built-in Game Profiling Module \n_ \n79\ndependent implementation) in the draw code so that it can be platform independent.\nYou may need to write a macro to create your four character code values, as many\ncompilers do not have support for them.\nThis same system can be used to take long running profiles of a game server to\ndetect problems. All the counters go through one source, so data can easily be filtered\ndown and saved to disk.\n\n\n1.12\nLinear Programming Model for\nWindows-based Games\nJavier F. Otaegui, Sabarasa Entertainment\njJavier@sabarasa.com.ar\nI\nn the past, when DOS ruled the earth, we programmed our games in a mostly lin-\near fashion. Then it was time to port our creations from DOS to DirectX, and this\nwas a big jump because of the Windows message pump. Its architecture is simply not\nadequate for game programming. In this gem, we will cover an effective way to encap-\nsulate the message pump, provide a linear programming model and, as a very desir-\nable side effect, allow correct \"alt-tab\" application switching. We will also cover\ncorrect recovery of lost surfaces.\nIf you have previously programmed linearly, you will easily understand the\nimportance of the method introduced in this gem. If your experience in game\nprogramming started with Windows, then you might find the message pump\na natural environment for game programming, but once you try linear pro-\ngramming, you will never go back to the message pump. It is far clearer and\neasier to follow and debug than a huge finite state machine is. You can save a\nlot of design, programming, debugging time, and thinking if you start work-\ning in a more linear way.\nUpdating the World\nModern games often have some sort of UpdateWorld function, located in the heart of\nthe application in the message pump, and invoked whenever it is not receiving any\nmessages. In a first attempt, coding an UpdateWorld function can be very simple: all\nthe application variables, surfaces, and interfaces have already been initialized, and\nnow we just have to update and render them. That should be an easy task, but only if\nwe plan that our game will have only one screen, no cut-scenes, no menus, and no\noptions.\nThe problem is that UpdateWorld must eventually finish and return to the mes-\nsage pump so we can process messages from the system. This prevents us from staying\nin a continuous for loop, for example. As old DOS games didn't have to return con-\nstantly to a message pump to process system requests, we could linearly program\n80\n\n\n1.12 Linear Programming Model for Windows-based Games \n81\nthem, and our subroutines could have all the loops they needed, or delays, or cut-\nscenes. We simply had to insert the corresponding code into the subroutine. Now,\nhowever, with the message pump, which requires constant attention, we must return\non every loop. As stated previously, the problem of returning in every single loop is\nwhen attempting to maintain several game screens.\nThe way to work around this is to make every subroutine of the application a\nfinite state machine. Each subroutine will have to keep track of its internal state, and,\naccording to this state, it must invoke several other subroutines. Each of these other\nsubroutines is also a finite state machine, and when it finishes its execution (that is, it\nhas no more states to execute), it must return a value to inform the invoking subrou-\ntine that it can proceed with its own following state. Of course, each subroutine,\nwhen it finishes, must reset its state to 0, to allow the application to invoke it again.\nNow if we imagine 30 or 40 of these subroutines, each with a couple dozen states,\nwe will be facing a very big monster. Trying to debug or even follow this code will be\ndifficult. This finite-state programming model is far more complicated that the sim-\nple model achieved by old linear DOS programs.\nThe Solution: Multithreading\nHere is a simple multithreading model that frees the game programmer from the mes-\nsage pump and its potentially undesirable finite-state programming model.\nWindows supports multithreading, which means that our application can run\nseveral threads of execution simultaneously. The idea is very simple - put the message\npump in one thread and the game into another one. The message pump will remain\nin the initial thread, so we can take out the UpdateWorld function from the message\npump and return it to its simplest form (a linear programming scheme). Now we just\nneed to add to the dolnit function the code necessary to initiate the game thread.\nHANDLE hMainThread; \n// Main Thread handle\nstatic BOOL\ndolnit( ... )\n{\n... // Initialize DirectX and everything else\nDWORD tid;\nhMainThread=CreateThread( 0,\n0,\n&MainThread,\n0,\n0,\n&tid);\nreturn TRUE;\n}\nMainThread is defined by:\n\n\n82 \nSection 1 General Programming\nDWORD WINAPI\nMainThread( LPVOID argl )\n{\nRunGame() ;\nPostMessage(hwnd, WM_CLOSE, 0, 0);\nreturn 0;\nMain Thread will invoke our RunGame function, and when it is finished, we just\npost a WM_CLOSE message to tell the message pump thread to finish execution.\nInitialization Code\nNow we must choose whether to include initialization code (including the DirectX\ninitialization code) in the dolnit function or directly into our RunGame function. It\nmay be more elegant to include it in the dolnit function, as long as we include all ter-\nminating code in the response to WM_CLOSE in our message handler. On the odier\nhand, we could include all the initialization code in the RunGame function, which\nmeans that we will handle all of the important parts of the code directly in our new\nlinear game-programming function.\nThe \"Alt-Tab\" Problem\nMaking a game truly multitasking under Windows is perhaps one of the most hazardous\nissues in game programming. A well-behaved application must be able to correcdy switch\nto other applications. This means allowing the user to alt-tab away from the application,\nwhich some games attempt to disallow, but we will try to make things work correcdy.\nWe could try using the standard SuspendThread and ResumeThread functions, but\nit's nearly impossible to get this to work properly. Instead, we will use a multithreaded\ncommunication tool: events. Events work like flags that can be used to synchronize\ndifferent threads. Our game thread will check if it must continue, or if it must wait for\nthe event to be set.\nOn startup, we must create a manual-reset event. This event should be reset\n(cleared) when the program is deactivated, and set when the program is reactivated.\nThen, in the main loop, we just have to wait for the event to be set.\nTo create the event, we need this global:\nHANDLE \ntask_wakeup_event;\nTo create and set the event, we need to include the following code during initial-\nization:\ntask_wakeup_event =\nCreateEvent(\nNULL, \n/ / N o security attributes\nTRUE, \n// Manual Reset ON\nFALSE, \n// Initial state = Non signaled\nNULL \n// No name\n\n\n1.12 Linear Programming Model for Windows-based Games \n83\nMost games have a function in their main loop that is called every time the game\nneeds to render a new screen; this is typically where DirectX is asked to flip the pri-\nmary and back buffers. Because this function is called constantly, this is an ideal loca-\ntion to make the thread wait for the event in an idle state, using this code:\nWaitForSingleObject( task_wakeup_event, INFINITE );\nWe must suspend the thread every time the operating system switches the active\napplication. To do this, we must have our WindowProc function, and upon receiving\nan APP_ACTIVATE message, check whether the application is active. If the applica-\ntion has gone to an inactive state, we must suspend the game execution, which\nrequires this call:\nResetEvent( task_wakeup_event );\nand to resume it:\nSetEvent( task_wakeup_event );\nWith this simple implementation, when the user hits alt-tab, the game will tem-\nporarily stop execution, freeing all the processor's time to enable die user to do other\ntasks. If the world update must continue executing even if the application loses focus,\nthen we can just suspend the rendering pipeline, and continue updating the world.\nThis event model can be used with any number of threads that the application may\nrequire, by inserting new events for each new thread.\nHandling Lost Surfaces\nIf we use video memory surfaces, we will face the problem of losing the surface infor-\nmation when the application loses focus. The problem that we now face is that with\nour new linear programming model, a program can be caught in the middle of a sub-\nroutine with all its surfaces lost.\nThere are many possible solutions to this situation, one of which is the Com-\nmand pattern [GoF94]. Unfortunately, it obscures our code, and the main goal of this\ngem is to make things more clear. We can use a global stack of pairs of callback func-\ntions and If Voids, which will be called when the surfaces need to be reloaded. When\nwe need to restore the surfaces, we would invoke callback_function( IpVoid ). The\nIf Void parameter can include pointers to all the surfaces that we need, so we can keep\nthe surfaces local to our new linear subroutines.\nLet's suppose that we have a subroutine called Splash that displays a splash screen\nin our game, which is a surface loaded from a file. If the user hits alt-tab while the\nsplash screen is displayed and then comes back, we want our application to show the\nsplash screen again (let's assume that the surface was lost while the application was\ninactive). Using our proposed method, we must do something like this:\nint LoadSplashGraphi.es ( Ipvoid Params )\n",
      "page_number": 71,
      "chapter_number": 9,
      "summary": "The Intel® Graphics Performance Toolkit (GPT) provides some powerful scene\nanalysis tools Key topics include game, counters, and code. Profiling the performance of a game or engine is one of those things that everyone\nagrees is important, but just as often as not guesswork or quick hacks are substituted\nfor a real game system that can gather solid data.",
      "keywords": [
        "Game Profiling Module",
        "Built-in Game Profiling",
        "Game",
        "counter",
        "Linear Programming Model",
        "Game Profiling",
        "game programming",
        "code",
        "application",
        "Built-in Game",
        "Programming Model",
        "Profiling Module",
        "Programming",
        "message pump",
        "Profiling"
      ],
      "concepts": [
        "game",
        "counters",
        "code",
        "coding",
        "profiling",
        "profiles",
        "programming",
        "program",
        "functions",
        "function"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 1",
          "chapter": 13,
          "title": "Segment 13 (pages 115-123)",
          "relevance_score": 0.59,
          "method": "sentence_transformers"
        },
        {
          "book": "Python Architecture Patterns",
          "chapter": 14,
          "title": "[ 465 ]",
          "relevance_score": 0.58,
          "method": "sentence_transformers"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 18,
          "title": "Segment 18 (pages 348-366)",
          "relevance_score": 0.57,
          "method": "sentence_transformers"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 17,
          "title": "Segment 17 (pages 326-347)",
          "relevance_score": 0.55,
          "method": "sentence_transformers"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 21,
          "title": "Segment 21 (pages 403-420)",
          "relevance_score": 0.55,
          "method": "sentence_transformers"
        }
      ]
    },
    {
      "number": 10,
      "title": "Segment 10 (pages 81-89)",
      "start_page": 81,
      "end_page": 89,
      "detection_method": "topic_boundary",
      "content": "Section 1 General Programming\nSurface *pMySurface;\npMySurface = (Surface *) Params;\n// \n(load the graphic from the file)\nreturn 1;\nint Splash()\nSurface MySurface;\n// Push the function\ngReloadSurfacesStack.Push( &LoadSplashGraphics, &MySurface );\n/ / D o not forget to load graphics for the first time\nLoadSplashGraphics( &MySurface );\n// ... the subroutine functionality.\n// Pop the function\ngReloadSurfaceStack.Pop();\n}\nWe are using a stack so that each nested subroutine can add all the surface load-\ning and generation code that it might need. The implementation could easily be\nchanged to another collection class, but this is a classic stack-oriented problem due to\nits nested functionality, and so a stack works best here.\nReferences\n[GoF94] Gamma, E., Helm, R., Johnson, R., & Vlissides, J. (1994), Design Patterns:\nElements of Reusable Object-Oriented Software. Addison-Wesley. 1994.\nOtaegui, Javier E, \"Getting Rid of the Windows Message Pump,\" available online at\nwww.gamedev.net/reference/articles/articlel249.asp.\n\n\n1.13\nStack Winding\nBryon Hapgood, Kodiak Interactive\nbryonh57@hotmail.com\nS\ntack winding is a powerful technique for assembly programmers that allows us to\nmodify an application's stack to do weird and wonderful things that can be\nextended into C/C++ with very little work. While the days of writing every line of\ngame code in hand-optimized machine language are over, sometimes it is worth the\neffort to dip into the realm of the arcane to get that extra bit of speed and elegance in\na game.\nIn this gem, we cover one particular type of stack winding that I call the \"tempo-\nrary return.\" This is the bare minimum form that we will build upon in subsequent\nexamples until we have a thunked temporary return. The code examples have been\ntested with Microsoft's MASM and Visual C++ compiler. I have personally used stack\nwinding in a number of projects for the GameBoy Color, PC, and Xbox.\nSimple TempRet\nStack winding, as its name implies, is a technique for modifying the stack to make it\ndo unexpected things. The term stack winding comes from the idea of inserting values\nin an existing stack frame to change its normal and expected behavior.\nListing 1.13.1 The TempRet routine\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n.586\n.model flat\n.data\nbuffer dd ?\nfile_handle\nfilesize dd\n.code\n_TempRetEg:\ncall\ncall\n)\ndd ?\n?\nfnO\nfn1\n; \nbefore\nj\npop\nedx\n85\n\n\nSection 1 General Programming\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27 end\ncall edx\n1\n; \nafter\n»\ncall fn2\ncall fn3\nret\nA: call _TempRetEg\nret\nIn Listing 1.13.1, we see the first building block of stack winding: the TempRet rou-\ntine. Let's take a function (call it MyFunc) and say it calls _TempRetEg. The latter\nthen calls two functions: fnO and fnl. It then hits the lines:\npop \nedx\ncall edx\nNow we know that the way the CPU handles the assembly CALL instruction on\nline 24 is to push the address of the next line (25) and execute a JUMP to line 8. Line\n15 pops that address off the stack and stores it in a CPU register. Now we CALL that\naddress. This pushes line 20 onto the stack and executes a JUMP to line 25. The lat-\nter does nothing but execute a CPU return, which pops an address off the stack and\njumps there.\nThe rest of _TempRetEg then continues and when it returns, we do not return to\nMyFunc but to whatever function called MyFunc in the first place. It is an interesting\nlittle trick, but why would it be important? The power comes when we consider the\nfunctions FNO through FN3.\nLet's say that FNO opens a file, FN1 allocates a buffer and reads the file into\nmemory, FN2 frees that memory, and FN3 closes the file. Thus, MyFunc no longer\nhas to worry about the release steps. It doesn't have to close the file or worry about\nfreeing up the memory associated with the file. Functionally the process of opening a\nfile, reading it into memory, freeing that memory, and closing the file is all contained\nwithin a single block of code. MyFunc only has to call _TempRetEg, use the buffer,\nand return.\nTempRet Chains\nThe TempRet example comes of age when we chain functions together. Let's take a\nclassic problem: the initialization and destruction of DirectX 7. This usually takes a\nnumber of steps, but it's incredibly important to release the components of DX in\nreverse order, which can sometimes become horribly complicated.\nSo, let's expand our first example to illustrate this:\n\n\n1.13 Stack Winding \n87\nListing 1.13.2 Winding multiple routines onto the stack\n0 .586\n1 .model flat\n2 .code\n3\n4 TempRet macro\n5 pop \nedx\n6 call edx\n7 TempRet endm\n8\n9 createWindow:\n10 \n; open the window\n11 \nTempRet\n12 \n; close it\n13 \nnet\n14 setCooperativeLevel:\n15 \n; set to exclusive\n16 \nTempRet\n17 \n; restore\n18 \nret\n19 changeDisplayMode:\n20 ; set 640x480 16 bpp\n21 \nTempRet\n22 \n; restore\n23 \nret\n24 createSurfaces:\n25 \n; create primary surface\n26 \n; get attached back\n27 \nTempRet\n28 \n; release primary\n29 \nret\n30 _SetupDX7:\n31 \ncall \ncreateWindow\n32 \ncall \nsetCooperativeLevel\n33 \ncall \nchangeDisplayMode\n34 \ncall \ncreateSurfaces\n35 \njmp \n_SomeUserRunFunc\n36\n37\n38 \nend\nBy performing numerous TempRets in succession we effectively have wound four\nroutines onto the stack so that when _SomeUserRunFunc returns, we will bounce\nback through createSurfaces, changeDisplayMode, setCooperativeLevel, and cre-\nateWindow at the line after the TempRet in reverse order.\nSo far, we've been using assembly language, but it's not necessary to write assem-\nbly modules to use this technique. We will cover two mechanisms in Microsoft's\nVisual C++ in the final section that aid us in stack winding: inline assembly and\nnaked functions.\n\n\n88 \nSection 1 General Programming\nThunking\nThe ideas discussed so far need to be translated into C/C++. As stated previously, Visual\nC++ has a handy mechanism for doing diis, but what about other compilers? If naked\nfunctions are not supported, then we will have to dip into assembly language because\nthe presence of a stack frame really complicates things. It is not impossible, just difficult.\nThunking is a technique popularized by Microsoft for slipping a piece of code\nbetween two others. In effect, program flow is hurtling along through our code until\nthunk!—it crashes into that layer. Thunks are a great way of implementing a stack-\nwinding paradigm in C++. Let's look at an example that performs the same task of set-\nting up DirectX as we saw earlier:\nListing 1.13.3 Visual C++ example using TempRet\n#define TempRet\\\n_ asm{pop edx}\\\n__ asm{call edx}\ntfdefine NAKED void _ declspec(naked)\ntfdefine JUMP _ asm jmp\ntfdefine RET _ asm ret\nstatic NAKED createWindow(){\n// open the window\nTempRet\n// close it\nRET\nstatic NAKED setCooperativeLevel(){\n// set to exclusive\nTempRet\n// restore\nRET\nstatic NAKED changeDisplayMode(){\n// set 640x480 16 bpp\nTempRet\n// restore\nRET\nstatic NAKED createSurfaces(){\n// create primary surface\n// get attached back\nTempRet\n// restore\nRET\n\n\n1.13 Stack Winding \n89\nNAKED SetUpDX7(){\ncreateWindow();\nsetCooperativeLevel();\nchangeDisplayMode();\ncreateSurfaces();\nJUMP run\nRecursion\nAs a final example of the power of stack winding, we will explore a solution for a clas-\nsic problem with recursive searching: how to roll back die recursion. In regular C we\nwould simply return repeatedly, walking back through the stack until we reach the\ntop. If our recursion is over 100 calls deep, however, this might take a little time. To\nfix this, here is a pair of utility functions called SafeEnter. Incidentally, the code works\njust as well from a C++ object as a global function.\nListing 1.13.4 The SafeEnter and SafeExit functions that aid\nrecursion\n.586\n.model flat\n.code\npublic SafeEnter,SafeExit\n; struct SAFE{\n; \nvoid*_reg[8];\n; \nvoid* ret;\nI }\n; assembly for SafeEnter routine\n_SafeEnter:\npop edx ; return address\nmov eax,[esp] ; safe\nmov [eax].safe. ret,edx\nmov [eax].safe. ebx.ebx\nn)ov [eax].safe. ebp,ebp\nmov [eax].safe. esp,esp\nmov [eax].safe. esi,esi\nmov [eax].safe. edi.edi\npop \neax ; safe pointer\npop \nedx ; call function\npush eax ; safe pointer\n\n\n90 \nSection 1 General Programming\nmov \nebp,eax\ncall \nedx\nmov \neax,ebp\njmp \nsex\n_SafeExit:\npop edx \n; \nreturn\npop eax \n; \nregs context\nmov edi,[eax].safe. edi\nmov esi,[eax].safe. esi\nmov esp,[eax].safe. esp\nmov ebp,[eax].safe. ebp\nmov ebx,[eax].safe. ebx\nmov edx,[eax].safe. ret\nmov eax,[eax].safe. eax\njmp \nedx\nend\nSafeEnter works by saving off to a SAFE structure a copy of crucial CPU regis-\nters. It then calls our recursive function. As far as the function is concerned, no extra\nwork is necessary. Now the cool part comes when we find the piece of data we're look-\ning for. We simply call SafeExit() and pass it the register context we built earlier. We\nare instantly transported back to the parent function.\nNow, if the unthinkable happened and the search routine did not meet its search\ncriteria, then the function can simply return in the normal way, all the way up the chain.\nListing 1.13.5 Recursive example using SafeEnter and SafeExit\nstatic void search(SAFE&safe,void*v){\nif(<meets_requirement>)\nSafeExit(safe);\n// do stuff\nsearch(safe,v);\nreturn;\n}\nint main(){\nSAFE safe;\nSafeEnter(\nsafe,\nsearch,\n<some_pointer>)\n\n\n1.14\nSelf-Modifying Code\nBryon Hapgood, Kodiak Interactive\nbryonh57@hotmail.com\nS\nelf-modifying code, also known as \"RAM-code,\" is a fascinating technique that\nactually allows a program to alter its own code as it executes. It has been used in\neverything from genetic algorithms to neural networks with amazing results. In games\nit can be used as a powerful optimization technique. Recently I used this technique on\na GameBoy Color title Test Drive Cycles to decompress artwork on the fly at 60 fps,\ndecode 14 palettes of color information (instead of the standard eight), and enable\nmultiple levels of parallax scrolling. In this gem, we will cover how to write self-\nmodifying applications.\nThe Principles of RAM-Code\nRAM-code is a simple idea, but one that can take an inordinate amount of time to get\njust right. It is written for the most part in hexadecimal and can be difficult to debug.\nLet's look at a very simple case. We want to load a pointer from a 16-bit variable\nstored somewhere in RAM.\ngetjil:\nId hl,ptr_var \nLoad HL register with the address ptr_var\nId a,(hli)\nId h,(hl)\nId l,a\nLoad A register with low byte\nand increment HL\nLoad L register with high byte of ptr_var\nSave low byte into L\nret \n; Return\nThis example can be improved by writing it as:\ngetjil:\ndb $2a \n; Id hi,...\nptr_var\ndw $0000 \n; ...ptr_var\nret\nThese two routines are logically no different from each other, but can you see the\ndifference? The second example is stating the variable that stores the address to be\nloaded in HL as an immediate value! In other words, instead of physically going out\nand loading an address, we just load HL. It's quicker to load an immediate value than\n91\n\n\n92 \nSection 1 General Programming\nto access main memory, and because there are fewer bytes to decode, the code runs\nmuch faster. We can take that idea much further when it comes to preserving regis-\nters. Instead of pushing and popping everything, which can be expensive, we simply\nwrite the value ahead into the code. For example, instead of writing:\nget_hl: \n:\nId \nhl,ptr_var\nId \na,(hli)\nId \nl,(hl)\nId \nh,a\nId \na,(hi)\npush af ; Save A register\nj\n; do something with A\nj\npop af ; Restore A register\nret\nthis code can be optimized down to:\ngetjil:\ndb \n$2a \n; Id hi,...\nptr_var\ndw \nptr_var \n; ...ptr_var\nId \na,(hi)\nId \n(var1),a\ni\n; do something with A\ndb \n$2F \n; Id a,...\nvarl db \n$00 \n; ...saved register value\nret\nThis is not a huge saving, but it illustrates the point.\nA Fast Bit Blitter\nIn many games, it is often crucial to convert from one pixel format to another, such as\nfrom 16-bit (565) RGB to 24-bit RGB. Whether this is done in some offline tool or\nwithin the game itself can be satisfied with this one routine. We can define a structure\n(call it BITMAP) that contains information about an image. From this, our blitter\ncan then use RAM-code techniques to construct an execute-buffer—a piece of code\nthat has been allocated with malloc and filled with assembly instructions.\nThe blitter works by taking a routine that knows how to read 16-bit (565) RGB\npixels and convert them to 32-bit RGBA values, and a routine that knows how to\nwrite them in another format. We can paste these two functions together, once for\nimages with odd widths, or multiple times in succession to effectively unroll our loop.\nThe example shown next takes the former approach.\nSo, let's define our bitmap structure and associated enumerated types.\n",
      "page_number": 81,
      "chapter_number": 10,
      "summary": "In this gem, we cover one particular type of stack winding that I call the \"tempo-\nrary return.\" This is the bare minimum form that we will build upon in subsequent\nexamples until we have a thunked temporary return Key topics include function, functionality, and functions.",
      "keywords": [
        "Stack Winding",
        "stack",
        "call",
        "SAFE",
        "ret",
        "TempRet",
        "eax",
        "Winding",
        "code",
        "General Programming",
        "ret static NAKED",
        "pop edx",
        "edx",
        "mov",
        "call edx"
      ],
      "concepts": [
        "function",
        "functionality",
        "functions",
        "code",
        "ret",
        "returns",
        "stack",
        "safe",
        "examples",
        "pop"
      ],
      "similar_chapters": [
        {
          "book": "C++ Templates_ The Complete Guide",
          "chapter": 34,
          "title": "Segment 34 (pages 1080-1114)",
          "relevance_score": 0.49,
          "method": "sentence_transformers"
        },
        {
          "book": "Computer Systems A Programmer’s Perspective",
          "chapter": 53,
          "title": "Segment 53 (pages 1064-1083)",
          "relevance_score": 0.49,
          "method": "sentence_transformers"
        },
        {
          "book": "C++ Concurrency in Action",
          "chapter": 39,
          "title": "Segment 39 (pages 382-396)",
          "relevance_score": 0.45,
          "method": "sentence_transformers"
        },
        {
          "book": "C++ Templates_ The Complete Guide",
          "chapter": 35,
          "title": "Segment 35 (pages 1115-1144)",
          "relevance_score": 0.44,
          "method": "sentence_transformers"
        },
        {
          "book": "Computer Systems A Programmer’s Perspective",
          "chapter": 18,
          "title": "Segment 18 (pages 352-373)",
          "relevance_score": 0.44,
          "method": "sentence_transformers"
        }
      ]
    },
    {
      "number": 11,
      "title": "Segment 11 (pages 90-100)",
      "start_page": 90,
      "end_page": 100,
      "detection_method": "topic_boundary",
      "content": "1.14 Self-Modifying Code\n93\nenum Format{\nRGB_3x8=0 ,\nRGB_565=4,\nRGB_555=8,\nRGB_4x8=12,\nRGB_1x8=16\nstruct BITMAP{\nvoid *pixels;\nu32 w, h, depth;\nTRIPLET *pal;\nFormat pxf;\nu32 stride;\nu32 size;\n- \nBITMAP();\nBITMAP ( int , int , int , Format , int n=1 ) ;\nvoid draw( int , int , BITMAP&, int , int , int , int ) ;\noperator bool(){\nreturn v!=NULL;\nNow, it's really important that we have the same structure defined on the assem-\nbly side of things.\nBITMAP\npixels\nw\nh\ndepth\npal\npxf\nstride\nsize\nstruct\ndd ?\ndd ?\ndd ?\ndd ?\ndd ?\ndd ?\ndd ?\ndd ?\nBITMAP ends\nPF_BGR_3x8 =\nPF_BGR_565 =\nPF_BGR_555 =\nPF_BGR_4x8 =\nPF BGR 1x8 =\nOOh\n04h\n08h\nOCh\n10h\nThe next step is to define our execute buffer.\nexecute_buffer db 128 dup(?)\nFor this code to work in C++, we must use a mangled C++ name for the member\nfunction BITMAP: :draw. After that comes some initialization code:\n?draw@BITMAP@<aQAEXHHAAU1 @HHHH@Z:\npush\nlea\nebp\nebp,[esp+8]\nget arguments address\n\n\n94 \nSection 1 General Programming\npush \nebx\npush \nedi\npush \nesi\nmov edi,ecx \n;dst bitmap\nmov esi,[ebp+8] \n;src bitmap\nmov eax,[esi].bitmap.pxf\nThe first thing we must decide is whether we need to do a conversion at all.\nTherefore, we test to see if the two pixel formats of the bitmap objects are the same. If\nso, we can further ask whether they are the same size. If that is the case, we can just do\na fast string copy from one to the other. If not, but they're the same width, then we\ncan still do the string copy. If the two have different widths, then we can do string\ncopies line by line.\nmov edx,[edi].bitmap.pxf\ncmp eax,edx\njne dislike\nlike copy\nmov ecx,[esi].bitmap._size\ncmp ecx,[edi].bitmap._size\nje k3\nmov \necx,[edi].image.stride\nmov edx,[esi].image.stride\ncmp edx,ecx\njne @f\n)\n; \nsame w different h\ni\nmov edx,[edi].image.h\nmov eax,[esi].image.h\ncmp eax,edx\njl k2\nmov eax,edx\nk2: mul ecx\nmov ecx,eax\nk3: mov esi,[esi].image.Ifb\nmov edi,[edi].image.Ifb\nshr ecx,2\nrep movsd\njmp ou\n,\n; \nfind smallest h -> ebx\nj\nmov eax,[edi].image.h\nmov ebx,[esi].image.h\ncmp ebx,eax\njl @f\nmov ebx,eax\n; \ncalc strides\n\n\n1.14 Self-Modifying Code\n95\nadd \nebp,12\nmov \neax, [ebp].rectangle.w\nmul \n[esi].image.depth; edx corrupts\nmov \nedx,[esi].image.stride\nsub \necx,eax\nsub \nedx,eax\ni\n; \ncalc offsets with intentional reg swap\npush\npush\npush\ncall\npop\npop\npop\neax\necx\nedx\ncalc_esdi\nedx\neax\necx\nou:\nshr\nmov\nrep\nlea\nlea\nmov\ndec\njne\npop\npop\npop\npop\nret\nedx=dest pad\necx, 2\nebp,ecx\nmovsd\nedi,[edi+eax]\nesi,[esi+edx]\necx,ebp\nebx\n@b\nesi\nedi\nebx\nebp\n1ch\nIf the two bitmaps have completely different pixel formats, we have no choice but\nto convert every single pixel from one format to the other. The following code shows\nthis in action. There's another way to further improve this routine by unrolling the\nloop—this would be as simple as repeating the build step four or more times.\ndislike\n:lea\nadd\npush\npush\npush\npush\npush\nmov\nmov\neax,execute_buffer\nebp,12\nou\neax\nedi\nesi\nebp\nebx,edi\nedi,eax\ndestination image\nwrite \"mov ebx,h\"\nmov \nal,OBDh\nstosb\nmov \neax,[ebp].rectangle.h\n\n\n96\nSection 1 General Programming\nstosd\n»\n; \nwrite \"mov ecx.w\"\nmov \nal,OB9h\nstosb\nmov \neax,[ebp].rectangle.w\nstosd\n; \nget read\nmov\nmov\nmov\nmov\nlodsd\nmov\nadd\nrep\n;\nmov\nmov\nlodsd\nmov\nadd\nrep\nedx\nebp\neax\nesi\necx\nedx\n,22\n,esi;\n,[ebp]\nsource\n. image. pf\n, rtbl_conv[eax]\n, eax\n,ecx\nmovsb\nput\neax\nesi\necx\nedx\nwrite\n,[ebx] . image. pf\n,wtbl_conv[eax]\n, eax\n,ecx\nmovsb\n; \nwrite tail\nmov\npush\nsub\nneg\nshl\nor\nmov\nstosd\nmov\npush\nmov\nmul\nsub\nJZ\necx\nedx\ndl,\ndl\nedx\nedx\neax\neax\neax\necx\n,[esp]\n19\n,16\n,08D007549h\n, edx\n,[ecx]\n,[ebp]\n. rectangle. w\n.image. stride\n[ebp] .image. depth\necx\n@f\nmov\n,eax\nal,OB6h\nstosb\nmov\neax, ecx\nstosd\njmp\npq\n; \nmodify outer branch\ndec\nmov\nedi\neax ,[esp+4]\nstart of exec_tail\nargs\nsource\n\n\n1.14 Self-Modifying Code\npq:\n97\npr:\nsub\nmov\npop\nmul\nmov\nsub\njz\npop\nsub\ninc\nneg\nshl\nor\neax,6\n[esp+4] ,eax\neax\n[ebx] .image. depth\necx, [ebx] .image. stride\necx, eax\n@f\nmov \nax,OBF8Dh\nstosw\nmov eax, ecx\nstosd\npop \neax\njmp \npr\neax\neax, 6\nal\nal\neax, 16\neax,OC300754Dh\nstosd\npop \nebp\npop \nesi\npop \nedi\ndest\nAnother important step in this blitter is to correctly calculate the x and y offsets\ninto the source and destination images. This routine does exactly that.\ncalc esdi:\n; \nDestination\nj\nmov \neax,[ebp-12].point.x\nmul \n[edi].image.depth\nmov \necx,eax\nmov \neax,[ebp-12].point.y\nmul \n[edi].image.stride\nmov \nedi,[edi].image.Ifb\nadd \nedi,ecx\nadd \nedi,eax\nSource\nmov \neax,[ebp].rectangle.x\nmul \n[esi].image.depth\nmov \necx,eax\nmov \neax,[ebp].rectangle.y\nmul \n[esi].image.stride\nmov \nedx,[esi].image.pal\nmov \nesi,[esi].image.Ifb\nadd \nesi,ecx\nadd \nesi,eax\nret\nget dx\nmultiply by d\nstore result\nget dy\nmultiple by stride\nget target pixels\nadd x\nadd y\nget sx\nmultiply by d\nstore result\nget sy\nmultiple by stride\npalette info\nget target pixels\nadd x\nadd y\n\n\n98\nSection 1 General Programming\nFor this whole RAM-code idea to work, we need some initialization that gets\nplaced at the top of the RAM-code buffer. It simply loads the ECX register with the\nnumber of scan lines to copy.\nexec head\ndd\ndb\nOB9h,OOOh,OOOh,OOOh,OOOh\n(size)\nmov ecx,0\nThe next few routines are the actual read and write routines (RC and WC). The\nfirst byte tells us how many bytes make up the code in each subroutine.\nRC_BGR_1x8 \ndd \n18\ndb \n033h,OCOh\ndb \nOACh\ndb \n08Bh,OD8h\ndb \n003h,OCOh\ndb \n003h,OC3h\ndb \n003h,OC2h\ndb \n08Bh,OOOh\ndb \n025h,OFFh,OFFh,OFFh,OOOh\nRC_BGR_3x8 \ndd \n7\ndb \nOADh\ndb \n025h,OFFh,OFFh,OFFh,OOOh\ndb \n04Eh\n(size)\nxor \neax,eax\nlodsb\nmov ebx.eax\nadd eax,eax\nadd eax,ebx\nadd eax,edx\nmov eax,[eax]\nand eax,-1\n(size)\nlodsd\nand eax,-1\ndec esi\nRC BGR 4x8\nRC BGR 565:\nRC BGR 555:\ndd\ndb\n1\nOADh\ndd \n1\nlodsw\ndd \n1\nlodsw\nI \n(size)\n; lodsd\n; (size)\n; (size)\nWC_BGR_3x8 \ndd \n6\ndb \nOAAh\ndb \nOC1h,OE8h,008h\ndb \n066h,OABh\nWC_BGR_555 \ndd \n28\ndb \n033h,ODBh\ndb \nOCOh,OE8h,003h\ndb \nOCOh,OECh,003h\ndb \n08Ah,ODCh\ndb \n066h,OC1h,OE3h,005h\ndb \nOOAh,OD8h\ndb OC1h,OE8h,013h\ndb 066h,OC1h,OEOh,OOAh\ndb \n066h,OOBh,OC3h\ndb \n066h,OABh\nWC_BGR_565 \ndd \n28\ndb \n033h,ODBh\n(size)\nstosb\nshr eax,8\nstosw\n(size)\nxor ebx,ebx\nshr al,3\nah, 3\nbl.ah\nbx,5\nbl.al\neax,l3h\nax,OAh\nax,bx\nshr\nmov\nshl\nor\nshr\nshl\nor\nstosw\n(size)\nxor ebx,ebx\n\n\n1.14 Self-Modifying Code\n99\nWC_BGR_4x8\nFinally, we have a\nBITMAP: :pf.\nrtbl_conv\nwtbl_conv\ndb\ndb\ndb\ndb\ndb\ndb\ndb\ndb\ndb\ndd\ndb\ntable\ndd\ndd\ndd\ndd\ndd\ndd\ndd\ndd\ndd\ndd\nOCOh,OE8h,003h\nOCOh,OECh,002h\n08Ah , ODCh\n066h,OC1h,OE3h,005h\nOOAh,OD8h\nOC1h,OE8h,013h\n066h,OC1h,OEOh,OOBh\n066h,OOBh,OC3h\n066h , OABh\n1\nOABh\nthat tells us which routine\nRC BGR 3x8\nRC BGR 565\nRC_BGR_555\nRC BGR 4x8\nRC_BGR_1 x8\nWC BGR 3x8\nWC BGR 565\nWC BGR 555\nWC BGR 4x8\n?\n; shr al,3\n; shr ah, 2\n; mov bl.ah\n; shl bx,5\n; or bl,al\n; \nshr \neax,13h\n; \nshl \nax.OBh\n; \nor \nax.bx\n; \nstosw\n! \n(size)\n; \nstosd\nto use for every pixel format in\n\n\n1.15\nFile Management Using\nResource Files\nBruno Sousa, Fireworks Interactive\ngems2@fireworks-interactive.com\nA\ns games increase in size (I think the grand prize goes to Phantasmagoria with\nseven CDs), there is a need for organization of the game data. Having 10 files in\nthe same directory as the executable is acceptable, but having 10,000 is not. More-\nover, there is the directory structure, sometimes going five or more levels deep, which\nis a pain to work with. Because our games will hardly resemble Windows Explorer, we\nneed to find a clean, fast way to store and organize our data. This is where resource\nfiles come into play. Resource files give us the power to encapsulate files and directo-\nries into a single file, with a useful organization. They can also take advantage of\ncompression, encryption, and any other features we might need.\nWhat Is a Resource File?\nWe already use resource files all the time in our daily work—examples of these are\nWinZip, the Windows installer, and backup programs. A resource file is nothing\nmore than a representation of data, usually from multiple files, but stored in just one\nfile (see Listing 1.15.1). Using directories, we can make a resource file work just like a\nhard drive's file system does.\nListing 1.15.1 Resource file structure.\nSignature \n= \"SEALRFGNU\" + '\\0'\nVersion \n= 1.0\nNumber of Files \n= 58\nOffset of First File = 19\n[File 1]\n[File 2]\n[File 3]\n[File .]\n[File .]\n[File .]\n[File Number Of Files - 1]\n[File Number Of Files]\n100\n\n\n1.15 File Management Using Resource Files \n101\nEach lump (we will start calling files \"lumps\" from now on) in the resource file\nhas its own structure, followed by all of the data (see Listing 1.15.2).\nListing 1.15.2 File lump structure.\nFile Size = 14,340\nFilename = \"/bmp/Bob.bmp\" + '\\0'\nFlags = COMPRESSED\nFlagslnfo = OxF34A400B\n[Byte 1]\n[Byte 2]\n[Byte 3]\n[Byte .]\n[Byte .]\n[Byte .]\n[Byte File Size - 1]\n[Byte File Size]\nBefore we do anything else, we'll need to name our resource system. We can then use\nthe name to give each component a special naming scheme, one that will differentiate\nit from the other parts of the game. Let's call this system the \"Seal Resource File Sys-\ntem,\" abbreviated to SRFS, and use \"si\" for class prefixes.\nFirst, we need a resource file header. By looking at Listing 1.15.1, it's easy to see\nthat we are keeping our system simple. However, that doesn't mean it isn't powerful, it\nmeans that it was designed to accommodate the most-needed features and still retain\na fairly understandable syntax and structure.\nOur resource file header gives us all the relevant information about the system.\nMultiple file types are used in games, and for each type, there is usually a file header\nthat contains something unique to differentiate it from other file types. SRFS is no\ndifferent, so the first data in its header is the file signature. This is usually a 5- to 10-\ncharacter string, and is required so that we can identify the file as a valid Seal resource\nfile. The version information is pretty straightforward—it is used to keep track of the\nfile's version, which is required for a very simple reason: if we decide to upgrade our\nsystem by adding new features or sorting the lumps differently, we need a way to ver-\nify if the file being used supports these new features, and if so, use the latest code.\nOtherwise, we should go back to the older code—backward compatibility across ver-\nsions is an important design issue and should not be forgotten. The next field in the\nheader is for special flags. For our first version of the file system, we won't use this, so\nit must always be NULL (0). Possible uses for this flag are described in the For the\nFuture section. Following this is the number of lumps contained in the resource file,\nand the offset to the first lump. This offset is required to get back to the beginning of\nthe resource file if we happen to get lost, and can also be used to support future ver-\nsions of this system. Extra information could be added after this header for later ver-\nsions, and the offset will point to the first lump.\n\n\n102 \nSection 1 \nGeneral Programming\nWe now move to our lump header, which holds the information we need to start\nretrieving our data. We start with the lump size in bytes, followed by name and direc-\ntory, stored as a fixed-length, NULL-terminated string. Following this is the flags\nmember, which specifies the type of algorithm(s) used on the lump, such as encryp-\ntion or compression. After that is information about the algorithm, which can con-\ntain a checksum for encryption or dictionary information for compression (the exact\ndetails depend on the algorithms). Finally, after all of this comes the lump informa-\ntion stored in a binary form.\nOur system has only two modules: a resource file module and a lump module. To\nbe able to use a lump, we need to load it from the resource file and possibly decrypt or\ndecompress it into a block of memory, which can be accessed normally. Some systems\nprefer to encapsulate all functionality into the resource file module, and even allow\ndirect access to lump data from within this module. This approach certainly has\nadvantages, but the biggest disadvantage is probably that we need to have the whole\nresource in memory at once, unless we use only raw data or complicated algorithms to\ndynamically uncompress or decrypt our lump data to memory. This is a difficult\nprocess and beyond the scope of this gem.\nWe need functions to open the resource file, read the header, open individual\nlumps, read information from lumps, and get data from lumps. These are covered in\nthe Implementation section.\nImplementation\nThe sample code included in the CD is written in C++, but for the text, we will use\npseudocode so it will be easy to implement in any language.\nThe sICLump Module\nOur lump module is similar to file streams in C++ or other language implementations\nof files in that we can write to it. Unfortunately, updating the resource file with a\nlump is very troublesome due to the nature of C++ streams. We can't add data to the\nmiddle of the stream—we can only replace it—and we can't modify the parent\nresource file.\nDWORD \ndwLumpSize;\nSTRING \nszLumpName;\nDWORD \ndwLumpPosition;\nBYTE [dwLumpSize] abData;\nThe variable dwLumpSize is a double word (32 bits) that specifies the size of the\nlump, szLumpName is a string describing die lump's name, dwLumpPosition keeps the\nlump's pointer position, and abData is an array of bytes with the lump information.\nHere are the sICLump module functions:\nDWORD \nGetLumpSize (void);\nSTRING GetLumpName (void);\n\n\n1.15 File Management Using Resource Files \n103\nDWORD \nRead (BYTE [dwReadSize] abBuffer, DWORD dwReadSize);\nDWORD \nWrite (BYTE [dwReadSize] abBuffer, DWORD dwWriteSize);\nDWORD \nSeek (DWORD dwSeekPosition, \nDWORD dwSeekType);\nBOOLEAN IsValid (void);\nGetLumpSizeO retrieves the lump's size, and GetLumpName() retrieves the lump's\nname. Read() reads dwReadSize bytes into sbBuffer, and Write () does the exact\nopposite, writing dwWriteSize bytes to sbBuffer. Seek() moves the lump's pointer by\na given number from a seek position, and I sValid () verifies if the lump is valid.\nThe sICResourceFile Module\nThis module has all the functionality needed to load any lump inside the resource.\nThe module members are nearly the same as those in the resource file header.\nDWORD \ndwVersion;\nDWORD \ndwFlags;\nDWORD \ndwNumberOfLumps;\nDWORD \ndwOffset;\nSTRING szCurrentDirectory;\nFILE \nfFile;\nThe use of these members has already been described, so here is a brief definition\nof each. dwVersion is a double word that specifies the file version, dwFlags is a double\nword containing any special flags for the lump, dwNumberOfLumps is the number of\nlumps in the resource, dwOffiet gives us the position in bytes where the first lump is\nlocated, szCurrentDirectory is the directory we are in, and fFile is the actual C++\nstream.\nNow for the real meat of our system, the sICResourceFile functions—those that\nwe use to access each lump individually.\nvoid \nOpenLump (STRING szLumpName, slCLump inOutLump);\nvoid \nIsLumpValid (STRING szLumpName);\nvoid \nSetCurrentDirectory (STRING szDirectory);\nSTRING GetCurrentDirectory (void);\nEach of these functions is very simple. IsLumpValid () checks to see if a file with a\ngiven szLumpName exists in the resource. SetCurrentDirectory () sets the resource file\ndirectory to szDirectory. This directory name is prepended to each lump's name\nwhen accessing individual lumps within the resource file. GetCurrentDirectory()\nreturns the current directory.\nNow for our Open function. This function opens a lump within the resource file,\nand the logic behind the algorithm is described in pseudocode.\nCheck flags of Lump\nif \nCompressed\nOpenLumpCompressed \n(szLumpName, \ninOutLump)\nif \nEncrypted\n",
      "page_number": 90,
      "chapter_number": 11,
      "summary": "This chapter covers segment 11 (pages 90-100). Key topics include file, code, and string. execute_buffer db 128 dup(?)\nFor this code to work in C++, we must use a mangled C++ name for the member\nfunction BITMAP: :draw.",
      "keywords": [
        "Resource File",
        "File",
        "mov",
        "BGR",
        "mov eax",
        "eax",
        "Resource",
        "lump",
        "resource file header",
        "Byte File Size",
        "esi",
        "resource file module",
        "Seal Resource File",
        "DWORD",
        "size"
      ],
      "concepts": [
        "file",
        "code",
        "string",
        "lump",
        "size",
        "bitmaps",
        "byte",
        "resource",
        "add",
        "writing"
      ],
      "similar_chapters": [
        {
          "book": "Computer Systems A Programmer’s Perspective",
          "chapter": 45,
          "title": "Segment 45 (pages 903-922)",
          "relevance_score": 0.64,
          "method": "sentence_transformers"
        },
        {
          "book": "C++ Templates_ The Complete Guide",
          "chapter": 32,
          "title": "Segment 32 (pages 1015-1044)",
          "relevance_score": 0.62,
          "method": "sentence_transformers"
        },
        {
          "book": "More Effective C++",
          "chapter": 8,
          "title": "Segment 8 (pages 61-75)",
          "relevance_score": 0.61,
          "method": "sentence_transformers"
        },
        {
          "book": "Computer Systems A Programmer’s Perspective",
          "chapter": 33,
          "title": "Segment 33 (pages 662-682)",
          "relevance_score": 0.6,
          "method": "sentence_transformers"
        },
        {
          "book": "Computer Systems A Programmer’s Perspective",
          "chapter": 55,
          "title": "Segment 55 (pages 1103-1105)",
          "relevance_score": 0.6,
          "method": "sentence_transformers"
        }
      ]
    },
    {
      "number": 12,
      "title": "Segment 12 (pages 101-108)",
      "start_page": 101,
      "end_page": 108,
      "detection_method": "topic_boundary",
      "content": "104 \nSection 1 \nGeneral Programming\nOpenLumpEncrypted (szLumpName, inOutLump)\nif Compressed and Encrypted\nOpenLumpCompressedEncrypted (szLumpName, inOutLump)\nelse\nOpenLumpRaw (szLumpName, inOutLump)\nend if\nDepending on the lump type, the appropriate function to open the lump is\ncalled, thus maintaining a nice design and simple code. The source of each function is\nincluded in the CD.\nLast Words about the Implementation\nSome support functions that are used to open the file or to keep track of information\nthat can't be called directly are not represented in the preceding text. It is advisable to\n^ c^ 5? \ncheck the source code on the CD, which is well commented and easy to follow The\nON me ca \nalgorithms for compression and encryption are simple RLE compression and bit-wise\nencryption, the actual implementations of which are beyond the scope of this gem\nand must be researched separately. Information about useful public domain algo-\nrithms is at [WotsitOO], [WheelerOO], and [Gillies98].\nConclusion\nThis system can be easily upgraded or adapted to any project. Some possibilities\ninclude supporting date and time validation, copy protection algorithms, checksums,\na data pool, and better compression and encryption algorithms. There is no limit.\nReferences\n[Hargrove98] Hargrove, Chris, \"Code on the Cob 6,\" available online at\nwww.loonygames.com/content/1.11/cote/, November 2-6, 1998.\n[TownerOO] Towner, Jesse, \"Resource Files Explained,\" available online at\nwww.gamedev.net/reference/programming/features/resfiles/, January 11, 2000.\n[WheelerOO] Wheeler, David J, et al, \"TEA, The Tiny Encryption Algorithm,\" avail-\nable online at www.cl.cam.ac.uk/ftp/users/djw3/tea.ps.\n[WotsitOO] Wotsit.org, \"The Programmer's File Format Collection: Archive Files,\"\navailable online atwww.wotsit.org, 1996—2000.\n[Gillies98] Gillies, David A. G., \"The Tiny Encryption Algorithm,\" available online\nat http://vader.brad.ac.uk/tea/tea.shtml, 1995-1998.\n\n\n1.16\nGame Input Recording and\nPlayback\nBruce Dawson, Humongous Entertainment\nbruced@humongous.com\nT\nhe eighteenth-century mathematician and physicist Marquis Laplace postulated\nthat if there was an intelligence with knowledge of the position, direction, and\nvelocity of every particle of the universe, this intelligence would be able to predict by\nmeans of a single formula every detail of the total future as well as of the total past\n[ReeseSO]. This is determinism.\nChaos theory, Heisenberg's uncertainty principle, and genuine randomness in\nquantum physics have combined to prove determinism wrong. However, in the sim-\nplified universe of a game, Laplace's determinism actually works. .\nIf you carefully record everything that can affect the direction of your game uni-\nverse, you can replay your record and recreate what happened.\nWhat Exactly Is Input Recording Useful For?\nGame input recording is useful for more things than many people realize: reproduc-\ning rare bugs, replaying interesting games, measuring optimizations, or creating game\nmovies.\nReproducing Bugs\nComputer programs are deterministic and completely predictable, yet we frequently\nhear about people encountering bugs that are difficult to reproduce, and therefore dif-\nficult to fix. If computers are deterministic, how can bugs be difficult to reproduce?\nOccasionally, the culprit is the hardware or OS. The timing of thread switching\nand the hard drive is not completely consistent, so race conditions in your code can\nlead to rare crashes. However, the rare crashes are most frequently caused by a partic-\nular combination of user input that happens to be very rare. In that case, the bug is at\nleast theoretically reproducible, if only we can reproduce the exact input sequence\nagain.\nVideotaping of testing helps track some of these bugs, but it doesn't help at all if\nthe timing is critical. Why don't we put that computer predictability to work, by hav-\ning the computer program record all input and play it back on demand?\n105\n\n\nSection 1 General Programming\nThe crucial step here is that if we are to use input recording to track bugs, we have\nto make sure that the input is recorded even when the game crashes—especially when\nthe game crashes! On Win32, this is typically quite easy. By setting up a structured\nexception handler [Dawson99], we can arrange for our input buffer to be saved when-\never the game crashes.\nIf we add an option to our game engine to \"fast-forward\" through game input\n(only rendering a fraction of the frames), we can get to the crash more quickly. If we\nalso add an option to render frames at the exact same points in the game update loop,\nwe can easily reproduce what are likely to be the relevant portions of the crash\nscenario.\nReproducing bugs is the one time when you will want to record and playback all\nof the user input, including the interactions with menu screens. Menu code is not\nimmune to tricky bugs.\nReplaying Interesting Games\nThe most common use of game input recording is for players to record interesting\ngames. These recordings are used to demonstrate how to play the game, to make tuto-\nrials, to test the performance of new computer hardware, or to share games.\nThe most important thing about recording games for users to play back later is\nthat the recording must always be enabled. It is unrealistic to expect users to decide at\nthe beginning of the game whether they want to record the game for posterity; they\nshould be asked at the end whether they want to permanently store the recorded\ngame.\nMeasuring Optimizations\nThe most important thing to do when optimizing is to measure the actual perfor-\nmance, both before and after. Failing to do this leads to a surprisingly frequent ten-\ndency to check in \"optimizations\" that actually slow the code.\nMeasuring the performance of a game is tricky because it varies so much. Polygon\ncount, texture set, overdraw, search path complexity, and the number of objects in the\nscene all affect the frame rate. Timing any single frame is meaningless, and a quick\nrun-through is hopelessly unscientific.\nGame input playback is a great solution. If you run the same playback multiple\ntimes, recording detailed information about game performance, you can chart your\nprogress after each change to see how you're doing and where you still need work.\nRecording the average and worst-case frame rate and the consistency of the frame rate\nbecomes easier and much more meaningful.\nTesting optimizations with game input playback doesn't always work because\nyour changes might affect the behavior—your wonderful new frame rate might just\nmean the player has walked into a closet. Therefore, when using game input playback\nfor optimization testing, it is crucial that you record critical game state and check for\nchanges on playback.\n\n\n1.16 Game Input Recording and Playback \n107\nCreating Game Movies\nTo create a demo reel, you can hook a VCR up to a video capable graphics card and\nplay the game; however, the results will not be pretty. The VCR, the video encoder,\nand the variable frame rate of the game will lead to a blurry, jerky mess.\nWith game input recording, it's trivial to record an interesting game, and then\nplay it back. With some trivial modifications to the engine you will be able to tell the\ngame engine when you are at an interesting part of the playback, at which point you\ncan switch from real-time playback to movie record playback. In this mode, the\nengine can render precisely 60 frames for each second of game play, and record each\none to disk. The frame rate may drop to an abysmal two frames per second, but it\ndoesn't matter because the canned inputs will play back perfectly.\nImplementing Multiplayer\nA number of games—X-Wing vs. TIE Fighter, and Age of Empires—have used input\nrecording and playback for their networking model [Lincroft99]. Instead of transmit-\nting player status information, they just transmit player input. This works particularly\nwell for strategy games with thousands of units.\nWhat Does ItJTake?\nGame input recording is simple in theory, and can be simple in practice as well. How-\never, there are a few subtleties that can cause problems if you're not careful.\nMaking Your Game Predictable\nFor game input recording and playback to work, your game must be predictable. In\nother words, your game must not be affected by anything unpredictable or unknow-\nable. For example, if your game can be affected by the exact timing of task switching,\nthen your game is unpredictable.\nMany games use variably interleaved update and render loops. Input is recorded\nat a set frequency. A frame is rendered and then the game update loop runs as many\ntimes as necessary to process the accumulated set of inputs.\nThis model implies that the number of times that the game update loop is run for\neach frame rendered is unpredictable; however, this needn't make the game itself\nunpredictable. If you are tracking down a bug in the Tenderer, then you may need to\nknow the exact details of how the render loop and update loop were interleaved, but\nthe rest of the time it should be irrelevant. It is worthwhile to record how many\nupdates happened for each frame, but this information can be ignored on playback\nunless you are tracking a Tenderer bug.\nHowever, if the render function does anything to change the state of the game,\nthen the variably interleaved update loop and render function do make the game\nunpredictable, and input recording will not work. One example of this is a render\nfunction that uses the same random number generator as the update loop. Another\n\n\nSection 1 General Programming\nexample can be found in Total Annihilation. In this game, the \"fog of war\" was only\nupdated when the scene was rendered. This was a reasonable optimization because it\nreduced the frequency of this expensive operation. While it ensured that the user only\never saw accurate fog, it made the game's behavior unpredictable. The unit AI used\nthe same fog of war as the Tenderer; the timing of the render function calls would sub-\ntly affect the course of the game.\nAnother example of something that can make a game unpredictable is uninitial-\nized local variables or functions that don't always return results. Either way, your\ngame's behavior will depend on whatever happened to be on the stack. These are bugs\nin your code, so you already have a good reason to track them down.\nOne tricky problem that can lead to unpredictability is sound playback. This can\ncause problems because the sound hardware handles them asynchronously. Tiny vari-\nances in the sound hardware can make a sound effect occasionally end a bit later. Even\nif the variation is tiny, if it happens to fall on the cusp between two frames, then it can\naffect your game's behavior if it is waiting for the sound to end.\nFor many games, this is not a problem because there is no synchronization of the\ngame to the end of these sounds. If you do want this synchronization, then there is a\nfairly effective solution: approximation. When you start your sound effect, calculate\nhow long the sample will play—number of samples divided by frequency. Then,\ninstead of waiting for the sound to end, wait until the specified amount of time has\nelapsed. The results will be virtually identical and they will be perfectly consistent.\nInitial State\nYou also need to make sure that your game starts in a known state, whether starting a\nnew game or loading a saved one. That usually happens automatically. However, each\ntime you recompile or change your data you are slightly changing the initial state.\nLuckily, many changes to code and data don't affect the way the game will unfold. For\ninstance, if you change the size of a texture, then the frame rate may change, but the\nbehavior should not—as long as the game is predictable. If changing the size of that\ntexture causes all other memory blocks to be allocated at different locations, then this\nshould also have no effect—as long as your code doesn't have any memory overwrite\nbugs.\nAn example of a code or data change that could affect how your game behaves\nwould be changing the initial position of a creature or wall, or slightly adjusting the\nprobability of a certain event. Small changes might never make a difference, but they\ndestroy the guarantee of predictability.\nFloating-point calculations are one area where your results may unexpectedly\nvary. When you compile an optimized build, the compiler may generate code that\ngives slightly different results from the unoptimized build—and occasionally, these\ndifferences will matter. You can use the \"Improve Float Consistency\" optimizer set-\nting in Visual C++ to minimize these problems, but floating-point variations are an\nunavoidable problem that you just have to watch for.\n\n\n1.16 Game Input Recording and Playback \n109\nRandom Numbers\nRandom numbers can be used in a deterministic game, but there are a few caveats.\nThe reason random numbers can be used is that rand() isn't really random. rand()\nis implemented using a simple algorithm—typically a linear congruential method—\nthat passes many of the tests for random numbers while being completely repro-\nducible. This is called a pseudo-random number generator. As long as you initialize\nrand() with a consistent seed, you will get consistent results. If having the randomness\nin your game different each time is important, then choose a seed for srandQ based on\nthe time, but record the seed so that you can reuse it if you need to reproduce the\ngame.\nOne problem with rand() is that it produces a single stream of random numbers.\nIf your rendering code and your game update code are both using rand()—and if the\nnumber of frames rendered per game update varies—then the state of the random\nnumber generator will quickly become indeterminate. Therefore, it is important that\nyour game update loop and your Tenderer get their random numbers from different\nlocations.\nAnother problem with rand() is that its behavior isn't portable. That is, the behav-\nior is not guaranteed to be identical on all platforms, and it is unlikely that it will be.\nThe third problem with rand() comes if you save a game and continue playing,\nand then want to reload the saved game and replay the future inputs. To make this\nwork predictably, you have to put the random number generator back to the state it\nwas in when you saved the game. The trouble is, there's no way to do this. The C and\nC++ standards say nothing about the relationship between the numbers coming out\nof rand() and the number you need to send to srand() to put it back to that state.\nVisual C++, for instance, maintains a 32-bit random number internally, but only\nreturns 15 of those bits through rand(), making it impossible to reseed.\nThese three problems lead to an inescapable conclusion: don't use rand(). Instead,\ncreate random number objects that are portable and restartable. You can have one for\nyour render loop, and one for your game update loop.\nWhen implementing your random number objects, please don't invent your own\nrandom number algorithm. Random number generators are very subtle and you are\nunlikely to invent a good one on your own. Look at your C runtime source code, the\nsample code on the CD, Web resources [Coddington], or read Knuth [KnuthSl].\nInputs\nOnce you have restored your game's initial state, you need to make sure that you can\nrecord and play back all of the input that will affect your game. If your game update\nloop is calling OS functions directly to get user input—such as calling the Win32\nfunction GetKeyState(VK_SHIFT) to find out when the Shift key is down—then it\nwill be very hard to do this. Instead, all input needs to go through an input system.\nThis system can record the state of all of the input devices at the beginning of each\nframe, and hand out this information as requested by the game update loop. The\n\n\n110 \nSection 1 \nGeneral Programming\ninput system can easily record this information to disk, or read it back from disk,\nwithout the rest of the game knowing. The input system can read data from Direct-\nInput, a saved game, the network, or a WindowProc, without the update loop know-\ning the difference. As a nice bonus, isolating the game input in one place makes your\ngame code cleaner and more portable.\nProgrammers have a habit of breaking all rules that are not explicitly enforced, so\nyou need to prevent them from calling OS input functions directly. You can use the\nfollowing technique to prevent programmers from accidentally using \"off-limits\"\nfunctions.\n#define GetKeyState Please do not use this function\ntfdefine GetAsyncKeyState Please do not use this function either\nAnother important input to a multiplayer game is the network. If you want to be\nable to replay your game, dien you need to record the incoming network data\ntogether with the user's input stream. This will allow you to replay the game, even\nwithout a network connection. The network data stream is the one type of data that\ncan actually get quite large—a game running on a 56K modem could easily receive\nmany megabytes of network data per hour. While this large data stream does make\nthe recording more unwieldy, it is not big enough to be really problematic. The ben-\nefits of recording this stream are enormous, and the costs are quite small.\nThe final \"input\" that a game might use is time. You may want certain events to\nhappen at a specific time, and it is important that these times are measured in game\ntime, not in real time. Whenever your game needs to know the time—except for pro-\nfiling purposes—it should ask the game engine for the current game time. As with the\nother input functions, it is a good idea to use the preprocessor to make sure that\nnobody accidentally writes code that calls timeGetTimeO or other OS time functions.\nIt is a good idea to record inputs throughout the game. That lets you use input\nplayback to track down bugs anywhere in the game, even in the pre-game menus.\nHowever, for many purposes you will want to store the record of the input during the\ngame separately, so that you can play it back separately.\nTesting Your Input Recording\nGame input recording should work on any well-written game. Even if your game is a\nmultiplayer game, if you record every piece of input that you receive on your\nmachine, then you should be able to reproduce the same game.\nHowever, if your game playbacks are failing to give consistent results, it can be\ndifficult to determine why. A useful option in tracking down these problems is record-\ning part of the game state along with die input—perhaps the health and location of all\nof the game entities. Then, during playback, you can check for changes and detect\ndifferences before they become visible.\n\n\n1.16 Game Input Recording and Playback \n111\nConclusion\nGame input recording and playback is a valuable part of a game engine with many\nbenefits. If it is planned from the beginning, then it is easy to add, and leads to a\nbetter-engineered and more flexible game engine. Here are some rules to follow:\n• Route all game input, including keyboard, mouse, joystick, network, and time,\nthrough a single input system, to ensure consistency and to allow recording and\nsaving of all input. This input should always be recorded. It should be stored per-\nmanently in case the game crashes or the user requests it at the end of the game.\n• Watch for floating-point optimizations or bugs in your code that can occasionally\nlead to behavior that is different or unpredictable in optimized builds.\n• The randQ function should be avoided; use random number objects instead.\n• Never change the game's state in rendering functions.\n• Store some of your game state along with the input so you can automatically\ndetect inconsistencies. This can help detect race conditions, unintended code\nchanges, or bugs.\nThe sample code on the CD includes an imput system and a random number\nclass.\nReferences\n[ReeseSO] Reese, W.L., Dictionary of Philosophy and Religion. Humanities Press, Inc.\n1980. p. 127.\n[KnuthSl] Knuth, Donald, The Art of Computer Programming, Second Edition, Vol-\nume 2, Seminumerical Algorithms.\n[Coddington] Coddington, Paul, \"Random Number Generators,\" available online at\nwww.npac.syr.edu/users/paulc/lectures/montecarlo/node98.html.\n[Dawson99] Dawson, Bruce, \"Structured Exception Handling,\" Game Developer\nmagazine (Jan 1999): pp. 52-54.\n[Lincroft99] Lincroft, Peter, \"The Internet Sucks: What I Learned Coding X-Wing\nvs. TIE Fighter,\" 1999 Game Developers Conference Proceedings, Miller Free-\nman 621-630.\n",
      "page_number": 101,
      "chapter_number": 12,
      "summary": "This chapter covers segment 12 (pages 101-108). Key topics include game, input, and code. The source of each function is\nincluded in the CD.",
      "keywords": [
        "Game Input Recording",
        "Game",
        "Game Input",
        "Input Recording",
        "Input",
        "Game input playback",
        "game update loop",
        "game update",
        "Recording",
        "random number",
        "Playback",
        "number",
        "game state",
        "input playback",
        "code"
      ],
      "concepts": [
        "game",
        "input",
        "code",
        "coding",
        "function",
        "functions",
        "recording",
        "algorithms",
        "randomness",
        "time"
      ],
      "similar_chapters": [
        {
          "book": "Game_Engine_Architecture",
          "chapter": 17,
          "title": "Segment 17 (pages 326-347)",
          "relevance_score": 0.71,
          "method": "sentence_transformers"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 40,
          "title": "Segment 40 (pages 809-829)",
          "relevance_score": 0.71,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 7",
          "chapter": 63,
          "title": "Segment 63 (pages 609-616)",
          "relevance_score": 0.7,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 3",
          "chapter": 11,
          "title": "Segment 11 (pages 111-118)",
          "relevance_score": 0.69,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 3",
          "chapter": 26,
          "title": "Segment 26 (pages 243-252)",
          "relevance_score": 0.68,
          "method": "sentence_transformers"
        }
      ]
    },
    {
      "number": 13,
      "title": "Segment 13 (pages 109-116)",
      "start_page": 109,
      "end_page": 116,
      "detection_method": "topic_boundary",
      "content": "1.17\nA Flexible Text Parsing System\nJames Boer, Lithtech, Inc.\njimb@lithtech.com\nN\nearly every modern game requires some sort of text parser. This gem, along with\nthe sample code on the CD, demonstrates a powerful but easy-to-use text pars-\ning system designed to handle any type of file format.\nText files have a number of advantages when representing data:\noNiHfco \n. They aj-e easy to reacj and efat using any standard text editor. Binary data usually\nrequires a custom-built tool that must be created, debugged, and maintained.\n• They are flexible—the same parser can be used for simple variable assignment or\na more complex script.\n• They can share constants between code and data (more on this later).\nUnfortunately, text data has a few drawbacks as well:\n• Unlike most binary formats, text must first be tokenized and interpreted, slowing\nthe loading process.\n• Stored text is not space efficient; it wastes disk space and slows file loading.\nBecause many game parameters only need to be tweaked during development, it\nmay be practical to use a text-based format during development, and then switch to a\nmore optimized binary format for use in the shipping product. This provides the best\nof both worlds: the ease of use of text files, and the loading speed of binary data. We'll\ndiscuss a method for compiling text files into a binary format later in the gem.\nThe Parsing System\nHere's what our parser will support:\n• Native support for basic data types: keywords, operators, variables, strings, inte-\ngers, floats, boots, and GUIDs\n• Unlimited user-definable keyword and operator recognition\n• Support for both C (block) and C++ (single-line) style comments\n• Compiled binary read and write ability\n• Debugging support, able to point back to a source file and line number in case of\nerror\n\n\n1.17 A Flexible Text Parsing System \n113\n• #include file preprocessing support\n• #define support for macro substitution\nMost of the preceding items are self-explanatory, but #indude files and #define\nsupport may seem a bit out of place when discussing a text parser. We'll discuss how\nthese features can greatly simplify scripts, as well as provide an additional mechanism\nto prevent scripts and code from getting out of sync.\nMacros, Headers, and Preprocessing Magic\nPreprocessing data files in the same manner as C or C++ code can have some wonder-\nful benefits. The concept is perhaps best explained by a simple example. Let's assume\nthat we wish to create a number of unique objects using a script file, which will pro-\nvide the necessary data to properly initialize each object and create unique handles for\nuse in code. Here's what such a script might look like:\nCreateFoo(l) \n{ Data = 10 }\nCreateFoo(2) \n{ Data = 20 }\nCreateFoo(3) \n{ Data = 30 }\nCreateBar(4) \n{ Foo = 1 }\nAssuming that the CreateFooQ keyword triggers the creation of a Foo object in\ncode, we now have three Foo objects in memory, each with unique member data, cre-\nated by a script. Also, assuming that we're referencing these objects with handles, we\ncan now access these objects in code with the values of 1, 2, and 3 as unique handles.\nNote that in our example, the script can also use these numeric handles. The Bar class\nrequires a valid Foo object as a data member, and so we use a reference to the first Foo\nobject created when creating our first Bar object.\nIt could get easy to lose track of the various handle values after creating several\nhundred of them. Any time an object is added in the script, the programmer must\nchange the same values in code. There are no safeguards to prevent the programmer\nfrom accidentally referencing the wrong script object. This problem has already been\nsolved in C and C++ through the use of header files in which variables and other com-\nmon elements can be designed for many source files to share. If we think of the text\nscript as simply another source file, the advantages of a C-like preprocessor quickly\nbecome apparent. Let's look again at our example using a header file instead of magic\nnumbers.\n- Header File -\n// ObjHandles.h\n// Define all our object handles\ntfdefine \nSmallFoo \n1\ntfdefine MediumFoo 2\n#define LargeFoo 3\n#define SmallBar \n4\n#define FooTypeX \n10\n\n\n114 \nSection 1 \nGeneral Programming\n#define FooTypeY \n20\ntfdefine FooTypeZ \n30\n- Script File -\n//\n// Directs the parser to scan the header file\n^include \"ObjHandles.h\"\nCreateFoo(SmallFoo) \n{ Data = FooTypeX }\nCreateFoo(MediumFoo) \n{ Data = FooTypeY }\nCreateFoo(LargeFoo) \n{ Data = FooTypeZ }\nCreateBar(SmallBar) \n{ Foo = SmallFoo }\nIn addition to this being much easier to read and understand without the magic\nnumbers, both the text script and source code share the same header file, so it's impos-\nsible for them to get out of sync.\nBecause we're already performing a simple preprocessing substitution with\n#define, it's just one more step to actually parse and use more complex macros. By rec-\nognizing generic argument-based macros, we can now make complex script opera-\ntions simpler by substituting arguments. Macros are also handy to use for another\nreason. Because macros are not compiled in code unless they are actually used (like a\nprimitive form of templates), we can create custom script-based macros without\nbreaking C++ compatibility in the header file.\nNote diat although we're processing macros and #defines, the parser does not rec-\nognize other commands such as #ifdef, #ifndef, and #endif.\nThe Parsing System Explained\nThere are five classes in our parsing system: Parser, Token, TokenList, TokenFile, and\nMacro. The Macro class is a helper class used internally in Parser, so we only need to\nworry about it in regard to how it's used inside Parser. TokenFile is an optional class\nused to read and write binary tokens to and from a standard token list. This leaves the\nheart of the parsing system: Parser, Token, and TokenList. Because Token is the basic\nbuilding block produced by the parser, let's examine it first.\nThe Token Class\nThe basic data type of the parsing system is the Token class. There are eight possible\ndata types represented by the class: keywords, operators, variables, strings, integers,\nreal numbers, Booleans, and GUIDs. Keywords, operators, variables, and strings are\nall represented by C-strings, and so the only real difference among them is semantic.\nIntegers, real numbers, and Booleans are represented by signed integers, doubles, and\nbooh. For most purposes, this should be sufficient for data representation. GUIDs, or\nGlobally Unique IDentifiers, are also given native data type status, because it's often\nhandy to have a data type that is guaranteed unique, such as for identifying classes to\ncreate from scripts.\n\n\n1.17 A Flexible Text Parsing System \n115\nThe Token class is comprised of a type field and a union of several different data\ntypes. A single class represents all basic data types. Data is accessed by first checking\nwhat type of token is being dealt with, and then calling the appropriate GetQ func-\ntion. Asserts ensure that inappropriate data access is not attempted.\nEach of the data types has a role to play in the parser, and it's important to under-\nstand how they work so that script errors are avoided. In general, the type definitions\nmatch similar definitions in C++. All keywords and tokens are case sensitive.\nKeyword\nKeywords are specially defined words that are stored in the parser. Two predefined\nkeywords are include and define. User-defined keywords are used primarily to aid in\nlexicographical analysis of the tokens after the scanning phase.\nOperator\nAn operator is usually a one- or two-character symbol such as an assignment operator\nor a comma. Operators are unique in the fact that they act like white space regarding\ntheir ability to separate other data types. Because of this, operators always have the\nhighest priority in the scanning routines, meaning that the symbols used in operators\ncannot be used as part of a keyword or variable name. Thus, using any number or\ncharacter as part of an operator should be avoided. Operators in this parsing system\nalso have an additional restriction: because of the searching method used, any opera-\ntor that is larger than a single character must be composed of smaller operators. The\nlarger symbol will always take precedence over the smaller symbols when they are not\nseparated by white space or other tokens.\nVariable\nA variable is any character-based token that was not found in the keyword list.\nString\nA string must be surrounded by double quotes. This parser supports strings of lengths\nup to 1024 characters (this buffer constant is adjustable in the parser) and does not\nsupport multiple-line strings.\nIntegers\nThe parser recognizes both positive and negative numbers and stores them in a signed\ninteger value. It also recognizes hexadecimal numbers by the Ox prefix. No range\nchecking is performed.\nFloats\nFloating-point numbers are called floats and are represented by a double value. The\nparser will recognize any number with a decimal point as a float. It will not recognize\nscientific notation, and no range checking is performed on the floating-point number.\nBooleans\nBoolean values are represented as a native C++ booltype, and true and false are built-\nin keywords. As with C++, these values are case sensitive.\n\n\n116 \nSection 1 General Programming\nQUIDs\nBy making use of the macro-expansion code, we can support GUIDs without too\nmuch extra work. Note that unless the macro is expanded with ProcessMacrosQ, the\nGUID will remain a series of separate primitive types. This function is described later.\nThe TokenLlst Class\nThe TokenList class is publicly derived from a standard STL list of Tokens. It acts\nexactly like a standard STL list of tokens, and has a couple of additional features. The\nTokenList class allows viewing of the file and line number that any given token comes\nfrom. This is exclusively an aid for debugging, and can be removed with a compile-\ntime flag.\nThe Parser Class\nThis is the heart of the parsing functionality. We first create a parser object and call\nthe CreateQ function. Note that all functions return a boot value, using true for success\nand false for failure. Next, we must reserve any additional operators or keywords\nbeyond the defaults required for the text parsing.\nAfter this comes the actual parsing. The parsing phase is done in three passes,\nhandled by three functions. Splitting the functionality up gives the user more control\nover the parsing process. Often, for simple parsing jobs, #include file processing and\nmacro substitution are not needed. The first pass reads the files and translates the text\ndirectly into a TokenList using the function ProcessSource(). The next function,\nProcessHeadersQ, looks for any header files embedded in the source, and then parses\nand substitutes the contents of those headers into the original source. The third func-\ntion, ProcessMacrosQ, performs both simple and complex C-style macro substitution.\nThis can be a very powerful feature, and is especially useful for scripting languages.\nLet's see what this whole process looks like. Note that for clarity and brevity's\nsake, we are not doing any error checking.\n/ / W e need a Parser and TokenList object to start\nTokenList toklist;\nParser parser;\n// Create the parser and reserve some more keywords and tokens\nparser.Create();\nparser.ReserveKeyword(\"special_keyword\");\nparser.ReserveOperator(\"[\");\nparser.ReserveOperator(\"]\");\n// Now parse the file, any includes, and process macros\nparser.ProcessSource(\"data\\scripts\\somescript.txt\", &toklist);\nparser.ProcessHeaders(&toklist);\nparser.ProcessMacros(&toklist);\n\n\n1.17 A Flexible Text Parsing System \n117\nThe TokenFile Class\nBecause parsing and processing human readable text files can be a bit slow, it may be\nnecessary to use a more efficient file format in the shipping code. The TokenFile class\ncan convert processed token lists into a binary form. This avoids having to parse the\ntext file multiple times, doing #include searches, macro substitutions, and so forth.\nCharacter-based values, such as keywords, operators, and variables, are stored in a\nlookup table. All numeric values are stored in binary form, providing additional space\nand efficiency savings. In general, this binary form can be expected to load five to ten\ntimes as fast as the text-based form.\nUsing the TokenFile class is simple as well. The WriteQ function takes a TokenList\nobject as an argument, and creates the binary form using either the output stream or\nfilename that was specified. The class can also store the file in either a case-sensitive or\ncase-insensitive manner. If both the variable \"Foo\" and \"foo\" appear in the script,\nturning the case sensitivity off will merge them together in the binary format, provid-\ning further space savings. It defaults to off.\nReading the file is performed with the Read() function. Here's how it looks in\ncode:\nTokenFile tf;\n// Write a file to disk\ntf.Write(\"somefile.pcs\", &toklist);\n//Or read it\ntf.Read(\"somefile.pcs\", &toklist);\nWrapping Up\nText file processing at its simplest level is a trivial problem requiring only a few lines\nof code. For anything more complex than this, however, it's beneficial to have a com-\nprehensive text-parsing system that can be as flexible and robust as the job demands.\n\n\n1.18\nA Generic Tweaker\nLasse Staff Jensen, Funcom\nlasse@funcom.com\n(uring game development, one of the most frequent tasks we perform is tweaking\nvariables until the game has just the right balance we need. In this gem, we\nwill cover an easy-to-use \"tweaker\" interface and the design issues behind the\nimplementation.\nRequirements Analysis\nOne of the primary goals of a generic tweaker interface is to make it as transparent\nand easy to use as possible. The user in this case is the programmer who exposes vari-\nables to be tweaked. Further requirements to emphasise are the size in memory, the\nability to tweak a variable without too much added overhead, and the speed of actu-\nally tweaking a variable (because in some cases the tweaker will be used in the release\nbuild as well).\nLet's try to break down the requirements in more detail, and see what the imple-\nmentation really needs to do:\n• It should be transparent to the coder, meaning that the variables we want to\ntweak shouldn't contain any additional data and/or functionality, and that the\nusage of these variables shouldn't need to know about the tweaker at all.\n• It should be simple to use, meaning that the user should be able to define vari-\nables to be tweaked in less than 10 lines of code, and be able to tweak and get\nvariables from a common database in typically two or three lines of code.\nImplementation\nDesign\nFigure 1.18.1 contains the UML diagram of the classes to be presented in a bottom-\nup fashion in the rest of this gem. The type information and the tweakable hierarchy\nare the essence of this design.\n118\n\n\n\"*\"'\n1' l;l\"wfer\nTweaker_c\n^Tweakables: TweakableBase_c\n*AddTweakable()\n*TweakValue()\nTweakerlnstanceDB^c\n^Categories: Tweaker_c\n^Instances: Tweaker_c\n*AddTweaker()\nFIGURE 1.18.1 Overview of the tweaker classes.\nTweakableTypeRange_c\n: void\n: void\n^TypelD_c*: void\n*GetMax()\n*GetMin()\n*GetStoredType()\nlntTypelD_c\n*GetType()\nFloatTypelD_c\n*GetType()\nBoolTypelD_c\n*GetType()\n(O\n",
      "page_number": 109,
      "chapter_number": 13,
      "summary": "This gem, along with\nthe sample code on the CD, demonstrates a powerful but easy-to-use text pars-\ning system designed to handle any type of file format Key topics include data, file, and text.",
      "keywords": [
        "Text Parsing System",
        "Flexible Text Parsing",
        "data",
        "Parsing System",
        "Text",
        "parser",
        "file",
        "Text Parsing",
        "Text files",
        "data types",
        "header file",
        "Flexible Text",
        "code",
        "System",
        "Token"
      ],
      "concepts": [
        "data",
        "file",
        "text",
        "parser",
        "classes",
        "script",
        "define",
        "defined",
        "function",
        "functionality"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 3",
          "chapter": 8,
          "title": "Segment 8 (pages 85-92)",
          "relevance_score": 0.68,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 3",
          "chapter": 9,
          "title": "Segment 9 (pages 93-101)",
          "relevance_score": 0.57,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 7",
          "chapter": 55,
          "title": "Segment 55 (pages 530-540)",
          "relevance_score": 0.57,
          "method": "sentence_transformers"
        },
        {
          "book": "Python Distilled",
          "chapter": 32,
          "title": "Segment 32 (pages 289-298)",
          "relevance_score": 0.57,
          "method": "sentence_transformers"
        },
        {
          "book": "Designing Machine Learning Systems An Iterative Process for Production-Ready Applications",
          "chapter": 10,
          "title": "Segment 10 (pages 80-87)",
          "relevance_score": 0.56,
          "method": "sentence_transformers"
        }
      ]
    },
    {
      "number": 14,
      "title": "Segment 14 (pages 117-128)",
      "start_page": 117,
      "end_page": 128,
      "detection_method": "topic_boundary",
      "content": "Section 1 General Programming\nType Information\nWe will use template specialization to provide type information that we can store in a\nuniform way. First is our base class TypelDjc that defines the interface for our type\ninformation class with a virtual function that returns a string with the type name:\nclass TypeID_c {\npublic:\nvirtual const char* GetTypeNameO const { return \"Unknown\"; }\n};\nNext, we create a template class that we can use to retrieve the correct type when\ngiven the variable. In this class, we add a member to get the pointer to our TypeID_c\ninstance that can be tested directly for the stored pointer address.\ntemplate <class T>\nclass Identifier_c {\npublic:\nstatic const TypeID_c* const GetType();\nNow that we have this class declared, we will use template specialization to define\neach unique type. Each subclass of TypeID_c will exist as a singleton, and the pointer\nto that instance serves as the identifier of the type. For simplicity, all of these will be\nplaced in the global scope through static members. We can make sure that the actual\ninstances exist, if called from other static functions, by receiving the pointer from the\nGetldentification method. The full implementation for float values follows:\nclass floatID_c : public TypeID_c {\npublic:\nvirtual const char* GetTypeNameO const { return \"float\"; }\nstatic TypeID_c* const Getldentification () ;\n} 5\ntemplate <>\nclass Identifier_c<float> {\npublic:\nstatic const TypeID_c* const GetType() {\nreturn floatID_c: :GetIdentification() ;\nTypeID_c* const floatID_c: :GetIdentification() {\nstatic floatID_c clnstance;\nreturn &clnstance;\nTo use these classes for type information, we can simply store the base pointer:\nfloat vMyFloat;\nconst TypeID_c* const pcType = TweakableBase_c: :GetTypeID( vMyFloat ) ;\n\n\n1.18 A Generic Tweaker \n121\nHere, the TweakableBase_c (more on this class later) has a template member that\ncalls the correct Identifier^ specialization. Then we can test the address of the\npointer:\nif( Identifier_c<float>::GetType() == pcType ) {\n// We have a float!\n}\nThere are two macros for defining user types in the code on the accompanying\nCD, so all that's required for support of a new data type is to place a call to\nDECLARE_DATA_TYPE in the header and DEFINE_DATA_TYPE in the imple-\nmentation file, and then recompile. (In addition, one might want to add a call to the\nmacro DUMMY_OPERATORS () in case one doesn't want to support range checking.)\nTweakableBase_c\nWe have a clean and easy way to store type info, so let's continue by creating the base\nclass to hold the pointer to the tweakable variable. This class also contains the tem-\nplate member for getting the type info mentioned earlier. Because one of our require-\nments is to keep memory overhead to a minimum, we will use RTTI for checking\nwhich specific types of tweakables we have stored in memory. We therefore make sure\nthe class is polymorphic by adding a virtual function to get the type info stored (or\nNULL if none). Here is the implementation:\nclass TweakableBase_c {\npublic:\nTweakableBase_c( void* i_pData ) : m_pData( i_pData ) {;}\n-TweakableBase_c() { /*NOP*/;}\nvirtual const TypeID_c* const GetStoredType() const { return NULL; }\ntemplate <class T>\nstatic const TypeID_c* const GetTypeID( const T& i_cValue ) {\nreturn Identifier_c<T>::GetType();\n}\nprotected:\nvoid* m_pData;\n}; \n// TweakableBase_c\nNow that we have the base class, we can create subclasses containing additional\ndata such as type information, limits for range checking, a pointer for a call-back func-\ntion, and any other data we might need to attach to the various tweakables, while keep-\ning die memory to a minimum. Here is how one of the specific tweakable classes looks:\ntemplate <class T>\nclass TweakableType_c : public TweakableBase_c {\n\n\n122 \nSection 1 \nGeneral Programming\npublic:\nTweakableType_c( T* i_pxData, const TypeID_c* i_pcType ) :\nTweakableBase_c( reinterpret_cast<void*>( i_pxData ) ),\nm_pcType( i_pcType ) { /*NOP*/; }\nconst TypeID_c* const GetDataType() const { return m_pcType; }\nvirtual const TypeID_c* const GetStoredType() const {\nreturn m_pcType; }\nprivate:\nconst TypeID_c* const m_pcType; \n:\n}; \n// TweakableType_c\nThe great thing about this code is that the subclasses are implemented as tem-\nplates, even though the base class was defined without them. This way, we can pass in\nthe pointer to the actual data type, hiding the casting to void horn the interface.\nTweakerje\nWe finally have all the building blocks we need to create the tweaker class itself. This\nclass will store all of our tweakables and give the user functionality for tweaking the\nstored values. We will use an STL map to hold all of the pointers to our tweakables,\nusing the name of each tweakable as the key. Simple template members provide all the\nfunctionality. An example of this is the TweakValue member:\ntemplate<class Value_x>\nTweakError_e TweakValue( const std::string& i_cID, const Value_x&\ni_xValue ) {\nTweakableBase_c* pcTweakable;\niTweakableMap_t iSearchResult = m_cTweakable_map.find( i_cID );\nif( iSearchResult == m_cTweakable_map.end() ) {\nreturn e_UNKNOWN_KEY; }\npcTweakable = (*iSearchResult).second;\n#ifdef _DEBUG\nTweakableType_c<Value_x>* pcType;\nif( pcType = dynamic_cast< TweakableType_c<Value_x>* >(\npcTweakable ) ) {\nassert( pcTweakable->GetTypeID( i_xValue ) ==\npcType-»GetDataType() );\n}\n#endif\nTweakableTypeRange_c<Value_x>* pcTypeRange;\nif ( pcTypeRange = dynamic_cast< TweakableTypeRange_c<Value_x>* >(\npcTweakable ) )\n{\nassert( pcTweakable->GetTypeID( i_xValue ) ==\npcTypeRange->GetDataType() );\nif( i_xValue < pcTypeRange->GetMin() ) { return e_MIN_EXCEEDED; }\nif( i_xValue > pcTypeRange->GetMax() ) { return e_MAX_EXCEEDED; }\n\n\n1.18 A Generic Tweaker \n123\n*(reinterpret_cast<Value_x*>( pcTweakable->m_pData ) ) = i_xValue;\nreturn e_OK;\n} // TweakValue\nBecause the member is a template, we can cast back to the given value directly,\nthereby completely hiding the ugly void casting. Note that if users decide to not store\nthe type information, they could easily force us to do something bad, since we have\nno way of checking the origin of the reinterpret_casA\nTweakerinstanceDB_c\nIn order to support grouping of tweakables and the ability to store several instances of\na given variable, we have an instance database to hold different tweakers. The imple-\nmentation is straightforward—an STL multimap holding all of the instances of differ-\nent tweakers, and an STL map of these multimaps where the category is the key.\nLet's test our implementation against the requirements to verify that we have reached\nour goals. Defining a variable to be tweakable requires us to create a tweaker and add\nit to the tweakable instance database.\nTweaker_c* pcTweaker = TweakerInstanceDB_c::AddTweaker( \"Landscape\",\nTWEAKER_CREATE_ID( this ), \"Graphics\" );\nHere we create a tweaker for the class Landscape (inside the constructor, for exam-\nple) and put it in the Graphics category. The TWEAKER_CREATE_ID macro takes\nthe this pointer and makes sure that each instance of the class Landscape gets a unique\nID. Then, we simply add each variable to this (and other tweakers we make) by:\npcTweaker->AddTweakable( &m_vShadowmapScaleTop, \"Shadowmap scale\",\nO.OF, 68.OF );\nHere we have added a variable, constrained it to the interval [0, 68], and called it\n\"Shadowmap scale.\" It's vital to note that because of the template nature of the\nAddTweakable method, we must pass correct types to all of the arguments (for exam-\nple, use O.OF and not just 0). Defining a variable to be tweakable takes two lines of\ncode, and is totally hidden from the users of the variable in question.\nFor tweaking this variable, all we need is the name, data type, and desired\ninstance. Usually, we have the pointer to the tweaker instance itself, but in the GUI\ncode, one would typically do something like:\nTweakerInstanceDB_c::iConstCategoryMap_t iCategory =\nTweakerInstanceDB_c::GetCategory( \"Graphics\" );\nTweaker_c* pcTweaker =\nGetTweaker( iCategory->second, \"Landscape\", TWEAKER_CREATE_ID(\npcLandscape ) ) ;\n\n\n124 \nSection 1 General Programming\nHere we first get all of the instance maps that are stored under the \"Graphics\" cat-\negory label. Then we search for the correct instance of the Landscape class (we assume\nthe pointer pcLandscape points to the instance in question). Changing the value of a\nspecific value is straightforward.\nTweaker_c::TweakError_e eError;\neError = pcTweaker->TweakValue( \"Shadowmap scale\", 20.OF );\nSo, tweaking a variable is one line of code, with additional lines for error handling\n(or simply asserting the return value). Receiving the stored value is done similarly:\nfloat vShadowmapScale;\neError = pcTweaker->GetValue( \"Shadowmap scale\", &vShadowmapScale );\nGraphical User Interface\nGUIs tend to be specific to each project, so I have left a general discussion of this\ntopic out of this gem, although I will describe an existing implementation as a source\nfor ideas. In Equinox, Funcom's next-generation 3D engine, we have implemented a\ndirectory structure, as shown in Figure 1.18.2, that can be browsed in a console at the\ntop of the screen.\nFor tweaking values, we have defined input methods that can be assigned to the\ntweakables. That way, we can create specialized input methods such as the angle\ntweaker seen in Figure 1.18.3.\nFor saving and loading, in addition to the binary snapshots, we can save all of the\ntweakables in #define statements directly into h files. Because the number of instances\nof a variable could change over the lifetime of the application, we only save the first\ninstance into the header file. This feature gives us the capability to add variables to be\ntweaked only in debug builds, and we then #indude the header file to initialize the\nTweaker: Application\n[..,.]„ \n._ \n,\n\"Fog density\"\"\"\"\" '\" \" \n\"' \n\"•' \"™\"™\" \"\"\" \n—••*•->• .-.•-.-••«\nFog end\nFog start\nLinear fog\nPhysical water\nShow Equinox logo\nShow caustics\nShow fog\nShow landscape\nShow sky\nShow water\nTable fog\nFIGURE 1.18.2 \nScreen shot from our GUI. The user can move up and down in the\ndirectories (categories in the code) and choose values to be tweaked.\n\n\n1.18 A Generic Tweaker \n125\nTweaker: Graphics\nTweaker instance name: GraphicsTestInstance\nAngleTweak 1/2\nType: float\nUalue = 56.649902\nLimited to range <45.080000, 120.800008>\nstep = 8,758006, use +/—/spaee to modify\nFIGURE 1.18.3 \nThis specialized input gives the user the possibility to visually tweak\nangles in an intuitive way.\nvariables to the latest tweaked value in the release build. Here is a sample of how this\nworks for our ShadowmapScale variable:\nlandscape_tweakables.h:\ntfdefine \nSHADOWMAP_SCALE \n43.5\nlandscape.cpp:\ntfinclude \n\"landscape_tweakables.h\"\nm_vShadowmapScale = SHADOWMAP_SCALE;\nIt is possible to use the RTTI typeidQ to replace the type information code detailed\npreviously. There are pros and cons to using our type information code.\nPros:\n• It takes up less space for the type information, since it is only required for classes\nthat use it.\n• One can add specific information to the TypeID_c class; for example, a way to\nload and store the type or a pointer to the GUI control.\nCons:\nWe have to use macros for each unique type, while RTTI provides the type infor-\nmation automatically.\n\n\n126 \nSection 1 General Programming\nAcknowledgment\nI would like to thank Robert Golias for invaluable help and suggestions, and for\nimplementing the Equinox tweaker GUI that was an excellent test of how simple the\ninterface actually turned out!\n\n\n1.19\nGenuine Random Number\nGeneration\nPete Isensee, Microsoft\npkisensee@msn.com\nC\nomputer games use random numbers extensively for rolling dice, shuffling cards,\nsimulating nature, generating realistic physics, and performing secure multi-\nplayer transactions. Computers are great at generating pseudo-random numbers, but\nnot so good at creating genuine random numbers. Pseudo-random numbers are num-\nbers that appear to be random, but are algorithmically computed based on the previ-\nous random number. Genuine, or real, random numbers are numbers that not only\nappear random, but are unpredictable, nonrepeating and nondeterministic. They are\ngenerated without the input of the previous random number. This gem presents a\nmethod of creating genuine random numbers in software.\nPseudo-Randomness\nPseudo-random number sequences eventually repeat themselves and can always be\nprecisely reproduced given the same seed. This leads to distinct problems in gaming\nscenarios. Consider the common case of a game that initializes its random number\ngenerator (RNG) with the current tick count - the number of ticks since the machine\nwas booted up. Now assume the player turns on their gaming console every time they\nbegin playing this game. The level of randomness in the game is gated by the choice\nof seed, and the number of bits of randomness in the seed is unacceptably small.\nNow consider the use of a pseudo-RNG to create secret keys for encrypting\nsecure multiplayer game transmissions. At the core of all public key cryptographic sys-\ntems is the generation of unpredictable random numbers. The use of pseudo-random\nnumbers leads to false security, because a pseudo-random number is fully pre-\ndictable—translate: easily hacked—if the initial state is known. It's not uncommon\nfor the weakest part of crypto systems to be the secret key generation techniques\n[Kelsey98].\nGenuine Randomness\nA genuine random number meets the following criteria: it appears random, has\nuniform distribution, is unpredictable, and is nonrepeating. The quality of\n127\n\n\n128 \nSection 1 General Programming\nunpredictability is paramount for security purposes. Even given full knowledge of the\nalgorithm, an attacker should find it computationally infeasible to predict the output\n[Schneier96].\nThe ideal way of creating genuine random numbers is to use a physical source of\nrandomness, such as radioactive decay or thermal noise. Many such devices exist; see\n[Walker(a)] for one example. However, PCs and video game consoles do not typically\nhave access to these types of devices. In the absence of a hardware source, the tech-\nnique recommended by RFC 1750 [Eastlake94] is \"to obtain random input from a\nlarge number of uncorrelated sources and mix them with a strong mixing function.\"\nBy taking input from many unrelated sources, each with a few bits of randomness,\nand thoroughly hashing and mashing them up, we get a value with a high degree of\nentropy—a truly random number.\nRandom Input Sources\nExamples of random input available on many PCs and game consoles include:\n• System date and time\n• Time since boot at highest resolution available\n• Username or ID\n• Computer name or ID\n• State of CPU registers\n• State of system threads and processes\n• Contents of the stack\n• Mouse or joystick position\n• Timing between last N keystrokes or controller input\n• Last N keystroke or controller data\n• Memory status (bytes allocated, free, etc.)\n• Hard drive state (bytes available, used, etc.)\n• Last N system messages\n• GUI state (window positions, etc.)\n• Timing between last N network packets\n• Last N network packet data\n• Data stored at a semi-random address in main memory, video memory, etc.\n• Hardware identifiers: CPU ID, hard drive ID, BIOS ID, network card ID, video\ncard ID, and sound card ID\nSome of these sources will always be the same for a given system, like the user ID\nor hardware IDs. The reason to include these values is that they're variable across\nmachines, so they're useful in generating secret keys for transmitting network data.\nSome sources change very little from sample to sample. For instance, the hard drive\nstate and memory load may only change slightly from one read to the next. However,\neach input provides a few bits of randomness. Mixed together, they give many bits of\nrandomness.\n\n\n1.19 Genuine Random Number Generation \n129\nThe more bits of entropy that can be obtained from input sources, the more ran-\ndom the output. It's useful to buffer sources such as mouse positions, keystrokes, and\nnetwork packets over time in a circular queue. Then the entire queue can be used as\nan input source.\nHardware Sources\nSome gaming platforms have access to physical sources of randomness. When these\nsources are available, they make excellent input sources. Examples of physical sources\ninclude:\n• Input from sound card (for example, the microphone jack) with no source\nplugged in\n• Input from a video camera\n• Disk drive seek time (hard drive, CD-ROM, DVD)\n• Intel 810 chipset hardware RNG (a thermal noise-based RNG implemented in\nsilicon) [Intel99]\nMixing Function\nIn the context of creating genuine random numbers, a strong mixing function is a\nfunction where each bit of the output is a different complex and nonlinear function of\neach and every bit of the input. A good mixing function will change approximately\nhalf of the output bits given a single bit change in the input.\nExamples of strong mixing functions include:\n• DES (and most other symmetric ciphers)\n• Diffie-Hellman (and most other public key ciphers)\n• MD5, SHA-1 (and most other cryptographic hashes)\nSecure hashing functions such as MD5 are the perfect mixers for many reasons:\nthey meet the basic requirements of a good mixing function, they've been widely ana-\nlyzed for security flaws, they're typically faster than either symmetric or asymmetric\nencryption, and they're not subject to any export restrictions. Public implementations\nare also widely available.\nLimitations\nUnlike generating pseudo-random numbers, creating genuine random numbers in\nsoftware is very slow. For the output to be truly random, many sources must be sam-\npled. Some of the sampling is slow, such as reading from the hard drive or sound card.\nFurthermore, the sampled input must be mixed using complex algorithms.\nGame consoles have a more limited selection of input sources compared to PCs,\nso they will tend to produce less random results. However, newer consoles often have\ndisk drives of some sort (CD-ROM, DVD, hard disk) that can be used as good hard-\nware sources of entropy.\n\n\nSection 1 \nGeneral Programming\nThe randomness of the results depends solely on the level of entropy in the input\nsamples. The more input samples and the more entropy in each sample, the better the\noutput. Keep in mind that the more often this algorithm is invoked in quick succes-\nsion, the less random the output, because the smaller the change in the input bits. To\nsum up, this technique is not a replacement for pseudo-RNG. Use this technique for\nthe one-time generation of your RNG seed value or for generating network session\nkeys that can then be used for hours or days.\nImplementation\nA C++ example of a genuine random number generator is provided on the accompa-\nnying CD. Any implementation of this algorithm will naturally be platform depen-\ndent. This particular version is specific to the Win32 platform, but is designed to be\neasily extensible to other platforms. It uses hardware sources of randomness, such as\nthe Intel RNG and sound card input, when those sources are available. In the inter-\nests of efficiency and simplicity, it does not use all of the examples listed previously as\ninput, but uses enough to produce a high level of randomness.\nThe primary functionality resides in the GenRand object within the TrueRand\nnamespace. Here is an example use of GenRand to create a genuine seed value:\n#include \"GenRand. h\" // Genuine random number header\nunsigned int nSeed = TrueRand: :GenRand() .GetRandInt() ;\nHere's another example showing the generation of a session key for secure net-\nwork communication. The Buffer object is a simple wrapper around stof: :toasic__\nstring<unsigned char>, which provides the functionality we need for reserving\nspace, appending data, and tracking the size of the sample buffer:\nTrueRand: : GenRand randGen;\nTrueRand: : Buffer bufSessionKey = randGen. GetRand( );\nThe Get/tend () function is the heart of the program. It samples the random\ninputs, and then uses a strong mixing function to produce the output. This imple-\nmentation uses MD5 hashing, so the resulting buffer is the length of an MD5 hash\n(16 bytes). The mCrypto object is a wrapper around the Win32 Crypto API, which\nincludes MD5 hashing.\nBuffer GenRand: :GetRand()\n{\n// Build sample buffer\nBuffer randlnputs = GetRandomlnputsO ;\n// Mix well and serve\nreturn mCrypto.GetHash( CALG_MD5, randlnputs );\n\n\n1.19 Genuine Random Number Generation \n131\nThe GetRandomlnputsf) function is the input sampler. It returns a buffer with\napproximately 10K of sampled data. This function can easily be modified to include\nmore or less input as desired. Because the time spent in the function varies according to\nsystem (drive, sound card) access, we can use the hardware latency as a source of random\ninput; hence, the snapshot of the current time at the beginning and end of the function.\nBuffer GenRand: :GetRandomInputs()\n{\n// For speed, preallocate input buffer\nBuffer randln;\nrandln. reserve ( GetMaxRandInputSize() );\nGetCurrTime( randln ); \n// append time to buffer\nGetStackState( randln ); \n// stack state\nGetHardwareRng( randln ); \n// hardware RNG, if avail\nGetPendingMsgs( randln ); \n// pending Win32 msgs\nGetMemoryStatus( randln ); \n// memory load\nGetCurrMousePos( randln ); \n// mouse position\n// . . . etc.\nGetCurrTime( randln ); \n// random hardware latency\nreturn randln;\n}\nFinally, here's one of the input sampling functions. It extracts the current time,\nand then appends the data to the mRandlnputs buffer object. QueryPerformance-\nCounter() is the highest resolution timer in Windows, so it provides the most bits of\nrandomness. We can ignore API failures in this case (and many others), because the\nworst that happens is that we append whatever random stack data happens to be in\nPerf Counter if the function fails.\nvoid GenRand: :GetCurrTime( Buffer& randln )\n{\nLARGE_INTEGER Perf Counter;\nQueryPerformanceCounter( &PerfCounter ); // Win32 API\nAppend( randln, PerfCounter );\nHow Random Is GenRand?\nThere are many tests for examining the quality of random numbers. One test is the\n^ c \"\"\") \npublicly available program ENT [Walker(b)], included on the accompanying CD,\nmm CD \nwhich applies a suite of tests to any data stream. Tests of GenRand () without using any\nsources of hardware input (including hard drive seek time), and generating a file of\n25,000 random integers using GetRandInt() gives the following results:\n• Entropy = 7.998199 bits per byte.\n• Optimum compression would reduce the size of this 100,000-byte file by 0 percent.\n",
      "page_number": 117,
      "chapter_number": 14,
      "summary": "Section 1 General Programming\nType Information\nWe will use template specialization to provide type information that we can store in a\nuniform way Key topics include random, returns, and input.",
      "keywords": [
        "Genuine Random Number",
        "Random Number",
        "Random",
        "const",
        "const TypeID",
        "Genuine Random",
        "Type",
        "input",
        "Type Information",
        "static const TypeID",
        "number",
        "creating genuine random",
        "Tweaker",
        "random input",
        "sources"
      ],
      "concepts": [
        "random",
        "returns",
        "input",
        "classes",
        "function",
        "functions",
        "functionality",
        "useful",
        "uses",
        "buffer"
      ],
      "similar_chapters": [
        {
          "book": "C++ Templates_ The Complete Guide",
          "chapter": 1,
          "title": "Segment 1 (pages 1-35)",
          "relevance_score": 0.64,
          "method": "sentence_transformers"
        },
        {
          "book": "C++ Templates_ The Complete Guide",
          "chapter": 54,
          "title": "Segment 54 (pages 1729-1761)",
          "relevance_score": 0.62,
          "method": "sentence_transformers"
        },
        {
          "book": "More Effective C++",
          "chapter": 3,
          "title": "Segment 3 (pages 17-24)",
          "relevance_score": 0.61,
          "method": "sentence_transformers"
        },
        {
          "book": "C++ Templates_ The Complete Guide",
          "chapter": 30,
          "title": "Segment 30 (pages 950-980)",
          "relevance_score": 0.6,
          "method": "sentence_transformers"
        },
        {
          "book": "C++ Templates_ The Complete Guide",
          "chapter": 61,
          "title": "Segment 61 (pages 1953-1984)",
          "relevance_score": 0.6,
          "method": "sentence_transformers"
        }
      ]
    },
    {
      "number": 15,
      "title": "Segment 15 (pages 129-137)",
      "start_page": 129,
      "end_page": 137,
      "detection_method": "topic_boundary",
      "content": "132 \nSection 1 General Programming\n• Chi square distribution for 100,000 samples is 250.13, and randomly would\nexceed this value 50 percent of the time.\n• Arithmetic mean value of data bytes is 127.4918 (127.5 = random).\n• Monte Carlo value for Pi is 3.157326293 (error 0.50 percent).\n• Serial correlation coefficient is 0.000272 (totally uncorrelated = 0.0).\nThese results indicate that the output has a high degree of randomness. For\ninstance, the chi square test—the most common test for randomness [Knuth98]—\nindicates that we have a very random generator.\nReferences\n[Callas96] Callas, Jon, \"Using and Creating Cryptographic-Quality Random Num-\nbers,\" available online at www.merrymeet.com/jon/usingrandom.html, June\n1996.\n[Eastlake94] Eastlake, D., Network Working Group, et al, \"Randomness Recommen-\ndations for Security,\" RFC 1750, available online at www.faqs.org/rfcs/\nrfcl750.html, December 1994. \n]\n[Kelsey98] Kelsey, J., et al, \"Cryptanalytic Attacks on Pseudorandom Number Gener-\nators,\" available online at www.counterpane.com/pseudorandom_number .html,\nMarch 1998.\n[Intel99] Intel Corporation, \"Intel Random Number Generator,\" available online at\nhttp://developer.intel.com/design/security/rng/rng.htm, 1999.\n[Knuth98] Knuth, Donald, The Art of Computer Programming, Volume 2: Seminu-\nmerical Algorithmsi Third Edition. Addison-Wesley. 1998.\n[Schneier96] Schneier, Bruce, Applied Cryptography, Second Edition. John Wiley &\nSons. 1996.\n[Walker(a)] Walker, John, \"HotBits: Genuine Random Numbers Generated by\nRadioactive Decay,\" available online at www.fourmilab.ch/hotbits/.\n[Walker(b)] Walker, John, \"ENT: A Pseudorandom Number Sequence Test Pro-\ngram,\" available online at www.fourmilab.ch/random/.\n\n\n1.20\nUsing Bloom Filters to\nImprove Computational\nPerformance\nMark Fischer, Beach Software\nbeach@beachsoftware.com\nI\nmagine the desire to store Boolean information in a bit array—a very simple\npremise. Simply assign each element in the bit array to a specific meaning, and then\nassign it a value. In this scenario, it takes 1 bit in the array to store 1 bit of stored\ninformation. The bit array faithfully represents its relative value with 100-percent\naccuracy. This, of course, works best when the stored data is array oriented such as a\ntransient over time or space. However, what if the data is not a linear transient-\noriented data set?\nBloom's Way\nIn 1970, Burton H. Bloom published a simple and clever algorithm [Bloom70] in the\n\"Communications of the ACM.\" In his publication, Bloom suggests using a \"Hash\nCoding with Allowable Errors\" algorithm to help word processors perform capitaliza-\ntion or hyphenation on a document. This algorithm would use less space and be faster\nthan a conventional one-to-one mapping algorithm. Using this example, a majority of\nwords (90 percent, for example) could be checked using a simple rule, while the\nsmaller minority set could be solved with an exception list used to catch the instances\nwhere the algorithm would report a word as simply solvable when it was not. Bloom's\nmotivation was to reduce the time it took to look up data from a slow storage device.\nPossible Scenarios\nA Bloom Filter can reduce the time it takes to compute a relatively expensive and rou-\ntinely executed computation by storing a true Boolean value from a previously executed\ncomputation. Consider the following cases where we'd like to improve performance:\n• Determine if a polygon is probably visible from an octree node.\n• Determine if an object probably collides at a coordinate.\n• Determine if a ray cast probably intersects an object at a coordinate.\n133\n\n\n134 \nSection 1 General Programming\nAll of these cases fit into a general scenario. Each case involves an expensive com-\nputation (CPU, network, or other resource) where the result is a Boolean (usually false)\nanswer. It is important to note that that the word probably is used in each case because\na Bloom Filter is guaranteed to be 100-percent accurate if the Bloom Filter test returns\na false (miss), but is, at best, only probably true if the Bloom Filter returns true (hit).\nA Bloom Filter can store the true result of any function. Usually, the function\nparameter is represented as a pointer to a byte array. If we wish to store the result of a\nfunction that uses multiple parameters, we can concatenate the parameters into a sin-\ngle function parameter. In cases where 100-percent accuracy is needed, we must com-\npute the original expensive function to determine the absolute result of the expensive\nfunction, if a Bloom Filter test returns true.\nHow It Works\nThere are two primary functions in a Bloom Filter: a function for storing the Boolean\ntrue value returned from an expensive function, and a function for testing for a previ-\nously stored Boolean true value. The storing function will accept input in any form\nand modify the Bloom Filter Array accordingly. The testing function will accept input\nin the same form as the storing function and return a Boolean value. If the testing\nfunction returns false, it is guaranteed that the input was never previously stored using\nthe storing function. If the function returns true, it is likely that the input was previ-\nously stored using the storing function. A false positive is a possible result from the\ntest. If 100-percent accuracy is desired, perform the original expensive function to\ndetermine the absolute value. A conventional Bloom Filter is additive, so it can only\nstore additional Boolean true results from an expensive function and cannot remove\npreviously stored values.\nDefinitions\nThe high-quality operation of a Bloom Filter requires a high-quality hash function\nthat is sometimes referred to as a message digest algorithm. Any high-quality hash\nfunction will work, but I recommend using the MD5 message digest algorithm\n[RSA01] from RSA Security, Inc., which is available in source code on the Net, and is\nalso documented in RFC 1321. The MD5 hash function takes N bytes from a byte\narray and produces a 16-byte (128-bit) return value. This return value is a hash of the\ninput, which means if any of the bits in the input change (even in the slightest),\nthe return value will be changed drastically. The return of the hash function, in\nBloom terminology, is called the Bloom Filter Key.\nBloom Filter Indexes are obtained by breaking the Bloom Filter Key into blocks\nof a designated bit size. If we choose a Bloom Filter Index bit size of 16 bits, a 128-bit\nBloom Filter Key can be broken into eight complete 16-bit segments. If there are\nremaining bits left over from breaking the Key into complete segments, they are\ndiscarded.\n\n\n1.20 Using Bloom Filters to Improve Computational Performance \n135\nThe number of Bloom Filter Phases used in a Bloom Filter is the number of\nBloom Filter Indexes used to store the Boolean value from the expensive function. For\nexample, three phases might be used from a 128-bit key using a Bloom Filter Index\nbit size of 16 bits. The remaining five indexes will be discarded, in this example.\nA Bloom Filter Array is used to store the expensive function's Boolean value. For\nexample, if the Bloom Filter Index bit size is 16 bits, the Bloom Filter Array will be 216\nbits long, or 64K bits (8K bytes). The larger the array, the more accurate the Bloom\nFilter test.\nThe Bloom Filter Saturation of the Bloom Filter Array is the percentage of bits set\nto true in the bit array. A Bloom Filter Array is optimal when saturation is 50 percent,\nor half of the bits are set and half are not.\nExample 1\nFor an example, we will store the function parameter (\"Mikano is in the park\") using\nthree phases with an index bit size of 16 bits into an array 64k bits long (8k bytes). In\nthis instance, the expensive function was used to determine if Mikano was truly in the\npark and the result was yes (true). Although we used a string variable, in this case, any\nvariable format will work. The format of the stored expensive function parameter data\nis independent of the Bloom Filter performance, accuracy, or memory usage.\nFirst, the hash function is computed from the expensive function parameter data.\nLet's assume that the hash function returned the 128-bit value Oxl0027AB30001BF\n7877AB34D976A09667. The first three segments of 16-bit indexes will be 0x1002,\n0x7AB3, and 0x0001. The remaining segments are ignored.\nThe Bloom Filter Array starts out reset (all false bits), before we begin to populate\nthe bit array with data. Then, for each of these indexes, we will set the respective bit\nindex in the Bloom Filter Array to true regardless of its previous value. As the array\nbecomes populated, sometimes we will set a bit to true that has already been set to\ntrue. This is the origin of the possible false positive result when testing the Bloom Fil-\nter Array (Figure 1.20.1).\nWhen we wish to examine the Bloom Filter Array to determine if there was a pre-\nviously stored expensive function parameter, we proceed in almost the same steps as a\nstore, except that the bits are read from the Bloom Filter Array instead of written to\nthem. If any of the read bits are false, then the expensive function parameter was\nabsolutely never previously stored in the Bloom Filter Array. If all of the bits are true,\nthen the expensive function parameter was likely previously stored in the Array. In the\ncase of a true result, calculate the original expensive function to accurately determine\nthe Boolean value (Figure 1.20.2).\nTuning the Bloom Filter\nTuning the Bloom Filter involves determining the number of phases and the bit\nsize of the indexes. Both of these variables can be modified to change the accuracy and\ncapacity of the Bloom Filter. Generally speaking, the larger the size of the bit array\n\n\n136\nSection 1 General Programming\nvoid store_bloom_data(\"Mikano is in the park\")\n128 Bloom Key divided\ninto 8 16-bit segments\n3 phase, 16-bit (8K Byte)\nBloom Filter\nHash\n0x1002\nOX7AB3\n0x0001\nOxBF78\nOx77AB\nOx34D9\nOx76AO\n0x9667\njwrite\nwrite\njwrite\nonly 3\nphase so\nignore the\nrest\nboolean test_bloom_data(\"Mikano is in the park\")\nread\nBit Value\nboolean test_bloom_data(\"Mikano is in the office \")\n\"Mikanq is in\nthe office\"\nHash\nOxFFFF\n0x7 AB3\nOxFFFC\n0x7063\nOx691E\nOxB269\n0x0110\nOxCOOl\nj-ead\n)\n(potential false positive) ,\n(not set so return false)\nr-J\n•w\n\\s\n•w\nIf OxFFFC was also set,\nthen a false positive would\nbe returned.\nBit Index\n0x0000\n0x0001\n0x0002\n0x0003\n0x1001\n0x1002\n0x1003\nOX7AB3\n0x7 AB4\nOxFFFC\nOxFFFD\nOxFFFE\nOxFFFF\nreturn true\nFalse Positive\nFIGURE 1.20.1 Flow of a Bloom Filter.\n\n\n1.20 Using Bloom Filters to Improve Computational Performance\n137\n// returns a pointer to 16 bytes of data that represent the hash\nvoid * compute_hash ( pData, nDataLength );\n// returns the integer value for the bits at nlndex for nBitLength long\nint get_index_value( void * pData, int nBitlndex, int nBitLength );\n// tests a bit in the Bloom Filter Array.\n// returns true if set otherwise returns false\nboolean is_bit_index_set( int nlndexValue );\n// sets a bit in the Bloom Filter Array\nvoid set_bit_index( int nlndexValue );\nvoid store_bloom_data( void * pData, int nDataLength )\n{\nvoid *pHash;\nint nPhases = 3, nPhaselndex = 0, nBitlndexLength = 16;\n// returns pointer to 16 bytes of memory\npHash = compute_hash( pData, nDataLength );\n// now set each bit\nwhile { nPhaselndex < m nPhases )\nTheoretically, a different input\nparameter could return the same\nvalue but that is unprobable.\nEither way, the algorithm will\nstill work.\nnlndexValue = get_index_value( pHash, nPhaselndex, nBitlndexLength );\n// if bit is not set, we have a miss so return false\nset_bit_index( nlndexValue ) ;\nnPhase!ndex++;\nboolean test_bloom_data( void * pData, int nDataLength )\nvoid *pHash;\nint nPhases = 3, nPhaselndex = 0, nBitlndexLength =. 16;\n// returns pointer to 16 bytes of memory\npHash = compute_hash( pData, nDataLength ); 4-\n// now test each bit\nwhile ( nPhaselndex < m nPhases )\ncompute_hash will always\nreturn the same 16 bytes of\ndata when called with the\nsame input parameters.\nnlndexValue = get_index_value( pHash, nPhaselndex, nBitlndexLength\n// if bit is not set, we have a miss so return false\nif ( !is_bit_index_set( nlndexValue ) ) return( false );\nnPhase!ndex++; \n*s.\n// all bits are set so we have a probably hit.\nreturn( true );\nReturn false as soon as we\nfind a false bit. At this point,\nthe expensive function has\ndefinitely not been previously\nstored.\nFIGURE 1.20.2 Basic use of a Bloom Filter.\n\n\nSection 1 General Programming\n(N) and the more phases, the less likely a false positive response will occur. Bloom\nasserted that the optimum performance of this algorithm occurs when saturation of\nthe bit array is 50 percent. Statistically, the chance of a false positive can be deter-\nmined by taking the array saturation and raising it to the power of the number of\nphases. Other equations are available to tune the Bloom filter algorithm.\nThe equation to calculate the percentage of false positives is:\npercent_false_pdsitive = saturationnumb\"-°f-fhases\nor expressed as a function of percent_false_positive:\nnumber_of_j>hases \n= Logsaturation(percentjalse_fositive)\nBy assuming that the Bloom Filter Array is operating at optimum capacity of 50-\npercent saturation, Table 1 .20. 1 can be computed from the preceding formulas.\nFor example, if we want the false positive rate below half a percent (0.5 percent),\neight phases must be used, which will return a worst-case scenario of 0.39-percent\nfalse positives.\nNext, we calculate the Bloom Filter Array bit size.\narray_bit_size = ( number_of_phases * max_stored_input\nThe array_bit_size is usually rounded up to the nearest value where array_bit_size\ncan be expressed as 2 to the power of an integer.\narray _bit_size = .2*\nFinally, compute the index_bit_size from the array_bit_size.\narray <_bit_size = 2>ndex-bit-\"z*\nTable 1.20.1 Percentage of False Positives Based on Number of Phases Used\npercent_false_positive \nnumber_of_phases\n50.00%\n25.00%\n12.50%\n6.13%\n3.13%\n1.56%\n078%\n0.39%\n\n\n1.20 Using Bloom Filters to Improve Computational Performance\n139\nExample 2\nSuppose we want to store a maximum of 9000 expensive function parameters\nwith at least 95-percent accuracy when the Bloom Filter Array test returns true. From\nTable 1.20.1, we can determine that five phases will be necessary to obtain an accu-\nracy of equal to or greater than 95 percent and a false positive of less than or equal to\n5 percent.\n5 phases * 9000 expensive function parameters / -ln(0.5) = 64,921 bits\nRounding up to the nearest 2n gives us 64K bits (8K bytes), and because 216 =\n64K, the index_bit_size will be 16 bits.\nFinal Notes\nOne way to improve performance is to use an exception list to prevent executing\nthe expensive function, as Bloom did in his algorithm. An exception list contains all\nof the false positive cases that can be returned from testing a Bloom Filter. This can be\ncomputed at parameter storage or dynamically when false positives are detected (Fig-\nure 1.20.3).\nAnother way to improve performance is to dynamically build a Bloom Filter\nArray. If the range of expensive function parameters is too great, Bloom Filters can be\ncalculated dynamically and optimized for repetitive calls to test the bit array. By\ndynamically building a Bloom Filter Array, the commonly tested expensive function\nparameters are calculated once, and untested function parameters do not waste space\nin the bit array.\nStandard Bloom Filter Test Code\nif ( test_bloom_data(c ) )\nboolean bSuccess = false;\nif ( in_exception_list ( c ) ) return ( bSuccess ) ; f*\nbSuccess = expensive_f unction (c ) ;\nif ( ibSuccess ) add_to_excepti\nreturn ( bSuccess ) ;\nelse\nif ( expensive_f unction (c ) )\nstore_bloom_data ( c ) ;\nreturn true;\nreturn false;\n/ \ni \n-.\nOptional Code\nException List Test\nDynamically computed\nException List\nDynamically computed\nBloom Filter\nFIGURE 1.20.3 \nBloom Filter configurations.\n\n\n140 \nSection 1 General Programming\nHere are some interesting Bloom Filter characteristics:\n• Two Bloom Filter Arrays can be merged together by bitwise ORing them.\n• Bloom Filter Arrays can be shared among parallel clients.\n• Optimized Bloom Filter Arrays are not compressible.\n• Underpopulated Arrays are very compressible.\n• Memory corruption in the array can be mended by setting unknown bits to true.\nConclusion\nBloom Filters offer a method of improving performance of repeatedly called expensive\nfunctions at the expense of memory. While this method has been documented for a\nlong time, it remains a relatively unused technique, although exceptions exist, such as\nBloom Filter usage in the very popular Web-caching program Squid (www.squid-\ncache.org/) by Duane Wessels. Adding a Bloom Filter algorithm to a program can\nusually be done in less that 20K bytes of code. As with most performance-enhancing\ntricks, it is a good idea to add Bloom Filters to a project during the optimization stage,\nafter the main functionality is finished.\nReferences\n[BeachOl] \nBeach Software, \n\"Bloom Filters,\" available online at http://\nbeachsoftware.com/bloom/, May 10, 2000.\n[RSA01] RSA Security, \"What Are MD2, MD4, and MD5,\" available online at\nwww.rsasecurity.com/rsalabs/faq/3-6-6.html, March 4, 2001.\n[FlipcodeOl] Flipcode, \"Coding Bloom Filters,\" available online at \"www.flipcode\n.com/tutorials/tut_bloomfilter.shtml, September 11, 2000.\n[Bloom70] Bloom, Burton H., \"Space/Time Trade-Offs in Hash Coding with Allow-\nable Errors,\" Communications of the ACM, Vol. 13, No.7 (ACM July 1970): pp.\n422-426.\n",
      "page_number": 129,
      "chapter_number": 15,
      "summary": "This chapter covers segment 15 (pages 129-137). Key topics include bloom, bits. • Arithmetic mean value of data bytes is 127.4918 (127.5 = random).",
      "keywords": [
        "Bloom Filter Array",
        "Bloom Filter",
        "Filter Array",
        "Bloom Filter Key",
        "Bloom",
        "Bloom Filter Index",
        "Bloom Filter test",
        "Filter",
        "Bloom Filter Indexes",
        "Bloom filter algorithm",
        "Bloom Filter returns",
        "Filter Index bit",
        "Bloom Filter performance",
        "Bloom Filter Phases",
        "array"
      ],
      "concepts": [
        "bloom",
        "bit",
        "bits",
        "filters",
        "array",
        "returns",
        "value",
        "performance",
        "perform",
        "tested"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 8",
          "chapter": 37,
          "title": "Segment 37 (pages 343-350)",
          "relevance_score": 0.57,
          "method": "sentence_transformers"
        },
        {
          "book": "Computer Systems A Programmer’s Perspective",
          "chapter": 33,
          "title": "Segment 33 (pages 662-682)",
          "relevance_score": 0.55,
          "method": "sentence_transformers"
        },
        {
          "book": "Designing Data-Intensive Applications",
          "chapter": 15,
          "title": "Segment 15 (pages 135-143)",
          "relevance_score": 0.54,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 1",
          "chapter": 11,
          "title": "Segment 11 (pages 99-106)",
          "relevance_score": 0.54,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 3",
          "chapter": 17,
          "title": "Segment 17 (pages 166-173)",
          "relevance_score": 0.53,
          "method": "sentence_transformers"
        }
      ]
    },
    {
      "number": 16,
      "title": "Segment 16 (pages 138-146)",
      "start_page": 138,
      "end_page": 146,
      "detection_method": "topic_boundary",
      "content": "1.21\n3ds max Skin Exporter and\nAnimation Toolkit\nMarco Tombesi\ntombesi@infinito.it\nW\ne have seen wonderful special effects in modern films that have taken glorious\nmonsters such as dinosaurs and made them move smoothly. We know how\nthey did it (using software such as LightWave, 3ds max, Maya, etc.), but how do we\nuse the same animation technology for our games?\nThis gem is intended as an introduction to a full toolset for that purpose, starting\njust after the creation of the animated character in 3ds max (and Character Studio),\nand ending with that object smoothly animating in a game's real-time scenes. Along\nthe way, it passes through the export plug-in and is stored in a custom data format. In\nthis gem, we will go into depth only about the export aspect; the rest is well explained\nby the code on the accompanying CD.\nLet's talk about the necessary steps:\n1. The animation is done with 3ds max 3.1 (hereafter simply called MAX) and\nCharacter Studio 2.2, using Biped and/or bones and the Physique modifier. It\nshould be noted that although newer versions of these tools will become\navailable, the algorithms required for any new versions should be similar.\n2. The export plug-in creates a custom format file (.MRC), which consists of:\n• Mesh information (vertices, normals).\n• Skeletal structure (the bone tree).\n• Influence values (weighting) of each bone to vertices of the mesh (one\nvertex may be influenced by multiple bones).\n• Bone animation: For each bone, this consists of a set of translation and\nrotation keys (using quaternions), including the exact time in millisec-\nonds from the animation start to when the transformation should be\nperformed.\n3. To read the .MRC file, we have a reusable DLL available, provided with full\nsource code.\n4. The Tenderer interpolates (linearly or better) between the sample keys and\ncalculates the current transformation matrix to be applied to each bone.\n141\n\n\n142 \nSection 1 General Programming\nThis is done using the time elapsed from the animation start, obtaining a\nsmooth and non-hardware-dependent animation.\n5. At each frame, the Tenderer recalculates the position of each vertex and its\nnormal. The calculation is based on the current transformation matrix and\ninfluence value that each bone has on a particular vertex. Most matrix oper-\nations can be done using the graphics hardware transformation and lighting\nfeatures if they exist (for example, on the GeForce and Radeon cards).\nThe process of exporting the animation data with a plug-in for MAX is not well\ndocumented. While there are many Web pages covering skinning techniques, few\nactually address the issue of exporting the data. Read and study the source code as\nwell as all Readme.txt files in the project directories for this gem on the CD. More\ninformation is also available on the authors Web page [TombesiOl], where updates\nfor MAX 4 will be available when it is released.\nThis gem is based on a hierarchical bone structure: a bone tree or a Biped, created\nusing Character Studio 2.2. Build a low polygon mesh (about 5000 triangles). The\nmesh should be a single selectable object in MAX. Deform the mesh using the\nPhysique modifier, based on the Biped previously created. The character animation\nshould be created on the Biped.\nExporting\nFirst, we need a file format specification.\nThe MRC File Format\nThis is a simple file format for the purposes of this gem. It supports normals, bones,\nvertex weights, and animation keys. See Figure 1.21.1 for a self-explanatory\nschematic, and check the code on the CD for technical clarification.\nExporting to MRC with the MAX SDK\nIf you are new to plug-in development and don't know how MAX works, be\nsure to refer to the MAX SDK documentation. In particular, study the fol-\nlowing sections before proceeding:\n• DLL, Library Functions, and Class Descriptors\n• \nFundamental Concepts of the MAX SDK\n• Must Read Sections for All Developers\n• Nodes\n• \nGeometry Pipeline System\n• Matrix Representations of 3D Transformations\n\n\nFILE\nVSTART/\nboneOfs\nFILE\nEND\n£\nO\nCO\nCD\nI\n43\n(G\nT3\nLUzo\nCO\n}\nvertCnt\nnormCnt\nfaceCnt\nt_hd\nchildCnt\ninfluencedVertexCnt\nkeyCnt\nboneCnt\nFIGURE 1.21.1 \nMRC file format description.\n143\n\n\n144 \nSection 1 General Programming\nWorking with Nodes\nIn our export plug-in, we must derive a class from SceneExport and implement some\nvirtual methods, one of which is the main export routine.\nclass MRCexport : public SceneExport {\npublic:\n// Number of extensions supported\nint ExtCount() \n{return 1;}\n// Extension (\"MRC\")\nconst TCHAR * Ext (int n) \n{return _T(\"MRC\");}\n// Export to an MRC file\nint DoExport( const TCHAR *name,\nExplnterface *ei,\nInterface *i,\nBOOL \nsuppressPrompts=FALSE,\nDWORD options=0);\n//Constructor/Destructor\nMRCexport () ;\n-MRCexport();\nAccessing scene data requires an Interface passed by MAX to the main export rou-\ntine (the entry point of the plug-in). For every object in MAX, there is a node in the\nglobal scene graph, and each node has a parent (except RootNode) and possibly some\nchildren. We can access the root node and then traverse the hierarchy, or we can\ndirectly access a node if the user has selected it in MAX before exporting.\nINode* pNode = i->GetSelNode(0) ;\nINode* const pRoot = i->GetRootNode() ;\nTo navigate the node structure, we have these methods:\nInt count = pNode->NumberOfChildren() ;\nINode* pChNode = pNode->GetChildNode(i) ;\nA node could represent anything, so we need to discriminate among object types\nvia the node's class identifier (Class_ID or SuperClassID), and then appropriately cast\nthe object. For our purposes, we need to check if a node is a geometric object (a mesh)\nor a bone (a Biped node or a bone).\nbool IsMesh( INode *pNode)\n{\nif(pNode == NULL) return false;\nObjectState os = pNode->EvalWorldState(0) ;\nif(os.obj->SuperClassID() == GEOMOBJECT_CLASS_ID)\nreturn true;\nreturn false;\n\n\n1.21 3ds max Skin Exporter and Animation Toolkit \n145\nbool IsBone(INode *pNode)\n{\nif(pNode == NULL)return false;\nObjectState os = pNode->EvalWorldState(0) ;\nif (los.obj) return false;\nif(os.obj->ClassID() == Class_ID(BONE_CLASS_ID, 0))\nreturn true;\nif(os.obj->ClassID() == Class_ID(DUMMY_CLASS_ID, 0))\nreturn false;\nControl *cont = pNode->GetTMController() ;\n//other Biped parts\nif( COnt->ClassID() == BIPSLAVE_CONTROL_CLASS_ID ||\n//Biped root \"Bip01\"\nCOnt->ClassID() == BIPBODY_CONTROL_CLASS_ID\n) return true;\nreturn false;\nThe previous example explains how to navigate MAX's nodes and check what\nthey represent. Once we get a mesh node, we need to acquire the desired vertex data.\nGetting Mesh Data\nFor convenience later on, we'll store all vertex data in global coordinate space. MAX\nobject coordinates are in object space, so we need a transformation matrix to be\napplied to each vertex and normal of the mesh.\nWe can grab this global transformation matrix at any time during the animation\nusing GetObjectTM(TimeValue time). This matrix is used to transform vectors from\nobject space to world space and could be used, for example, if we want to get the\nworld space coordinate of one mesh vertex. We could do this by taking the vertex\ncoordinate in object space and multiplying it (post-multiply in MAX) by the matrix\nreturned from this method. We are interested in mesh data at the animation start, so\nTimeValue is zero.\nMatrix3 tm = pNode->6etObjectTM(0)\nMAX uses row vector 1x3 and 4x3 matrices, so to transform a vector, we\nmustpremultiply it by the matrix.\nMart\nVertices and other data are not statically stored, but dynamically calculated each\ntime. To access data, we must first perform the geometry pipeline evaluation, specify-\ning the time at which we want to get the object state.\n\n\n146 \nSection 1 General Programming\nMAX has a modifier stack system, where every object is the result of a modifica-\ntion chain. Starting from a simple parametric primitive (such as a box) that is the base\nobject, the final object is built, applying modifiers in sequence along the stack. This is\nthe object pipeline and we will work with the result. The resulting object is a Derived-\nObject and has methods to navigate the stack of modifiers.\nTo get the result at a specified animation time, we must first retrieve an Object-\nState, which is done by invoking the method EvalWorldState on the node. This makes\nMAX apply each modifier in the pipeline from beginning to end.\nObjectState os = pNode->EvalWorldState(0);\nObjectState contains a pointer to the object in the pipeline and, once we have this\nobject, we can finally get the mesh data. To do this, we must cast the generic object to\na geometric one, which has a method to build a mesh representation.\nMesh& mesh = *(((GeomObject*)os.obj)->GetRenderMesh(0, pNode, ...));\nNow it is easy to access the mesh members and finally put vertices, faces, and normals\nin memory, ready to be written to a file. These methods are available to accomplish this:\nMesh::getNumVerts(), Mesh::getNumFaces(), Mesh::getVert(i), anAMesh::getNormal(i).\nListing 1.21.1 illustrates how to export mesh data to a file.\nGetting the Bone Structure\nNow we need a way to write the skeleton's hierarchical structure to an output data file.\nStarting from the root node, we traverse depth-first through the tree, and for each\nbone, we need to get several things. First, we assign an index to any direct child and to\nthe bone's parent, and then we grab the bone orientation matrix.\ntm = pNode->GetNodeTM(0);\ntm.Invert();\nAlthough very similar, the preceding matrix isn't the object matrix, but is\nrelated to the node's pivot point, which may not be the object's origin. Check\n3^,, \nwith the SDK documentation to find a precise description. We will use this\nMOTt \n• \nr \ni \n/ \n, , \n, \n, i\nmatrix to transform every mesh vertex from world space to related bone space,\nso it can move with the bone. Since we have to multiply any vertex by the\ninverse of this matrix, we can invert it now and save rendering time.\nGetting the Bone Influences\nNow we are at the most exciting part of this gem: getting the vertex bone assignment\nand influence value (weighting). The weighting is important when two or more bones\ninfluence the same vertex and the mesh deformation depends on both (see [Wood-\nlandOO] for the theory). These assignments should be done using the Physique modi-\nfier in Character Studio 2.2. Note to the reader: Study the Phyexp.h header that comes\nwith Character Studio for modifier interface help.\n\n\n1.21 3ds max Skin Exporter and Animation Toolkit \n147\nFirst, we must find the Physique modifier on the object's node that we wish to\nexport (this is the same node we used earlier to get the mesh vertex data). We do this\nby accessing the referenced DerivedObject and then scanning each applied modifier on\nthe stack until we find the Physique modifier (using a Class_ID check).\nModifier* GetPhysiqueMod(INode *pNode)\n{\nObject *pObj = pNode->GetObjectRef();\nif(lpObj) return NULL;\n// Is it a derived object?\nwhile(pObj->SuperClassID() == GEN_DERIVOB_CLASS_ID)\n{\n// Yes -> Cast\nIDerivedObject *pDerivedObj =\nstatic_cast<IDerivedObject*>(pObj);\n// Iterate over all entries of the modifier stack\nint ModStacklndex = 0;\nwhile(ModStacklndex < pDerivedObj->NumModifiers())\n{\n// Get current modifier\nModifier* pMod = pDerivedObj->\nGetModifier(ModStacklndex);\n//Is this Physique?\nif(pMod->ClassID() ==\nClass_ID(PHYSIQUE_CLASS_ID_A,\nPHYSIQUE_CLASS_ID_B))\nreturn pMod;\n// Next modifier stack entry\nModStackIndex++;\n}\npObj = pDerivedObj->GetObjRef();\n}\n// Not found\nreturn NULL;\n}\nNow we enter the Bone assignment phase (see Listing 1.21.2; a code overview\nfollows). Once we have the Physique modifier, we get its interface (IPhysiqueExpori)\nand then access the Physique context interface (IPhyContextExporf) for the object.\nThis owns all of the methods with which we need to work. Each vertex affected by a\nmodifier has an interface IPhyVertexExport. Grab this interface to access its methods,\ncalling GetVertexInterface(i) on the Physique context interface.\nWe must check to see if a vertex is influenced by one or more bones (RIGID_TYPE\nor RIGID_BLENDED_TYPE, respectively). In the former case, the weight value is 1 and we\nhave to find just a single bone (calling GetNode on the i-th vertex interface). In the lat-\nter case, we have to find every bone assigned to the vertex, and for each bone we must\n\n\nSection 1 General Programming\nget its proper weight value by invoking GetWeightQ) on the i-th vertex interface,\nwhere j is the j-th bone influencing it. In addition, note that at the end, we must\nremember to release every interface.\nNow we are ready for the last phase: bone animation data acquisition.\nGetting Bone Animation Keys\nThis is a simple step. At selected time intervals (default 100 milliseconds), grab the\ntransformation matrix of each bone. In the MAX SDK, time is measured internally in\n\"ticks,\" where there are 4800 ticks per second, so we must perform a conversion.\nThen we use this method:\ntm = pNode->GetNodeTM(timeTicks);\nIt's more efficient to not store the complete matrix (16 floats), but instead only\nthe translation (3 floats) and rotation data (4 floats), so we extract a position vector\nand a unit quaternion from the matrix.\nPoints pos = tm.GetTrans();\nQuat quat(tm);\nOnce we have all the data collected in memory, we store everything to disk using\nthe MRC file format. Now it is time to see how to use it all to perform smooth ani-\nmation in our games.\nPut It to Use: The Drawing Loop\nIn our application, for each frame displayed, we should perform the following steps in\nsequence.\nGet the Exact Time\nTo make the animation very smooth and not processor dependent, getting the system\ntime is necessary. We update the skeleton structure by cycling through the bone tree\nand, for each bone, work out the current transformation matrix by linearly interpo-\nlating between two sample keys. To find out which sample keys to interpolate\nbetween, we require the current real animation time (in milliseconds) from animation\nstart.\nMoving the Skeleton\nWe determine actual bone position and rotation by linear (or better) interpolation\nand by quaternion interpolation (SLERP or better) between selected sample keys\n(sample times should enclose the current time). Then, given these data, you can build\nthe current bone animation matrix from the translation and rotation. The math\ninvolved, especially in the quaternion calculations, is explained well in the previous\nGame Programming Gems book [ShankelOO]. To take better advantage of graphics\nhardware, we perform all matrix calculations using OpenGL functions. This way we\n\n\n1.21 3ds max Skin Exporter and Animation Toolkit \n149\ncan exploit any advanced hardware features such as transformation and lighting, and\nperformance will be much better!\nRecalculate the Skin\nOnce the skeleton is moved, it is time to deform the mesh accordingly, with respect to\nvertex weight assignments. See [WbodlandOO] for a good overview of this topic. It is\nconvenient to check the vertices in bone-major order, traversing depth-first through\nthe bone tree and doing the following passes for each bone. For each vertex influenced\nby the bone, we refer it to the bone's local coordinate system (multiplying by the bone\ninverse orientation matrk), and then transform it via the current bone animation\nmatrk. Then, we multiply the vertex coordinates by the influence value (weight) this\nbone exerts on it. We add the result to the corresponding vertex value stored in a tem-\nporary buffer. Now this buffer contains the current vertex coordinates for the skin, at\nthis point in the animation. To finish, we draw the computed mesh using vertex\narrays (or better) to gain even more performance.\nListing 1.21.1: Exporting the Mesh to a File\nbool ExportMesh (iNode* pNode, FILE *out)\n{\nMRCmesh_hdr mHdr;\nMatrixS tm = pNode->GetObjectTM(0) ;\nObjectState os = pNode->EvalWorldState(0) ;\nint needDelete;\nMesh& mesh = *(( (GeomObject*) os.obj )->GetRenderMesh (\n0, pNode, ...));\n// write the mesh vertices\nmHdr.vertCnt = mesh.getNumVerts() ;\nforfint i = 0; i < mHdr.vertCnt; i++)\n{\nPoints pnt = mesh.getVert(i) * tm; \n//premultiply in MAX\n// write vertex normals\nmesh.buildNormalsO ;\nmHdr.normCnt = mesh.getNumVerts() ;\nfor(i = 0; i < mHdr.normCnt;\nPoints norm = Normalize(mesh.getNormal(i) ) ;\n// build and write faces\nmHdr.faceCnt = mesh.getNumFaces() ;\nfor(i = 0; i < mHdr.faceCnt;\n",
      "page_number": 138,
      "chapter_number": 16,
      "summary": "In\nthis gem, we will go into depth only about the export aspect; the rest is well explained\nby the code on the accompanying CD Key topics include bones, mesh, and object.",
      "keywords": [
        "bone",
        "max",
        "max Skin Exporter",
        "Mesh",
        "Animation",
        "object",
        "vertex",
        "Bone animation",
        "pNode",
        "MAX SDK",
        "MRC file",
        "max Skin",
        "MRC File Format",
        "matrix",
        "file"
      ],
      "concepts": [
        "bones",
        "mesh",
        "object",
        "matrix",
        "vertex",
        "max",
        "data",
        "returned",
        "animation",
        "animated"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 1",
          "chapter": 48,
          "title": "Segment 48 (pages 462-474)",
          "relevance_score": 0.45,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 7",
          "chapter": 46,
          "title": "Segment 46 (pages 443-452)",
          "relevance_score": 0.44,
          "method": "sentence_transformers"
        },
        {
          "book": "makinggames",
          "chapter": 39,
          "title": "Segment 39 (pages 340-347)",
          "relevance_score": 0.44,
          "method": "sentence_transformers"
        },
        {
          "book": "AI Agents and Applications",
          "chapter": 11,
          "title": "Segment 11 (pages 84-95)",
          "relevance_score": 0.43,
          "method": "sentence_transformers"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 26,
          "title": "Segment 26 (pages 503-525)",
          "relevance_score": 0.43,
          "method": "sentence_transformers"
        }
      ]
    },
    {
      "number": 17,
      "title": "Segment 17 (pages 147-155)",
      "start_page": 147,
      "end_page": 155,
      "detection_method": "topic_boundary",
      "content": "150 \nSection 1 General Programming\nMRCface_hdr fHdr;\nfHdr.vert[0] = mesh.faces[i].v[0];\nfHdr.vert[1] = mesh.faces[i].v[1];\nfHdr.vert[2] = mesh.faces[i].v[2];\nListing 1.21.2: Reading Bone Assignments\nbool GetPhysiqueWeights(INode *pNode, INode *pRoot,\nModifier *pMod, BoneData_t *BD)\n{\n// create a Physique Export Interface for given Physique Modifier\nIPhysiqueExport *phylnterface = (IPhysiqueExport*)\npMod->Get!nterface(I_PHYINTERFACE);\nif (phylnterface)\n{\n// create a ModContext Export Interface for the specific\n// node of the Physique Modifier\nIPhyContextExport *modContext!nt = (IPhyContextExport*)\nphyInterface->GetContext!nterface(pNode) \n;\n// needed by vertex interface (only Rigid supported by now)\nmodContext!nt->ConvertToRigid(TRUE) ;\n// more than a single bone per vertex\nmodContextInt->AllowBlending(TRUE) ;\nif (modContextlnt)\n{\nint totalVtx = modContextlnt ->GetNumberVertices() ;\nfor(int i = 0; i < totalVtx; i\nIPhyVertexExport *vtxlnterface = (IPhyVertexExport*)\nmodContext!nt->GetVertexInterface(i) ;\nif (vtxlnterface)\n{\nint vtxType = vtxInterface->GetVertexType() ;\nif(vtxType == RIGID_TYPE)\n{\nINode *boneNode = ((IPhyRigidVertex*)vtxInterface)\n-> GetNode();\nint boneldx = GetBoneIndex(pRoot, boneNode);\nInsert\n// Build vertex data\nMRCweightJidr wdata;\nwdata.vertldx = i;\nwdata. weight = 1 .Of ;\n//Insert into proper bonedata\nBD[ boneldx] . weight sVect .push_back( wdata) ;\n// update vertexWeightCnt for that bone\n\n\n1.21 3ds max Skin Exporter and Animation Toolkit \n151\nBD[boneIdx] .Hdr.vertexCnt\n= BD[boneIdx] .weightsVect.size() ;\n}\nelse if(vtxType == RIGID_BLENDED_TYPE)\n{\nIPhyBlendedRigidVertex *vtxBlended!nt =\n(IPhyBlendedRigidVertex*)vtxInterface;\nfor(int j = 0; j < vtxBlendedInt->GetNumberNodes()\nINode *boneNode = vtxBlendedInt->GetNode(j) ;\nint boneldx = GetBoneIndex(pRoot, boneNode);\n// Build vertex data\nMRCweightJidr wdata;\nwdata.vertldx = i;\nwdata. weight = vtxBlendedInt->GetWeight(j) ;\n// check vertex existence for this bone\nbool notfound = true;\nfor (int v=0; notfound\n&& v < BD[boneIdx] .weightsVect.size() ;\n// update found vert weight data for that\n// bone\nif ( BDfboneldx] .weightsVectfv] .vertldx\n== wdata.vertldx )\n{\nBD[boneIdx] .weightsVect[v] .weight\n+= wdata. weight;\nnotfound = false;\nif (notfound)\n{\n// Add a new vertex weight data into proper\n// bonedata\nBD[boneIdx] .weightsVect.push_back(wdata) ;\n// update vertexweightCnt for that bone\nBD[boneIdx] .Hdr.vertexCnt\n= BD[boneIdx] .weightsVect.size() ;\nphyInterface->ReleaseContextInterface(modContextInt) ;\n}\npMod->Release!nterface(I_PHYINTERFACE, phylnterface) ;\n}\nreturn true;\n\n\n152 \nSection 1 General Programming\nReferences\nSDK documentation file:\n[DiscreetOO] Max SDK Plug-in development documentation: SDK.HLP\nWeb links:\n[TombesiOl] Tombesi, Marco's Web page: http://digilander.iol.it/baggior/\nBooks:\n[WoodlandOO] Woodland, Ryan, \"Filling the Gaps—Advanced Animation Using\nStitching and Skinning,\" Game Programming Gems. Charles Raver Media 2000;\npp. 476-483.\n[ShankelOO] Shankel, Jason, \"Matrix-Quaternion Conversions\" and \"Interpolating\nQuaternions,\" Game Programming Gems. Charles River Media 2000; pp.\n200-213.\n\n\n1.22\nUsing Web Cameras in\nVideo Games\nNathan d'Qbrenan, Firetoad Software\nnathand@firetoads.com\nI\nost games nowadays have multiplayer capabilities; however, the only interaction\nthat goes on among online gamers is the occasional text message. Imagine hav-\ning the ability to see the expression on your opponent's face when you just pass them\nbefore reaching the finish line, or when they get fragged by your perfectly placed\nrocket. Web cams allow you that functionality, and with high-speed Internet slowly\nbecoming standard, it's becoming feasible to send more data to more clients.\nThis gem demonstrates a straightforward approach to implementing Web cam\nmethodologies into a game. We'll be using Video for Windows to capture the Web\ncam data, so Windows is required for the Web cam initialization function. We will\ncover numerous approaches for fast image culling, motion detection, and a couple of\nimage manipulation routines. By die end, we will have a fully functional Web cam\napplication tliat can be run and interacted widi at reasonable frame rates.\nInitializing the Web Cam Capture Window\nThe following code demonstrates how to use Video for Windows to set up a Web\nC^^l>3 \ncamera window in an application. Note to die reader: when dealing with video drivers\nONTHICD \nfrom hardware vendors: You can never have too much error checking and handling\ncode (review source code on CD for a more thorough implementation).\n// Globals\nHWND hWndCam = NULL;\nBOOL cam_driver_on = FALSE;\nint wco_cam_width = 160, wco_cam_height = 120;\nint wco_cam_updates = 400, wco_cam_threshold = 120;\n// WEBCAM_INIT\nvoid webcam_init(HWND hWnd)\n{\n// Set the window to be a pixel by a pixel large\nhWndCam = capCreateCaptureWindow(appname,\nWS_CHILD | WS_VISIBLE |\nWS_CLIPCHILDREN |\nWS_CLIPSIBLINGS,\n153\n\n\n154 \nSection 1 General Programming\n0,0,\n1,1,\nhwnd,\n0);\nif(hwndCam)\n{\n// Connect the cam to the driver\ncam_driver_on = capDriverConnect(hWndCam, 1);\n// Get the capabilities of the capture driver\nif(cam_driver_on)\n{\ncapDriverGetCaps(hWndCam, &caps, sizeof(caps));\n// Set the video stream callback function\ncapSetCallbackOnFrame(hWndCam, webcam_callback);\n// Set the preview rate in milliseconds\ncapPreviewRate(hWndCam, wco_cam_updates);\n// Disable preview mode\ncapPreview(hWndCam, FALSE);\n// Initialize the bitmap info to the way we want\ncapwnd.bmiHeader.biSize = sizeof(BITMAPINFOHEADER);\ncapwnd.bmiHeader.biWidth \n= wco_cam_width;\ncapwnd.bmiHeader.biHeight = wco_cam_height;\ncapwnd.bmiHeader.biPlanes = 1;\ncapwnd.bmiHeader.biBitCount = 24;\ncapwnd.bmiHeader.bicompression = BI_RGB;\ncapwnd.bmiHeader.biSizelmage =wco_cam_width*wco_cam_height*3;\ncapwnd.bmiHeader.biXPelsPerMeter = 100;\ncapwnd.bmiHeader.biYPelsPerMeter =100;\nif(capSetVideoFormat(hWndCam, icapwnd,\nSizeof(BITMAPINFO)) == FALSE)\n{\ncapSetCallbackOnFrame(hwndCam, NULL);\nDestroyWindow(hWndCam);\nhWndCam = NULL;\ncam_driver_on = FALSE;\n}\nelse\n{ // Assign memory and variables\nwebcam_set_vars();\n{\nglGenTextures(1, &webcam_tex.gl_bgr);\nglBindTexture(GL_TEXTURE_2D, webcam_tex.gl_bgr);\nglTex!mage2D(GL_TEXTURE_2D, 0, 3, webcam_tex.size,\nwebcam_tex.size, 0, GL_BGR_EXT,\nGL_UNSIGNED_BYTE, webcam_tex.bgr);\nglTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_S,\nGL_REPEAT);\n\n\n1.22 Using Web Cameras in Video Games\n155\nglTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_T,\nGL_REPEAT);\nglTexParameterf(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER,\nGLJ.INEAR);\nglTexParameterf(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER,\nGL_LINEAR);\nglGenTextures(1, &webcam_tex.gl_grey);\nglBindTexture(GL_TEXTURE_2D, webcam_tex.gl_grey);\nglTex!mage2D(GL_TEXTURE_2D, 0, 1, webcam_tex.size,\nwebcam_tex.size, 0, GLJ.UMINANCE,\nGL_UNSIGNED_BYTE, webcam_tex.greyscale);\nglTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_S,\nGL_REPEAT);\nglTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_T,\nGL_REPEAT);\nglTexParameterf(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER,\nGL_LINEAR);\nglTexParameterf(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER,\nGL_LINEAR);\nelse\n{\ncam_driver_on = FALSE;\nThe above function retrieves the handle to the Web cam window we're capturing\nfrom through the function capCreateCaptureWindow(). We then initialize it with win-\ndows properties such as its size, and whether it should be visible. In our case, we do\nwant it to be visible; however, we're only going to set the window to a 1x1 pixel, so it's\nbasically invisible. This is required because we don't actually want to display the image\nsubwindow, but we want to receive the data updates from Windows through the call-\nback function.\nWe then retrieve driver information, set the callback function (more on this\nlater), the number of times per second we want to refresh the Web cam, and then reset\nall our variables. The driver is then tested to see if it can handle returning the stan-\ndard bitmap information in which we are interested. Upon success, we initialize all\nthe memory for all our movement buffers, as well as the OpenGL texture. We pull a\nlittle trick when deciding how big to make this texture, which will come in handy\nlater on. Based on whatever height we set up our Web cam window to be, we find and\nallocate our memory to the next highest power of 2. Even though we are allocating a\nbigger buffer than the Web cam image, we save ourselves an expensive texture resize\noperation, by just doing a memcpyQ right into the larger buffer — at the cost of some\nsmall precision loss in the Web cam image.\n\n\n156 \nSection 1 General Programming\nRetrieving Data\nOnce we have our video window initialized, we need a way to retrieve the data from\nthe Web cam every frame. To let Windows know which callback function it should\nsend the data to, we must call capSetCallbackOnFrameQ with the address of the call-\nback function. When Windows decides it's time to update the Web cam, it will pass\nus the bitmap information inside the VIDEOHDR structure.\nIn our case, we'll make the callback function process all the Web cam data to\ndecide if we want to create a texture out of it. We can pass all of that data to the web-\ncam_calc_movement () function for further processing, which will determine if enough\ndata has changed since die last frame, after which, we can update the texture.\n// WEBCAM_CALLBACK\n// Process video callbacks here\nLRESULT WINAPI webcam_callback(HWND hwnd, LPVIDEOHDR videojidr)\n{\n// Calculate movement based off of threshold\nif(webcam_calc_movement(video_hd r,\nwebcam_tex.delta_buffer,\nwco_cam_width,\nwco_cam_height,\nwebcam^tex.size,\nwco_cam_threshold))\n{\nwebcam_make_texture(videojidr, wco_cam_rendering);\n}\nreturn TRUE;\n}\nWindows defines the LPVIDEOHDR structure as:\ntypedef struct videohdr_tag\n{\nLPBYTE \nIpData; \n// pointer to locked data buffer\nDWORD \ndwBufferLength; // Length of data buffer\nDWORD \ndwBytesllsed; \n// Bytes actually used\nDWORD \ndwTimeCaptured; // Milliseconds from start of stream\nDWORD \ndwUser; \n// for client's use\nDWORD \ndwFlags; \n// assorted flags (see defines)\nDWORD \ndwReserved[4]; \n// reserved for driver\n} VIDEOHDR, NEAR *PVIDEOHDR, FAR * LPVIDEOHDR;\nWindows saves the Web cam data in the buffer called If Data. This is the primary\nvariable we are interested in, but dwTimeCaptured and some of the flags may prove\nuseful as well. Now that we've captured the data from the Web cam, let's test it to see\nif it's useful.\n\n\n1.22 Using Web Cameras in Video Games \n157\nMotion Detection\nWe now want to weed out any unnecessary frames which have barely changed so we\ncan avoid unnecessary updates to our texture. Updating textures is a notoriously slow\noperation in a 3D API such as OpenGL.\nThe following source code compares delta buffers, and returns true or false if the\ngiven threshold has been breached. Note that returning early when the threshold has\nbeen exceeded could optimize this function further; however, that would hamper\nus from using the delta buffer later on. Ectosaver [FiretoadOO] uses these unsigned\nbytes of delta movement to calculate the amplitude of the waves it causes, and to\ndetermine when there is no one moving around.\n// GLOBALS\nunsigned char wco_cam_threshold=128; // This is a good amount (0-255)\n// WEBCAM_CALC_MOVEMENT\n// This is a simple motion detection routine that determines if\n// you've moved further than the set threshold\nBOOL webcam_calc_movement(LPVIDEOHDR video_hdr,\nunsigned char *delta_buff,\nint webcam_width, int webcam_height,\nint gl_size, unsigned char thresh)\n{\nunsigned char max_delta=0;\nint i=0, j=0;\nint length;\nunsigned char *temp_delta = (unsigned char *)malloc(\nsizeof(unsigned char)* webcam_width * webcam_height);\nlength = webcam_width * webcam_height;\nwebcam_tex.which_buffer = webcam_tex.which_buffer 7 0 : 1 ;\nif(!video_hdr->lpData)\nreturn FS_TRUE;\nfor(i=0; i<length; i++)\n{\n// Save the current frames data for comparison on the next frame\n// NOTE: Were only comparing the red channel (IpData is BGR), so\n//in theory if the user was in a solid red room, coated in red\n// paint, we wouldn't detect any movement....chances are this\n//isn't the case :) For our purposes, it this test works fine\nwebcam_tex.back_buffer[webcam_tex.which_buffer][i]\n= video_hdr->lpData[i*3];\n// Compute the delta buffer from the last frame\n// If it's the first frame, it shouldn't blow up given that we\n// cleared it to zero upon initialization\ntemp_delta[i] =\nabs(webcam_tex.back_buffer[webcam_tex.which_buffer][i] -\nwebcam_tex.back_buffer[!webcam_tex.which_buffer][i]);\n\n\n158 \nSection 1 General Programming\n//Is the difference here greater than our threshold?\nif (temp_delta[i] > max_delta)\nmax_delta = temp_delta[i] ;\n// Fit to be inside a power of 2 texture\nfor(i=0; i<webcam_height ;\nmemcpy(&delta_buff [i*(gl_size)] ,\n&temp_delta[i*(webcam_width)] ,\nsizeof (unsigned char)*webcam_width) ;\nf ree(temp_delta) ;\nif(max_delta > thresh)\nreturn TRUE;\nelse\nreturn FALSE;\nManipulating Web Cam Data\nGet the BGR Pixels\nOnce we've performed all our testing and culling, we are ready to manipulate the data\nwe were sent from Windows. For this, we will simply copy the pixels from die\nVIDEOHDR data struct (the native format Windows returns is BGR) into a buffer\nthat we've allocated to have a power of 2. Note that this technique avoids resizing the\ntexture data's pixels, as it simply copies the pixels straight over, preserving the pixel\naspect ratio. The only drawback to this technique is that it will leave some empty\nspace in our texture, so we're left with a bar of black pixels at the top of the image. We\ncan eliminate that bar by manipulating texture coordinates (once mapped onto 3D\ngeometry) or resizing the texture.\n// WEBCAM_MAKE_BGR\nvoid webcam_make_bgr(unsigned char *bgr_tex, unsigned char *vid_data,\nint webcam_width, int webcam_height, int glsize)\n{\nint i;\nfor(i=0; i<webcam_height; i++)\n{\nmemcpy(&bgr_tex[i*(glsize*3)],\n&vid_data[i*(webcam_widtn*3)],\nsizeof(unsigned char)*webcam_width*3);\n",
      "page_number": 147,
      "chapter_number": 17,
      "summary": "This gem demonstrates a straightforward approach to implementing Web cam\nmethodologies into a game Key topics include windows, data. weight = 1 .Of ;\n//Insert into proper bonedata\nBD[ boneldx].",
      "keywords": [
        "Web cam",
        "WEBCAM",
        "Web cam data",
        "Web",
        "TEXTURE",
        "cam",
        "Web cam window",
        "data",
        "int",
        "int webcam",
        "General Programming",
        "Web cam image",
        "Web Cameras",
        "unsigned char",
        "buffer"
      ],
      "concepts": [
        "windows",
        "web",
        "data",
        "buffers",
        "cams",
        "cam",
        "game",
        "returning",
        "texture",
        "unsigned"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 7",
          "chapter": 7,
          "title": "Segment 7 (pages 57-65)",
          "relevance_score": 0.44,
          "method": "sentence_transformers"
        },
        {
          "book": "Designing Data-Intensive Applications",
          "chapter": 15,
          "title": "Segment 15 (pages 135-143)",
          "relevance_score": 0.41,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 7",
          "chapter": 59,
          "title": "Segment 59 (pages 567-580)",
          "relevance_score": 0.4,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 3",
          "chapter": 8,
          "title": "Segment 8 (pages 85-92)",
          "relevance_score": 0.39,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 3",
          "chapter": 10,
          "title": "Segment 10 (pages 102-110)",
          "relevance_score": 0.39,
          "method": "sentence_transformers"
        }
      ]
    },
    {
      "number": 18,
      "title": "Segment 18 (pages 156-172)",
      "start_page": 156,
      "end_page": 172,
      "detection_method": "topic_boundary",
      "content": "1.22 Using Web Cameras in Video Games \n159\nConvert to Grayscale\nOnce we've captured the BGR data, we could convert it to grayscale. This would result\nin an image that is one-third the size of our regular textures, which would be practical\nfor users who have slow Internet connections, but still want to transmit Web cam data.\nHere is a function that multiplies each RGB component in our color buffer by a\nscalar amount, effectively reducing all three color channels to one:\n// WEBCAM_MAKE_GREYSCALE\nvoid webcam_make_greyscale( unsigned char *grey,\nunsigned char *color, int dim)\n{\nint i, j;\n// Greyscale = RED * 0.3f + GREEN * 0.4f + BLUE * 0.3f\nfor(i=0, j=0; j<dim*dim; i+=3,\ngrey[j] = (unsigned char)float_to_int(0.30f * color[i] \n+\n0.40f * color [i+1] +\nO.SOf * color[i+2]);\nReal-Life Cartoons\nOnce we've successfully converted all our data to grayscale, we can manipulate the\ndata to draw the picture in a cartoon-like fashion. This method splits the image into\nfive different levels and six different colors, coloring different ranges of pixel values\nwith solid values. All we have to do is perform some simple comparisons and evaluate\neach pixel based on our heat intensity constants.\nThe final result is compared against a lookup from either the grayscale buffer or\nour delta buffer. If we want to see the image every frame (single buffer), we will need\nto compare against the grayscale. To give different results, we'll assign random color\nintensities for each pixel based on our heat intensity constants.\n// WEBCAM_INIT_CARTOON\nvoid webcam_init_cantoon(cartoon_s *cartoon_tex)\n{\nchar i;\nfor(i=0; i<3; i++)\n{\n// Pick random colors in our range\ncartoon_tex->bot_toll_col[i] = rand()%255;\ncartoon_tex->min_toll_col[i] = rand()%255;\ncartoon_tex->low_toll_col[i] \n= rand()%255;\ncartoon_tex->med_toll_col[i] = rand()%255;\ncartoon_tex->high_toll_col[i] = rand()%255;\ncartoon_tex->max_toll_col[i] = rand()%255;\ntfdefine MIN \nCAM \nHEAT \n50\n\n\n160 \nSection 1 General Programming\ntfdefine LOW_CAM_HEAT \n75\n#define MED_CAM_HEAT 100\n#define HIGH_CAM_HEAT 125\n#define MAX_CAM_HEAT 150\n// WEBCAM_MAKE_CARTOON\nvoid webcam_itiake_cartoon( unsigned char *cartoon,\ncartoon_s cartoon_tex,\nunsigned char *data, int dim)\n{\nint i, j, n;\nfor(i=0, j=0; j<dim*dim; i+=3,\n{\nif(data[j] < MIN_CAM_HEAT)\nfor(n=0; n<3;\ncartoon[i+n] = cartoon_tex.bot_toll_col[n] ;\n}\nif(data[j] > MIN_CAM_HEAT && data[j] < LOW_CAM_HEAT)\nfor(n=0; n<3;\ncartoon [i+n] = cartoon_tex.min_toll col[n];\n}\nif(data[j] > LOW_CAM_HEAT && data[j] < MED_CAM_HEAT)\nfor(n=0; n<3;\ncartoon[i+n] = cartoon_tex.low_toll_col[n] ;\n}\nif(data[j] > MED_CAM_HEAT && data[j] < HIGH_CAM_HEAT)\nfor(n=0; n<3;\ncartoon[i+n] = cartoon_tex.med_toll_col[n] ;\n}\nif (data[ j] > HIGH_CAM_HEAT && data[j] < MAX_CAM_HEAT)\nfor(n=0; n<3;\ncartoon [i+n] = cartoon_tex.high_toll_col[n] ;\n}\nif(data[j] > MAX_CAM_HEAT)\nfor(n=0; n<3;\ncartoon[i+n] = cartoon_tex.max_toll_col[n] ;\nUploading the New Texture\nNow, all that's left is uploading the texture to OpenGL. The first step is to get the\ncolor values from Video for Windows. Once the new color values are calculated,\nwe can go on to converting it to grayscale, and then go on to our cartoon Tenderer.\nOnce all the image manipulation is finished, we call glTexSubImage2D() to get it into\nthe appropriate texture. It is then ready for use in a 3D application as a texture.\n\n\n1.22 Using Web Cameras in Video Games \n161\n// WEBCAM_MAKE_TEXTURE\nvoid webcam_make_texture(LPVIDEOHDR video, webcam_draw_mode mode)\n{\n// Build the color first\nwebcam_make_bgr(webcam_tex.bgr,\nvideo->lpData,\nwco_cam_width,\nwco_cam_height ,\nwebcam_tex.size) ;\nif (mode == GREYSCALE || mode == CARTOON)\nwebcam_make_greyscale (webcam_tex . greyscale ,\nwebcam_tex.bgr, \nwebcam_tex.size) ;\n// Note: Could also pass in the delta buffer instead of\n// the greyscale\nif (mode == CARTOON)\nwebcam_make_cartoon (webcam_tex . bgr ,\nwebcam_tex . cartoon ,\nwebcam_tex. greyscale,\nwebcam_tex.size) ;\n// Upload the greyscale version to OpenGL\nif (mode == GREYSCALE)\n{\nglBindTexture(GL_TEXTURE_2D, webcam_tex.gl_grey) ;\nglTexSub!mage2D(GL_TEXTURE_2D, 0,0,0,\nwebcam_tex . size , webcam_tex . size ,\nGL_LUMINANCE,\nGL_UNSIGNED_BYTE, webcam_tex. greyscale) ;\n}\n// Upload the color version to OpenGL\nelse\n{\nglBindTexture(GL_TEXTURE_2D, webcam_tex.gl_bgr) ;\nglTexSub!mage2D(GL_TEXTURE_2D, 0,0,0,\nwebcam_tex . size , webcam_tex . size ,\nGL_BGR_EXT, GL_UNSIGNED_BYTE, webcam_tex.bgr) ;\nDestroy the Web Cam Window\nAfter we're done using the Web cam, we need to destroy the window and set our call-\nback function to NULL, so Windows knows to stop sending messages to it. In addi-\ntion, we must free up all the memory we previously allocated to our color, grayscale,\nand delta buffers.\n// WEBCAM_DESTROY\nvoid webcam_destroy(void)\n{\nif (cam_driver_on)\n\n\n162 \nSection 1 General Programming\ncapSetCallbackOnFrame(hWndCam, NULL);\nDestroyWindow(hWndCam) ;\nhWndCam = NULL;\nif (webcam_tex . bgr)\nf ree(webcam_tex.bgr) ;\nif (webcam_tex . grayscale )\nfree(webcam_tex. grayscale) ;\nif (webcam_tex . delta_buf f er)\nf ree(webcam_tex.delta_buffer) ;\nif (webcam_tex.back_buffer[0] )\nf ree(webcam_tex.back_buffer[0]) ;\nif (webcam_tex.back_buffer[1 ] )\nf ree(webcam_tex.back_buffer[1 ] ) ;\nConclusion\nWeb cams have a lot of untapped potential that game developers may not realize.\nThey have the ability to be used as input devices, as in the way a mouse is used, by\ntracking color objects and translating their rotations from 2D to 3D [Wu99] . It's even\npossible to replace your standard mouse using a Web cam, by performing data\nsmoothing and color tracking algorithms on the input frames.\nReferences\nMicrosoft Developer Network Library http://msdn.microsoft.com/library/devprods/\nvs6/visualc/vcsample/vcsmpcaptest.htm.\n[FiretoadOO] Firetoad Software, Inc., Ectosaver, 2000 www.firetoads.com.\n[Wu99] Wu, Andrew, \"Computer Vision REU 99\" www.cs.ucf.edu/-vision/reu99/\nprofile-awu.html.\n\n\n2.1\nFloating-Point Tricks:\nImproving Performance with\nIEEE Floating Point\nYossarian King, Electronic Arts Canada\nyking@ea.com\nOverview\nIntegers have fixed precision and fixed magnitude. Floating-point numbers have a\n\"floating\" decimal point and arbitrary magnitude. Historically, integers were fast and\nfloats were slow, so most game programmers used integers and avoided floats. Integer\nmath was cumbersome for general calculations, but the performance benefits were\nworth the effort. Hardware costs have come down, however, and todays PCs and\ngame consoles can do floating-point add, subtract, multiply, and divide in a few\ncycles. Game programmers can now take advantage of the ease of use of floating-point\nmath.\nAlthough basic floating-point arithmetic has become fast, complex functions are\nstill slow. Floating-point libraries may be optimized, but they are generally imple-\nmented for accuracy, not performance. For games, performance is often more impor-\ntant than accuracy.\nThis gem presents various tricks to improve floating-point performance, trading\naccuracy for execution speed. Table lookup has long been a standard trick for integer\nmath; this gem shows generalized linear and logarithmic lookup table techniques for\noptimizing arbitrary floating-point functions.\nThe following sections discuss:\n• The IEEE floating-point standard\n• Tricks for fast float/int conversions, comparisons, and clamping\n• A linear lookup table method to optimize sine and cosine\n• A logarithmic method to optimize square root\n• Generalized lookup table methods to optimize arbitrary floating-point functions\n• The importance of performance measurement\n167\n\n\n168 \nSection 2 Mathematics\nIEEE Floating-Point Format\nThe IEEE standard for floating-point numbers dictates a binary representation and\nconventions for rounding, accuracy, and exception results (such as divide by zero).\nThe techniques outlined in this article rely on the binary representation, but are gen-\nerally not concerned with the rounding and exception handling. If a computer or\ngame console uses the standard binary representation, then these tricks apply, regard-\nless of whether the floating-point handling is fully IEEE compliant. The Pentium III\nStreaming SIMD Extensions (SSE) and PS2 vector unit both implement subsets of\nthe IEEE standard that do not support the full range of exception handling; however,\nsince the binary representation follows the standard, die tricks in this gem will work\nwith these instruction sets.\nThe IEEE standard represents floating-point numbers with a sign bit, a biased\nexponent, and a normalized mantissa, or significand. Single precision, 32-bit floating-\npoint numbers (a \"float\" in C) are stored as shown in Figure 2.1.1.\ns f i r f r ljeg fTijrnrri mm m m m |m m m m mm m m m mm m m m m\n31 30 \n\" \" \n23 22 \n~ \n\" \n\"' \n\" \n\" \n\" \n0\ns = sign\ne = biased exponent\nm = normalized mantissa\nfloating point number is s x 1 .m x 2'6-127)\nFIGURE 2.1.1 IEEE 32-bit floating-point format has a 1-bitsign, 8-bit exponent, and\n23-bit mantissa.\nThe exponent is stored as a positive number in biased form, with 127 added to\nthe actual exponent (rather than the more familiar two's complement representation\nused for integers). The mantissa is usually stored in normalized form, with an implied\n1 before the 23-bit fraction. Normalizing in this way allows maximum precision to be\nobtained from the available bits.\nA floating-point number thus consists of a normalized significand representing a\nnumber between 1 and 2, together with a biased exponent indicating the position of\nthe binary point and a sign bit. The number represented is therefore:\nn = sxl.mx2(e-127)\nFor example, the number -6.25 in binary is -110.01, or -1 X 1.1001 x 22. This\nwould be represented with s=l,e = 2+l 27= 10000001, m = [1.] 1001, as shown in\nFigure 2.1.2.\nSome additional \"magic values\" are represented using the exponent. When e =\n255, m encodes special conditions such as not-a-number (NaN), undefined result, or\npositive or negative infinity. Exponent e = 0 is used for denormalized numbers—\nnumbers so tiny that the range of the exponent overflows 8 bits.\n\n\n2.1 Floating-Point Tricks: Improving Performance with IEEE Floating Point \n169\ns=1\n-6.25 decimal \n\"-110.01 binary \n* -1 x [1.]1001 x 22 \n+ 6 = 2 + 127 = 10000001\nm= 1001000...\nI\nFIGURE 2.1.2 The number -6.25 as stored in memory in 32-bit IEEE floating-point\nformat.\nDouble precision 64-bit floating-point numbers are stored using the same basic\nformat, but with 11 bits for the exponent and 52 for the significand. The exponent is\nbiased by 1023, rather than 127. Double precision numbers require twice the storage\nspace and may be slower to load from memory and to process. For these reasons, dou-\nble precision should generally be avoided in game code. This gem uses only single-\nprecision floats.\nFloating-Point Tricks\nBefore getting to the lookup table techniques, this section discusses some useful\nfloating-point tricks that help explain the games you can play with the bit patterns of\nfloating-point numbers.\nFloat/lnt Conversions\nThe lookup table techniques that follow convert a floating-point number to an inte-\nger to generate lookup table indices. This operation can be slow; on a Pentium II, for\nexample, casting a float to an int with \"(int)f' takes about 60 cycles. This is because\nthe ANSI C standard dictates that casting a float to an int should truncate the frac-\ntion, but by default, the FPU rounds to the nearest integer. Casting to an int becomes\na function call to a routine that changes the FPU rounding mode, does the conver-\nsion, and then changes the rounding mode back. Nasty.\nNote that the cost of casting between ints and floats is dependent on the compiler\nand processor with which you are working. As with all optimizations, benchmark this\nconversion trick against a regular typecast and disassemble the code to see what's actu-\nally happening.\nThe conversion can be performed much faster by simply adding 1 x 223 to the\nfloating-point number and then discarding the upper exponent bits of the result.\nWe'll look at the code first, and then analyze why it works.\nTo do this, it is helpful to define the following union, which lets us access a 32-bit\nnumber as either an integer or a float.\n\n\n170 \nSection 2 Mathematics\ntypedef union\n{\nint \ni;\nfloat \nf;\n} _INTORFLOAT;\nThe INTORFLOAT type is used in code snippets throughout this gem. Note that\nit makes access to the bit pattern of numbers look very simple—in practice, the com-\npiler may be generating more code than you expect. On a Pentium II, for example,\nfloating-point and integer registers are in separate hardware, and data cannot be moved\nfrom one to the other without going through memory; for this reason, accessing the\nmembers of the INTORFLOAT union may require additional memory loads and\nstores.\nHere is how to convert a float to an int:\nINTORFLOAT \nn; \n// floating-point number to convert\nINTORFLOAT \nbias; \n// \"magic\" number\nbias.i = (23 + 127) « 23; // bias constant = 1 x 2*23\nn.f = 123.456f; \n// some floating-point number\nn.f += bias.f; \n// add as floating-point\nn.i -= bias.i; \n// subtract as integer\n// n.i is now 123 - the integer portion of the original n.f\nWhy does this work? Adding 1 x 223 as a floating-point number pushes the man-\ntissa into the lower 23 bits, setting the exponent to a known value (23 + 127). Sub-\nfloating-point\n43.25= \n1 0 1 0 1 1.0 1\n1 x 223 = \n+ 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 . 0 0\n1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 1 . 0 1\n[1 .]00000000000000000101011 01 x 223\noTv.i ojoj tTi|? |i jctl o I o I o] o I o I o I o I o I o I o I o I o I o I o [ o I o I o 111 o J11 o 11 h~|\n31 30 \n23 22 \n0\n— o I:'F'l'*ril-'i-'f' o o o o o o o o o o o o o o o o o o o o o o o\n1 0 1 0 1 1 \n=43\ninteger\nFIGURE 2.1.3 The number 43.25 is converted to an integer by manipulating the floating-point\nformat. The underlined bits in the mantissa do not fit in memory and are discarded (with rounding).\n\n\n2.1 Floating-Point Tricks: Improving Performance with IEEE Floating Point \n171\ntracting the known exponent as an integer removes these unwanted upper bits, leav-\ning the desired integer in the low bits of the result. These steps are illustrated in Fig-\nure 2.1.3 for the number 43.25.\nOn a Pentium II (with everything in cache), this reduces the conversion time\nfrom 60 cycles to about 5. Note that it is also possible to write inline assembly code to\nget the FPU to convert from float to int without changing the rounding mode—this\nis faster than typecasting, but generally slower than the biasing trick shown here.\nThis trick works as long as the floating-point number to be converted does not\n\"overlap\" the bias constant being added. As long as the number is less than 223, the\ntrick will work.\nTo handle negative numbers correctly, use bias = ((23 + 127) « 23) + (1 «\n22)—the additional (1 « 22) makes this equivalent to adding 1.5 x 223, which causes\ncorrect rounding for negative numbers, as shown in Figure 2.1.4. The extra bit is\nrequired so that the subtract-with-borrow operation does not affect the most signifi-\ncant bit in the mantissa (bit 23). In this case, 10 upper bits will be removed instead of\n9, so the range is one bit less than for positive numbers—the number to be converted\nmust be less than 222.\nTo convert from a float to a fixed-point format with a desired number of frac-\ntional bits after the binary point, use bias = (23 - bits + 127) « 23. Again, to handle\nnegative numbers, add an additional (1 « 22) to bias. This is illustrated in Figure\n2.1.5, which shows the conversion of 192.8125 to a fixed-point number with two\nfractional bits.\nNote that you can use the \"inverse\" of this trick to convert from integer to float-\ning-point.\nfloating-point\n-43-25 = \n- 1 0 1 0 1 1.0 1\n1.5x223= \n+ 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0.0 D _\n0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 0 0.1 1\n[1 .]0111111111111111101010011 x 22\n31 30 \n23 22 \n0\n— o SJ'SWfM-¥X§;Q o o o o o o o o o o o o o o o o o o o o o o\n0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 0 0 \n=-44\ninteger\nFIGURE 2.1.4 To convert a negative float to an integer is slightly different than for positive numbers.\nHere we see the conversion of-43.25. Observe how the rounding applied when the underlined bits\nare discarded yields the correct negative integer.\n\n\n172 \nSection 2 Mathematics\nfloating-point\n192.8125= \n1 1 0 0 0 0 0 0.1 1 0 1\n1x2 2 3~ 2 = \n+ 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0.0 0 0 0\n1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0.1 1 0 1\n[1J00000000000001100000011 01 x 223\no ] j I fi} •o|iT€f iTTil oToToToJoToJo I oj o I o [ o I o I o I o 1111 |o I o I o I o I o I o 11 h\n31 30 \n23 22 \n0\n~~ ° 33\"I\"CT1-rP£ o 0 0 0 0 0 0 0 0 0 0 0 o o o o o o o o o o o\n1 1 0 0 0 0 0 0.1 1 \n=192.75\n21.2 fixed-point\nFIGURE 2.1.5 Fractional bits can be preserved during the conversion from float to integer. Here,\n192.8125 is converted to a fixed-point number with two bits after the binary point.\nn.i = 123; \n// some integer\nn.i += bias.i; \n// add as integer\nn.f -= bias.f; \n// subtract as floating-point\n// n.f is now 123.0 - the original n.i converted to a float\nUsually, int-to-float conversions using typecasts are fast, and thus less in need of a\nperformance-optimizing trick. \n>\nSign Test\nBecause the sign bit of a floating-point number is in bit 31, the same as for integers,\nwe can use the integer unit to test for positive or negative floating-point numbers.\nGiven a floating-point number f, the following two code fragments are (almost)\nequivalent:\nif ( f < O.Of ) \n// floating-point compare\nINTORFLOAT ftmp;\nftmp.f = f;\nif (ftmp.i < 0) \n// integer compare\nAlthough they are equivalent, the integer compare may run faster due to better\npipelining of the integer instruction stream. Try it and see if it helps your code.\n(\"Almost\" equivalent because negative 0 will behave differently.)\n\n\n2.1 Floating-Point Tricks: Improving Performance with IEEE Floating Point \n173\nComparisons\nSince the floating-point format stores sign, exponent, mantissa in that bit order, we\ncan use the integer unit to compare floating-point numbers—if the exponent of a is\ngreater than the exponent of b, then a is greater than b, no matter what the mantissas.\nThe following code fragments may be equivalent:\nif ( a < b ) \n// floating-point compare\nINTORFLOAT atmp, btmp;\natmp.f = f; btmp.f = b;\nif (atmp.i < btmp.i) \n// integer compare\nAgain, the integer comparison will usually pipeline better and run faster. Note\nthat this breaks down when a and b are both negative, because the exponent and man-\ntissa bits are not stored in the two's complement form that the integer comparison\nexpects. If your code can rely on at least one of the numbers being positive, then this\nis a faster way to do comparisons.\nClamping\nClamping a value to a specific range often comes up in games programming, and\noften we want to clamp to a [0,1] range. A floating-point value /can be clamped to 0\n(i.e., set/= 0 if/< 0) by turning the sign bit into a mask, as in the following code\nsnippet:\nINTORFLOAT ftmp;\nftmp.f = f;\nint s = ftmp.i » 31; \n// create sign bit mask\ns = -s; \n// flip bits in mask\nftmp.i &= s; \n// ftmp = ftmp & mask\nf = ftmp.f;\ns is set to the bits of/shifted right by 31—sign extension replicates the sign bit\nthroughout all 32 bits. NOT-ing this value creates a mask of 0 bits if/was negative, or\n1 bits if/was positive. AND-ing/with this value either leaves/unchanged or sets/to\n0. Net result: if/was negative, then it becomes 0; if it was positive, it is unchanged.\nThis code runs entirely in the integer unit, and has no compares or branches. In\ntest code, the floating-point compare and clamp took about 18 cycles, while the in-\nteger clamp took less than five cycles. (Note that these cycle times include loop\noverhead.)\nClamping positive numbers to 0 (set/= 0 if/> 0) is less useful but even easier,\nsince we don't need to flip the bits in the mask.\nINTORFLOAT ftmp;\nftmp.f = f;\nint s = ftmp.i » 31; // create sign bit mask\n\n\n174 \nSection 2 Mathematics\nftmp.i &= s; \n// ftmp = ftmp & mask\nf = ftmp.f;\nClamping to 1 (set/= 1 if/> 1) can be done by subtracting 1, clamping to 0, and\nthen adding 1.\nINTORFLOAT ftmp;\nftmp.f = f - 1.0f;\nint s = ftmp.i » 31; // create sign bit mask\nftmp.i &= s; \n// ftmp = ftmp & mask\nf = ftmp.f + 1.Of;\nNote that using conditional load instructions in assembly will generally increase\nthe speed of clamping operations, as these avoid the need for branching, which kills\nthe branch prediction logic in the instruction pipeline.\nAbsolute Value\nThis one's easy: since floating-point numbers do not use two's complement, taking\nthe absolute value of a floating-point number is as simple as masking the sign bit to 0.\nINTORFLOAT ftmp;\nftmp.f = f;\nftmp.i &= Ox7fffffff;\nf = ftmp.f;\nNote that this is much faster than using a compare to determine if/is less than 0\nbefore negating it.\nLinear Lookup Tables for Sine and Cosine\nTrigonometry is often useful in games—for calculating distances and angles, stepping\nalong a circle, or animating a water mesh. The standard math library has all the nor-\nmal trig functions, but they are slow, and they work on doubles, so they use more\nmemory than needed. In a game, a low-precision calculation is often sufficient.\nTo efficiently compute sine and cosine, we can use a lookup table. A common\napproach is to use fixed-point math, with angles represented on an integer scale, say, 0\nto 1023 to cover the full circle. However, this means that the game programmer needs\nto understand the library implementation of sine and cosine, and represent his or her\nangles in the format it requires. By using floating-point tricks for efficient indexing,\nwe can create floating-point trig functions that use standard radians and do not\nrequire the programmer to know about implementation details.\nsin\nLet's implement:\nfloat fsin( float theta );\n\n\n2.1 Floating-Point Tricks: Improving Performance with IEEE Floating Point \n175\nThis can easily be done with a lookup table. A 256-entry table, covering the range\nof angles 0 to 271, is initialized as:\nsintable[i] = (float)sin((double)i * 2.0*3.14159265/256.0)\nwhich simply converts i in the range 0-256 to floating-point radians in the range 0 to\n2n and takes the sine of the resulting angle.\nGiven this table, the jsin function could be implemented as follows:\nfloat fsin( float theta )\n{\ni = (unsigned int)(theta * 256.Of/\n(2.0f*3.14159265f));return \ntable[i];\n}\nHowever, this has two problems: first, it uses the slow float-to-int typecast, and\nsecond, if theta is outside the range [0,2Jl), then the function will index out of the\ntable.\nBoth of these problems are solved with this implementation:\n#define FTOIBIAS \n12582912.Of \n// 1.5 * 2*23\n#define PI \n3.l4l59265f\nfloat fsin( float theta )\n{\nint \ni;\nINTORFLOAT ftmp;\nftmp.f = theta * (256.Of/(2.0f*PI)) + FTOIBIAS;\ni = ftmp.i & 255;\nreturn table[i];\n}\nThis implementation uses the floating-point biasing trick described previously\nfor fast conversion from floating-point to integer. It masks the integer with 255 so\nthat the table index wraps around, always staying in the 0-255 range. Note that if/\nexceeds 222, then the float-to-integer conversion trick will fail, so it's still necessary to\nperiodically reduce/to the valid [0,27l) range.\nThis implementation of jsin takes about 10 cycles on a Pentium II (assuming all\ncode and data is in primary cache), as compared with almost 140 cycles for the stan-\ndard math library implementation of sin (even though sin uses the hardware sine\ninstruction in the FPU).\nA 256-entry floating-point table takes IK, which should easily stay within cache\nfor the duration of your inner loops. Accuracy is basically eight bits, as constrained by\n('\"c>?''\\ \nt\"ie l°°kuP table size. The worst-case error can easily be determined from analyzing\n^-—--^ \nthe lookup table (as is demonstrated in the code on the CD). Larger lookup tables\nincrease the accuracy of your results, but will hurt cache performance.\n\n\n176 \nSection 2 Mathematics\ncos\nThe cosine function could be implemented in exactly the same way, with its own\nlookup table, but we can take advantage of the fact that cos(0) = sin(9 + n/2), and use\nthe same lookup table. To do this, we just need to add 256/4 (since adding n/2 means\nwe're adding a quarter of a circle to the angle) to the lookup table index, which we can\ndo at the same time as biasing the exponent. This yields the following implementation:\nfloat fcos( float theta )\n{\nint \ni;\nINTORFLOAT ftmp;\nftmp.f = theta * (256. Of /(2.0f*PI)) + FTOIBIAS + 64f;\ni = ftmp.i & 255;\nreturn table[i] ;\nDepending on the application, it is often useful to get both sine and cosine at the\nsame time. This can be done more efficiently than computing each separately — sim-\nply look up sin, and then add 64 to the index and mask by 255 to look up cos. If you\nneed to compute several sines or cosines at once, you can write custom code to inter-\nleave the calculations and make it faster still.\nLogarithmic Optimization of Square Root\nSquare roots are useful in games for operations such as computing distances, normal-\nizing vectors, and solving quadratic equations. Despite the presence of a square root\ninstruction built into the FPU, the sqrt function in the standard C library still\ntakes about 80 cycles on a Pentium II CPU, making it another good candidate for\noptimization.\nSquare root optimization is an interesting use of floating-point bit fiddling,\nbecause the logarithmic, multiscale nature of square root allows us to decompose the\nsquare root calculation and manipulate the mantissa and exponent separately. Con-\nsider the square root of a floating-point number:\nsqrrtf) = sqrl{\\.m x 2')\n= sqrt(l.m)x2'n\nSo, to compute the square root off, we compute the square root of the mantissa\nand divide the exponent by 2. However, the exponent is an integer, so if the exponent\nis odd, then dividing by 2 loses the low bit. This is addressed by prepending the low\nbit of the exponent to the mantissa, so we have:\nsqrtff) = sqrt(\\.m-x. 2\">) x 2 ['/2j\nwhere e0 is the low bit of the exponent.\n\n\n2.1 \nFloating-Point Tricks: Improving Performance with IEEE Floating Point \n177\nThis is implemented with a 256-entry table for the square root of the truncated\nmantissa and some additional tweaking for the exponent calculation, as follows:\nfloat fsqrt( float f )\nINTORFLOAT \nftmp;\nunsigned int \nn, e;\nftmp.f = f;\nn = ftmp.i;\ne = (n » 1) & Ox3f800000; // divide exponent by 2\nn = (n » 16) & Oxff; \n// table index is eO+m22-m16\nftmp.i = sqrttable[n] + e; // combine results\nreturn ftmp.f;\nThe table index is simply the upper bits of the mantissa and the low bit of the\nexponent (e0). The lookup table contains the mantissa of the computed square roots.\nThe exponent of the square root is computed by shifting the exponent of /by 1\nto divide by 2. Since the exponent is biased, this divides the bias by 2 as well as the\nexponent, which is not what we want. This is compensated for by adding an addi-\ntional factor to the entries otsqrttable to re-bias the exponent.\nThis fcqrt function takes about 16 cycles on a Pentium II CPU—about five times\n^~-_i^ \nfaster than the C library implementation. Again, this is assuming that everything is in\nmma> \ncache.\nThe algorithm is explained in more detail in the code on the CD.\nOptimization of Arbitrary Functions\nConsider an arbitrary floating-point function of one variable:\nThe techniques just discussed reveal two basic methods for table-based optimiza-\ntions of general functions. For sine and cosine, the value of x was linearly quantized\nover a known range and used as a table index to look up y. For square root, the value\nof x was logarithmically quantized and used as a table index to look up a value. This\nvalue was scaled by a function of the exponent of x to get the final value of y.\nThe linear approach rescales a floating-point number and converts it to an integer\nto generate a lookup table index via linear quantization. This is a simple technique very\nsimilar to integer lookup tables, the only wrinkle being die efficient conversion of a\nfloating-point value into an integer index. The logarithmic approach uses the floating-\npoint bit pattern directly as a table index, to achieve logarithmic quantization.\nBoth of these techniques can be generalized to the case of arbitrary functions.\nDepending on the function, the linear or logarithmic approach may be more\nappropriate.\n\n\nSection 2 Mathematics\nLinear Quantization\nThe fiin function in the previous section can be used as a template for optimiz-\ning general functions via linear quantization. Suppose we know that the function\nwill only be used over a limited range x e [A, S). We can build a lookup table\nthat uniformly covers this range, and efficiently calculate the correct index into the\ntable for values of x within the range. The optimized function f is then imple-\nmented as:\ntfdefine \nFTOIBIAS \n1258291 2. Of \n// 1.5 * 2\"23\ntfdefine \nTABLESIZE \n256\ntfdefine INDEXSCALE \n((float) TABLESIZE / ( B - A ) )\nfloat flut( float x )\n{\nint \ni;\nINTORFLOAT ftmp;\nftmp.f = x * INDEXSCALE + (FTOIBIAS - A * INDEXSCALE);\ni = ftmp.i & (TABLESIZE - 1);\nreturn ftable[i] ;\nThe lookup table is initialized with:\nftable[i] = f( (float)i / INDEXSCALE + A );\nwhere /is the full-precision floating implementation of the function. The y?«J compu-\ntation requires two floating-point operations (multiply and add), one integer bitwise\nmask, and a table lookup. It takes about 10 cycles on a Pentium II CPU.\nNote that additional accuracy can be obtained for a few more cycles by linearly\ninterpolating the two closest table entries. An API supporting this optimization for\ngeneral functions is provided on the CD, including optional linear interpolation to\nincrease accuracy.\nLogarithmic Quantization\nThe linear method treats the range [A,B) uniformly. Depending on the function, a\nlogarithmic treatment may be more appropriate, as in the square root optimization.\nThe basic idea is that the bits of the floating-point representation are used directly as\na lookup table index, rather than being manipulated into an integer range. By extract-\ning selected bits of the sign, exponent, and mantissa, we can massage the 1:8:23 IEEE\nfloating-point number into our own reduced precision format with as many bits as we\nlike for the sign, exponent, and mantissa.\nIn the square root example, we extracted 8 bits to give a logarithmically quantized\n0:1:7 representation. We used 1 bit of the exponent and 7 bits of the mantissa. The\nsign bit was discarded, since the square root of a negative number is undefined. The\n0: 1 :7 format represents an 8-bit mantissa (remember the implied 1 in the IEEE rep-\n\n\n2.1 Floating-Point Tricks: Improving Performance with IEEE Floating Point \n179\nresentation) and a 1-bit exponent, so it can represent numbers between [1]. 0000000\nx 2° and [1] . 1 1 1 1 1 1 1 x 21, which covers the range [1 ,4).\nThe square root function was decomposed into an operation on the 0:1:7 quan-\ntized number (a table lookup) and an independent operation on the exponent (divide\nby 2). Additional trickery was employed to optimize the two independent operations\nand combine the mantissa and exponent into a 32-bit floating-point result.\nOther functions can benefit from this method of logarithmic quantization. The\nIEEE format makes it easy to extract the least significant bits of the exponent with the\nmost significant bits of the mantissa in a single shift and mask operation. To extract\nebits of the exponent and mbits of the mantissa, simply do this:\nbits = (n » (23 - mbits)) & ((1 « (ebits + mbits)) - 1)\nThis shifts the number n to the right so that the desired bits of the mantissa and\nexponent are the rightmost bits in the number, and then masks off the desired num-\nber of bits.\nThe sign bit can be handled with some extra bit fiddling, depending on the func-\ntion with which you are working. If you know that you are only dealing with positive\nnumbers (for example, square root), or that your function always returns a positive\nresult, then you can ignore the sign. If the sign of your result is the same as the sign of\nthe input number (in other words, f(-x) = -f(x)), you can simply save and restore the\nsign bit.\nFor functions with a limited range of input values, masking out selected bits of\nthe exponent and mantissa can give you a direct table index. For example, if you only\ncare about your function over the range [1,16), then you can use 2 bits of exponent\nand 4 bits of mantissa (for example). This 0:2:4 representation stores binary numbers\nbetween 1 .0000 x 2° and 1 . 1 1 1 1 x 23, or decimal 1 .0 to 1 5 . 5 . Mask out these bits and\nuse the bits directly as an index into a precomputed 64-entry table. This requires very\nfew cycles and is computationally fast. However, as you add more precision, the table\ngrows and may become prohibitively large, at which point cache performance will\nsuffer.\nAn alternative is to decompose the exponent and mantissa calculations, as was\ndone in the square root example. If your function f(x) can be decomposed as:\nthen you can, for example, approximate fl with a 256-entry lookup table, using 8 bits\nof the mantissa m, and perform the calculation of f2 directly, as an integer operation\non the exponent e. This is essentially the technique used by the square root trick.\nLogarithmic quantization is a powerful tool, but often requires function-specific\nbit fiddling to optimize a particular function. Fully general techniques are not always\npossible, but the methods described in this section should be helpful when tackling\nyour specific optimization problem.\n",
      "page_number": 156,
      "chapter_number": 18,
      "summary": "If we want to see the image every frame (single buffer), we will need\nto compare against the grayscale Key topics include floating, bits. This would result\nin an image that is one-third the size of our regular textures, which would be practical\nfor users who have slow Internet connections, but still want to transmit Web cam data.",
      "keywords": [
        "Floating-Point",
        "IEEE Floating Point",
        "WEBCAM",
        "floating-point number",
        "bits",
        "exponent",
        "Floating-Point Tricks",
        "lookup table",
        "number",
        "CARTOON",
        "bit",
        "cam",
        "Integer",
        "sign bit",
        "heat"
      ],
      "concepts": [
        "floating",
        "bit",
        "bits",
        "point",
        "integers",
        "numbers",
        "tables",
        "function",
        "functions",
        "exponent"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 3",
          "chapter": 48,
          "title": "Segment 48 (pages 456-465)",
          "relevance_score": 0.53,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 7",
          "chapter": 46,
          "title": "Segment 46 (pages 443-452)",
          "relevance_score": 0.5,
          "method": "sentence_transformers"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 23,
          "title": "Segment 23 (pages 441-462)",
          "relevance_score": 0.5,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 1",
          "chapter": 59,
          "title": "Segment 59 (pages 570-580)",
          "relevance_score": 0.47,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 4,
          "title": "Segment 4 (pages 31-40)",
          "relevance_score": 0.46,
          "method": "sentence_transformers"
        }
      ]
    },
    {
      "number": 19,
      "title": "Segment 19 (pages 173-181)",
      "start_page": 173,
      "end_page": 181,
      "detection_method": "topic_boundary",
      "content": "180 \nSection 2 Mathematics\nPerformance Measurement\nWhen optimizing code, make sure you measure performance carefully before and\nafter making the optimization. Sometimes an optimization that looks good on paper\ncauses trouble when implemented, due to cache behavior, branch mispredictions, or\npoor handling by the compiler. Whenever you make changes, be sure that you are\nimproving your performance—never assume.\nMake sure compiler optimizations are enabled. Use inline functions where appro-\npriate. Again, test your results when using inline functions or tweaking the compiler\nsettings.\nWhen benchmarking code, take care that compiler optimization isn't getting in\nthe way of your tests. Disassemble your code and step through it to be sure it's run-\nning what you expected. When timing things, it's often helpful to run something in a\nloop—but if the body of your loop gets optimized out, then your timing won't be\nvery accurate!\nOn Pentium computers, you can use the rdtsc (read time stamp counter) instruc-\ntion to get the current CPU cycle count. Intel warns that this instruction should be\nexecuted a couple times before you start using the results. Intel also recommends\nusing an instruction such as cpuid that will flush the instruction cache, so that you get\nmore consistent timing results. To get absolute times, the cycle counts can be con-\nverted to seconds by dividing by the execution speed (MHz) of the processor.\nCycle counters are the most reliable way to measure fine-grain performance.\nOther tools such as VTune and TrueTime (on the PC) are useful for higher level pro-\nfiling. For any benchmarking, make sure that memory behavior is realistic, as mem-\nory bottlenecks are one of the most serious impediments to high performance on\nmodern processors. Be aware of how your benchmark is using the cache, and try to\nsimulate the cache behavior of your game. For a benchmark, the cache can be\n\"warmed up\" by running the algorithm a couple of times before taking the timing\nmeasurements. However, a warm cache may not emulate the behavior of your\ngame—best is to benchmark directly in the game itself. Disable interrupts for more\nreliable results, or take measurements multiple times and ignore the spikes.\nAll the cycle times reported in this gem are from an Intel Pentium II 450-MHz\nmachine. Each operation was repeated 1000 times in a loop, with the instruction and\ndata cache warmed by running the test multiple times. Cycle counts include loop\noverhead. See the code on the CD for actual benchmarks used.\nThe lookup table techniques described in this article are appropriate if the lookup\ntable remains in cache. This is probably true within the inner loop of your rendering\npipeline or physics engine, but it's probably not true if you are calling these functions\nrandomly throughout the code. If the lookup tables cannot be kept in cache, then\ntechniques that use more computation and fewer memory accesses are probably more\nappropriate—methods such as polynomial approximation (see [EdwardsOO] for a\ngood overview).\n\n\n2.1 Floating-Point Tricks: Improving Performance with IEEE Floating Point \n181\nConclusions\nThis gem scratched the surface of floating-point optimization. Lookup tables are the\nprimary method explored, and they often produce significant speedups. However, be\naware of cache behavior, and always benchmark your results. Sometimes you can\nachieve the same result faster by using more computation but touching memory\nless—techniques such as polynomial approximation may be appropriate. The tricks\nshown here can be extended in a variety of ways, and many other tricks are possible.\nAs a popular book title suggests, there is a Zen to the art of code optimization, and a\nshort overview like this can't hope to cover all possibilities.\nReferences\n[Abrash94] Abrash, Michael, Zen of Code Optimization, Coriolis Group, 1994.\n[EdwardsOO] Edwards, Eddie, \"Polynomial Approximations txp Trigonometric Func-\ntions,\" Game Programming Gems, Charles River Media, 2000.\n[IntelOl] Intel Web page on floating-point unit and FPU data format. Good for PCs,\nbut relevant to any IEEE-compliant architecture. Available at http://developer\n.intel.com/design/intarch/techinfo/Pentium/fpu.htm.\n[Lalonde98] Lalonde, Paul, and Dawson, Robert, \"A High Speed, Low Precision\nSquare Root,\" Graphics Gems, Academic Press, 1998.\n\n\n2.2\nVector and Plane Tricks\nJohn Olsen, Microsoft\ninfix@xmission.com\nY\nour collision detection routine is running flawlessly now, returning a surface\npoint and a normal back when you feed it a position and velocity vector. Now\nwhat? Actually, there are quite a few things you can do based on the data you have.\nIn general, you may want to have your collision routine generate the actual colli-\nsion point, but the methods in this gem show how to handle collision results that\nshow only the plane of intersection. Since a plane can be fully specified with a surface\nnormal and any point on the plane, you can work your way through the math to find\neverything you need from there.\nData that goes into your collision code would be an initial point Pt and a final\npoint Pf, and the output in the case of a collision would be a plane that is defined by\na unit vector surface normal TV and a point on the surface Ps. The point need not be\nthe actual intersection point as long as it is on the plane.\nFor optimization purposes, you will probably want to build a subset of these cal-\nculations back into your collision code. Much of the information you need will have\nalready been calculated during the collision tests. It will be much faster to reuse the\nalready known information rather than recalculate it from scratch.\nThe plane equation Ax + By + Cz + D = 0 maps onto the supplied data, where x,\ny, and z are the components of the normal vector N, and D is the dot product N* Ps.\nAltitude Relative to the Collision Plane\nOne of the most commonly used pieces of data when checking collisions is the alti-\ntude of one of your data points. If the altitude is positive, the point is above the sur-\nface and has not collided yet. If it is negative, you have collided and penetrated the\nsurface.\nTypical collision testing code will only return a hit if one of your test points is on\neach side of the test surface. This means that if you want to predict collisions, you\nneed to pass along a position with an exaggerated velocity vector. That way, the exag-\ngerated vector will intersect much earlier than your actual movement would allow.\nOnce you have tricked your collision code into returning a surface point and nor-\nmal, you can get your altitude relative to that surface by using your initial position.\nThe final position is not used for this altitude calculation.\n182\n\n\n2.2 Vector and Plane Tricks\n183\nFIGURE 2.2.1 Determining the altitude.\nAs shown in Figure 2.2.1, we want to find the length of the vector (Ps - Pt) when\nit is projected onto the surface normal N. This gives us the distance of the shortest\nline from the point to the surface. This shortest vector is by definition perpendicular\nto the surface. This is exactly what the dot product gives us, so we are left with the\nscalar (nonvector) distance to the surface Ds as shown:\nNearest Point on the Surface\nOnce we have the distance to the surface, it takes just one more step to get the point\non the surface PH that is closest to the initial point Pf as also shown in Figure 2.2. 1 . We\nalready know the point is distance Ds from die starting point, and that distance is\nalong the surface normal TV. That means die point can be found with the following:\nPtt = P,-DsN\nThe normal vector is facing the opposite direction of the distance we want to\nmeasure, so it needs to be subtracted from the starting point.\nPinning Down the Collision Point\nWhen you have one point on each side of a test surface, your vector must at some\npoint intersect with it. Finding this intersection point Pc will tell you where your vec-\ntor pierces die surface. If your collision detection code has not already provided you\nwith the exact point, here is how you would find it.\nYou know that the collision point must lie somewhere along the line. Knowing in\nadvance that there is a collision makes it possible to take some shortcuts since we\nknow there actually is a solution to the equation. If the test ray is parallel to the sur-\nface, the ratio cannot be calculated since it results in a divide by zero. We can take\nadvantage of the calculation for Ds in finding die collision point Pc. Figure 2.2.2\nshows the information needed for this calculation.\n\n\n184\nSection 2 Mathematics\nFIGURE 2.2.2 Finding the collision pointPc.\nSince we know the collision is between the two points, we can find it by calculat-\ning how far it is along the line from P/ to Pf. This ratio can be written as:\nR = ((Pi - P,) • N) I ((% - Pf) • N)\nOr, using our already computed Ds, it becomes:\nR = D,I ((P,. - Pf) • N)\nThe two line segments are arranged to both point in the same direction relative to\nthe surface normal, which guarantees that our ratio will be non-negative. Once we\nhave this ratio, we can use it to multiply the length of the vector from P, to Pyto tell\nhow far from P, the collision occurs. In the special case of R = 1, you can avoid the cal-\nculation since it results in the point Pf For R = 0, the point is P,-. Otherwise, the fol-\nlowing equation is used:\nPe=Pf + R(Pf - P^\nDistance to the Collision Point\nAlthough similar to Ds, this differs from the distance from the collision plane because\nthe distance is calculated along the path of travel rather than along the surface normal.\nIn the case of travelling near the surface but nearly parallel to it, your distance to col-\nlision will be very large when compared to your altitude.\nThis is the type of calculation you would want to use when calculating altitude\nfor an aircraft, since you cannot guarantee the direction of a surface normal on the\nground below. Rather than sending your actual velocity for a collision test, you would\nsend your current position and a very large down vector, long enough to guarantee\nthat it will intersect the ground. This works in the case of intersecting a small polygon\n\n\n2.2 Vector and Plane Tricks\n185\nFIGURE 2.2.3 Calculating distance to the collision point.\nthat happens to be aligned nearly perpendicular to the test vector. In that case, the\naltitude relative to the collision plane Pn as calculated earlier would give a very small\nnumber.\nOnce you have the actual collision point, it's very easy to calculate the distance\nusing Euclid's equation to find how far it is from the starting point to the collision\npoint. Figure 2.2.3 shows the elements required. The distance to the collision point,\nDc, is the magnitude of the vector from our starting point /J to the collision point Pe\nthat was calculated earlier:\nAnother way to describe the magnitude of this vector is that it is the square root\nof the sum of the squares of the differences of each component of the vector. Most\nvector libraries include a function call to find the magnitude or length of a vector.\nVector magnitudes are never negative.\nAnother possible shortcut can be used when you know the ratio R used to find\nthe collision point as described in the previous section. The distance to the collision\npoint is the length of the full line (which you may already have lying around) multi-\nplied by the already computed ratio.\nD. = RPf-Pi\nReflecting Off the Collision Plane\nThe usual result of a collision is to bounce. The interesting part is figuring out the\ndirection and position once you have rebounded off a surface. Figure 2.2.4 shows\nthe elements used in calculating the reflected vector. The first two cases will perfectly\n\n\nSection 2 Mathematics\n2N((Ps-Pf)-N)\nP.\nP.-Pf\nFIGURE 2.2.4 Calculating the reflected vector.\npreserve the magnitude of the velocity. In both cases, the result of the bounce will be\nthe same distance from the plane as Pf.\nOne of the simplest ways to visualize reflecting a point relative to a plane is to\nimagine a vector from the below-ground destination point back up to the surface\nalong the surface normal. The new reflected location is found by continuing that line\nan equal distance to the other side of the plane. You obtain the new location\nby adding to the final point twice the distance from the final point to the surface.\nReusing our equation to find the distance perpendicular to the plane, we come up\nwith the following. The distance is multiplied by the surface normal to turn it back\ninto a vector since you cannot add a simple scalar value such as Ds to a vector.\nThe original and reflected vectors will have the same angle relative to the plane.\nAnother way of looking at this is that if you normalize the vectors from your collision\npoint going out to both your original start point and your reflected point, then find a\ndot product of each with your surface normal; they will be equal.\nVectors are normalized by dividing the vector by its length or magnitude, so the\nstatement about reflected vectors in the previous paragraph can be written as:\np~p,\nP.-P.\np - p\n-±c \n±.N\nP.-P;\nAny point on the plane could be substituted for Pc (Ps works, for instance) in the\npreceding equation and the same result would hold since all we are saying here is that\nthe ends of the unit vectors are the same distance from the plane.\nA complication with reflections is that the newly determined end point needs to\nbe tested all over again with your collision code to see if you have been pushed\nthrough some other surface. If you repeat the collision test, but with a vector from\nyour collision point Pc to the newly reflected point Pr, you will get a possible new col-\nlision. You will need to repeat this process until no collision occurs. At each pass, your\n\n\n2.2 Vector and Plane Tricks\n187\nvector will be smaller as it is chewed up by bouncing, as long as you do not try to\nbounce between two coincident planes.\nThere is one degenerate case you should also watch out for when chaining colli-\nsions together. Should you hit exactly at the intersection of two planes, your second\ntest will be made with an initial point on the edge of the surface. This is easy to han-\ndle if you know about this problem and allow for it in advance by assuming anything\nexactly at the surface (or on the edge) has not yet collided, and is counted as above the\nsurface for collision purposes. Collisions are reserved for penetration distances greater\nthan zero.\nOnce you have completed your final reflection, a new velocity vector can be com-\nputed by normalizing the direction from the last collision to the final reflected loca-\ntion and multiplying it by the original velocity like this:\nV = (Pr - PcPt - Pf\nP.-P.\nKickback Collision\nSometimes, rather than reflect off the collision plane, you want to kick the player\nback the way he or she came as shown in Figure 2.2.5. The calculations for this are\nsimple once you have the collision point. Since this collision also preserves velocity, it\nis also perfectly elastic.\nThe point to which you are kicked back, /^, is obtained by calculating the vector\nfrom your final point Pf back to your collision point Pe and adding it to the collision\npoint.\nWe can combine terms to get:\nPk = 2Pc - Pf\nFIGURE 2.2.5 Calculating a kickback vector.\n\n\n188 \nSections Mathematics\nYou can run into the same problems with kickback collisions as with reflections\nwhere the destination point leads to an additional collision. However, there is an early\nway out of the loop for kickback collisions in some cases. If the collision point is more\nthan halfway from the initial point to the final point, the resulting kickback point will\noccur in an area that has already been checked for collisions, so no additional check is\nnecessary.\nCollisions with Damping\nShould you want to perform a collision with some sort of friction or damping, you\nwill need to be careful of how you handle the vectors. You will need a scalar value\nS that will be used as a multiplier to change your velocity at each impact. It will\ntypically range from zero (the object stops on impact) to one (a completely elastic\ncollision preserving velocity). Energy can be injected into the system by increasing\nthe scalar above one. A kickback collision is the same as using a scalar of negative\none.\nTo properly handle nonelastic collisions, you must scale only the portion of the\nvector from the collision point Pe to the reflected point Pr as shown in Figure 2.2.6,\nsince that is the only portion of the flight that will have been slowed due to the\nimpact. The following equation relies heavily on the earlier equations to determine\nwhat your new slowed point would be.\nIn coordination with this, you would need to multiply any separately stored\nvelocity vector by the same scalar value, or your object will resume its full speed the\nnext frame. In the case of a collision putting your point into another immediate colli-\nsion as discussed earlier, this scale factor should be applied at each pass to simulate the\ndamping effect of multiple bounces in a single frame.\nFIGURE 2.2.6 Calculating a damped reflection vector.\n",
      "page_number": 173,
      "chapter_number": 19,
      "summary": "This chapter covers segment 19 (pages 173-181). Key topics include point, collision, and collisions. Again, test your results when using inline functions or tweaking the compiler\nsettings.",
      "keywords": [
        "Collision Point",
        "Point",
        "collision",
        "Vector",
        "surface",
        "Collision Plane",
        "Plane",
        "surface normal",
        "distance",
        "collision code",
        "collisions",
        "final point",
        "surface point",
        "Plane Tricks",
        "actual collision point"
      ],
      "concepts": [
        "point",
        "collision",
        "collisions",
        "vector",
        "timing",
        "time",
        "surface",
        "figuring",
        "reflecting",
        "reflections"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 1",
          "chapter": 40,
          "title": "Segment 40 (pages 381-388)",
          "relevance_score": 0.65,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 3",
          "chapter": 33,
          "title": "Segment 33 (pages 314-325)",
          "relevance_score": 0.62,
          "method": "sentence_transformers"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 32,
          "title": "Segment 32 (pages 632-651)",
          "relevance_score": 0.62,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 7",
          "chapter": 21,
          "title": "Segment 21 (pages 194-209)",
          "relevance_score": 0.6,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 7",
          "chapter": 22,
          "title": "Segment 22 (pages 210-218)",
          "relevance_score": 0.6,
          "method": "sentence_transformers"
        }
      ]
    },
    {
      "number": 20,
      "title": "Segment 20 (pages 182-197)",
      "start_page": 182,
      "end_page": 197,
      "detection_method": "topic_boundary",
      "content": "2.2 Vector and Plane Tricks \n189\nInterpolation Across a Line or Plane\nAn interesting side note about lines and planes is that a weighted average interpola-\ntion between any set of points occupies the space defined by those points. For\ninstance, starting with a line, you can assign weights to the end points where the\nweights sum to one, and all possible resulting points are on the line defined by\nthe points. Adding another point to build a plane extends the rule so the sum of the\nthree weights must equal one in order for the weighted sum to remain on the plane\ndefined by the three points. Additional points on the plane may be added, and addi-\ntional dimensions may also be added should you have need for a point on an\nn-dimensional plane.\nThis trick is related in a roundabout way to the reason we can often use Ps and Pc\ninterchangeably in several of the previous equations. Either point is sufficient to fill\nthe needs of the plane equation.\nIt's also interesting to note that the individual weights don't need to be between\nzero and one. They just need to all sum up to the value one, which allows the result-\ning point to be outside the line segment or polygon defined by the points while still\nbeing on the extended line or plane.\nSphere-to-Plane Collision\nColliding a ball with a surface is a little bit more complex than colliding a point against\nthe surface. One way to approach it is through ratios. If you draw a line from\nthe start point P± to the line-based collision point Pc of the vector against the plane, die\nball center Ph will be somewhere on that line when the ball begins to intersect the\nplane.\nWhen the ball just touches the surface, we can compare the line from Pf to Pc to\nthe line Pf to Pn to gain the information we need. If you project the first line onto the\nsecond, the ball center is off the surface by exactly the ball radius r on the line Pj to Pn.\nSince the length of that line is known to be Ds, we can get a ratio of how far the ball\nis along the line. This is similar to the way we used a ratio to find the surface collision\npoint Pc. This ratio is the same when applied to the line from P{ to Pc, which leads to\nthe equation:\n(Pe ~ Pi) \nD\nS\nThe equation can be solved for the location of the ball /^, resulting in:\np -p \nV<-Pi*\nPb-lC \n~\n\n\nSection 2 Mathematics\nFIGURE 2.2.7 Colliding with a sphere.\nFigure 2.2.7 shows the relation graphically, indicating where the sphere is in rela-\ntion to the vectors. Care must be taken to notice that the ball does not actually reach\nPc as the ball touches the surface unless the line from Pf to Pc is perpendicular to the\nsurface. As the vector conies closer to being parallel to the plane, the ball will be far-\nther from Pc when it touches the plane.\n\n\n2.3\nFast, Robust Intersection of\n3D Line Segments\nGraham Rhodes, Applied Research Associates\ngrhodes@sed.ara.com\nT\nhe problem of determining the intersection of two line segments comes up from\ntime to time in game development. For example, the line/line intersection prob-\nlem can be beneficial in simple collision detection. Consider two objects in three-\ndimensional space that are moving in time. During a time step or animation frame,\neach object will move from one point to another along a linear path. The simplest\ncheck to see if the objects collide during the time step would be to see how close the\ntwo linear paths come to crossing, and if they are within a certain distance of each\nother (in other words, less than the sum of the radii of bounding spheres of the\nobjects), then process a collision. Other common applications for line segment inter-\nsections include navigation and motion planning (for example, when combined with\nan AI system), map overlay creation, and terrain/visibility estimation.\nThis gem describes a robust, closed form solution for computing the intersection\nbetween two infinite lines or finite-length line segments in three-dimensional space, if\nan intersection exists. When no intersection exists, the algorithm produces the point\nalong each line segment that is closest to the other line, and a vector between the two\nnearest points.\nWhat Makes This Algorithm Robust?\nThe algorithm presented here is robust for a couple of reasons. First, it does not carry\nany special requirements (for example, the line segments must be coplanar). Second,\nit has relatively few instances of tolerance checks. The basic algorithm has only two\ntolerance checks, and these are required mathematically rather than by heuristics.\nThe Problem Statement\nGiven two line segments in three-dimensional space, one that spans between the points\nj4i = [Alx Aiy Alz]r and A2 = [A^ A2y A2z\\T and one that spans between the\npoints Bl = [5lx \nBiy \nBlz\\ rand B2 = [B^ \nB2y \nB2z]T, we would like to find the true\npoint of intersection, P=[PX Py PZ]T, between the two segments, if it exists. \"When\n191\n\n\nSection 2 Mathematics\nFIGURE 2.3.1 Two line segments in three-dimensional space. A) An intersection exists. B)\nNo intersecton.\nno intersection exists, we would like to compromise and find the point on each seg-\nment that is nearest to the other segment. Figure 2.3.1 illustrates the geometry of this\nsituation.\nThe nearest points, labeled C and D respectively, can be used to find the shortest\ndistance between the two segments. This gem focuses on finding the nearest points,\nwhich are identical to the true intersection point when an intersection exists.\nObservations\nBefore delving into how to solve the line intersection problem, it can be useful to\nmake a few observations. What are the challenges to solving the problem correctly?\nConsider an arbitrary, infinite line in space. It is likely that the line will intersect\nan arbitrary plane (if the line is not parallel to the plane, then it intersects the plane);\nhowever, it is unlikely that the line will truly intersect another line (even if two three-\ndimensional lines are not parallel, they do not necessarily intersect). From this obser-\nvation, we can see that no algorithm designed to find only true intersections will be\nrobust, capable of finding a result for an arbitrary pair of lines or line segments, since\nsuch an algorithm will fail most of the time. The need for a robust algorithm justifies\nthe use of an algorithm that finds the nearest points between two lines, within a real-\ntime 3D application such as a game.\nSince every student who has taken a basic planar geometry class has solved for the\nintersection of lines in a two-dimensional space, it is useful to consider the relationship\nbetween the three-dimensional line intersection problem and the two-dimensional\nintersection problem. In two-dimensional space, any two nonparallel lines truly inter-\nsect at one point. To visualize what happens in three-dimensional space, consider a\nplane that contains both defining points of line A, and die first defining point of line\n\n\n2.3 Fast, Robust Intersection of 3D Line Segments \n193\nB. Line A lies within the plane, as does the first defining point of line B. Note that die\npoint of intersection of die two lines lies on die plane, since diat point is contained on\nline A. The point of intersection also lies on line B, and so two points of line B lie\nwidiin die plane. Since two points of line B lie in the plane, the entire line lies in the\nplane.\nThe important conclusion here is diat whenever there is a true intersection of\ntwo lines, those two lines do lie widiin a common plane. Thus, any time two three-\ndimensional lines have a true intersection, the problem is equivalent to a two-\ndimensional intersection problem in die plane diat contains all four of the defining\npoints.\nNaTve Solutions\nA naive, and problematic, solution to die intersection problem is to project the two\nsegments into one of the standard coordinates planes (XY, YZ, or XZ), and then solve\nthe problem in the plane. In terms of implementation, the primary difficulty widi diis\napproach is selecting an appropriate plane to project into. If neither of the line seg-\nments is parallel to any of the coordinate planes, dien the problem can be solved in\nany coordinate plane. However, an unacceptable amount of logic can be required\nwhen one or both segments are parallel to coordinate planes. A variation on diis\napproach, less naive but still problematic, is to form a plane equation from three of\nthe four points, Aly A2, Bl3 and B2, project all four points into the plane, and solve the\nproblem in the plane. In the rare case that there is a true intersection, this latter\napproach produces the correct result.\nOne key feature that is completely lacking from the basic two-dimensional pro-\njected intersection problem is the ability to give a direct indication as to whether a\nthree-dimensional intersection exists. It also doesn't provide the three-dimensional\nnearest points. It is necessary to work backwards to produce diis vital information.\nThe biggest problem with either variation on the projected solution arises when\nthe two lines pass close to one anodier, but do not actually intersect. In this case, the\nsolution obtained in any arbitrary projection plane will not necessarily be the correct\npair of nearest points. The projection will often yield completely wrong results! To\nvisualize this situation (which is difficult to illustrate on a printed page), consider the\nfollowing mind experiment. There are two line segments floating in space. Segment A\nis defined by die points (0, 0, 0) and (1, 0, 0), and segment B is defined by (1, 0, 1)\nand (1, 1, 1). When the lines are viewed from above, equivalent to projecting the lines\ninto the XY plane, the two-dimensional intersection point is (1, 0, 0), and the three-\ndimensional nearest points are (1, 0, 0) and (1, 0, 1). These are the correct nearest\npoints for the problem. However, if those two lines are viewed from different arbitrary\nangles, the two-dimensional intersection point will move to appear anywhere on the\ntwo line segments. Projecting the two-dimensional solution back onto the diree-\nC_^l^_^ \ndimensional lines yields an infinite number of \"nearest\" point pairs, which is clearly\nONTHCCO \nincorrect. The test code provided on the companion CD-ROM is a useful tool to see\n\n\n194 \nSection 2 Mathematics\nthis problem, as it allows you to rotate the view to see two line segments from differ-\nent viewing angles, and displays the three-dimensional nearest points that you can\ncompare to the intersection point seen in the viewport.\nIn the next section, I derive a closed-form solution to the calculation of points C\nand D that does not make any assumptions about where the two line segments lie in\nspace. The solution does handle two special cases, but these cases are unavoidable\neven in the alternative approaches.\nDerivation of Closed-Form Solution Equations\nCalculating the Nearest Points on Two Infinite Lines\nThe equation of a line in three-dimensional space can be considered a vector function\nof a single scalar value, a parameter. To derive a closed-form solution to the nearest-\npoint between two 3D lines, we first write the equation for an arbitrary point,\nC = [Cx \nCy \nCJr, located on the first line segment, as Equation 2.3.1.\nC = Al+sLA, where LA = (A2 - 4) \n(2.3.1)\nNotice that Equation 2.3.1 basically says that the coordinates of any point on the\nfirst segment are equal to the coordinates of the first defining point plus an arbitrary\nscalar parameter s times a vector pointing along the line from the first defining point\nto the second defining point. If s is equal to zero, the coordinate is coincident with the\nfirst defining point, and if s is equal to 1, the coordinate is coincident with the second\ndefining point. We can write a similar equation for an arbitrary point, D = [Dx Dy\nDJT, located on the second line segment, as Equation 2.3.2:\nD = 5; + tLB, where LB = #, - B \n(2.3.2)\nHere, t is a second arbitrary scalar parameter, with the same physical meaning as s\nwith respect to the second line segment. If the parameters s and t are allowed to be\narbitrary, then we will be able to calculate points C and D as they apply to infinite\nlines rather than finite segments. For any point on a. finite line segment, the parame-\nters s and t will satisfy 0 < s,t < 1 . We'll allow s and t to float arbitrarily for now, and\ntreat the finite length segments later.\nThe two 3D line segments intersect if we can find values of s and t such that\npoints C and D are coincident. For a general problem, there will rarely be an intersec-\ntion, however, and we require a method for determining s and t that corresponds to\nthe nearest points C and D. The remainder of the derivation shows how to solve for\nthese values of; and t.\nFirst, subtract Equation 2.3.2 from Equation 2.3.1 to obtain the following equa-\ntion for the vector between points C and D:\n\n\n2.3 Fast, Robust Intersection of 3D Line Segments\n195\nC-D = -AB + sLA - tLB = [o 0 OJr\nwhere AB = Bl - Al\n(2.3.3)\nHere, since we would like for points C and D to be coincident, we set the vector\nbetween the points to be the zero vector. The right side of Equation 2.3.3 can then be\nrepresented by the following matrk equation:\ns*\nLA. -L,\nABy\nAB.\n(2.3.4)\nThere are three rows in Equation 2.3.4, one for each coordinate direction, but\nonly two unknowns, the scalar values s and t. This is a classic over-determined or\nunder-constrained system. The only way there can be an exact solution is if the coef-\nficient matrix on the left side turns out to have rank 2, in which case the three equa-\ntions are equivalent to just two independent equations, leading to an exact solution\nfor s and t. Geometrically, when there is an exact solution, the two lines have a true\nintersection and are coplanar. Thus, two arbitrary lines in three-dimensional space\ncan only have a true intersection when the lines are coplanar.\nThe difference between the left side and right side of Equation 2.3.4 is equal to\nthe vector representing the distance between C and D. It is also the error vector of\nEquation 2.3.4 for any arbitrary values of s and t. We determine the nearest points by\nminimizing the length of this vector over all possible values of s and t.\nThe values of s and t that minimize the distance between C and D correspond to\na linear least-squares solution to Equation 2.3.4. Geometrically, the least-squares solu-\ntion produces the points C and D. When we have the case of the segments being\ncoplanar but not parallel, then the algorithm will naturally produce the true intersec-\ntion point. Equation 2.3.4 can be written in the form:\nM? = b, where 7 = I s \nt\\\n(2.3.5)\nOne method for finding the least-squares solution to an over-determined system\nis to solve the normal equations instead of the original system [Golub96]. The normal\nequations approach is suitable for this problem, but can be problematic for general\nproblems involving systems of linear equations. We generate the normal equations by\npremultiplying the left side and right side by the transpose of the coefficient matrk\nM. The normal equations for our problem are shown as Equation 2.3.6.\nMTM? = MT£ , where Mris the transpose of M.\n(2.3.6)\n\n\n196\nSection 2 Mathematics\nEquation 2.3.6 has the desired property of reducing the system to the solution of\na system of two equations, exactly the number needed to solve algebraically for values\nof / and t. Let's carry through the development of the normal equations for Equation\n2.3.4. Expanding according to Equation 2.3.6 , the normal equations are:\nLAX \nLAy \nL^\n~~JLiD., \n~~\"-L>O,. \n-t-'D™\n~L\nBy\n-Ax\n-Ay\n-Az\nLBz\nABX\nABy\nAB.\n(2.3.7)\nCarrying through the matrix algebra:\nLA \n-LA\n\\-LA-LB\n-LS-AB_\n(2.3.8)\nOr, simplifying by defining a series of new scalar variables:\n(2.3.9)\nThis is a simple 2x2 system, and to complete this section we will solve it alge-\nbraically to form a closed-form solution for s and t. There are a number of ways to\nsolve Equation 2.3.9, including Cramer's rule [O'Neil87] and Gaussian elimination\n[Golub96]. Cramer's rule is theoretically interesting, but expensive, requiring approx-\nimately («+!)! multiply and divide operations for a general-sized problem. Gaussian\nelimination is less expensive, requiring «3/3 multiply and divide operations. There are\nother approaches to solving systems of linear equations that are significantly more\nreliable and often faster for much larger systems, including advanced direct solution\nmethods such as QR factorizations for moderate-sized systems, and iterative methods\nfor very large and sparse systems. I will derive the solution using Gaussian elimina-\ntion, which is slightly less expensive than Cramer's rule for the 2x2 system. Here, we\nperform one row elimination step to yield an upper triangular system. The row elim-\nination step is as follows. Modify row 2 of Equation 2.3.9 by taking the original row\n2 and subtracting row 1 times Ll2/Ln. to yield Equation 2.3.10.\nA,\nAa\nAi j \nAa \nAa T\nMI \nAi\nrn -\nAa\nAi\n(2.3.10)\nSimplify Equation 2.3.10 and multiply the new row 2 by Lu to yield the upper\ntriangular system shown in Equation 2.3.11.\n\n\n2.3 Fast, Robust Intersection of 3D Line Segments \n197\ni;K \\ 1\n*• I \nI / \n*• \n/ \nr \n\\\nl/J \nL^ifB \nMl^J\nAl \n^ . 1 * 1 = 1 \n'^ \nI \n(2-3.11)\no AiA2-A2\n2\nEquation (2.3.11) immediately yields a solution for t,\nt = AI^B ~ LUTA \n(2.3.12)\n*i 1-^22 ~~ A£\nand then, for 5,\ns = TA ~ Lnt \n(2.3.13)\nAi\nIt is important to note that Equations 2.3.12 and 2.3.13 fail in certain degenerate\ncases, and it is these degenerate cases that require that we use tolerances in a limited\nway. Equation 2.3.13 will fail if line segment A has zero length, and Equation 2.3.12\nwill fail if either line segment has zero length or if the line segments are parallel. These\nsituations lead to a divide-by-zero exception. I provide more discussion later in the\nsection titled Special Cases.\nIn terms of computational expense for the 2x2 problem, the only difference\nbetween solving for s and t using Gaussian elimination and Cramer's rule, for this\ncase, is that the computation of s requires one multiply, one divide, and one subtrac-\ntion for Gaussian elimination, but four multiplies, one divide, and two subtractions\nfor Cramer's rule.\nTo summarize from the derivation, given line segment A from point Al to A2 and\nline segment B from point Bl to B2, define the following intermediate variables:\nLA = (A, - 4); ls = (B2 -B,)- ~AB = BI-AI \n(2.3.14)\nand\n•HI = ^A • LA; \nL22 = LB • LB; \nZ^ = — LA • LB\nCompute the parameters ^ and t that define the nearest points as,\nt = LU}\"B ~ ^2[A \n(2.3.16)\nAiAi ~ Ai\nand\ns =\n(2.3.17)\n\n\n198 \nSection 2 Mathematics\nThe point where the first segment comes closest to the second segment is then\ngiven by:\nC = AL+ sLA \n(2.3.18)\nand the point where the second segment comes closest to the first segment is\ngiven by:\n£> = #!+ tLB \n(2.3.19)\nWe can consider a point located halfway between the two nearest points to be the\nsingle point in space that is \"nearest\" to both lines/segments as:\nP = (C + D)/2 \n(2.3.20)\nOf course, when the lines do intersect, point P will be the intersection point.\nSpecial Cases\nWhen we talk about the nearest points of two infinite lines in space, there are only\ntwo possible special cases. The first case occurs when one or both lines are degenerate,\ndefined by two points that are coincident in space. This occurs when point A^ is coin-\ncident with A2, or when B\\ is coincident with B2. We'll call this the degenerate line spe-\ncial case. The second case occurs when the two lines are parallel, called $\\<z parallel tine\nspecial case.\nIt is easy to relate the degenerate line special case to the equations developed pre-\nviously. Note that variable Ln, defined in Equation 2.3.15, is equal to the square of\nthe length of line segment A, and L22 is equal to the square of the length of segment\nB. If either of these terms is zero, indicating that a line is degenerate, then the deter-\nminant of the matrix in Equation 2.3.9 is zero, and we cannot find a solution for s\nand t. Note that when either Ln or L22 is zero, then L12 is also zero.\nOne standard test to check and decide if line A is degenerate is the following,\nbool line_is_degenerate = Ln < e2 ? true : false;\nHere, e is a small number such as perhaps 10\"6. It is wiser to choose a value for £\nsuch as 10\"6 rather than a much smaller number such as machine epsilon.\nWhen segments A and B are both degenerate, then point C can be selected to be\nequal to point A, and point D can be selected to be equal to point B^. When segment\nA alone is degenerate, then point Cis equal to A\\> and point D is found by computing\nthe point on segment B that is nearest to point C. This involves computing a value for\nparameter tonly, from Equation 2.3.21.\n-LBt = AB \n(2.3.21)\n\n\n2.3 Fast, Robust Intersection of 3D Line Segments \n199\nEquation 2.3.21 is a simplification of Equation 2.3.4 for the case where segment\nA is degenerate, and again it requires that we find a least-squares solution. The least-\nsquares solution, shown here using normal equations without derivation, is:\n(2.3.22)\nPoint D can be calculated using Equation 2.3.2.\nWhen segment B alone is degenerate, then point D is set equal to B\\, and point C\nis found by computing the point on segment A that is nearest to point D. This\ninvolves computing a value for parameter s only, from Equation 2.3.23, which is anal-\nogous to Equation 2.3.21.\nLA* = AB \n(2-3.23)\nSolving for s yields:\ns = -p- \n(2.3.24)\nAi\nNote that Equation 2.3.24 is identical to Equation 2.3.13 with fset equal to zero.\nSince t equals zero at point Blt our derivation here is consistent with the derivation for\nnondegenerate lines.\nCertainly, a nice way to handle the cases where only one segment is degenerate is\nto write a single subroutine that is used both when segment A alone is degenerate and\nwhen B alone is degenerate. It is possible to do this using either Equation 2.3.22 or\nEquation 2.3.24, as long as the variables are treated properly. The implementation\n(^CBj5| \nprovided on the companion CD-ROM uses Equation 2.3.24 for both cases, with\nmm a \nparameters passed in such that the degenerate line is always treated as segment B, and\nthe nondegenerate line is always treated as segment A.\nIt is also easy to relate die parallel line special case to the equations developed pre-\nviously, although it is not quite as obvious as the degenerate case. Here, we have\nto remember that L12 is the negative dot product of the vectors LA and LB, and\nwhen the lines are parallel, the dot product is equal to the negative of the length of LA\ntimes the length of LB. The determinant of the matrix in Equation 2.3-9 is given by\nLnL22 - Lu, and this is equal to zero when L12 is equal in magnitude to the length of\nLA times the length of LB. Thus, when the line segments are parallel, Equation 2.3.9\nis singular and we cannot solve for s and t.\nIn the case of infinite parallel lines, every point on line A is equidistant from line\nB. If it is important to find the distance between lines A and B, simply choose C to be\nequal to Alt and then use Equations 2.3.22 and 2.3.2 to find D. Then, the distance\nbetween C and D is the distance between the two segments. We'll look at how to han-\ndle finite length segments in the next section.\n\n\n200 \nSection 2 Mathematics\nCoding Efficiency\nFor coding efficiency, you should check first for degenerate lines, and then for parallel\nlines. This approach eliminates the need to calculate some of the convenience\nvariables from Equations 2.3.14 and 2.3.15 when one or both of the lines are degen-\nerate.\nDealing with Finite Line Segments\nThe previous two sections treated infinite lines. This is useful; however, there are per-\nhaps many more situations in game development when it is required to process finite\nline segments. So, how do we adjust the results shown previously to deal with finite-\nlength line segments?\nLine Segments that Are Not Parallel\nIf Equations 2.3.12 and 2.3.13 generate values of s and t that are both within the\nrange [0,1], then we don't need to do anything at all, since the finite length line seg-\nment results happen to be identical to the infinite line results. Whenever one or both\nof s and rare outside of [0,1], then we have to adjust the results. For nonparallel lines,\nthere are two possibilities: 1) s or t is outside of [0,1 ] and the other is inside [0,1]; and\n2) both s and rare outside of [0,1]. Figure 2.3.2 illustrates these two cases.\nFor the case when just one of s or t is outside of [0,1], as in Figure 2.3.2a, all we\nneed to do is:\n1. Clamp the out-of-range parameter to [0,1].\n2. Compute the point on the line for the new parameter. This is the nearest\npoint for the first segment.\n3. Find the point on the other line that is nearest to the new point on the first\nline, with the nearest point calculation performed for a finite line segment.\nThis is the nearest point for the second segment.\nIn the last step, just clamp the value from Equation 2.3.22 to [0,1] before calcu-\nlating the point on the other segment.\nFor the case when both s and t are outside of [0,1], as in Figure 2.3.2b, the situa-\ntion is slightly more complicated. The process is exactly the same except that we have\nto make a decision about which segment to use in the previous process. For example,\nif we selected line segment^ in Figure 2.3.2b, step 2 would produce point A2. Then,\nstep 3 would produce point 5ls the nearest point on segment B to point A2. The pair\nof points, A2 and BI clear jv are not the correct points to choose for Cand D. Point Bl\nis the correct choice for D, but there is a point on segment A that is much closer to\nsegment B than A2. In fact, the point generated by step 3 will always be the correct\nchoice for either C or D. It is the point from step 2 that is incorrect. We can compute\nthe other nearest point by just using the result from step 3. The process for both s and\nt outside of [0,1] then becomes:\n\n\n2.3 Fast, Robust Intersection of 3D Line Segments \n201\nInfinite Line Result\nInfinite Line Result \n„ \n_.£__ \n,\n\"2 \n, \n1\nB7\n \nB2\nFinite Line Result\nFinite Line Result\n0 \n-I.......Q\nFIGURE 2.3.2 Finite-length line segments. A) Either sortis outside of[0,1]. B) Both s\nand t are outside of[0,1].\n1. Choose a segment and clamp its out-of-range parameter to [0,1].\n2. Compute the point on the line for the new parameter. This is not guaran-\nteed to be the nearest point for the first segment!\n3. Find the point on the other line that is nearest to the new point on the first\nline, with the nearest point calculation performed for a finite line segment.\nThis is the nearest point for the second line segment.\n4. Find the point on the first line segment that is nearest to the point that\nresulted from step 3. This is the nearest point for the first line segment.\nIf we select segment B in Figure 2.3.2b as our initial segment to correct, we would\nimmediately select point 5;, and step 3 would give the point between Al and A2. In\nthis case, step 4 is not required. The implementation provided here does not bother to\ncheck for this situation.\nLine Segments that Are Parallel\nThere are two basic possible scenarios when the two segments are parallel, both of\nwhich are illustrated in Figure 2.3.3. First, there might be a single unique pair of near-\nest points, shown in Figure 2.3.3a. This always occurs when the projection of both\nsegments into a line parallel to both do not overlap. Second, there might be a locus of\npossible nearest point pairs, shown in Figure 2.3.3b. Here, we could choose the two\n^*-^5 \nnearest points to be any pair of nearest points between the two vertical gray lines. The\nON me co \nimplementation provided on the accompanying CD-ROM selects the nearest points\nfor finite length, overlapping parallel line segments to be halfway between the gray\nlines; that is, at the midpoint of the overlapping portion of each segment.\nIt is important to note that when the two segments are parallel, or almost parallel,\nthe nearest points computed by this algorithm will often move erratically as the lines\n\n\nSection 2 \nMathematics\nA \nB\nFIGURE 2.3.3 Parallel line segments. A) Unique nearest point pair. B) Locus of nearest\npointpairs.\nare rotated slightly. The algorithm will not fail in this case, but the results can be con-\nfusing and problematic, as the nearest points jump back and forth between the ends\nof the segments. This is illustrated in Figure 2.3.4.\nShown in Figure 2.3.4a, the nearest points will stay at the far left until the lines\nbecome exactly parallel, at which point the nearest points will jump to the middle of\nthe overlap section. Then, as the lines continue to rotate past parallel, the nearest\npoints will jump to the far right, shown in Figure 2.3.4b. This behavior may be prob-\nlematic in some game applications. It is possible to treat the behavior by using a dif-\nferent approach to selecting the nearest point when lines are parallel or near parallel.\nFor example, you could implement a rule that arbitrarily selects the point nearest A\\\nas the nearest point on segment A when the segments are parallel within, say, 5\ndegrees of each other. To avoid the erratic behavior at the 5-degree boundary, you\nwould need to blend this arbitrary nearest point with an algorithmically generated\nnearest point between, say, 5 and 10 degrees, with the arbitrary solution being 100%\nat 5 degrees and 0% at 10 degrees. This solution will increase the expense of the algo-\nrithm. There are certainly other approaches, including ones that may be simpler,\ncheaper, and more reliable. The implementation provided on the companion CD-\n*'**\"* \nROM does not attempt to manage this behavior.\nA \nB\nFIGURE 2.3.4 Erratic movement of nearest points for nearly parallel line segments. A)\nNearest points at the left. B) Nearest points at the right.\nImplementation Description\nThe implementation includes four C-language functions, contained in the files\nlineintersect_utils.h and lineintersect_utils.cpp. The primary interface is the function\nIntersectLineSegments, which takes parameters defining the two line segments, and\nreturns points C, D, and P, as well as a vector between points Cand D. The function\n\n\n2.3 Fast, Robust Intersection of 3D Line Segments \n203\nalso takes a parameter indicating whether you want the line segments to be treated as\ninfinite lines, and a tolerance parameter to be used to check the degenerate and paral-\nlel line special cases. The vector between C and D can be used outside of the imple-\nmentation to determine a distance between the lines. It is important to note that the\nvector is not necessarily normal to either of the line segments if the lines are finite. If\nthe lines are infinite and at least one is not degenerate, the vector will be normal to the\nnondegenerate line(s). The supporting functions are as follows:\n• FindNearestPointOnLineSegment calculates the point on a line segment that is\nnearest to a given point in three-dimensional space.\n• FindNearestPointOjParallelLineSegments calculates representative (and possibly\nunique) values for Cand D for the case of parallel lines/segments.\n• AdjustNearestPoints adjusts the values of C and D from an infinite line solution to\na finite length line segment solution.\nThe code is documented with references to the text.\n,,— -,„ \nA test program is also provided, called line_intersection_demo. The demo requires\n^-ll-^ \nthat you link to the GLUT library for OpenGL. Project files are present for Microsoft\nVisual C++ 6.0 for Windows. It should not be too difficult to port this to other sys-\ntems that support OpenGL and GLUT.\nOpportunities to Optimize\nThe implementation source code was written carefully, but without any attempt to\noptimize for a particular processor or instruction set. There are a number of opportu-\nnities in every code to optimize the implementation for a given platform. In this case,\nperhaps the biggest opportunity is in the area of vectorization. There are numerous\noperations in this code that require a multiply or addition/subtraction operation on\nall three elements of a vector. These are prime opportunities to vectorize. Addition-\nally, if you have an instruction set that supports high-level operations such as dot\nproducts, take advantage when evaluating Equation (2.3.15), for example. To truly\nmaximize the performance, I strongly recommend that you use a professional code\nprofiling utility to identify bottlenecks and opportunities for your target platform(s).\nI i§£% \nThe text presented here and the implementation provided on the accompanying\nONWCD \nCD-ROM is rigorous, and treats every conceivable situation. The code is generally\nefficient, but in the case where the infinite lines intersect outside of the range of the\nfinite segments (in other words, one or both ofs and t are outside of [0,1]), the true\nnearest points are not necessarily cheap to compute. In fact, the nearest point problem\nwe've solved here is a minimization problem, and as is the case in general, the cost\nincreases when constraints are applied to minimization problems. Beyond proces-\nsor/platform-specific optimizations, it is certainly possible to remove parts of the\nimplementation that are not required for your application. For example, if you do not\nneed to treat finite length segments, remove everything that deals with finite length\n\n\n204 \nSection 2 Mathematics\nsegments. Just have the main function return a bool that is true when the nearest\npoint is found between the finite segment endpoints, and false when the nearest point\nis found outside the finite segment endpoints.\nConclusions\nThe algorithm discussed here is rigorous and capable of handling any line intersection\nproblem without failing. Depending on your particular use of line intersections, you\nmay need to adjust the algorithm; for example, to manage the idiosyncrasies that arise\nwhen two finite segments are nearly parallel, or to remove the processing of finite seg-\nments when you only deal with infinite lines. I sincerely hope that some of you will\nbenefit from this formal discussion of line and line segment intersections, along with\nready-to-use source code.\nReferences\n[Golub96] Golub, Gene H., and Charles F. van Loan, Matrix Computations, Third\nEdition, The Johns Hopkins University Press, 1996.\n[O'Neil87] O'Neil, Peter V., Advanced Engineering Mathematics, Second Edition,\nWadsworth Publishing Company, 1987.\n",
      "page_number": 182,
      "chapter_number": 20,
      "summary": "This chapter covers segment 20 (pages 182-197). Key topics include points, equations, and equation.",
      "keywords": [
        "Line Segments",
        "Line",
        "point",
        "nearest points",
        "equation",
        "segment",
        "Segments",
        "parallel line segments",
        "finite line segment",
        "nearest",
        "line intersection problem",
        "line segment intersections",
        "Intersection",
        "equations",
        "line intersection"
      ],
      "concepts": [
        "points",
        "equations",
        "equation",
        "line",
        "segment",
        "segments",
        "plane",
        "solution",
        "solutions",
        "intersect"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 7",
          "chapter": 20,
          "title": "Segment 20 (pages 181-193)",
          "relevance_score": 0.55,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 1",
          "chapter": 30,
          "title": "Segment 30 (pages 279-290)",
          "relevance_score": 0.52,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 3",
          "chapter": 16,
          "title": "Segment 16 (pages 156-165)",
          "relevance_score": 0.5,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 3",
          "chapter": 32,
          "title": "Segment 32 (pages 296-313)",
          "relevance_score": 0.5,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 3",
          "chapter": 36,
          "title": "Segment 36 (pages 347-355)",
          "relevance_score": 0.49,
          "method": "sentence_transformers"
        }
      ]
    },
    {
      "number": 21,
      "title": "Segment 21 (pages 198-206)",
      "start_page": 198,
      "end_page": 206,
      "detection_method": "topic_boundary",
      "content": "2.4\nInverse Trajectory\nDetermination\nAaron Nicholls, Microsoft\naaron feedback@hotmail.com\nA\nproblem frequently faced in the development of games is that of calculating tra-\njectories. In the most common case, we have a velocity and a direction for a pro-\njectile, and need to determine the location at a given time, and whether the projectile\nhas collided with any other entities. This is a simple iterative problem, but it is not all\nthat is required for most games. In many cases, we also need to solve the inverse of this\nproblem; namely, given a number of constants (gravity, starting position, intended\ndestination), we must calculate the proper yaw, pitch, and/or initial velocity to propel\nthe projectile between the two points. In addition, once we have a solution for this\nproblem, we can use this as a framework for solving more complex variants of the\nsame problem.\nThis gem expects that the reader is familiar with fundamental 2D/3D transfor-\nmations, basic integral calculus, and trigonometry.\nSimplifying the Problem at Hand\nThere are several ways to simplify the problem, and we can begin by reducing a three-\ndimensional problem to a two-dimensional one. Given an initial velocity and direc-\ntion for a projectile, if the only acting force is gravity (which can usually be assumed\nto be constant), the trajectory of the projectile will be parabolic and planar. Therefore,\nby transforming this planar trajectory into two dimensions (x and_y), we can simplify\nthe problem significantly. In addition, by translating the starting point to the origin,\nwe can remove the initial x and y values from most of the equations, focusing on the\ndestination coordinates. A sample trajectory, rotated into the xy plane and translated\nto the origin, is shown in Figure 2.4.1.\nIn addition, we need to determine exactly what the problem is that we wish to\nsolve. In this case, our variables are initial velocity, angle of elevation, and distance in\nx and y between the points. In the case where we know three of the four values (and\nthus have one unknown), our goal is to produce an equation that defines the value of\nthe unknown in terms of the three known values.\n205\n\n\n206\nSection 2 Mathematics\nSource\nDestination (x, y)\nv, = Vj cos 6\nFIGURE 2.4.1 Trajectory between two points in two dimensions.\nHowever, it is very common to have to deal with multiple unknowns. In that\ncase, the best solution is typically to get rid of some of the variables by setting their\nvalues to constants. For instance, we often know the locations of the two points, but\nneed to provide an initial velocity and angle of elevation. In this case, we can elimi-\nnate initial velocity as a variable by setting it to the maximum possible velocity vmac\nBy doing so, we only have one unknown, and we simply need to determine the angle\nof elevation 6 in terms of v ,-, x, and y. This technique and guidelines for using it are\ndiscussed in further detail later in this gem, under Solving for Multiple Variables.\nDefining Position and Velocity as a Function of Time\nNow that we have reduced the problem to two dimensions, we can identify the veloc-\nity and acceleration working in each dimension. Starting with initial velocity vf, angle\nof elevation ?, and gravity g, we can express initial velocity along the x and y axes as\nfollows:\nvyi = Vf sinO\nSince the only force acting upon this system is gravity, we can assume that verti-\ncal velocity (v,) stays constant, while gravity is acting upon horizontal velocity (vy).\nThe two can be expressed as follows:\nvx = v{ cosO \n(2.4.1)\nv = v/ sin 0 — gt\n(2.4.2)\nNext, we integrate the velocity equations to determine the position at a given\ntime (assuming the origin as the starting point).\n\n\n2.4 Inverse Trajectory Determination \n207\nx = \\vt cos 9 dt\n-> x = vf cos 9 \n(2.4.3)\ny = J (»,- sin 0- gt]dt\ny = vf sin 0 \n£t2 \n(2.4.4)\nA Special Case:\nBoth Points at the Same Elevation\nBefore tackling the general case of this problem, let's examine a simpler case, which\nwill give us insight into solving the more general problem. One of the common spe-\ncial cases is that in which both the start and end points have the same y value. An\nexample of this might be a game where the ground is flat, and a cannon on the ground\nis firing at a ground target. In this case, we know that y, the horizontal displacement\nbetween the two points, is zero. Therefore, we can simplify the horizontal position\nequation by setting y=0. This allows us to simplify Equation 2.4.4 to solve for time t,\ninitial velocity vt, or angle of elevation 9 as follows:\ny = vf sin 9 -- gf2 =0\n2v • sin 6\n-> t = — '- -\ng\nFt\n-» V; = —& -\n2 sin 0\nIn addition, this leads to a simplified formula for calculating x for this special case:\ni\nx = v\\ — '- - - cos0\nI \ng \n)\n2v sin 9 cos 9\nx = — \n'- -\ng\n\n\n208 \nSection 2 Mathematics\nUsing the trigonometric identity sin 9 cos 0 = sin 29, we can simplify further as\nfollows:\n2v; sin 29 \n. . .\nx = —'- \n(2.4.5)\ng\nIn addition, in the previous case where a ground-based cannon is firing at ground\ntargets on flat terrain, this equation can be used to determine the maximum horizon-\ntal range of a cannon at angle of elevation 0, given maximum projectile velocity v^:\nRange =\n,2sin29\ng\n(2.4.6)\nSolving for Angle of Elevation\nNow that we have defined the equations that define the projectile's movement and\nsolved for a special case, we can continue to solve for the more general case. First, we\nwill analyze the case in which both points may not be at the same altitude, and\nwe must determine the angle of elevation or velocity required to propel a projectile\nbetween the two points. Since we have expressed x and y in terms of t, we can begin\nby removing t from the equation and defining x and^ in terms of each other.\nn \nX\nx = v-t cos 9 —» t = vf cos 9\nNext, we replace t with x I v, cos 9 in the equation for y to remove t from the\nequation.\ny = vitsm9--gt2\ni vf cos 9\n-> y = x tan 9 -- —\n2vf cos2 9\nWe then use the trigonometry identity I/cos2 9 = tan2 9 + 1 to reduce further.\n\") \nT \n'\n2v \ncos2 9\n\n\n2.4 Inverse Trajectory Determination\n209\n. \nme2 (tan2 0 + 1)\ny = x tan 0 - &—\n2V;\nxtan0\ny = 0\n(2.4.7)\nAs odd as this final equation may look, it serves a purpose: this version of the\nequation fits into the quadratic equation as follows:\ntan0 =\nwhere\n-b ± V£2 - 4ac\n2a\nPlugging the preceding values of a, b, and c into the quadratic equation and solv-\ning for 9, we obtain the following:\n6 = tan\n,\n-x±\ns\nV-\ny\n-> 9 = tan\n-x±\nV;\n•\\\\\n(2.4.8)\n\n\n210\nSection 2 Mathematics\nThe quadratic form provides us with a way to solve for G, given a known initial\nvelocity vf, horizontal displacement x, and vertical displacement y. If (b2 - 4ac) is\npositive, we have two possible solutions, and if it is negative, there are no solutions for\nthe given parameters. In addition, if the initial velocity is zero, we know that the tra-\njectory is entirely vertical, so 6 is irrelevant.\nWhen dealing with two trajectories, it is important to remember that the flatter\ntrajectory will yield a faster route to the target, and is thereby preferable in most cases.\nIf both angles are between -7C/2 and 7t/2, the angle closer to zero will yield the flatter\ntrajectory for a given vf. A case with two valid angles of elevation to reach a given tar-\nget is shown in Figure 2.4.2. Here, Trajectory 2 is the fastest.\nTrajectory 1\nSource\nTrajectory 2\nDestination (x, y)\nFIGURE 2.4.2 Two angle of elevation solutions OC and§ for a given Vj.\nSolving for Initial Velocity\nNow that we have the problem solved for the case where 0 is unknown, we can change\nEquation 2.4.7 slightly to solve for initial velocity vt, given a known angle of elevation\n9, horizontal displacement x, and vertical displacement y as follows:\n2 \n_ 2\n2\n- tan 9 - x tan 0 + &— + 7 = 0\n2vs\n2v:\n6 + £—r = x tan 6 - y\n-> ^-(tan2 0 + 1) = xtanfl - y\n2v\nWe then multiply both sides by V; /(x tan Q -y), thereby isolating initial velocity.\n\n\n2.4 Inverse Trajectory Determination \n211\n-(tan20\n2(x tan 9 -\nSolving for vf, we get the following:\n— y)\nAgain, we can choose to use the trigonometric identity I/cos2 6 = fan2 6 + 1 to\nsimplify the square root.\n(2A10)\nAgain, since we are dealing with a square root, there are some cases that have no\nsolution. An example would be when the slope of the initial trajectory is less than the\nslope to the target. One special case is where 6=n/2 (straight upward), since there can\nbe two solutions.\nCalculating Maximum Height for a Trajectory\nSolving for peak height of a trajectory is straightforward: vertical peak is defined as\nthe point where vertical velocity vy=0, given 9>0. Therefore, we simply solve the ver-\ntical velocity equation as follows:\nvy(t) = vi sin0 - gt = 0\nSolving for t, we get the following:\nv sin 6\ng\nNow, to determine the maximum altitude, we substitute the preceding value for t\nin the vertical position equation as follows:\n-\nv] sin2 9 \ng\\vi sin 9 |\nv] sin2 9\n— - - \n(2.4.11)\n\n\n212 \nSection 2 Mathematics\nAs mentioned previously, this depends on &>0. If the angle of elevation 6 is neg-\native (pointing downward), the vertical peak will be a.ty=0, since the projectile's initial\ndownward velocity is only increased by gravity. This is somewhat of a special case,\nsince vertical velocity is not necessarily zero at the vertical peak in this case.\nCalculating Flight Time\nIn order to determine time to destination, we can simply rewrite the horizontal posi-\ntion from Equation 2.4.3 in terms of?.\nx(t) = vf cos 6 —» t = vi cos d\nHowever, in the case where v^ = 0 or cos 6 = 0, t is undefined if expressed in terms\nof x In addition, in this case, x will always be zero, and no solutions exist in this case\nif the two points are not at the same x value. In implementation, these boundary cases\nare worth testing, since a mistake here can cause an engine to crash or behave errati-\ncally at times.\nTo solve for t when vt = 0 or cos 6 = 0, we can use the vertical position equation\nfrom Equation 2.4.4 instead.\ny(t) = vf sin 0 - - gt2\nIf Vi = 0, we can use the following equation to express t in terms of/ and g.\ny - — & -> t =\ni\nHowever, if cos 6 = 0 and v{>0, there can be one or two solutions (the latter hap-\npens only ifd>0, since vf >0 in practice). In addition, we know that if cos 6 = 0, sin 6\n= ±1. This reduces the problem further, but we still need to express this in terms of t\nas follows:\ny = vitsine--gt2\n-> - gt2 - Vft sin 6 + y = 0 \n(2.4.12)\nThis is a quadratic in terms of t, and the solution thereof is left to the reader.\nSolving for Multiple Variables\nAs mentioned near the start of this topic, it is very common that two or more values\nare unknown or need to be determined, usually 9 and vf (since both points are usually\n\n\n2.4 Inverse Trajectory Determination \n213\nknown). In multivariate cases, the set of possible solutions expands greatly, so in order\nto solve the problem, the fastest approach is to eliminate some of the unknowns. In\nthe most common case, we are given two points and a maximum initial velocity vmax,\nand need to solve for both v-t and G.\nWhen reducing variables in order to simplify to a single-variable problem, it is\nimportant to reduce in a manner that does not overly restrict possible solutions. In the\nprevious case in which both 6 and vt are unknown, restricting 6 greatly reduces the\nnumber of solutions, and is undesirable. On the other hand, setting vf = vmax and\nvarying 6 preserves a larger set of landing points. This same logic can be extended to\nother forms of this problem, although there is not space to elaborate further within\nthe scope of this gem.\nOptimizing Implementation\nWhen implementing the previous equations in code, there are a few optimizations\nthat can make a substantial difference in performance. This is because trigonometric\nfunctions have a very high overhead on most systems.\nAvoid Oversimplification\nWhen deriving mathematical calculations, there is a tendency to reduce formulae to\ntheir simplest mathematical form, rather than the simplest or most optimal algo-\nrithm. For instance, in solving for initial velocity vf, we came across Equations 2.4.9\nand 2.4.10 as follows:\nv- = x\nx \n£\nThe tendency from a mathematical point of view would be to prefer the latter\nform, since it reduces the equation; however, in implementation, it is more efficient to\nprecalculate tan 9 and use it twice in the first equation, rather than calculating both\ntan 9 and cos 9 as is done in the latter formula. In addition, even if we choose to use\nthe second equation (and not simplify to terms of tan Q), leaving cos 9 outside of the\nsquare root bracket means that two divisions need to be done: one inside the bracket\nand one outside. To optimize, one can either place the cos 9 inside the divisor within\nthe bracket as cos2 9, or multiply x by II cos 9.\n",
      "page_number": 198,
      "chapter_number": 21,
      "summary": "This chapter covers segment 21 (pages 198-206). Key topics include velocity, equations, and equation. In this case, our variables are initial velocity, angle of elevation, and distance in\nx and y between the points.",
      "keywords": [
        "initial velocity",
        "velocity",
        "case",
        "Inverse Trajectory Determination",
        "equation",
        "Trajectory",
        "problem",
        "initial",
        "angle of elevation",
        "cos",
        "Inverse Trajectory",
        "sin",
        "points",
        "Trajectory Determination",
        "elevation"
      ],
      "concepts": [
        "velocity",
        "equations",
        "equation",
        "cos",
        "trajectory",
        "trajectories",
        "case",
        "sin",
        "problem",
        "tan"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 8",
          "chapter": 18,
          "title": "Segment 18 (pages 172-180)",
          "relevance_score": 0.56,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 1",
          "chapter": 16,
          "title": "Segment 16 (pages 140-149)",
          "relevance_score": 0.43,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 14,
          "title": "Segment 14 (pages 129-138)",
          "relevance_score": 0.42,
          "method": "sentence_transformers"
        },
        {
          "book": "makinggames",
          "chapter": 24,
          "title": "Segment 24 (pages 213-221)",
          "relevance_score": 0.4,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 1",
          "chapter": 23,
          "title": "Segment 23 (pages 205-212)",
          "relevance_score": 0.39,
          "method": "sentence_transformers"
        }
      ]
    },
    {
      "number": 22,
      "title": "Segment 22 (pages 207-219)",
      "start_page": 207,
      "end_page": 219,
      "detection_method": "topic_boundary",
      "content": "214 \nSection 2 Mathematics\nReduce Trigonometric Functions to\nSimpler Calculations\nRather than using the provided functions for sin, cos, and tan, it is much more effi-\ncient to use pregenerated lookup tables or take advantage of known relations between\nother variables. For instance, to calculate tan 9, you can simply divide the initial value\nof vy by t>x, since they are defined in terms of sin 6 and cos 9, respectively, and are likely\nprecomputed.\nIn addition, there is additional room for optimization—The purpose here is sim-\nply to alert the reader to the high computational cost involved with trigonometric cal-\nculation and the importance of optimization.\nSummary\nEfficient trajectory production can enhance perceived AI quality and engine perfor-\nmance. Although the derivation can be math intensive, the resulting equations are rel-\natively simple and easy to understand. In addition, once the process involved in\nderiving and simplifying the previous formulae is understood, it is easy to apply that\nknowledge to more complicated situations, such as moving targets, nonvertical accel-\neration, and other related problems.\n\n\n2.5\nThe Parallel Transport Frame\nCarl Dougan\nCarl.dougan@gte.net\nI\nany tasks in computer games require generating a suitable orientation as an\nobject moves through space. Let's say you need to orient a camera flying along a\nlooping path. You'd probably want the camera to turn with the path and point along\nthe direction of travel. When the path loops, the orientation of the camera should\nchange appropriately, to follow the loop. You wouldn't want it to suddenly flip or\ntwist, but turn only to match the changes of the path. The parallel transport frame\nmethod can help provide this \"steady\" orientation.\nYou can also use this technique in the generation of geometry. A common opera-\ntion in 3D modeling is lofting, where a 2D shape is extruded along a path curve, and\nmultiple sections made from the shape are connected together to produce 3D geome-\ntry. If the 2D shape was a circle, the resulting 3D model would be a tube, centered on\nthe path curve. The same criteria apply in calculating the orientation of the shape as\ndid with the camera—the orientation should \"follow\" the path and shouldn't be sub-\nject to unnecessary twist.\nThe parallel transport method gets its stability by incrementally rotating a coor-\ndinate system (the frame) as it is translated along a curve. This \"memory\" of the pre-\nvious frame's orientation is what allows the elimination of unnecessary twist—only\nthe minimal amount of rotation needed to stay parallel to the curve is applied at each\nstep. Unfortunately, in order to calculate the frame at the end of a curve, you need to\niterate a frame along the path, all the way from the start, rotating it at each step. Two\nother commonly used methods of curve framing are the Frenet Frame and the Fixed\nUp method [EberlyOl], which can be calculated analytically at any point on the\npath, in one calculation. They have other caveats, however, which will be described\nlater.\nThe Technique\nA relatively simple numerical technique can be used to calculate the parallel transport\nframe [Glassner90]. You take an arbitrary initial frame, translate it along the curve,\nand at each iteration, rotate it to stay as \"parallel\" to the curve as possible.\n215\n\n\n216 \nSection 2 Mathematics\nGiven:\na Curve C\nan existing frame Fl at t-1\na tangent Tl at t-1 (the 1st derivative or velocity of C at t-1)\na tangent T2 at t\na new frame F2 at the next time t can be calculated as follows:\nF2s position is the value of C at t.\nF2s orientation can be found by rotating Fl about an axis A with angle Ot, where\nA = Tl X T2 and\na = ArcCos((Tl •T2)/(|T1||T2|))\nIf the tangents are parallel, the rotation can be skipped (i.e., if Tl X T2 is zero)\n(Figure 2.5.1).\nA\nFIGURE 2.5.1 The frame at t-1 is rotated about A by Of to calculate the frame at t.\nThe initial frame is arbitrary. You can calculate an initial frame in which an axis\nlies along the tangent with the Fixed Up or the Frenet Frame method.\nIn some cases, you may find it desirable to use parallel transport to generate\nframes at a coarse sampling along the curve, and then achieve smooth rotation\nbetween the sample frames by using quaternion interpolation. Using quaternions is\ndesirable anyway, since there is an efficient method of generating a quaternion from a\nrotation axis and angle [EberlyOl]. You can use the angle and axis shown previously to\ngenerate a rotation quaternion, and then multiply it with the previous frame's quater-\nnion to perform the rotation.\nMoving Objects\nYou can orient a moving object with a single parallel transport rotation each time the\nobject is moved, presumably once per frame. We need three pieces of information: the\nvelocity of the object at the current and previous locations, and the orientation at the pre-\nvious location. The velocities correspond to the tangents Tl and T2 shown previously.\nFor some tasks, the parallel transport frame may be too \"stable.\" For example, an\naircraft flying an S-shaped path on the horizontal plane would never bank. To achieve\n\n\n2.5 The Parallel Transport Frame\n217\nrealistic-looking simulation of flight, you may need to use a different solution, such as\nsimulating the physics of motion. Craig Reynolds describes a relatively simple, and\nthus fast, technique for orienting flocking \"boids\" that includes banking [Reynolds99].\nReynolds' technique is similar to parallel transport in that it also relies on \"memory\" of\nthe previous frame.\nComparison\nThe details here show how the parallel transport method we have looked at so far\ncompares with the Frenet Frame and Fixed Up methods of curve framing.\nThe Frenet Frame\nThe Frenet Frame is built from three orthogonal axes:\n• The tangent of the curve\n• The cross-product of the tangent, and the second derivative\n• Another vector generated from the cross-product of the prior two vectors\nThe Frenet Frame is problematic for the uses already discussed because it cannot\nbe calculated when the second derivative is zero. This occurs at points of inflection\nand on straight sections of the curve [Hanson95]. Clearly, not being able to calculate\na frame on a straight section is a big problem for our purposes. In addition, the frame\nmay spin, due to changes in the second derivative. In the case of an S-shaped curve,\nfor example, the second derivative points into the curves, flipping sides on the upper\nand lower halves. The resulting Frenet Frames on the S-shaped curve will flip in con-\nsequence. Figure 2.5.2 shows what this means graphically; instead of continuous\nFIGURE 2.5.2 Second derivative on an S-shaped curve, and Frenet Frame generated tube\nfrom the same curve.\n\n\n218 \nSection 2 Mathematics\ngeometry, we have a discontinuity where the second derivative switches sides. If this\nwas a flock of birds, they would suddenly flip upside down at that point.\nThe Fixed Up Method\nIn the case of the Fixed Up method, the tangent T and an arbitrary vector V (the\nFixed Up vector) are used to generate three axes of the resulting frame, the direction\nD, up U, and right R vectors [EberlyOl].\nD = T / |T|\nR = DxV/|DxV|\nU = RxD\nA problem with the Fixed Up method occurs when the tangent and the arbitrary\nvector chosen are parallel or close to parallel. When T and V are parallel, the cross-\nproduct of D and V is zero and the frame cannot be built. Even if they are very close,\nthe twist of the resulting vector relative to the tangent will vary greatly with small\nchanges in T, twisting the resulting frame. This isn't a problem if you can constrain\nthe path—which may be possible for some tasks, like building the geometry of free-\nways, but may not be for others, like building the geometry of a roller coaster.\nFigure 2.5.3 shows a comparison of a tube generated using parallel transport with\none using the Fixed Up method. In the upper and lower sections of the curve, the\ncross-product of tangent and the Fixed Up vector is coming out of the page. In the\nmiddle section, it is going into the page. The abrupt flip causes the visible twist in the\ngenerated geometry.\nFixed Up \nParallel Transport\nFIGURE 2.5.3 Comparison of Fixed Up and parallel transport.\n\n\n2.5 The Parallel Transport Frame \n219\nConclusion\nFor unconstrained paths—for example, flying missiles or looping tracks—parallel\ntransport is one method that you can use to keep the tracks from twisting and the\nmissiles from flipping.\nReferences\n[Glassner90] Bloomenthal, Jules, \"Calculation of Reference Frames Along a Space\nCurve,\" Graphics Gems, Academic Press, 1990: pp. 567-571.\n[EberlyOl] Eberly, David H., 3D Game Engine Design, Academic Press, 2001.\n[Hanson95] Hanson, Andrew)., and Ma, Hui, Parallel Transport Approach to Curve\nFraming, Department of Computer Science, Indiana University, 1995.\n[Reynolds99] Reynolds, Craig, \"Steering Behaviors for Autonomous Characters,\"\navailable online at www.red3d.com/cwr/steer/gdc99/index.html.\n\n\n2.6\nSmooth C2 Quaternion-based\nFlythrough Paths\nAlex Vlachos, ATI Research;\nand John Isidore\nalex@Vlachos.com and jisidoro@cs.bu.edu\nI\nn this gem, we describe a method for smoothly interpolating a camera's position and\norientation to produce a flythrough with C2 continuity. We draw on several known\nmethods and provide a C++ class that implements the methods described here.\nIntroduction\nSmoothly interpolating the positions of a flythrough path can easily be achieved by\napplying a natural cubic spline to the sample points. The orientations, on the other\nhand, require a little more attention. We describe a method for converting a quater-\nnion in S3 space (points on the unit hypersphere) into R4 space (points in 4D space)\n[Johnstone99]. Once the quaternion is in R4 space, any 4D spline can be applied to\nthe transformed data. The resulting interpolated points can then be transformed back\ninto S3 space and used as a quaternion. In addition, a technique called selective nega-\ntion is described to preprocess the quaternions in a way that produces the shortest\nrotation path between sample point orientations.\nCamera cuts (moving a camera to a new location) are achieved by introducing\nphantom points around the camera cut similar to the way an open spline is padded.\nThese additional points are needed to pad the spline to produce smooth results near\nthe cut point. The code provided describes cut points as part of a single fly path and\nsimplifies the overall code. Internally to the C++ class, the individual cut segments are\ntreated as separate splines without the overhead of creating a spline for each segment.\nPosition Interpolation\nLet's now discuss position interpolation.\nSample Points\nThere are two common ways to specify sample points. The first is to have each segment\nbetween control points represent a constant time (for example, each control point rep-\n220\n\n\n2.6 Smooth C2 Quaternion-based Flythrough Paths \n221\nresents one second of time). The second is to use the control points only to define the\nshape of the camera path, and to have the camera move at a constant speed along this\npath. The code provided with this gem assumes a constant time between control points,\nalthough this code could easily be modified for the constant speed technique.\nNatural Cubic Spline\nA natural cubic spline is chosen due to the high degree of continuity it provides,\nnamely C2. However, it's important to note that any spline may be used in place of the\nnatural cubic spline. Code for implementing this spline is widely available, including\nNumerical Recipes In C [Press97]. The sample code provided is modeled after this.\nA natural cubic spline is an interpolating curve that is a mathematical representa-\ntion of the original drafting spline. One important characteristic of this spline is its\nlack of local control. This means that if any single control point is moved, the entire\nspline is affected. This isn't necessarily a disadvantage; in fact, this functionality may\nbe desirable. As you begin to use this spline, you'll see the advantages it has in smooth-\ning out the camera movement when you sample the spline at a higher frequency.\nIt is important to differentiate between open and closed splines. In the case of a\nclosed spline, the spline is specified such that the last point is the same as the first\npoint. This is done to treat the camera path as a closed loop. To work around any pos-\nsible discontinuities in the spline at the loop point, simply replicate the last four\npoints of the spline to the beginning of the array, and the first four sample points to\nthe end of the array. In practice, we've found that using four points was sufficient to\neliminate any visual artifacts.\nThis replication eliminates the need for modulus arithmetic and also simplifies\nour preprocessing of the camera path. This is even more important when dealing with\norientations using the selective negation method as described later (Figure 2.6.1).\n2,12\n-2,8\nFIGURE 2.6.1 Replicating points for a closed spline.\n\n\n222\nSection 2 Mathematics\nFIGURE 2.6.2 Creating phantom points for an open spline.\nIn contrast, an open spline has a different beginning and end point. In order to\nsample the spline, you need to pad the spline with several \"phantom\" points at both\nthe beginning and end of the open spline (Figure 2.6.2). A constant velocity is\nassumed for the phantom points before and after the open spline path. At the begin-\nning of the spline in Figure 2.6.2, the vector V^Pj-Po is subtracted from P0 to get the\nresulting point P_j. Similarly, V0 is subtracted from P_j to create P_2, and so on. The\ntrailing phantom points are calculated in a similar way.\nOrientation Interpolation\nSample Points\nUnit quaternions are used as the orientation data at the sample points. Quaternions\ncan be very useful for numerous applications. The beauty of quaternions is that, for\nrotations, they take the form of a normalized 4-element vector (later referred to as a 3-\nelement vector and a scalar component). This is exactly enough information to repre-\n\n\n2.6 Smooth C2 Quaternion-based Flythrough Paths \n223\nsent an axis of rotation and an angle of rotation around that axis [GPG1]. Quater-\nnions give us everything we need to represent a rotation and nothing more.\nFor orientation, however, there is an ambiguity in using quaternions. Orientation\ncan be thought of as a rotation from a base orientation. When using quaternions,\nthere are two possible rotations that will bring you to the same orientation. Suppose\nthere is a counterclockwise rotation 9 about an axis w that gives you the desired ori-\nentation. A rotation by 360°-0 about the axis —w also results in the same orientation.\nWhen converted into a quaternion representation, the second quaternion is simply\nthe negation of the first one.\nDirection of Rotation and Selective Negation\nWhen performing quaternion interpolation, there is one small nuance that needs to\nbe considered. When representing an orientation, either a quaternion or its negation\nwill suffice. However, when interpolating orientations (for example, performing a\nrotation), the positive and negative quaternions result in vastly different rotations and\nconsequently different camera paths. If the desired result is to perform the smallest\npossible rotation between each pair of two orientations, you can preprocess the\nquaternions to achieve this.\nTaking the dot product of two quaternions gives the cosine of half the angle of\nrotation between them. If this quantity is negative, the angle of rotation between the\ntwo quaternions is greater than 180 degrees. In this case, negating one of the orienta-\ntion quaternions makes the angle between the two quaternions less than 180 degrees.\nIn terms of interpolation, this makes the orientation spline path always perform the\nshortest rotation between the orientation key frames. We call this process selective\nnegation.\nThe technique of selectively negating orientation quaternions can be incorpo-\nrated as a preprocessing step for a camera flythrough path. For the preprocessing step,\ntraverse the flythrough path from start to end, and for each quaternion q,on the path,\nnegate it if the dot product between it and its predecessor is negative (in other words,\nif (qt- q,.j)<0). Using selective negation as a preprocessing step makes spline interpo-\nlation much more efficient by not requiring the selective negation math for every\nsample.\nTo preprocess a closed spline path, it is necessary to replicate the first four points\nof the spline path and append them to the end of the path prior to the selective nega-\ntion. Note that the replicated points may have different signs than the original points.\nWhen dealing with an open spline, you need to create phantom quaternions (corre-\nsponding to the phantom control points) to pad the spline. The concept is similar\nin that you want to linearly interpolate the difference between the two quaternions\nclosest to the beginning or end of the path. However, linearly interpolating quater-\nnions doesn't suffice. Instead, we use the spherical linear interpolation (slerp) algo-\nrithm. Given quaternions q0 and qt, we need to generate four phantom\nquaternions—q.j, q_2, and so on— to pad the beginning of an open spline. We use the\n\n\n224 \nSection 2 Mathematics\nslerp function (spherical linear interpolation) to slerp from q, to q0 with a slerp value\nof 2.0. This effectively gives us a linear change in rotation at our phantom points.\nOnce we have preprocessed our entire list of orientation quaternions for interpo-\nlation, it is straightforward to perform smooth spline-based quaternion interpolation\ntechniques.\nSpline Interpolation for Quaternions\nAs seen for positional interpolation, splines can be used to give us much smoother\ninterpolation than linear interpolation can. However, spline interpolation for quater-\nnions is not so straightforward, and there are several techniques that can be used. One\ntechnique simply interpolates the raw quaternion values, and then renormalizes the\nresulting quaternion. However, this technique does not result in a smooth path and\nproduces bizarre changes in angular velocity. Another idea is to use techniques based\non the logarithms of quaternions. SQUAD (spherical quadrangle interpolation)\n[Shoemake91] is an example of this. A performance limitation is incurred when using\nthese techniques because they require transcendental functions (sin, cos, log, pow, and\nso on). Other techniques involve blending between great 2-spheres laying on the unit\nquaternion hypersphere [Kim95], or involve some sort of iterative numeric technique\n[Neilson92]. While many of these techniques provide decent results, most of them do\nnot provide C2 continuity or are computationally prohibitive to use, especially when\nmany flythrough paths are used (for game characters or projectiles, as an example).\nHowever, there is a technique for quaternion spline interpolation that gives very\ngood results and obeys derivative continuity requirements. This uses an invertible\nrational mapping Qohnstone99] M between the unit quaternion 4-sphere (S3) and\nanother four-dimensional space (R4). In the following equations, a, b, and c are the\ncomponents of the vector portion of the quaternion, and s is the scalar portion.\nThe transformation M-/ from S3 — >R4 is:\nx = a/sqrt(2(l-s))\ny = b/sqrt(2(l-s))\nz = c/sqrt(2(l-s))\nw=(l-s) /sqrt(2(l-s))\nThe transformation M from R4 — > S3 is:\na = 2xu> I (y? + y2 + z? + iv2)\nb = 2yw / (x2 + y2 + z2 + ui2)\nc = 2zw I (x2 + y2 + z2 + iv2)\nTo use this for quaternion spline interpolation is straightforward. First, selective\nnegation should be applied to the control quaternions to assure the shortest possible\nrotation between control points. After this, apply M ; to all the control quaternions to\nget their resulting value in R4. This can be done as a preprocessing step and can be\n\n\n2.6 Smooth C2 Quaternion-based Flythrough Paths \n225\ndone in the flythrough-path building or loading stage of a program. This way, die\nsquare root does not have to be calculated when die flythrough path is being evaluated.\nNext, the resulting 4-vectors can be interpolated using the spline of your choice.\nBecause this is a continuous rational mapping, the continuity of the interpolated S3\nquaternion path has the same continuity as die spline used for interpolation in R4\nspace.\nIn our application, we use natural cubic splines [Hearn94] [Press97] for the inter-\npolation in R4 space.\nThis gives us C2 continuous orientation interpolation as well. The qualitative\neffect of this is that die camera path does not have any sharp changes in angular\nacceleration.\nAfter the desired point on the spline in R4 is found, it can be converted back into\na quaternion using M.\nHowever, there is one mathematical nuance in using this technique that needs to\nbe addressed.\nSingularity in the Rational Mapping\nIf your flythrough path contains orientation quaternions close or equal to (1,0,0,0), it\nwill cause numerical instability when interpolated through in R4 space, as M~;(l,0,0,0)\n= C00,00,00,00). There are a few ways to handle diis singularity. One possible option is to\nignore it, and surprisingly, this is feasible in many cases. For example, if the z-axis of the\nworld is pointing up, and you know the camera will never point straight up with the\ncamera's up-vector pointing up the y-axis, the orientation quaternion (1,0,0,0) will\nnever occur in the flythrough path, and die problem is solved.\nIf this is not the case, another option is to find a quaternion ^that is not within\n30 degrees of any of the orientation quaternions, and use gy-to rotate all of the quater-\nnions into \"safe\" orientations that are not near the singularity Qohnstone 99]. The\nbasic idea behind this is to perform the spline interpolation on a rotated version of\nyour flythrough path, and then rotate die interpolated orientations back into their\noriginal coordinate frame. All that has to be done is to multiply all your orientation\nquaternions by q^ after the selective negation step. Following, you transform the\nquaternions from S3 space into R4 space, apply the natural cubic spline, and transform\nthe resulting R4 values back into S3 space. After this, we add the additional step of\nrotating each resulting quaternion by qj1 before using it.\nAn easy way to find gy-is to randomly generate unit length quaternions, until you\nfind one that is not within 30 degrees of any of the selectively negated orientation\nquaternions.\nCamera Cuts\nA camera cut is defined as moving the camera from one point in your scene to another.\nYou can't just introduce a cut in the middle of a spline, and you can't simply step over\n\n\n226\nSection 2 Mathematics\n14\nFIGURE 2.6.3 Creating phantom points for a path cut segment.\nCode\na segment of the spline. Instead, you segment your spline into two separate splines at\na cut point, and process these splines as separate open splines. This is done simultane-\nously for both the position- and orientation-based splines. The code we supply deals\nwith camera cuts in such a way that you don't need to explicitly create a separate path\n(see Figure 2.6.3).\nThe code accompanying this gem is a C++ class that implements most of the tech-\nniques explained in this article. It has member functions for creating and editing the\ncontrol points manually, reading and writing path files, dealing with cut points, sam-\npling the spline at a given time, and setting up vertex and index buffers for drawing\nthe spline. The class assumes there is a constant time between control points as\nopposed to a constant velocity. In addition, the code does not solve the singularity\nproblem, since we never saw the singularity in our project. Please see the source files\nfor more information.\n",
      "page_number": 207,
      "chapter_number": 22,
      "summary": "This chapter covers segment 22 (pages 207-219). Key topics include quaternion, frame, and framing. 2.5\nThe Parallel Transport Frame\nCarl Dougan\nCarl.dougan@gte.net\nI\nany tasks in computer games require generating a suitable orientation as an\nobject moves through space.",
      "keywords": [
        "Parallel Transport Frame",
        "spline",
        "Parallel Transport",
        "Frame",
        "path",
        "points",
        "Frenet Frame",
        "quaternions",
        "Transport Frame",
        "quaternion spline interpolation",
        "orientation",
        "Parallel",
        "spline path",
        "orientation quaternions",
        "flythrough path"
      ],
      "concepts": [
        "quaternion",
        "frame",
        "framing",
        "point",
        "path",
        "spline",
        "rotating",
        "rotation",
        "rotate",
        "rotations"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 1",
          "chapter": 23,
          "title": "Segment 23 (pages 205-212)",
          "relevance_score": 0.56,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 1",
          "chapter": 31,
          "title": "Segment 31 (pages 291-298)",
          "relevance_score": 0.56,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 3",
          "chapter": 33,
          "title": "Segment 33 (pages 314-325)",
          "relevance_score": 0.54,
          "method": "sentence_transformers"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 9,
          "title": "Segment 9 (pages 160-181)",
          "relevance_score": 0.54,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 1",
          "chapter": 17,
          "title": "Segment 17 (pages 150-158)",
          "relevance_score": 0.52,
          "method": "sentence_transformers"
        }
      ]
    },
    {
      "number": 23,
      "title": "Segment 23 (pages 220-230)",
      "start_page": 220,
      "end_page": 230,
      "detection_method": "topic_boundary",
      "content": "2.6 Smooth C2 Quaternion-based Flythrough Paths \n227\nReferences\n[Press97] Press, William H., et al, Numerical Recipes in C, Cambridge University\nPress, 1997.\n[Hearn94] Hearn, Donald, Baker, M. Pauline, Computer Graphics Second Edition,\nPrentice Hall, Inc. 1994.\n[Johnstone99] Johnstone, J. K., Williams, J. P., \"A Rational Quaternion Spline of Arbi-\ntrary Continuity,\" Tech Report: www.cis.uab.edu/info/faculty/jj/cos.html, 1999.\n[GPG1] Edited by Mark DeLoura, Game Programming Gems, Charles River Media,\n2000.\n[Shoemake91] Shoemake, K., Quaternion Calculus for Animation, Math for SIG-\nGRAPH (ACM SIGGRAPH '91 Course Notes #2), 1991.\n[Neilson92] Neilson, G., and Heiland, R., \"Animating Rotations Using Quaternions\nand Splines on a 4D Sphere,\" English Edition, Programming and Computer Soft-\nware, Plenum Pub., New York. 1992.\n[Kim95] Kim, M.S. and Nam, K.W., Interpolating Solid Orientations with Circular\nBlending Quaternion Curves, Computer-Aided Design, Vol. 27, No. 5, pp.\n385-398,1995.\n\n\n2.7\nRecursive Dimensional\nClustering: A Fast Algorithm\nfor Collision Detection\nSteve Rabin, Nintendo of America\nsteve rabin@hotmail.com\n> asic collision detection can be a costly operation. The simplest method relies on\n'treating each object as a sphere and comparin n2 distances. Listing 2.7.1 shows\nthe code for this simple brute-force comparison algorithm. However, a new technique\ncalled Recursive Dimensional Clustering (RDC) can take the typical case from O(rf)\nto something close to O(nlog2n).\nListing 2.7.1 \nBrute-force comparison algorithm\n// Slightly optimized 0((n*2-n)/2) time complexity\nfor( i=0; i<num_objects; i++ ) {\nfor( j=i+l; j<num_objects; j++ ) {\nif( Distance(i, j) < Radius(i) + Radius(j) ) {\n//in collision\nThe practical difference between RDC and the brute-force method is shown in\nTable 2.7.1. These times were calculated on a Pentium II 400 MHz with data con-\ntaining only one collision. Note that the brute-force O(r^) algorithm was fully opti-\nmized to run at O((rf-n)/2) as in Listing 2.7.1 and compared positions using distance\nsquared in order to avoid the costly square root operation.\nWhat's interesting about Table 2.7. 1 is that RDC increases almost linearly, while\nthe brute force method increases exponentially. Although the results are remarkable,\nRDC only becomes useful if you are dealing with large numbers of objects that are\nusually not in collision.\n228\n\n\n2.7 Recursive Dimensional Clustering\n229\nTable 2.7.1 The Difference between RDC and the Brute-Force Method\nObjects\n10\n50\n100\n200\n300\n400\n500\n1000\n2000\n5000\n10000\nRDC\n< 1 ms\n2 ms\n4ms\n7 ms\nUrns\n15 ms\n19ms\n38ms\n81 ms\n222ms\n478ms\nBrute Force\n< 1 ms\n6 ms\n18ms\n67 ms\n150ms\n263ms\n406ms\n1596ms (1.6 seconds)\n6335 ms (6.3 seconds)\n39380 ms (39.4 seconds)\n157621 ms (2 minutes, 37.6 seconds)\nOther Applications\nOne of the benefits of RDC is that it naturally finds groups of objects rather than sin-\ngle collision pairs. A group is a collection of objects that touch each other or are\nwithin a certain radius of each other. This definition also includes groups such that if\nA touches B and B touches C, then A, B, and C are all in the same group, meaning\nthat every group member is not required to touch every other group member. Thus,\nRDC can be used to find simultaneous collisions of several objects or even groups of\nenemies on a battlefield.\nOne interesting application of RDC involves identifying metaball clusters in\norder to speed up geometry generation (Marching Cubes algorithm). In this use, RDC\nfinds the clusters and then calculates the minimal axis-aligned bounding boxes\n(AABB) around those clusters. Minimal bounding boxes are critical for the Marching\nCubes algorithm. This is because the computational speed is proportional to the vol-\nume of the boxes, which equates to an algorithm with O(n?) time complexity. Color\nPlate 1 shows an example.\nThe RDC Algorithm\nIn order to understand how RDC works, the first step is to follow how it recognizes\ngroups of objects in collision along a single dimension. Figure 2.7.1 shows a one-\ndimensional example with three objects.\nAs you can see, objects B and C overlap, while object A is by itself. Thus, a clus-\ntering algorithm would find two groups: one group containing A, and a second group\ncontaining both B and C. Although it's easy to figure this out visually, we need a sys-\ntematic algorithm that achieves the same result.\nThe basic idea of this algorithm is to mark the boundaries of each object and then\nfind groups of overlapping objects using that data. This is done by looping through all\nentities and storing the beginning and ending boundaries for a given dimension in a\n\n\nSection 2 Mathematics\nB\n-H-H-\n10 \n20 \n25\nFIGURE 2.7.1 Three objects along one dimension.\nlinked list. For example, the first object A has a left boundary of 7 and a right bound-\nary of 13. In order to make this apply to any dimension, we can think of these bound-\naries in terms of brackets and label them open and close, instead of left and right.\nFigure 2.7.2 shows the resulting linked list created from the three objects.\nA\nopen\npos 7\n-+\nA\nclose\npos 13\n-*-\nE\nopen\npos 17\n-»•\nB\nclose\npos 23\n-*•\nC\nopen\npos 22\n-*•\nC\nclose\npos 28\nFIGURE 2.7.2 The boundary list.\nWith the boundary list complete, the next step is to sort the list from lowest to\nhighest position using your favorite sorting algorithm, such as quicksort. The sorted\nlist is shown in Figure 2.7.3. In this example, only two elements were swapped.\nNow that we have the sorted list of boundaries, we can find the groups. The\nalgorithm for finding the groups is very similar to parser algorithms for matching\nbrackets. The pseudocode in Listing 2.7.2 will go through the sorted list and extract\neach \"bracketed\" group.\nA\nopen\npos 7\n— *\nA\nclose\npos 13\n— *•\nB\nopen\npos 17\n-*•\nC\nopen\npos 22\n-*\nB\nclose\npos 23\n-*•\nC\nclose\npos 28\nFIGURE 2.7.3 The list after sorting.\nListing 2.7.2 Algorithm for finding groups along one dimension\nint count = 0;\nClear( currentGroup );\nfor( element in list )\n{\nif( element is an \"open bracket\" ) {\ncount++;\nAdd entity to currentGroup;\n\n\n2.7 Recursive Dimensional Clustering\n231\nelse { //element is a \"closed bracket\"\ncount- - ;\nif( count == 0 ) { //entire group found\nStore( currentGroup );\nClear( currentGroup );\nassert( count == 0 ) ;\nAt this point, you may have noticed that the algorithm arbitrarily groups objects\nthat share boundaries. For example, if object A has a closed boundary at position 10,\nand object B has an open boundary at position 10, then any simple sorting algorithm\nwould not distinguish between them. The result is that the algorithm in Listing 2.7.2\nwould inconsistently group these types of cases. However, there are many solutions to\nthis problem. The easiest is to use floating-point values and to make sure that objects\ndon't snap to integer locations. Another solution involves \"puffing out\" each object\nradius by a very tiny amount, thus causing identical boundaries to be offset from each\nother. You could also fix the problem in the sorting function; however, that would\nintroduce extra overhead and increase the running time.\nRDC in Higher Dimensions\nClearly, this algorithm works well for finding groups along one dimension. How-\never, it would only be useful if it worked in two or three dimensions. The trick for\nmultiple dimensions is to first find groups along one axis, and then send each newly\nformed group to the next axis to be subdivided further.\nFigure 2.7.4 shows a set of four objects in two dimensions. Again, it's easy to spot\nthe groups visually, but this example will show how the algorithm determines groups\nin multiple dimensions.\nThe ordered linked list for Figure 2.7.4 along the x-axis is shown in Figure 2.7.5.\n(6, 16,rad3)\n(14, 14,rad3)\n(19, Il,rad4)\n(22, 3,rad2)\nI I I I I II I I I I I I I ITTTT\nFIGURE 2.7.4 Two-dimensional example of four objects.\n\n\nSection 2 Mathematics\nD\nopen\npos 3\n— *•\nD\nclose\npos 9\n-*•\nE\nopen\npos 11\nopen\npos 15\nE\nclose\npos 17\nopen\npos 20\nF\nclose\npos 23\nG\nclose\npos 24\nFIGURE 2.7.5 The sorted boundary list for Figure 2.7.4.\nThe groups in the x-axis are:\nGroupo = { D }, Groupl = { E, F, G }\nWe've now determined that there are at least two groups. The first group contains\nobject D, and the second group contains E, F, and G. With the x-axis done, each new\ngroup is sent to the y-axis to be divided further. Since object Ds group has only one\nmember, it doesn't need to be divided anymore and will simply be its own group.\nHowever, objects E, F, and G must now be analyzed along the y-axjs. Figure 2.7.6\nshows the ordered linked list for Group, along the y-axis.\nG\nopen\npos 1\n->\nG\nclose\npos 5\n->•\nF\nopen\npos 7\n-*•\nE\nopen\npos 11\n-*•\nF\nclose\npos 15\n-+\nE\nclose\npos 17\nFIGURE 2.7.6 The Groupi y-axis sorted boundary list.\nThe groups in the y-axis are:\nGroup1a = { G }, Group1b = { E, F }\nNow that we've gone through each dimension once, the final groups are:\nGroup0 = { D }, Group1a = { G }, Group1b = { E, F }\nFigures 2.7.7s. and 2.7.7b graphically show the boundaries of each object in each\ndiniension and the resulting groups. When this algorithm is expanded to three\ndimensions, the groups are simply analyzed in one more dimension; namely, the\nz-axis. Following is a summary of the steps involved in the RDC algorithm.\nRDC Steps:\n1. Start with the x-axis.\n2. Construct a linked list of object boundaries in this dimension.\n3. Sort that list by boundary position, from lowest to highest.\n4. Find groups using the open/close \"bracket matching\" algorithm in Listing\n2.7.2.\n5. For each group found in that dimension, repeat steps 2-5 in the next\ndimension.\n\n\n2.7 Recursive Dimensional Clustering\n233\n1 1\nH\nGroup o\n1\nn'.i.\n\\ •'•*';\n•\";•\n1 1 !\n\\\n\\\n1\n4-\nit\n\"\"f\n1 1\nGroup\n1\n1\n1 1\nA\nGroup!\n•i:\nGroup\nB\nFIGURE 2.7.7 A) Groups found in thex-axis. B) Group, subdivided in they-axis.\nA Flaw in the Algorithm\nUnfortunately, the algorithm described so far has a fatal flaw. When grouping objects\nalong one axis, objects can get sucked into groups that aren't later separated by other\ndimensions. Figure 2.7.8 points out a problem configuration.\nNTT\nGroup Ob\nGroup Oa\nI I I I\nGroup 0\nA \nB \nC\nFIGURE 2.7.8 A) Flaw example. B) Groups in thex-axis. C) Group 0 subdivided in they-axis.\nFigure 2.7.8b shows the first pass along the x-axis and finds that all three objects\noverlap. Thus, they are all assigned to the same group. Then the single group is ana-\nlyzed along the y-axis, as in Figure 2.7.8c. This results in two groups being found, but\nit understandably fails to put object A and object C in separate groups.\nThe correct solution would be for each object to be in its own group. However,\nthe result of the algorithm was only partially correct. The fix is to send the new groups\nfound along the y-axis back to be analyzed again along the x-axis. When this is done,\nthe correct groups are finally found.\nThis solution can be generalized in order to permanently correct the algorithm.\nThe algorithm needs the following rule:\n\n\n234 \nSection 2 Mathematics\nWhen a group is subdivided along one dimension,\nthe resulting subgroups must be reanalyzed along all other dimensions.\nIn the 2D case, a group that is broken up along the y-axis must be reanalyzed in\nthe x-axis, and vice versa. In 3D, a group that is broken up along the y-axis must be\nreanalyzed in both the x-axis and the z-axis. This fix finally explains the recursive ele-\nment of RDC. Following are the revised steps for RDC algorithm.\nRDC steps (revised):\n1. Start with the x-axis.\n2. Construct a linked list of object boundaries in this dimension.\n3. Sort that list by boundary position, from lowest to highest.\n4. Find groups using the open/close \"bracket matching\" algorithm in Listing\n2.7.2.\n5. For each group found in that dimension, repeat steps 2-5 in the other\ndimension(s) until the group no longer gets subdivided and all dimensions\nhave been analyzed for that unique group.\nFinding Pairs in Collision\nAs presented so far, RDC only identifies groups or clusters of objects that touch each\nother. The effect is that a group can contain members who may or may not directly\ntouch every other member in the group. While this has many great uses (simultane-\nous collisions, grouping info), general collision detection usually requires pairs that\nare in collision.\nTo find collision pairs, each final cluster group from RDC must be sent to the\nbrute-force comparison algorithm. Hopefully, the clusters have very few objects at\nthis point so that the O((n2-n)f2) algorithm runs sufficiently fast.\nOne way to find collision pairs even faster is to use the brute-force algorithm once\na collision cluster gets below a certain number; for example, less than 10 objects. At\nthis point, it would be simply faster to compare all of the objects rather than attempt-\ning to subdivide the group further with continued recursive calls.\nThe RDC Implementation\nAs described, the algorithm is basically recursive and attempts to break groups up\nuntil the minimum clusters are found. The tricky part is designing a recursive func-\ntion that chooses which dimensions to subdivide and when to end the recursion. In\n3D, the function must at least try to subdivide the group along all three dimensions.\nHowever, if any of those dimensions results in subdivision, each subdivided group\nmust then be sent recursively to the other two dimensions.\nThe easiest way to accomplish this is to let a recursive function take three argu-\nments that determine which dimensions still need to be considered. When the func-\n\n\n2.7 Recursive Dimensional Clustering \n235\ntion first gets called, all three dimensions appear as arguments. As each dimension is\nanalyzed and not subdivided, the dimension argument list shrinks to zero and the\nrecursion halts. However, it is mandatory for a subdivided group to be called recur-\nsively with two arguments (the other two dimensions). The complete function can be\nfound in Listing 2.7.3.\nListing 2.7.3 RDC algorithm (pseudocode)\nvoid RDC( Pairs& pairs, Group& group,\nAxis axisl, Axis axis2, Axis axisS )\n{\n//\"pairs\" holds all final pairs that are in collision\n//\"group\" is the current group of objects to analyze\n//\"axisl\" is the axis to analyze within this function\n//\"axis2\", \"a3\" will be analyzed in recursive calls\nif( Size( group ) < 10 || axisl == INVALID_AXIS )\n{ //end recursion and test for collisions\nBruteForceComparisonf pairs, subGroup );\n}\nelse {\n//for this group, find the boundaries and sort them\nOpenCloseBoundaryList boundaries;\nFindOpenCloseBoundaries( axisl, group, boundaries );\nSortOpenCloseBoundaries( boundaries ); \n//O(nlogn)\nGroup subGroup;\nunsigned int count = 0;\nAxis newAxisI = axis2;\nAxis newAxis2 = axisS:\nAxis newAxis3 = INVALID_AXIS;\nbool groupSubdivided = false;\n//subdivide the group if possible and call recursively\nfor( every curBoundary in boundaries list )\n{\nif( curBoundary is \"open bracket\" )\n{ //this entity lies within a cluster group\ncount++;\nAddToGroup( subGroup, curBoundary->entity );\n}\nelse\n{\ncount-;\nif( count == 0 )\n{ //found the end of a cluster group - take subgroup\n//and call recursively on remaining axis'\nif( curBoundary != GetLastBoundary( boundaries ) )\n{ //this group is being subdivided - remember\ngroupSubdivided = true;\n\n\n236 \nSection 2 Mathematics\nif( groupSubdivided )\n{ //reconsider all other axis'\nif ( axisl == X_AXIS ) {\nnewAxisI = Y_AXIS;\nnewAxis2 = Z_AXIS;\n}\nelse if ( axisl == Y_AXIS ) {\nnewAxisI = X_AXIS;\nnewAxis2 = Z_AXIS;\n}\nelse if( axisl == Z_AXIS ) {\nnewAxisI = X_AXIS;\nnewAxis2 = Y_AXIS;\n//recursive call\nRecursiveClustering( pairs, subGroup,\nnewAxisI, \nnewAxis2, \nINVALID_AXIS );\nClear( subGroup ); //clear the subGroup for the next group\nAs you examine the RDC function, note that it has been augmented to find col-\nlision pairs. When the recursion halts and a minimal cluster is found, it then sends\nthat cluster to the brute-force comparison function. It will also halt the recursion\nshould a cluster fall below 10 members. At this point, it immediately compares the\nmembers with the brute-force function.\nTime Complexity\nAt first glance, this algorithm looks fairly time intensive. Your gut feeling probably\ntells you that it's an O(r?) algorithm — and you'd be pretty close. However, because of\nthe physical restrictions of 3D space, certain worst-case configurations are extremely\nrare. Instead, the algorithm takes on average O(nlog2n), as long as most objects aren't\nin collision.\nRDC performs badly in two extreme cases. One is when the objects' configura-\ntion causes RDC to recurse very deeply — this is the worst case o^O(n2log2n). The\nother is when the objects are all in collision with each other, in which case RDC does\nalmost no work and the brute-force algorithm must be used with Q(t£).\nIn the worst case, recursion gets very deep. Functionally, this happens when the\nobject set is split completely asymmetrically, with one object in one group, and n-1\nobjects in the other. The larger group is then sent to the function recursively. If this\nhappens at each level of recursion, we get a total of n-1 calls to the function. (This\nanalysis applies to one dimension only. In three dimensions, we can get up to\n3 + 2(n-l) calls. In all cases, this is O(n)).\n\n\n2.7 Recursive Dimensional Clustering\n237\nFor these calls, the average group size m is equal to n/2. The most complex part of\nthe function is the sort that we assume to be O(mlog2m) or O(nlog2n). This gives the\ntotal time complexity of the worst case as O(n) * O(nlog2n), or O(n2log2n).\nFigure 2.7.8 shows the near worst-case scenario for time complexity (a true worst-\ncase scenario might not be physically possible). Since Figure 2.7.9 is such an unlikely\nconfiguration, the worst-case time complexity of O(n2log2n) is somewhat misleading.\nInterestingly, this particular configuration results in an actual time complexity of\nO(nL78log2n). In practice you should never expect anything nearly that bad, since this\nparticular case is humorously rare and contrived.\nA more likely bad case for RDC occurs when all objects are in collision with each\nother. In this situation, each dimension would be tested, and only one group would\nbe found. This would take O(3nlog2n) time. Then the entire group would be sent to\nthe brute-force comparison algorithm in order to find the final collision pairs. This\nwould make the actual worst case be O(3nlog2n + (r£-n)f2), or simply O(rf). Given\nthat this time complexity is identical to the brute-force method and that no objects\nwill ever be in collision with all other objects, it's almost always faster to use RDC.\nT M i r i 111 11 M i M n 11 M i\nFIGURE 2.7.9 \nNear worst-case configuration for RDC (24 objects).\nConclusion\nAlthough Recursive Dimensional Clustering (RDC) isn't a complete collision detec-\ntion solution, it's an impressive first-pass filter for determining groups of objects that\nmight be in collision. It works with blazing speed, dramatically outperforming brute-\nforce methods. While partitioning of the world space is the standard solution for\nspeeding up collision detection, RDC has remarkable performance in the absence of\nsuch techniques. However, for practical purposes, RDC is best suited for analyzing\nlarge numbers of objects (25+) for collision, perhaps even after other partitioning\nalgorithms have reduced the testable set.\n",
      "page_number": 220,
      "chapter_number": 23,
      "summary": "This chapter covers segment 23 (pages 220-230). Key topics include groups, algorithm, and recursive. [GPG1] Edited by Mark DeLoura, Game Programming Gems, Charles River Media,\n2000.",
      "keywords": [
        "Quaternion-based Flythrough Paths",
        "group",
        "RDC",
        "Quaternion-based Flythrough",
        "Flythrough Paths",
        "Recursive Dimensional Clustering",
        "Algorithm",
        "objects",
        "RDC Algorithm",
        "pos",
        "axis",
        "open pos",
        "close pos",
        "Recursive Dimensional",
        "Dimensional Clustering"
      ],
      "concepts": [
        "groups",
        "algorithm",
        "recursive",
        "recursion",
        "object",
        "collision",
        "collisions",
        "boundaries",
        "boundary",
        "dimension"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 8",
          "chapter": 24,
          "title": "Segment 24 (pages 222-231)",
          "relevance_score": 0.63,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 3",
          "chapter": 33,
          "title": "Segment 33 (pages 314-325)",
          "relevance_score": 0.59,
          "method": "sentence_transformers"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 32,
          "title": "Segment 32 (pages 632-651)",
          "relevance_score": 0.56,
          "method": "sentence_transformers"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 33,
          "title": "Segment 33 (pages 652-672)",
          "relevance_score": 0.55,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 1",
          "chapter": 30,
          "title": "Segment 30 (pages 279-290)",
          "relevance_score": 0.54,
          "method": "sentence_transformers"
        }
      ]
    },
    {
      "number": 24,
      "title": "Segment 24 (pages 231-239)",
      "start_page": 231,
      "end_page": 239,
      "detection_method": "topic_boundary",
      "content": "238 \nSection 2 Mathematics\nReferences\n[Blow97] Blow, Jonathan, \"Practical Collision Detection,\" Proceedings, (Computer\nGame Developers Conference 1997), also available online at http://l42.104.104\n.232/eCOW/projects/Resources/practical_collision_detection.html.\n[BobicOO] Bobic, Nick, \"Advanced Collision Detection Techniques,\" available online\nat www.gamasutra.com/features/20000330/bobic_pfV.htm, March 30, 2000.\n[Roberts95] Roberts, Dave, \"Collision Detection,\" Dr. Dobb's Sourcebook (May/June\n1995): pp. 7-11.\n\n\nProgramming Fractals\nJesse Laeuchli\njesse@laeuchli.com\nT\noday, many 3D games and applications display randomized landscapes. Often,\nfractals are used to create these landscapes. Such landscapes are known for their\nquality and realism, but only recently has the computer power become available in\ngame machines to play with them in real time.\nThere are a number of reasons why you might use fractals to make a landscape. If\nyou created a completely random landscape, setting the heights of the valleys and hills\nto any height, it would look random, and unlike any real-life landscape. On the other\nhand, if you assigned the landscape heights with an orderly function—for example,\nsin—you would get a completely regular and predictable landscape, something not\npossible in real life. It is possible to use fractals to get a mix between the two: a land-\nscape where there will not be impossibly wild mountains and valleys, or evenly spaced\nhills, but more life-like scenes that match the qualities of the physical landscapes we\nsee around us.\nA good non-mathematical definition of a fractal is something regular that has\nrandomness added in a controlled way. Things modeled with fractals are not com-\npletely random, but they are not entirely orderly either. Fractals are most often used as\ntextures, or to create geometric models. Things that are complex, but do not have any\nregularity (such as people) cannot be directly modeled with fractals.\nThis gem looks at the more useful fractals, and examines how they are used. Not\nall types of fractals will be examined, as many of them are highly mathematical and\nhave little use in game programming currently. In games, fractals are usually stored as\nheight-maps: a rectangular grid with numbers in each cell representing the fractal's\nvalue at that point. In the case of a fractal landscape, the value represents the height;\nin the case of a fractal cloud, it might represent the density. The value can be inter-\npreted in many ways, some of which (no doubt) have yet to be invented, however,\nsince height is the most frequent case, I shall refer to the \"height\" of a fractal at a\npoint, rather than using the rather bland word value.\n239\n\n\n240 \nSection 2 Mathematics\nThe Plasma Fractal\nOne of the most common fractals is the plasma fractal. This is very easy to program,\nthe sort of thing demo writers love to optimize, and you have probably seen hundreds\nof them (Figure 2.8.1).\nFIGURE 2.8.1 A small plasma fractal.\nTo create a plasma, we create an empty height-map and assign heights to the four\ncorners. Then, for each side, we linearly interpolate between each pair of corners. The\ncenter squares height is the arithmetic mean of the four corners' heights. We then\nrepeat the process for each of the four squares we have defined with these new ver-\ntices, and recurse. This interpolation scheme generates a smooth curved surface\nbetween the four corners; in fact, it can be used alone to smoothly interpolate a\nheight-map.\nTo make a fractal from this simple curved surface, we introduce a new step at\neach level of recursion. After generating the center vertex, we add or subtract a ran-\ndom amount from its height. At the next level of recursion, we do the same thing, but\nwe reduce the range of the random numbers by a number H. Note that this factor is\nthe only control available over the fractal. If H is 0, the height-map varies wildly; as H\ngets larger, die height-map gets less varied.\nThe main advantages of die plasma fractal are that it is extremely easy to understand\nand runs very fast. Unless speed is more important than results, though, this fractal\nshould be avoided for two reasons. First, very litde control is available over die fractal.\nSecond, this fractal has very bad artifacts—very pronounced ridges along the edges.\nThe Fault Fractal\nAnother common fractal is the fault fractal. This is also quite easy to program, but\nmuch slower than the plasma fractal. The fault fractal very roughly simulates the\neffect of severe earthquakes along random \"fault lines.\"\nTo create this fractal, we again create an empty height-map. Then, we apply a\nseries of \"earthquakes\" as follows: create a random line through the height-map, raise\nevery cell on one side of the line up a small amount, and move every odier cell down\na small amount. This process is repeated until the landscape looks good enough.\nThis technique can create some very good fractals, but generating them is a slow\nprocess. Generally, 1000 to 10,000 fault lines are required before you get acceptable\n\n\n2.8 Programming Fractals \n241\nresults. Therefore, the fractal cannot be done in real time! However, for offline pro-\ncessing, this fractal is very easy to implement and does not suffer from the same alias-\ning effects as subdivision fractals such as the plasma.\nThe fault fractal is one of the few fractals that work on a sphere. The lines become\ngreat circles on the sphere that split the sphere into two hemispheres. Then, each\nhemisphere is moved slightly on their common plane.\nFault fractals have no control parameters, other than the sequence of random\nnumbers used, so it is difficult to generate them artistically.\nFractal Brownian Motion\nThe methods given so far are rather ad hoc approaches to generating fractals. Fractal\nbrownian motion (FBM) fractals have a more rigorous mathematical background and\nhave very good mathematical properties, which makes them simple to work with.\nAn FBM fractal is a combination of noise functions, but each noise function is\nspecial. The key to this technique is understanding the different types of noise.\nFirst, we have white noise, which is completely random. The static on a television\nnot picking up a signal is akin to white noise. The heights in white noise change\nwildly, and are not related to the heights nearby.\nSecond, we have pink noise, which has a limit on how much its heights change\nfrom one point to another.\nIn computer graphics, when the term noise is used it usually means pink noise\nunless otherwise specified. Ken Perlin was the first to use pink noise in computer\ngraphics, when he wrote his now-famous noise() function (known as Perlin Noise).\nHe was also the first graphics programmer to win an Academy Award—for the afore-\nmentioned function. (I look forward to winning my Oscar for best call to fopenQ!)\nWhile we usually think of noise as a ID function (e.g., sound) or a 2D function\n(e.g., a height-map), it can be generated in 3D, 4D, and even higher dimensions. This\ncan be useful when one wishes to introduce a time component to an animating tex-\nture (which can simulate fire) or to an animating 3D density function (which can\nsimulate boiling clouds).\nTo create pink noise, you take a regular grid (or higher-dimension array) and\nstore random values in each cell. The fractal is then generated at every point on the\nsurface by interpolating between these values. The defining feature of any such noise\nfunction is then the frequency, which is the inverse of distance between the grid\npoints. The higher the frequency, the closer the pink noise gets to white noise.\nOnce you have created pink noise of various frequencies, it is easy to create an\nFBM fractal by mixing the heights returned by the noise function. The simplest case\nis just adding the noise functions together, but they can be multiplied or combined in\nother ways.\nThe FBM has a few more parameters than noise alone. In addition to the fre-\nquency, there are the octave, amplitude, and //parameters. The octave variable sets how\nmany noises are added together. The amplitude is a variable that adjusts the overall\n\n\n242 \nSection 2 Mathematics\nheight of the noise. H controls how much the amplitude changes over each octave. The\nfrequency of each slice of noise must be chosen as well. To understand the effects of fre-\nquency on an FBM, we can consider fractal landscapes. When adding noises together,\nthe lower frequency noise is responsible for hills and mountains, and the higher fre-\nquency noise creates roughness. This gives a tremendous amount of control over\nexacdy how the fractal looks. In addition, it is possible to make the amount that you\nchange the frequency differ from section to section of the noise function. This makes it\npossible to have some areas of your fractal rougher than others, so you could have a\nlandscape that is rougher in the mountains, and smoother in the deserts.\nIt is also possible to multiply the noise functions instead of adding them together.\nDoing this will create more variety in your fractal. Multiplying noises together has the\neffect of damping out the lower parts of the noise, and accentuating the higher parts.\nIf the resulting heightmap is used for a landscape, it will have planes, mountains, and\nfoothills—if you just add the noises together, the landscape will have a uniform look.\nIt is necessary to be careful when multiplying noises together, as it is easy to go to\nextremes and dampen and accentuate things too much, leaving just a flat plane with\nspikes in it!\nImplementation\nNow that we have examined the theory of creating FBMs, the next step is to imple-\nment a noise generator. To generate noise, a source of random numbers to be interpo-\nlated has to be generated. The following is the code for my random number\ngenerator:\nfloat random (int x , int y)\n{\nint \nn=x+y*57;\nn=(n«13)*n;\nfloat ret;\nret= (1 - ( (n * (n * n * 19417 + 189851) + 4967243) & 4945007) /\n3354521.0);\nreturn ret;\n}\nThis function just multiplies, adds, and subtracts prime numbers from your\nnumbers, and returns a pseudo-random value between —1 and 1. This is not the only\nway to generate random numbers, of course. Some systems use pregenerated random\nnumbers. That method gives a small performance improvement, but then you must\nstore large amounts of random numbers. With this method, all that needs to be\nremembered is the seed to regenerate the random numbers that were used.\nNext, we need a function that interpolates these random values. A simple lerping\nfunction would work, and it would be fast, but it does not provide very good results.\nWhile some use spline interpolation, this is the slowest and most complex option.\nThis article uses cosine interpolation to build our noise function. This has good qual-\n\n\n2.8 Programming Fractals \n243\nity, it is fast, and it is easy to understand. Note that this is not the only noise function\npossible, and it differs from Perlin Noise (which is much more complex). For a more\ncomplete list, see [Ebert98].\nHere is some code for cosine interpolation:\ndouble cosineinterpolation(double number-1 .double number2,double x)\n{\ndouble ft;\ndouble f;\ndouble ret;\nft = x * 3.1415927;\nf = (1 - cos(ft)) * .5;\nret=number1*(1-f) + number2*f;\nreturn ret;\n}\nNow that there is a random number function, and an interpolation function, it is\npossible to create a noise function by creating random numbers and interpolating diem.\nfloat noise(float x, float y)\n{\nint xinteger=x;\nfloat fractionx=x-xinteger;\nint yinteger=y;\nfloat fractiony=y-yinteger;\nfloat v1,v2,v3,v4,i1,i2;\nfloat ret;\nv1= randomnumber (xinteger, yinteger);\nv2= randomnumber (xinteger + 1, yinteger);\nv3= randomnumber (xinteger, yinteger +1);\nv4= randomnumber (xinteger + 1, yinteger +1);\ni1= cosineinterpolation (v1,v2,fractionx);\ni2= cosineinterpolation (v3,v4,fractionx);\nret= cosineinterpolation (i1,i2,fractiony);\nreturn net;\n}\nThe preceding function takes two variables. Normally, the function is called for\neach point on the heightmap or grid in which you wish to store the results. Note that\nthis is two-dimensional noise.\nIn some cases, it is better to smooth the noise. Smoothing reduces the frequency\nof your noise, and makes it look less square. It is pointless to smooth ID noise, as the\nsame effect is achieved by just reducing the frequency. If you want to smooth your\nnoise, call smoothrandom instead of randomnumber in the noise function.\nfloat smoothrandom(int x,int y)\n{\nfloat corners=(randomnumber(x-1,y-1)+randomnumber(x+1,y-\n1)+randomnumber(x-1,y+1)+randomnumber(x+1,y+1))/16;\nfloat sides = (randomnumber(x-1, y)+randomnumber(x+1,\ny)+randomnumber(x, y-1)+randomnumber(x, y+1) ) / 8;\n\n\n244\nSection 2 Mathematics\nfloat center = \nrandomnumber(x, y) / 4;\nfloat ret=corners+sides+center;\nreturn ret;\nThis is equivalent to doing integration on the nine points around the center\npoint.\nAfter a noise function has been constructed, it is quite easy to create an FBM.\nThis is how it is done:\nfloat FBM(float x, float y, float octaves, float amplitude, float\nfrequency, float h)\n{\nfloat ret=0;\nfor(int i=0;i<(octaves-1) ;i\nret +=( noise (x* frequency, y* frequency)* amplitude);\namplitude*=h;\n}\nreturn ret;\nWhile the way the values change over each octave in this noise may work fine in\nmany cases, sometimes it may be useful to change them. You can change the amount\nthe frequency and amplitude change over each octave. You can even skip octaves. This\ncontrol is another advantage to using FBMs (Figure 2.8.2).\nA slight variation on FBMs are multifractals. Multifractals are like FBMs, except\nthat instead of adding noise, noise is multiplied together. Here is how they are made:\n1\nFIGURE 2.8.2 A) An FBM of just a few octaves. B) The same FBM after several more\noctaves.\n\n\n2.8 Programming Fractals\n245\nfloat Multi-fractal (float x, float y, float octaves, float amplitude\nfloat frequency, float h, float offset)\nfloat ret=1;\nfor(int i=0;i<(octaves-1);i++)\n{\nret *=(offset)*( noise (x* frequency, y* frequency)*\namplitude);\namplitude*=h;\n}\nreturn ret;\n}\nThe offset variable gives some control over the multiplication of the noise. You\nwill notice that the resulting fractal has dififerent kinds of hills and mountains, as well\nas planes.\nUsing FBM\nLet's learn how to make clouds with FBMs.\nClouds\nClouds are quite easy to make with FBMs. You generate an FBM, then you interpret\nall the heights over zero as white, and assign them an alpha value greater than zero. To\nall heights lower than zero, assign an alpha value of zero. Map this texture to a quad or\nsphere, colored the way the sky would be at the time of day being modeled. Figure\n2.8.3 shows some example cloud textures. See clouds.cpp for more details.\nThe example program uses OpenGL to map this texture to a quad. While it looks\nless realistic on a qua4 than on a sphere, it demonstrates the theory.\nA \nB\nFIGURE 2.8.3 (A-C) Clouds generated with FBMs of decreasing frequency.\n\n\n246\nSection 2 Mathematics\nLandscapes\nFBMs are also useful for creating landscapes; in fact, FBMs can create excellent land-\nscapes. Just interpret the heightmap as heights for the landscape (hence, the name!).\nTo render it, create a flat plane out of triangles, and at each triangle vertex, use a\nheight from the heightmap (Figures 2.8.4 and 2.8.5). See Iandscape2.cpp for the\ncomplete listing.\nA\nB\nC\nFIGURE 2.8.4 Various fractal heightmaps: the ground texture is a height-frequency FBM colored by\nheight. A) Generated with a small frequency, small octave, and small amplitude. B) The same\nlandscape with a much higher amplitude. C) Generated with a high frequency.\nA\nB\nFIGURE 2.8.5 Two multifractal landscapes. Note how there are valleys, plains, hills, and tall\nmountains all in the same landscape.\nReferences\n[Ebert98]. David S. Ebert, et al. Texturing and Modeling. San Diego: Academic Press,\n1998.\n",
      "page_number": 231,
      "chapter_number": 24,
      "summary": "This gem looks at the more useful fractals, and examines how they are used Key topics include fractals, noise, and float. Covers function. Programming Fractals\nJesse Laeuchli\njesse@laeuchli.com\nT\noday, many 3D games and applications display randomized landscapes.",
      "keywords": [
        "noise",
        "fractal",
        "noise function",
        "float",
        "function",
        "Collision Detection",
        "FBM",
        "random",
        "Practical Collision Detection",
        "Plasma Fractal",
        "Advanced Collision Detection",
        "Programming Fractals",
        "ret",
        "frequency",
        "FBM fractal"
      ],
      "concepts": [
        "fractals",
        "noise",
        "float",
        "randomized",
        "random",
        "function",
        "functions",
        "landscapes",
        "useful",
        "uses"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 7",
          "chapter": 63,
          "title": "Segment 63 (pages 609-616)",
          "relevance_score": 0.56,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 1",
          "chapter": 51,
          "title": "Segment 51 (pages 491-499)",
          "relevance_score": 0.54,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 53,
          "title": "Segment 53 (pages 511-519)",
          "relevance_score": 0.52,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 7",
          "chapter": 62,
          "title": "Segment 62 (pages 601-608)",
          "relevance_score": 0.51,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 7",
          "chapter": 64,
          "title": "Segment 64 (pages 617-624)",
          "relevance_score": 0.5,
          "method": "sentence_transformers"
        }
      ]
    },
    {
      "number": 25,
      "title": "Segment 25 (pages 240-248)",
      "start_page": 240,
      "end_page": 248,
      "detection_method": "topic_boundary",
      "content": "3.1\nStrategies for Optimizing Al\nSteve Rabin, Nintendo of America\nsteve rabin@hotmail.com\n^Sophisticated AI requires significant computational power. The problem worsens\n%^when dozens or hundreds of autonomous agents must intelligently roam the\nworld simultaneously. Yet this isn't your average optimization problem. Many\ndomains within games deal with scalability, but AI has the extra wrinkle of supporting\nimaginary parallelism. This parallelism comes from each AI agent running its own\npiece of code with the illusion of all agents thinking at the same time.\nAs it turns out, parallelism is one of AI's greatest exploitable assets. This paral-\nlelism, along with other unique attributes of AI agents, can be manipulated to opti-\nmize most AI systems. As you read through the following optiinization strategies,\nkeep in mind a mental picture of hundreds of AI agents all having unique actions and\nagendas. When you consider this magnitude, it's more obvious why certain strategies\nmake sense.\nStrategy f 1: Use Event-Driven Behavior Rather than Polling\nIdeally, autonomous agents should continuously monitor their world and react accord-\ningly. Every frame they might poll the world for events or objects to which they should\nrespond. This means everything from collision detection to noticing interesting things\nto look at. The problem with diis approach is that it promotes an enormous amount of\nredundant computation. As a rule, individual polling is usually wasteful.\nThe alternative is to employ event-driven techniques whenever possible. For\nexample, in a baseball game when the ball is initially hit, the ball could simply tell the\nfielders that it was hit. This is extremely more efficient than each fielder polling the\nsituation to detect when the batter has hit the ball. Granted, this is an obvious use of\nevent-driven behavior, but it still shows the magnitude of processing that can be saved\nby using an event-driven strategy.\nAnother example would be of an arrow flying through a battlefield. Normally, the\narrow would be checking for collisions with characters. If the arrow strikes a character,\nit would then notify the character of the collision as well as the location. The charac-\nter could then react appropriately, responding to where the arrow pierced him. While\nthis is starting to be event driven, nothing too spectacular has happened yet.\n251\n\n\n252 \nSection 3 Artificial Intelligence\nNow consider if you wanted the character to anticipate the impact of the arrow,\nor even try to avoid the arrow. A polling solution would involve each character inter-\nmittently looking for nearby arrows. Conversely, the event-driven solution is to have\nthe arrow predict future collisions, as part of its collision detection routine, and notify\nany characters that might get hit in the future. The characters can then do whatever\nthey want with that info, including running away, ducking, or bracing for impact.\nThe result is very deep behavior without the need to poll for every contingency.\nA good example of an event-driven AI system can be found in the first Game Pro-\ngramming Gems book, in the article \"Designing a General Robust AI Engine\"\n[RabinOOa].\nStrategy #2: Reduce Redundant Calculations\nThe goal of this strategy is to reduce redundant calculations by sharing the results\nbetween several AI agents. Many times agents will individually recalculate the same\ninformation, even though they could have calculated it once and shared it. This is an\neasy optimization that can often save many cycles.\nA simple example of this strategy is apparent in collision detection. If every object\nwere to run its own simplistic collision checks, there would be O(rf-n) tests, or 9900\ncalculations for 100 objects. However, since a given pair of objects only needs to be\ntested once, an optimized collision algorithm would have only O((rf-n)/2) tests, or\n4950 calculations for 100 objects. The savings come directly from eliminating redun-\ndant work.\nAnother example of reducing redundant computation is found in pathfinding.\nWhen a player grabs a bunch of units and orders them to all move to the other side of\nthe map, each unit might expect to separately find a path. Instead, a faster and simpler\nsolution is to let one unit find a path and then let the other units roughly follow him.\nThis avoids the virtually identical path requests that would have normally taken place,\nthus saving a considerable number of cycles.\nStrategy #3: Centralize Cooperation with Managers\nAgents often need to cooperate with other agents, whether they comprise a crack\ncommando squad or a sports team. Cooperation among multiple agents can be made\nfaster and simpler by having a manager entity make the complex decisions. These\ncomplex decisions usually determine each member's role, while the agent is left to\nautonomously execute that role.\nFor example, imagine a SWAT team that is infiltrating a building. The team\nneeds to cooperate very tightly in order to secure each position and move on. If mem-\nbers had to determine their actions individually, it would be quite difficult to coordi-\nnate and would require an enormous amount of inter-member communication.\nInstead, a manager entity can plan out each step of the operation and instruct indi-\nvidual members as to their immediate goal. This simpler approach results in a more\n\n\n3.1 Strategies for Optimizing Al \n253\nrobust and efficient design. An example of how a manager can simplify the game of\nbaseball can be found in [Rabin98].\nIt's important to remember that with this strategy, managers don't need to be rep-\nresented on-screen. Usually these managers are just fictitious entities that organize the\ncomplex cooperation among AI agents. You can even imagine transient managers that\ndynamically form around groups of monsters that have banded together. If that group\nthen divides or combines with another group, each newly formed group can be\nassigned its own manager. With these monster managers, individual monsters can\nbe coordinated so that optimal targets are chosen and everyone doesn't mob the same\nenemy.\nStrategy #4: Run the Al Less Often\nRarely do AI agents need to run through all of their decision-making routines every\nframe. Many times, agents can run portions of code every couple frames or even every\ncouple seconds. Since real creatures have reaction times, it's not unreasonable for AI\nagents to have less than lightning reflexes. This results in a handy way to cut down on\nAI processing.\nUsing an agent architecture that supports arbitrary timer callbacks is a great way\nto implement this strategy. If an agent can easily set a timer and be notified when it\nexpires, flexible systems can be built that are easily tunable. The first Game Program-\nming Gems book has a gem \"Designing a General Robust AI Engine\" [RabinOOa] that\ndiscusses a timer messaging system that is well suited for this strategy.\nOne problem with this strategy is the possibility of AI processing peaks. This\nwould occur if a majority of the agents became synchronous in their callback execu-\ntions, simultaneously executing every TV seconds or so. The simple solution is to ran-\ndomize the window of processing for each agent. For example, an agent might execute\nhis invader-detection code every 0.3 to 0.5 seconds, randomly picking a new delay\nwithin that window after each callback. This random window of execution virtually\nguarantees that agents won't become synchronous with each other, accidentally caus-\ning a processing peak.\nStrategy #5: Distribute the Processing over Several Frames\nTypically, A* pathfinding is one of the dreaded algorithms that can eat up CPU\ncycles. Since situations rarely change much over a couple frames, it's possible for an\nagent to spread a pathfinding calculation over several frames. By saving the results\nfrom each frame and resuming the next frame, a path can be found over 2-4 frames.\nThis results in a lower per-frame processing load. Any algorithm that can take an\nunspecified amount of time can be broken up in this manner.\nThis strategy can be implemented as a special case in a module, like a pathfinding\nmodule, or it can be part of an AI operating system. The next gem in this book,\n\"Micro-Threads for Game Object AI,\" by Bruce Dawson, explains how you can\n\n\n254 \nSections Artificial Intelligence\nimplement a micro-thread strategy in order to minimize AI loads. This particular\narchitecture makes it easier for an AI agent to spread calculations over many frames\nand can help keep processing loads under control. Following Bruce's gem is \"Manag-\ning AI with Micro-Threads\" by Simon Carter, which describes how to best structure\nyour AI within a micro-thread environment.\nStrategy #6: Employ Level-of-Detail AI\nThe level-of-detail (LOD) concept is a clever optimization that has many uses outside\nof graphics. Currently, most game engines use graphical LODs in order to quickly\nrender objects that are far off in the distance. The idea is to use a low polygon count\nmodel when an object is far from the camera, and use a high polygon count model\nwhen it's close. The effect is that the rendering time is greatly sped up with little or no\nvisual loss to the game. An important realization is that the level-of-detail concept can\nalso be applied to other game programming areas, such as AI.\nPractically, the level-of-detail technique for AI comes down to three strategies. The\nfirst is to vary the processing frequency of an agent by how close it is to the camera,\nplayer, or action. The second is to vary the complexity of an agent's algorithms based\non relevance, by doing things such as eliminating precise pathfinding when an agent is\noffscreen. The third is to represent multiple agents in a single simulation algorithm as\ntheir individual importance decreases to the player. An extreme example of the third\nvariation is to simulate the outcome of a far-off military battle with a simple formula,\nwhile battles close to the player might simulate every single soldier and bullet.\nLevel-of-detail is all about trying to get away with less work without the player\nnoticing. If the player can tell something is wrong or different, then the optimization\nneeds to be scaled back, just as it would be with graphical LODs that visually \"pop.\"\nStrategy #7: Solve Only Part of the Problem\nWhen given a large problem, sometimes it suffices to only solve the part that you need\nright away. The rest of the solution can then be computed in the future when you\nactually need it. It might even be the case that the situation changes enough that the\nrest of the problem is irrelevant and never needs to be computed anyway. This strat-\negy is extremely similar to lazy evaluation.\nThe best example of this strategy in action is probably hierarchical pathfinding. In\nhierarchical pathfinding, the path is found in two phases. First, the character's high-\nlevel, room-to-room path to the goal is calculated. Once that is computed, the micro\npath to get the character to the next room, toward the goal, can be computed as each\nnew room is entered. If for some reason the character gets redirected, the remaining\npath is thrown away and never computed. This on-demand pathfinding results in a\ntremendous speed improvement that is critical for games that have large areas to navi-\ngate. See [RabinOOb] for a complete description of hierarchical pathfinding issues and\nimplementation.\n\n\n3.1 Strategies for Optimizing Al \n255\nStrategy #8^ Do the Hard Work Offline\nSometimes, a problem is so difficult that you don't even have the CPU time to solve\nit. In the early years of game development, problems such as finding the cosine of an\nangle simply took too much time. This resulted in programmers precalculating cosine\nfor a range of values and simply indexing a look-up table to get the answer. While\ntoday that technique is no longer relevant, the basic strategy is as useful as ever. .\nCurrent incarnations of this strategy can be found in precomputed BSPs, pfe-\nanalyzed terrains, and carefully trained neural nets. Later, you'll find three gems that\nexemplify this strategy: \"Terrain Reasoning for 3D Action Games\" by William van\nder Sterren, \"Expanded Geometry for Points-of-Visibility Pathfinding\" by Thomas\nYoung, and \"Using a Neural Network in a Game: A Concrete Example\" by John\nManslow. Each gem exploits the bountiful offline time that can be used to analyze,\nrefine, and store specialized information that can then be used at a moment's notice\nduring runtime. This is surely one of the most powerful optimization strategies, since\nit can cram thousands of hours of wisdom into a few kilobytes of data and a trivial\namount of CPU cycles.\nStrategy #9: Use Emergent Behavior to Avoid Scripting\nThis strategy has the opposite problem of the last strategy. Often, you don't have\nenough offline time to create the behavior or scripts for hundreds of background AI\nentities that might populate your world. The solution is to come up with very simple\nrules that result in intelligent, emergent behavior. Later in this book, the gem \"Flock-\ning with Teeth: Predators and Prey\" by Steven Woodcock details how flocking can help\ncreate wonderfully complex behavior that is unscripted, yet interesting and lifelike.\nUnfortunately, this strategy is a double-edged sword. While it cuts down on the\namount of offline work, it has the potential for unintended consequences. In his gem,\nSteven describes a world full of creatures that feed off each other. This sometimes\nresults in the predators completely wiping out the population of prey, causing the\nentire ecosystem to collapse. By its very nature, emergent behavior is unpredictable\nand can be hard to thoroughly test. Consequently, it might be best suited for noncrit-\nical AI entities that aren't pivotal to the progress or completion of a game, such as\nbackground wildlife.\nStrategy #10: Amortize Query Costs with\nContinuous Bookkeeping\nSometimes a lot of data needs to be collected in order to make an intelligent decision.\nIf that data is gathered right when it's needed, then it might take an unacceptable\namount of time to calculate. The solution is to continuously update a data structure\nwith this data as it changes. Although more time and memory is spent keeping track of\ndata, it's amortized over many, many frames. The result is that a simple query of the\ndata no longer causes a hit to the frame rate.\n\n\n256 \nSection 3 Artificial Intelligence\nInfluence maps are an excellent example of this strategy at work. Influence maps\nare used to analyze general strategic patterns, and in doing so, speed up AI decisions.\nAs a game progresses, the units keep their info updated within the influence map as\nthey move, evolve, or disappear. This way, when a general strategic AI wants to ana-\nlyze the world, the data is already available. This results in quick queries to the influ-\nence map without any significant speed hit. Further in this book, you'll find the gem\n\"Influence Mapping\" by Paul Tozour that explains influence maps and has some\nunique insights into making them even more powerful.\nThis strategy is also key in a later gem written by Matt Pritchard entitled \"A\nHigh-Performance Tile-Based Line-of-Sight and Search System.\" In his gem, Matt\nuses this strategy of continuous bookkeeping to maintain the line-of-sight data for\nhundreds of agents in real time, which is not a simple task. Many RTS games fail to\nachieve this frame-by-frame accuracy for their fog-of-war, mini-map, and general\nintelligence; however, Matt fully explains the techniques and strategies that give the\nAge of Empires series that extra edge.\nStrategy #11; Rethink the Problem\nMichael Abrash is well known as an optimization guru within the game development\ncommunity, as well as one of the leading figures in graphics research. On many occa-\nsions, both in presentations and in print [AbrashOO], he has stressed the importance\nof rethinking a problem in order to speed up code by orders of magnitude. His main\npremise is that optimizing specific sections of code will always result in marginal\ngains. The real way to optimize is to attack the problem from a slightly different per-\nspective, with an alternate approach or algorithm.\nThis strategy is well illustrated later in the book by Michael Zarozinski in his gem\n\"Imploding Combinatorial Explosion in Fuzzy Systems.\" In this gem, Michael\nexplains an alternate algorithm, called the Combs Method, which completely circum-\nvents the exponential nature of traditional fuzzy systems. Although the method\ndoesn't produce identical results, the output is very comparable and sufficient for\nmost purposes. In addition, it simplifies fuzzy logic implementation and planning to\nthe point where anyone can easily incorporate it into a game.\nRethinking a problem from a different perspective is probably the best advice\nanyone can give for optimization. It's the seed from which every other optimization\ngrows. Only through the process of redefining or abstracting the problem, creating an\nanalogy, or changing your perspective, can you make the leaps that will allow you to\ntruly optimize your code. While leaps don't come very often, you can learn from\nother's leaps by simply reading and learning as much as you can about how they\nsolved similar problems.\n\n\n3.1 Strategies for Optimizing Al \n257\nConclusion\nIt takes a slightly different perspective to optimize the problems that face AI systems.\nDon't be afraid to scan the list of strategies the next time you're faced with trying to\nspeed up a seemingly unoptimizable system. With so many ways to view a problem, it\nhelps to refresh your memory and contemplate how each strategy applies to your\nunique situation. Here is a recap of all the strategies:\n1. Use event-driven behavior rather than polling.\n2. Reduce redundant calculations.\n3. Centralize cooperation with managers.\n4. Run the AI less often.\n5. Distribute the processing over several frames.\n6. Employ level-of-detail AI.\n7. Solve only part of the problem.\n8. Do the hard work offline.\n9. Use emergent behavior to avoid scripting.\n10. Amortize query costs with continuous bookkeeping.\n11. Rethink the problem.\nAs you read the gems that follow, consider how these optimization strategies have\nbeen applied and exploited within each. While there are a wide variety of strategies,\nit's quite amazing how disparate problems can often be solved with the same strategy.\nThe genius is in seeing those connections.\nReferences\n[AbrashOO] Abrash, Michael, \"It's Great to Be Back! Fast Code, Game Programming,\nand Other Thoughts from 20 (Minus Two) Years in the Trenches,\" Conference\nProceedings, (Game Developers Conference 2000). Text available online at\nwww.gamasutra.com/features/20010117/abrash_01.htm. Video also available\nonline at www.gamasutra.com/features/index_video.htm.\n[Rabin98] Rabin, Steve, \"Making the Play: Team Cooperation in Microsoft Baseball\n3D,\" Conference Proceedings, (Computer Game Developers Conference 1998).\n[RabinOOa] Rabin, Steve, \"Designing a General Robust AI Engine,\" Game Program-\nming Gems, Charles River Media, 2000: pp. 221-236.\n[RabinOOb] Rabin, Steve, \"A* Aesthetic Optimizations,\" and \"A* Speed Optimiza-\ntions,\" Game Programming Gems, Charles River Media, 2000.\n\n\n3.2\nMicro-Threads for Game\nObject Al\nBruce Dawson, Humongous Entertainment\nbruced@humongous.com\nW\nriting good AI can be very difficult. It took many years and millions of dollars\nbefore a computer program was able to beat the world's best chess players.\nGame AI doesn't have to play championship chess, but it does have to update many\ngame objects per frame, in very little CPU time.\nAdding to the essential complexity of writing good AI is the \"accidental complex-\nity\" [Brooks95] introduced by the common methods of implementing AI for game\nobjects.\nAs an example of accidental complexity in most games' code, let's say we want to\nmake a \"Janitor\" object that wanders around our world cleaning up. This janitor's\nroutine is very simple: choose a target, move toward it, dispose of it when you get\nclose enough, and then repeat. Of course, since this is for a game we want to do it in\nsmall steps, one per update loop. Some C++ style pseudocode — without accidental\ncomplexity — might look like this:\nvoid Janitor: :Process() {\nwhile (true) {\nGameObject* target = GetNewTarget(this) ;\nwhile (Distance(this, target) > k_collisionTolerance) {\nWaitOneFrameO ;\nMoveABitTowards(this, target);\n}\nDispose(this, target);\nHowever, that doesn't work very well in a game because it doesn't share the CPU\nother entities in the world. Therefore, the traditional way to implement such a\njanitor object would be as a Janitor class with a virtual function that is called every\nframe, like this code, taken from the sample on the CD:\nJanitor: :Janitor()\n: m_target(0) , m state (k_NeedsGoal) {\n258\n\n\n3.2 Micro-Threads for Game Object Al \n259\nvoid Janitor: :ProcessFrame(){\nswitch (m_state) {\ncase k_NeedsGoal:\nm_target = GetNewTarget(this) ;\nif (Distance(this, m_target) <= k_collisionTolerance)\nm_state = k_DisposeObject;\nProcessFrame() ; \n// Call ourselves.\nreturn;\n}\nm_state = k_MovingTowardsTarget;\n// Intentionally missing break.\ncase k_MovingTowardsTarget :\nMoveABitTowards(this, m_target);\nif (Distance(this, m_target) > k_collisionTolerance)\nbreak;\nelse\nm_state = k_DisposeObject;\n// Intentionally missing break.\ncase k_DisposeObject:\nDispose (this, m_target);\nm_state = k_NeedsGoal;\nbreak;\nWhat a mess! Our AI code has gone from simple and elegant to a huge and unread-\nable state machine. Modifying the second version of die code will clearly be much more\ncomplex, and die state machine cannot be reused widi anodier class, because it requires\nm_state and m_target. That's accidental, or nonessential complexity.\nCentral to die problem is that all of die state now has to be stored in die object.\nThis is a profound change. In the first version of the code the \"target\" variable was\ndeclared as a local variable. It was created exactly when it was needed and fell out of\nscope when its job was done. Now, the target has to be recorded in the object. We also\nadded another member variable to our Janitor class, m_state. Where did this variable\ncome from? Why wasn't it needed in our first version of this routine?\nIn the first version of Process ( ) , die state is implied by which line of code is exe-\ncuting. It's stored in the program counter. The program counter keeps track of die\ncurrent state, the stack pointer points at the current set of variables, and life is easy.\nWhen we implement AI with callbacks, we have to simulate the instruction pointer\nand stack pointer and the benefits they bring us.\nA Simpler Method\nAt this point, it should seem obvious that using callbacks for our entity code is messy.\nTherefore, how do we turn our simple version of die janitor code into something that\nactually works? To do that we need to let the rest of the game loop and die other\nobjects have some CPU time, and we need to synchronize the objects so they do\nexacdy one update per frame. To do this we need to put each game entity into a\n",
      "page_number": 240,
      "chapter_number": 25,
      "summary": "This chapter covers segment 25 (pages 240-248). Key topics include strategies, strategy, and games. This parallelism comes from each AI agent running its own\npiece of code with the illusion of all agents thinking at the same time.",
      "keywords": [
        "Strategy",
        "game",
        "agents",
        "problem",
        "code",
        "Strategies",
        "gem",
        "time",
        "Game Developers Conference",
        "target",
        "Janitor",
        "state",
        "Game Object",
        "game programming",
        "objects"
      ],
      "concepts": [
        "strategies",
        "strategy",
        "games",
        "optimizing",
        "optimized",
        "optimal",
        "optimize",
        "optimizations",
        "gems",
        "gem"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 7",
          "chapter": 25,
          "title": "Segment 25 (pages 238-245)",
          "relevance_score": 0.69,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 7",
          "chapter": 2,
          "title": "Segment 2 (pages 9-16)",
          "relevance_score": 0.63,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 7",
          "chapter": 34,
          "title": "Segment 34 (pages 321-328)",
          "relevance_score": 0.63,
          "method": "sentence_transformers"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 3,
          "title": "Segment 3 (pages 17-24)",
          "relevance_score": 0.62,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 7",
          "chapter": 10,
          "title": "Segment 10 (pages 91-99)",
          "relevance_score": 0.62,
          "method": "sentence_transformers"
        }
      ]
    },
    {
      "number": 26,
      "title": "Segment 26 (pages 249-257)",
      "start_page": 249,
      "end_page": 257,
      "detection_method": "topic_boundary",
      "content": "260 \nSection 3 Artificial Intelligence\nseparate thread and have the WaitOneFrame () function switch to the next thread. With\nsuch a system, the pseudocode of the first example can be compiled and run perfectly!\nWe could start an OS thread for each object. This lets each thread pretend that it\nowns the CPU, while the operating system manages the magic of swapping things\naround to change the CPU state. The WaitOneFrame () function would do the neces-\nsary work to switch to the next thread—see the sample code for details.\nThis sort of strategy works well for Web servers and other multi-threaded apps,\nbut it's a poor option for games. Many games run in environments where there is no\noperating system support for threads—or no operating system at all. Even if there are\nthreads, they are frequently too expensive for game purposes. Switching threads on\nWin32 takes thousands of machine cycles, and each thread uses up a minimum of 8\nKB of memory—4 KB for the Thread Information Block and 4 KB for the smallest\npossible stack. Both allocations take 4 KB because, in order to keep threads indepen-\ndent and allow for stack growth, their allocations are put on separate memory man-\nagement pages, and this forces a 4K granularity.\nOn Win32, there is also the option of using fibers—cooperatively multitasking\nthreads. Fibers are a bit better for our purposes because the context switching is much\nfaster and more easily controlled. However, the stack still takes at least 4 KB, and\nfibers don't work at all on Win95. On Win98, each fiber stack takes a minimum of 8\nKB, making its memory footprint as bad as for regular threads.\nMicro-Threads\nLet's step back and think about precisely what we want. We want to be able to write\nAI or other object-updating code that can pretend that it owns the CPU. After exe-\ncuting the code for one time slice update, we want to be able to call WaitOneFrame()\nto give the rest of the game some CPU time. When WaitOneFrame () returns we want\nexecution to continue where it left off, one time slice later. We want this to be fast,\nand we want minimal memory overhead.\nWhat do we have to do to switch from one thread of execution to another? The\ninstruction pointer in a CPU is a register that points at the next instruction to be exe-\ncuted. If we were to write some code that changed the instruction pointer, we could\neasily jump from one thread to another. Changing the instruction pointer is easy-\nCPUs have many instructions for doing that. In a few lines of assembly language you\ncan get the current instruction pointer, store it somewhere, and then jump to a new\nlocation. This will give die desired effect of jumping back into a previously running\npiece of code—but if that's all you do, you will be terribly disappointed.\nThe instruction pointer is not the only piece of state in a CPU and it is not the\nonly thing that determines what function you are executing. Another important piece\nof the puzzle is the stack pointer. All of the local variables of a function are stored rel-\native to the stack pointer (or the stack frame pointer, but let's ignore that for now). In\nfact, the stack pointer is even more important than the instruction pointer, because\nfunction return addresses—instruction pointers—are stored on the stack.\n\n\n3.2 Micro-Threads for Game Object Al \n261\nLet's imagine that we've written a piece of code that pushes the instruction\npointer onto the stack, then changes the stack pointer, and then pops the instruction\npointer off of the stack. Since the new instruction pointer is popped off of the new\nstack, changing the stack pointer has also changed the instruction pointer—voilfr,\nwe've changed threads. In fact, since calling a function pushes the instruction pointer,\nand returning from a function pops the instruction pointer, our thread switching\nfunction is just two instructions—move a new value into the stack pointer, then\nreturn!\nOkay, it's not quite that easy. First, CPUs have more registers than just the stack\npointer and the instruction pointer. No problem—we'll deal with them the same way.\nPush them all onto the stack at the beginning, change the stack pointer, and then pop\nthem all at the end. It just works. The exact details vary from CPU to CPU, but any\nCPU that has enough flexibility in where you point the stack pointer can implement\nthis system. Micro-threads have even been implemented on a Nintendo GameBoy!\nOn an x86 CPU, a complete thread switch can be implemented in 12 assembly lan-\nV_lli' guage instructions. In the micro-thread sample programs on the CD, that is all the\nONmca> assembly language that is used. Here is a sample SwapThreads() routine:\nSwapThreads\n// Preserve all of the registers that VC++ insists we preserve.\n// VC++ does not care if we preserve eax, ecx and edx.\npush \nebx\npush \nebp\npush \nesi\npush \nedi\n// Swap stack pointers\nitiov \neax, \nesp\nmov \nesp, s_globalStackPointer\nmov \ns_globalStackPointer, eax\n// Restore all of the registers that we previously preserved.\n// Yes, they're coming off of a different stack - they were\n// carefully placed there earlier.\npop \nedi\npop \nesi\npop \nebp\npop \nebx\nret\nIs that all there is to it? That depends. On some CPUs, you may have to preserve\nfloating-point or multimedia registers as well. On the Intel architecture, because of\nthe, umm, peculiar arrangement of the floating-point registers, it is impractical for\ncompilers to preserve them over function calls, so compilers always make sure that all\nfloating-point numbers have been written to memory before calling any function,\nincluding your WaitOneFrame() function. You also don't need to preserve all of the\ninteger registers, because compilers don't expect all of them to be preserved over func-\ntion calls—consult your compiler documentation for details.\n\n\n262 \nSection 3 Artificial Intelligence\nStack Management\nBut what, exactly, are we assigning to our stack pointer when we change threads?\nWhen we start an OS thread we are implicitly allocating and initializing a stack—now\nwe have to do it ourselves. On Win32, the operating system allocates a 4 KB page of\nmemory for each stack. It also reserves some extra address space—1 MB by default—\nso that the stack can grow. If you declare a large array in a function, or have deeply\nrecursive function calls, the operating system automatically allocates more 4 KB pages\nof memory. If you go beyond the address space that was reserved, it stops you with a\npage fault.\nWe're trying to avoid allocating 4 KB of stack for each thread, so how much\nshould we allocate? We might decide that we want to allocate no more than 100 bytes\nof stack per object; after all, we want to have hundreds or thousands of these things.\nWe could use malloc or new to allocate 100-byte blocks and then, with a bit of care-\nful array initialization, set up this stack so that we can switch to it with\nSwapThreads(). This method will work, but it's rather dangerous. If you write any\ngame entity code that uses a bit too much stack, terrible things will happen. You will\ncorrupt whatever block of memory conies before the thread stack, and your game will\ncrash. If you decide to use this system, be sure to put some sort of marker at the far\nend of the stack, and check these markers after every thread switch to see if they have\nbeen overwritten. At least that way you will know when you have trashed memory.\nA slightly different implementation of micro-threads can avoid these strict stack\nsize limits. In this variation a large stack is allocated that all micro-threads share.\nWhen a micro-thread goes to sleep, the thread manager copies the contents of the\nstack to a resizable backup buffer. This buffer only needs to be reallocated when the\nthread's stack size increases, so the buffer allocation time is negligible. Therefore,\nthe only additional overhead of this method is copying the contents of the stack back\nand forth. Interestingly enough, this copying is virtually free, because it primes the\nCPU caches and prepares them for running the thread.\nSo far, stack copying probably doesn't seem any better than allocating a fixed\nstack for each thread. However, the advantage with stack copying is that the stack\nusage only needs to be small when you switch threads. If your AI entities need to call\na complex BSP pathfinding routine, a debug print function, or some other function\nthat uses a lot of stack, they can do this with stack copying micro-threads. The tem-\nporarily large stack usage is harmless as long as you don't call WaitOneFrame() from\ndeep within these utility functions. With fixed-stack micro-threads you can never use\nlarge amounts of stack—not even temporarily.\nThis is a huge advantage. If your AI routines are forced to use a tiny little stack\nwith not much depth, you may end up with AI that has a tiny little brain with not\nmuch depth.\n\n\n3.2 Micro-Threads for Game Object Al \n263\nComplications\nLoading and Saving Games\nCompilers will sometimes generate stack frames for each function, which are used for\neasier addressing of local variables and parameters. These stack frames are tied\ntogether in a linked list on the stack. In other words, a typical stack contains pointers\nto itself. Therefore, the stack image cannot be used in a different location.\nStacks also contain return addresses—pointers to code. Therefore, if you save a\nstack buffer to disk you cannot load it up and expect it to work if you have recompiled\nyour code—all of the code bytes will have moved.\nEven if you deal with the problems of micro-thread stacks containing pointers to\nthemselves and to code, the stacks will contain local variables, some of which will\nbe pointers. When you have pointers in a structure you can still save and restore the\nstructure if you are careful, but with micro-thread stacks, you don't know where the\npointers are. Careful use of C++ pointer objects can manage this problem, but it is\ncomplicated.\nTherefore, loading and saving of games that use micro-thread stacks is problem-\natic. This may restrict their usage to games that don't need to load and save, or to con-\nsole machines where the exact memory layout can be restored when saving.\nStructured Exception Handling\nWin32 structured exception handling is a critical part of a debugging strategy, as it\nensures that detailed crash information is recorded. It is also used to implement C++\nexception handling. However, if you aren't careful, structured exception handlers will\nnot get called for exceptions that happen inside micro-threads. That's because the OS\nhandler that walks the linked list of exception handlers (another linked list on the\nstack) gives up if it notices an implausible pointer, such as a stack pointer outside of\nthe current OS thread's known stack range [Pietrek97].\nThis can be avoided if you locate your temporary stack somewhere in the address\nrange of your real stack, well below what you're actually using. Remember that it has\nto be in a fixed location because the linked lists on the stack won't work if it moves,\nand you have to make sure that your main thread's stack never goes down far enough\nto be overwritten by the micro-thread stacks.\nOutputDebugString\nOn Windows NT, if you call OutputDebugString () from a micro-thread when you're\nnot running under a debugger, your program may exit, due to the structured excep-\ntion handling problem mentioned earlier. This is easily fixed by placing your stack\nC^j2i5 \nappropriately or by using the OutputDebugStringW95() function on the companion\nON m a> \nCD-ROM, which detects whether you are running under a debugger and only uses\nOutputDebugString () when it is safe. It also looks for DBWin32, the freely available\ndebug output monitoring program, and talks to it directly whenever possible.\n\n\n264 \nSection 3 Artificial Intelligence\nConclusion\nThreads are a simpler method of writing AI code for many independent entities.\nMicro-threads let us implement our game entities using threads without die high\nmemory or CPU cost of other threading methods. Micro-threads can be easily imple-\nmented on any CPU architecture, with very little assembly language [KeppelOl].\nA sample implementation of micro-threads for Win32 is on the companion CD-\nROM. Also included is a simple game that uses micro-threads, and a test application\n«,««« \n£or comparmg micro-threads to Fibers and OS threads.\nMicro-direads have also been implemented in several scripting languages used in\ngames, such as Lua [LuaOl], SCUMM (a proprietary Lucas Arts engine also used by\nHumongous Entertainment), and Python [TismerOl].\nA micro-thread janitor can clean up your game code.\nReferences\n[Brooks95] Brooks, Frederick P., Jr. The Mythical Man-Month: Essays on Software\nEngineering, Anniversary Edition, Addison-Wesley, 1995.\n[KeppelOl] Keppel, David, \"QuickThreads distribution,\" available online at http://\nwww.mit.edu/afs/sipb/project/scheme/src/guide-1.3/qt/, June5, 2001.\n[LuaOl] \"The Programming Language Lua,\" available online at www.tecgraf.puc-rio.\nbr/lua/about.html, February 22, 2001.\n[Pietrek97] Pietrek, Matt, \"A Crash Course on the Depths of Win32 Structured\nException Handling,\" Microsoft Systems Journal (Jan 1997).\n[TismerOl] Tismer, Christian, \"Stackless Python,\" available online at www.stackless.\ncom/, February 23, 2001.\n\n\n3.3\nManaging Al with Micro-\nThreads\nSimon Carter, Big Blue Box Studios\nscarter@bigbluebox.com\nA\ns discussed in the previous gem, AI in games is generally implemented through\nsome form of state machine. State machine architecture has a number of advan-\ntages for AI. Most notably, the system can be suspended at any particular state, a facil-\nity that is critically important for any game that intends to have more than one AI\nentity. However, traditional implementations of state machines tend to be messy,\nunintuitive, pro'ne to bugs, difficult to debug, and hard to read. Micro-threads offer a\nfar more elegant way of implementing state machines and can lead to a very robust\nand extensible AI system. This gem attempts to give an idea of how to implement\nsuch a system and take full advantage of its flexibility.\nPiece by Piece\nMicro-threads allow us to code up state machines using normal, everyday program-\nming practices. Most of the \"magic\" goes on in the background, leaving us free to\ndesign our AI system as elegantly as we wish, without having to pander to background\narchitecture issues. Although this is very liberating, it can be difficult to know where\nto start when so many restrictions are lifted.\nGood artificial intelligence in games is all about organizing what can become a\nvery complex system into manageable chunks, and to make these \"modules\" as intu-\nitive and reusable as possible. An important design decision is the granularity of this\nmodularization. By way of example, classic state machines by necessity tend to make\neach individual state a module, and it is this very low-level granularity that makes the\nsystem awkward. Micro-threads allow us to choose the granularity of our modules\nourselves, and choose the level that makes the most sense conceptually.\nFrom a design standpoint, it is far better to break complex AI into units of\n\"behavior.\" In this context, \"behavior\" is the full set of tests and actions that are used\nto model an entity's responses to particular stimuli; for example, being hungry, being\nin a fight, being scared, and so forth. The more behaviors a particular entity has, the\nmore rich and varied its resulting AI will appear to be. An ideal design scenario would\nbe to have the ability to attach different suites of behaviors to different entities. In\n265\n\n\n266 \nSection 3 Artificial Intelligence\naddition, it would be great to be able to reuse certain common behaviors between dif-\nferent types of entities, and hence minimize the amount of replicated code.\nA system based on behavioral units will allow us to construct flexible AI out of\nthese different modules, allowing us to rapidly build up different entity \"brains\" from\nreusable behaviors.\nGood Behavior\nHere's how a general interface for a behavior module might look:\nclass CAIBehavior\n{\nCAIEntity* PEntity;\npublic:\nCAIBehavior(CAIEntity* \npentity);\nvirtual bool IsRunnable(void) = 0;\nvirtual void Update(void) = 0;\nvirtual void OnActivate(void) = 0;\nvirtual void Cleanup(void) = 0;\n};\nThe IsRunnable method is responsible for stating whether the correct conditions\nare present for the behavior to run; for example, is there food nearby and is the entity\nhungry, for a \"hunger\" behavior. OnActivate is called whenever a particular behavior\nbecomes \"active.\" Cleanup is called whenever a behavior is deactivated and is respon-\nsible for making sure that the entity is put back cleanly into whatever state it was in\nbefore the behavior was activated.\nDon't worry about these too much, as they are only necessary when we want to\norganize multiple behaviors later. For the moment, the most important method\nfor our single unit of behavior is Update, as this is the method that performs the meat\nof our AI.\nIn general, a particular module of AI behavior will simply be a tree of conditional\ntests, which will resolve into different actions. For example, think about what a hun-\ngry creature might do.\nCFood* pfood = FindPFood(PEntity->GetPos());\nif(pfood!=NULL){\n//Move toward the food until we are near it\nwhile(!PositionsAdjacent(PEntity->GetPos(), \npfood->GetPos())\nPEntity->MoveOneStepTowardsPos(pfood->GetPos());\nPEntity->EatFood(pfood); //Eat the food.\n}\nHere, the creature looks for food and, if it finds it, moves toward it one step at a\ntime until it is adjacent. When it is near the food, it eats it. Unfortunately, if we ran\nthis code, the game would freeze in the while loop; this is where micro-threads come\nin to save the day. Assuming this behavior class is being run in a micro-thread, all we\nhave to do is add one magical line:\n\n\n3.3 Managing Al with Micro-Threads \n267\nwhile ( !PositionsAdjacent(PEntity->GetPos() , pfood->GetPos()){\nPEntity->MoveOneStepTowardsPos(pfood->GetPos()) ;\nMicroThreadSleepO ; // a call to suspend the micro thread.\n}\nPEntity->EatFood(pfood) ;\nSuddenly, our simple AI process is a state machine! Now, after every step, the AI\nwill suspend its processing, returning control to the main game.\nIt's All in the Mind\nAlthough it may not seem like we've achieved much yet, we are now able to construct\na single module of AI behavior. In order to make an entity's life rich and varied, how-\never, we need some way of organizing and prioritizing multiple, conflicting behaviors\nin such a way that only one is active at a time. This is where the brain class comes in.\nclass CAIBrain\n{\nMicroThreadlnfo* \nPMicroThread;\nstd: :list<CAIBehavior> \nBehaviors;\nstd: :list<int> \nBehaviorPriorities;\nCAIBehavior* \nPActiveBehavior;\nint \nActiveBehaviorPriority;\npublic:\nvoid AddBehavior(int priority, CAIBehavior& behavior);\nvoid Update (void) ;\nEach AI entity in our game will have its own brain, and each brain has a micro-\nthread. Using the AddBehavior method, different types of entities can add different\nbehaviors to the suite of possibilities. In addition, each behavior is given a priority,\nwhich can be used to help choose the behavior to run. It is the responsibility of the\nUpdate method of the brain to keep switching control to the micro-thread, which will\nin turn keep pumping the Update method of the active behavior.\nBefore that, however, we must make sure that there is an active behavior. When\nour entity has nothing to do, we need to run through all the available behaviors and\nchoose the one with the highest priority that succeeds in the IsRunnable test. We take\nthat chosen behavior, call OnActivate on it in case it has any special initialization\ncode, and set it as our active behavior. Once that behavior has finished, we call\nCleanup on it to run any uninitialization routines it may have, and then do the whole\nthing again.\nIn this way, a brain will make sure it always keeps an appropriate active behavior\nrunning. In practice, it is usually a good idea to give all entities some type of fallback\nidling behavior that will always pass the IsRunnable test, just so that it always looks\nlike it is doing something.\nThere is a slight additional complication to this. Say our entity has decided it\nwants to go and run its Sleep behavior for a couple of minutes, because everything is\n\n\n268 \nSections Artificial intelligence\nquiet and its Def endSelf behavior, despite having a higher priority, has found no\naggressors in the IsRunnable method. Unfortunately, while it is sleeping, the entity is\nattacked by some unscrupulous enemies. Using the system described previously, our\nsleeping AI character will be brutally murdered in his sleep, because he would only\nchoose another active behavior when his current one finished.\nWhat we need to do is periodically check our behavior list for an entry that suc-\nceeds on IsRunnable and is of a higher priority than the active behavior. If we find\none, we unplug whatever is currently running—in this case, our Sleep behavior—and\nslap in our new, higher priority system—Def endSelf. In this particular instance, it\nwould probably be the job of the Cleanup method of the Sleep behavior to ensure that\nthe entity is awake, before the new and rather more violent behavior is plugged in.\nThe code for the basics of this system is shown here:\nvoid Update()\n{\nCAIBehavior* pending = NULL;\nif(PActiveBehavior) {\npending = FindNextBehavior(ActivePriority);\n}\nif(Spending && !PActiveBehavior)\npending = FindNextBehavior(-1);\nif(pending){\nif(PActiveBehavior)\nTerminateActiveBehavior();\nPActiveBehavior = pending;\nPActiveBehavior->OnActivate();\n}\nif(PActiveBehavior)\nSwitchToMicroThread(PMicroThread);\n}\nvoid FindNextBehavior(int priority)\n{\n//Find a higher priority behavior that passes IsRunnable\n}\nstatic void MicroThreadFunction(void* pcontext)\n{\nCAIBrain* pthis = (CAIBrain*)(pcontext);\nwhile(!pthis->TerminateThread){\nif(pthis->PActiveBehavior){\npthis->ActiveBehaviorRunning = true;\npthis->PActiveBehavior->Update();\npthis->ActiveBehaviorRunning = false;\n}\nMicroThreadSleep();\n",
      "page_number": 249,
      "chapter_number": 26,
      "summary": "This chapter covers segment 26 (pages 249-257). Key topics include stack, thread, and behavior. With\nsuch a system, the pseudocode of the first example can be compiled and run perfectly.",
      "keywords": [
        "stack",
        "stack pointer",
        "instruction pointer",
        "behavior",
        "pointer",
        "thread",
        "CPU",
        "Micro-Threads",
        "micro-thread stacks",
        "system",
        "code",
        "thread stack",
        "instruction",
        "function",
        "game"
      ],
      "concepts": [
        "stack",
        "thread",
        "behavior",
        "behavioral",
        "micro",
        "memory",
        "different",
        "pointer",
        "function",
        "functions"
      ],
      "similar_chapters": [
        {
          "book": "Computer Systems A Programmer’s Perspective",
          "chapter": 12,
          "title": "Segment 12 (pages 219-238)",
          "relevance_score": 0.73,
          "method": "sentence_transformers"
        },
        {
          "book": "Computer Systems A Programmer’s Perspective",
          "chapter": 18,
          "title": "Segment 18 (pages 352-373)",
          "relevance_score": 0.7,
          "method": "sentence_transformers"
        },
        {
          "book": "operating_systems_three_easy_pieces",
          "chapter": 18,
          "title": "Segment 18 (pages 162-173)",
          "relevance_score": 0.69,
          "method": "sentence_transformers"
        },
        {
          "book": "C++ Concurrency in Action",
          "chapter": 37,
          "title": "Segment 37 (pages 363-372)",
          "relevance_score": 0.68,
          "method": "sentence_transformers"
        },
        {
          "book": "Computer Systems A Programmer’s Perspective",
          "chapter": 1,
          "title": "Segment 1 (pages 1-20)",
          "relevance_score": 0.68,
          "method": "sentence_transformers"
        }
      ]
    },
    {
      "number": 27,
      "title": "Segment 27 (pages 258-267)",
      "start_page": 258,
      "end_page": 267,
      "detection_method": "topic_boundary",
      "content": "3.3 Managing AI with Micro-Threads \n269\nComplications\nDying Considerately\nAll of this so far has been deceptively simple. Brains run micro-threads, which in turn\ncall update methods in behaviors. However, distributing processing across game turns\nhas a number of important ramifications with which we need to deal. If we return to\nthe simple hunger code we looked at earlier, there are a couple of hidden difficulties.\nFirst is the issue of tracked entity death; because the code is now spread across multi-\nple game turns, somebody else may eat the food we are tracking by the time we reach\nit. If our food had simply been deleted from the game when it had been eaten, the\ncode would crash since our pointer would be tracking invalid data.\nDepending on how we handle entity deaths in our game, there are a number of\nways to deal with this. Fundamentally, we have to make sure that any handles we have\non game entities will be valid between game turns. In addition, we should be able to\ninquire whether the entity we are tracking has died. One solution is to force our per-\nsistent handles to be identifier numbers instead of pointers, unique to every entity\nthat gets allocated in our game. That way, when an entity dies, our game code can\nsimply tell us that our handle is invalid. Unfortunately, whenever we wish to access\nany part of the entity, we have to turn our handle into a reference to the actual data,\nwhich can result in bloated, inefficient code.\nA better method is to write a special smart pointer system that deals with all of\nthese issues automatically; a good set of guidelines for writing smart pointers is given\nby Scott Meyers [Meyers96]. Classic smart pointers conceptually have a degree of\nownership over the objects they point to, through reference counting of some sort.\nWhat we want is the reverse, a pointer that passes ownership of itself to the special\ntype of object at which it is pointing. Whenever a tracking pointer is pointed at one\nof our objects, it registers itself with it. Then, when the object dies, it can inform any\ntracking pointers that refer to it about its death and set them to a null value. Once we\n- ,, \nhave this working, all we have to do in our AI code is make sure we check that the\nV_l2ss^ \npointer is non-null before we use it. Example code on how to implement this \"track-\ning pointer\" system is provided on the companion CD-ROM.\nDying Cleanly\nThere is another issue with which we have to deal. What happens if the object whose\nAI we are running dies or is interrupted? If this occurs, then the active behavior needs\nto stop, all the objects we created on the heap need to be deleted, and we have to exit\nour AI code as quickly as possible. Again, depending on your preferences, there are a\nnumber of ways to handle this.\nAn elegant method is to use the C++ exception language facility. When an excep-\ntion is thrown, behind-the-scenes C++ magic cleans up the stack and moves control\nback up the execution hierarchy, which is exactly the functionality we want. All the\n\n\n270 \nSection 3 Artificial Intelligence\nbrain class needs to do is catch the exception and call the behaviors cleanup method.\nHowever, this is a fairly heavyweight approach, and some micro-thread implementa-\ntions don't deal too kindly with exceptions.\nA simpler approach, although rather more invasive, is to periodically check for\nwhether we have been terminated, and return if we have. This does require some care-\nful structuring of the AI code, but it is also a very lightweight solution. With some\nthought, this can even be packaged up to be only minimally invasive. In most cases, to\nbe on the safe side, the brain will keep polling the micro-thread until it receives noti-\nfication that the behavior has indeed stopped running, a technique with which you\nare familiar if you have used threads before.\nvoid CAIBrain: :TerminateActiveBehavior()\n{\nif (PActiveBehavior){\nPActiveBehavior->SetTerminateFlag() ;\nwhile ( Act iveBehaviorRunning)\nSwitchToMicroThread(PMicroThread) ;\nPActiveBehavior->Cleanup( ) ;\nPActiveBehavior->ClearTerminateFlag() ;\nActions Speak Louder\nTaking all these modifications on board, let's see how our earlier example \"hunger\"\nbehavior code might now look.\nvoid Update ()\n{\nCTrackingPointer<CFood> pfood;\npfood = FindPFood(PCreature->GetPos()) ;\nif(pfood!=NULL){\nif (ActionMoveTowardsFood( pfood )==AI_OK)\nPEntity->EatFood(pfood) ;\nEAIReturn ActionMoveTowardsFood(CSmartPointer<CFood> pfood)\n{\nwhile (pfood!=NULL && !PositionsAdjacent(PEntity, pfood-\n>GetPos()){\nif (TerminatedO)\nreturn (AI_TERMINATE) ;\nPEntity->MoveOneStepCloserToPos(pf ood->GetPos( ) ) ;\nMicroThreadSleepO ;\n}\nif(pfood!=NULL)\nreturn (AI_OK);\nreturn (AI_FAIL);\n\n\n3.3 Managing Al with Micro-Threads \n271\nA special tracking pointer is used to track the food in case it dies. The Action-\nMoveTowardsFood method asks the brain to suspend the micro-thread after every step\nit takes toward the food. If die action finds that it has been \"terminated\" by the\nbehavior's brain, it returns a value that lets the calling AI behavior know that it should\ncleanly exit. Likewise, if the food dies, it returns a code telling the behavior as much.\nIn addition, all the code that deals with the problems of distributing the process across\ngame turns has been packaged into a separate method. Structuring our code in this\nway has a number of important advantages:\n• AI is effectively a tree of conditional tests that ultimately resolve into actual diings\nto do. These \"actions\" are the only pieces of code that need to be distributed across\ngame turns; hence, it makes sense to isolate them from die rest of the system.\n• Since only actions need to suspend processing, only they need to do any testing\nfor termination. Keeping the suspension and termination code together keeps\nthings tidy and reduces the chances of forgetting to do one or die odier.\n• Action functions can be put into the behavior base-class and reused between dif-\nferent behaviors.\nExtensions\nThe system described here has been kept purposefully loose, as I have simply\nattempted to give an idea of the elegant architecture that micro-threads can provide\nfor AI. Any number of favored AI tricks can be added, including:\n• Giving each behavior a string name, which can be displayed for debugging pur-\nposes.\n• Allowing brains to be assembled using an external data scripting language, to\nallow nonprogrammers to create and specialize entities. See Scott Bilas' excellent\ngem in this book on the topic.\n• Using the \"message\" system described in Game Programming Gems to allow AI\nentities to enquire and send information about interesting events in the world\n[RabinOO].\nConclusion\nMicro-direads allow an enormous amount of flexibility for writing AI. Using this free-\ndom properly, it is possible to create convincing, fast, lightweight, bug-free AI quickly\nand easily. Particular advantages that this system has over other methods include:\n• Behaviors are grouped intuitively into modules. They can be reused between dif-\nferent types of entities trivially by adding them to different brains.\n• There is no arbitrary jumping around spaghetti links between states, common in\nother state machine implementations. As such, when debugging, you can see the\nentire conditional tree that led to a particular problem, without having to trace\nthrough disparate states.\n\n\n272 \nSection 3 Artificial Intelligence\n• Programmers can code using their favored programming techniques, without\nhaving to pander to a rigid architecture.\n• Data specific to an entity and its behavior can be stored naturally between game\nturns in the behavior class.\nReferences\n[Meyers96] Meyers, Scott, \"Smart Pointers,\" More Effective C++, Addison Wesley,\n1996.\n[RabinOO] Rabin, Steve, \"Designing a General Robust AI Engine,\" Game Program-\nming Gems, Charles River Media, 2000.\n\n\n3.4\nAn Architecture for RTS\nCommand Queuing\nSteve Rabin, Nintendo of America\nsteve rabin@hotmail.com\n[\neal-time strategy games have a unique method of user interaction. Using a\nmouse, the player is able to assign multiple orders to individual units or groups\nof units. This interaction has matured over the years, with each new RTS building\nand improving on previous designs. One of the most evolved designs is a technique\ncalled command queuing. This gem describes how this method of interaction works,\nand how it can be directly woven into the underlying AI architecture.\nRTS Commands\nThe basic user interface for an RTS game involves selecting units and commanding\nthem to do some task, such as attack an enemy or move to a particular spot. This is a\nfairly simple concept that doesn't require any great AI architecture to implement.\nHowever, it's important to first consider the range of simple commands that are avail-\nable in most RTS games before discussing more complex combinations. The follow-\ning is a list of common RTS commands.\n• Attack a creature or building\n• Build a structure or weapon\n• Move to a spot\n• Patrol to a spot\n• Collect a resource (food, raw material, energy)\n• Research a skill\n• Repair a unit or building\n• Reclaim a unit (recycle dead unit's material/energy)\n• Guard a unit or building (attack anyone who attacks it)\n• Hold position (attack anything in range but don't move)\n• Stop\n• Self-destruct\n273\n\n\n274 \nSections Artificial Intelligence\nCommand Queuing\nWhile playing an RTS game, you spend much of your time telling units where to\nmove. Unfortunately, the pathfinding in most games isn't perfect and it often helps\nwhen the player assists in planning paths by setting waypoints. Waypoints are simply\nsuccessive move commands that are queued up within a unit. The player queues up\nthe move commands by holding some special button (like the Shift key) while click-\ning on the ground for each waypoint.\nWaypoint queuing was an important step that has opened the door for a more pow-\nerful interface system. If you can queue waypoints, why not let the player queue any\ncombination of commands? In effect, you could tell a unit to attack a creature, repair a\nwall, and then build a gun turret, all widiout waiting for any of the tasks to be com-\npleted. In addition, the player could decide, at a slighdy later time, to queue even more\ncommands onto the end of those. Generally, this idea is known as command queuing.\nThe trick is to think of every command as a task and to think of a unit's brain as\na queue of tasks. The unit will always process the task that's at the front of the queue.\nOnce that task is completed, it's destroyed and the next task is started. When there are\nno more tasks to process, a unit should have a default idle task. Figure 3.4.1 is an\nexample of a unit's brain queue.\nFigure 3.4.1 shows the result of queuing the commands attack, repair, and move.\nIt also shows that each task has data associated with it, such as what to attack or where\nto move. New tasks to be queued are placed at the end of the list, but before the\ndefault task. The default task must always be the last task and it never completes and\nis never destroyed.\nIf the player commands a unit to do a new task without holding the \"queuing\"\nbutton, all tasks are destroyed and the new task is put in the queue. Thus, queued\ntasks can easily be replaced by a single, new command.\nBrain Queue\n(front of queue)\nCurrent\nactive task\nenemy 24\nj-v \n-s \n.J^- \n•: i .&*&?#.&£&&* •• -\\ ' Ulill T-^\nQueued\nnon-active\ntasks\npos\n. Insert additional\nqueued tasks here\nDefault task\n—' \n9\n(never completes)\nFIGURE 3.4.1 An AItask list in the form of a brain queue.\n\n\n3.4 An Architecture for RTS Command Queuing \n275\nWith this architecture, a common behavior is to allow the player to \"see\" the\ncommand queue by selecting the unit and holding the \"queuing\" button. The on-\nscreen result is that arrows show where the unit is planning to go and what they\nintend to do, such as build a structure. The elegant way to implement this is to let\neach task draw its contribution onto the screen. This allows the player to quickly see\nwhat's queued up in the unit and what additions might be appropriate.\nThis simple architecture is also blind to who put the commands in the queue.\nObviously, the player can put commands there, but the game can also preload com-\nmands for a NPC (Non-Player Character) that might be patrolling or guarding a spot.\nThe AI can also make high-level decisions about which units to attack by simply\nputting those commands in the queue. Even packets from over a network can be\nallowed to place commands in a unit's queue. It's a very elegant system that allows a\nlot of flexibility.\nCyclic Commands\nPatrolling is a cyclic command that presents some interesting consequences for the\nsystem described so far. When a player takes a unit and tells it to Patrol to a spot, the\nunit will remember his original spot and then walk back and forth between the two,\nindefinitely (or until an enemy is in sight). The player could also queue up several\nPatrol waypoints and the unit would similarly cycle through the waypoints forever.\nFigure 3.4.2 shows a three-point patrol that was initiated with two mouse clicks.\nOriginal Character Position \nFirst Patrol Click\nSecond Patrol Click\nFIGURE 3.4.2 Patrol path for a unit.\nQueuing the First Patrol Point\nThe first Patrol click from a player actually ends up placing two patrol commands on\nthe queue. This is because the intent of the player is for the character to move to the\nposition of the mouse click, and then move back to his original spot, repeating the\ncycle over and over again. Figure 3.4.3 shows the brain queue after just one Patrol\ncommand was issued by the player.\n\n\nSection 3 Artificial Intelligence\npos 1\nFIGURE 3.4.3 The brain queue after a single Patrol command was issued.\nInterestingly, a Patrol command is identical to a Move command, except that it\ngets cycled to the back of the queue. Therefore, our queuing system will work per-\nfectly if a simple \"cyclic\" flag is set within a Move task in order to make it a Patrol\ntask. When the Patrol task completes, rather than being destroyed (like a Move task),\nit's put onto the back of the queue (but before the default task). Figure 3.4.4 shows\nseveral iterations of the three-point patrol sequence from Figure 3.4.2.\ntrain Queu<\nnitial pos 1\nliP\" /\nS|i| ill I\n• . - :-\"\n.«..i^a:. ;• .: ._\nisiil\nIgSflS iki;!\n-..:•-. \n'-\n:-i\nX' •\"„''>\n~.-Mc\nISEiel\n\".\".:.-;'\n:\" \n. \"v.\n1\n~;Sg«\nHillr\n-.,;i»^.\nill\nJ \nE\n) \n(P\n^pos2\ncyclic\npos 3\ncyclic\n_^pos 1\ncyclic\nlime —\ntrain Queui\nos 2 reache\n'?'.\n:',:.^\n: ^^Bffe^\nfliif|:\n||i|i|i\ns-SV.^1.\".:-.1\"1.1:?\";?;^:^.;;1\n2 \nE\nd) \n(p\n_^pos 3\ncyclic\nr-Kpos l\ncyclic\n_^pos2\ncyclic\n*•\ntrain Queue\nos 3 reache*\nK|i3v*fl\n'iiiii:i\n\"^^IHftifr^-\n., \n. . v«^>.'-^>tef. . , ; • . • ; :\npos 1\ncyclic\npos 2\ncyclic\npos 3\ncyclic\nFIGURE 3.4.4 Three iterations of a patrol path.\nQueuing Additional Commands\nSome tricky issues arise when the player wants to queue extra commands when Patrol\ntasks exist in the queue. While the following might be slightly subjective, experimen-\ntally it's very close to what most players expect.\n\n\n3.4 An Architecture for RTS Command Queuing\n277\nThe first issue is where to put additional Patrol commands that are to be queued\nup. The player who is adding these extra Patrol points will probably expect that\nthey're put after the first set of Patrol points (regardless of where the unit currently is\nin the brain queue). This is an important point since the unit could be anywhere\nalong the patrol when the second set of Patrol commands are queued.\nThe solution is to mark the last Patrol command ever queued. This allows new\nPatrol commands to get queued after it. Once new Patrol commands are added, the\n\"last\" marker is moved. Figure 3.4.5 shows an example of three Patrol commands\nbeing queued successively.\nBrain Queue\n(first Patrol click)\nBrain Queue\n(second Patrol click)\nBrain Queue\n(third Patrol click)\npos 2\npos 1\ncyclic\npos 2\ncyclic\npos 3\n• cyclic\nlast\npos 1\ncyclic\npos 2\ncyclic\n_^_iis~l pos 1\ncyclic\nFIGURE 3.4,5 Three Patrol commands being queued in order.\nThe second issue with queued Patrol commands involves queuing additional\nnon-Patrol commands. In general, the player expects the command to be executed\nimmediately after the current Patrol waypoint is achieved. This is tricky since the new\ncommands must be placed after the current Patrol command, if there is one, and after\nany other noncyclic commands. Figure 3.4.6 shows a case of queuing several new\nnon-Patrol commands.\nAs shown, Patrol commands throw several wrenches into the command queuing\nconcept. The trick is to implement what the user expects to happen. The user will\ntypically have a model in his or her head of how the system will work. Uncovering\nthat model is not an easy task, but it will give you good insight into how to design the\ninteraction and behavior of the command queuing system.\nHowever, dealing with the users' mental model is a two-way street. It's also\nimportant to give the players immediate feedback, letting them know the result of\n\n\n278\nSection 3 Artificial Intelligence\nBrain Queue\n(Patrol Issued)\nTV- \na \nP<>s2\n| Move \n!->• cyclic\n3 \nlast\nBrain Queue\n(Build Issued)\npos 2\nBrain Queue\n(Repair Issued)\nhouse\npos (4, 7)\nhouse\npos (4, 7)\nunit 42\nFIGURE 3.4.6 Queuing additional commands with Patrol tasks already queued.\ntheir input and how it was interpreted. That way, if the users' model is incorrect or\nflawed, they can quickly reconcile it with the correct model. A wonderful book that\ndiscusses the subject of mental models is \"The Design of Everyday Things\" by Don-\nald Norman [Norman90].\nConclusion\nCommand queuing is now a standard power feature that no RTS game can do with-\nout. By using the brain queue architecture to store tasks, many of the complexities of\na command queuing system go away. In addition, you can think of the brain queue as\na simple task list, or you can turn each task into its own neatly wrapped AI system\nthat knows how to accomplish its job. Either way, your players should be able to\nqueue up whatever they wish, and easily manage hundreds of units with this simple,\nyet powerful interface.\nReferences\n[Norman90] Norman, Donald, A., The Design of Everyday Things, Currency/Double-\nday, 1990.\n",
      "page_number": 258,
      "chapter_number": 27,
      "summary": "This chapter covers segment 27 (pages 258-267). Key topics include command, patrol, and patrolling. Brains run micro-threads, which in turn\ncall update methods in behaviors.",
      "keywords": [
        "patrol commands",
        "Patrol",
        "brain queue",
        "Command Queuing",
        "queue",
        "Commands",
        "RTS Command Queuing",
        "Patrol Click",
        "task",
        "unit",
        "Queuing",
        "brain",
        "queued Patrol commands",
        "game",
        "pos"
      ],
      "concepts": [
        "command",
        "patrol",
        "patrolling",
        "task",
        "queuing",
        "dying",
        "died",
        "dies",
        "die",
        "pos"
      ],
      "similar_chapters": [
        {
          "book": "operating_systems_three_easy_pieces",
          "chapter": 12,
          "title": "Segment 12 (pages 103-116)",
          "relevance_score": 0.6,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 7",
          "chapter": 13,
          "title": "Segment 13 (pages 116-124)",
          "relevance_score": 0.58,
          "method": "sentence_transformers"
        },
        {
          "book": "C++ Concurrency in Action",
          "chapter": 33,
          "title": "Segment 33 (pages 330-337)",
          "relevance_score": 0.57,
          "method": "sentence_transformers"
        },
        {
          "book": "operating_systems_three_easy_pieces",
          "chapter": 8,
          "title": "Segment 8 (pages 57-67)",
          "relevance_score": 0.57,
          "method": "sentence_transformers"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 7,
          "title": "Segment 7 (pages 50-57)",
          "relevance_score": 0.56,
          "method": "sentence_transformers"
        }
      ]
    },
    {
      "number": 28,
      "title": "Segment 28 (pages 268-275)",
      "start_page": 268,
      "end_page": 275,
      "detection_method": "topic_boundary",
      "content": "3.5\nA High-Performance Tile-\nbased Line-of-Sight and\nSearch System\nMatt Pritchard, Ensemble Studios\nmpritchard@ensemblestudios.com\nI\nn the realm of strategy games, the concepts of Line-of-Sight (LOS) and Fog-of-War\n(FOW) for target identification and acquisition are often encountered. In tradi-\ntional turn-based strategy games, using the brute-force approach of completely rebuild-\ning a player's explored and visible maps has generally proven to be adequate. However,\nusing the same approaches in a Real-Time Strategy (RTS) game quickly reveals perfor-\nmance issues, especially as the size of the game world or number of units increases. Still,\nmany commercial RTS games, some very successful, have used this rebuild-all approach.\nUnfortunately, they have to make performance compromises such as forgoing the FOW\naltogether or not updating it every game turn, thus allowing inaccuracies to appear in\nthe display. This gem presents an efficient implementation of a player visibility system\nfor tile-based games that minimizes the performance impact, while providing support\nfor fast searching as well as other game features.\nOverview\nThe first assumption is that internal to the program, sections of the game world area\nare represented by small chunks or tiles, which correspond to a two-dimensional\narray. Most real-time strategy games have rectangular game maps, but this implemen-\ntation is easy to adapt to a hex-based world layout.\nThe goals of our player visibility system are as follows:\n• The game's explored, visible, and fogged tiles must be fully accurate at all times.\n• Units must be able to search very fast for other units or objects of interest, with\nrespect to FOW and visibility.\n• The system must support up to 16 players at a time, allowing for arbitrary infor-\nmation sharing between players.\n• The system must scale well with respect to more units, larger maps, and larger\nsearch radii.\n279\n\n\n280^ \njSection 3 Artificial Intelligence\nDefinitions\nTile. The smallest discrete square- or hexagon-shaped portion of the game world.\nWorld. The total area in which the game takes place; internally a 2D array of tiles,\nalso called the map.\nPlayer. A human or computer entity who controls a population of units. Each\nplayer has a unique set of visibility information.\nUnit. Any game entity that is owned or controlled by a player. It does not have to be\nmovable.\nLine-of-Sight (LOS). The area around a unit that is currently visible because of its\npresence.\nLOS Radius. The range of a units LOS area, measured in tiles.\nUnexplored Tile. A tile that the player's units have never seen within their LOS.\nFogged Tile. A tile that has been explored but is not currently in the LOS of any of\nthe player's units.\nVisible Tile. A tile that is currently in the LOS of one or more of the player's units.\nFog of War (FOW). The concept that if an explored tile is not currently in the LOS\nof a player's unit, then the player can't see other players' units on that tile.\nIn an RTS, we assume that for each player, the map starts out unexplored. As tiles fall\ninto a unit's LOS, those tiles become explored for the player who owns that unit.\nWhen an explored tile is no longer in a unit's LOS, the tile becomes fogged for that\nplayer, yet will never revert to being unexplored. It's important to note that die tile\nstates of unexplored, explored, and fogged are unique for each player.\nComponent #1: Individual Player Visibility Maps\nThe first component of the player visibility system that needs to be implemented is a\nvisibility count map for each player in the game. This is a rather simple structure: a\n2D byte array with a one-to-one correspondence to the tile layout. Each array element\ncontains a count of how many of the player's units can see that tile (in other words,\nhow many units' LOS contain that tile).\nUpdating the visibility map is simple. When a unit is first created or moved into\na new tile position, all of the visibility counts are incremented by one for the tiles in\nthe unit's line of sight. When the unit is deleted, destroyed, or moves off a tile, all of\nthe visibility counts are decremented by one for the tiles in the unit's LOS. The value\nin each visibility map element is nonzero if the tile is visible to the player. However, it\nis unclear if a zero value means an unexplored tile or a fogged tile. To solve this, we\ndesignate zero to mean fogged, and -1, or 255 in byte storage, to mean unexplored.\nUnfortunately, when an unexplored tile is incremented for the very first time, the\nvalue will wrap to zero, which incorrectly means the tile is fogged. However, we can\ncatch this special case and ensure that an increment that results in zero gets incre-\nmented again. This also provides a convenient place to add code for additional one-\ntime processing on the explored tile, such as adding it to a mini-map, recording its\n\n\n3.5 A High-Performance Tile-based Line-of-Sight and Search System \n281\ntype, or searching it for resources. Since most games do not ever revert a tile to unex-\nplored, this special case will not appear in the decrement code. It's worth noting that\nthe storage element size—in this case, a byte—sets an upper limit to the number of\nunits that can see a specific tile at one time, which in this case is 254.\nComponent #2: LOS Templates\nIn most strategy games, a unit's LOS is defined as a circular area around the unit, with\nthe radius measured in the number of tiles. The simplest way to compute this shape,\nwhich many games have done, is to take a radius-sized box of tiles around the unit's\nposition and see if the distance from each tile is less than the unit's LOS radius. How-\never, from a performance standpoint, this is horribly inefficient. Given that this oper-\nation can be called a huge number of times each turn, this function begs for major\noptimization.\nOne of the best ways to optimize this is to precompute the LOS area for each pos-\nsible LOS radius that is used in the game. This shape information can then be stored\nin a template structure with different templates used to represent different LOS radii.\nThe best implementation I have found is to store the LOS area as a series of hor-\nizontal strips, with start, stop, and vertical displacements relative to the unit's posi-\ntion, starting from the top and working down. The templates are processed\nhorizontally under the assumption that elements in that axis of the array are stored\nlinearly in memory, thus minimizing the number of cache accesses during processing.\nFor units at the edges, clipping the LOS template shape to the game map just requires\nclamping the start and stop values in the outer loop. The following code shows a\nfunction to add a unit's LOS template to the visibility count map.\n// This routine \"explores\" the game map in an area around the\n// specified unit position using a line of sight template\n// The template span data is an array of structs with 3 offset elements:\n// {vertical position, horizontal start, horizontal end}\nvoid VisibilityMap::AddLOSTemplate(int XPosition, int YPosition,\nLOSTemplate *template)\n{\nint n, x, y, xStart, xEnd;\n*\nfor (n = 0; n < template->number_of_vertical_lines; n++)\n{\ny = Yposition + template->SpanData[n].Yoffset;\nif (y >= map_y_min_coord && y <= map_y_max_coord)\n{\nxStart = max(XPosition + template->lines[n].XStartOffset,\nmap_x_min_coord);\nxEnd = min(XPosition + template->lines[n].XEndOffset,\nmap_x_max_coord);\nfor (x = xStart; x <= xEnd; x++)\n{\nif ((VisibleMap[y][x]++) == 0)\n\n\n282\nSection 3 Artificial Intelligence\nExploreTileForFisrtTimeHandler(x, y);\nVisbleMap[y][x] = 1;\nWhen a player's unit is removed from the game world, the game decrements the\nvisibility count of its LOS area. If none of the player's other units have the tile in their\nLOS, it will be zero, indicating that the tile is no longer visible for the player, and is\nnow fogged.\nWhen a unit moves from one tile to an adjacent tile, which is normally a very\ncommon operation, it removes its LOS from the old position and adds it back in at\nthe new position. Since this pair of function calls will be often made in tandem from\nthe unit's movement code, another optimization is to combine the two operations\ninto a single function. This new function takes both the old and new positions and\nonly updates the portions of the player's visibility map where the increment and the\ndecrement do not overlap. Another situation is when a unit's LOS radius changes. In\nthat case, the remove LOS function is called with the old radius, followed by the add\nLOS function with the new radius. Properly written, the optimized update function\nshould handle this case as well.\nThere are additional advantages to using LOS templates. The first is that differ-\nent shapes can be created for different-sized objects with the same LOS radius. While\na small game unit may occupy a single tile, larger units, such as immobile structures,\nmight occupy several adjacent tiles and possibly even be nonsquare, such as rectangu-\nlar or elliptical. An LOS template that appears centered on a one-tile unit would\nappear off center when used on the larger unit. Figure 3.5.1 shows a set of LOS tem-\nplate shapes for two different-sized objects, both with a radius of three tiles.\nAnother advantage of using templates is that nonsymmetrical LOS shapes can be\nmade. Figure 3.5.2 shows an example of two rotations of a directional searchlight\nTiles occupied\nby a unit\nB:l\nVisible tiles\nFogged or un-\nexplored tiles\nFIGURE 3.5.1 LOS shapes with the same radius for units of different size.\n\n\n3.5 A High-Performance Tile-based Line-of-Sight and Search System\n283\nTiles occupied\nby a unit\nVisible tiles\nFogged or un-\nexplored tiles\nFIGURE 3.5.2 Noncircular LOS areas with two rotations of a searchlight pattern.\nshape. With a full set of rotated LOS templates, the searchlight unit could be easily\nanimated to sweep a full circle, producing a cool game effect with very little special-\nized programming.\nComponent #3: The Combined Visibility Map\nSo far, what's been implemented is more efficient, but it doesn't help with some of the\nother goals. This next component, called the combined visibility map, will tie the other\nstructures together. This data structure will be accessed the most by the rest of the\ngame code and will provide a big boost to the searching functions.\nLike the individual player maps, the combined visibility map is a 2D array, sized\nthe same as the tile grid. The difference is that there is only one combined visibility\nmap for the entire game, and its elements are 32-bit DWORDs instead of bytes.\nGiven its usage, it could be a good idea to make this globally available to the program.\nThe purpose of the combined visibility map is to contain all of the up-to-date vis-\nibility information in a single place for all of the players in the game. This is done by\nusing just 2 bits per element for each player. One bit is to indicate that a player has\nexplored the tile, and the other bit is used to indicate if the tile is currently visible to\nthe player. This gives room for 16 players' worth of data in each DWORD.\nThe organization of the individual bits in a combined visibility map element is\nup to the user to implement. This should have no relevance on performance, as all\nupdates should consist of a single binary OR, AND, or XOR operation on the entire\n32-bit element, using mask values precomputed for each player.\nIn practice, the combined visibility map is initialized to all tiles as unexplored and\nfogged. It is then updated when any of the following events occurs for any player:\n\n\n284 \nSections Artificial Intelligence\n• A tile is explored for the first time.\n• A tile transitions from unexplored or fogged to visible.\n• A tile transitions from visible to fogged.\nDuring the display of the game world or other structure such as a radar map, each\nplayer has a visibility mask value that contains the explored and visibility bits shifted\ninto the correct position for that player. As each tile location is traversed by the vari-\nous functions, the combined visibility map value for that location is ANDed with the\ncurrent player's visibility mask. The result gives the visibility and explored status of\nthat tile for the specified player, on which the code can then operate.\nThe first benefit of using the combined visibility map is that the player's visibility\nmasks can be combined. This allows for various game effects such as sharing lines-of-\nsight and visibility with teammates, as well as spying on other players. The effects for\neach player can be added or removed at any time by simply updating the player's visi-\nbility mask and refreshing the display.\nImproved Searching\nThe direct approach to searching involves looking at the occupants of each tile in the\nsearching unit's LOS area. As more units are added into the game, the number of\nsearches each turn increases. In addition, as the radius for each search increases, such\nas with ranged units or LOS upgrades, the number of tiles searched rises very quickly.\nFor example, a single ranged attack unit with a search radius of 10 tiles would have an\narea of about 350 tiles to be searched. Therefore, this direct approach results in a per-\nformance drop proportional to the number of tiles scanned.\nProbably the biggest benefit of using the combined visibility map comes with this\ntask of searching in a unit's LOS for enemy targets or other objects of interest. Rather\nthan search the individual tiles, it's better to keep a running list of the other player's\nunits in a given player's total combined LOS. This is where the combined visibility\nmap comes into play. Each unit in the game accesses the combined visibility map\nentry for the tile it occupies. With this data, each unit knows which players can cur-\nrently see that unit. By saving this information from the previous turn, a unit knows\nwhen it moves into and out of the LOS of every other player in the game, even if it is\nnot moving. In addition, when a change occurs, the unit can add or remove itself\nfrom a list of units visible to the other player. The update overhead is only a single\nDWORD check per unit per turn, except for when the unit has actually transitioned\nin or out of another player's combined line-of-sight.\nThe list that the units add and remove themselves from can then be broken down\nfurther depending on what the unit represents to the player (for example, teammate,\ncombat unit, infrastructure, etc.) The result is that each player will have a series of\nvery small lists, often even empty, containing pointers to other players' units that are\ncurrently in the player's total LOS.\nOnce the lists are maintained, there is no longer a need to search large numbers of\ntiles, most of which probably won't contain possible targets. Instead, searching\n\n\n3.5 A High-Performance Tile-based Line-of-Sight and Search System \n285\nbecomes a process of scanning a far smaller list that contains only possible targets.\nThe search code can be simplified and the lists will cache better. The performance\nimprovement can be an order of magnitude better, especially in situations that involve\nmany long-range units.\nThe following code shows how a unit's update would process the changes in LOS\nvisibility. This code determines for which players its visibility status has changed, and\nsubsequently how to change them.\nvoid GameUnit: :TurnllpdateProcess( . . .)\n{\n// Game specific unit processing code...\n// Now we check to see if we've gone in or out of anyone's LOS\nDWORD CurrentlyVisibleTo =\nCombinedVisibilityMap[Yposition] [Xposition] ;\nif ( CurrentlyVisibleTo != LastVisibleToValue)\n{\n// Get only the bits that have changed\nDWORD VisibilityChanges = CurrentlyVisibleTo A\nLastVisibleToValue ;\nLastVisibleToValue = CurrentlyVisibleTo; \n// Save new value\nfor (int playerNo = 0; player-No < theGame->numOfPlayers;\nplayerNo++)\n{\nDWORD PlayerMask = 0x0001 « playerNo; // bit mask for\nplayer\n// Check to see if our visibility for this player has\nchanged\nif ((VisibilityChanges & PlayerMask) != 0)\n{\nif ((CurrentlyVisibleTo & PlayerMask) != 0)\nAddUnitToPlayersVisibleList ( playerNo , self ) ;\nelse\nRemoveUnitFromPlayersVisibleList ( playerNo , self ) ;\n// Continue with game processing\n}\nAnother benefit of this method is that the searches will respect the player's total\nvisibility and don't need to be restricted in range to the unit's LOS radius. As illus-\ntrated in Figure 3.5.3, each of the player's units at the bottom performs a target search\nwith a search radius greater than its own LOS radius and finds the enemy units visible\nto the player on the upper-left side. However, they also failed to find the two enemy\nunits in the upper right because they are on tiles that are currently fogged to the\nplayer. By respecting the combined LOS and using a search radius not tied to their\nLOS radius, more intelligent and humanlike AI decisions can be made.\n\n\n286\nSection 3 Artificial Intelligence\nVisible tiles\nFogged or un-\nexplored tiles\nTiles occupied\nby a Player's unit\nTiles with player's\n. units searching\nfor enemies\nTiles with enemy\nunits on them\nFigure 3.5.3 Demonstration of which enemy units can be seen by the player. By\nrespecting the total LOS, the searching units will only see the enemy units on the left, even\nthough the units in the FOWare closer.\nThe same processing code can be used for large units that occupy more than one die in\nthe game world. The only difference is that the current visibility value is made by\nORing together the combined visibility map values for each tile occupied, instead of\ntaken from a single tile's value. This also makes it easy to do things like revealing the\nentire map area occupied by the unit, even if the player's LOS only falls on a corner of it.\nMirages are another game capability that the combined visibility map makes easy\nto implement. Mirages are ghost representations of units that appear visually in\nanother player's fogged area, representing what that player last saw when he or she\nexplored the area. Units that can generate mirages do so when they have transitioned\nout of another player's LOS. Also, the mirages know to remove themselves from the\ngame when they detect that they are again fully visible to the other player, by check-\ning the combined visibility map values.\nConclusion\nIt never hurts to rethink a situation, even when it appears simple and straightforward.\nThe development of this approach was the result of asking \"why\" and seeing how\nseemingly unrelated systems could lend each other a hand. The greatly improved\nsearching capability is made possible because of the presence of the combined visibil-\nity map. This only works because the individual player visibility maps are always kept\nup to date, every game tick. Therefore, while the individual systems do their specific\njobs, when joined together, more capabilities are exposed and greater optimizations\nare achievable.\n",
      "page_number": 268,
      "chapter_number": 28,
      "summary": "This gem presents an efficient implementation of a player visibility system\nfor tile-based games that minimizes the performance impact, while providing support\nfor fast searching as well as other game features Key topics include tiles, units, and games.",
      "keywords": [
        "LOS",
        "unit LOS",
        "Combined Visibility Map",
        "player",
        "unit LOS radius",
        "Tile",
        "Unit",
        "visibility map",
        "LOS Radius",
        "visibility",
        "player visibility",
        "Combined Visibility",
        "player units",
        "game",
        "map"
      ],
      "concepts": [
        "tiles",
        "units",
        "games",
        "visibility",
        "map",
        "search",
        "searches",
        "templates",
        "player",
        "function"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 3",
          "chapter": 25,
          "title": "Segment 25 (pages 234-242)",
          "relevance_score": 0.52,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 32,
          "title": "Segment 32 (pages 300-308)",
          "relevance_score": 0.5,
          "method": "sentence_transformers"
        },
        {
          "book": "makinggames",
          "chapter": 39,
          "title": "Segment 39 (pages 340-347)",
          "relevance_score": 0.47,
          "method": "sentence_transformers"
        },
        {
          "book": "makinggames",
          "chapter": 40,
          "title": "Segment 40 (pages 348-355)",
          "relevance_score": 0.46,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 7",
          "chapter": 51,
          "title": "Segment 51 (pages 495-502)",
          "relevance_score": 0.43,
          "method": "sentence_transformers"
        }
      ]
    },
    {
      "number": 29,
      "title": "Segment 29 (pages 276-286)",
      "start_page": 276,
      "end_page": 286,
      "detection_method": "topic_boundary",
      "content": "3.6\nInfluence Mapping\nPaul Tozour\ngehn29@yahoo.com\nW\ne consider a game AI agent to be \"intelligent\" if it consistently makes decisions\nthat we consider appropriate in a given context. Thus, we can say that the core\nof intelligent game AI is decision-making.\nEveryday experience teaches that the key to effective decision-making is not\nmerely having the best data, but presenting the data in the right way. Raw data is use-\nless until converted to contextual information. An appropriate representation of the\ndata will force the relevant underlying patterns to reveal themselves.\nThis and the subsequent gem on strategic assessment present techniques for giv-\ning AI agents a well-informed tactical and strategic perspective on the character of the\ngame world and the current game state. We also discuss techniques relevant to differ-\nent game genres and virtual environments.\nInfluence Maps\nInfluence mapping is an invaluable and proven game AI technique for performing\ntactical assessment. Influence maps have been used most often in strategy games, but\nare also useful for many other types of games that require an aspect of tactical analy-\nsis. The general concepts of influence mapping are an essential part of any AI devel-\noper's toolkit.\nAn influence map is a spatial representation of an AI agent's knowledge about the\nworld. It allows a computer player to develop a tactical perspective of the current\ngame state layered on top of the underlying physical/geographical representation of\nthe game environment. An influence map indicates where a computer player's forces\nare deployed, where the enemy is located or is most likely to be found, where the\n\"frontier\" between players lies, what areas remain to be explored, where significant\nbattles have occurred, and where its enemies are most likely to attack it in the future.\nThe structure of the influence map also makes it possible to make intelligent infer-\nences about the characteristics of different locations in the environment. Influence\nmaps can pick out areas of high strategic control, pinpoint weak spots in an oppo-\nnent's defenses, identify prime \"camping\" locations or strategically vulnerable areas,\nfind choke points on the terrain, and identify other meaningful features that human\nplayers would choose through intuition or practice.\n287\n\n\n288\nSection 3 Artificial Intelligence\nThere is no single, standard algorithm for creating influence maps, nor any single\nway to apply the technique. This gem describes several of the more popular influence\nmapping concepts, but it is only a starting point. The way you construct and employ\ninfluence maps will depend heavily on the specific strategic and tactical needs of your\nparticular game and the design of the game world that your AI agents inhabit.\nA Simple Influence Map\nAn influence map can operate in almost any type of game world topography—a\nsquare grid, a hexagonal grid, or a fully 3D environment. For the sake of simplicity,\nmost of this gem assumes a 2D grid, which is applicable to most strategy games. The\nfinal section of this gem discusses applications in more complex environments.\nWe begin with a set of square cells superimposed on our game world. All the cells\nare initialized with a value of zero. For each cell, we add a certain type of \"influence\"\nwe wish to consider. For the sake of this example, we'll compute an estimate for \"com-\nbat effectiveness.\" We'll add a positive value for each friendly unit, and a negative\nvalue for each enemy unit.\nThe specific value we add or subtract will be an estimate of the unit's combat\neffectiveness. For the moment, we'll assume that each unit has an effectiveness rating\nof 1, as shown in Figure 3.6.1.\nThe next step is to spread the influence of each cell to nearby cells. For now, let's\nassume that we propagate each cell's influence such that each time the influence is\nspread to a neighboring cell, it is diminished by 50 percent. Therefore, a value of 4\nwould add two points to each adjacent cell, one point to each cell two squares away,\nthen 1/2, and so on.\nFigure 3.6.2a shows how the influence of our two bugs spreads across the influ-\nence map. The influence of our two opponents—the sinister and nefarious agents of\n-1\n-1\nFIGURE 3.6.1 Initial influences.\n\n\n3.6 Influence Mapping\n289\nthe dreaded Ford Motor Company—will propagate in a similar way (not shown), but\ntheir influence values will be negative because we hate them.\nWhen we combine the influences of all the cars and bugs, we end up with Figure\n3.6.2b. It should be immediately clear that this gives us an excellent sense of where\neach player wields influence. Darker cells belong to us; lighter cells belong to our\nopponent. More importantly, we can now trace a contour for the \"frontier\" between\nfriendly and hostile assets. The frontier is defined as any part of the grid where two\nadjacent cells shift between negative and non-negative values. This is shown as an out-\nlined white line in Figure 3.6.2b.\n+0.7\n+1\n+0.7\n+0.35\n+1\n+2^\n*\n+1\n+0.5\n+0.7\n+1\n+0.7\n+0.35\n+0.35\n+0.5\n+0.35\n+0.24\nFIGURE 3.6.2 A) Influence propagation. B) The final influence map.\nWe can use this frontier to determine where to place our forces for offense or\ndefense. By weighting the enemy's forces more heavily than our own (using a multi-\nplier greater than one), we can pull the frontier closer to our own forces for a more\ndefensive posture. If we weight our own forces more heavily, we push the frontier for-\nward and develop toward a more aggressive posture.\nInfluence Map Cell Data\nThe preceding example is clearly trivial. An influence map in a real game is consider-\nably more sophisticated. Rather than simply containing a number, each of the influ-\nence map's \"cells\" is a repository for some amount of data about the game world. Each\ncell is, in effect, a miniature database of relevant data for all the units and resources\nthat occupy that cell. Following are examples of some of the types of statistics that a\ncell will typically contain.\n\n\n290 \nSection 3 Artificial Intelligence\n• Combat strength. This is the estimated combat effectiveness of the units cur-\nrently in the cell. This should take into account factors such as attack/defense\nstrength, current health or hit points, attack range, rate of fire, and so on. It may\nalso be advisable to break units into categories in a manner appropriate to the\ndesign of your particular game; for example, to account for the relative strengths\nof ranged versus melee, infantry versus cavalry, or flying versus land-based versus\naquatic units.\n• Vulnerable assets. This is an estimate of the value of a player's current assets in\nthe cell, such as a part of a village or military base in a typical strategy game.\n• Area visibility. This is a number indicating how long the area has been visible or\ninvisible to the player.\n• Body count. Indicates how many units have died in the cell in the past, and\nwhen.\n• Resources. The total resources still available for exploitation—gold, lumber, etc.\n• Passability. An estimate of the difficulty of moving through the cell, possibly\nbroken down by movement type (flying, walking, tracked, etc.) This value is\nused to more accurately propagate a cell's influence to neighboring cells, and can\nfactor into the cell's desirability for a given decision. A good variant is to sepa-\nrately store eight passability values, one for each of the directions exiting the cell.\nAn influence map will typically track these variables for each player in die game\nseparately. Think of this as maintaining multiple parallel influence maps: each player\nupdates an influence map for its own assets, plus an additional influence map to repre-\nsent its own knowledge of every other player. This is useful as it allows you to distin-\nguish the particular strengths and weaknesses of specific opponents, or to blend any set\nof friendly or enemy influences together as desired. Be warned, however, that perfor-\nmance can quickly get out of hand with more than three or four competing AI players.\nOf course, you could also just keep a single influence map for everyone, and let\nevery AI player access it. In a game with any kind of hidden map or fog-of-war\n(FOW), this constitutes \"cheating,\" and it could produce suboptimal behaviors in\nsome situations.\nComputing Desirability Values\nRather than using the basic statistics for each cell directly as a basis for decision-\nmaking, it's more useful to combine them into a \"desirability value.\" This is a com-\nputed value which estimates the cell's \"value\" with regard to a certain decision. By\ncomparing the desirability values of different cells, we can construct a ranking of\nwhich cells appear to be \"better\" for the task than others.\nThe most useful formula for desirability is often a simple weighted sum. Pick the\nvariables from each cell that you consider relevant for the decision at hand, multiply\neach by a coefficient that roughly indicates that factor's relative utility in making the\ndecision, and add the resulting values to determine desirability.\n\n\n3.6 Influence Mapping \n291\nThe specific parameters you select to calculate different desirability values will\ndepend strongly on the particular needs of your game and the unique characteristics\nof your game design. The choice of appropriate coefficients is also subjective and is\nbest achieved through careful tweaking and tuning. Simulated annealing or competi-\ntive evolutionary approaches are feasible, but probably not desirable. Be forewarned\nthat you will also need to compensate for the different units of measurement that you\nuse for statistics such as unit health/hit points, rate of fire, attack strength, and so on.\nA short list of sample desirability values follows.\n• Attack and defense desirability. We can typically compute a single \"vulnerabil-\nity\" score to represent defense and attack capabilities for this player and his ene-\nmies, respectively. A high vulnerability score for an enemy means we can damage\nthe assets in that area easily, so we should consider attacking the enemy in that\ncell; a high vulnerability score for this AI player means that we have significant\nassets in the cell that are susceptible to attack, and we should defend them more\ncarefully.\nVulnerable areas are typically those with many assets and key resources but\nminimal opposing military units nearby. Therefore, if an enemy player has a value\nof 80 for \"assets\" in a given cell (representing its base buildings and resources) and\nan enemy offensive value of 60 (representing the enemy forces that could poten-\ntially defend it), the final \"vulnerability\" rating is 20.\n• Exploration. For strategy games that use a hidden map or FOW, a good AI\nplayer will dispatch scouts on a regular basis to refresh its view of the battlefield.\nA good heuristic for exploration is to rank the influence map cells that have gone\nunseen the longest as the most desirable for exploration. Other good factors in\nthis decision are the enemy influence in a cell and the area's estimated passability\n(so your scouts can escape if attacked).\n• Defensive asset placement. Immobile defensive assets should be placed in areas\nclose to lots of vulnerable assets. They should be in areas vulnerable enough to be\nworth defending, but not so vulnerable that they can't be constructed.\nChoke points are also good spots for defensive assets. Terrain choke points can\nbe easily identified on die influence map using precomputed passability values;\nchoke points will be high-passability influence map cells that connect other high-\npassability areas but are surrounded by low-passability cells.\n• Resource-collection asset placement. Assets that serve as resource collection\npoints (Town Centers) are typically most effective in easily defensible areas that\nare as close as possible to the largest amounts of exploitable resources.\n• Unit-producing asset placement. Unit-producing assets (such as a Barracks)\nshould typically be placed in defensible areas closest to enemy forces.\n• Vulnerable asset placement. Assets that need to be protected should be placed in\nthe most defensible areas, and the farthest from potential threats. It's also usually\na good idea to place such assets in less accessible areas to shield them from attack.\nFor flat, rectangular game worlds, it's also often a good idea to consider that map\n\n\n292 \nSections Artificial Intelligence\ncorners have fewer avenues of approach and so are often less vulnerable, so you\ncan weight the desirability values higher at the sides and corners of the map.\nDetermining Optimal Cell Size\nThe size of the influence map cells is somewhat arbitrary. It's a trade-off between accu-\nracy and efficiency. With cells that are too large, your influence maps will have a dif-\nficult time identifying small features, such as terrain choke points or weak spots in\nenemy defenses. If the cells are too small, things will get out of hand fast; you'll end\nup doing a lot of redundant computation and possibly using a lot of memory as well.\nIn practice, it's usually best to make the cells fairly large. Avoid the temptation to\nassume that smaller cells will make the AI smarter. For a typical strategy game, I rec-\nommend (as a starting point) making each cell large enough to fit 10—20 of your\ngame's standard \"units\" side by side along the width or height of the cell, and carefully\ntune the cell size from there to obtain the best results in gameplay.\nSome readers may note that the arbitrary positioning of the cells over the map\ncould be problematic. A unit straddling two neighboring influence map cells will have\na different effect depending on which of the two cells receives its influence. This will\nusually not be an issue due to the \"influence propagation\" described in the next sec-\ntion. However, a good way to handle the problem is to modulate the (X, Y) world-\nspace offset of the entire influence map on a regular basis (perhaps each time you\nrecalculate the influence map), using either a random or periodic offset. This is akin\nto a fishing net floating on the ocean that is washed back and forth by the waves.\nInfluence Propagation\nOnce you have calculated an initial value for each cell of the influence map, the next\nstep is to propagate the value of each cell to some number of nearby cells, as in the\nearlier example. This process is also referred to as smoothing or blurring as it has a lot\nin common with standard 2D image blurring techniques (see [EvansOl]).\nInfluence propagation gives us a much more accurate picture of the current tacti-\ncal situation. We don't care only about where units are and what they're doing; we care\nabout what they might do—what areas they potentially \"influence.\" If we have a pair\nof Archers in the field flanked by large battalions of Plasma Tanks on either side, we\nwant our AI to perceive that the area the Archers occupy is really \"owned\" by the\nenemy. We need to propagate the Tanks' influence to the cell the Archers occupy.\nPropagation is just a matter of spreading the influence of each cell to neighboring\ncells using a \"falloff rule\" that determines how the influence of a given cell decreases\nwith distance as it spreads across the map. The selection of a particular falloff rule is\nsubjective and there is no single accepted technique—-as always, you will need to\ntweak and tune for optimal results. I typically find exponential falloff the most useful:\npick a falloff constant between 0 and 1 (typically 0.6 < n < 0.8), and each time you\nspread influence to a neighboring cell, use this constant as a multiplier. Given a falloff\nconstant of 0.75 (=75%), a neighboring cell will have 0.75 = 75% of the original\n\n\n3.6 Influence Mapping \n293\nvalue. A cell two squares away will have (0.75)2 ~ 0.56 = 56% of the original value, a\ncell three squares away will have (0.75)3 ~ 0.42 = 42%, and so on. The falloff constant\nshould be proportional to the cell size: smaller influence map cells require a larger\nfalloff value to spread the influence the same distance.\nOther useful falloff rules include linear falloff (in which a cell's influence\ndecreases by a constant value each time it spreads to a neighboring cell) and Gaussian\nfilters (see [EvansOl]).\nNote that if you use floating-point numbers, your propagated influence values\nwill never actually reach zero regardless of how far you spread them. This means that\neach cell will end up spreading its influence to every other cell in the entire influence\nmap. The literature consistently refers to this phenomenon as \"a bad thing.\" The sim-\nplest solution is to terminate propagation at a certain minimum influence value (usu-\nally a value beneath which the smoothed influence would be too tiny to make a\ndifference anyway). This cutoff constant is best determined by experimentation.\nNote, however, that it's usually a good idea to spread a cell's influence a fair dis-\ntance. If your influence map consists of many small cells and the cells' influence is not\npropagated very far, you will likely end up with a lot of empty space (in other words,\na lot of zeroes) in the influence map, and it will be difficult to determine exactly where\nthe frontier lies. Use big cells, and spread their influence a good distance.\nThere is also an interesting alternative influence propagation technique based on\nquadtrees. All cells' values are passed up the quadtree to each higher layer, so higher-\nlevel quadtree cells can be used to obtain approximate \"smoothed\" values for their\nchild cells. Unfortunately, this approach spreads cells' influence in a somewhat arbi-\ntrary fashion. The distance that a cell's influence is propagated is tightly bound to the\nstructure of the quadtree, and influence might be propagated far more in some direc-\ntions than others. I find this technique less flexible and often less accurate than the\npropagation technique described earlier.\nAccounting for Terrain\nThe propagation technique described here does not necessarily paint an accurate pic-\nture in all situations. Imagine that a powerful enemy wizard has a fortress on one side\nof a mountain range. The propagation technique will spread the influence of the\nfortress over the mountains even if the wizard has no way to attack us over the moun-\ntains, and cannot navigate any of his units over or around them.\nThere are several ways to account for the impact of terrain on the influence map.\nProbably the simplest is to use a precomputed passability value for each cell and use\nthis as a multiplier for falloff values, as shown in Figure 3.6.3. Each cell contains\neither a single passability estimate or a set of four or eight passability values in the car-\ndinal directions exiting the cell. We then spread the influence from the cell in a man-\nner similar to a breadth-first search or the flood-fill algorithm. Although Figure 3.6.3\ndoes not show it, this can also handle cells where influence is merely diminished and\nnot blocked entirely.\n\n\n294\nSection 3 Artificial Intelligence\nFIGURE 3.6.3 Spreading around terrain.\nA second technique involves precomputing all possible paths between nearby\nneighbors (Figure 3.6.4). For each cell, we perform a pathfinding step during map\npreprocessing that determines the shortest path from that cell to all neighbor cells up\nto a maximum path distance away. We can then store the computed distance to each\ntarget cell and use this as the actual \"distance\" to the neighboring cell when perform-\ning the propagation step. We consider a cell to be unavailable for influence propaga-\ntion if no path exists.\nFIGURE 3.6.4 \nPrecomputedpropagation.\n\n\n3.6 Influence Mapping \n295\nThe advantage of this technique is that it provides very accurate influence propa-\ngation. If there is an easy way to navigate around the mountain range, such as a pass\nthrough the center of the mountains, the influence map propagation will accurately\nreflect the fact that the mountains are not a significant tactical obstacle.\nUnfortunately, this technique is difficult to apply to dynamic environments. If\nyour game world allows players to build extended walls or to block off mountain\npasses, the precomputed propagation values no longer reflect reality, and it may be\nvery difficult to update your influence map in real time. This method can also poten-\ntially require a lot of preprocessing time, as it requires us to perform pathfinding from\neach cell in the influence map to potentially dozens or hundreds of other cells.\nSpecial Considerations\nTerrain will have different effects on different units. Flying units will not be stopped\nby mountains, and seafaring units will spread their influence over water but not over\nland. Therefore, it's important that each influence map cell track such different unit\ntypes separately (for example, track \"flying\" vs. \"nonflying\" assets in each cell), and\npropagate their values differently according to the terrain type.\nQuite often, certain units will have very long firing ranges, and if a unit can fire a\ncertain distance, then it can also fire that distance from any point to which it can move.\nA good way to account for this is for each influence map cell to separately track ranged-\nfire units according to the distance they can fire (possibly categorized as multiples of\nthe width of an influence map cell). After spreading the influence for these ranged dis-\ntance categories using propagation, we then spread the influence an extra TV cells from\neach influenced cell without diminishing the value. This way, we can account for a bat-\ntleship's ability to strike far into the shore, even though it can't go on land.\nYou may also find it useful to add mobile units to the map based on their pro-\njected future positions rather than their current positions. This makes the influence\nmap a bit more accurate, particularly if you don't recalculate the influence map very\noften. The simplest approach is dead reckoning—estimate each unit's position per-\nhaps 5—10 seconds from now based on its velocity vector. Since you're presumably\nwriting the AI, you might also simply look up each unit's future position if the unit is\nperforming pathfinding (although of course this may constitute cheating if an AI\nplayer looks at other players' chosen routes).\nRefreshing the Influence Map\nIf your AI needs to analyze large portions of the influence map on a regular basis, it\nmay make sense to recompute the entire influence map on a regular basis, perhaps\nevery 1-10 seconds. Considering the pace of a typical strategy game, a faster refresh\nrate will probably not produce a more effective AI. Once the influence map is com-\nputed, you can then use it to perform many calculations extremely quickly.\nA second approach is demand-based refreshing, a sort of lazy evaluation technique.\nThis is a more flexible approach, and is more efficient when you need to perform less\n\n\n296 \nSection 3 Artificial Intelligence\nextensive influence map analysis. With this variant, you compute the values in a given\ncell only when the cell is actually queried, searching all the neighboring cells within a\ngiven maximum distance to see how their values propagate back to the original cell.\nThis technique has the added advantage that you can specify the propagation parame-\nters and desirability value coefficients at query time.\nInfluence Maps in 3D Environments\nThis gem has focused thus far on applications in 2D environments. However, influ-\nence mapping and related approaches are also broadly applicable to more complex\nenvironments such as the 3D environments of typical action games.\nUsing a 2D grid for 3D influence mapping is usually a bad idea, as it will not\naccurately reflect the topography of our game environment. Fortunately, AI pathfmd-\ning in 3D environments is usually (though, alas, not always!) based on a navigation\nmesh approach (see [SnookOO]). A navigation mesh consists of a graph of intercon-\nnected convex polygons that describe where characters can move in the game world.\nWe can use each polygon of the navigation mesh as an influence map cell. The links\nbetween polygons can describe the avenues for influence propagation. Influence\ndecreases according to the length \"traveled\" along each mesh node.\nBecause 3D game worlds are more topographically complex than 2D worlds and\nthe emphasis is usually on individual combatants, terrain assessment is typically more\nimportant than the real-time player-versus-player tactical assessment that an influence\nmap can provide. It's critical that our AI agents can pick out the tactical significance of\ndifferent areas. The following list explains some of these tactical assessment factors.\n• Vulnerability (\"cover\"). 3D action games typically involve firing powerful\nweapons over large distances, so it's critical to take into account the range of pos-\nsible fire locations to and from each cell of the influence map. AI agents often\nneed to determine the degree of \"cover\" in a given cell. A simple approach is to\ncalculate an estimate for the degree of cover for each of the six faces of a cube pro-\njected from each influence map node.\nHowever, we often want to know whether a given cell (potential destination)\ncan shoot or be shot from another cell (enemy position). A good line-of-fire rep-\nresentation would list the set of nodes that are \"attackable\" from any given\nnode—but this could quickly get out of hand for large and highly interconnected\nenvironments that approach an N2 degree of interconnectivity. A good solution is\nto package groups, of influence map nodes into \"zones,\" such that all nodes in a\ngiven zone are in the same \"room\" or \"portal,\" and use this representation to\ndetermine which zones are potentially vulnerable from other zones.\n• Visibility. This is similar to vulnerability, except that it disregards weapon dis-\ntances, takes illumination levels into account, and can pass through certain sur-\nfaces that weapons fire cannot, such as reinforced glass. This calculation becomes\ntricky when dynamic lighting is used, and lights can be turned on and off.\n\n\n3.6 Influence Mapping \n297\n• Passability. As before, this is an estimate of the difficulty of moving through an\narea. Tight passages are usually more difficult to move through, and elevators, lad-\nders, and odier such routes cause slow movement and thus have low passability.\n• Height advantage. Locations with a high elevation relative to surrounding loca-\ntions are usually tactically superior for both offense and defense, particularly if\nthe game features hand grenades.\nThese are the basic precalculated statistics in our influence map cells. We can now\nwhip out a few coefficients and compute desirability values.\nThe best locations for offense are typically those with high passability, high cover,\nand low visibility, but which also have a good line-of-fire to many areas of high visi-\nbility (and, ideally, low passability). Good offensive locations also usually have good\ncover locations nearby in case the agent comes under fire.\nThe best defensive locations are those with the highest cover and lowest visibility,\nand for which all the potential attacking locations have high visibility.\nMore to the point, if we precalculate these desirability values for all the nodes, we\nthen can propagate these values to their neighbors using our standard influence map-\nping techniques and end up with a complete tactical assessment of the level.\nFinally, note that we can also use the influence map to make inferences about our\nopponents—we can determine their respective levels of cover, visibility, passability,\nand height advantage. We can use this to select the best opponent to attack at any\ngiven moment, or to search for a destination that has an advantage over any or all of\nour opponents.\nAnother useful extension is to estimate opponents' most likely positions in the\nnear future by finding the most desirable destinations available to them. This will\nallow us to prepare for our enemies' actions, and have the ambush already prepared.\nReferences and Additional Reading\n[comp.ai.games95] The seminal 1995 \"influence mapping\" thread on comp.ai.games\n(various authors) is reprinted at www.gameai.com/influ.thread.html.\n[EvansOl] Evans, Alex. \"Four Tricks for Fast Blurring in Software and Hardware,\"\navailable online at www.gamasutra.com/features/20010209/evans_01.htm.\n[PottingerOO] Pottinger, Dave. \"Terrain Analysis in Realtime Strategy Games,\" avail-\nable online at www.gdconf.com/archives/proceedings/2000/pottinger.doc.\n[SnookOO] Snook, Greg. \"Simplified 3D Movement and Pathfinding Using Naviga-\ntion Meshes\" from Game Programming Gems I (Ed. Mark DeLoura, Charles River\nMedia, 2000).\n[SterrenOl] van der Sterren, William. \"Terrain Reasoning for 3D Action Games.\"\n[Zobrist69] Zobrist, Albert L. \"A Model of Visual Organization for the Game of Go.\"\nThe seminal article on influence mapping. Proc. AFIPS 1969 Spring Joint Com-\nputer Conf. 34: pp. 103-112.\n",
      "page_number": 276,
      "chapter_number": 29,
      "summary": "This chapter covers segment 29 (pages 276-286). Key topics include cells, influence, and influenced. Everyday experience teaches that the key to effective decision-making is not\nmerely having the best data, but presenting the data in the right way.",
      "keywords": [
        "influence map",
        "influence map cells",
        "Influence",
        "cell",
        "map",
        "Influence Mapping",
        "cell influence",
        "map cells",
        "game",
        "entire influence map",
        "Influence propagation",
        "influence map propagation",
        "neighboring influence map",
        "game world",
        "Simple Influence Map"
      ],
      "concepts": [
        "cells",
        "influence",
        "influenced",
        "game",
        "value",
        "mapping",
        "maps",
        "map",
        "unit",
        "player"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 7",
          "chapter": 25,
          "title": "Segment 25 (pages 238-245)",
          "relevance_score": 0.58,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 28,
          "title": "Segment 28 (pages 261-272)",
          "relevance_score": 0.57,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 22,
          "title": "Segment 22 (pages 205-213)",
          "relevance_score": 0.54,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 23,
          "title": "Segment 23 (pages 214-221)",
          "relevance_score": 0.51,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 3",
          "chapter": 21,
          "title": "Segment 21 (pages 198-207)",
          "relevance_score": 0.48,
          "method": "sentence_transformers"
        }
      ]
    },
    {
      "number": 30,
      "title": "Segment 30 (pages 287-294)",
      "start_page": 287,
      "end_page": 294,
      "detection_method": "topic_boundary",
      "content": "3.7\nStrategic Assessment\nTechniques\nPaul Tozour\ngehn29@yahoo.com\nT\nhis gem describes a suite of useful techniques for strategic decision-making.\nWhere the previous gem on influence mapping provided a means for tactical\nassessment on a geographical level, these data structures provide an AI agent or player\nwith a means of assessing the current game state on a strategic and functional level.\nThese techniques are most clearly applicable to games that involve some aspect of\neconomic management, resource-allocation decisions, and/or technological advance-\nment, such as strategy games, economic simulations, and \"god games.\" However,\nthere are doubtless many potential applications to other genres as well.\nThe Resource Allocation Tree\nThe resource allocation tree is a tree structure that represents the specific functional\npurpose of all the assets under a player's control. The tree breaks down all of the units\nand resources currently in play into a hierarchy of functional categories.\nThe usefulness of this representation derives from its ability to allow an AI player\nto evaluate the strategic strengths and weaknesses of all of the players in the game,\nitself included. The tree also provides an excellent basis for a wide variety of economic\nproduction and resource-allocation decisions. For example, it provides an immediate\nbasis for determining what types of new units to produce and how to reallocate exist-\ning units into different functional roles.\nAt the top of the tree is a root node that represents a player's total assets. Directly\nbeneath the root is a breakdown of the major different categories of assets available in\nthe game.\nLet's imagine we break this down into Military, Economic, and Intelligence. Each\nof these is broken down further into subcategories. Military might be broken down\ninto Offense and Defense, for example, and each of these could be broken down into\nBallistic, Ranged, and Melee to indicate different functional roles for military units.\nEconomic would likely be broken down into Resource Gathering, Unit Production,\nBase Construction, Tech Advancement, and so on down the tree. Figure 3.7.1 illus-\ntrates a small slice of the resource allocation tree.\n298\n\n\n3.7 Strategic Assessment Techniques\n299\n(...) \n(...)\n(...)\nFIGURE 3.7.1 The resource allocation tree.\nThe leaves of the tree are the specific types of units available. For example, \"Pike-\nmen\" sits in Root/Military/Offense/Melee/Pikemen. The Pikemen node itself would\nlikely include various statistics on all the Pikemen we've dedicated to an offensive\ncapacity, such as the total quantity, total hit points, total number of Pikemen killed in\ncombat, and so on.\nJust as with an influence map, an AI player should maintain a separate instance of\nthis data structure for each player in the game, including itself. The graphs for the\n\n\n300 \nSection 3 Artificial Intelligence\nother players will represent this player's current knowledge and best estimates of the\nfunctional breakdown of each player's current strategic assets.\nA Pikeman is primarily a defensive unit, but it could also be used for attack or\nexploration. This raises the question of how to categorize a single species of unit that\ncan participate in multiple functional roles.\nAn AI player will typically dedicate a given unit to only one functional role at any\ngiven moment, so I recommend categorizing units in terms of their current functional\nemployment rather than attempting to split a single Pikeman into, say, 10% Explo-\nration, 60% Defense, and 30% Offense. The Pikeman nodes beneath Offense,\nDefense, and Exploration should represent the Pikemen that are currently allocated to\neach of those functional roles.\nIt's also important to note that at any given moment, the resource allocation tree\ncontains only those assets that I actually possess or am currently capable of producing.\nIf I have no Mage Towers and can't currently build one, there is no reason to include\nit as a node in the tree.\nCalculating Desired Allocation\nThe structure of the resource allocation tree provides us with a very simple and nat-\nural means for determining appropriate resource allocation. We can rank the intended\npriority of each node in the tree by proceeding down the graph from the root.\nBegin with a value of 1.0 at the root, indicating a desired 100% resource alloca-\ntion. At each node, we split the current value into an appropriate fraction of the\ndesired allocation for each child node. Starting from 1.0, we break this value down\ninto Military = 0.3, Intelligence = 0.1, and Economic = 0.6. Under \"Military,\" we\nbreak this 0.3 down further into 67% Defense and 33% Offense (Defense = 0.2 and\nOffense = 0.1). This process continues down the tree so that we calculate a \"desired\nallocation\" value for each tree node.\nThe algorithm for determining the numeric breakdown at each node will depend\non the design of your game. Each nonleaf node will require custom logic code to con-\ntinuously update the distribution to its child nodes in response to the evolving state of\nthe game world. This is a matter of tweaking and tuning to achieve optimal results.\nInitially it's often a good idea to simply take a few guesses and use predetermined con-\nstants until you get a good sense of what specific factors should cause the computer\nplayer to change these weights as a given game session unfolds.\nDetermining Current Allocation\n«m:::.:~: \n:::-::-:-::--::™::::'::~:^:^:::-:~;::-::Tr::\":::v::\":-::'::\":::^::-:--:':^^\nSimultaneously, we can use the tree to calculate a \"current allocation\" value for each\nnode. This gives us a breakdown of the assets we actually possess.\nThis calculation proceeds in the opposite direction, from the bottom of the tree\nup to the root. We iterate over all the Pikemen currently allocated to Defense, for\nexample, and calculate some value indicating every defensive Pikeman's estimated\n\n\n3.7 Strategic Assessment Techniques \n301\nvalue (say, by multiplying an attack strength value for Pikemen by that specific Pike-\nman's current hit points). We then add all these Pikemen's scores together and mark\nthis as the current allocation value of the Pikeman node beneath Defense/Melee. We\nthen pass this number up to the parent node (Melee), which adds together all of\nthe numbers it receives from its children (such as all the Spearmen and Footmen we've\nallocated to Defense) and forwards this number up to its parent (in this case,\nDefense). Ultimately, the root node receives input from all of its children, and we end\nup with a fat floating-point number at the root that indicates the total current assets\nof all our possessions in the game world.\nOnce we've generated this value for \"total assets,\" we can renormalize to values\nbetween 0 and 1. Revisit each node in the tree and divide its \"current allocation\" value\nby the root node's value, so that the root node again has a value of 1.0.\nAt this point, it should be obvious that we can directly compare the current allo-\ncation value in each tree node to the desired allocation value to trivially determine how\nfar we are over or under budget in any particular capacity.\nStrategic Decision-Making\nIt should be apparent that the final allocation tree representation instantly provides us\nwith an excellent way of organically maintaining the balance of our forces. If I'm in a\nbattle and I lose all 20 of my Elephants, the Elephant node and all its parent nodes are\nnow under-allocated relative to their desired allocation.\nOf course, this won't necessarily mean that I replace all my Elephants with new\nElephants. As the parent node of Elephant receives the resources it needs to fill in new\nchild nodes, it may decide that the best course of action is to build a battalion of\nPlasma Tanks now that it's uncovered the requisite technologies.\nThe resource allocation tree is useful primarily for deciding which new units to\nconstruct and how to allocate existing units to the most appropriate roles. The first\npriority is usually to find those nodes that are most desperately in need of additional\nallocation, and then determine whether this is more appropriately addressed by real-\nlocating existing units or by creating new ones.\nThe resource allocation tree also gives us a good way to design unique player per-\nsonalities. Developing an expansionist, military-oriented \"Genghis Khan,\" an eco-\nnomically obsessive capitalist, or a research-oriented technocrat is just a matter of\ntweaking the coefficients for the appropriate parts of the tree to favor or disfavor spe-\ncific nodes. With a little tweaking at different parts of the tree, AI players can be made\nto favor individual species of units, different balances of growth versus defense, spe-\ncific strategic categories of assets, or overall play styles.\nWhere combat is concerned, it's often a good idea to keep a precomputed \"com-\nbat balancing table\" of relative unit strengths, and use this for making decisions under\nthe Military branch of the tree. This is essentially a 2D lookup table that allows you\nto determine the general effectiveness of any unit in combat against any other. By ana-\n\n\n302 \nSections Artificial Intelligence\nlyzing the functional asset tree that represents your knowledge of a particular enemy,\nyou can determine the composition of his forces and emphasize the production of the\nassets that will be most effective against them.\nFinally, the resource allocation tree is an excellent place to store all types of addi-\ntional statistics. Several of the factors we would typically track in an influence map\ncell are also appropriate to a functional asset tree node.\nIt's also often a good idea to track which nodes in the tree have proven effective in\nthe past, and which nodes have been attacked by enemy players. In die former case, it\nwould allow me to detect that my Pikemen have served me well against another\nplayer, and to use this to direct my growth and development toward the functional\nroles that made my Pikemen victorious. In the latter case, it will allow me to detect\nthat my enemy has a proclivity for attacking my resource-gathering units (for exam-\nple), and to take additional steps to protect them in the future.\nMeasuring Value\nProbably the most significant challenge with this technique is finding an appropriate\nway to measure each unit's value in its particular branch of the tree. The numeric\nunits used in each node need to be commensurate with all other units' values in their\nrespective branches. Values under the Military branch should represent units' contri-\nbutions in combat, and should take into account attack strength, rate of fire, move-\nment speed, armor value, current hit points, and any other appropriate parameters.\nValues in the Intelligence branch should take into account factors appropriate for\neach unit's exploration ability, such as visibility range and movement speed, but prob-\nably not attack strength or hit points. Nodes in Resource Collection (under Eco-\nnomic) should take into account how quickly each resource-gatherer can collect\nresources, drop them off at the depot, and get back to the resources again. Finding an\nappropriate way to correlate these values is, like so much else in game AI, a matter of\nexperimentation to find the optimal solution for your particular game.\nAnother potential challenge is handling economic systems with multiple resources.\nIn games where different units cost different amounts of, say, gold, energy, and\ntiberium to produce, a single allocation value does not translate directly into a single\nresource. The potential solutions to this problem are beyond the scope of this gem.\nThe Dependency Graph\nThe dependency graph is a data structure that models all the dependencies between the\ndifferent types of assets in the game. The dependency graph encompasses all depen-\ndency-based relationships, such as a game's \"tech tree\" and \"building tree.\"\nThe primary dependency type is a creational dependency. This indicates some\nnumber of conditions that must exist before a given species of asset can be con-\nstructed. For example, you must possess a Barracks before you can build a Pikeman.\nYou must construct a Castle before you can reach the Imperial Age.\n\n\n3.7 Strategic Assessment Techniques\n303\nFIGURE 3.7.2 The dependency graph.\nCreational dependencies can also include resource dependencies and other, more\nabstract dependencies. A Barracks requires gold and lumber. Gold and lumber come\nfrom the labors of peasants. Peasants get the gold from a gold mine and lumber from\nthe forest.\nFigure 3.7.2 shows a tiny sample dependency graph comprised solely of cre-\national dependencies. A peasant can create Barracks and Archery Ranges, but the\nArchery Range can only be constructed after reaching the Medieval Age.\nThe second type of dependency is a support dependency. A Mage unit might\nrequire mana, which can only be generated by a Shrine. Without a shrine, the Mage\nwill be essentially useless, as he cannot cast spells without a Shrine to feed him his pre-\ncious mana.\nAs with the previously discussed data structures, an AI player should maintain\nseveral parallel dependency graphs, one for itself and one for each of the other players.\nDependency Graph Nodes\nA given node in a dependency graph will typically contain several different types of\ndata. Useful categories include the total number of units of that type that the player\ncurrently possesses (or is believed to possess, if we are looking at another player); the\ntotal estimated value of those units; and the number of those assets currently in pro-\nduction (being created by a Barracks, for example). Given the overlap between their\n\n\n304 \nSections Artificial Intelligence\nconcerns, it may be possible for a \"node\" in the dependency graph to be similar to a\n\"node\" in the functional asset tree, or even be the same physical data structure. The\nmain difference between the two is that the resource allocation tree tracks only the\ncurrently available assets, while the dependency graph tracks all possible assets.\nEconomic Planning\nThe first and most obvious use for a dependency graph is building toward a goal. A\ncomputer player can use the dependency graph to determine what it needs to build in\norder to be able to produce a given asset. \"I know I want to build a Wizards' Tower\neventually, so to get there, I need to build a Library, and then secure a suitable source\nof mana, and then start building a Mage Hall\nThe choice of which dependencies to fill in first is a trade-off between reacting to\nthe present and planning for the future. A purely reactive AI will use the resource allo-\ncation tree to rank all the assets it can potentially create immediately and pick the best\navailable node. A more planning-oriented AI will analyze all the nodes in the graph to\nfind a long-term goal worth pursuing, query the functional asset tree to determine\nwhich dependencies are likely to be the most valuable, and build toward the most\npromising technology, however deep in the graph it may be.\nNote that this process becomes tricky when there are several possible ways to ful-\nfill a dependency—when either A or B will allow C. This seldom happens in practice,\nas game designers wisely avoid these types of dependencies. In a situation in which\nthere are so many optional dependencies that the best route to a given node isn't obvi-\nous, any standard search algorithm should solve the problem quickly.\nFinding Vulnerable Dependencies\nA dependency graph can be used to analyze strengths and weaknesses in a player's\nforces, and to pinpoint its opponents' most vulnerable dependencies. In Red Alert 2,\nthe enemy AI will usually destroy my Barracks after taking out my War Factory. This\nis a clever and potentially devastating strategy as it forces me to spend precious time\nand money rebuilding the Barracks before I can consider rebuilding my War Factory.\nThere are three factors that generally determine whether a given node in the\ndependency graph is \"vulnerable.\"\n• Intrinsic value. Some assets are valuable of their own accord. A Nuclear Silo is\nvaluable because it can attack the enemy directly. Assets deeper in the graph (far-\nther along in the tech tree) usually have much higher intrinsic values.\n• Strong child dependencies. Some assets are worth targeting because of what\nthey can create or support. A War Factory can create tanks and other vehicles. A\nLibrary allows me to create the Mage Hall, which will eventually lead to Mages. A\nFusion Plant supplies lots of electricity to a player's base (a support dependency).\n• Weak parent dependencies. We can also eat away at parent dependencies, as\nwith the Barracks destroyed after the War Factory. Graph nodes whose parents are\n\n\n3.7 Strategic Assessment Techniques \n305\nrelatively weak (few instances of each supporting asset) and easy to attack (poorly\ndefended) are more vulnerable to this type of attack.\nWe can use the same heuristic for both attack and defense. For attack, we often\nwant to select the most valuable opposing player dependencies, and go after the War\nFactory first and the Barracks second. In defense, we use the graph to prepare for that\nexact possibility—we increase our defense and build duplicate buildings as backup.\nStrategic Inference\nOne subtle advantage of the dependency graph is that it provides a basis for making\ninferences about other players' current assets and likely strategies based on incomplete\nobservations. For example, if I know my enemy has a Barracks, I can be confident that\nhe either has Pikemen already or is capable of creating them in the near future. Simi-\nlarly, if I see an enemy Pikeman, I can be 100-percent certain that he has a Barracks\nsomewhere about (or at least, that he did when Pikeman unit was created—there's\nalways the chance that the Barracks was destroyed after he created the Pikeman).\nInference works in two directions: forward and backward.\nWith forward inference, we know that the player in question possesses a given\nunit or resource, and we can project the likelihood that he will then fill in the child\ndependency. Each Barracks we observe makes the existence of Pikemen more likely.\nWith backward inference, we go back up the chain and assert that a given unit\nmakes its dependencies nearly certain. Seeing a Pikeman makes us very confident of a\nBarracks, even if we've never observed it directly.\nThis kind of dependency-based inference can go a long way. If I see an enemy\nGrand Mage, I can assume there's a high probability that he also has a Mages'\nArcanum building, High Magic upgrade, a Wizards' Tower, a Sages' Guild, a Library,\nand all the other dependencies leading up to the Grand Mage unit. Furthermore, I\ncan then turn around and use forward inference on each of these nodes with their new\nprobabilities. Since the Grand Mage allowed me to infer the existence of a Sages'\nGuild, I can assume that the player is probably capable of producing a Sage.\nThis process is a form of probabilistic inference and is broadly similar to a popu-\nlar inference technique known as a \"Bayes network\" [see the References for details].\nInterestingly, it's also possible to use inference to make certain nodes less probable.\nIf we set an upper bound on the maximum possible size of a player's economy at a\ngiven point during the game—either on account of the amount of time he's had avail-\nable to build up, or by reasoning based on inferences using data from the influence\nmap—then certain dependencies make others less likely. Four minutes into the game,\nI know that the best player can build a Red Dragon Roost or a Nuclear Silo, but not\nboth. Therefore, the presence of either makes the other less likely.\nOf course, this is all a lot of work, and you can just as easily cheat and look at the\nother players' assets directly. As always, I leave this decision to your conscience and\nyour opinion of how this decision would affect the entertainment value of your\ngame.\n",
      "page_number": 287,
      "chapter_number": 30,
      "summary": "The Resource Allocation Tree\nThe resource allocation tree is a tree structure that represents the specific functional\npurpose of all the assets under a player's control Key topics include units, depend, and dependency.",
      "keywords": [
        "Resource Allocation Tree",
        "Allocation Tree",
        "Tree",
        "Resource Allocation",
        "Dependency Graph",
        "functional asset tree",
        "node",
        "Allocation",
        "player",
        "Strategic Assessment Techniques",
        "Dependency",
        "graph",
        "Resource",
        "assets",
        "tree node"
      ],
      "concepts": [
        "units",
        "depend",
        "dependency",
        "dependencies",
        "node",
        "tree",
        "value",
        "resource",
        "games",
        "allocation"
      ],
      "similar_chapters": [
        {
          "book": "Game_Engine_Architecture",
          "chapter": 15,
          "title": "Segment 15 (pages 289-307)",
          "relevance_score": 0.55,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 1",
          "chapter": 9,
          "title": "Segment 9 (pages 78-85)",
          "relevance_score": 0.53,
          "method": "sentence_transformers"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 16,
          "title": "Segment 16 (pages 308-325)",
          "relevance_score": 0.53,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 7",
          "chapter": 6,
          "title": "Segment 6 (pages 48-56)",
          "relevance_score": 0.5,
          "method": "sentence_transformers"
        },
        {
          "book": "operating_systems_three_easy_pieces",
          "chapter": 21,
          "title": "Segment 21 (pages 193-203)",
          "relevance_score": 0.49,
          "method": "sentence_transformers"
        }
      ]
    },
    {
      "number": 31,
      "title": "Segment 31 (pages 295-305)",
      "start_page": 295,
      "end_page": 305,
      "detection_method": "topic_boundary",
      "content": "306 \nSections Artificial Intelligence\nPlayer Personality\nAs with the functional asset tree, we can use the dependency graph to give AI players\ndistinct personalities.\nThe vulnerability values for the various nodes in the dependency graph are a\nprime candidate for tweaking. By exaggerating or deflating the vulnerability values for\ndifferent nodes, we cause our AI players to deflate or overvalue the significance of\nthose assets. If we tweak the values on the dependency graphs we maintain for oppos-\ning players, we change the likelihood diat we will target certain enemy assets rather\nthan others. If we tweak the values on our dependency graph of our own assets, we\nchange the way our economy develops and the specific technologies we embrace.\nOne simple technique for setting initial priorities is to pick a set of ultimate\n\"goals\" for a given AI player. Look at all the rightmost (deepest) nodes in the graph,\nfind a suitable algorithm to rank these final dependencies by desirability, and come up\nwith good final desirability values. You can then propagate these desirability values\nback toward the left side of the graph, and this will give the AI player a very clear indi-\ncation of which technologies it should generally favor.\nPutting It All Together\nMost of AI is decision-making, and a good representation of the game state can make\nan AI player's decisions vastly easier to make.\nThis gem and the previous one have described data structure foundations for this\ntype of decision-making. Although not every game will be able to use all of these data\nstructures, there are endless opportunities for intercommunication between whichever\nof these data structures you use for shared strategic and tactical decision-making.\nWhen the Influence Map, die Resource Allocation Tree, and the Dependency Graph\ncommunicate and share their data, we end up with a whole diat is more than die sum\nof its parts. The Influence Map tells you where the enemy is, die Resource Allocation\nTree tells you what you need to hit him with, and the Dependency Graph tells you\nhow to build it and how to keep it full of gas once you're up and rolling.\nReferences and Additional Reading\n[Ferber99] Ferber, Jacques, Multi-Agent Systems, Addison-Wesley, London, England,\n1999. A useful perspective is to consider the cells/nodes of the data structures\ndescribed here as hierarchical \"agents\" in a multi-agent system.\n[PearlSS] Pearl, Judea, Probabilistic Reasoning in Intelligent Systems: Networks of Plau-\nsible Influence, Morgan Kaufman, San Francisco, CA, 1988. A must-read intro-\nduction to Bayes nets and probabilistic reasoning systems as they relate to AI.\n[Russell95] Russell, Stuart and Norvig, Peter, Artificial Intelligence: A Modern\nApproach, Prentice Hall, Upper Saddle River, NJ, 1995. A comprehensive intro-\nduction to AI techniques—trie \"AI bible.\"\n\n\n3.8\nTerrain Reasoning for 3D\nAction Games\nWilliam van der Sterren, CGF-AI\nwilliam@cgf-ai.com\nft I \nocation! Location! Location!\" This decree not only holds for real estate, but\n^•i also for the virtual worlds in 3D action games. There, locations play a key role\nas sniper spots, strongholds, avenues of attack, bottlenecks, or \"red armor\" power-up\nareas. When locations are important in a game, they had better be important in the\ngame AI as well.\nThis gem presents a technique for reasoning about locations and their role in the\ngame. It shows how to translate location concepts to algorithms, so that the AI can\ncompute and grasp these concepts. This helps the AI in picking good locations for its\nactions and in understanding the positions that other actors occupy. It literally puts\nthe AI in a better position to assist or challenge the player.\nFirst, we pick a terrain representation that the AI can handle efficiently: waypoint\ngraphs. To illustrate waypoint-based reasoning, an example problem is introduced.\nThen, we identify tactical attributes and relate them to waypoint properties. We con-\nstruct formulas to compute these waypoint properties, using static data such as the\nworld geometry, and dynamic data such as actor activity. Finally, we discuss how to\nintegrate terrain reasoning in our game and we look at various other applications of\nwaypoint-based terrain reasoning.\nRepresenting Terrain to Reason About It\nReasoning about locations would be easy if there were only a few locations. However,\ntoday's game worlds feature tens of thousands of accessible polygons. In a game, mul-\ntiple AI actors take into account both visible and invisible locations. If this were done\nin terms of raw polygons, that effort would probably consume more resources than\nthe 3D graphics rendering.\nTo complicate matters further, the value of a location isn't so much determined by\nits own characteristics as it is its relationship with the surrounding locations. For exam-\nple, is it easy to access the location? Is die location observable by many odier locations?\nAre there any power-ups nearby? In addition, actual gameplay matters a lot: some loca-\ntions (for example, near an objective) are frequendy visited, whereas other areas are not.\n307\n\n\n308 \nSection 3 Artificial Intelligence\nThus, to reason effectively and efficiently about terrain, we had better pick a rep-\nresentation that approximates the terrain using far less detail than the raw polygonal\ngeometry. That representation should express relations between locations easily, and\nsupport capturing of location-based game activity. Ideally, the representation allows\nus to use precomputed intermediate results, leaving us some CPU time for more\nadvanced AI or a faster game.\nWaypoints\nMost 3D game AIs already have a terrain representation that is easy to handle. They\nuse waypoints, or similar navigation aids such as grids, or cells (see [SnookeOO],\n[RabinOO], [ReeceOO]). These waypoints represent the most relevant part of the ter-\nrain: the terrain that is accessible to the game actors. Each waypoint is a sample, an\napproximation, of its immediate surroundings. The number of waypoints is typically\nin the order of 250 to 2500.\nReasoning in terms of waypoints is attractive because many game AIs already use\nthese waypoints to move around, to find paths, to mark the presence of special items\nand obstacles, and to receive hints from the level designer. Because the AI performs\nmany of its actions with waypoints in mind, and because it thinks of players as being\nnear waypoints, capturing gameplay data per waypoint is easy and almost free.\nBefore we start reasoning about the waypoint-based terrain representation, that\nrepresentation needs to approximate the terrain and relevant properties well enough.\nThe network of waypoints should be sufficiently dense to represent all relevant loca-\ntions as well as any cover and concealment present. Typically, that means a larger\nnumber of waypoints than required for AI navigation and pathfinding.\nTerrain reasoning often deals with other inter-waypoint relations than shortest\npath and movement. The need for these additional relations and the reasoning about\nwaypoints are best illustrated using an example.\nExample Terrain and AI Needs\nTo illustrate waypoint-based terrain reasoning, let's look at the following example: in\nthe area depicted in Figure 3.8.1, we want our AI actors to pick solid offensive and\ndefensive tactical positions, both before and during a fight.\nTo support the AI in efficiently picking and visiting strong positions, we compute\nfor each waypoint and for a number of directions, the offensive and defensive value of\nthat waypoint. This value is computed using the waypoint graph and world geometry\nand improved with captured gameplay \"experience.\" Such a \"tactical\"' understanding\nof each waypoint can be input for pathfinding, for flocking, to pick guard positions\noverlooking an objective, and so forth.\nThe example area features one objective and two entrances, and is populated by a\ndense grid of waypoints. Note that just the waypoints themselves (in Figure 3.8.1 cen-\nter) already give you a good clue of the level's architecture.\n\n\n3.8 Terrain Reasoning for 3D Action Games\n309\ndistribution of waypoint\nw's line-of-sight relation\nx' 4;\nsectors being used to\naggregrate relations\nFIGURE 3.8.1 (left) A top view of the example terrain, featuring two entrances!exits, and\none objective o. The terrain is covered by a good number ofwaypoints, including\nwaypoint w. (center) The waypoints in the example terrain, and the valid lines of sight\nfrom waypoint w to other waypoints. (right) The distribution of lines of sight from w,\nand the proposed sectors to aggregate them.\nTactical Analysis\nIn assessing the tactical value of a location, many factors need to be considered. A\nlarge number of these factors can be translated to properties of a waypoint, which in\nturn can be computed. Let's consider the example area from both a Quake-style\ncapture-the-flag game and from a tactical simulation perspective.\nIn a fast capture-the-flag game, characterized by rapid movement, power-ups,\nnonlethal weapons, and rocket launchers, the tactical value of a location is largely\ndetermined by the following characteristics:\n• Locations that provide for fast movement and freedom to move in any direction\nare essential for attackers.\n• Locations near power-ups are valuable.\n• Locations susceptible to rocket blasts aren't that attractive.\n• Locations overlooking the path to the flag while being hard to spot when rushing\nto the flag make for good defensive positions.\nIn a tactical simulation, characterized by lethal weapons, slow movement, cover,\nstealth, and sniping, other characteristics become key.\n• Nearby cover is important for offensive and defensive actions. Even partial cover\nor reduced visibility at a location can be a serious advantage.\n\n\n310\nSection 3 Artificial Intelligence\n• Locations where movement is slow or predictable (near the entrance, for exam-\nple) make for bad offensive spots, whereas the locations overlooking them\nbecome more attractive for defense.\n• As within the capture-the-flag game, locations that overlook the objective, and\nlocations overlooking the main paths to and from the objective are important as\nwell.\nFrom Tactical Values to Waypoint Properties\nNow that we have identified a number of tactical characteristics that largely determine\nthe offensive and defensive values of a location, we need to turn them into an evalua-\ntion function and output.\nFirst, we look at the waypoint properties that we can use to express tactical char-\nacteristics. Figure 3.8.2 illustrates the different types of waypoint properties available.\nA waypoint has properties that are local, such as the light level and the presence of\na power-up or door. Another category of properties is determined by the waypoints'\nmembership in a larger terrain representation (typically a group of waypoints). For\nexample, the waypoint may be part of a room, a street, or a roof. Note that both the\nlocal properties and the group membership properties are nondirectional.\nThe relations between waypoints, however, are directional. For example, way-\npoint w (in Figure 3.8.1) can see almost all waypoints to its east, and it will be hard to\napproach waypoint w from the east without being observed. In a 3D world, height\ndifferences often cause a waypoint to be easily accessed from one direction, and much\nharder (read: taking a longer path and more time) from other directions.\nA last, but essential, aspect is the distribution of the waypoints relations. For\nexample, if a waypoint overlooks many other locations in primarily one direction, the\nplayer or AI is able to focus on that direction and see all visible activity instandy, with-\nout having to worry about attacks from other directions. The concentration of rela-\ntions in a sector is called focus.\n0\nO © €> C\n€> C» i\nFIGURE 3.8.2 Waypoint properties: (from left to right) local properties, group membership, relations\nwith other waypoints, and focus.\n\n\n3.8 Terrain Reasoning for 3D Action Games \n311\nComputing Way point Properties\nTo compute a useful offensive or defensive rating for a given waypoint and direction,\nwe need to implement each applicable tactical characteristic as a function of waypoint\nproperties.\nMany tactical characteristics can be decomposed into primitive functions about\nthe waypoint graph, in effect dealing with linear distance, travel time, line-of-sight,\nline-of-fire, objectives, and obstacles. For example, an important characteristic of a\ngood attack position is that it provides for rapid movement at that position. A \"water\"\nposition does not allow rapid movement locally. A waypoint with a \"water\" local\nproperty should rate low in enabling rapid movement.\nIn small rooms and tunnels, it is difficult to dodge rockets and avoid the blast\nfrom a rocket or grenade. Locations that are more spacious thus offer an advantage. If\na waypoint is part of an area (represented by a group of waypoints) that is a small\nroom or tunnel, it should rate lower in being \"open.\" Thus, the waypoint's group\nmembership can be used to compute a tactical characteristic.\nIn the following code, two tactical characteristics are computed using a local way-\npoint property and a group membership property, respectively.\nfloat GetLocalRapidMovement( waypointid wp )\n{ // result in [0 .. 1], higher values meaning higher speeds\nreturn ( GetActorMovementSpeedAtWaypoint( wp )\n/ GetMaxActorMovementSpeed( ) );\n}float GetOpenAreaMembership ( waypointid wp )\n{ // result in [0 .. 1], higher values meaning more open\nreturn 1.0 - max( IsPartOfSmallRoom( wp ),\nIsPartOfTunnel( wp ) );\n}\nIt is more complicated to compute a directional relation for a waypoint. A spe-\ncific relation for waypoint w, such as the availability of nearby cover from another\nwaypoint wu that has a line of sight on w, is computed in the following function.\n\n\n312 \nSections Artificial Intelligence\nfloat GetCoverFromThreatsInDirection(waypointid w) {\nfloat \nproperty [kMaxDirections];\nunsigned int entry[kMaxDirections];\n// set all property and entry values to 0\n// pass one: collect and interpret relations\nfor (waypointid w_to = 0; w_to < kMaxWaypointld; w_to++ ) {\ndirection dir = GetDirectionForWaypoints( w, w_to );\n// check for line-of-fire from w_to to w\nif ( (w_to != w ) && (HasLineOfFire(w_to, w)) ) {\nentry[dir]++;\n// get value for relation (value in [0..1])\nfloat value = GetCoverFromThreatsAt( w, w_to );\nproperty [dir} += value;\n// pass two: level result into [0 .. 1] range\nfor ( direction dir = 0; dir < kMaxSectors; dir++ ) {\nif ( entry [dir] > 0 ) {\nproperty [dir] /= entry [dir];\nfloat GetCoverFromThreatsAt (waypointid w, waypointid w_at) {\nfor (waypointid w_n = 0; w_n < kMaxWaypointld; w_n++ ) {\n// check for lack of line-of-fire to neighbor of w\nif ( IsNeighborOf (w, w_n) && ( !HasLineOfFire(w_at, w_n))\nreturn 1 .0;\n}\nreturn 0; // no cover found\nIn a first iteration over all waypoints, solely those waypoints with a line of fire to\nw are considered. For each of these waypoints, the number of w's relations is incre-\nmented, and the value of the nearby cover available is accumulated.\nIn a second \"iteration, the amount of \"nearby cover\" is divided by the number of\nrelations, to return a value between 0 and 1 . Rather than using the number of rela-\ntions here, we will use the focus ( ) function to deal with the concentration of relations\nin a certain direction. This focus ( ) function is explained later.\nIn a function such as GetCoverFromThreatsAt () (the second function at bottom\nof the previous code listing), a very simple approximation is made. A more advanced\napproximation might use fuzzy logic to deal with such issues as the travel time to the\nnearest cover, the amount of cover available, and the weapon effectiveness over the\ndistance between the waypoints.\n\n\n3.8 Terrain Reasoning for 3D Action Games \n313\nfocus() =\n3 x front\nleft + rear + right\nFIGURE 3.8.3 Simple computation of the focus values for waypoint ~w in the example\nterrain. All relations are projected on a 2D dish with four 90-degree sectors. The focus of\na sector is a weighted ratio of its relations versus the relations in other sectors.\nThe focus of a waypoint reflects the concentration of relations over the various\ndirections. Focus is particularly valuable in defense and when survival is important. In\nthese cases, it is not sufficient for a location to offer great sniping opportunities in one\ndirection. The location also needs to offer flank and rear protection; that is, have few\nline-of-sight/fire relations to the sides and to the rear.\nThe function focus ( w, d ) expresses the distribution of relations in one direction\nrelative to the distribution in other directions. The exact implementation of focus ()\ndepends on the number of different directions considered (the sectors) and the type of\nrelation for which the concentration is considered (often the line-of-sight). Figure 3.8.3\nillustrates an implementation of focus for waypoint w in our example terrain, using sim-\nply four sectors to represent die various directions possible in a 3D sphere. When deter-\nmining the focus, you should also deal widi the exceptional case of a waypoint having\nrelations solely in a single sector. Then, a default maximum should be used.\nThe focus() function assumes a more or less uniform distribution of waypoints\nacross the terrain. However, the function is largely robust against moderate deviations\nin that distribution. When we have expressed every tactical characteristic in a number\nof waypoint property computations, we can combine them as follows:\nrating( w, d ) = Z k± x local_propertyi( w )\n+ £ kj x group_membershipj( w )\n+ focus( w, d ) x I ki x relation^ w, d )\nNote that for focus () to correcdy emphasize or dampen the results from the rela-\ntionx() functions, these relation*() should all return positive values. This rating\nexpresses the AI's a-priori understanding of a location and its role in the game. This\nrating, the tactical value of a location, is based on die waypoint graph and world geom-\netry, and implicitly uses some static game constants such as actor movement speeds,\nweapon performance, and power-up locations. For the example area discussed, we are\nnow able to automatically annotate each waypoint with its offensive and defensive val-\nues in a given direction (given some time for experimentation and tuning).\n\n\n314 \nSections Artificial Intelligence\nLearning from Gameplay Experience\nObviously, not every value will be fully correct. Our terrain sampling, by means of\nwaypoints, is an approximation, and so are the evaluation functions used to compute\nthe values.\nIn addition, we have been ignoring actual gameplay. That mistake, however, is\neasily turned into an advantage.\nBecause the AI uses waypoints for its actions, and thinks of the players as being\nnear waypoints, we can record their activity at a waypoint with little effort. We can\nuse that information in two ways. We can use it to correct the outcome of our com-\nputations, and we can use it as additional input in the computations.\nWe can improve, for example, the defensive value of a waypoint in a direction by\nadding the damage done by an actor, and subtracting the damage received by an actor\nat that waypoint. In other words, we add a little reinforcement learning to the AI's\nunderstanding of the locations. That will correct part of the error present in our\nresults. More importantly, it leads to an AI that will vary and adapt its choice of loca-\ntion based on its past successes and failures!\nThe captured gameplay data can also be input for our waypoint properties. For\nexample, the more \"hostile traffic\" waypoints that can be seen from a location, the\nmore useful that location will be for defense. Such a relation can be computed easily,\nif the required traffic data is available. When using gameplay data as input for the\ncomputations, the AI actually gains tactical understanding of the terrain.\nPutting Terrain Reasoning in the Game\nSo, our AI can analyze the example area by a series of computations, using geometry\ndata, travel time, shortest paths, line-of-sight, line-of-fire, and waypoint-related\ngameplay data. These computations have O(n 3) time complexity, because in comput-\ning some of the waypoint-to-waypoint relations, other nearby waypoints are also con-\nsidered. In practice, the computations take some tens of seconds. This kind of\nwaypoint reasoning is best done when preprocessing a level and possibly between mis-\nsions, as a background thread.\nFew resources are used by the results from the terrain reasoning algorithm. Typi-\ncally, they consist of several tables per waypoint, each table containing a small number\nof bytes. The tables can quickly be read and contain knowledge about the terrain that\nwould otherwise be almost impossible to obtain. In addition, the reinforcement learn-\ning based on gameplay data enables some varying and adaptive AI behavior at negligi-\nble costs.\nIn general, waypoint-based reasoning need not be CPU intensive. Terrain reason-\ning is quite feasible during gameplay, provided the AI considers a small set of way-\npoints, and has intermediate reasoning results available. Using small look-up tables\nfor each waypoint to store both the nearby waypoints and the visible waypoints, the\nAI can, for example, efficiently plan paths that avoid locations under fire from threats.\n\n\n3.8 Terrain Reasoning for 3D Action Games \n315\nDynamic game terrain and entities, such as doors, vehicles, destructible terrain,\nand smoke do complicate the terrain reasoning, because these dynamics partially\ninvalidate precomputed results. Notably the line-of-sight, line-of-fire, and paths will\nbe affected by dynamic terrain. Nevertheless, it often remains attractive to use pre-\ncomputed intermediate results. It is often more intelligent and efficient to use these\nresults and try to correct for any dynamics than to use no reasoning at all.\nThe terrain reasoning discussed here is a set of heuristics. It takes a number of\nexperiments and some analysis to find the right ingredients and weights for your AI\nterrain reasoning. To effectively tune and verify your algorithm, visualization of the\n(intermediate) reasoning output is essential. The output can be interpreted easily\nwhen projected onto the terrain within the game. Alternatively, you can export the\nresults to a spreadsheet for further analysis.\nOther Applications\nWaypoint-based terrain reasoning is presented here using a simple example, precom-\nputing the offensive and defensive values of the game locations. The ideas behind the\nreasoning have a much wider use than that example. The idea of dissecting tactical\nguidelines and expressing them as evaluation functions per location is an approach\nthat will work for many games where the AI needs to reason about locations.\nJust ask yourself the question:\n\"If I were to defend this base (or whatever the AI needs to do), why would I prefer\nlocation x over location y, and what does distance, travel time, line-of-fire, the type of area,\n(or whatever terrain property or game item you can come up with) have to do with it?\"\nWaypoints, if placed in a sufficiently dense graph across the terrain, serve many\nmore purposes than just navigation. Together with a few small lookup tables for\nnearby waypoints and visible waypoints, they enable the AI to predict out-of-sight\nopponent movement, and to find a nearby location providing a new line-of-sight.\nWaypoints are a handy means to \"host\" additional costs for A* pathfinding. If\nwe tag all waypoints that are visible from the assumed threat positions with extra\ncosts, the A* pathfinder provides us a path offering cover from the threats where\navailable. If we also tag all waypoints that restrict our movement, the path returned\nwill be even more \"tactical.\" These are just two of the many examples of waypoint-\nbased reasoning. You can probably think of a few more that will put your AI in a\nstrong position.\nConclusion\nWaypoint graphs provide an easy-to-use representation of the game terrain. You can\ntranslate many of the terrain-related tactics in your game to waypoint-related proper-\nties. As an example, this gem shows how to build a per-waypoint evaluation function\nthat expresses the value of a location for general offense, general defense, or a parti-\n\n\n316 \nSection 3 Artificial Intelligence\ncular tactic such as ambushing or sniping. This will provide your AI with a good\nunderstanding of the terrain.\nYou can extend and improve that evaluation function with captured gameplay\ndata, resulting in an AI that becomes more varied and adaptive. There are many other\nways your AI can reason about terrain using waypoints. Just try to relate the tactical\nguidelines to waypoint properties (that fit in a look-up table).\nReferences and Additional Reading\n[PottingerOO] Pottinger, Dave, \"Terrain Analysis in Realtime Strategy Games,\" Pro-\nceedings of Computer Game Developer Conference, 2000.\n[RabinOO] Rabin, Steve, \"A* Speed Optimizations,\" Game Programming Gems,\nCharles River Media, 2000: pp. 272-287.\n[ReeceOO] Reece, Doug, et al, \"Tactical Movement Planning for Individual Combat-\nants,\" Proceedings of the 9th Conference on Computer Generated Forces and\nBehavioral Representation, 2000. Also available online at www.sisostds.org/\ncgf-br/9th/.\n[SnookOO] Snook, Greg, \"Simplified 3D Movement and Pathfinding Using Naviga-\ntion Meshes,\" Game Programming Gems, Charles River Media, 2000: pp.\n288-304.\n",
      "page_number": 295,
      "chapter_number": 31,
      "summary": "If we tweak the values on the dependency graphs we maintain for oppos-\ning players, we change the likelihood diat we will target certain enemy assets rather\nthan others Key topics include location, locations, and game.",
      "keywords": [
        "waypoint",
        "Terrain Reasoning",
        "Terrain",
        "waypoint properties",
        "game",
        "Reasoning",
        "locations",
        "Location",
        "tactical",
        "Action Games",
        "waypoint-based terrain reasoning",
        "Artificial Intelligence",
        "Sections Artificial Intelligence",
        "relations",
        "waypoint graph"
      ],
      "concepts": [
        "location",
        "locations",
        "game",
        "terrain",
        "ais",
        "tactical",
        "tactics",
        "relate",
        "relations",
        "relation"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 7",
          "chapter": 34,
          "title": "Segment 34 (pages 321-328)",
          "relevance_score": 0.52,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 1",
          "chapter": 27,
          "title": "Segment 27 (pages 248-255)",
          "relevance_score": 0.51,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 3",
          "chapter": 31,
          "title": "Segment 31 (pages 288-295)",
          "relevance_score": 0.51,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 7",
          "chapter": 10,
          "title": "Segment 10 (pages 91-99)",
          "relevance_score": 0.51,
          "method": "sentence_transformers"
        },
        {
          "book": "AI Agents and Applications",
          "chapter": 51,
          "title": "Segment 51 (pages 441-449)",
          "relevance_score": 0.47,
          "method": "sentence_transformers"
        }
      ]
    },
    {
      "number": 32,
      "title": "Segment 32 (pages 306-318)",
      "start_page": 306,
      "end_page": 318,
      "detection_method": "topic_boundary",
      "content": "3.9\nExpanded Geometry for\nPoints-of-Visibility Pathfinding\nThomas Young\nthomas.young@bigfoot.com\nI\nn Game Programming Gems, Bryan Stout and Steve Rabin described \"points-of-\nvisibility\" pathfinding [StoutOO], [RabinOO]. This is essentially a way to find the\nshortest path around polygonal obstacles.\nAs Steve pointed out, there are big advantages to the method. It enables you to\ncreate a minimal representation of the search space, resulting in very fast searches. In\naddition, paths found are perfectly direct.\nIn this gem I explain how to automate construction of expanded geometry from\npolygonal obstacles, and how to use this to implement points-of-visibility pathfinding.\nBy using expanded geometry, we overcome most of the disadvantages of the technique.\n• Points of visibility can be extracted directly from the expanded geometry without\ndesigner assistance.\n• It is possible to support dynamic objects (such as characters, doors, moving\nblocks, and so on) by generating and integrating expanded geometry for those\nobjects on the fly.\n• The expansion can be parameterized to support characters of different sizes and\nformations.\nFor many games, pathfinding is fundamental to the AI. It is up to the pathfinder\nto guarantee certain aspects of character behavior. It is essential, for example, that AI\ncharacters do not get stuck against obstructions. Characters must not fail to find a\npath around obstacles when that path looks obvious to the player. When collision\nagainst obstructions is complicated, even these capabilities are difficult to guarantee.\nIf we accept some limitations on the collision model for character movement, we\ncan use exactly the same model for both collision and pathfinding. By using expanded\ngeometry we can build a pathfinding system that is exactly correct for this collision\nmodel. This system is guaranteed to understand correctly any position a character can\nreach, and returns paths that are guaranteed to be unobstructed, so characters can't get\nstuck.\nHigher-level AI built on a \"perfect\" pathfinding system is much easier to code\nbecause you don't need to catch those tricky situations, such as a character getting\n317\n\n\n318 \nSections Artificial Intelligence\nstuck because no path can be found from its current position. By depending com-\npletely on the results of the pathfinding system, it is possible to build sophisticated\nmovement-related AI with far fewer lines of code. It is also much more fun.\nDefining a Collision Model\nA collision model precisely specifies character collision against the environment. We\nbuild our collision model around a \"collision shape\" for each character. The collision\nshape is a convex polygon chosen to best represent the shape and size of that charac-\nter. The shape translates with the characters origin when the character moves, but\ndoesn't rotate when it turns. The character is obstructed for positions where its colli-\nsion shape overlaps the environment.\nThe environment is represented polygonally and can be comprised of convex and\nnonconvex polygons that mark obstructed areas, 2D meshes to represent unob-\nstructed areas, or some combination of these representations (Figure 3.9.1).\n: -(-Obstructed\n, j .-tt'nobstructed\nFIGURE 3.9.1 Collision shapes in polygonal environments.\nPolygonal Pathfinding\nNow that we have specified a collision model, it is the job of the pathfinder to find\npaths for a character that are unobstructed for this model. For simplicity, I consider\nonly the traditional pathfinding constraint; that is, to find the shortest path from the\nstart position to a given goal position. The problem can be restated as finding the\nshortest set of unobstructed line sections connecting start to goal.\nExpand and Conquer\nThe trick is to build an expanded geometry that combines our collision shape with\nthe shape of the obstacles in the environment. This representation greatly simplifies\nthe queries we require for our pathfinding system.\n\n\n3.9 Expanded Geometry for Points-of-Visibility Pathfinding \n319\nThe expansion we use is a Minkowski sum of planar sets. Specifically, our\nexpanded geometry will be a Minkowski sum between the environment and the\nnegated collision shape. This is sometimes called a Minkowski difference.\nThe Minkowski sum of two sets A and B is the set of values that can be generated\nby adding some member of set A to some member of set B. A polygon can be viewed\nas a planar set; that is, the set of points inside that polygon.\nOur expanded geometry represents the set of points that can be generated by sub-\ntracting some offset in our collision shape from some point inside the environment.\nThis means that for each position in our expanded geometry, some point in the colli-\nsion shape overlaps the environment. Therefore, our expanded geometry represents the\nset of points where our character will be obstructed (Figure 3.9.2).\nColl\nDoesn't Collide \\^~ \nDoesn't Collide\nFIGURE 3.9.2 Collision shape in polygonal environment, point in expanded environment.\nCollision between a collision shape and the original polygonal environment is\nidentical to collision between a point and the expanded geometry. To find out if a\ncharacter can be placed at a position, we test whether that position is inside our\nexpanded geometry. To find out if a line section is obstructed for a character, we sim-\nply test whether the line collides against our expanded geometry.\nFor points-of-visibility pathfinding, the set of convex corners in our expanded\ngeometry gives us our points of visibility. Two points can be connected if the line\nbetween the points doesn't collide against our expanded geometry.\nMinkowski Sum of Convex Polygons\nTo build our geometry, we start by looking at the simpler case of a single convex poly-\ngon obstruction. The negated collision shape is also a convex polygon, so we must\nconstruct a Minkowski sum of two convex polygons.\nFor convex polygons C and O, this sum can be visualized as the space swept out\nby dragging the center of C around the perimeter of O (Figure 3.9.3a). This space will\nbe bounded by a larger convex polygon. The sum can also be visualized as the shape\n\n\n320\nSection 3 Artificial Intelligence\nA \nB\nFIGURE 3.9.3 A) Sum of convex polygons. B) Alternative visualization.\nenclosed by the center of the (non-negated) collision shape as it slides around touch-\ning the perimeter of O (Figure 3.9.3b).\nEdges in the expanded polygon are generated in three ways (see Figure 3.9.3B):\n1. Directly from an edge in C, when C is placed at a corner of O.\n2. By a corner of C as C moves along an edge in O.\n3. By an edge in C as C moves along a parallel edge in O.\nWhen there are no parallel edges, each edge in C and O is used exactly once, giv-\ning us a limit for edges in our expanded polygon equal to die edges in C plus the edges\nin O. This is useful for us to allocate space in advance for the expanded polygon.\nIt is fairly easy to build the expanded polygon. Vertices in C are numbered in a\nclockwise direction (Figure 3.9.4a). For each edge in O, we determine which of these\nvertices is used to expand the start and end points of that edge (Figure 3.9.4b). This\nA \nB\nFIGURE 3.9.4 A) Vertices in C. B) Stan and end points, interpolated vertices.\n\n\n3.9 Expanded Geometry for Points-of-Visibility Pathfinding\n321\nstart=2 end=2\nend=3 \nstart=l\nend=2\nA \nB\nFIGURE 3.9.5 Ordering by edge vectors, start and end expansion for an edge.\ngives us our type (2) or type (3) edges. Type (1) edges are constructed where the end\npoint of one of these edges does not connect to the start point of the next, by inter-\npolating vertices in C, if required, and adding edges (also Figure 3.9.4B). Interpola-\ntion is just a case of counting through vertices in C until we reach the vertex that\nexpands the start of the next edge.\nSo, how do we determine the start and end expansions for each edge in the first\nplace? We can define a circular ordering on vectors, based on the directions of die edges\nin C (Figure 3.9.5). For each edge in O, position in this ordering tells us which vertices\nin C expand the start and end points of diat edge (also Figure 3.9.5). For a bit of extra\nspeed, this position can be tracked incrementally as we loop through edges in O.\nExpanding Nonconvex Geometry\nNow that we can expand a convex polygon, there is a straightforward way to extend\nthis to a nonconvex polygon. We simply split the nonconvex polygon into convex\nparts and expand each part separately (Figure 3.9.6a). However, this can result in a\nlarge number of overlapping polygons with a lot of unnecessary edges and corners.\nTo make a well-formed Minkowski sum, we should detect intersections between\nexpanded polygons and connect them together to make a single expanded shape. A\nfundamental problem with this approach is the fact that intersections may not fall\nexactly on points representable by the numbers we are using for coordinates. More-\nover, if we use approximate points at intersections, then our padifinder no longer cor-\nresponds exacdy to our collision model, although this may not matter if our collision\nengine will also be built around the same expanded representation.\nA good solution is to make a \"lazy man's Minkowski sum.\" Here we are not con-\ncerned with the set of obstructed points, but rather with transitions from unob-\nstructed areas into obstructed areas. This approach is more appropriate for external\nboundaries that can't be decomposed, as such, into convex polygons. This will also be\n\n\n322 \nSection 3 Artificial Intelligence\nmore relevant if we need to make extensions in the fixture to support features such as\noverlapping geometry.\nTo build a \"lazy man's Minkowski sum,\" we can use virtually the same method we\nused to expand a convex polygon. The difference is that we do not interpolate points\nat a concave corner. If the end point for the edge before the corner is not same as the\nstart point for the edge after the corner, then we get an intersection and a discontinu-\nity in the expanded edge list (Figure 3.9.6b).\nThis process is a lot easier to code and a lot faster than generating a true\nMinkowski sum. For a start, we don't have to perform any triangulation or detect\nintersections. For large collision shapes, we can still end up with unnecessary edges\nand corners, but this is usually not a big problem.\nA \nB\nFIGURE 3.9.6 A) Nonconvexpolygon expanded as convex subparts. B) Lazy man's\nMinkowski sum.\nChoosing a Collision Shape\nThe fact that our collision shape doesn't rotate is a major limitation for our collision\nmodel. Because the characters in our games will almost certainly need to rotate, we\nwill want to use rotationally symmetrical collision shapes in order to get the most con-\nsistent collision behavior. A circle would be the best approximation, but we can't use a\ncircle because the resulting expanded geometry would have no corners and hence no\npoints of visibility. Instead, we must use an N-sided regular polygon to approximate a\ncircle.\nIn general, the more edges we use in our collision shape, the more edges and cor-\nners we get in the resulting expanded geometry. With more edges and corners,\npathfinding becomes more expensive (sometimes exponentially). Squares and\noctagons are obvious choices because they are relatively simple and because they can\nbe aligned with the coordinate axes.\nIn the past, it was important to use axis-aligned collision shapes for performance\nreasons. For vector comparisons against horizontal, vertical or 45-degree lines,\n\n\n3.9 Expanded Geometry for Points-of-Visibility Pathfinding \n323\nmultiplication can often be avoided. Nowadays, branch prediction issues mean that it\nis better to simply go ahead and perform the same multiplications for all cases, so\nthere is no longer any performance reason to only use axis-aligned shapes. For some\nplatforms, avoiding multiplication may still be an important issue, however.\nConclusion\nI have shown how a pathfinding system can be constructed that is precise with respect\nto a reasonably interesting polygonal collision model. There is a trade-off to be made\nbetween sophisticated collision systems and collision systems that characters can\n\"understand.\" For games where you are able to use this model for both character col-\nlision and pathfinding, there can be a big payback in reduced debugging and simpli-\nfied AI.\nReferences\n[RabinOO] Rabin, Steve, \"A* Speed Optimizations,\" Game Programming Gems,\nCharles River Media, 2000.\n[StoutOO] Stout, Bryan, \"The Basics of A* for Path Planning,\" Game Programming\nGems, Charles River Media, 2000.\n\n\n3.10\nOptimizing Points-of-Visibility\nPathfinding\nThomas Young\nthomas.young@bigfoot.com\nT\nhe \"points of visibility\" pathfinding method has a number of advantages (see Steve\nRabin's article in Game Programming Gems, [RabinOO]). Also, with expanded geom-\netry we can make this an exact mediod to guarantee correct paths with respect to a given\npolygonal obstruction set (see \"Expanded Geometry for Points-of-Visibility Pathfind-\ning\" in tins volume.) Complexity is independent of scale, so it is possible to efficiently\ncompute paths over long distances, and by precalculating the network of connections\nbetween points of visibility, an extremely fast pathfinder can be constructed.\nAs map complexity increases, and with it the number of points of visibility, we\nfind that the number of connections between these points can increase exponentially,\nparticularly on maps with large open areas. Memory can become an issue, especially\non console platforms. In addition, the need for interesting AI demands that pathfind-\ners must support dynamic features such as moving objects, characters, doors, and so\non. To support dynamic features such as these, we need to work with points of visi-\nbility that are generated on the fly, and obstacles that can move to invalidate connec-\ntions. If we are not careful, the overhead for calculating visibility with these dynamic\nfeatures can also increase exponentially.\nI present some optimizations that enable us to quickly discard many potential\npaths and to greatly reduce the size of our network of connections. This results in\nfaster searches and less overhead for dynamic objects. With these optimizations, our\nalgorithm will scale better to handle increasingly complicated maps.\nPoints-of-Visibility Pathfinding\nFor this gem, I assume that the pathfinding agent can be considered as a point agent\nin a polygonal environment. Section 3.9 explains how a more interesting collision\nmodel can be converted to this form.\nOur pathfinder uses an A* algorithm with a set of points of visibility as possible\nintermediate states between start and goal. The points of visibility are derived directly\nfrom the convex corners in our polygonal environment. For an explanation of the A*\nalgorithm, see Bryan Stout's article in Game Programming Gems [StoutOO].\n324\n\n\n3.10 Optimizing Points-of-Visibility Pathfinding \n325\nStoring the Shortest Path to Each Point\nAn important first step to prevent exponential growth of our search tree is to ensure\nthat only the shortest path to any intermediate point is retained for further consider-\nation. This is not a specific optimization for points-of-visibility pathfinding as it\nshould probably be standard behavior for any A* implementation. This needs to be\nstressed, however, because it makes a big difference to scalability.\nIn Bryan Stout's article, he describes the use of an open list and a closed list. At\neach step of the A* algorithm, these lists are searched to find any other paths that also\nend at the current point under consideration.\nOne important difference between tile-based pathfinding and points-of-visibility\npathfinding is the number of potential intermediate locations we need to consider.\nSince we only consider the convex corners in our environment, this will tend to be an\norder of magnitude less than the number of tiles required to represent the same map\nfor tile-based pathfinding.\nThis means that it is feasible to use an array (with one entry per point of visibil-\nity) to keep a record of the shortest path found so far to each point. Instead of search-\ning through open and closed lists, we need only make a single lookup into this array.\nIn fact, this means that there is no longer any need for a closed list at all.\nThe array must be cleared before each use, but on most platforms, there will be a\nfast memory clear routine readily available, so the time this takes is usually irrelevant.\nIf there is a very large number of points and you expect to only use a small number of\nthese for each search, then it might be worth keeping the closed list as a record of\nwhich points must be cleared after the search is complete.\nConnecting the Corners\nEach step in the A* algorithm involves taking the best partial path found so far and\ngenerating a set of successor paths. Each successor is formed by connecting the end of\nthe partial path to another point with a line section. The point can be either a point\nof visibility or the goal point. The straightforward approach is to generate a successor\nfor every point in the world for which the line section will be unobstructed.\nBy preprocessing collision between all pairs of points of visibility and building a\n(possibly large) table, we can determine very quickly at runtime which other points of\nvisibility can be reached from some source point of visibility. The start and goal posi-\ntions will change at runtime, so line sections to and from these points cannot be pre-\nprocessed. The same is true for any points of visibility resulting from dynamic\nobstacles.\nOptimization #1: Only Consider Paths to Silhouette Points\nAs seen from some source point, each other point in the world can be classified as left\nsilhouette, right silhouette, or not a silhouette (Figure 3.10.1).\n\n\n326 \nSections Artificial Intelligence\nilhouette \ncorner can\nPoint \nbe cut\nSource Point \nSource Point\nFIGURE 3.10.1 Silhouette points.\nThis optimization is based on the observation that we don't need to consider path\nsections that connect to nonsilhouette points. Any path section going to a nonsilhou-\nette point will result in a corner that can be cut to make a shorter path. (This is true\nunless that point coincides exactly with the goal point, or with another silhouette\npoint. In both cases, there will be an alternative mechanism to generate that path.)\nThe optimization applies when we are generating the set of successors to a partial\npath. I will refer to the point at the end of this partial path as the current point. The\npoints we consider using to extend the path are potential next points. We can simply\ndiscard any of these points that are not silhouettes as seen from the current point.\nWe discard nonsilhouette points because the resulting path can always be short-\nened by cutting a corner. To better visualize what is going on here, it is useful to\nunderstand that the shortened path will be realized as the search continues. This will\nhappen either by connection directly from the current point or by connecting to a sil-\nhouette on a blocking object.\nIf we are using a visibility graph, then this optimization can also be applied\ndirectly to the connections in our visibility graph. Any connection can be removed\nfrom the graph where the destination point is not a silhouette from the source point.\nOptimization #2: Only Consider Paths that Go\nAround the Corner\nThis optimization is also applied when generating successors to a partial path.\nFor this optimization, we are interested in the line section at the end of our par-\ntial path. When generating successors for the first time, from the start position, the\npartial path is empty so this optimization does not apply. I will refer to the point at\nthe start of this line section as the previous point. The point at the end of the partial\npath is our current point. As a result of our first optimization, the current point will\nalways be a silhouette point as seen from the previous point.\nThe reasoning behind this optimization is similar to die reasoning behind die first\noptimization. Any path diat does not go around the silhouette point will result in a cor-\nner that can be cut to make a shorter path. Figure 3.10.2 shows a silhouette point, a set\n\n\n3.10 Optimizing Points-of-VisibilityPathfinding \n327\nof path sections that go around that point, and one example of a path that can be dis-\ncarded. Again, the shortened path will be realized either by a direct connection from the\nprevious point, or via another silhouette point if the direct connection is obstructed.\nTo implement this optimization, we use the vector from the previous point to the\ncurrent point and the vector from the current point to the potential next point under\nconsideration. At a left silhouette, the next vector must be on the right of the previous\nvector and to the left of the obstacle. At a right silhouette, the next vector must be on\nthe left of the previous vector and to the right of the obstacle (Figure 3.10.2).\nGoal\nStart\nFIGURE 3.10.2 The path must go around each corner.\nSilhouette Zones\nFor implementation, it is useful to define two zones relating to each point of visibility\n(Figure 3.10.3). Each point of visibility is positioned at a convex obstruction corner.\nThe zones are formed by extension of the obstruction edges before and after that cor-\nner. The zones classify this point of visibility as seen from some arbitrary point. If that\npoint is in the left silhouette zone, then our point of visibility is classified as left sil-\nhouette, and vice versa.\nTo go \"around\" the silhouette point, the next point must be in the opposite zone\nto the previous point, but it must also be inside the set of valid destinations bounded\nby the extension of the axis from the previous connection.\nWe can apply the second optimization to the connections in our visibility graph.\nEach connection in our graph has a source point and a destination point. When gen-\nerating successors, these correspond to the current and next points, but there is no\ninformation in a simple visibility graph about the position of the previous point. This\nmeans that when we apply this optimization to the visibility graph, we must allow for\n\n\n328\nSection 3 Artificial Intelligence\nI 1 4\nI\" ~'f\" Right Silhouette\nLeft\nFIGURE 3.10.3 Silhouette zones at a corner.\nall possible positions for the previous point. This just means that our set of valid des-\ntinations becomes the set of points in either of our silhouette zones.\nSo, to apply this optimization to our visibility graph, we also discard connections\nwhere the destination point is not in one of the source point's silhouette zones. When\nwe retrieve a connection from the visibility graph, we know the position of the previ-\nous point so we can make a more specific test to possibly discard that connection.\nEnvironment 1\nEnvironment 2\nPoints \nConnections before\n21 \n231\n96 \n1638\nConnections after\n98\n568\nFigure 3.10.4 shows two examples of obstruction environments. The table above\nshows the number of connections in our visibility graph before and after using sil-\nhouette optimizations to discard connections.\nFIGURE 3.10.4 Environment 1, Environment 2.\n\n\n3.10 Optimizing Points-of-Visibility Pathfinding \n329\nUsing Silhouette Zones with Spatial Partitioning\nThe optimizations I have described enable us to reduce the number of connections in\nour visibility graph, and to reduce the size of our search tree. For dynamic points, we\nstill need to test for connection to and from every other point in the world. We can\nquickly discard many of these connections, but connections that cannot be discarded\nneed to be tested for collision.\nThe next step is to build a representation to quickly determine a minimal set of\npoints that can potentially connect to or from a given dynamic point. Silhouette\nzones are a good starting point for building this representation. The zones for a given\npoint of visibility give us an area within which dynamic points can potentially con-\nnect to that point of visibility. The exact nature of this representation should vary for\ndifferent types of obstruction environments.\nIn maps with low visibility, built from rooms connected by portals, silhouette\nzones can be projected through portals to determine which rooms can potentially see\nthe corresponding point of visibility.\nFor a more general system, silhouette zones can be clipped against the polygonal\nenvironment to determine the area in which a given point is visible. The resulting shapes\ncan then be entered into some general spatial partitioning system. If the shape for one of\nthese areas is represented exacdy, then there is no need for any collision checking once it\nis known diat a dynamic point is inside that shape. (Note that exact representation of the\nclipped area may depend on using an exact representation for line intersections.)\nConclusion\nThere are many more details involved in building an efficient points-of-visibility\npathfinding system. I have described some techniques for quickly discarding many\nconnections and therefore reducing the total number of paths that must be consid-\nered. This is a good first step.\nI have briefly mentioned how silhouette zones can be used with spatial partition-\ning to handle dynamic points efficiently. To support the addition of dynamic obsta-\ncles efficiently, a good spatial partitioning system is essential.\nA final detail is the problem of testing for connection from one dynamic point to\nanother. For the case with no dynamic obstacles, this only needs to be done once, for\nthe potential connection from start point to goal point. With dynamic obstacles, this\ntest may need to be performed a large number of times, so an efficient implementa-\ntion becomes important.\nReferences\n[RabinOO] Rabin, Steve, \"A* Speed Optimizations,\" Game Programming Gems,\nCharles River Media, 2000.\n[StoutOO] Stout, Bryan, \"The Basics of A* for Path Planning,\" Game Programming\nGems, Charles River Media, 2000.\n",
      "page_number": 306,
      "chapter_number": 32,
      "summary": "This chapter covers segment 32 (pages 306-318). Key topics include points, path, and pathfinder. As Steve pointed out, there are big advantages to the method.",
      "keywords": [
        "point",
        "Expanded Geometry",
        "collision",
        "Expanded",
        "collision shape",
        "path",
        "Pathfinding",
        "silhouette point",
        "Geometry",
        "visibility",
        "Silhouette",
        "Game Programming Gems",
        "collision model",
        "Minkowski sum",
        "current point"
      ],
      "concepts": [
        "points",
        "path",
        "pathfinder",
        "collision",
        "polygonal",
        "polygonally",
        "expanded",
        "edges",
        "characters",
        "obstructions"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 3",
          "chapter": 32,
          "title": "Segment 32 (pages 296-313)",
          "relevance_score": 0.68,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 3",
          "chapter": 33,
          "title": "Segment 33 (pages 314-325)",
          "relevance_score": 0.64,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 1",
          "chapter": 30,
          "title": "Segment 30 (pages 279-290)",
          "relevance_score": 0.63,
          "method": "sentence_transformers"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 32,
          "title": "Segment 32 (pages 632-651)",
          "relevance_score": 0.62,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 1",
          "chapter": 40,
          "title": "Segment 40 (pages 381-388)",
          "relevance_score": 0.6,
          "method": "sentence_transformers"
        }
      ]
    },
    {
      "number": 33,
      "title": "Segment 33 (pages 319-337)",
      "start_page": 319,
      "end_page": 337,
      "detection_method": "topic_boundary",
      "content": "3.11\nFlocking with Teeth: Predators\nand Prey\nSteven Woodcock\nferretman@gameai.com\nF\nlocking (sometimes called swarming or herding) is a technique first put forth by\nCraig Reynolds in a 1987 paper he did for SIGGRAPH entitled \"Flocks, Herds,\nand Schools: A Distributed Behavioral Model\" [Reynolds87]. In this paper, Reynolds\ndefined the three basic rules (or steering behaviors) for flocking and explained how\nthey interacted to give lifelike group behavior to creatures he called boids. In Game\nProgramming Gems, I wrote a short gem introducing the subject [WbodcockOO] and\nadded another steering behavior to make what I called the \"Four Rules of Flocking.\"\n• Separation: Steer to avoid crowding local flockmates.\n• Alignment: Steer toward the average heading of local flockmates.\n• Cohesion: Steer to move toward the average position of local flockmates.\n• Avoidance: Steer to avoid running into local obstacles or enemies.\nWhat's interesting about these four simple behavioral rules is how lifelike the\nresulting behavior of the boids can seem. Watching the original demo from the first\nbook (also provided on the companion CD-ROM files for this chapter), one can see\ngroups of boids coalesce and move in ripples around their world. When they\nON THE CD approach boids belonging to another flock, they flee, breaking apart into smaller\nflocks, if necessary, to avoid contact with anybody not belonging to their flock. If\nsplit from their original flocks, individual boids eventually find fellows and form a\nnew flock, which in turn would eventually find other flocks to join.\nAnother interesting aspect of flocking is that the movement algorithm itself is\nstateless—no information is maintained from movement update to movement\nupdate. Each boid reevaluates its environment at every update cycle. Not only does\nthis reduce memory requirements that might otherwise be needed to provide a simi-\nlar behavior using approaches besides flocking, it also allows the flock to react in real\ntime to changing environmental conditions. As a result, flocks exhibit elements of\nemergent behavior—no one member of the flock knows anything about where the\nflock is going, but the flock moves as one mass, avoids obstacles and enemies, and\nkeeps pace with one another in a fluid, dynamic fashion.\n330\n\n\n3.11 Flocking with Teeth: Predators and Prey \n331\nThis technique has proven to be a valuable one for video games, having uses in\neverything from unit formations in an RTS, to realistic behavior of crowds in RPGs.\nThis gem builds on the original article in a number ways, borrowing from some\nof the suggested enhancements outlined there, together with one or two suggestions\nreceived by readers. I'll expand on the original demo, adding some features that\nsomewhat individualize the boids, giving each boid a new feature—hunger. The\nworld itself will be made a bit more difficult to navigate through the introduction of\nobstacles. I'll then introduce a new discriminator that gives our boids a reason to flee\neach other—some will be predators that actually feed on the others! Boids will now\ncome in three flavors: hawks, sparrows, and flies. To this end, we'll be adding a \"Fifth\nRule\":\n• Survival: Steer to eat as needed, or to avoid being eaten if a predator is seen.\nA Whole New World\nThe original cube-shaped world of the first demo is a boring, empty place; nothing\nexists in that realm but the boids themselves. Left to itself (and assuming it didn't run\ninto a boid from another flock), a given boid would pretty much fly around forever,\nwandering aimlessly. The only flocking-related code that might otherwise have influ-\nenced a boid's motion was a minor function I added to the flocking algorithm (in\nCBoid:: Cruising ()), and even that didn't contribute much. The world wrap code\n(which teleported boids flying off one side of the world to the other side) could screw\nup flocks a bit, but they always eventually found each other again.\nMore variety is needed if we're to make the lives of our creations more interesting\nand to provide an environment closer to one that might be found in an actual game.\nTo help give our boids more to think about this time around, we've got to give them\nsomething new to deal with—obstacles.\nObstacles\nAn obstacle is pretty much what it sounds like—something that's in the way. A new\nclass of object called CObstacle has been added to create these. A CObstacle object\nforms an impenetrable cone-shaped barrier that all boids will try to avoid during their\ntravels.\nThis class gives us a simple way to make the world a bit more interesting and pro-\nvides them with some interesting navigational challenges. Obstacles can be created\nanywhere within the world with any arbitrary orientation, using either specified val-\nues or randomly determined ones. The CObstacle: :GetPosition () method has been\nadded to help us with collision detection and in determining if an obstacle is in the\nline of sight of a given boid, while Cobstacle: :GetRelativeDiameter() will return the\nrelative size of the obstacle at the boid's cruising altitude.\n\n\n332 \nSection 3 Artificial Intelligence\nCritters of All Kinds\nFigure 3.11.1 shows how boids now come in three flavors, arbitrarily named hawks,\nsparrows, and flies, as they are all flying creatures. Each serves an important role in the\necology of our gem by hunting and feeding on each other.\n- Moves quick \n- Moves average \n- Moves slow\n- Sees further \n- Sees average \n- Can't see far\n- Hunts Sparrows \n- Hunts Flies \n- Hunts nothing\n- Randomly reproduces\nFIGURE 3.11.1 Types of boids.\nEvery Boid Is a Bit Different\nThe original Simple Flocking demo initialized all boids with various parameters—range\nof sight, maximum speed of flight, etc.—which were identical for all boids anywhere in\nthe world. There were no particular discriminators to distinguish one boid from\nanother, beyond the flock to which it belonged. Boids belonging to other flocks were\nautomatically enemies and avoided like the plague (if that switch was turned on).\nThe Predators and Prey flocking demo individualizes each boid a bit by allowing a\nrandomized component upon boid creation. A boid thus created (via a new construc-\ntor added to the CBoid class) will now have some \"personality,\" making each one a\nlittle bit different from its fellows. Some won't see well, while others will see farther\nthan their brothers. Still others will want to maintain more distance from their fellows\nthan the norm. Some will be hungrier than others, and so on.\nWhy do this? There are a couple of reasons, both of which add to the lifelike\nbehavior of the creatures in our little world. First, providing each boid with slightly\ndifferent capabilities is simply more realistic than an endless army of clones. Second,\nthe differences will combine to provide some novel forms of emergent behavior as our\nboids interact, again providing what in the end is a more realistic representation of a\ngroup of creatures moving en masse. The tug and pull of two boids in the same flock,\none of which wants to maintain a cohesion much tighter than its fellow, will make for\nsome interesting group dynamics, as will a boid that can see an oncoming predator\njust a bit farther than any of his flockmates.\nAdditionally, the new demo adds some finer control over what types of boids\nare considered \"enemies\" and what types aren't. A new parameter has been added to\nthe CBoid constructor that allows specification of that boid's type. This allows for sim-\nple tests to be added to the CBoid:: SeeEnemies () and CBoid:: FindFood () methods to\ncompare types and determine if a given boid is a predator to be avoided or prey to be\nhunted.\n\n\n3.11 Flocking with Teeth: Predators and Prey \n333\nDoes this all add some overhead? Yes, though it's not much. The needs of die par-\nticular implementation, of course, will drive any such design decisions. For example,\nin an RTS game, every unit of archers might well be fairly generic, while in an FPS\ngame, every squad-mate is an individual with unique characteristics.\nFeeding the Flock\nIt follows that if we're going to have classes of boids that feed on one another, we're\ngoing to need something to control that hunger. Nothing outside of the Jaws movies\nhas an insatiable appetite, and our boids are no exception.\nTo represent this, both hawks and sparrows have a hunger rating that decrements\na little each update cycle. \"When it reaches zero, our boid will become hungry and will\nbegin to actively seek out prey to satisfy that hunger. In our demo, hawks hunt for\nsparrows, of course, while sparrow boids will seek out flies. Flies are at the bottom of\nthe food chain and don't eat anything, but they will reproduce if there are enough of\nthem in one flock. Each time a hawk or a sparrow eats, a random test will determine\nif it's still hungry by comparing its current hunger rating to its starting hunger rating.\nFor example, if a hawk starts out with 10 hunger points and has eaten four sparrows,\nthere's a 40-percent chance it will be satisfied and stop eating.\nSince it isn't my desire to build a complicated feeding simulator, both hawks and\nsparrows \"eat\" when they successfully collide with their favorite food. A hawk will\nattempt to close with any sparrow boid it sees, while a sparrow boid will deliberately\nsteer to intercept the nearest fly. Anything eaten is, of course, removed from the\nworld.\nThere's Always Another Fly\nSince hawks feed on sparrows and sparrows feed on flies, flies are both at the low end\nof the food chain and arguably the most important members of it. If they die off,\nevery other boid will too, sooner or later. To prevent this, flies have one feature that\nno other type of boid has—they can reproduce. To do this, I've added a Reproduction\nparameter to the CBoid class that controls the creation of new flies. When enough flies\ncongregate in a flock, they can reproduce, creating a new fly boid every few seconds.\nDinner on the Go\nAs mentioned previously, feeding is a pretty straightforward affair. When a hawk or\nsparrow is hungry (in other words, its Hunger rating has decremented down to zero),\nit will look for the nearest food it sees and try to collide with it. Any hawk that suc-\ncessfully intercepts a sparrow will gain one hunger point and then check to determine\nif it's eaten enough. The sparrow, on the other hand, is immediately removed from the\nworld. Sparrows hunt flies in a similar fashion.\nSince hawks are normally faster than sparrows, and sparrows are normally faster\nthan flies, about the only thing that will prevent a given sparrow or fly from being\neaten is a failure on the part of the predator to catch its prey. Each boid will, of course,\n\n\n334^ \n_ \nSection 3 Artificial Intelligence\nautomatically try to avoid any and all predators it sees, and so that natural motion\nwill help somewhat. Interestingly, the biggest single frustrating factor for predators are\nthe obstacles we'll be scattering about the world. Avoiding collision with them will\noften slow down a predator enough for an individual target to get away—for a while,\nanyway.\nFlocking with Teeth\nThe results of all this effort can be seen in the Flocking with Teeth demo on the CD.\nThe demo maintains the same control features of the original, with the user being\nON me a> \nabje to pan jmj zoorn as desired, turn on bounding bubbles to better visualize boid\nsight, avoidance, and cohesion distances, and so forth.\nA few hawks (the larger delta-shaped objects) prowl in a world filled with obsta-\ncles of all sizes. Groups of sparrows (the medium-sized delta-shaped objects) flit\nbetween masses of flies (the masses of pixel-sized objects), eating them nearly as fast as\nthey can reproduce. Every so often, a hawk becomes hungry and swoops towards the\nnearest flock of sparrows, causing them to scatter in all directions to avoid being\neaten. Often an obstacle will frustrate either predator or prey, preventing capture or\nescape. Scattered flocks of sparrows and flies will seek the safety of others and form\nnew flocks, and the whole cycle starts over again.\nDepending on how the demo is set up, and to some degree blind luck, most\ndemos end in one of two ways. The most likely outcome is what amounts to ecologi-\ncal disaster—the sparrows eat all the flies or the hawks eat all the sparrows. If all the\nflies die off, the sparrows also eventually die too from lack of food, and the hawks (left\nfoodless) will follow soon after. If the sparrows all die because the hawks are just a bit\ntoo good at what they do, the hawks will eventually die as well, leaving a world filled\nwith nothing but flies and obstacles. This seemed to happen quite a bit in most of\nmy tests.\nAnother possibility is a sort of stasis between the sparrows and flies. The hawks\nmight all die off dirough bad luck and not finding any sparrows to eat. If this hap-\npens, the sparrows will live on, feeding on the flies for an indefinite period. They\nmight eventually kill off flies, which puts us back into the first scenario described ear-\nlier, but a balance is also possible, with the flies reproducing just fast enough to keep\nall the sparrows fed and happy.\nIf sparrows and hawks are allowed to reproduce (not the demo default, but\nan easy exercise for the reader), just about any outcome is possible. This is the most\nrealistic way to configure the simulation, but it's also the most difficult to balance\nproperly.\nLimitations and Potential Improvements\nAlthough overall I'm fairly happy with the performance of the demo for the purposes\nof this gem, there are several improvements and enhancements that suggest them-\n\n\n3.11 Flocking with Teeth: Predators and Prey \n335\nselves, particularly if one were to try to adopt this code for a game. Although only flies\ncan reproduce in the demo, it's a simple matter to allow both sparrows and hawks to\ndo so. Another potential improvement that could help \"close the loop\" ecology-wise\nmight be to give the flies something to feed on as well, perhaps hawk feathers.\nVision is still handled very basically, with all boids having perfect 360-degree\nvision that enables them to see infinitely in any direction. In reality, most predators\nhave rather keen and far-sighted forward vision, while most prey animals are fairly\nnear-sighted with vision to the sides (compare the wolf to the sheep, for example). It\nwouldn't be too difficult to make vision in the demo more realistic and force hawks to\nactually search for sparrows rather than simply stumbling across them, although the\nadditional overhead associated with limiting vision (line-of-sight tests, angle-of-vision\ntests, etc.) can add a lot of math overhead.\nAcknowledgments and Other Resources\nAgain, I'd like to thank Christopher Kline (Mitre Corporation) for his excellent\nmethod for computing roll/pitch/yaw (liberally adapted here), originally published in\nhis C+ + Boids implementation (available on his Web site [Kline96]). Another must-\nsee site is the one maintained by the \"father of flocking,\" Craig Reynolds\n[ReynoldsOO], where there are nearly a hundred pointers to uses of flocking in gaming\nand film, along with a huge resource of research on the topic. The author's Web site\n[WoodcockOl] also maintains a number of pointers to flocking articles and pages.\nOne reader of the original Game Programming Gems built a great litde flocking\napp that allows you to vary the influence of each steering behavior in real time\n[GrubOl]. This is a great way to study how these behaviors affect the flock on an indi-\nvidual basis, and how their combination causes the emergent behavior that makes\nflocking so interesting.\nFinally, an excellent book that addresses the topic of artificial life in general, in\naddition to discussing both flocking and boids, is Steven Levy's Artificial Life\n[Levy93].\nReferences\n[GrubOl] Grub, Tom, \"Flocking Demo,\" www.riversoftavg.com/flocking.htm,\nMarch 6, 2001.\n[Kline96] Kline, Christopher, maintains one of several excellent pages on flocking,\ntogether with many demos and sample code, at www.media.mit.edu/-ckline/\ncornellwww/boid/boids.html, August 14, 1996.\n[Levy93] Levy, Steven, Artificial Life: A Report from the Frontier Where Computers\nMeet Biology, Vintage Books, 1993.\n[Reynolds87] Reynolds, C. W. (1987) Flocks, Herds, and Schools: A Distributed Behav-\nioral Model, in Computer Graphics, 21(4) (SIGGRAPH '87 Conference Pro-\nceedings) pp. 25-34.\n[ReynoldsOO] Reynolds, Craig, maintains an extensive reference on flocking and\nsteering behavior at www.red3d.com/cwr/boids/ and has presented a wide variety\n\n\n336 \nSection 3 Artificial Intelligence\nof papers at various conferences discussing the progress he's made in exploring\nand perfecting uses of this technology, December 6, 2000.\n[WoodcockOO] Woodcock, Steven, \"Flocking a Simple Technique for Simulating\nGroup Behavior,\" Game Programming Gems, Charles River Media, 2000.\n[WoodcockOl] Woodcock, Steven, maintains a page dedicated to game AI at\nwww.gameai.com, 2001.\n\n\n3.12\nA Generic Fuzzy State\nMachine in C++\nEric Dybsand\nedybs@ix.netcom.com\nF\nuzzy logic was ably presented in the original Game Programming Gems article\ntitled \"Fuzzy Logic for Video Games\" by Mason McCuskey [McCuskeyOO]. Like-\nwise, a generic Finite State Machine was introduced in that same book, in the article\n\"A Finite-State Machine Class\" written by me [DybsandOO]. This gem will serve to\nmarry these two concepts into a generic Fuzzy State Machine (FuSM) C++ class that\nyou can use in your games, and to provide you with an additional overview of fuzzy\nlogic, as well as some ideas on how to use fuzzy logic in your games.\nFirst, let's briefly review the FAQ definition of fuzzy logic:\n\"Fuzzy logic is a superset of conventional (Boolean) logic that has been\nextended to handle the concept of partial truth—truth values between\n\"completely true\" and \"completely false\" [FAQ97].\"\nThus, instead of the states of ON and OFF, or TRUE and FALSE, a fuzzy state\nmachine can be in a state of almost ON or just about OFF, or partially TRUE or sort\nof FALSE. Or even both ON and OFF or TRUE and FALSE, but to various degrees.\nWhat does this mean to a game developer? It means that a Non-Player Character\n(NPC), for instance, does not have to be just AMD at a player, but that the NPC can\nbe almost MAD, or partly MAD, or really MAD, or raging MAD at a player. In other\nwords, by using a FuSM (implementing fuzzy logic), a game developer can have mul-\ntiple degrees of state assigned to a character (or a concept within the game—more on\nthis later). This could also mean that states in a game do not have to be specific and\ndiscrete (often referred to in the fuzzy logic world as crisp), but can be, well, fuzzy (less\ndetermined). The real advantage to this is discussed in the next section.\nStatus in a FuSM is typically represented internally using the range of real num-\nbers from 0.0 to 1.0; however, that is not the only way we can represent a fuzzy value.\nWe can choose literally any set of numbers, and consider them fuzzy values. Continu-\ning the NPC attitude example [DybsandOO], let us consider how to maintain the \"dis-\nlike portion\" of the attitude of an NPC toward a player within a FuSM. We could use\nthe range of integers from 1 to 25 to indicate that an NPC has a variable feeling of\n337\n\n\n338 \nSections Artificial Intelligence\n99\nThese values could even overlap\ni \nV\n1 \nAnnoyed > 30\nFIGURE 3.12.1 A) Fuzzy values for dislike attitudes toward player. B) Fuzzy values that\noverlap.\nANNOYANCE toward a player, and the range of integers from 26 to 50 may reflect an\nNPC's variable feeling of MAD toward a player, while the range of integers from 51 to\n99 may indicate the NPC's variable feeling of RAGE. Thus, within each type of atti-\ntude toward a player, the NPC may possess various degrees of dislike such as\nANNOYANCE, MAD or RAGE (Figure 3.12.1).\nBefore we leave this brief introduction to FuSMs, let's clear up one common mis-\nconception often associated with fuzzy logic: there is no specific relationship between\nfuzzy values and probability. Fuzzy logic is not some new way to represent probability,\nbut instead represents a degree of membership in a set. In probability, the values must\nadd up to 1.0 in order to be effective. Fuzzy logic values have no such requirement (note\nthe overlap example just presented). This does not mean that fuzzy logic values can't\nhappen to add up to 1.0, it just means that they don't have to for a FuSM to be effective.\nWhy Use a FuSM In a Game?\nIn this author's opinion, the number-one reason to use FuSMs in a computer game is\nthat it is an easy way to implement fuzzy logic, which can broaden the depth of rep-\nresentation of the abstract concepts used to represent the game world and the rela-\ntionships between objects in the game.\nIn essence, to increase gameplay!\nHow do FuSMs increase gameplay, you ask? FuSMs increase gameplay by provid-\ning for more interesting responses by NPCs, by enabling less predictable NPC behav-\nior, and by expanding the options for choices to be made by the human player.\nThus, a player does not encounter an NPC that is just MAD or not MAD about\nbeing attacked by the player. Instead, the player must deal with an NPC that can be\n\n\n3.12 A Generic Fuzzy State Machine in C++ \n339\nvarious degrees of being MAD. This broader array of considerations increases game-\nplay by adding to the level of responses that can be developed for the NPC, and seen\nby the human player.\nAnother effect of adding FuSMs to computer games is to increase the replayabil-\nity of the game. By broadening the range of responses and conditions that the player\nmay encounter in given situations during the game, the player will be more likely to\nexperience different outcomes in similar situations.\nHow To Use FuSMs in a Game\nActually, various forms of FuSMs have been used a lot in computer games!\nOne example of where a FuSM has been used in computer games is for the health\nor hit points of an NPC or agent. Instead of the agent simply being healthy or dead\n(finite states), using a range of hits points can reflect the agent being anything from\ncompletely healthy to partially healthy to almost dead to totally dead (fuzzy states).\nAnother example of using a FuSM in a computer game can be found in the control\nprocess for accelerating or braking an Al-controlled car in a racing game. Using a\nFuSM in this case would provide various degrees of acceleration or braking to be cal-\nculated in lieu of the finite states of THROTTLE-UP or THROTTLE-DOWN and\nBRAKE-ON or BRAKE-OFF actions. And as our ongoing example of representing an\nattitude shows, a FuSM is perfect for representing NPC emotional status and attitude\ntoward the player or other NPCs.\nApplying fuzzy logic to states in a computer game is relatively straightforward, as\nnoted in the previous examples. Those decision processes that can be viewed as having\nmore than two discrete outcomes are perfect candidates for the application of fuzzy\nlogic, and there are many of those processes to be found.\nNow let's consider putting fuzzy logic into a generic C++ class, a FuSM.\nReview of Game Programming Gems' Generic\nFinite State Machine in C++\nThe original Generic FSM in C++ [DybsandOO] consisted of two classes: FSMclass\nand FSMstate. The FSMclass class object encapsulated the actual finite state machine\nprocess, maintained the current state of the FSM, supported the container for the var-\nious FSMstate class objects, and provided control for the state transition process.\nThe FSMstate class object encapsulated a specific state and maintained the arrays\nof input and output states for which a transition could be performed for the state of\nthe object.\nInputs to the FSM were presented to FSMclass: :StateTransition(), which\ndetermined the appropriate FSMstate object that was to handle the input (based on\nthe current state), and then the input was passed to FSMstate:: GetOutput () to obtain\nthe new output state.\n\n\n340 \nSections Artificial Intelligence\nThe new output state was returned to the FSM user process by FSMclass::State -\nTransition () and was also made the new current state of the FSMclass object. Thus,\nthe generic FSM provided a crisp and discrete state transition in response to an input.\nAdapting the Generic FSM in C++ to FuSM in C++\nThere are only a few changes needed to transform the Generic FSM into a FuSM. The\nfirst is to add support to the FSMclass class object for multiple current states. The next\nchange is to modify the FSMstate class to support degrees of being in a state. Finally, we\nneed to modify the state transition process within both class objects to support a tran-\nsition to multiple states and a degree of being in the new state. During this refinement\nprocess, we will morph FSMclass into FuSMclass and the FSMstate class into the\nFuSMstate class.\nThe reader is invited to review the Fuzzy/Finite State Machine project found on\n,-ke companion CD-ROM, and to follow along in that project code as the various\nclasses are referenced.\nThe adaptation process begins with the FuSMclass class that, while similar to\nFSMclass, is now capable of supporting multiple current states (the new FuSMclass\nand FuSMstate class members are shown in bold.) This capability is provided by the\nFuzzyState_List m_list member, which is an STL list object that contains pointers\nto FuSMstate objects. A pointer to any active fuzzy state (based on the current input\nvalue) object is saved in this list. This way, multiple current states can be supported.\nAs in FSMclass before, FuSMclass also maintains an STL map object (the Fuzzy -\nState_Map m_map member) for containing pointers to all possible FuSMstate objects\nthat could be considered by FuSMclass.\nWe continue the adaptation process by developing an access member function\n(called GetNextFuzzyStateMember()) that will provide an accessing service to the\nFuSMclass object. The GetNextFuzzyStateMember() member function maintains a\npointer to the next FuSMstate pointer in the FuzzyStateJ-ist m_list, so that all\nactive current states can be accessed by processes outside of FuSMclass. Thus, this ser-\nvice is how you can get access to the active current states by your program. By contin-\nuing to call GetNextFuzzyStateMember() until you receive a NULL pointer, your\nprogram can determine all the active fuzzy states.\nThe next step in the adaptation process is to modify the FuSMstate class to sup-\nport various degrees of membership. This support is provided by adding the new\nmember variables of int m_iLowRange and int m_iHighRange. For simplicity, this\ndesign views the fuzzy membership range as whole positive numbers, and could be\neasily adapted to view membership as a set of real numbers. For convenience, this\nadaptation also maintains two additional attributes of the FuSMstate object: the value\nof membership in the set for this FuSMstate object (int m_iValueOf Membership), and\nthe degree of membership in the set (int m_iDegreeOfMembership).\nNotice that the biggest difference between the finite state object (FSMstate) and\nour new fuzzy state object (FuSMstate) is that a state transition array is no longer\n\n\n3.12 A Generic Fuzzy State Machine in C++ \n341\nneeded. This is because in fuzzy logic, it is possible to be in one or more states at the\nsame time; while in finite logic, it is possible only to be in one state at a time.\nConcluding the adaptation process involves modifying the state transition\nprocess in both the FuSMclass and FuSMstate objects to support the possibility of\nmultiple current states and to support various degrees of membership within a given\nstate. For FuSMclass, this means modifying StateTransition() to process the Fuzzy-\nState_Map m_map member containing all possible states, giving each FuSMstate object\nan opportunity to effect a transition based on the accumulated input value (the int\nm_iCurrentInput member found in the FuSMclass). Those FuSMstate objects that do\ntransition have their pointers saved off in the FuzzyState_List m_list member, thus\nindicating that the FuSMstate object is an active current state.\nFor the FuSMstate class object, the adaptation process involves replacing FSM-\nstate: :GetOutput () (from the FSM) with a new transition function. The new FuSM-\nstate: :DoTransition() member function accepts the input value maintained by\nFuSMclass and considers the degree of membership this input value represents. If\nmembership within the fuzzy state exists, the member function returns a TRUE and\nmaintains the status of membership for any future access.\nThis completes the adaptation process. For more details and the code listings, see\ntne FuSM project on the companion CD-ROM.\nNow Fuzzy Up Your Games!\nUsing the FuSMclass and FuSMstate classes as a guide, you are now ready to start mak-\ning your games more fuzzy! Doing so will enrich the gameplay experience of your\nplayers and broaden your own understanding of how to deploy one of the more flexi-\nble forms of artificial intelligence tools available to game developers.\nReferences\n[DybsandOO] Dybsand, Eric, \"A Generic Finite State Machine in C++,\" Game Pro-\ngramming Gems, Charles River Media, 2000.\n[FAQ97] \"What is fuzzy logic?\" FAQ: Fuzzy Logic and Fuzzy Expert Systems 1/1\nMonthly Posting, www.faqs.org/faqs/fuzzy-logic/partl/, 1997.\n[McCuskeyOO] McCuskey, Mason, \"Fuzzy Logic for Video Games,\" Game Program-\nming Gems, Charles River Media, 2000.\n\n\n3.13\nImploding Combinatorial\nExplosion in a Fuzzy System\nMichael Zarozinski, Louder Than\nA Bomb! Software\nmichaelz@LouderThanABomb.com\nF\nuzzy logic, when you come right down to it, is just a bunch of \"if-then\" state-\nments. One of the biggest problems in using fuzzy logic is that the number of \"if-\nthen\" statements grows exponentially as you increase the number of fuzzy sets you\n\"if\" together. This is called combinatorial explosion, and can make fuzzy systems slow,\nconfusing, and difficult to maintain. In games, speed is essential, and combinatorial\nexplosion can make the use of fuzzy logic impractical.\nFor an introduction to fuzzy logic see \"Fuzzy Logic for Video Games\" by Mason\nMcCuskey in the first Game Programming Gems [McCuskeyOO]. For this gem, we'll\nprovide some definitions, as there is little agreement on fuzzy logic terminology.\n• Variable. A fuzzy variable is a concept such as \"temperature,\" \"distance,\" or\n\"health.\"\n• Set. In traditional logic, sets are \"crisp\"; either you belong 100 percent to a set or\nyou do not. A set of tall people may consist of all people over six feet tall, anyone\nless than six feet is \"short\" (or more appropriately, \"not tall\"). Fuzzy logic allows\nsets to be \"fuzzy\" so anyone over six feet tall may have 100-percent membership\nin the \"tall\" set, but may also have 20-percent membership in the \"medium\nheight\" set.\nThe Problem\nTable 3.13.1 shows the effects of combinatorial explosion as more variables and/or\nsets are added to the system.\nThis exponential growth in the number of rules can bring any system to its knees\nif every possible rule must be checked on each pass.\n342\n\n\n3.13 Imploding Combinatorial Explosion in a Fuzzy System \n343\nTable 3.13.1 The Effects of Combinatorial Explosion\nNumber of Variables \nSets Per Variable \nNumber of Rules\n2\n3\n4\n5\n6\n7\n8\n9\n10\n5\n5\n5\n5\n5\n5\n5\n5\n5\n52 =\n53 =\n54 =\n55 =\n56 =\n57 =\n58 =\n59 =\n5\n10 =\n25\n125\n625\n3,125\n15,625\n78,125\n390,625\n1,953,125\n= 9,765,625\nThe Solution\nWilliam E. Combs, an engineer at Boeing, developed a method for turning the expo-\nnential growth shown above into linear growth known, appropriately enough, as the\n\"Combs Method.\" This results in a system with 10 variables and 5 sets per variable\nhaving only 50 rules, as opposed to 9,765,625 rules.\nIt is important to note that the Combs Method is not an algorithm for convert-\ning existing \"if-then\" rules to a linear system. You should start from the bottom up,\ncreating rules that fit in with the Combs Method.\nIf you're interested in the theory behind the Combs Method, see the proof at the\nend of this gem.\nThe Real World\nTo bring this theory into the real world, we'll look at a trivial system for calculating\nthe aggressiveness of a unit in a game. For now, we'll consider a one-on-one battle with\nthree variables, ignoring any surrounding units (friend or foe):\n• Our health\n• Enemy health\n• Distance between us and the enemy\nThe health variables have three sets: Near death, Good, and Excellent.\nThe distance variable has three sets: Close, Medium, and Far.\nFinally, our output (aggressiveness) has three sets: Run away, Fight defensively,\nand All-out attack!.\nTraditional Fuzzy Logic Rules\nIf we were using a traditional fuzzy logic system, we'd start creating rules in a spread-\nsheet format as shown in Table 3.13.2.\n\n\nSection 3 Artificial Intelligence\nTable 3.13.2 Some Traditional Fuzzy Logic Rules\nOur Health\nExcellent\nExcellent\nExcellent\nExcellent\nExcellent\nExcellent\nExcellent\nExcellent\nExcellent\nEnemy Health\nExcellent\nExcellent\nExcellent\nGood\nGood\nGood\nNear death\nNear death\nNear death\nDistance\nClose\nMedium\nFar\nClose\nMedium\nFar\nClose\nMedium\nFar\nAggressiveness\nFight defensively\nFight defensively\nAll-out attack!\nFight defensively\nAll-out attack!\nAll-out attack!\nAll-out attack!\nAll-out attack!\nAll-out attack'\nGood\nGood\nClose\nFight defensively\nGood\nNear death\nClose\nFight defensively\nNear death\nNear death\nNear death\nExcellent\nExcellent\nExcellent\nClose\nMedium\nFar\nRun away\nRun away\nFight defensively\nNote that Table 3.13.2 only shows 14 of the 27 possible rules. While a trivial\nexample such as this is fairly manageable, combinatorial explosion quickly conies into\nplay. In a game, we may need to take into account more variables such as the relative\nhealth of our forces and the enemy forces that may join in the battle. If we were to\nrepresent these two additional variables (bringing the total number of variables to\nfive), the table would grow from 27 rules to 243 rules. This can quickly get out of\nhand. Fortunately, the Combs Method only needs 15 rules to deal with the same five\nvariables.\nCombs Method of Fuzzy Logic Rules\nBuilding rules in the traditional system, we look at how the combination of input sets\nrelates to the output. To build rules using the Combs Method, we look at each indi-\nvidual set's relationship to the output and build the rules one variable at a time (Table\n3.13.3).\nIn a Combs Method system, it is recommended that all variables have the same\nnumber of sets as the output variable. This is not an absolute rule, but it gives each\noutput set the chance to be paired with an input set for each variable.\n\n\n3.13 Imploding Combinatorial Explosion in a Fuzzy System\n345\nTable 3.13.3 Each Individual Set's\nRelationship to the Output\nOur health\nExcellent\nAggressiveness\nAll-out attack!\nGood\nFight defensively\nNear death\nRun away\nEnemy health\nExcellent\nAggressiveness\nRun away\nGood\nFight defensively\nNear death\nAll-out attack!\nDistance\nClose\nAggressiveness\nFight defensively\nMedium\nFight defensively\nFar\nAll-out attack!\nConcrete Example\nTo test the system, we'll use the following values:\n• Our health: 76.88\n• Enemy health: 20.1\n• Distance: 8.54\nFigures 3.13.1 through 3.13.3 show the \"Degree of Membership,\" or DOM, for\nthe input values in the system (note that the DOMs for a variable do not have to sum\nto 100 percent).\nr.O;\nFIGURE 3.13.1 Our Health>r a value of 76.88. Near death:\nExcellent: 53%.\n\n\n346\nSection 3 Artificial Intelligence\nfear, death\n1:0\nFIGURE 3.13.2 Enemy Healthy»rd value of 20.1. Near death: 60%, Good: 17%,\nExcellent: 0%.\nFigures 3.13.1 through 3.13.4 were taken from the Spark! fuzzy logic editor,\nwhich allows you to visually create a fuzzy logic system, integrate it into your game,\nand change the AI in real time without having to recompile.\nFIGURE 3.13.3 Distance fir a value of 8.54. Close: 83%, Medium: 0%, Far:\nConcrete Example with the Traditional System\nUsing the rules we created earlier, the rules listed in Table 3.13.4 are activated in the\ntraditional system.\nThe DOM of the input sets are ANDed together to get the output set's DOM. The\nANDing is logically equivalent to taking the MINIMUM of the three input values.\nThe denazification method we're using—center of mass—takes the MAXIMUM\nvalue for the output set then finds the center of mass for the output sets (Figure\n3.13.4).\n\n\n3.13 Imploding Combinatorial Explosion in a Fuzzy System\n347\nTable 3.13.4 These Rules Are Activated in the Traditional System\nOur Health\nEnemy Health\nDistance\nAggressiveness\nExcellent (53%)\nExcellent (53%)\nGood (18%)\nGood (18%)\nGood (17%)\nNear death (60%)\nGood (17%)\nNear death (60%)\nClose (83%)\nClose (83%)\nClose (83%)\nClose (83%)\nFight defensively (17%)\nAll-out attack! (53%)\nFight defensively (17%)\nFight defensively (18%)\n:.AI.oyl\n.23\no;6o\nSO\nm I\nFIGURE 3.13.4 Traditional system output. Fight defensively: 18%; All-out attack: 53%;\nAggressiveness: 68.66.\nConcrete Example Using the Combs Method\nUsing the same input values, the Combs Method rules are listed in Table 3.13.5.\nThe Combs Method result of 60.39 is not exactly the same as the traditional\nmethod (68.66), but we wouldn't expect it to be as we're using a different inference\nmethod. The Combs Method is ORing the values together, which is the same as\ntaking the MAXIMUM (Figure 3.13.5). Traditional fuzzy logic ANDs values\ntogether, which takes the MINIMUM; hence, the difference in the fight defensively\noutput sets.\nNote that (in this case) if we took the MINIMUM of the output sets (and there\nis no rule saying we can't) we would get the exact same result as the traditional fuzzy\nlogic method. This is a result of the rules we selected for the Combs Method. Since\nthere is not an algorithm to convert traditional fuzzy logic rules to the Combs\nMethod, we cannot say that by simply taking the MINIMUM you will always get the\nsame results as in the traditional method.\nThe Proof\nIt is not essential that you understand why the Combs Method works in order to use\nit. Formal logic can be confusing, so this proof is provided for the reader who wishes\nto have a deeper understanding of the theory behind the Combs Method. The Combs\n\n\n348\nSection 3 Artificial Intelligence\nTable 3.13.5 Combs Method system output. Fight defensively: 83%;\nAll out attack: 53%; Aggressiveness: 60.39.\nOur Health\nExcellent (53%)\nGood (18%)\nEnemy Health\nGood (17%)\nNear death (60%)\nDistance\nClose (83%)\nAggressiveness\nAll-out attack! (53%)\nFight defensively (18%)\nAggressiveness\nFight defensively (17%)\nFight defensively (60%)\nAggressiveness\nFight defensively (83%)\niJilli.iiisl'-spgs'^?!\n\"\"H *\nft 00\nFIGURE 3.13.5 Combs Method system output. Fight defensively: 83%, All out attack:\n53%. Aggressiveness: 60.39.\nMethod is based on the fact that the logical proposition (p and q) then r is equivalent\nto (p then r) or (q then r).\nSince fuzzy logic is a superset of formal logic, we can ignore \"fuzziness\" and just\nprove the equivalence of the Combs Method to the traditional method. In Table\n3.13.6, p and q are antecedents and r is the consequence. The antecedents are state-\nments such as \"if Jim is tall\" or \"if Jim is healthy.\" The consequence is a potential\nresult such as \"Jim can play basketball\".\nThis proof is straightforward, except for the x thenjy type clauses. These are stan-\ndard formal logic propositions, but their truth table is confusing—especially when x\nand y are false but the proposition is true. See [aiGuruOl] for some examples that will\nhelp clarify this proposition's truth table.\n",
      "page_number": 319,
      "chapter_number": 33,
      "summary": "Watching the original demo from the first\nbook (also provided on the companion CD-ROM files for this chapter), one can see\ngroups of boids coalesce and move in ripples around their world Key topics include flocking, fuzzy, and fuzziness.",
      "keywords": [
        "Fuzzy Logic",
        "Fuzzy",
        "Generic Fuzzy State",
        "Fuzzy State Machine",
        "Combs Method",
        "Traditional Fuzzy Logic",
        "Fuzzy Logic Rules",
        "Fuzzy State",
        "State",
        "Combs Method system",
        "logic",
        "fuzzy logic system",
        "Game",
        "State Machine",
        "Finite State Machine"
      ],
      "concepts": [
        "flocking",
        "fuzzy",
        "fuzziness",
        "state",
        "logic",
        "logical",
        "object",
        "game",
        "gaming",
        "figures"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 1",
          "chapter": 33,
          "title": "Segment 33 (pages 308-321)",
          "relevance_score": 0.48,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 1",
          "chapter": 25,
          "title": "Segment 25 (pages 227-237)",
          "relevance_score": 0.43,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 1",
          "chapter": 32,
          "title": "Segment 32 (pages 299-307)",
          "relevance_score": 0.42,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 3",
          "chapter": 26,
          "title": "Segment 26 (pages 243-252)",
          "relevance_score": 0.41,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 7",
          "chapter": 63,
          "title": "Segment 63 (pages 609-616)",
          "relevance_score": 0.39,
          "method": "sentence_transformers"
        }
      ]
    },
    {
      "number": 34,
      "title": "Segment 34 (pages 338-346)",
      "start_page": 338,
      "end_page": 346,
      "detection_method": "topic_boundary",
      "content": "3.13 \nImploding Combinatorial Explosion in a Fuzzy System\nTable 3.13\nP..__J7 _.,.\nT \nT\nT \nT\nT \nF\nT \nF\nF \nT\nF \nT\nF \nF\nF \nF\n349\n.6 Antecedents and Consequences\npandq\nT\nT\nF\nF\nF\nF\nF\nF\nT \nIp and q) then r\nT \nT\nF\nT\nF\nT\nF\nT\nF\nF\nT\nT\nT\nT\nT\nT\np then r\nT\nF\nT\nF\nT\nT\nT\nT\nq then r \n(p then r) or (Q then r)\nT \nT\nF\nT\nT\nT\nF\nT\nT\nF\nT\nT\nT\nT\nT\nT\nIf you need visual proof, the Venn diagrams are shown in Figures 3.13.6 and\n3.13.7. Since Venn diagrams can only show AND, OR, and NOT relationships, the\nfollowing conversions are made by material implication:\n• Traditional Logic: (p and q) then r is equivalent to (not (p and q)) or r\n• Combs Method: (p then r) or (q then r) is equivalent to ((not/>) or r) or ((not q)\nor r)\np and q \nnot (p and q) \n(not (p and q)) or r\nFIGURE 3.13.6 Venn diagram for Traditional Logic.\n(not p) or r \n(not q) or r \n((not p) or r) or ((not q) or r)\nFIGURE 3.13.7 Venn diagram for Combs Method.\n\n\n350 \nSections Artificial Intelligence\nConclusion\nIf forced to make a choice between fast and intelligent game AI, fast will win almost\nevery time (ignoring turn-based games). The Combs Method allows you to create AI\nthat is not only fast, but also complex enough to result in rich, lifelike behavior, thus\nproviding a more engaging experience for the player.\nNext time you're faced with creating a complex behavior system, give the Combs\nMethod a try. You may be surprised by the depth of the behavior you can get with\nsuch a small number of rules.\nReferences\n[aiGuruOl] \nZarozinski, \nMichael, \n\"if p \nthen \nq?\" \navailable \nonline at\nwww.aiGuru.com/logic/if_p_then_q.htm, March 5, 2001.\n[Andrews97] Andrews, James E., \"Taming Complexity in Large-Scale Fuzzy Sys-\ntems,\" PC AI (May/June 1997): pp.39-42.\n[Combs99] Combs, William E., The Fuzzy Systems Handbook 2nd Ed, Academic\nPress, 1999.\n[McCuskeyOO] McCuskey, Mason, \"Fuzzy Logic for Video Games,\" Game Program-\nming Gems, Charles River Media, 2000.\n\n\n3.14\nUsing a Neural Network in a\nGame: A Concrete Example\nJohn Manslow, Neural\nTechnologies Limited\njfm96r@ecs.soton.ac.uk\nT\nhe original Game Programming Gems book included a contribution that gave a\nbroad and comprehensive overview of the field of neural networks [LaMotheOO].\nThis gem complements that by providing a concrete illustration of the application of\none of the most useful and widely applied neural networks, the multiplayer percep-\ntron (MLP). In so doing, it describes how to identify problems that can be solved by\nthe MLP, and highlights the steps required to produce a solution.\nThe Game \n_._\nTo provide a concrete illustration of the application of the MLP for this gem, it was\nnecessary to construct an application that was sufficiently simple that the role of the\nneural network was clear, but not so trivial as to have any obvious alternative solution.\nThe application that was settled upon was a simple tank game where two tanks are\nplaced on a randomly generated side-view landscape, with the leftmost tank con-\ntrolled by the player, and the rightmost tank by the computer.\nThe tanks take turns firing at each other, and the first one to score a hit is\ndeclared the winner. Each tank aims by adjusting the inclination of its barrel—a task\nmade especially difficult because the tank's shell decelerates as it travels (due to drag)\nand is affected by wind (which, for simplicity, maintains a constant speed and direc-\ntion for the duration of the shell's flight). The main challenge for the AI is thus how\nto set the inclination of its tank's barrel to hit the enemy tank. This gem will show\nhow an MLP can be taught, by example, to solve this problem.\nThe Multilayer Perceptron\nThe MLP is a type of neural network that became popular in the mid-1980s as a\nresult of the discovery of a particularly efficient way of teaching it. Since then, the\ntechnique has grown rapidly in popularity and is currently one of the most widely\n351\n\n\n352\nSection 3 Artificial Intelligence\napplied neural network architectures in industry, and has even been used in a number\nof games (such as Codemasters' Colin McRae Rally 2.0).\nAlthough more advanced techniques are now common in academia, the MLP\nremains popular because it is one of the easiest to understand, easiest to code, easiest\nto apply, and offers robust performance even in the hands of relatively inexperienced\nusers. The MLP is thus a good starting point for people new to the field of neural net-\nworks and a powerful tool for more experienced users.\nA neural network such as an MLP is really just a complex nonlinear function with\na number of adjustable parameters that can be changed to control its shape. The\nprocess of teaching the network (or training it, as it is more commonly called) is sim-\nply one of adjusting its parameters so that the function it represents takes on a desired\nshape. Although polynomials and splines can be used to address similar problems to\nthe MLP, the structure of the MLP makes it particularly robust.\nThe shape of the function to be learned is indicated by pairs of input-output sam-\nples and thus neural network training consists of nothing more than curve fitting-—\nadjusting the parameters in the network so that it fits roughly tJirough the samples.\nThis process will be familiar to many readers from science class, where it was often\nnecessary to draw smooth curves through data collected from experiments.\nSince neural networks often represent quite complex equations, they are fre-\nquently visualized in terms of directed graphs. For example, Equation 3.14.1 is the\nformula for the output j/ of an MLP with one linear output, N inputs, Xj to x//, and M\nhidden neurons, and Figure 3.14.1 is its graphical representation. Although the MLP\nis represented by a directed graph, arrows are usually omitted from the network dia-\ngram since information flow is always in the direction of input to output.\nInput neurons\nHidden neurons\nMN\nM\nOutput neuron\nFIGURE 3.14.1 The graphical representation of the MLP in Equation 3.14.1. The\nellipses indicate that the number of inputs and hidden neurons can vary.\n\n\n3.14 Using a Neural Network in a Game: A Concrete Example \n353\ny-\n(3.14.1)\nThe adjustable parameters of the network are the w's (weights) and b's (biases),\nthe distinction being that weights connect neurons together, whereas the biases excite\nor inhibit individual neurons even in the absence of other activity in the network. The\nbiases are not shown in Figure 3.14.1 since each can be considered to be part of the\ninternal make-up of an individual neuron. A detailed examination of the structure of\nneural networks is given in [LaMotheOO] and [Haykin94] and will not be repeated\nhere.\nFor the purposes of diis gem, it is sufficient to understand that an MLP represents\nthe function given in Equation 3.14.1, and that that function will be used to calculate\ndie inclination of die AI tank's barrel that is required to hit die player's tank. The w's\nand b's in Equation 3.14.1 are adjustable parameters that we can use to fit the MLP to\na set of samples diat illustrate how the inclination of the barrel should be set, and that\nthose parameters are found using some curve-fitting procedure, otherwise known as\ntraining.\nSo, in order to train the MLP, we need a set of samples that consists of input-\noutput pairings that are examples of how the AI tank's barrel should be set to hit the\nplayer's tank. Clearly, from the problem we're trying to solve, we want the network's\noutput to be the inclination of die AI tank's barrel, but what should die inputs be?\nThis often complex question is considered in the next section.\nInput Selection\nBefore the input-output samples that are required to train the network can be col-\nlected, it is necessary to decide what inputs the MLP is going to need. Clearly, the\ninputs must contain the information necessary for die MLP to calculate the correct\noutput; in diis case, die inclination of the tank's barrel that is required to hit the\nplayer's tank.\nThe selection of inputs is often difficult in practice, since a wide range of informa-\ntion can usually be extracted from the game world, and the problem being solved is\noften too complex or poorly understood to specify exactly what information is useful.\nIn this case, much time can be spent training many different networks with different\ncombinations of input variables to see which perform best. To minimize the effort\nrequired to find good combinations, the following guidelines should be followed:\n• Use prior knowledge about the problem you're trying to solve. Make educated\nguesses about what information in die game world is likely to be relevant. If you\n\n\n354 \nSection 3 Artificial Intelligence\nthink the network output should depend on a particular function of variables,\nadd that function into the set of network inputs.\n• Abstract variables derived as a function of much simpler ones often provide more\nprecise information than any of their constituent parts. For example, in a strategy\ngame, a single indicator of enemy strength may be more useful than lots of indi-\nvidual indicators relating to different aspects of it.\n• Use variables that provide as different information about the game world as pos-\nsible, because this lets you convey the same amount of information with fewer\ninputs. For example, no benefit would be gained in giving the relative positions of\nthe players tank and the AI tank in both polar and Cartesian coordinates since\nthey contain no unique information.\n• Try using combinatorial search algorithms to look for good combinations of\ninputs. For example, forward selection takes a large set of candidate inputs and\nrepeatedly adds single inputs to the network, at each stage adding the one that\nimproves performance the most. Such techniques require minimal human inter-\nvention, but are slow and may fail to find the best combination.\nAlthough it is tempting to avoid the laborious process of input selection by pro-\nviding the network with access to all variables that may be of relevance, this is likely to\nresult in a network that performs poorly and in unpredictable ways. Input selection is\nthe most labor-intensive part of developing a neural network application, and finding\na small set of inputs that is rich in relevant information is crucial to success.\nFortunately, our prior knowledge is sufficient to say exactly what information is\nrequired to work out the inclination of the AI tank's barrel—the displacement\nbetween the tanks (expressed, say, as two inputs, x-displacement and^-displacement),\nand the wind speed and direction (expressed as a single signed input). The drag on the\nshell is fixed, and hence the network does not need to be told the strength of drag, but\nwill learn its effect during training. Now that it has been decided what inputs to use,\nit is possible to collect the samples that will be used during training.\nCollecting Data\nThe simplest and most obvious way to generate samples that show how to set the\ninclination of the AI tank's barrel is for a player to control the AI tank, and to record\nthe selected input variables (relative positions of the tanks and wind speed) and the\ninclination of the AI tank's barrel every time the player controlling the AI tank scores\na hit. This process is repeated until a sufficiently large set of samples is available for\ntraining. Since a human player typically hits the enemy tank only in around one in\nfive shots, the many hundreds or thousands of samples required for training can take\na long time to collect.\nTo generate the samples used in this gem, the data collection process was auto-\nmated by performing simple random searches for the correct inclination. This was\ndone by setting the AI tank's barrel to random inclinations until, by chance, it scored\n\n\n3.14 Using a Neural Network in a Game: A Concrete Example \n355\na hit. At this point, the relative positions of the tanks, the wind speed, and the incli-\nnation that achieved the hit were recorded, and the process repeated for new, ran-\ndomly placed tanks and a random wind speed.\nAlthough this was highly inefficient, it required no human intervention and was\nleft running until a sufficiently large data set had been generated. In addition, the\nsimulation of the game world need not be run at normal speed and may be acceler-\nated by, for example, disabling rendering, provided that this does not change its\nbehavior. Overnight, this process achieved around 1200 hits and hence created a data\nset of roughly 1200 samples.\nOne important question that needs to be asked when collecting data is, \"How\nmuch data should I collect?\" Unfortunately, there is no simple answer to this, because\nit depends on the complexity of the problem you're trying to solve. In practice, pro-\nvided that the number of hidden neurons is kept small (the 10 used in this gem would\nnormally be considered quite a large number), good performance can be achieved\nwith as few as 107 training samples for a network with 7 inputs.\nOne important hazard in developing neural network solutions is that the last-\nminute tweaking of a game engine that is often done to fine-tune game play can, if it\nchanges the behavior of the game world, cause the neural network to perform poorly.\nThis can be overcome by repeating the data collection and training processes to pro-\nduce a new set of parameters for the network. Provided that the changes in the behav-\nior of the game weren't too drastic, the difficult problem of input selection will not\nnormally have to be repeated. Now that we've decided what the network is going to\ncontrol and the inputs it needs, and we've collected some training data to show it\nwhat to do, we're ready to train it.\nTraining the MLP\nAs has already been described, the MLP is a nonlinear function that is fit to a series of\nsamples by adjusting its parameters. This training process is achieved by using an\noptimization algorithm to search for the parameters that minimize a measure of the\nerror with which the MLP reproduces each output sample given their associated\ninput. The mean squared error is the most commonly used error measure and is cal-\nculated from the sum of the squares of the differences between the MLP s outputs and\nthe corresponding outputs in the samples, divided by the number of samples.\nAlthough the gradient descent optimization algorithm is usually used to fit an\nMLP to the training samples, this article uses a rarely applied technique called the\nperturbation search because it is easier to code, easier to understand, and easier to\napply (for example, it is guaranteed to be stable). In addition, the perturbation search\ndoes not require gradient information,\n• Making it easy to experiment with a wide range of network structures, nonlinear-\nities, and error functions.\n• Eliminating common bugs that result from the incorrect calculation of gradient\ninformation or propagation of that information through the network structure.\n\n\n356 \nSection 3 Artificial Intelligence\n• Allowing integer versions of networks (aimed at low-end platforms) to be opti-\nmized directly, avoiding some spurious behaviors that can result from the conver-\nsion of floating-point networks to integer form.\n• Permitting the inclusion of discontinuous functions in the network.\nThe basic perturbation search can be summarized as follows: Measure die perfor-\nmance of the MLR Perturb the MLP's parameters by adding a small amount of\nrandom noise to each one, and remeasure its performance. If its performance deterio-\nrated, restore the parameters to dieir original values. Repeat this process until some\nstopping criterion is met.\nSince all of the techniques that can be used to train an MLP will indefinitely\nimprove its performance (if only incrementally), some decision must be made as to\nwhen to stop training. To this end, the MLP's performance should periodically be\nevaluated in the game, and training should stop either when the measured perfor-\nmance is adequate, or when further training fails to improve performance.\nWhen evaluating the performance of the MLP in the game, great care must be\ntaken to exercise the game in a way that is representative of how the game will actually\nbe played. This ensures that the environment that the MLP is presented with during\nthis testing phase is similar to the one that it will encounter once the game has\nshipped, and hence guarantees that the measured performance is a useful guide to the\nhow the MLP will perform in the final product. If the MLP's performance in the\ngame fails to reach a useful level, consider the following causes:\n• The optimization algorithm has hit a plateau or a local minimum [Bishop95].\nTry restarting training from a random set of parameters.\n• The input samples contain insufficient information about their associated out-\nputs for the network to reproduce them. Repeat the input selection process to\nfind new inputs that contain more relevant information.\n• The network is too simple to learn the relationship between the inputs and out-\nputs in die sample data. Consider transformations of the inputs that might sim-\nplify the relationship, or increase the number of hidden neurons in the network\n(but keep them to an absolute minimum).\n• The samples are not representative of the environment that the network encoun-\nters in game. The behavior of the game world must not change after the training\nsamples have been collected, and the samples must contain everything that the\nnetwork will encounter in-game in the right proportions.\nComputational Issues\nSince game AI operates in an environment in which CPU time is at a premium, it is\nimportant to consider the computational cost associated with neural networks.\nUnfortunately, training an MLP is processor intensive, making the MLP poorly\nsuited to in-game learning and, in most cases, much simpler learning mechanisms can\nalmost always be employed. In contrast, computing the output of a trained MLP\n\n\n3.14 Using a Neural Network in a Game: A Concrete Example \n357\nrequires very little processor time, particularly since all internal quantities can be\nmodeled using integers and nonlinear functions replaced by look-up tables. Such\noptimizations have allowed the MLP to be used in several real-time titles on the PC\nand Playstation.\nResults\nFollowing the steps outlined in the preceding sections, an MLP was created that had\nthree inputs, two consisting of a Cartesian representation of the relative positions of\nthe player's tank and the AI tank, and one representing wind speed. We collected\n1207 examples of successful shots, and the MLP was trained for around two-and-a-\nhalf hours on a PC with a 500MHz Intel Celeron processor. At this time, training was\nstopped because the MLP's performance was as good as was required, achieving a 98-\npercent hit rate in the game.\nConclusion\nThis gem described the steps taken to produce the neural network AI that is used in\nC e>% \nthe simple tank game that is included on the CD. The interested reader is strongly\non me CD \nencouraged to pursue important issues such as input selection and overfitting in refer-\nences such as [Haykin94] and [Bishop95], which are able to provide both a broader\nintroduction and greater detail than is possible here. Finally, there is no substitute for\npractical experience—experiment with the MLP class that accompanies this article\nand apply it to your own problems. Follow the development process that was out-\nlined, and you'll discover neural networks to be a flexible and powerful tool.\nReferences\n[Bishop95] Bishop C. M., Neural Networks for Pattern Recognition, Oxford University\nPress Inc., 1995.\n[Haykin94] Haykin S., Neural Networks: A Comprehensive Foundation, Macmillan\nCollege Publishing Company, 1994.\n[LaMotheOO], LaMothe, A., Game Programming Gems, Edited by DeLoura, M.,\nCharles River Media, Inc, 2000.\n[SarleOl] Sarle, W. S., \"Neural Network FAQ\" available online at www.ci.tuwien\n.ac.at/docs/services/nnfaq/FAQ.html, February 15, 2001.\n",
      "page_number": 338,
      "chapter_number": 34,
      "summary": "This chapter covers segment 34 (pages 338-346). Key topics include games, input, and network. (not p) or r \n(not q) or r \n((not p) or r) or ((not q) or r)\nFIGURE 3.13.7 Venn diagram for Combs Method.",
      "keywords": [
        "Neural Network",
        "MLP",
        "Imploding Combinatorial Explosion",
        "Network",
        "game",
        "Neural",
        "tank",
        "inputs",
        "tank barrel",
        "neural network training",
        "training",
        "samples",
        "MLP performance",
        "simple tank game",
        "Input Selection"
      ],
      "concepts": [
        "games",
        "input",
        "network",
        "tank",
        "training",
        "output",
        "die",
        "samples",
        "information",
        "gems"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 1",
          "chapter": 35,
          "title": "Segment 35 (pages 331-343)",
          "relevance_score": 0.52,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 7",
          "chapter": 63,
          "title": "Segment 63 (pages 609-616)",
          "relevance_score": 0.5,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 7",
          "chapter": 10,
          "title": "Segment 10 (pages 91-99)",
          "relevance_score": 0.48,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 7",
          "chapter": 34,
          "title": "Segment 34 (pages 321-328)",
          "relevance_score": 0.48,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 7",
          "chapter": 62,
          "title": "Segment 62 (pages 601-608)",
          "relevance_score": 0.48,
          "method": "sentence_transformers"
        }
      ]
    },
    {
      "number": 35,
      "title": "Segment 35 (pages 347-359)",
      "start_page": 347,
      "end_page": 359,
      "detection_method": "topic_boundary",
      "content": "4.1\nComparison of VIPM Methods\nTom Forsyth, Mucky Foot Productions\ntomf@muckyfoot.com\nV\niew-Independent Progressive Meshing (VIPM) has moved from the status of an\ninteresting research project, to promising new technology, to sensible addition to\nall the best engines, and now into the Direct3D graphics API itself. It is now becom-\ning almost required for any engine, and its inclusion in the Direct3DX library means\nthat one form of VIPM is relatively easy to add.\nHowever, in an effort to push the performance of VIPM, and in particular to\ndrive the hardware as efficiently as possible, several new forms have been developed,\neach with their own tradeoffs and characteristics. This gem is intended as a guide to\nsome of the more promising versions, and should help people decide which of the\nmany variants to use in particular situations.\nThis gem does assume a basic familiarity with VIPM, and there is no space for a\nthorough introduction here. However, there are several good guides both in print and\nonline. The two best known are Jan Svarovsky's gem in Game Programming Gems\n[SvarovskyOO] and Charles Bloom's Web site [BloomOl], both of which have excellent\nstep-by-step guides to implementations of the \"vanilla\" VIPM method. All of the\nmethods discussed here use the same basic collapse/split algorithm, but implement it\nin different ways.\nConsiderations\nThere are a few main points on which the various methods need to be judged. Differ-\nent situations demand different choices, and the different ways each object type in a\ngame is used may mean that different methods of VIPM are used. Things to consider\ninclude:\n• Global memory cost. How much memory is taken up just by the mesh repre-\nsentation of the model? This memory is shared between all onscreen instances.\n• Instance memory cost. How much memory is used for each instance of the\nobject drawn onscreen? This memory is duplicated for each instance and cannot\nbe shared.\n• Streaming or referenced memory cost. This is the amount of data actually ref-\nerenced on each frame. There may be a large amount of existing data for an\n363\n\n\nSection 4 \nGeometry Management\nobject that is mainly left on CD or swapped out to a hard drive by virtual mem-\nory. However, on each frame the actual amount of data referenced may be small,\nallowing the data to be streamed and/or handled efficiently by the virtual mem-\nory system. This is especially important for consoles that typically have limited\nmemory.\n• CPU cost. How many clock cycles does the algorithm take, in terms of user code?\nThis includes both single-frame rendering costs and the cost of changing the level\nof detail from frame to frame.\n• API interface efficiency. How many CPU cycles are used in driver and API\ninterfaces getting data down to the graphics card?\n• Bus bandwidth. How much data must be sent to the graphics card? On a PC,\nthis means the AGP bus bandwidth.\n• Vertex—cache coherency. Modern graphics cards try to fetch, transform, and\nlight each vertex only once, even though the vertex will be used by multiple tri-\nangles. To do this, they have a vertex cache that holds the most recently used ver-\ntices, and applications need to try to use vertices in this cache as often as possible\nto get maximum performance. An algorithm that uses more triangles than\nanother may still be faster because it has a higher vertex cache hit rate.\nVertex cache coherency will be quoted in terms of the number of vertices loaded\nor processed per triangle drawn, or \"vertices per triangle.\" Current triangle reordering\nalgorithms for static (i.e., non-VIPM) meshes using modern vertex caches of around\n16 entries can get numbers down to around 0.65. For an example, see [Hoppe99].\nThis gives suitable benchmark figures to compare efficiencies when the mesh is con-\nverted to a VIPM one. Also note that when calculating the vertices per triangle using\ntriangle strips, only drawn triangles should be counted, not degenerate ones. The\ndegenerate triangles are a necessary evil—they add nothing to the scene.\nAlgorithms that are good at streaming allow the application to draw huge worlds\nthat are mostly stored on disk, and to degrade image quality gracefully if the stream-\ning of data hits a limit somewhere along the way, such as available disk bandwidth or\navailable memory on the machine.\nThis also helps systems with virtual memory; if the data is accessed linearly, the\nvirtual memory manager can swap out data that has yet to be accessed, or has not\nbeen accessed for a long time. Static data can be optimized even further and made\ninto a read-only memory-mapped file. This also ensures that irritating \"loading level\"\nmessages are no more tedious than absolutely necessary. The object data does not all\nneed to be loaded at the beginning; the player can start playing the level with low-\nresolution data and as the detailed models are needed, they will be loaded.\nAll the methods discussed here are based around implementations of the same\nfundamental algorithm. Single operations are done that collapse a single vertex onto\nanother vertex along one of its triangle edges. No new \"average\" vertex is generated,\nand no collapses between vertices that do not share an edge are allowed. These are\nworth looking into; however, the current consensus is that they involve a higher run-\n\n\n4.1 Comparison of VIPM Methods \n365\ntime cost for equivalent error levels on most current hardware. Of course, things\nchange, and new algorithms are always being invented.\nA note on the terminology used: The resolution of a mesh is proportional to the\nnumber of triangles in it. Thus, a high-resolution mesh undergoes edge collapses and\nbecomes a lower-resolution mesh. The opposite of an edge collapse is an edge split,\nwhere a single vertex splits into two separate vertices. For a given edge collapse, there\nis a kept vertex and a binned vertex. The binned vertex is not used in any lower-\nresolution meshes, whereas the kept vertex is. For a given edge collapse, there are two\ntypes of triangles. Those that use the edge being collapsed will not be in any lower-\nresolution mesh and are binned. For a typical collapse, there are two binned trian-\ngles, although there may be more or less for complex mesh topologies. Those that\nare not binned but use the binned vertex are \"changed\" triangles, and changed so\nthat they use the kept vertex instead of the binned vertex. When performing an\nedge split, the previously binned vertex and triangles are \"new,\" although they are\noften still called binned because there are typically no split data structures, just col-\nlapse data structures that are done in reverse. Most of the perspective is in the col-\nlapsing direction, so words like first, next, before, and after are used assuming\ncollapses from a high-triangle mesh to a low-triangle mesh. Again, splits are done by\nundoing collapses.\nThis gem will be talking in a very PC and DirectX-centric way about CPUs, AGP\nbuses, graphics cards (\"the card\"), system/video/AGP memory, index, and vertex\nbuffers. This is generally just a convenience—most consoles have equivalent units and\nconcepts. Where there is a significant difference, it will be highlighted. The one term\nthat may be unfamiliar to the reader is the AGP bus; this is the bus between the main\nsystem memory (and the CPU) and the graphics card with its memory. There are var-\nious speeds, but this bus is typically capable of around 500Mbytes/sec, which makes\nit considerably smaller than the buses between system memory and the CPU, and\nbetween the graphics chip and its video memory. Some consoles have a similar bottle-\nneck; others use a unified memory scheme that avoids it. In many cases, this is the\nlimiting factor in PC graphics.\nVanilla VIPM\nThis is the best-known version of VIPM, and the version used by the Direct3DX8\nlibrary. It has a global list of static vertices, arranged in order from last binned to first\nbinned. Each time a collapse is done, the vertex being binned by the collapse is the\none at the end of the list, and the number of vertices used is decremented by one. This\nensures that the used vertices are always in a single continuous block at the start of the\nvertex buffer, which means that linear software T&L pipelines always process only\nthe vertices in use.\nThe triangles are also ordered from last binned to first binned. Each edge collapse\ngenerally removes two triangles, although they may actually remove anywhere from\nzero upward for meshes with complex topologies.\n\n\nSection 4 Geometry Management\nTriangles that are not binned but are changed during a collapse simply have the\nindex to the binned vertex changed to that of the kept vertex. Since the index list\nchanges as the level of detail changes, the triangle index buffer is stored as per-instance\ndata. The index buffer is comprised of indexed triangle lists (each triangle defined by\nthree separate indices), rather than indexed triangle strips.\nEach record of collapse data has the following format:\nstruct VanillaCollapseRecord\n{\n// The offset of the vertex that doesn't vanish/appear.\nunsigned short wKeptVert;\n// Number of tris removed/added.\nunsigned char bNumTris;\n// How many entries in wlndex0ffset[] .\nunsigned char bNumChanges;\n// How many entries in wlndex0ffset[] in the previous action.\nunsigned char bPrevNumChanges;\n// Packing to get correct short alignment.\nunsigned char bPadding[1];\n// The offsets of the indices to change.\n// This will be of actual length bNumChanges,\n// then immediately after in memory will be the next record.\nunsigned short wlndex0ffset[] ;\nThis structure is not a fixed length — wlndexOf f set [ ] grows to the number of ver-\ntices that need changing. This complicates the access functions slightly, but ensures\nthat when performing collapses or splits, all the collapse data is in sequential memory\naddresses, which allows cache lines and cache prefetching algorithms to work .effi-\nciently. It also allows the application to stream or demand-load the collapse data off a\ndisk very easily. Because it is static and global, it can also be made into a read-only\nmemory-mapped file, which under many operating systems is extremely efficient.\nAlthough at first glance bPrevNumChanges doesn't seem to be needed for collapses,\nit is needed when doing splits and going back up the list — the number of wlndexOff -\nset[] entries in the previous structure is needed so they can be skipped over.\nAlthough this makes for convoluted-looking C, the assembly code produced is actu-\nally very simple.\nTo perform a collapse, the number of vertices used is decremented since the\nbinned vertex is always the one on the end. The number of triangles is reduced by\nbNumTris; again, the binned triangles are always the ones on the end of the list.\nThe changed triangles all need to be redirected to use the kept vertex instead of\nthe binned one. The offsets of the indices that refer to the binned point are held in\nwlndexOff set[]. Each one references an index that needs to be changed from the\nbinned vertex's index (which will always be the last one) to the kept vertex's index —\nwKeptVert.\n\n\n4.1 Comparison of VIPM Methods\n367\nVanillaCollapseRecord *pVCRCur = the current collapse;\niCurNumVerts-;\niCurNumTris -= pVCRCur->bNumTris;\nunsigned short *pwlndices;\n// Get the pointer to the instance index buffer.\np!ndexBuffer->Lock ( &pwlndices );\nfor ( int i = 0; i < pVCRCur->bNumChanges; i++ )\n{\nASSERT \n( \npwIndices[pVCRCur->w!ndexOffset[i]] \n==\n(unsigned shortJiCurNumVerts );\npwIndices[pVCRCur->w!ndexOffset[i]] = pVCRCur->wKeptVert;\n}\n// Give the index buffer back to the hardware.\np!ndexBuffer->Unlock();\n// Remember, it's not a simple ++\n// (though the operator could be overloaded).\npVCRCur = pVCRCur->Next();\nNote that reading from hardware index buffers can be a bad idea on some archi-\ntectures, so be careful of exactly what that ASSERT () is doing—it is mainly for illustra-\ntion purposes (Figure 4.1.1).\nIndex list\nVanillaCollapseRecord\nwKeptVert = 4\nbNumTris = 2\nbNumChanges = 3\nbPrevNumChanges = -1\nwlndexOffset [3] = {\n1,\n5,\n12}\nIndex list\n148\n846\nFIGURE 4.1.1 An edge collapse with before and after index lists and the VanillaCollapseRecord.\n\n\n368 \nSection 4 Geometry Management\nDoing a split is simply a matter of reversing the process.\nVanillaCollapseRecord *pVCRCur = the current collapse;\npVCRCur = pVCRCur->Prev();\nunsigned short *pwlndices;\np!ndexBuffer->Lock ( &pwlndices );\nfor ( int i = 0; i < pVCRCur->bNumChanges; i++ )\n{\nASSERT ( pwIndices[pVCRCur->w!ndexOffset[i]] ==\npVCRCur->wKeptVert );\npwIndices[pVCRCur->w!ndexOffset[i]] =\n(unsigned shortJiCurNumVerts;\n}\niCurNumTris += pVCRCur->bNumTris;\niCurNumVerts++;\nplndexBuffer->Unlock();\nNote that in practice, and for arbitrary historical reasons, in the sample code the\nVertexCollapseRecords are stored last first, so the Prev() and Next () calls are swapped.\nVanilla VIPM is simple, easy to code, and has decent speed. It should probably be\nthe first version used for any evaluation of VIPM, because it is so simple, and even\nthis will give good scalability, streaming, and so on.\nThe good thing about vanilla VIPM is that it streams very well. Collapse infor-\nmation and index buffer data is completely linear in memory and ordered by collapse,\nso implementing a streaming system with fallbacks for when data is not immediately\navailable is extremely easy.\nHowever, there are many bad things about vanilla VIPM. Vertex cache coherency\nis poor. Because triangle order is strictly determined by collapse order, there is no\nway to reorder triangles for better vertex caching.\nAnother problem is the relatively large per-instance memory use. The whole\nindex data chunk needs to be replicated for each instance. This can be reduced by\nonly allocating as many indices as are actually currently being used, and growing or\nshrinking as needed (along with a bit of hysteresis to prevent calling malice () and\nf ree() all the time), but it is still large if there are lots of objects onscreen.\nFinally, vanilla VIPM only works with indexed triangle lists, which can be a poor\nchoice for hardware that prefers strips.\nSkip Strips\nSkip strips is a slightly overloaded name. It was borrowed from a paper on View-\nDependent Progressive Meshing (VDPM) [El-Sana99]. VDPM is significantly more\ncomplex and requires some fairly extensive data structures to achieve good efficiency,\nand a skip list is one of those data structures. However, the section that inspired this\nVIPM method was the bit that noted that to bin a triangle, it does not have to fall off\nthe end of the index list, as in vanilla. There is not much wrong with simply making\nit degenerate by moving one of its vertices (usually the binned vertex) to another one\n\n\n4.1 Comparison of VIPM Methods \n369\n(usually the kept vertex), and leaving it in the list of drawn triangles. Hardware is very\ngood at spotting degenerate triangles, and throws them away very quickly without\ntrying to draw any pixels.\nThis means that the order of triangles is no longer determined by collapse order;\nthey can be ordered using some other criteria. The cunning thing that the original\nskip strips paper pointed out is that triangles can now be ordered into strip order, and\nindeed converted into strips. This is great for hardware that prefers its data in strip\norder. Since this VIPM method was inspired by the paper, it inherited the name,\ndespite it being somewhat inaccurate.\nThe ability to reorder triangles increases vertex cache coherency. Strips are natu-\nrally good at this—they have an implicit 1.0 vertices per triangle efficiency (for long\nstrips with no degenerates), and with the right ordering and a decent-sized vertex\ncache, they can get much lower values.\nOne cunning thing about the implementation is that the collapse/split routines\nand data structures are virtually identical to vanilla VIPM. The only change is that the\nnumber of drawn triangles does not change with collapses and splits. Triangles simply\nbecome degenerate; they do not fall off the end of the list.\nHowever, this shows a big problem with skip strips. After many collapses, there\nare many degenerate triangles in the list. Although they are rejected by the hardware\nquickly, they still take some time to reject, and their index data still has to be sent to\nthe card. This eats into the bus bandwidth, and lowers the visible triangle throughput\nin triangles/second.\nAfter many collapses, the vertex cache efficiency also drops. The nice neat strips\nwill have been bent and broken by the collapses, which disrupts the cache efficiency.\nMoreover, as triangles become degenerate, the number of indices referring to one of\nthe remaining vertices increases. A collapse that bins that vertex must change all the\nindices that refer to it, including the degenerate triangles. Therefore, the more col-\nlapses that are done, the more expensive each collapse becomes, because the size of\nwlndexOffsett ] grows. This does not scale with the number of triangles drawn,\nwhich is no good since that is the whole point of VIPM—things at lower detail\nshould take less time to render.\nMultilevel Skip Strips\nFortunately, there is a solution to most of skip strip's woes. After a certain number of\ncollapses, simply stop, take the current geometry with all of its collapses done, throw\naway the degenerate triangles, and start making a completely new skip strip from\nscratch. Continue collapses with this new skip strip until it too becomes inefficient,\nand so on.\nWhen creating each new skip strip level, all of the degenerate triangles are thrown\naway, which reduces the number of triangles (both visible and degenerate) that are\nsent to the card. The triangles are also reordered to make lists that are again vertex-\ncache optimal. New collapses don't need to change lots of degenerate triangle indices\n\n\nSection 4 Geometry Management\neach time, each instance only needs to copy the skip strip level that it actually uses,\nand they become shorter with decreasing detail.\nThe different index lists can be stored globally since when switching to a new list,\na new copy is taken and then refined with collapses to exactly the number of triangles\nwanted. Therefore, the fact that there are now multiple index lists is not too bad—its\nglobal data. This also restores some of the nice streaming friendliness that the vanilla\nmethod has. The granularity is a bit coarser; the whole of an index list must be\ngrabbed before anything can be rendered using that level, but at least it's no longer an\nall-or-nothing thing, and the lower-resolution index lists are actually very small.\nFor a bit more efficiency, two versions of the index lists can be stored in global\nspace: fully collapsed (before switching to a lower-resolution list, that is) and fully\nuncollapsed. This means that a single-collapse oscillation across the boundary\nbetween two index lists is still fairly efficient. If only the uncollapsed versions are held,\neach time the level of detail increases, the higher-resolution index list must be copied,\nand then all of its collapses need to be performed to draw the next frame. Having the\ncollapsed versions stored as well means that a change in the level of detail of n col-\nlapses only actually requires n collapses (and sometimes fewer).\nThe actual collapse/split code and structures are the same as for standard skip\nstrips, except that there is a global array of structures holding the premade index lists,\nthe collapse lists for each one, and the number of collapses in each. Before doing any\ncollapses or splits, the code checks to see if it needs to change levels, and if so, copies\nthe new level's index list and starts doing collapses/splits until it reaches the right level\nof detail within that level.\nSo, this has fixed all the bad things about skip strips when compared to vanilla in\nexchange for an increase in global (but easily streamed or swapped) memory.\nSkip strips also have an equivalent using triangle lists instead of triangle strips.\nThe principle is exactly the same, but use a different primitive. Some algorithms\nrequire lists rather than strips, and some vertex cache routines can obtain slightly\nhigher caching rates with lists than strips. No separate implementation was done in\nthe sample code, because they are so similar.\nMixed-Mode VIPM\nOne of the problems with the types of VIPM mentioned so far is that the whole index\nlist needs to be copied for each instance of the object. This can be quite a burden in\nsome cases, especially on machines with limited memory, notably consoles, where\neverything has to be shoehorned into memory that is usually half the size that the pro-\ngrammers would like, even before VIPM is mentioned. It would be excellent if some\nof this index list could be moved to global (i.e., static and shared between instances)\nmemory instead of having to be copied for each instance.\nOn a multilevel skip strip, many of the triangles are not affected, even when that\nlevel is fully collapsed. Therefore, there is no need to copy those triangles per instance;\n\n\n4.1 Comparison of VIPM Methods \n371\nthey can be global and shared between instances. In fact, for this algorithm, indexed\nlists are used—the indexed strip case will be discussed later as a variant. At each level,\nthe triangles are split into four lists:\n• The triangles that are not affected by any collapses.\n• The triangles that are binned by collapses, but not modified by any before they\nare binned.\n• The triangles that are modified by collapses, but not binned.\n• The triangles that are first modified by one or more collapses and then binned.\nLists 2 and 4 are each sorted by bin order, just as for vanilla VIPM. Lists 1 and 3\nare sorted into whatever order gives the highest vertex cache efficiency. Then list 2 is\nappended to list 1, and the combined list is put into a global index buffer that is sta-\ntic and shared by all instances. List 4 is appended to list 3, and the combined dynamic\nlist is copied into instances when they use that level. This list is then modified at run-\ntime using exactly the same modification algorithm as vanilla VIPM.\nTo draw the mesh, the required collapses and splits are done to the dynamic per-\ninstance list, and the list is drawn. Then the associated level's static list is drawn, with\nthe only modification being that the number of triangles drawn will change as static\ntriangles are collapsed.\nThe code and structures needed are based on the multilevel skip list, except that\nfor each level there are two lists: the copied dynamic one and the shared static one.\nThe other change is that there are two triangle counts, one for each list, and a collapse\nmay alter either or both of these numbers. Therefore, the bNumTris member is\nreplaced by bNumStaticTris and bNumDynamicTris, and the appropriate increments\nand decrements are added.\nThis means that a large proportion of each mesh is being drawn from a static\nindex buffer that is tuned for vertex cache coherency (list 1). It is not quite as good as\nit could be, since the triangles in this list only make up part of the object. There will\nbe \"holes\" in the mesh where triangles have been moved to the other three lists, and\nthis decreases both the maximum and the actual vertex per-triangle numbers that are\nobtained. Some of the dynamic buffer is also ordered for optimal vertex cache behav-\nior (list 3), although collapses can interfere with this efficiency, and the mesh for list 3\nis usually far from usefully connected, so there is a limit to what any reordering\ncan do.\nLike all multilevel methods, it is streaming friendly; although in this case, since\nthe lists are ordered by collapse order, the granularity is even finer at the triangle level,\nnot just the list level. Whether this is terribly exciting is a different question—the\nfiner control is probably not going to make much of a difference in performance.\nThis does require two DrawIndexedPrimitive() calls to Direct3D (or equivalent\nAPI), although on most platforms, this is not a bottleneck and does not affect render-\ning speed. It may be important for very low-triangle meshes, and for these, switching\nto another method may be appropriate.\n\n\n372 \nSection 4 Geometry Management\nMixed-Mode Skip Strips\nMixed-mode skip strips are identical to mixed-mode lists, except that strips are used,\nand instead of the dynamic list being done with vanilla VIPM, it is done using the\nskip strips algorithm. As with skip strips, using strips means that ordering by collapse\norder is too inefficient, and diis means that list 2 triangles now have to be binned by\nbeing made degenerate. This forces them to become dynamic instead of static, and\nthey join lists 3 and 4. The triangles from these three lists are merged and treated as a\nskip strips —reordered for optimal vertex cache efficiency, copied for each instance,\nand modified by collapse information.\nThe disadvantages with this method are that there is now more data being copied\nfor each instance, and because the triangles are ordered by strip order and not collapse\norder, triangles cannot be binned entirely by simply dropping them off the end of the\nindex list. However, both these factors are only mildly worse than the list version, and\nif the hardware needs to be fed strips, this is still an excellent method.\nSliding Window\nSliding window VIPM introduces the idea of fully static and global index buffers,\nwith no editing of indices, and therefore a tiny amount of per-instance memory.\nSliding window notes that when a collapse happens, there are two classes of trian-\ngles: binned triangles and modified triangles. However, there is no real need for the\nmodified triangles to actually be at the same physical position in the index buffer\nbefore and after the collapse. The old version of the triangles could simply drop off\nthe end of the index buffer along with the binned triangles, and the new versions\nadded on at the other end.\nTherefore, instead of an example collapse binning two triangles and editing three\nothers, it actually bins five triangles and adds three new ones. Both operations are per-\nformed by just changing the first and last indices used for rendering—sliding a \"ren-\ndering window\" along the index buffer (Figure 4.1.2).\nThe index buffer is split into three sections. At the beginning are triangles added\nas a result of changes, in reverse collapse order. In the middle are triangles not affected\nby collapses, in any (vertex cache-optimal) order. At the end are triangles binned or\nchanged by collapses, again ordered in reverse collapse order—first collapse at the\nend. Note that a triangle modified as the result of a collapse cannot then be involved\n(either binned or changed) in another collapse. To be modified by a second collapse\nwould mean that triangle would have to fall off the end of the index buffer. It has\nalready been added to the beginning so it cannot then also fall off the end—the\nchance of the ordering being just right to allow this are incredibly slim.\nOnce a triangle has been modified by a collapse, the only way it can be involved\nin another collapse is if a new index buffer is started that has all the same triangles as\nthe previous (collapsed) one. The ordering of this new one is not constrained by the\nprevious collapses, and so can be sorted by new collapses. Again, the multilevel con-\n\n\n4.1 Comparison of VIPM Methods\n373\nIndex List \nSlidingWindowRecord\ndwFirstlndexOf fset = 0,\nwNumTris = 7,\nwNum Verts = 8\ndwFkstlndexOffset =9,\nwNumTris = 9,\nwNum Verts = 9\nFIGURE 4.1.2 A collapse showing the index list and the two windows.\ncept is used, but in this case because further collapses cannot happen without it, not\nsimply for efficiency.\nThe problem with this at face value is that algorithms such as QEM give an\nordering for collapses. If this ordering is strictly followed, the QEM frequently wants\nto do a new collapse that involves a triangle that has already been modified by a pre-\nvious collapse. This forces a new level to be made, and the index buffer needs to be\ncopied. Since only a few collapses have been done, this copy is almost as big as the\noriginal. If only a few collapses are done before having to make a copy, the memory\nused for all the index buffers is going to be huge.\nHowever, there is actually no need to strictly follow the order of collapses that\nQEM decides. Progressive meshing is not an exact science, since it ignores everything\nbut the distance of the camera from the object, and the whole point is to simply be\n\"good enough\" to fool the eye. Therefore, diere is no real need to precisely follow the\ncollapse order that QEM decides—it can be manipulated a bit.\nThe way to do this is to follow the QEM collapse order until it decides to do a\ncollapse that involves triangles that have already been modified. Doing this collapse\nwould force a new level, and so this is put off for as long as possible. For the moment\n\n\n374 \nSection 4 Geometry Management\nthis collapse is ignored, and the best one that can be done without creating a new level\nis found. The errors of the two collapses are compared, and if they are within a certain\ntolerance, then doing them out of strict order is not going to affect visual quality all\nthat much, and the collapse that will not force a new level is done.\nOnce the difference in error levels is too great, then doing the wrong collapse first\nis going to affect image quality significantly, and the algorithm bites the bullet and\ncreates a new level. There have now been a decent number of collapses done before\nthis copy happens, the triangle count has been significantly reduced, and thus far,\nfewer levels are needed before they collapse down to the minimum level of detail.\nThe sample code uses a fairly small tolerance level of 10 percent of the average\ncollapse error, and even this small tolerance reduces the number of levels dramatically.\nUsing a larger error tolerance can reduce the memory use even more, although only to\na point. After a while, the algorithm simply runs out of triangles that have not already\nbeen involved in a collapse. Most meshes can only lose around 20 percent of their tri-\nangles before this happens, but this still keeps memory use at sensible levels.\nSince no runtime modification is made to the index or vertex lists, all the data can\nbe made global, and there is almost zero per-instance memory use. There is also\nalmost zero CPU time used to change level of detail—each time, a simple table look-\nup is made to decide the index list to use, the start and end index to draw from that\nindex list, and how many vertices are used. In practice, the index lists are concate-\nnated together, so that the first index also implies the index list to use. The table is\ncomposed of this structure:\nstruct SlidingWindowRecord\n{\nunsigned int \ndwFirstlndexOffset;\nunsigned short wNumTris;\nunsigned short wNumVerts;\n};\nAlthough the number of triangles and vertices is known to be less than 64k (this\nis a limit in all currently known hardware), because the index list is a concatenation of\nmany lists, it may easily be greater than 64k indices in length, so 32 bits are required\nfor it. This does mean that the structure is nicely padded to 8-byte alignment,\nthough. The rendering code is amazingly simple:\nSlidingWindowRecord &pswr = swrRecords[iLoD];\nd3ddevice->DrawIndexedPrimitive (\nD3DPT_TRIANGLELIST, // Primitive type\n0, \n// First used vertex\npswr->wNumVerts, \n// Number of used vertices\npswr->dwFirst!ndexOffset,// First index\npswr->wNumTris ); \n// Number of triangles\nThere is no code to do splits or collapses as with all the other methods—the cur-\nrent level of detail is just looked up in die SlidingWindowRecord table each time the\n\n\n4.1 Comparison of VIPM Methods \n375\nobject is rendered. This also means that with hardware transform and lighting cards,\nthe CPU time required to render objects is fixed and constant per object, whatever\ntheir level of detail. The phrase \"constant time\" is always a good one to find lurking in\nany algorithm.\nThe major problem with sliding window VIPM is that it forces the ordering of\nthe triangles at the beginning and end of each level's index lists. This has two effects:\nit makes strips hard to use—only triangle lists really handle fixed ordering well—and\nvertex cache efficiency is affected.\nFortunately, it is not as bad as it first seems. When an edge collapse is performed,\nall of the triangles that use the binned vertex are removed, so they all go on the end of\nthe triangle list. This is typically from five to seven triangles, and they form a triangle\nfan around the binned vertex. Then the new versions of the triangles are added. These\nneed to go together at the beginning of the index list, there are typically three to five of\nthem, and they form a triangle fan around the kept vertex. These fans can be ordered\nwithin themselves to get the best cache coherency. The middle of the index list that is\nnot affected, and thus has no set order, can be reordered for the vertex cache. This gets\nmuch better cache coherency than vanilla. Although it is still quite a bit short of the\ntheoretical ideal, it is not unreasonably poor.\nVertex cache coherency can be raised by having a larger middle index list section\nin each level—by having fewer collapses per level. This takes more memory, but the\nextra performance may be worth it, especially as it is global memory.\nHardware that requires strips rather than lists can still use this method, although\nit does require many degenerate triangles to join the different parts. In practice, this\ndoes not increase the number of indices required, it actually reduces it—strips have\none index per triangle, compared to a list's three. The vertex cache efficiency per\ndrawn triangle is exactly the same. The raw triangle throughput is increased a lot\n(roughly doubled), but since all of these extra triangles are just degenerate, most hard-\nware will reject them very quickly. If there is a choice, which of the two primitives\nused depends on whether the hardware is limited by index bandwidth (in which case,\nstrips are optimal) or triangle throughput (in which case, lists are optimal).\nSummary\nVIPM seems to be coming of age. It is now mainstream, it has been incorporated into\na major API, and for discrete objects it has beaten off VDPM and static level of detail\nmethods for the most visual bang for the CPU buck (although it is worth noting that\nVDPM methods are still challengers for large landscapes, especially regular-height-\nfield ones). In addition, it now has a plethora of methods from which to choose, each\nwith its own advantages and disadvantages. Innovation certainly won't stop there—\nthere are already some interesting paths for future investigation, but this roundup\nshould give a fairly good guide to some of the issues and options when choosing\nwhich VIPM method to implement.\n",
      "page_number": 347,
      "chapter_number": 35,
      "summary": "This chapter covers segment 35 (pages 347-359). Key topics include collapse, collapsed, and triangles. The two best known are Jan Svarovsky's gem in Game Programming Gems\n[SvarovskyOO] and Charles Bloom's Web site [BloomOl], both of which have excellent\nstep-by-step guides to implementations of the \"vanilla\" VIPM method.",
      "keywords": [
        "triangles",
        "index list",
        "VIPM",
        "collapse",
        "list",
        "index",
        "Vertex",
        "VIPM Methods",
        "vertex cache",
        "Vanilla VIPM",
        "binned vertex",
        "binned",
        "strips",
        "index buffer",
        "level"
      ],
      "concepts": [
        "collapse",
        "collapsed",
        "triangles",
        "list",
        "index",
        "vertex",
        "strips",
        "level",
        "methods",
        "cache"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 1",
          "chapter": 47,
          "title": "Segment 47 (pages 450-461)",
          "relevance_score": 0.62,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 3",
          "chapter": 34,
          "title": "Segment 34 (pages 326-336)",
          "relevance_score": 0.61,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 3",
          "chapter": 36,
          "title": "Segment 36 (pages 347-355)",
          "relevance_score": 0.61,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 7",
          "chapter": 44,
          "title": "Segment 44 (pages 413-428)",
          "relevance_score": 0.58,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 1",
          "chapter": 3,
          "title": "Segment 3 (pages 19-28)",
          "relevance_score": 0.53,
          "method": "sentence_transformers"
        }
      ]
    },
    {
      "number": 36,
      "title": "Segment 36 (pages 360-367)",
      "start_page": 360,
      "end_page": 367,
      "detection_method": "topic_boundary",
      "content": "376 \nSection 4 Geometry Management\nTable 4.1.1 Summary of Strengths and Weaknesses of Each VIPM Method\nVertex cache use\nGlobal memory use\nInstance memory use\nLoD-change CPU cost\nAPI efficiency\nList efficiency\nVanilla\nPoor\nLow\nHigh\nMedium\nGood\nPoor\nSkip Strips\nExcellent\nMedium\nHigh\nMedium\nGood\nExcellent\nMixed-Mode\nGood\nMedium\nMedium\nMedium\nGood\nGood\nSliding Window\nGood\nHigh\nLow\nTiny\nExcellent\nGood\nTable 4.1.1 shows the results of each method with their relative strengths and\nweaknesses. Note that \"skip strips\" refers to multilevel skip strips—the single-level\nversion is not actually a sensible method in practice, for the reasons given.\nReferences\n[SvarovskyOO] Svarovsky, Jan, \"View-Independent Progressive Meshing,\" Game Pro-\ngramming Gems, Charles River Media, 2000, pp. 454-464.\n[BloomOl] Bloom, Charles, VIPM tutorial, and various VIPM thoughts gathered\nfrom many sources, www.cbloom.com/3d/index.html.\n[Hoppe99] Hoppe, Hugues, \"Optimization of Mesh Locality for Transparent Vertex\nCaching,\" Computer Graphics (SIGGRAPH 1999 proceedings) pp. 269-276.\nSee also www.research.microsoft.com/-hoppe/.\n[El-Sana99] J. El-Sana, F. Evans, A. Varshney, S. Skiena, E. Azanli, \"Efficiently Com-\nputing and Updating Triangle Strips for View-Dependent Rendering,\" The Jour-\nnal of Computer Aided Design, vol. 32, no. 13, pp. 753-772. See also\nwww.cs.bgu.ac.il/-el-sana/publication.html.\n\n\nSimplified Terrain Using\nInterlocking Tiles\nGreg Snook\ngregsnook@home.com\nW\nith recent advancements in 3D rendering hardware, it seems that everyone is\nbringing his or her game to the great outdoors. Far horizons and mountainous\nlandscapes, once hidden by fog and far clipping planes, are now an obtainable reality.\nGame programmers once consumed with the BSP tree and span-based rendering\nmethods are now trading in tired old buzzwords for shiny new acronyms like ROAM\nand VDPM.\nROAM (Real-time Optimally Adapting Meshes) [Duchaineau] and VDPM (View\nDependent Progressive Meshes) [Hoppe98] are outlined elsewhere in great detail (see\nthe References), so I'll just give them a quick overview here. Both of these methods do\nan amicable job of reducing the polygon count (and therefore the rendering load) on\nthose parts of the terrain that do not require a great deal of geometry, such as reason-\nably flat plains or areas far off in the distance. In turn, they allow more detailed terrain\nto exist closer to the camera, or on very rough surfaces, where additional polygons are\nneeded. Essentially, they are two rather complex ways to achieve the same simple goal:\nmore polygons where you need them, less where you don't.\nThe trouble for some applications is that methods such as ROAM and VDPM\ntend to rely on procedurally generated geometry to achieve a smooth transition from\nlow- to high-detail areas. ROAM uses a binary tree of triangle intersections to con-\nstruct the actual terrain geometry from a given height field. VDPM achieves a similar\neffect by using a coarse mesh to represent the low-detail terrain and applying a set of\nsuccessive vertex splits to further divide the terrain polygons where necessary. In most\ncases, these continuous triangulations disrupt the speed advantage of hardware trans-\nform and lighting, which relies on static geometry for optimum speed.\nThe main reason for this is that diese methods work almost too well. They have the\npower to analyze die terrain down to the poly level, hand-picking tliose that stay and\nthose that get collapsed. This can result in many minute changes to the terrain geome-\ntry over time, and requires reprocessing of the entire method should the terrain change.\nBy sacrificing that finite level of control over the geometry, we can remain hardware\nfriendly by working over larger areas of static geometry and remain flexible to changes in\nthe terrain over time.\n377\n\n\n378 \nSection 4 Geometry Management\nWhat this gem proposes is a far simpler method that most applications can\ntake advantage of with a minimal amount of coding. It is not intended to wrestle with\nthe visual quality that ROAM or VDPM methods can produce; instead, it serves to\ncreate a simple terrain with the benefits of dynamically adapting detail levels and ani-\nmation flexibility. It does this while maintaining a data system that is perfectly suited\nfor hardware transform and lighting.\nTiles Revisited\nMany moons ago, game programmers used 2D tiles to represent the playfield. This\nwas done for one simple reason: less artwork was easier to create and manage. Early\ngames simply did not have the memory to afford a large amount of pixel data, so\nsmaller pictures were tiled to create the illusion of a larger area. These small tiles were\nalso easier to draw and push around, so smooth-scrolling 2D games could easily be\ncreated out of little 32x32 pixel tiles.\nThe terrain method presented here works on the same basic principle by dividing\nthe terrain into smaller, reusable tiles. The same advantages apply: smaller bits of data\nare easy to push around, drawing can be optimized, and memory is used more effi-\nciently. The obvious difference is that we are no longer dealing with pixel data within\nthe tiles. The terrain tiles are represented as index buffers that link together the ver-\ntices of the terrain.\nThink of the 3D tiles as a grid being projected down on the landscape from\nabove. Each grid square represents a single tile in the terrain system. On the surface, it\nmay not appear as if the terrain tiles ever repeat, given that terrain is a pretty random\nset of geometry. The truth is the terrain may never repeat on the surface, but behind\nthe scenes, there is ample data to tile and reuse.\nConsider each terrain tile in the form of a vertex and index buffer. While each tile\nmay contain a unique set of vertex data, the index buffers used to draw the tiles can be\nmade to repeat rather frequently. In fact, by careful planning of the vertex data, we can\ncreate a finite set of index buffer \"tiles\" to use throughout the entire terrain.\nWe do this by taking advantage of a few refinements in the geometry of our tiles.\nFirst, each tile must contain an identical number of vertices, sharing the edge vertices\nwith its neighbors. These vertices represent the highest level of detail possible for the\ntile. Second, the vertices of the tile are arranged in a regular grid on the x-y plane,\nusing z to represent the vertices' height above sea level. Last, we store the vertices of\neach tile in an identical order so our index buffers can be used on any tile. Have a look\nat the sample tile shown in Figure 4.2.1. Here we have a 17x17 vertex tile showing\nthe grid-aligned positioning of each vertex, each of which has a unique height value\nsampled from the terrain bitmap.\nThe reason for this vertex organization is simple. Since the vertex data always\nappears in a regular grid and in an identical order, a fixed set of index buffers can be\ncreated for the entire terrain. Using the proper index buffer, a given tile can be ren-\ndered at any level, ranging from full detail down to a simple pair of triangles. Index\n\n\n4.2 Simplified Terrain Using Interlocking Tiles\n379\n£\n-:.^^\"^'-^.x-' ?f'iXm$K'm f *- -«-•*. --' ~ g-wii-z-z?,\n,\ngli|M*MW^\nills\nC*; KrKifp^ r- TM^'^fe'ip' |Ssff\nliKf^;Sf|;^-;'SlP^4\nFIGURE 4.2.1 A sample terrain tile of 17x17 vertices.\nbuffers that use more of the available vertices create a higher detailed representation of\nthe tile. Similarly, index buffers using less vertices render tiles with reduced triangle\ncounts. Figure 4.2.2 illustrates this by showing a sample tile rendered at different\ndetail levels.\nFIGURE 4.2.2 Using index buffers to create two separate detail levels from the same set of\nvertices.\nMap Making\nIn order to create the landscape tiles, we need a set of source data from which to pull.\nA common method is to read elevation data from a height map. This map is simply a\ngrayscale bitmap of the terrain, where the luminance of the pixel is used to represent\nthe elevation at a given position. The height map has the added advantage that it is\n\n\n380 \nSection 4 Geometry Management\nalready arranged in a regular grid, so it can be easily translated into terrain vertex data.\nIt can also serve as an animation resource, adjusting the pixel values to afTect the ter-\nrain height at different locations.\nCreating the tile vertices is simple. Since each tile vertex has a known 2D position\non the x-y grid, all that remains is to sample the corresponding height pixel from the\nterrain bitmap and translate it to a z value for the terrain vertex. For each terrain tile, a\ncorresponding block of pixels in the height map can be sampled to create a unique\nvertex buffer for the tile. In the case of an animating height map, this process must be\nrepeated periodically to update the terrain vertices.\nTile Templates\nThe index buffer can be thought of as a drawing template cast over the tile vertices. As\nwe saw in Figure 4.2.2, the index buffer defines how we pull triangles out of the tile,\ncontrolling how detailed a version of it we draw. Following our key rules, each tile's\nvertex buffer has been laid out in an identical order so the index buffers can be used\ninterchangeably. For an example 9x9 vertex tile, we can create a global set of index\nbuffers to draw all possible detail levels for any 9x9 set of vertices, skipping vertices in\nthe grid to create the level geometry. The top-level index buffer uses all 81 vertices to\ndraw 128 triangles, while the lowest level uses only the four corner vertices to draw a\ntwo-triangle quad. In addition, there are two additional detail levels representing 32\nand 8 triangles, respectively.\nThe next requirement is a method to determine which of our four detail levels\neach tile needs to use when being drawn. This determination can range from a simple\nfunction of the distance between the tile and the camera, to a full heuristic taking into\naccount die viewing angle and perceived roughness of the tile. The best method to use\ndepends on die game terrain and camera movement. Hugues Hoppe's paper on the\nVDPM mediod [Hoppe] sheds more light on heuristic ideas that can be used to select\ndetail levels for each terrain location. The sample application on the companion CD-\nROM, SimpleTerrain, uses the distance from the tile to die camera for simplicity. Once\nthe detail level is known, drawing is a simple matter of sending die tile's vertex buffer\nalong widi die desired index buffer into your chosen rendering API for drawing.\nUgly, Ugl* Ugly\nWe have the basic terrain system in place, but it is by no means a smooth terrain.\nWhat we have now is a terrain that changes abruptly as tiles of different detail levels\nare drawn side by side. In addition to that, seams can appear in the gaps created by\ntwo tiles of different detail levels. In short, we have made a mess, but there is still\nhope.\nThe key to this method is having tiles that interlock. That is, creating tiles that\nmesh together perfectly, regardless of the differences in detail levels between neigh-\nboring tiles. To do this, a different set of index buffers is required to merge tiles of dif-\nferent levels together without gaps and seams. These index buffers can be broken into\n\n\n4.2 Simplified Terrain Using Interlocking Tiles\n381\nFIGURE 4.2.3 The 16 basic tile bodies. Unshaded areas show where linking pieces must\nbe placed.\ntwo groups: bodies and links. Bodies represent a major portion of a tile at a given\ndetail level, with areas removed to provide space for linking pieces. Links, as the name\nsuggests, link the bodies of different detail levels together seamlessly.\nFigure 4.2.3 shows the 16 possible body types for a tile of any given detail level.\nTo keep things under control, we specify that tiles only link downward, meaning that\ntiles at higher detail levels must use link pieces to fit together with lower-detail neigh-\nbors. Looking at Figure 4.2.3, the unshaded areas of each body type then represent\nspaces where links are required to connect to a neighbor tile at a lower detail level.\nLinking pieces are smaller index buffers that fit into the spaces left vacant by the\nbody tiles. These index buffers arrange triangles to step down from a tile using a\nhigher number of vertices to an adjacent one using less. Figure 4.2.4 shows an exam-\nple link tile used to connect two body tiles. Since we only link downward in detail lev-\nels, each detail level needs enough link pieces to connect to the details levels below it.\nFor the example 9x9 vertex tile, we would need three linking pieces for each side of\nour highest-detail level, since it must be able to link to three lower-detail levels. Our\nlowest-detail level, the simple quad tile, needs no linking pieces, since all higher-detail\nlevels must do the work to link down to it.\nFIGURE 4.2.4 An example link piece used to join two tiles of different detail levels.\n\n\n382 \nSection 4 Geometry Management\nTable 4.2.1 All Index Buffers Required for Our Sample of Four Detail Levels\nDetail Level \nBody Pieces Required \n+ \nLinking Pieces Required \n= \nTotal\n4 \n16\n3 \n16\n2 \n15\n1 \n1 '\n3 for each side \n28\n2 for each side \n24\n1 per side \n19\n0 \n1\nGrand Total: \n72\nGiven our example of a 9x9 vertex tile with four detail levels, we can calculate\nthat the total number of index buffers required amounts to a grand total of 48 \"body\"\npieces and 24 \"linking\" pieces. Table 4.2.1 shows the full table of index buffers\nrequired to smooth out our terrain. As can be seen, increasing the number of detail\nlevels increases the index buffer count, but since these are relatively small in size and\ncan be used throughout the entire terrain, they still remain rather efficient.\nBetter, Faster, Stronger\nUsing the new body and linking pieces means we need to change our rendering\nmethod. For each tile, we now need to examine the tile's neighbors. We choose a body\ntile that contains a notched side for each neighbor that is at a lower detail level than\nthe current tile. Then, we select the necessary linking pieces that fill the notches and\nconnect us with the adjacent tiles. Each of these index buffers is then sent to the ren-\ndering API along with the tile's vertex buffer for drawing. In the worst case, we send\nfive index buffers per tile (one body, four linking), but in the best case, we still send\nonly one (the full body tile).\nOrganizing the index buffers into triangle strips and fans can further optimize the\nmethod. For larger tiles (33x33 vertices and up), this will greatly reduce rendering\ntime. In addition, the order of the vertices in the tile can be adjusted for better cache\nperformance when rendering. The exact order will depend on which index buffers the\ntile will be rendered with most often.\nConclusion\nFigure 4.2.5 shows the final output of the rendering method. The sample program\nSimpleTerrain demonstrates the method using DirectX 8.0. Full source code for the\n^-•~ij:'-s%, \nsample program is available on the companion CD-ROM. In this image, the wire-\nframe of the terrain is exposed to show the various body tiles and linking tiles in use.\nONJHCCP \nI I \nJ\nf\nJ \nU-l-\nGround textures have been removed tor readability.\nThe intent of this gem was to provide an alternative to the popular procedural\nmethods for rendering dynamic terrain while fully enabling hardware transform and\nlighting. By using this method, a dynamic terrain system can be up and running\nquickly without severely impacting the application's frame rate. While the final ter-\nrain may not rival that of a well-written ROAM or VDPM system, it does provide the\n\n\n4.2 Simplified Terrain Using Interlocking Tiles\n383\nFIGURE 4.2.5 Sample output of the SimpleTerrain^rograzwz showing tiles and linking\npieces in use.\nsame basic advantages of those methods with the potential of greater rendering speed\nin hardware.\nReferences\n[Duchaineau] Duchaineau, M., Wolinski, M., Sigeti, D., Miller, M., Aldrich, C., and\nMineev-Weinstein, M., \"ROAMing Terrain: Real-time Optimally Adapting\nMeshes\" (www.llnl.gov/graphics/ROAM).\n[Hoppe98] Hoppe, H. \"Smooth View-Dependent Level-of-Detail Control and Its\nApplication to Terrain Rendering\" IEEE Visualization 1998, October 1998, pp.\n35-42. (www.research.microsoft.com/'-hoppe).\n",
      "page_number": 360,
      "chapter_number": 36,
      "summary": "This chapter covers segment 36 (pages 360-367). Key topics include tiles, tiled, and terrain. Note that \"skip strips\" refers to multilevel skip strips—the single-level\nversion is not actually a sensible method in practice, for the reasons given.",
      "keywords": [
        "tile",
        "index buffers",
        "Terrain",
        "detail levels",
        "tile vertex buffer",
        "index",
        "detail",
        "buffers",
        "levels",
        "terrain tile",
        "Vertex",
        "Index Buffers Required",
        "vertices",
        "vertex tile",
        "Method"
      ],
      "concepts": [
        "tiles",
        "tiled",
        "terrain",
        "level",
        "rendering",
        "render",
        "method",
        "vertices",
        "vertex",
        "triangle"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 3",
          "chapter": 36,
          "title": "Segment 36 (pages 347-355)",
          "relevance_score": 0.68,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 7",
          "chapter": 47,
          "title": "Segment 47 (pages 453-467)",
          "relevance_score": 0.62,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 48,
          "title": "Segment 48 (pages 461-471)",
          "relevance_score": 0.62,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 7",
          "chapter": 9,
          "title": "Segment 9 (pages 76-90)",
          "relevance_score": 0.61,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 7",
          "chapter": 44,
          "title": "Segment 44 (pages 413-428)",
          "relevance_score": 0.61,
          "method": "sentence_transformers"
        }
      ]
    },
    {
      "number": 37,
      "title": "Segment 37 (pages 368-376)",
      "start_page": 368,
      "end_page": 376,
      "detection_method": "topic_boundary",
      "content": "4.3\nSphere Ttees for Fast Visibility\nCulling, Ray Tracing, and\nRange Searching\nJohn W. Ratcliff, Sony Online Entertainment\njratcliff@verant.com\n\\JLJfcile there are many data structures for storing static 3D objects, including\nWlf quadtrees, octrees, and BSP trees, they are not always ideal for large numbers of\ndynamic objects. This gem presents an algorithm and demonstration application that\nmanages thousands of objects in motion that are continuously maintained as a collec-\ntion of hierarchical bounding spheres in a SphereTree.\nThe design goal for this algorithm has been to make the 99-percentile case spend\nalmost no CPU time updating an object in motion within the tree structure. Queries\nagainst the SphereTree perform more tests than other data structures, but this is mit-\nigated by the fact that the tree can be maintained using very little CPU time. This\ndata structure is ideally suited for gross culling of massive numbers of moving objects\nin a large world space. It doesn't matter if the objects are moving at widely disparate\nspeeds, or even if many of them are not in motion at all. It also has a very low cost\nwhen objects are inserted and removed from the tree with great frequency.\nBounding Spheres\nThere are certain limitations when using a bounding sphere as a culling primitive. A\nbounding sphere does not necessarily fit very tightly around an object, especially if it\nis tall and thin. On the other hand, this over-described bounding sphere can be seen\nas a feature, not necessarily a limitation. A bounding sphere must encompass the\ncomplete extent of an object in all orientations. This includes taking into considera-\ntion all possible animation poses that might be applied. Additionally, this bounding\nsphere is presumed to encompass all child objects that are attached to the parent. This\nallows for the assumption that whatever the visibility state of the parent is also con-\nsidered true for its children. Another advantage of an over-described bounding sphere\nis that it can be used to cull animations, shadows, and other associated effects. This\nextra slop around an object can be an effective tool to determine when to treat an\n384\n\n\n4.3 Sphere Trees for Fast Visibility Culling, Ray Tracing, and Range Searching \n385\nobject, its children, and its associated effects as active or inactive. Culling shadows,\nanimations, and special effects are just as critical as culling geometry alone.\nUsing Sphere Trees\nEvery object in the simulation, whether it is in motion or not, uses the class\nSpherePack to maintain itself inside a valid SphereTree. When an object changes posi-\ntion using the method NewPos(), SpherePack simply computes the squared distance\nbetween the new position and the center of the parent node. If it is still contained\nwithin the radius of the parent sphere, which is designed to be true almost all of the\ntime, the routine immediately returns. This method is implemented inline for maxi-\nmum performance. This is the only calculation performed for the vast majority of all\nobjects in motion, even if there are thousands of them. For static objects, nothing is\ndone beyond their initial insertion into the tree.\nWhen a new position would cause an object to pierce the skin of its parent\nsphere, then that child is removed from the parent and inserted into the root node of\nthe tree. This involves only a couple of pointer swaps to instantly maintain a com-\npletely valid tree. When a child node is detached from its parent, it is placed into the\nreintegration FIFO queue. The parent is added to the recomputation FIFO queue to\nmaintain an optimally balanced tree. At each frame, the simulation performs the\nprocess method on the SpherePackFactory so that the reintegration and recomputa-\ntion FIFO queues can be flushed.\nOne problem with a quadtree or an octree is that it is possible for a single leaf\nnode to be contained in multiple nodes of the tree. If an object crosses a quadtree\nboundary, it needs to be represented in both nodes. The SphereTree does not have\nthis property. No leaf node can ever be contained in more than one SuperSphere.\nWhat is true for the SuperSphere is automatically true for all children. If a Super-\nSphere is outside the view frustum, then all of its children are outside the view frus-\ntum as well. The same is true for range tests and ray trace tests.\nThis makes the sphere tree an ideal data structure for these kinds of queries.\nWhen performing visibility culling with a sphere tree, each node keeps track of the\nstate it was in on the previous frame. Callbacks occur only when a node undergoes a\nstate change, which allows the simulation to efficiently maintain a list of only those\nobjects in the view frustum.\nDemonstration Application\nThis algorithm is demonstrated in the Windows application SphereTest.exe.\nSphereTest.exe will create a SphereTree containing 1000 spheres in motion. Even\nthough this demonstration application is in 2D, the SphereTree is a completely 3D\ndata structure. The rather large SphereTree displayed runs at a low frame rate since\nrendering all of this data is fairly slow under Windows. The SphereTest application\n\n\n386\nSection 4 Geometry Management\napt\n<~3**\nON THE CO\ndemonstrates building a SphereTree and performing a variety of high-speed queries\nagainst it while running a simulation that models the type of situations seen in\ngames.\nThe number of spheres created by the simulation can be passed as a command-\nline argument. With fewer spheres, it will be much easier to visualize the SphereTree\nthat is built. If a SphereTree of 5000 to 10,000 items is created, queries will still be\nseen taking place very quickly, with most of the CPU time burned just calling Win-\ndows graphics routines to render the results. If the application is begun with a very\nlarge number of items, there will be a pause while the initial tree is built and balanced,\nafter which it will run fairly quickly.\nThe example simulation models the type of situations one would see in an actual\ngame. In this simulation, 25 percent of the objects are in stasis, and the other 75 per-\ncent are always attempting to clump toward one of 16 different attraction points. In\nan actual game, objects are not usually evenly distributed across the address space.\nThe example simulation demonstrating the use of the SpherePackFactory class is con-\ntained in the files Circle.cpp and Circle.h on the companion CD-ROM.\nFigure 4.3.1 shows the class diagram for the SpherePack system.\nTo use the SpherePack system in a simulation, we simply instantiate a\nSpherePackFactory class with the maximum number of spheres, the size of the root\nnode, the size of the leaf node, and the amount of gravy around each SuperSphere.\nThe gravy factor acts as a bit of slop in our coordinate space to prevent objects from\ndetaching from their parent SuperSphere too frequently. For each object in the simu-\nlation, we call the AddSphere () method to create a SpherePack instance. Whenever an\nobject changes position, we invoke the NewPos () method. If the object changes both\nposition and radius, we invoke the NewPosRadiusO method. When an object in the\nSpherePack System\n•'•'•-•';: ^Interface./ :,i£jf!\nSpherefacKallback\nFIGURE 4.3.1 \nThe SpherePack system class diagram.\n\n\n4.3 Sphere Trees for Fast Visibility Culling, Ray Tracing, and Range Searching \n387\nsimulation is destroyed, we invoke the RemoveQ method on the SpherePackFactory\nclass.\nThe SpherePackFactory class maintains the complete SphereTree hierarchy and\ncontains the two integration FIFO queues. When performing queries, an interface\ncalled SpherePackCallback is used to extract information from the SphereTree. The\nleaf node SpherePack inherits the properties of a Sphere class.\n\n\nCompressed Axis-Aligned\nBounding Box Trees\nMiguel Gomez, Lithtech\nmiguel@lithtech.com\nT\nhe axis-aligned bounding box (AABB) tree structure has proven to be very useful\nfor accelerating intersection queries on sets of geometry. The data structure is\neasy to implement, the built structure is numerically well conditioned, and like all\nbinary trees, they have O(log n) search time [Sedgewick90]. This gem explains several\ntechniques that can be used to lower the overall memory footprint of an AABB tree to\n11 bytes per triangle.\nA Brief Survey of Hierarchical Sorting Methods\nThis section covers quadtrees, k-d trees, BSP trees, bounding volume trees, and\naxis-aligned bounding boxes, data structures for sorting three-dimensional sets of\ntriangles.\nQuadtrees, k-d Trees, and BSP Trees\nSome of the most popular data structures for sorting three-dimensional sets of trian-\ngles are the octree, k-d tree, and BSP tree. While the octree is probably the simplest to\nimplement, the more sophisticated k-d and binary space partitioning (BSP) trees\nadapt better to specific sets of geometry. All of these structures use planes to separate\nspace into convex regions, which leads to some serious side effects. First, any triangle\nthat straddles a separating plane must either be split into two pieces, which increases\nthe set of data and can create problematic \"slivers,\" or included in multiple nodes,\nwhich removes any upper bound on the size of the node structure. Second, octrees\nand k-d trees do not separate geometry adaptively, so they may need arbitrary thresh-\nolds to terminate a recursive build algorithm. For example, if many triangles share the\nsame vertex, the octree recursion may never achieve one triangle per node and will\nhave to be terminated based on tree depth. This can lead to unnecessarily deep trees.\nBSP trees that adaptively use the planes of individual triangles for separation do not\nhave this problem, but they still can have problems introduced by splitting.\n388\n\n\n4.4 Compressed Axis-Aligned Bounding Box Trees\n389\nBounding Volume Trees\nBounding volume trees approach the problem differently. Instead of dividing space,\nbounding volume trees recursively divide a set of triangles into two subsets and find\na bounding volume that encloses each subset. This approach avoids having to split tri-\nangles or include them in multiple nodes, and building a tree simply stops when a\nsubset has only one remaining triangle. For more information on bounding volume\ntrees, see [vandenBergen99].\nAxis-Aligned Bounding Boxes\nAn axis-aligned bounding box has a position (its center) and extents. As its name\nimplies, the sides of an AABB are parallel to the x-,y-, and z-axes. Figure 4.4.1 shows\nhow an AABB fits a single triangle.\nFIGURE 4.4.1 The sides of an AABB are parallel to the coordinate axes.\nAABB Trees\nThe bounding boxes in an AABB can and often do overlap. Figure 4.4.2 shows a shal-\nlow tree for a set of two connected triangles, L and R. Notice that die left and right\nAABBs overlap.\n\n\n390\nSection 4 Geometry Management\n(a)\n(b)\nFIGURE 4.4.2 A) The AABBs for two connected triangles will always intersect. B) The\nAABB tree structure for this particular geometry.\nBuilding AABB Trees\nAn AABB tree is built to by successively dividing a set of triangles into two subsets\nuntil each subset contains only one triangle. The basic algorithm for building an\nAABB tree is:\n• Find the AABB that encloses the entire set.\n• Divide the set into two subsets. This can be done by classifying the centroid of\neach triangle along the major (longest) axis of this AABB. If one subset is empty,\narbitrarily create two subsets of approximately equal size.\n• If a subset contains only one triangle, create a leaf.\n• Otherwise, repeat the same process on each subset.\nCompressing AABB Trees\nIn most applications, 4-byte floats have sufficient precision (seven digits) for specify-\ning box extents, requiring 6 X 4 = 24 bytes at each node. Any binary tree requires\nexactly 2n - 1 nodes to sort n elements, allowing an array of nodes to be allocated\nbefore building the tree. If the data set is large, it might be necessary to specify the\nindices of the child nodes with 4-byte unsigned integers. To avoid having to store yet\nanother 4-byte integer for a triangle index at each node, we can exploit the fact that\nthe 0th node (the root) is never referenced by another node. Therefore, if one of the\nchild node indices is zero, we can consider the node a leaf, and the other integer must\nindex a triangle. This trick gives us a grand total of 32 bytes per node, or about 64\nbytes per triangle as n becomes large. If we are willing to limit our triangle count to\n215 (giving a node count of 216 - 1), unsigned 2-byte integers can be used for child\nnode indices. This reduces the footprint to 28 bytes per node, or about 56 bytes per\ntriangle. Since most applications can divide triangle sets into chunks of 215, 56 bytes\nper triangle will be used as a reference value.\nThere are two important properties of AABB trees that can be exploited to mini-\nmize storage. First, child AABB nodes are fully contained by their parent. This allows\nus to store child extent values as unsigned 8-bit integer offsets relative to their parent's\n\n\n4.4 Compressed Axis-Aligned Bounding Box Trees\n391\nextents. Second, at most, six extent values of the child nodes are not identical to those\nof the parent node. This means diat we only need to store six values to fully describe\nthe two children.\nApproximating Extents\nIn order to use unsigned bytes as relative extent values for nodes, we must keep track\nof the floating-point extent values of the parent as the tree is built. By scaling the child\nextents relative to the parent AABB and then truncating to an integer value, we get a\nconservative estimate for the child AABB extents (Figure 4.4.3).\nexact max\ntruncated max\ntruncated min\nexact min\nFIGURE 4.4.3 When approximating extents with unsigned 8-bit integers, min values are\nmeasured from the left, while max values are measured from the right.\nThe error of any extent value relative to its parent is never more than 1/255 ~\n4 X 10~3. To put this in perspective, if the extents of the parent node are one meter on\neach side, we get a resolution of about four millimeters for the child extents. Keep in\nmind that these numbers scale as the nodes become smaller. The equations for calcu-\nlating relative offset values are:\n= trunc 255-\nMid - mm parent\n255-\nW^e \n[0,255].\nUsing 1 byte instead of 4 bytes to store an extent value immediately brings the\nmemory consumption down to 10 bytes per node, or 20 bytes per triangle.\n\n\n392\nSection 4 Geometry Management\nExploiting Redundancy\nIn order to store only six extent values for both children, we must take a bold step and\nstore both the left and the right child information within one node structure. In this\nstructure, a bit field is used to indicate which extent belongs to which child. A true bit\nmeans that the unique extent value belongs to the left child (so the parent's extent\nvalue belongs to the right child), and a. false bit indicates the opposite situation. This\nrequires only 6 bits, so the other 2 bits are used to indicate which nodes are leaves.\nWhen information for both children is stored at a single node, the node only con-\nsumes 11 bytes (Figure 4.4.4).\nflags (1 byte)\nextents (6 bytes)\nleft node/triangle\nindex\n(2 bytes)\nright node/triangle\nindex\n(2 bytes)\nFIGURE 4.4.4 The compressed AABB node structure consumes only 11 bytes per node.\nIn addition, only n nodes (including the root) are required to sort n triangles, so\nthe tree now needs only 11 bytes of storage per triangle. (Some architectures may\nrequire a 12-byte structure for alignment.) This is almost 50 percent less than if rela-\ntive values were used alone, and about one-fifth the storage of our reference value. As\nan added bonus, we can now keep track of twice as many triangles (216 - 1 instead of\n215) (Figure 4.4.5).\nIn practice, the root node is a separate data type that specifies the floating-point\nextents of the entire triangle set and is not part of the actual node array, which con-\ntains « - 1 nodes.\nFIGURE 4.4.5 For a set of four triangles, the uncompressed tree requires seven nodes,\nwhereas the tree on the right requires only four.\n",
      "page_number": 368,
      "chapter_number": 37,
      "summary": "This gem presents an algorithm and demonstration application that\nmanages thousands of objects in motion that are continuously maintained as a collec-\ntion of hierarchical bounding spheres in a SphereTree Key topics include node, trees, and triangle.",
      "keywords": [
        "tree",
        "node",
        "bounding volume trees",
        "AABB tree",
        "AABB",
        "Bounding Box Trees",
        "bounding sphere",
        "bounding",
        "Sphere",
        "Sphere Trees",
        "AABB tree structure",
        "BSP trees",
        "triangle",
        "objects",
        "parent"
      ],
      "concepts": [
        "node",
        "trees",
        "triangle",
        "extent",
        "objects",
        "bytes",
        "sphere",
        "bound",
        "culling",
        "value"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 1",
          "chapter": 45,
          "title": "Segment 45 (pages 431-441)",
          "relevance_score": 0.63,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 55,
          "title": "Segment 55 (pages 529-536)",
          "relevance_score": 0.59,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 1",
          "chapter": 40,
          "title": "Segment 40 (pages 381-388)",
          "relevance_score": 0.58,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 1",
          "chapter": 41,
          "title": "Segment 41 (pages 389-403)",
          "relevance_score": 0.46,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 1",
          "chapter": 46,
          "title": "Segment 46 (pages 442-449)",
          "relevance_score": 0.46,
          "method": "sentence_transformers"
        }
      ]
    },
    {
      "number": 38,
      "title": "Segment 38 (pages 377-385)",
      "start_page": 377,
      "end_page": 385,
      "detection_method": "topic_boundary",
      "content": "4.4 Compressed Axis-Aligned Bounding Box Trees \n393\nRuntime Efficiency\nThe runtime cost of converting the 8-bit values back to floating-point values is mini-\nmal. An experiment in which a line segment was tested for possible intersection with\n16K randomly distributed triangles showed that the compressed structure was about\n10 percent slower than the full floating-point representation. It seems that the ability\nof the significantly smaller data set to fit in the cache nearly compensates for the over-\nhead of converting integers to floating point values.\nFuture Work\nThe compressibility of AABB trees gives them a clear advantage over other structures;\nhowever, it may be possible to apply the same techniques to compress other bounding\nvolume tree structures, such as OBB trees. The fact that child AABB nodes are fully\ncontained by their parent volume allows us to easily scale and share extent values. This\nsame property does not hold for OBB trees [Gottschalk96]. The lack of this property\nmay make it impossible to share redundant extent values; however, it may still be pos-\nsible to store scaled 8-bit extent values and 8-bit orientation values for OBB trees by\npropagating the expanded dimensions back up the tree to the root node.\nReferences\n[Gottschalk96] Gottschalk, S., Lin, M. C., and Manocha, D., \"OBBTree: A Hierar-\nchical Structure for Rapid Interference Detection,\" SIGGRAPH Proceedings,\n1996, pp. 171-180.\n[Sedgewick90] Sedgewick, Robert, Algorithms in C, Addison-Wesley, 1990.\n[vandenBergen99] van den Bergen, G., Collision Detection in Interactive 3D Computer\nAnimation, Ph.D. Thesis, Eindhoven University of Technology, 1999.\n\n\n4.5\nDirect Access Quadtree\nLookup\nMatt Pritchard, Ensemble Studios\nmpritchard@ensemblestudios.com\nQ\nuadtrees are versatile and well-known constructs for spatially managing large\namounts of two-dimensional data. In games programming, they are a favorite\nfor managing object locations in a game world, offering good search performance and\nflexible implementation possibilities. In cases where the game data is static, quadtrees\ncan be precalculated, and from a performance standpoint, they are quite efficient.\nBut what about a highly dynamic case, such as in a real-time strategy (RTS) game\nwhen large numbers of objects are constantly in motion and coming into and out of\nexistence in the game world (quadtree)? During the implementation and subsequent\nprofiling of such a scenario, I found that my quadtree update routines were showing\nup surprisingly high on the list of CPU-consuming code. This behavior for a con-\nstantly updating data set led me to ask where the time was actually going, and to look\nfor more efficient ways to get the same job done. The result is the technique that I\npresent here.\nThis technique is a general-purpose optimization for quadtree access that\nimproves performance in three ways over the traditional implementations: 1) by elim-\ninating node traversal and the unnecessary cache-misses it causes, 2) by requiring\nfewer instructions and CPU cycles overall vs. a best case traditional approach, and 3)\nby doing so in a compact amount of time and with minimal memory accesses regard-\nless of what depth in the tree the target node resides in. Because it is general purpose\nin nature, many ways can be found to tweak and adapt this technique to suit the par-\nticular uses that may arise.\nWhere the Performance Goes\nExamining my original quadtree traversal routines (similar to those in Listing 4.5.1)\nshowed almost no fat in the code itself after the compiler optimizations. The search rou-\ntine was just a few lines of code that checked die bounding box of each child node and\ncalled itself recursively if necessary. Generating a CPU cycle count estimate of the num-\nber of calls assuming the worst case where it would recurse to the bottom level of die\nquadtree every time, didn't even begin to add up to die time that the profiles indicated.\n394\n\n\n4.5 Direct Access Quadtree Lookup \n395\nIt turns out that the performance drag was much the result of modern computer\narchitecture. The code was constandy touching data through pointers, and then mov-\ning on to other data that wasn't adjacent in memory. The result of this was an\nextremely high cache miss rate. If all of the quadtree updates were queued up sequen-\ntially, most of the upper nodes toward the root node of the quadtree would eventually\nbe in the CPU cache. When the updates weren't queued together, much of the previ-\nously cached quadtree node data would be flushed between calls.\nTo further degrade performance, the code in Listing 4.5.1 is comprised almost\nentirely of comparison functions which, when compiled, result in a large number of\nbranch, jump, and call instructions, and a large number of possible data paths for\neach iteration. On modern CPUs, this stalls the instruction pipeline every time a\nbranch or jump is mispredicted. Due to the nature of the data, this happens more\noften than one might think because, unlike most loops, the branch chosen in a previ-\nous iteration has no relevance to the likelihood of it being taken again.\nEliminating the Middlemen\nBasically, the compact C++ code in Listing 4.5.1 was spending more time waiting on\ndata and instructions than actually executing. Upon further reflection, the vast major-\nity of the data actually being looked at was not needed other than to be eliminated\nfrom consideration. Therefore, the question became: how to get the resultant\nquadtree node without actually examining the quadtree nodes themselves?\nIt is the asking of, or more specifically the answering of, this question that would\neliminate most of the performance hit on the quadtree access routines. Of course, the\nimplementation counts too, and what is presented here is an interesting and very effi-\ncient way to calculate the answer, but it is by no means the only possible solution.\nConditions and Requirements\nThere are two limitations to this technique. First, the quadtree has to be regular;\nthat is, each node is split exactly in the middle on each axis, making all nodes at a\nparticular depth in the tree represent the same size area. Fortunately, most quadtrees\nare implemented this way. Second, the program has to select in advance the maxi-\nmum depth (number of subdivisions) of the quadtree. Again, this is not unusual.\nConsidering these limitations, one might conclude that the area represented by the\nquadtree then needs to be perfectly square, but that's not the case as will be explained\nlater.\nThe only requirement is that the program needs to have array ordered access to\nthe nodes at each level in the tree. This means that either all of the quadtree node\npointers are placed in a linear array ordered by their spatial position, or if the quadtree\nnode elements themselves are a fixed size, then they are stored in an array. Put another\nway, given the x and y node coordinates on a specific level, the address of the quadtree\ndata can be obtained without having to traverse through other nodes.\n\n\n396\nSection 4 Geometry Management\nDetermining the Tree Level\nThe first step in directly finding the target quadtree node is determining at what level\nin the tree the target resides. Once that is known, the coordinates of the search object\nwill provide the row and column at which to directly look up the target node. For the\nrest of this gem, when we talk about objects, we are usually referring to their bound-\ning volumes.\nConsider that an object will reside in the root node of a quadtree if its volume\ncrosses the nodes midline for either axis. If it doesn't touch the midlines, it can there-\nfore be wholly contained in one of the node's children (Figure 4.5.1). It is assumed\nthat it already passed the root volume area contain test. The process is repeated until\neither it gets to the bottom level of the quadtree, or it finds a node where the object\ncrosses the midlines. The area check never has to worry about the outer edges, because\nthey were the previous level's midlines and other edges.\nConsider just one axis of the area represented by the quadtree if the total length was\nan exact power of 2, say 256.0 for example, and had nine levels where the lowest leaf\nnodes represented an area 1.0 by 1.0. The midline of the root node would be at 128.0,\nthe midlines of the next level nodes would be at 64.0 and 192.0. Level 3 midlines would\nbe 32.0, 96.0, 160.0, and 224.0. See a pattern here? The transition point for each level\nis at a different power of 2 that direcdy corresponds to the level depth on the tree.\nNow take the same axis of the search object's bounding area, which gives a line\nsegment (x1; x2). What we want to know is the largest power of 2 that it spans,\nbecause that indicates the lowest level of the quadtree in which it can be wholly con-\ntained. Now, \"spanning\" a power of 2 simply means that the range from xl to x2 tran-\nsitions from below the power of 2 value to greater than (or equal to) the value. Since\nour storage requirement is that the object be fully contained inside a quadtree node,\nthe quadtree level to store the object is actually one level higher than the level where\nthe node area size is the specific power of 2 that is crossed.\nA \nB\nFIGURE 4.5.1 A) Objects that cross the node's midlines cannot be stored in child nodes. B)\nObjects that don't cross the midlines are stored in child nodes.\n\n\n4.5 Direct Access Quadtree Lookup\n397\nSince the spanning of the value can be represented as a binary transition from 0 to\n1, the program quickly can determine where the spanning occurs by taking the integral\nportions of our range (#1; x2) and XORing them together. Each bit in the result indi-\ncates that the range crosses a point at the corresponding power of 2, returning 1 if there\nwas a transition at that position. The lower the position of the first \"1\" bit of the result,\nthe lower (deeper) in the quadtree the span can be stored. If a zero result occurs (i.e., no\n\"1\" bits in the result), then the range can be stored at the very lowest level in the\nquadtree. Therefore, the bit position of the highest \"1\" bit indicates how many levels\nabove the bottom of the quadtree the range (xl} x2) can first be properly placed.\nHere are some examples using a nine-level, 256.0-length axis that illustrate this\npower of 2 property. Figure 4.5.2 shows a 2D representation of each example, using\nthe x-axis.\n128.0 \n160.0 \n192.0\n1^1J\n_\nI\nr\nj\n1\nExample #1\n(127.8 to 128.3)\nExample #2\n(128.3 to 128.8)\nExample #3\n(155.4 to 166.1)\nFIGURE 4.5.2 Illustration of the examples. Example boxes not to scale for illustrative\npurposes.\nExample #1\nObject bounding line (127.8, 128.3). This object is sitting in the middle of the root\nnode and only fits at the top level. Integer values for (x1; x2) are (127, 128).\nX1 =\nX2=\n127 = 0 1 1 1 1 1 1 1\n128 = 10000000\nXOR result 255 = 11111111\nThe first \"1\" in the result is bit 7 (27) or the 8th position. 9-8 (number of tree\nlevel minus position) gives us 1, or the first level (root level) in the quadtree.\n\n\n398 \nSection 4 Geometry Management\nExample #2\nObject bounding line (128.3, 128.8). The object in Example #1 has been nudged just\noff the centerline and should fall all the way down to a leaf node (level 9). Integer val-\nues for (#1, x2) are (128, 128).\nX1= \n128 = 10000000\nX2= \n128 = 10000000\nXOR result \n0 = 00000000\nThere is no \"1\" bit in the result, so we get 0 for the position. 9-0 = 9* level in\nthe quadtree.\nExample #3\nObject bounding line (155.4, 166.1). This is a very big object centered at about 60\npercent of the range. Because of its size compared to the smallest node, it will be at\nleast four levels above the bottom nodes (level 9). Integer values for (#j, x2) are (155,\n166).\nX1= \n155 = 10011011\nX2= \n166 = 10100110\nXOR result 61 = 00111101\nThe first \"1\" is at bit position 6. 9 - 6 = 3rd level in the quadtree.\nMapping to the Situation\nNow that we know how to determine the level for a one-dimensional tree, moving the\nprocess to two dimensions is as simple as repeating the process for each axis and\nchoosing the highest level (in the quadtree) result.\nWhile the preceding examples work because they assume the storage range is a\npower of 2, in most situations the area represented by a quadtree is not going to be an\neven power of 2, and the smallest nodes are not going to just happen to represent an\narea 1.0 by 1.0 in size. Fortunately, the solution is as simple as transforming coordi-\nnate values from the game or applications measuring system to a scale that represents\nthe quadtree's dimensions. This can be accomplished by computing a scale factor for\neach axis during initialization, and multiplying the coordinates by the scale before\nconverting them to integers. For the quadtree scale, 1.0 represents the size of the leaf\nnodes on each axis. (Note that each axis can be independently scaled, allowing rectan-\ngular areas to map to a square node). Thus, the scaled coordinates for an n level\nquadtree will be in the range 0 to 2\"~1 for each axis.\nAfter scaling and converting the coordinates to integers, we XOR together the\nstart and end positions of each axis. There are several ways to determine which bit\n\n\n4.5 Direct Access Quadtree Lookup \n399\nposition contains the highest\" 1\" bit. The simplest and most portable is a shift loop to\ncount the bits, but a look-up table may work better for quadtrees with six or fewer\nlevels. Even better, there are platform-specific solutions such as the Pentium's BSR\ninstruction and the PowerPC's cntlzw instruction that bit-scan a value, removing\nlooping and branching in the process. See Listing 4.5.2 for an example of code that\ndetermines the quadtree level using this method and a while loop.\nDetermining the Location\nOnce the level in the quadtree has been determined, the only step remaining is to take\nthe scaled coordinates and extract the row and column positions of the target node. If\nthe target node is on the bottom level, no scaling will be necessary. For each level\nup the tree, the target coordinates have to be scaled down by 2 to reflect the smaller\nnumber of nodes on that level. This scaling can be done simply by right-shifting the\ninteger coordinates by the number of levels the target is from die bottom level. This\ngives the row and column positions to plug into the array lookup for nodes on that level\nof the quadtree. Listing 4.5.3 shows an example function that puts all of this together.\nTraversing the Quadtree\nIf, after locating the search node, there still is a need to traverse the quadtree, all that\nis required is to save the tree level and array row and column positions. By shifting the\nposition values right or left, a program can go up and down the tree levels, and by\nincrementing and decrementing die array positions, it can move adjacently on die\ncurrent tree level.\nTuning the Quadtree\nHere are a couple of quick tips for getting the most out of a quadtree that apply to any\nquadtree access implementation.\nThe first is to make sure that items are being positioned as far down in die tree as\npossible. Improper edge boundary conditions can cause items to be placed much\nhigher than they should be. In the example used of a 256 by 256 tree, an object that\nspanned position 128.0 would be placed in a root node. However, what about objects\nthat only touch, but don't actually span, such as 1.0 sized \"tiles\" that sit at 127.0 to\n128.0? In this case, switching \">=\" or \"<=\" for \">\" or \"<\" or tweaking the object coor-\ndinates with a tiny value can make the difference between root node placement and\nleaf node placement.\nThe next tip is to make sure that the program picks the correct number of levels\nfor the quadtree. If it picks too few, the nodes will be overloaded with items to be\nsearched, when the whole idea is to reduce the size of the search set in the first place.\nToo many tree levels can be just as bad. Many nodes may go empty, wasting space,\nand too much node traversal may be taking place during various operations. It's a\n\n\n400 \nSection 4 Geometry Management\ngood idea to add performance counters and statistics to the nonrelease versions of a\nquadtree implementation, and analyze the results using real data, as the optimal set-\ntings will be dependent on the actual data that is encountered.\nFinally, I don't see any reasons why this technique couldn't be adapted to octrees.\nPerhaps someone out there will try this and let me know how well it works.\nListing 4.5.1 Simple implementation of quadtree search\n// Two C++ classes, one to represent the QuadTree and one to\n// Represent each individual node.\n// all variables are class members unless defined\nQuadNode* QuadTree: :GetNodeContaining(const rect &ObjBounds)\n{\nif (RootNode->Contains(ObjBounds) )\nreturn(RootNode->GetNodeContaining(ObjBounds) ) ;\nelse\nreturn(NULL);\n}\nQuadNode* QuadNode: : Get NodeContaining( const rect &0bj Bounds)\n{\nif (lisLeafNode)\n{\nif (ULNode->Contains(ObjBounds)\nreturn(ULNode->GetNodeContaining(ObjBound)) ;\nif (URNode->Contains(ObjBounds)\nreturn(URNode->GetNodeContaining(ObjBound) ) ;\nif (LLNode->Contains(ObjBounds)\nreturn(LLNode->GetNodeContaining(ObjBound) ) ;\nif (LRNode->Contains(ObjBounds)\nreturn(LRNode->GetNodeContaining(ObjBound) ) ;\n}\nreturn(this);\nbool QuadNode: : Contains (const rect &0bj Bounds)\n{\nreturn (Obj Bounds. top \n>= y1 && ObjBounds.left >= x1 &&\nOb j Bounds. bottom <= y2 && Obj Bounds. right <= x2);\n\n\n4.5 Direct Access Quadtree Lookup \n401\nListing 4.5.2 Code to determine the level of the target quadnode\nint Quadtree::GetNodeLevelContaining(const rect &ObjBounds)\nint \nxResult = ((int) (ObjBounds.left * QuadXScale)) A\n((int) (ObjBounds.right * QuadXScale));\nint \nyResult = ((int) (ObjBounds.top * QuadYScale)) *\n((int) (ObjBounds.bottom * QuadYScale));\nint \nNodeLevel = NumberOfTreeLevels;\nwhile (xResult + yResult != 0 ) \n//Count highest bit position\nxResult »= 1;\nyResult »= 1;\nNodeLevel--;\nreturn (NodeLevel);\n}\nListing 4.5.3 Code to determine the level of the target quadnode\nQuadNode* QuadTree::GetNodelContaining(const rect &0bjBounds)\nint \nx1 = (int) (ObjBounds.left * QuadXScale);\nint \ny1 = (int) (ObjBounds.top * QuadYScale);\nint \nxResult = x1 \" ((int) (ObjBounds.right * QuadXScale));\nint \nyResult = y1 A ((int) (ObjBounds.bottom * QuadYScale));\nint \nNodeLevel = NumberOfTreeLevels;\nint \nshiftCount = 0;\nwhile (xResult + yResult != 0 ) \n//Count highest bit position\nxResult »= 1;\nyResult »= 1;\nNodeLevel--;\nShiftCount++;\n// Now lookup the node pointer in a 2D array stored linearly\nx1 »= shiftCount; \n// Scale coordinates for\ny1 »= shiftCount; \n// quadtree level\nQuadNode** nodes = NodeLevelPointerArray[NodeLevel];\nreturn (nodes[y1«(NodeLevel-1 )+x1 ]);\n",
      "page_number": 377,
      "chapter_number": 38,
      "summary": "This chapter covers segment 38 (pages 377-385). Key topics include nodes, level, and position. It seems that the ability\nof the significantly smaller data set to fit in the cache nearly compensates for the over-\nhead of converting integers to floating point values.",
      "keywords": [
        "Quadtree",
        "Direct Access Quadtree",
        "level",
        "quadtree node",
        "node",
        "Access Quadtree Lookup",
        "Access Quadtree",
        "quadtree level",
        "quadtree node data",
        "Quadtree Lookup",
        "root node",
        "tree",
        "Tree Level",
        "target quadtree node",
        "object"
      ],
      "concepts": [
        "nodes",
        "level",
        "position",
        "positions",
        "trees",
        "data",
        "contained",
        "value",
        "bounding",
        "object"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 8",
          "chapter": 38,
          "title": "Segment 38 (pages 351-358)",
          "relevance_score": 0.6,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 34,
          "title": "Segment 34 (pages 317-324)",
          "relevance_score": 0.57,
          "method": "sentence_transformers"
        },
        {
          "book": "Computer Systems A Programmer’s Perspective",
          "chapter": 33,
          "title": "Segment 33 (pages 662-682)",
          "relevance_score": 0.56,
          "method": "sentence_transformers"
        },
        {
          "book": "Designing Data-Intensive Applications",
          "chapter": 11,
          "title": "Segment 11 (pages 89-108)",
          "relevance_score": 0.56,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 1",
          "chapter": 45,
          "title": "Segment 45 (pages 431-441)",
          "relevance_score": 0.55,
          "method": "sentence_transformers"
        }
      ]
    },
    {
      "number": 39,
      "title": "Segment 39 (pages 386-393)",
      "start_page": 386,
      "end_page": 393,
      "detection_method": "topic_boundary",
      "content": "4.6\nApproximating Fish Tank\nRefractions\nAlex Vlachos, ATI Research\nalex@vlachos.com\nT\nhis gem briefly explains a method for approximating the refraction effect seen\nwhen looking through the side of a fish tank. The majority of this gem explains\nhow to construct the transformation matrix that will be applied to the geometry\ninside the tank to simulate the refraction effect.\nFish Tank Observations\nHave you ever had a long wait at a seafood restaurant and spent any time staring at\nthe fish tanks by the lobby? If so, you probably noticed the unique way in which the\ninternal shape of the tank seems to change. Through observation, you'll notice that as\nyou walk by the tank from one side to the other, the back wall of the tank seems to\nshear in the left and right directions. Simultaneously, the tank seems to flatten almost\nto a 2D image when you're at the far left or far right of the tank. Further observations\n(and common sense) show that the height of your head also affects the appearance of\nthe internal shape of the tank in a similar way. An obvious way to simulate diis move-\nment is to concatenate a shear and scale matrix to simulate these observations.\nAlthough there are surely more mathematically savvy methods using Snell's Law\nfor computing refraction rays and so on, this gem focuses on approximating this\nvisual effect based solely on empirical observation. It is important to note that this\ngem refers to fish tanks instead of shark tanks, the difference being the size of the tank\nrelative to the viewer. This algorithm assumes that the viewer is, for the most part, not\nstanding extremely close to the front of the glass. The phrase \"extremely close\" is obvi-\nously a relative one. If you imagine a fish tank that is approximately 3 feet by 2 feet, a\nperson walking by that tank is the scale at which this gem is aimed. If you picture that\nsame person walking in front of a shark tank measuring 30 feet by 10 feet, you'll real-\nize that the person is spending most of his or her time directly in front of the tank rel-\natively close to the glass. Although this algorithm doesn't break down, the visual\neffects are best noticed when the viewer is moving relative to the glass as opposed to\nstanding directly in front of it. Environment mapping makes a similar assumption, so\nthis is nothing new to real-time graphics.\n402\n\n\n4.6 Approximating Fish Tank Refractions\n403\nPreeomputations\nGiven a fish tank whose front face has dimensions width and height, the transforma-\ntion matrix that places the center of the front face of the tank at the origin in a certain\norientation can be precomputed (e.g., back of the tank extends down the positive z-\naxis with the positive j/-axis as the up vector). The reason the center of the front face\nis placed at the origin is to facilitate the scale and shear transformations. Once the\ntransformation matrix has been generated, the position of the camera can be trans-\nformed into the space of the fish tank with a simple matrix multiply. This will allow\nall of the computations to happen in that common space (tank space). It's important\nto note that this method is based solely on the position of the camera relative to the\ntank. The view direction of the camera does not affect the visual results.\nScale Factor\nThe scale factor for the tank needs to be computed per frame, which can be visualized\nby bringing the far face of the tank toward the near face (the face through which the\nviewer is looking). When the viewer is standing directly in front of the glass, no scal-\ning should take place. When the viewer is standing off to the side of the tank looking\nacross the face of the glass, the tank is scaled in quite a bit. The effect of this left to\nright motion is shown in Figure 4.6.1.\nGiven the viewer s position in tank space and the center of the glass, the angle to\nthe surface of the tank is computed while taking into account the ratio of the width\nFIGURE 4.6.1 Three shearing and scaling examples based on the viewer's position. The\nuser clip planes are created based on the viewer's position and the edges of the tank glass.\n\n\n404\nSection 4 \nGeometry Management\nand height of the tank's glass. If the glass dimensions aren't taken into account, the\nresults across different shapes of glass will be inconsistent.\nThe scale factor is computed using the following method:\n1. Transform the viewer's position into fish tank space. This puts the center of\nthe tank's glass at the origin.\n2. Calculate the vector from the center of the glass (the origin) to the camera,\nbut do not normalize it.\n3. Divide the x- and y-coordinates of the vector by the width and height of the\nglass, respectively.\n4. Divide the z-coordinate of the vector by the depth of the tank (distance\nfrom near to far glass).\n5. Normalize the vector.\n6. Compute the dot product of this vector and the face normal of the glass in\ntank space (0, 0, -1). This scalar value clamped 0.0 to 1.0 will serve as the\nscale factor.\nAssuming the tank was transformed to the origin as explained previously, the\nscale would take place along the .zr-axis.\nShear Factor\nThe shear factor must also be computed per frame. Two separate shear values need to\nbe generated: one for the x-axis and one for the y-axis. For the shear along the x-axis,\nwe create a 2D vector composed of the x- and z-coordinates of the vector computed\nfor the scale factor and normalize it. The x-component of the normalized 2D vector is\nused for the shearing along the x-axis. Similarly, we create a 2D vector composed of\nthe y- and z-coordinates, normalize it, and use the x-component of the normalized\n2D vector for the shearing along the y-axis. Experimentation has shown that limiting\nthe shear values in x to 0.75 and in y to 0.25 helps reduce unwanted effects.\nComposing the Matrix\nThe scale and shear factors can be placed into a single matrix:\n1 \n0 \nshearx \n0\n0 \n1 \nsheary \n0\n0 \n0 \nscale \n0\n0 0 0 \n1\nUser Clip Planes and the Stencil Buffer\nWhen visualizing what happens to the geometry after the shear and scale transforma-\ntions are applied, it becomes apparent that the geometry ends up touching pixels that\n\n\n4.6 Approximating Fish Tank Refractions \n405\nwere never intended to be modified. To solve this problem, if the fish tank glass is rec-\ntangular in shape, enabling four user clip planes from the position of the viewer to the\nfour borders of the glass will solve the problem (Figure 4.6.1). This will clip all of\nthe sheared geometry that could otherwise be seen from the outside of the tank. If the\nglass is circular or some other nonrectangular shape, the stencil buffer will need to be\nused in place of user clip planes to stencil out the pixels that don't belong to the fish\ntank glass.\nImproving the Reality\nSo far, this method describes how to make the geometry on the inside of the tank look\nas if it's filled with water. There is still much room for improvement. The first\nimprovement that can be done is to apply caustic textures. In short, caustics are the\npatterns of light that appear on the bottom of a water-filled volume. These patterns\nare caused by light refracting as it passes from outside the tank through the surface of\nthe water at the top. While it is nice to have caustic effects that correspond roughly to\nthe simulation of the water surface, acceptable caustics can be created by simply\nscrolling two caustic textures across all of the geometry in the tank using projective\ntextures.\nThe next obvious visual cue that is missing is making the outside of the glass\nreflective. A simple way to get nice reflections on glass is to render the reflected geom-\netry of the glass into a renderable texture and then texture from that to give the illu-\nsion of a transparent reflective surface.\nTo give the viewer the ability to see through the water at the top of the tank, we\ncould use another renderable texture to render what could be seen if there were no\nwater in the tank. We could then apply environment-mapped bump mapping (or any\nother applicable pixel shader that uses dependent texture reads) to that renderable tex-\nture to give the illusion of animated water.\nObviously, this algorithm can be applied to each separate face of the fish tank. In\naddition, higher order culling can be performed if the vertices defining each side of\nthe glass are outside the current view frustum. This method for culling large groups of\npolygons can be applied to each individual pane of glass.\nConclusion\nSimulating refractions through a planar surface can be very simple to fake. When\ncombined with other real-time rendering techniques, it is possible to create a very\nconvincing approximation to the real world.\n\n\n4.7\nRendering Print Resolution\nScreenshots\nAlex Vlachos and Evan Hart,\nATI Research\nalex@vlachos.com and ehart@ati.com\nW\nith the recent advances in real-time graphics technology, games have become\nfantastically rich in visual quality. While these images are great for display on a\ncomputer monitor that is typically 72 dots per inch (dpi), they are somewhat less\nappealing when displayed in print. Print resolution is typically a minimum of four\ntimes finer than monitor resolution in each dimension. Thus, a one-to-one mapping\nof the screen pixels to the dots on the printed page results in postage-stamp-sized\nscreenshots. One solution to this problem is to enlarge the source image in the page\nlayout software, but this results in blocky images that sell the original content short.\nThe simple solution to this problem is to take the screen shots at a higher frame\nbuffer resolution. Naturally, the larger buffer can be an offscreen surface, so that it is\nnot tied to the monitor's supported resolutions. This still poses problems, as most\naccelerators are only designed to render to the maximum resolution of monitors, leav-\ning the programmer with at best a 2048 by 2048 screenshot. Although this resolution\nmay sound sufficient, it won't cover a full magazine page at 300 dpi. This approach\nalso takes up 32MB of graphics memory for a single color buffer and a depth buffer.\nThe solution proposed here is to break the task into the rendering of several\nsmaller subimages. These subimages can then be pasted together to form a screen shot\nof arbitrary resolution. This gem focuses on the projection matrix tricks required to\ndo this seamlessly.\nBasic Algorithm\nSince current graphics hardware cannot render the resolutions required for print, the\ndesired final image must be divided into a grid of subimages and pasted together. In\nthe example code later in this gem, the dimensions for each of the subimages are\nassumed to be equal to the frame buffer dimensions. Although the subimages must\nbe a supported rendering resolution by the graphics hardware, setting the viewport\n406\n\n\n4.7 \nRendering Print Resolution Screenshots\n407\nsize to anything smaller than the frame buffer will allow this method to handle arbi-\ntrary dimensions.\nFigure 4.7.1 shows how an image can be segmented into a grid of subimages. Six\nfrustum planes define a projection matrix: near, far, left, right, top, and bottom. For\neach subimage, new left, right, top, and bottom planes are computed that will define\na unique projection matrix for rendering that subimage.\nTaking the screen shot involves three steps:\n1. Calculate the frustum planes.\n2. Determine the intermediate planes.\n3. Render each subimage using its own frustum composed of the intermediate\nplanes.\nFirst, the frustum planes for the projection matrix are computed as six scalars.\nThe near and far values are simply the distance from the eye to the near and far\nplanes, while the left, right, top, and bottom values are defined by the points at which\nplanes intersect the near plane. Section 3.5 of Real-Time Rendering has an excellent\ndescription of the meaning of these values [Moller99].\nNext, the intermediate plane values Hn and Vn are computed by linearly interpolat-\ning the top and bottom values and the left and right values, respectively.\nFinally, the frustum for each subimage is composed of the bordering Hn and Vn\nvalues for the left, right, top, and bottom. The projection matrix can be generated by\nh\n3072 Pixels\nFIGURE 4.7.1 Segmentation of the image.\nH\nPaneO\n1\nffi\n00\n1024 Pixels\ntop\n2*top/\nH2\ntop/3 +\nH3\nV0 \nV, \nV2 \nV3 bottom\neft \n2*left/3 + right/3 left/3 + 2*right/3 right\n\n\n408 \nSection 4 Geometry Management\ncalling either glFrustum() or D3DXMatrixPerspectiveOffCenter(). When rendering\ninto each of the subimages, the entire scene is rendered normally.\nFollowing is a simple code example for manually building the projection matrix\nfor both OpenGL and Direct3D for a 3x3 grid of subimages.\nconst float GPG_PI = 3.14159265f;\ninline float GpgDegToRad(float D) { return ((D) * (GPG_PI/180.0f)); }\nvoid GpgPerspective (double fovy, double aspect, double Near, double\nFar, int subrect)\n{\ndouble fov2, left, right, bottom, top;\nfov2 = GpgDegToRad(fovy) * 0.5;\ntop = Near/(cos(fov2)/sin(fov2));\nbottom = -top;\nright = top*aspect;\nleft = -right;\nif (subrect == -1) \n//Regular full screen\nGpgFrustum (left, right, bottom, top, Near, Far);\nelse if (subrect == 0) //UL\nGpgFrustum(left, left/3.0, top/3.0, top, Near, Far);\nelse if (subrect == 1) //UC\nGpgFrustum(left/3.0, right/3.0, top/3.0, top, Near, Far);\nelse if (subrect == 2) //UR\nGpgFrustum(right/3.0, right, top/3.0, top, Near, Far);\nelse if (subrect == 3) //ML\nGpgFrustum(left, left/3.0, bottom/3.0, top/3.0, Near, Far);\nelse if (subrect == 4) //MC\nGpgFrustum(left/3.0, right/3.0, bottom/3.0, top/3.0, Near, Far);\nelse if (subrect == 5) //MR\nGpgFrustum(right/3.0, right, bottom/3.0, top/3.0, Near, Far);\nelse if (subrect == 6) //BL\nGpgFrustum(left, left/3.0, bottom, bottom/3.0, Near, Far);\nelse if (subrect == 7) //BC\nGpgFrustum(left/3.0, right/3.0, bottom, bottom/3.0, Near, Far);\nelse if (subrect == 8) //BR\nGpgFrustum(right/3.0, right, bottom, bottom/3.0, Near, Far);\n}\nvoid GpgFrustum (double left, double right, double bottom, double\ntop, double zNear, double zFar)\n{\nfloat matrix[16] = { 1.0f, O.Of, O.Of, O.Of,\n0.Of, 1.Of, 0.Of, 0. Of,\nO.Of, O.Of, 1.0f, O.Of,\n0. Of, 0. Of, 0. Of, 1 . Of } ;\n#ifdef GPG_OPENGL_API\nmatrix[0] = (float)(2.0*zNear/(right-left));\nmatrix[5] = (float)(2.0*zNear/(top-bottom));\nmatrix[8] \n= (float)((right+left)/(right-left));\n\n\n4.7 Rendering Print Resolution Screenshots \n409\nmatrix[9] \n= (float) ((top+bottom)/ (top-bottom) );\nmatrix[ 10] = (float) (-(zFar+zNear)/(zFar-zNear) );\nmatrix[11] = (float) (-1 .0) ;\nmatrix[14] = (float) (-(2.0*zFar*zNear)/(zFar-zNear) ) ;\n#else //DirectSD\nmatrix[0] \n= (float) (2. 0*zNear/ (right-left j) ;\nmatrix[5] \n= (float) (2. 0*zNear/ (top-bottom) );\nmatrix[8] = (float) ((right+left)/(right-left)) ;\nmatrix[9] \n= (float) ((top+bottom) /(top-bottom) );\nmatrix[10] = (float) (-(zFar)/(zFar-zNear)) ;\nmatrix[11] = (float) (-1 .0) ;\nmatrix[14] = (float32) (-(zFar*zNear)/(zFar-zNear)) ;\n#endif\n//Now set this matrix as the current projection matrix\nCaveats and Concerns\nAs with any rendering algorithm, the programmer must pay attention to how this\ntechnique interacts with any special tricks performed by the graphics engine. The pro-\ngrammer should be aware that the utilization of multiple images to create the screen\nshot could affect Gouraud shading in the case of very large polygons in the scene. Due\nto the multiple projections, large polygons can possibly be clipped at all the subimage\nboundaries, resulting in lighting artifacts. Additionally, the programmer should\ntake care to handle any special effects that require rendering into textures. The resolu-\ntion for these images may also need to be increased for optimal results. Of course, if\nanything in the scene is animated, one should make sure that the same exact time is\nused in the animation when each of the subimages is rendered.\nWhile we have referred to the Direct3D and OpenGL graphics APIs directly and\nimplied the use of PC hardware, this technique would work equally well on game\nconsoles where the screen shot problem is the worst. On these devices especially, gam-\ning magazines are forced to jump through all sorts of hoops to get terrible screen grabs\nfrom NTSC signals.\nIs this technique cheating? No. This method is equivalent to running your game\nat a higher resolution. You're not misrepresenting your work by providing large print-\nresolution screenshots to a gaming magazine. We have used this technique for color\nplates in Real-Time Rendering and Game Programming Gems and have been very\npleased with the results.\nConclusion\nWe have presented a technique for rendering print-resolution screenshots using\ngraphics hardware. Since it is not possible to directly render the high-resolution\nimages required for print, we have shown how to divide the desired final image into a\n",
      "page_number": 386,
      "chapter_number": 39,
      "summary": "4.6\nApproximating Fish Tank\nRefractions\nAlex Vlachos, ATI Research\nalex@vlachos.com\nT\nhis gem briefly explains a method for approximating the refraction effect seen\nwhen looking through the side of a fish tank Key topics include matrix, tank, and render.",
      "keywords": [
        "Tank",
        "Fish Tank",
        "Approximating Fish Tank",
        "fish tank glass",
        "tank glass",
        "matrix",
        "Fish Tank Refractions",
        "glass",
        "top",
        "left",
        "bottom",
        "Fish",
        "Rendering Print Resolution",
        "float",
        "Fish Tank Observations"
      ],
      "concepts": [
        "matrix",
        "tank",
        "render",
        "rendering",
        "resolution",
        "resolutions",
        "value",
        "planes",
        "graphics",
        "effects"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 1",
          "chapter": 60,
          "title": "Segment 60 (pages 581-588)",
          "relevance_score": 0.51,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 1",
          "chapter": 37,
          "title": "Segment 37 (pages 352-362)",
          "relevance_score": 0.42,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 3",
          "chapter": 48,
          "title": "Segment 48 (pages 456-465)",
          "relevance_score": 0.41,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 2,
          "title": "Segment 2 (pages 14-22)",
          "relevance_score": 0.41,
          "method": "sentence_transformers"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 23,
          "title": "Segment 23 (pages 441-462)",
          "relevance_score": 0.37,
          "method": "sentence_transformers"
        }
      ]
    },
    {
      "number": 40,
      "title": "Segment 40 (pages 394-404)",
      "start_page": 394,
      "end_page": 404,
      "detection_method": "topic_boundary",
      "content": "410 \nSection 4 Geometry Management\ngrid of subimages that are rendered separately. This allows content developers to show\ntheir games in the best light in print media.\nReferences\n[Moller99] Moller, Tomas, and Eric Haines, Real-Time Rendering, AK Peters, 1999.\n\n\n4.8\nApplying Decals to Arbitrary\nSurfaces\nEric Lengyel, C4 Engine\nIengyel@c4engine.com\nI\nany games need to render special effects such as scorch marks on a wall or foot-\nprints on the ground that are not an original part of a scene, but are created dur-\ning gameplay. These effects are commonly implemented by creating a new object,\nwhich we will call a decal, which coincides with an existing surface, and rendering it\nusing some type of depth offset technique (for example, see [LengyelOO]). Applying a\ndecal to the interior of a planar surface is simple, but difficulties arise when applying\ndecals to the more complex surfaces used in today's games to represent curved objects\nand terrain patches. This gem presents a general method for applying a decal to an\narbitrarily shaped surface and concurrently clipping the decal to the surface s boundary.\nThe Algorithm\nWe begin with a point P that lies on an existing surface and a unit normal direction N\nthat is perpendicular to the surface at diat point. The point P represents die center of\nthe decal and may be the point at which a projectile has impacted the surface or the\npoint where a character s foot has stepped on the ground. A unit tangent direction T\nmust also be chosen in order to determine die orientation of the decal. This configu-\nration is illustrated in Figure 4.8.1.\nFIGURE 4.8.1 Configuration of a decal.\n411\n\n\n412 \nSection 4 Geometry Management\nGiven the point P and the directions N and T, we have an oriented plane that is tan-\ngent to the surface geometry at P. We can carve a rectangle out of this plane that rep-\nresents the area of our decal by constructing four boundary planes that are parallel to\nthe normal direction N. Let w and h be the width and height of the decal. Then the\n4D vectors corresponding to the four border planes are given by\nw \nI\nright = -T, — + T • P\nbottom = B, \nB • P\ntop = [-B, - + B • P | \n(4.8.1)\nwhere B = N X T. We will generate a triangle mesh for the decal object by clipping\nnearby surfaces to the four boundary planes. We also want to clip to front and back\nplanes to avoid bleeding through to parts of the same surface mesh that may be inside\nthe boundary planes, but far in front of or behind the point P. The 4D vectors corre-\nsponding to the front and back planes are given by\nfront = (-N, d + N • P)\nback = (N, d - N • P) \n(4.8.2)\nwhere d is the maximum distance that any vertex in the decal may be from the tan-\ngent plane passing through the point P.\nThe algorithm proceeds as follows. First, we identify which surfaces in the world\nmay potentially be affected by the decal. This may be determined by locating any sur-\nfaces whose bounding volume reaches within a certain distance of the point P. For\neach potentially affected surface, we individually examine each triangle in the surface's\nmesh. Let M denote the unit normal direction corresponding to the plane of a trian-\ngle in the mesh. We throw out any triangles for which N • M < £ for some fixed posi-\ntive value E, since these triangles are facing away from the decal s normal direction N.\nRemaining triangles are clipped to the planes given by Equations 4.8.1 and 4.8.2 and\nstored in a new triangle mesh.\nWhen a triangle overlaps any of the planes and needs to be clipped, we interpo-\nlate the normal vectors as well as the vertex positions so that we can later apply color-\ning to the clipped vertices that reflects the angle between each vertex's normal and the\ndeed's normal direction. This has the effect of smoothly fading the decal texture in\n\n\n4.8 Applying Decals to Arbitrary Surfaces \n413\nrelation to each triangle's orientation relative to the plane of the decal. We assign an\nalpha value to each vertex using the equation\nN ' R - e\nR\nalpha = \n(4.8.3)\nwhere R is the (possibly unnormalized due to interpolation) normal corresponding to\nthe vertex. This maps the dot product range [e,l] to the alpha value range [0,1].\nTexture mapping coordinates are applied to the resulting triangle mesh by mea-\nsuring the distance from the planes passing through the point P and having normal\ndirections T and B. Let Q be the position of a vertex in the decal's triangle mesh.\nThen the texture coordinates s and t are given by\nw \n2\nB • (Q - P) !\nt = — \n- + -\nh \n2 \n(4.8.4)\nTriangle Clipping\nEach triangle belonging to a surface that is potentially affected by the decal is treated\nas a convex polygon and is clipped to each of the six boundary planes one at a time.\nClipping a convex polygon having n vertices to a plane results in a new convex poly-\ngon having at most n + 1 vertices. Thus, polygons that have been clipped against all\nsix planes may possess as many as nine vertices. Once the clipping process is complete,\neach polygon is treated as a triangle fan and added to the decal's triangle mesh.\nTo clip a convex polygon against an arbitrary plane, we first classify all of the ver-\ntices belonging to the polygon into two categories: those that lie on the negative side\nof the plane, and those that lie on the positive side of the plane or on the plane itself.\nIf all of the polygon's vertices lie on the negative side of the plane, the polygon is dis-\ncarded. Otherwise, we visit every pair of neighboring vertices in the polygon looking\nfor edges that intersect the clipping plane. As shown in Figure 4.8.2, new vertices are\nadded to the polygon where such intersections occur, and vertices lying on the nega-\ntive side of the plane are removed.\nSuppose that the vertex V, lies on the positive side of the clipping plane C, and\nthat the vertex V2 lies on the negative side of C. A point V3 lying on the line segment\nconnecting Vj and V2 can be expressed as\nV3 = V1 + t(V2-V1) \n(4.8.5)\n\n\nSection 4 Geometry Management\nFIGURE 4.8.2 Clipping a polygon against a plane.\nwhere the parameter t satisfies 0 < t < 1. We would like to know for what value of t the\npoint v3 lies on the plane C. If we treat the V, as a homogeneous vectors having w-\ncoordinates of one, then we simply need to find the value of t for which the 4D dot\nproduct C • V3 is zero. Plugging in the right side of Equation 4.8.5 for V3 and solving\nfor t gives us\nt =\nO V,\no(v,-v2)\n(4.8.6)\n(Note that the difference V\\ — V2 has a zf-coordinate of zero.) Substituting this\nvalue of t back into Equation 4.8.5 gives us our new vertex.\nImplementation\nThe source code on the companion CD-ROM demonstrates the algorithm presented\nin this article through the implementation of a C++ class called Decal. The construc-\ntor of this class takes the decal center P, the normal direction N, and the tangent direc-\ntion T as parameters, as well as the width, height, and depth of the decal. After\ncalculating the boundary planes using Equations 4.8.1 and 4.8.2, the constructor\nclips all potentially affected surfaces to these planes and stores the resulting mesh in a\nnew triangle array. Vertex colors and texture mapping coordinates are then assigned\nusing Equations 4.8.3 and 4.8.4. The source code generated the scorch marking decal\nshown in Figure 4.8.3.\n\n\n4.8 Applying Decals to Arbitrary Surfaces\n415\nI*»s»«3iS(g3t8««»*8K\nFIGURE 4.8.3 A scorch mark decal applied to a curved surface.\nReferences\n[LengyelOO] Lengyel, Eric, \"Tweaking a Vertex's Projected Depth Value,\" Game\nProgramming Gems, Charles River Media, 2000, pp. 361-365.\n\n\n4.9\nRendering Distant Scenery\nwith Skyboxes\nJason Shankel, Maxls\nshankel@pobox.com\nC\nonsider a game that takes place on a Tibetan mountaintop. In the distance, we\ncan see the ridge of the Himalayas, clouds in the sky, and a village down in the\nvalley. Or, consider a game in deep space, with the Eagle and Orion nebulae shining\nfrom light-years away. Such imagery can heighten the beauty and sense of immersion\nof a 3D game.\nRendering distant scenery in 3D can be accomplished with skyboxes. This gem\nexplains the principle of skyboxing and describes alternative means for rendering a\nskyboxed scene.\nBasic Technique\nThe idea behind a skybox is very simple. Distant scenery is rendered onto six textures,\neach of which is applied to one side of a cube. The camera is placed at the center of\nthe cube. The camera can rotate freely within, but never move from the center of this\ncube. When the scene is rendered, the images projected on the walls of the skybox\ngive the impression of distant scenery much in the same way images projected onto\nthe ceiling of a planetarium give the impression of the night sky (Figure 4.9.1).\nSkybox Resolution\nIdeally, one texel in die skybox object should map to one pixel on the screen. The fol-\nlowing formula can be used to determine the ideal skybox resolution for a given\nscreen resolution\nscreenRes\nskyboxRes =\ntan.(fov/z)\nwhere skyboxRes is the resolution of one side of the skybox in texels, screenRes is the\nwidth of the screen in pixels, andyof is the angle of the horizontal field of view. For\nexample, a scene with a 90-degree field of view running at 640x480 would have an\nideal skybox resolution of 640 texels.\n416\n\n\n4.9 Rendering Distant Scenery with Skyboxes\n417\nFIGURE 4.9.1 Skybox as seen from above: distant terrain is rendered on the sides of the\nbox, and the camera is placed at the center.\nSome 3D systems limit texture resolution to 256x256 texels. This means that the\nskybox textures may be stretched noticeably when rendered to the screen. For some\napplications, this stretching may be acceptable. Others may wish to subdivide each\nskybox face to increase texture resolution (Figure 4.9.2).\nFIGURE 4.9.2 Subdividing the skybox's faces will improve image quality at the cost of\nincreased texture memory and polygon count. Upper left) One texture per side. Upper\nright) Four textures per side. Lower left) Sixteen textures per side.\n\n\n418 \nSection 4 Geometry Management\nSkybox Size\nBecause the camera is always at the center, it does not matter how big we make the\nskybox as long as it falls within the viewing frustum. As the size of the skybox\nincreases, its walls become proportionally more distant, keeping the same portion in\nframe.\nThe skybox dimensions should be chosen so that the farthest points, the corners,\nare closer to the camera than the far clipping plane. The following formula can be\nused to calculate the maximum skybox size:\nskyboxWidth <\nwhere skyboxWidth is the length of one edge of the skybox in world units, and zf aP. is\nthe distance to the far clipping plane in world units.\nRendering the Scene\nThe simplest technique for drawing a skybox is to render an ordinary textured cube,\naligned to the world axes and centered on the camera's world position. The skybox\nshould be the first thing rendered. There is no need to clear the color buffer first, as\nthe skybox will always fill the entire screen.\nWhen rendering a skybox, both depth testing and depth writing should be dis-\nabled, as the skybox geometry will not intersect properly with the other geometry in\nthe scene. Lighting, fogging, and any other similar effects should also be disabled.\nThe skybox images should be rendered without any atmospheric modification.\nAs noted earlier, a simple one-texture-per-face cube may produce significant tex-\nture stretching. Texture filtering can be used to reduce the effect of this stretching.\nTexture filtering reduces the jagginess of stretched images by sampling neighboring\ntexels and blending them together.\nTexture filtering may cause seams to appear along the edges of the skybox, where\ntwo textures meet. These seams are caused by improper texture wrapping. Texture\nwrapping determines how the texture filter decides which texels \"neighbor\" the texels\nat the edge of a texture. If texture wrapping is set to repeat (GL_REPEAT in OpenGL),\ntexels on one edge will be combined with texels on the opposite edge, causing seams\nbetween textures to stand out.\nIn OpenGL, texture wrapping should be set to GL_CLAMP_TO_EDGE_EXT, if possi-\nble. This will clamp filtering to the edge the texture, eliminating interference from\nborder texels. GL_EXT_texture_edge_clamp is an OpenGL extension, so it might\nnot be available on all systems. If the GL_CLAMP_TO_EDGE_EXT mode is not available,\ntexture filtering should be set to GL_CLAMP, which combines edge texels with the tex-\nture's constant border color.\n\n\n4.9 Rendering Distant Scenery with Skyboxes\n419\nCube Environment Mapping\nCube environment mapping is an alternative to traditional skybox rendering. Cube\nenvironment mapping combines all six sides of a skybox into a single texture.\nTraditionally, texture coordinates are specified as offsets into a two-dimensional\ntexture map, with (0,0) being one corner of the texture, and (1,1) being the opposite\ncorner. In cube environment mapping, six textures are combined to form a cube, and\ntexture coordinates are specified as three-dimensional vectors, pointing outward from\nthe center of the cube to a point on its surface (Figure 4.9.3).\nCube environment mapping can be used to render distant scenery, and to cast\nreflections of the skybox on nearby shiny objects.\nCube environment mapping limits skyboxes to one 2D texture per face, so subdi-\nviding faces to increase resolution is not possible. Fortunately, most cube environ-\nment mapping systems support texture resolutions above 256x256.\nFIGURE 4.9.3 Texture coordinates for cube environment maps are specified as vectors\npointing to the surface of a cube centered on the origin.\nGenerating Skybox Textures\nSome software packages provide direct support for generating skyboxes. For those\nthat don't, manually generating skybox images is simple.\nThe size of the output image should be set to texture resolution (e.g., 256x256)\nand the camera's field of view set to 90 degrees. Six renderings are generated, with the\ncamera looking up and down each of the three cardinal axes (left, right, up, down, for-\nward, and back).\n\n\n420 \nSection 4 Geometry Management\nConclusion\nA sense of place is critical to most 3D games. Rendering distant scenery not only\nincreases visual beauty, it also provides players with a means of orienting themselves in\nthe virtual environment. Skyboxes provide an economical and effective way to render\ndistant scenery.\nSource Code\nSample source code is provided using OpenGL and GLUT. The sample program\ndemonstrates both 2D and cube environment map rendering.\nCube environment mapping is supported in OpenGL via the GL_ARB_texture_\ncube_map extension. The sample code checks for the presence of this extension at\nstartup. In cube environment map mode, a shiny object is placed in the camera's view,\ndemonstrating reflectance.\nSkybox textures were generated with Terragen (Copyright © 1997—2000 Planet-\nside Software).\n",
      "page_number": 394,
      "chapter_number": 40,
      "summary": "These effects are commonly implemented by creating a new object,\nwhich we will call a decal, which coincides with an existing surface, and rendering it\nusing some type of depth offset technique (for example, see [LengyelOO]) Key topics include texture, textured, and skyboxes.",
      "keywords": [
        "texture",
        "skybox",
        "decal",
        "plane",
        "Rendering Distant Scenery",
        "Cube Environment Mapping",
        "surface",
        "cube",
        "Cube Environment",
        "Distant Scenery",
        "Applying Decals",
        "skybox textures",
        "decal triangle mesh",
        "Geometry Management",
        "clipping plane"
      ],
      "concepts": [
        "texture",
        "textured",
        "skyboxes",
        "skybox",
        "surfaces",
        "rendered",
        "render",
        "triangle",
        "clipping",
        "clip"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 7",
          "chapter": 47,
          "title": "Segment 47 (pages 453-467)",
          "relevance_score": 0.64,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 1",
          "chapter": 57,
          "title": "Segment 57 (pages 550-561)",
          "relevance_score": 0.59,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 1",
          "chapter": 60,
          "title": "Segment 60 (pages 581-588)",
          "relevance_score": 0.56,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 3",
          "chapter": 45,
          "title": "Segment 45 (pages 431-439)",
          "relevance_score": 0.56,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 1",
          "chapter": 44,
          "title": "Segment 44 (pages 422-430)",
          "relevance_score": 0.54,
          "method": "sentence_transformers"
        }
      ]
    },
    {
      "number": 41,
      "title": "Segment 41 (pages 405-415)",
      "start_page": 405,
      "end_page": 415,
      "detection_method": "topic_boundary",
      "content": "4.10\nSelf-Shadowing Characters\nAlex Vlachos, David Gosselin, and\nJason L. Mitchell; ATI Research\nalex@vlachos.com, gosselin@ati.com,\njasonm@ati.com\nR\nendering self-shadowing characters is an important visual cue missing from most\nreal-time games. This gem presents a projective texture approach, which enables\nself-shadowing of convex subsections of characters in real time. After breaking the\ncharacter into convex subsections, the subsections are rendered into a texture with\nvarying alpha values from the point of view of the light source. When the character is\nrendered from the viewer's point-of-view, this texture is projected back onto the con-\nvex subsegments of the character, simulating the occlusion of each subsegment with\nrespect to the light source. Being map based rather than stencil-volume based, this\ntechnique requires no additional work to be compatible with higher-order surface tes-\nsellation techniques.\nPrevious Work\nProjective techniques for shadowing started with [Williams78] and have been refined\nin many papers. This gem breaks with the depth-based shadow mapping and uses a\ntechnique similar to the priority buffers of [Hourcade85]. [LengyelOO] also uses a\nsimilar segmented technique.\nSegmenting Character Geometry\nThe first step in this algorithm is grouping the character geometry. The artist tags\nbones to form groups of geometry that will shadow the other groups of geometry.\nThese groups should be selected to reduce the segmenting of the model but retain the\nshadowing relationships. During preprocessing, the dominant bone for each polygon\nwill be determined by finding the bone that has the largest blending weight. The tag\nwill then be extracted from this bone and the polygon will be placed in the appropri-\nate group. See Figure 4.10.1 for an example of a segmented model.\n421\n\n\n422\nSection 4 Geometry Management\nFIGURE 4.10.1 Segmented model.\nRendering the Texture\nOnce the character has been logically divided into convex subsegments, these groups\nare sorted from front to back with respect to the light source. Since there are usually a\nrelatively small number of groups in a given character, this sorting is an insignificant\ncomputational burden. The character in Figure 4.10.2, for example, has only six\ngroups to sort. Then a view matrix is computed from the light's point of view such\nthat is centered on the center of the bounding box surrounding the object. A perspec-\ntive projection matrix is also generated to have the character fill as much of the ren-\nderable texture as possible.\nThe basic steps are:\n1. Compute light matrix.\n2. Clear renderable texture with (255, 255, 255, 255).\n3. Draw each of the subsegments into the alpha texture from front to back\n(from the light's point of view) with increasing alpha values: 0, 1, 2, 3,4,...\n254. (255 is reserved as the alpha clear color.)\nNote that the rate of increasing the alpha values can be spread out to cover the\nentire range of alpha values available based on the number of groups being rendered.\nThis will help to remove rendering artifacts, which is explained in the next section.\n\n\n4.10 Self-Shadowing Characters \n423\nRendering the Character\nOnce the shadow map is created, the next step is to render the character into the\nframe buffer using the shadow map. In a brute-force approach, this is accomplished in\nthree passes. The first pass renders a fully lit character into the frame buffer. The sec-\nond pass renders each of the subsegments of the character with an alpha test of less\nthan the alpha value that was used to draw the subsegment into the shadow buffer.\nThis is done for two reasons/The first reason is to use only those parts of the shadow\nbuffer that would be shadowing the character. Since the shadow buffer was segmented\nusing the alpha values, setting the alpha test of less than retrieves the shadows of all\nthe previous groups (the ones closer to the light). The second reason for using the\nalpha test is to effectively shrink the shadows by half a pixel in order to avoid pulling\nunwanted alpha values in from bilinear texture fetching. The texture matrix is set to\ntake the world space position of the object and transform it by the light's view and\nprojection matrix tliat was calculated when rendering to the texture. The pixels\nthat pass the alpha test are drawn in black, effectively masking out the lighting in the\nfirst pass. The final pass draws the character with its base color modulated by a small\nambient term to brighten the areas in shadow by an ambient term. Figure 4.10.2\nshows the results of this rendering over several frames of animation. This is obviously\na brute-force approach and can be optimized using pixel shaders.\nFIGURE 4.10.2 Character rendered, with shadows from three different angles.\nConclusion\nWe presented a way to render animated characters with self-shadowing using a pro-\njective texture technique. By segmenting the character into convex subsegments, we\navoided the aliasing found in purely depth-based approaches. The approach is also\ngeneral enough to be used by any graphics hardware that supports rendering to tex-\ntures and projective texture mapping.\n\n\n424 \nSection 4 Geometry Management\nReferences\n[Hourcade85] Hourcade, J. C., and Nicolas, A., \"Algorithms for Antialiased Cast\nShadows,\" Computers and Graphics, vol. 9, no. 3, pp. 259-264.\n[LengyelOO] Lengyel, Jerome E., \"Splatting for Soft-Edged Shadows,\" Microsoft\nTechnical Report, 2000.\n[Williams78] Williams, Lance, \"Casting Curved Shadows on Curved Surfaces,\"\nComputer Graphics (SIGGRAPH 78 Proceedings), vol. 12, no. 3, 1978, pp.\n270-274.\n\n\n4.11\nClassic Super Mario 64\nThird-Person Control and Animation\nSteve Rabin, Nintendo of America\nsteve rabin@hotmail.com\nT\nhe classic Super Mario 64 control scheme has easily become one of the most intu-\nitive ways to control a 3D character from a third-person perspective. While the\ngame Super Mario 64 didn't invent the technique, it did manage to polish it and pop-\nularize it with millions of gamers. It's routinely used as the measuring stick of an\nextremely playable control scheme. However, the real beauty is that it makes sense to\neven a first-time player, which is no small accomplishment.\nThis gem will deal with the basic issues of controlling and animating a character\nfrom a third-person perspective. While it seems straightforward enough (just copy\nSuper Mario 64), it's not as trivial as it first appears. There are many small nuggets of\nwisdom that can often take weeks of trial and error to discover.\nThe Setup\nThe classic Super Mario 64 control incorporates a free-floating camera that follows the\ncharacter around wherever he may go. Imagine the camera hovering behind him\nattached by a bungee cord to his body. As the character moves from a stand to a run,\nthe camera smoothly accelerates toward the character trying to maintain a fixed dis-\ntance from him. As the character turns, the camera gently circles around trying to stay\nbehind him.\nThe key to this control scheme is that the character will go whichever way we tell\nhim, as if we were sitting inside the camera. Therefore, if we press up on the con-\ntroller, the character will move away from the camera. If we press right, the character\nmoves rightward from the camera's perspective. The tricky part is that the camera is\nalways moving and that this camera-oriented control needs to be mapped onto the\nworld's coordinate system, where the character actually moves around.\nConverting the Controller Input\nThe basic programming problem involves converting the player's input (up, down,\nright, left) from the camera's perspective to the world orientation. In order to do this,\n425\n\n\n426 \nSection 4 Geometry Management\nwe need a vector that corresponds to the camera's forward direction, and a vector that\ncorresponds to the cameras rightward direction.\nThese vectors become useful because any up/down controller movements get\ndirectly mapped into translations along the camera's forward vector. Similarly, any\nright/left controller movements get mapped into translations along the camera's right\nvector. However, since the character basically moves on a flat plane, these camera vec-\ntors shouldn't contain any height information (traditionally represented by the/-axis).\nFigure 4.11.1 shows how we can think of the controller input in relation to the cam-\nera and the character.\nTop Down View\nDown\n1 T\nRight\nFIGURE 4.11.1 Controller relationship to character with respect to the camera.\nThe forward vector of the camera is easy to find since it's simply the direction the\ncamera is facing. Once we have it, we zero out the vertical axis and renormalize it.\nNow we can get the camera's right vector with the following relationship:\nright.x = forward.z\nright.z = -fonward.x\nnight.y = 0 . 0\nSince controller input traditionally comes in the form of numbers, a brief expla-\nnation is necessary. We can expect that the user input on an analog stick will basically\nvary from -1.0 to 1.0 along each axis. In reality, most input schemes use integers\nand vary from -128 to 127 or -32768 to 32767, but for our purposes, we'll need to\nconvert those to a floating-point number within the -1.0 to 1.0 range. However, its\nimportant to realize that Up and Right are both positive. The layout of a controller is\nshown in Figure 4.11.2.\n(Up)\n+1.0\n(Left)-1.0 •*—{ \n)—*+1.0 (Right)\n-1.0\n(Down)\nFIGURE 4.11.2 Values from an analog controller.\n\n\n4.11 Classic Super Mario 64 Third-Person Control and Animation \n427\nArmed with the camera's forward and right vectors, we can now remap the input\nfrom the controller to get the final world vector. The following relationship gives the\ndirection the character should move, in world coordinates.\nfinal.x = (inputLtRt * right.x) + (inputUpDn * forward.x)\nfinal.z = (inputLtRt * right.z) + (inputUpDn * forward.z)\nfinal.y = 0\nOnce this final vector is normalized, it can be applied to the character so that he\nmoves in the proper direction. It's important to remember that for every frame, a new\nforward and right vector must be calculated, since the camera can move at any time.\nRotating the Character\nThe user input at any instant gives a desired direction. By sampling the magnitude of\nthe directions over time, the speed of the character can be determined. A simple\nmodel for moving the character is to maintain both a direction and a speed separately.\nIt helps to keep them separate, instead of representing both as a single vector, so that\na speed of zero still retains a direction. Obviously, bad things would happen if we try\nto orient the character using a zero vector.\nAs the input is sampled over time, the character's direction should converge on\nthe user's desired direction. For example, if the character is facing north and the player\nturns him east, the character should turn toward the east using some kind of damp-\nening. A very pleasing dampening effect comes from simply adding a proportion of\nthe desired direction to the current direction, based on frame rate. In Figure 4.11.3,\nnotice how the character initially rotates quickly and then slowly dampens toward the\nfinal desired direction over a short period of time.\nThe soft dampening shown in Figure 4.11.3 results in a smooth, responsive feel\nwhen controlling the character. The rate at which it converges on the desired direc-\ntion can be carefully tuned to get the desired feel. The dampening function in Figure\n4.11.3 can be represented by the following formula:\nnew_dir = (old_dir * 0.5) + (desired_dir * 0.5)\nNormalize( new_dir )\nBy taking into account frame rate, the dampening function can be made to be\nfairly resilient to frame rate fluctuations. Unfortunately, wild frame rate fluctuations\nAngle: 90° \n45° \n22.5° \n12.3° \n6.1° \n3.0° \n1.5°~* 0°\nTime: \n0\n1\n2\n3\n4\n5\n6\n7\nFIGURE 4.11.3 Character rotation over time with exponential dampening.\n\n\n428 \nSection 4 Geometry Management\nof 100 percent or so are not dealt with properly. The following is a dampening for-\nmula that is semi-resilient to frame rate changes (within a certain window).\nnew_ratio = 0.9 / FPS\nold_ratio = 1.0 - new_ratio\nnew_dir = (old_dir * old_ratio) + (desired_dir * new_ratio)\nNormalize( new_dir )\nThis new dampening formula will now rotate the character 90 percent toward the\ndesired direction after one second, regardless of frame rate. The percentages need to\nbe tuned, but whatever frame rate it's tuned to becomes the center of our frame rate\nwindow. However, as the frame rate wanders too far from that center, the \"feel\" will\nslowly distort and become either too sensitive or too sluggish. If the frame rate varies\ntoo much, we can consider decoupling this calculation with the graphics update in\norder to maintain a steady rate.\nWhen a character is told to move 180 degrees from the current direction, smooth\nrotation is not always the best solution. Since there is such a large angle to cover, it\nresults in an extended rotation that can feel clunky and unnatural. Instead, it's better\nto use a transition animation to make large changes in direction. In Super Mario 64,\nthis occurs when Mario is at a full run and told to go in the opposite direction. This\nresults in a skidding stop followed by a seamless 180-degree in-place turn. However,\nduring this process, there's a speed penalty that stalls him for a split second before he\ncan move again.\nThe method of rotation described up to this point is fairly touchy feely and is\nultimately susceptible to frame rate issues, even though they have been reduced. For\nexample, if you record a player's input and feed it back to the game at a slightly dif-\nferent frame rate, the result will be slightly different. This has grave consequences if\nyou record a game, using input alone, and plan to replay it back from a different cam-\nera angle (perhaps causing the frame rate to vary). The solution is either to lock the\nsimulation rate or use a highly controlled method of rotation, such as clamping to a\nparticular angular velocity. However, this would give up some of the smooth accelera-\ntion effects in return for higher predictability.\nTranslating the Character\n•lim,f.-............ ...,„.,.... ..,.,........„.._„„....... \n....-*....,.... ................,~...................... -::~p~.~~:™wr™~:~^~ -;-•;•::-/ -.\".>s;i^-\"-..\"&^;::-~ —;;:••:-• :•--• ^.\\.^..:':\"-:^::*\nWith the character smoothly turning, we now need to actually move the character.\nThis is done by taking the character's current direction and translating him forward\nby the current speed. The smooth rotation of the character basically points the hips in\nthe proper direction, and the current speed moves him forward.\nWe'll want some type of dampening function, just like with the rotation, to con-\ntrol the speed. However, the speed needs to be clamped to a top speed, unlike the\nrotation. We'll also want to penalize the current speed for 180-degree turns and turns\nin general. The dampening function should quickly converge (faster than I/10th of a\nsecond) to the desired speed in order to make the control feel responsive.\n\n\n4.11 Classic Super Mario 64 Third-Person Control and Animation\n429\nResponsiveness is a funny thing. Ideally, a character should respond instanta-\nneously to a player's input. However, this is both unrealistic and abrupt. By adding an\nexponential dampening, the edge is taken off transitions while maintaining respon-\nsiveness. Note that this implies that there are no physics taking place. Characters have\ntremendous control over their movement and actually don't accelerate and decelerate\nlike a car or rocket ship. Figure 4.11.4 shows the speed of a character under controller\ninput. Notice how responsiveness equates to quickly advancing to the desired speed\nand then smoothly converging on it.\nControl Stick\n0.0\n•1.0\nMagnitude\nFIGURE 4.11.4 Character speed based on controller input with exponential dampening.\nAnimating the Character\nThe simplest animation scheme is to have two different animation loops: standing\nand running. When the character's speed is zero, play the stand animation. When the\ncharacter's speed is above zero, play the running animation. Obviously, most charac-\nters should have more elaborate animations, but this is a good starting place.\nHere are some tricks to making the animation look reasonable:\n1. Match the speed of the animation (the movement of the feet) with the top\nspeed of the character. When moving, the character will spend most of the\ntime at the top speed, so the loop should look the best at this speed. At this\nspeed, the feet should meet the ground and appear to stick until they're\nlifted back up.\n2. The speed of the animation can be changed to match the speed of the char-\nacter, but most animations only look reasonable at a tiny range of speeds.\nThere is a little room to vary the speed, but not the full range from 0 to 8\nm/s for a decent run. A run can usually be varied from 5 to 8 m/s, a trot can\nbe varied from 3 to 5 m/s, and a walk can vary from 1 to 3 m/s. Actual\nranges can only be found experimentally with the actual animation data\nand are extremely subjective.\n3. When the character is turning sharply at high speeds, die character should\nalgoridimically lean into the turn. This helps emphasize speed and looks more\n\n\n430\nSection 4 Geometry Management\nnatural. Another turning enhancement is to have the character algorithmically\nrotate his head slighdy in the direction of the turn. This further adds to the\nrealism, since characters generally anticipate and look toward future positions.\n4. Transition animations (stand to run, walk to run) are tricky to implement.\nUsually they tend to get in die way of responsiveness. A simple, clean solu-\ntion is to algorithmically construct a single in-between frame when transi-\ntioning. This takes the edge off transitions without getting in the way of the\nlook or feel. Calculating in-between frames is a well-known problem that\ncan be referenced in many animation programming books.\n5- The transition from a stand to a walk or run can be virtually seamless by\ndesigning the walk or run loop correctly. Figure 4.11.5 shows what the first\nframe of the loop should look like. Notice how the left foot is on the\nground while the right foot is barely being lifted into the air. This particular\nkeyframe minimizes the jar when changing animations from a stand to the\nwalk or run. However, since a moving character can potentially stop at any\ntime, this doesn't help smooth the transition to a stand. Transitioning to a\nstand can be dealt with by quickly interpolating die character to the stand\nposition, paying careful attention not to let the feet pierce the ground.\n6. A more elaborate transition system can be devised where there are actual\ntransition animations, such as a stand-to-run and a run-to-stand. When the\nplayer commands the character to start moving, the stand-to-run animation\nis played and then followed by the run loop. When the player tells the char-\nacter to stop, the character must somehow transition smoodily to the run-\nto-stop animation regardless of the current frame of the run loop. A simple\nway to solve this is to have two different run-to-stand animations, each\nbeginning with a different foot in front. This way, the run loop at most\n1R\nStand \nWalk \nRun\nFIGURE 4.11.5 First frame for smooth transitions.\n\n\n4.11 Classic Super Mario 64 Third-Person Control and Animation\n431\nneeds to play out half the run cycle before it can seamlessly transition into\nthe run-to-stand animation. Unfortunately, some responsiveness is sacri-\nficed if animations are forced to play out longer than necessary in order to\nline up transitions. Also, transition animations need to be lightning quick\nor else responsiveness is compromised even further. Depending on the\ndesired look and feel of the game, it will take experimentation with both\ncanned and algorithmic transitions in order to find the proper mix.\nSuper Mario 64 Animation Analyzed\nThe following tables list the animation behavior that can be found in Super Mario 64.\nThis info was created by observing the game without any knowledge of actual imple-\nmentation. Certainly, any game can be analyzed in this way in order to deconstruct\nthe control and animation techniques.\nSpeed\nStand\nMedium\nFast\nVery Fast\nTransitions\nAnimation\nSeveral idle animations\nTrot\nRun with forward lean\nRun with pronounced forward lean\nAnimation\nStand to Tip-toe\nStand to Trot\nStand to Run\nTip-toe to Stand\nTrot to Stand\nRun to Stand\nTip-toe to Trot\nTrot to Run\nTrot to Tip-toe\nRun to Tip-toe\nRun to Trot\nAction\nAny turn during Stand\n180° turn during Tip-toe\n180° turn during Trot\n180° turn during Run\n< 180° turn during Tip-toe\n< 180° turn during Trot\n< 180° turn during Run\nTurning during Run\nSingle Walk cycle followed by Tip-toe\nPop into Trot\nPop into Run with puff of smoke\nPop into Stand\nPop into Stand\nPop into skidding stop, then seamlessly into Idle\nPop into Trot\nPop into Run (matching the foot cycle) with puff of smoke\nPop into Tip-toe\nPop into Tip-toe\nPop into Trot (matching the foot cycle)\nResulting Behavior\nPop into direction\nSmooth tight u-turn\nSmooth tight u-turn\nSkid to stop with smooth about-face\nSmooth rotation\nSmooth rotation\nSmooth rotation\nLean into turn\n",
      "page_number": 405,
      "chapter_number": 41,
      "summary": "This gem presents a projective texture approach, which enables\nself-shadowing of convex subsections of characters in real time Key topics include animation, animated, and animations.",
      "keywords": [
        "character",
        "Classic Super Mario",
        "Super Mario",
        "run",
        "animation",
        "speed",
        "frame rate",
        "Character speed",
        "stand",
        "direction",
        "frame",
        "camera",
        "Mario",
        "Classic Super",
        "Character Geometry"
      ],
      "concepts": [
        "animation",
        "animated",
        "animations",
        "characters",
        "control",
        "controlling",
        "speed",
        "speeds",
        "smoothly",
        "dampens"
      ],
      "similar_chapters": [
        {
          "book": "Game_Engine_Architecture",
          "chapter": 26,
          "title": "Segment 26 (pages 503-525)",
          "relevance_score": 0.53,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 7",
          "chapter": 46,
          "title": "Segment 46 (pages 443-452)",
          "relevance_score": 0.51,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 1",
          "chapter": 57,
          "title": "Segment 57 (pages 550-561)",
          "relevance_score": 0.5,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 3",
          "chapter": 45,
          "title": "Segment 45 (pages 431-439)",
          "relevance_score": 0.49,
          "method": "sentence_transformers"
        },
        {
          "book": "makinggames",
          "chapter": 6,
          "title": "Segment 6 (pages 43-50)",
          "relevance_score": 0.49,
          "method": "sentence_transformers"
        }
      ]
    },
    {
      "number": 42,
      "title": "Segment 42 (pages 416-423)",
      "start_page": 416,
      "end_page": 423,
      "detection_method": "topic_boundary",
      "content": "432 \nSection 4 Geometry Management\nConclusion\nUndoubtedly, many great games have implemented the classic Super Mario 64 third-\nperson control, even before Super Mario 64 ever existed. However, before trying to\ncode something, find an example to model and become intimately familiar with it.\nTry to notice every nuance of what happens under different controller inputs. Notice\nthe transitions, the acceleration/deceleration of the motion/rotation, the different\nspeeds of walks/trots/runs, the shallow and sharp turns, and the decay after com-\npletely letting go of the controller. Having a good example to model is important so\nthat you have a stable target to copy and ultimately improve upon.\nReferences\n[Maestri99] Maestri, George, Digital Character Animation 2: Essential Techniques,\nNew Riders Publishing, July 1999.\n\n\n5.1\nInker\nCartoon Rendering: Real-time\nSilhouette Edge Detection and\nRendering\nCarl S. Marshall, Intel Architecture Labs\ncarl.s.marshall@intel.com\nS\nilhouette detection and rendering is a key component for adding a stylized look\nto 3D cartoon rendering. The basic concept of silhouette edge detection is to find\nthe important edges that depict the outline of a model. Many cartoon animators illus-\ntrate these silhouettes by tracing a black outline around the borders of a model. This\ncartoon rendering gem describes several silhouette edge detection techniques: an\nedge-based detection method, a programmable vertex shader technique, and an\nadvanced texturing technique. The advantages and disadvantages of each technique\nare highlighted.\nThe terms inking and painting come from the artist's traditional cartoon eel creation\nprocess. Inking a eel is the process of drawing the outlines of the characters and\nobjects in the scene, while painting is the process of coloring or filling in the interior\nof the outlines. This gem focuses on the inking process of cartoon rendering. Adam\nLake's gem on \"Cartoon Rendering Using Texture Mapping and Programmable Ver-\ntex Shaders\" covers the painting process. Together, these two techniques form a com-\nplete cartoon rendering engine. Figure 5.1.1 demonstrates the inking and painting\nprocess on a 3D duck model.\nThe general inking process is comprised of two parts. The first part is the detec-\ntion of the silhouettes, and the second is the rendering of the silhouettes. This gem\ndescribes this inking process using several techniques that can all be performed in real\ntime on both manifold and nonmanifold meshes.\n\n\n5.1 Cartoon Rendering: Real-time Silhouette Edge Detection and Rendering\n437\nFIGURE 5.1.1 A gouraud-shaded duck (left), inked duck with faces colored as\nbackground (center), and a flat-shaded duck using the painter (right).\nImportant Edges\nSilhouette edge detection (SED) is the main component of the inker. Along with the\ndetection and rendering of silhouettes, there are other important edges of the model\nthat artists tend to highlight: the crease and boundary edges. As described in the intro-\nduction, silhouette edges are the edges that form the outline of a model, but can also\ncontain some internal edges, as shown in Figure 5.1.2. One aspect that is very impor-\ntant to silhouette edge detection is that silhouettes are view dependent. This means\nthat the silhouettes have to be re-detected and rendered with each change in the\nmovement of the camera or model. Crease angle edges are those edges whose angle\nBack-facing polygon\n\\\nFront-facing polygon\nCamera's View Vector \nSilhouettes from Camera View\nFIGURE 5.1.2 Shows the silhouettes detected from a camera facing the first step (left).\n(Right) shows the silhouettes from the camera's view of the stairs.\n\n\n438 \nSection 5 Graphics Display\nbetween its two neighboring faces is within a given threshold. This is called the dihe-\ndral angle. A user-defined threshold is used to detect crease angles. The boundary\nedges are edges that border a discontinuity in the mesh. A discontinuity in the mesh\noccurs where two faces that border an edge contain the same vertices for that edge but\nhave one of the following differences: texture coordinates, materials, or normals.\nSilhouette Edge Detection Techniques\nWhy are there so many different silhouette edge techniques? For starters, there are\nseveral rendering APIs that have certain advantages and disadvantages as far as render-\ning performance, features, and functionality on various video cards. This gem\ndescribes a summary of experiments on many of the inking methods. Texture map-\nping features, line segment rendering, and polygon offsetting are just a few of the fea-\ntures that vary dramatically across hardware and APIs.\nEdge-based Inking\nThe term edge-based is used to describe a technique that analyzes the edges of the\npolygons of the model to detect and render its important edges. The full silhouette of\nthe model along with accurate silhouettes and crease edges are guaranteed with this\nmethod. Other inking techniques imply silhouette and crease edges through an esti-\nmation of surface curvature. The edge-based technique consists of two parts: a pre-\nprocess part and a run-time part.\nPreprocess\nThe first step in the preprocess is to allocate and find a unique edge list for the model.\nThe three edges of each face of the model are examined individually and inserted into\na hash table if they have not previously been stored. Once the hash table is complete,\na compacted array can be stored with only the unique edges. An edge entry includes\ntwo vertex indices, two face indices, and a flag entry. The flag entry describes the edge\nas a silhouette, crease angle, boundary, and/or an unimportant edge.\nTo detect silhouettes accurately, face normals have to be computed. If the model\nis static (nonanimating), then these normals can be precomputed along with the\ncrease angle edges. For nonprogressive meshes, the boundary edges can be processed\nat authoring or load time. The trade-off for accurate silhouettes at runtime for ani-\nmating objects is the recomputation of the face normals every frame.\nRuntime\nRuntime consists of detecting and rendering the important edges of the model. V\nrefers to the viewing vector, and Nj and N2 are the face normals of the triangles that\nshare the edge in consideration.\n\n\n5.1 Cartoon Rendering: Real-time Silhouette Edge Detection and Rendering \n439\nRuntime Inking\n1. If animating geometry, recalculate face normals.\n2. For each edge in the unique edge list,\n• Compute V by subtracting the viewing vector position from one of the\nedge vertex positions.\n• Set boundary flag if edge has one neighboring face or two neighboring\nfaces with discontinuities.\n• If animating geometry, set crease flag if the dihedral angle between the\ntwo neighboring faces exceeds a given threshold.\n• Detect silhouette using (A/i • V) X (N2 • V) < 0 and set silhouette flag.\n3. Iterate over edge list and render edges whose edge flag is set. Creating sepa-\nrate silhouette, crease, and boundary edge lists can optimize the rendering\nof the edges since each edge list can be rendered in a single API call. If the\nAPI you are using supports polygon offsetting and line thickness, they both\ngive added visual appeal to the final rendering.\nStep 2 is the core to the silhouette detection algorithm. By calculating the dot\nproducts between the face normal and the view vector for each of the edge's neigh-\nboring faces, highly accurate silhouettes are detected. Vertex normals could be used as\nan optimization, but this technique would miss silhouettes much like many of the\nvertex and pixel shader-based approaches. See Listing 5-1.1 for a code example.\nAdvantages\n• Cross-platform solution.\n• Completely accurate silhouette edge detection.\n• Artists can choose threshold for crease angle edges.\n• Visibility of edges is solved via the z-buffer.\nDisadvantages\n.• Line thickness is only available under certain APIs.\n• Must compute face normals for silhouette edge detection.\n• An offset needs to be applied to the lines to avoid the model occluding the line.\nListing 5.1.1 Edge-based silhouette edge detection\n// Detect silhouettes\nEdge *pEdge;\n// Iterate over all edges\nfor(unsigned int i=0; i < numEdges; i++){\npEdge = &m_pEdgel_ist[i];\n//Calculate vector from eye\npEdgeVertexPosition =\npMesh->GetVertexPosition(pEdge->GetVertexIndex(0));\n\n\n440 \nSection 5 Graphics Display\n// Subtract eyeposition from a vertex position on the edge\nviewVector = pEyePosition - pEdgeVertexPosition;\nview/Vector. normalize () ;\n// Calculate the dot products from the face normal and\n// the view vector\nuDotProductl = DotProduct(viewVectpr, *pFaceNormalA);\nuDotProduct2 = DotProduct(viewVector, *pFaceNormalB);\nif((uDotProductl * uDotProduct2) <= 0.0f){\n// The edge is a silhouette edge\nAddEdgeToRenderEdges(pEdge, uNumfienderedVertices);\nProgrammable Vertex Shader Inking\nA programmable vertex shader is an extremely flexible graphics API for modern\ngraphics architectures. Why is a programmable vertex shader able to help with inking?\nSince we have shown that inking relies on the dot product of a normal with the view\nvector, we can pass the view vector and normals to the graphics hardware to find\nsilhouettes.\nProgrammable Vertex Shader Inking Runtime\n1. Set up texture pipeline via the graphics API. This requires the creation\nor loading of a one-dimensional texture. It works fine to load a two-\ndimensional texture, but only the first row will be used. In setting up the\ntexture, the color may be varied when moving across the texture from the\nsilhouette color, usually black, to any color desired. A 1x32 or 1x64 texture\nwith only a few black pixels near u=0 progressing to the surface material\ncolor for the rest of the texels is recommended.\n2. Load the registers of the programmable vertex shader. What you need to\nload may depend on your specific application and where you are doing your\ntransformations, but normally you need to send the world to eye and projec-\ntion matrix. Next, the vertex position and vertex normal should be sent and\ntransformed. Then, the eye position is sent and used to compute texture\ncoordinates. Since new texture coordinates are computed, they do not need\nto be passed to the card. However, remember to make sure that the graphics\nunit expects texture coordinates to be generated for the model.\n3. Perform the transformation of the vertex position from model to homoge-\nnous clip space.\n4. For each vertex, create a view vector by subtracting the vertex position in\nworld space from the eye vector. Compute the dot product between the ver-\ntex normal and the view vector, N* V, shown in Listing 5.1.2. Make sure\nthe normal and view vector are in the same coordinate frame or the results\n\n\n5.1 Cartoon Rendering: Real-time Silhouette Edge Detection and Rendering \n441\nwill be incorrect. This can be done on the graphics unit or the CPU before\nbeing loaded into the constant registers of the vertex shader.\n5. Store the result of step 4 as the texture coordinate for the u texture\ncoordinate.\nAnother silhouette programmable vertex shading technique is a two-pass tech-\nnique that first extrudes the vertex along its normal. Then the depth buffer is disabled\nand the model is rendering in the desired silhouette color. Next, the depth buffer is\nreenabled and die model is rendered in its normal state.\nAdvantages\n• Fast. All silhouette detection processing is placed on graphics card.\n• Varying line thickness.\nDisadvantages:\n• Less accurate. Relies on vertex normals that depend on the object's shape.\n• Does not detect crease or boundary edges without special variables.\n• \nRequires programmable vertex shader API support.\nListing 5.1.2 Silhouette shader for DirectX 8.0\nvertex programmable shading\nt \n.. \n... \n._ \n_ \n... \n.. \n... \n.. \n... \n...\n; Constants specified by the application\n; \nc8-c11 = world-view matrix\n; \nc12-c15 = view matrix\n; \nc32 \n= eye vector in world space\ni\n; Vertex components (as specified in the vertex DECL)\n; \nvO \n= Position\n; \nv3 \n= Normal\n; Vertex transformation\nt \n. \n_ \n_ \n....-.....-.-. \n--..-.\n; Transform to view space (world matrix is identity)\n; m4x4 is a 4x4 matrix multiply\nm4x4 r9, vO, c8\n; Transform to projection space\nm4x4 n10, r9, c12\n; Store output position\nmov oPos, r10\n; Viewing calculation eye dot n\nt \n- \n. \n--. \n_ \n_ \n__. \n- \n. \n.\n;first, make a vector from the vertex to the camera\n;value in r9 is in world space (see vertex xform above)\n\n\n442 \nSections Graphics Display\nsub r2, c32, r9 \n;make vector from vertex to camera\n; now normalize the vector\n; dp3 is a dotproduct operation\nmov r3, r2 \n;make a temp\ndp3 r2.x, r2, r2 \n;r2A2\nrsq r2.x, r2.x \n;1/sqrt(r2A2)\nmul r3, r2.x, r3 \n;(1/sqrt(r2A2))*r3 = r3\n•',. dp3 oTO.x, r3, v3 \n; (eye2surface vector) dot surface normal\nInking with Advanced Texture Features\nAn innovative technique that can be performed fully on the graphics processor is\ndescribed in detail in [DietrichOO]. This method uses a per-pixel Ndot Vto calculate\nand obtain the silhouette. An alpha test is used to clamp the values to a black outline,\nand a per-primitive alpha reference value is used to vary the line thickness. The basic\nsteps are listed next, but for more details, see the reference.\nBasic Steps\n1. Create a normalizing cube map texture. Effectively, this creates a single tex-\nture that contains the six square faces. Each face contains a per-pixel RGB\nnormal that represents the direction of that point on the unit cube from the\norigin.\n2. Use view space normal texture coordinates as a lookup into the cube map\ntexture. This outputs a RGB-encoded vector representing A^.\n3. Use view space position texture coordinates as a lookup into the cube map\ntexture. This outputs a RGB-encoded vector representing V.\n4. Set the Alpha compare mode to LESS_EQUAL.\n5. Set the Alpha reference value to 0 for thin lines, higher for thicker lines.\n6. Perform the dot product on the color values from steps 2 and 3, performing\nNdotV.\n7. Perform one pass with the alpha test LESS_EQUAL for the silhouettes, and\nthen another pass with alpha test set to GREATER for the shaded object.\nAdvantages\n• Very fast with appropriate hardware.\n• Allows line thickness to vary.\nDisadvantages\n• Less accurate. Relies on vertex normals that depend on the object's shape.\n• Requires specific thresholds for detecting crease angles, and specific alpha refer-\nence values for boundary edges.\n• Requires specific hardware for speed.\n",
      "page_number": 416,
      "chapter_number": 42,
      "summary": "This gem focuses on the inking process of cartoon rendering Key topics include edge, silhouette, and texture. However, before trying to\ncode something, find an example to model and become intimately familiar with it.",
      "keywords": [
        "Silhouette Edge Detection",
        "Silhouette Edge",
        "Edge Detection",
        "Edge",
        "Real-time Silhouette Edge",
        "Silhouette",
        "Cartoon Rendering",
        "vertex",
        "Rendering",
        "programmable vertex shader",
        "edge detection techniques",
        "vertex shader",
        "Detection",
        "Vector",
        "Texture"
      ],
      "concepts": [
        "edge",
        "silhouette",
        "texture",
        "rendering",
        "render",
        "facing",
        "face",
        "cartoon",
        "detection",
        "detected"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 3",
          "chapter": 42,
          "title": "Segment 42 (pages 401-412)",
          "relevance_score": 0.61,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 1,
          "title": "Segment 1 (pages 1-13)",
          "relevance_score": 0.6,
          "method": "sentence_transformers"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 22,
          "title": "Segment 22 (pages 421-440)",
          "relevance_score": 0.6,
          "method": "sentence_transformers"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 23,
          "title": "Segment 23 (pages 441-462)",
          "relevance_score": 0.53,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 3",
          "chapter": 48,
          "title": "Segment 48 (pages 456-465)",
          "relevance_score": 0.52,
          "method": "sentence_transformers"
        }
      ]
    },
    {
      "number": 43,
      "title": "Segment 43 (pages 424-431)",
      "start_page": 424,
      "end_page": 431,
      "detection_method": "topic_boundary",
      "content": "5.1 Cartoon Rendering: Real-time Silhouette Edge Detection and Rendering \n443\nConclusion\nThe inking and painting techniques used to cartoon render a scene are just a couple of\ntechniques in a larger domain called nonphotorealistic rendering (NPR). There are\nmany other stylized rendering techniques in the NPR field with which to experiment.\nA few of these techniques are pencil sketching, water coloring, black-and-white illus-\ntrations, painterly rendering, and technical illustrations. Inking is a fundamental tool\nand is a great place to start building your NPR library. This library will help you dis-\ntinguish your game from others by giving you the flexibility of alternate rendering\nstyles that will potentially broaden the appeal of your game.\nReferences\n[DietrichOO] Dietrich, Sim. \"Cartoon Rendering and Advanced Texture Features of\nthe GeForce 256 Texture Matrix, Projective Textures, Cube Maps, Texture Coor-\ndinate Generation and DOTPRODUCT3 Texture Blending.' Available online\nat: www.nvidia.com/Marketing/Developer/DevRel.nsf/WhitepapersFrame. 2000.\n[GoochOl] Gooch, Bruce, and Amy Gooch. Non-Photorealistic Rendering, A.K.\nPeters, Ltd., 2001.\n[IntelOO] Intel's Graphics and 3D Technologies Web page. Available online at:\nhttp://developer.intel.com/ial/3dsoftware. 2000.\n[LakeOO] Lake, Adam, Carl Marshall, Mark Harris, and Mark Blackstein. \"Stylized\nRendering Techniques of Real-Time 3D Animation.\" Non-Photorealistic Anima-\ntion and Rendering Symposium, pp. 13-20. 2000. ftp://download.intel.com/\nial/3dsoftware/toon.pdf.\n[Markosian97] Markosian, Lee, Michael Kowalski, et al. \"Real-Time Nonphotorealis-\ntic Rendering.\" In Proceedings of ACM SIGGRAPH 97, pp. 113-122. 1997.\n\n\n5.2\nCartoon Rendering Using\nTexture Mapping and\nProgrammable Vertex Shaders\nAdam Lake, Intel Architecture Labs\nadam.t.lake@intel.com\nC\nartoon rendering is a stylistic rendering technique that can give a 3D scene the\nlook and feel of a cartoon environment. The techniques described in this gem\ntake advantage of modern real-time graphics capabilities, including texture mapping\nand programmable vertex shading. The basic idea is to simulate a limited color palette\nusing textures. To do this, we modify the standard diffuse shading equation to create\na highlight and shadow color, and use these colors to create a small texture map for\neach material to be used as a lookup table at runtime. Additionally, these techniques\nrequire no additional markup information from the artist—this gem describes the\ncreation of the texture maps and texture coordinates for each material.\nCartoon Shading\nCartoon shading is achieved by mimicking the process of fainting And inking eels used\nfor animation. This gem covers the painting algorithm. Carl Marshall has a gem, \"Car-\ntoon Rendering: Real-time Silhouette Edge Detection and Rendering,\" that covers the\ninking of the eel used for animation. Inking creates the outlines, or silhouettes, of the\nmodels that are \"filled\" by the painting pass of the Tenderer. It does diis by detecting\nthe silhouettes, creases, and material boundaries of the surface. For more details on the\ninking technique, see Carl Marshall's gem. The painter examines the material proper-\nties of the object along with the lighting, and calculates a texture map to be used for\nrendering of each mesh. The painter also calculates texture coordinates for the surface.\nEach gem can be used alone to achieve its own effect, or they can be used in combina-\ntion to simulate the complete painting and inking method used by animators.\nPainting\nThe painting process can be broken down into two phases, the preprocess and the run-\ntime. In the preprocess, each material is assigned a texture map that is created based\n\n\n5.2 Cartoon Rendering Using Texture Mapping and Programmable Vertex Shaders \n445\non lighting and material properties. In the runtime phase, this texture map is set as\nthe active texture, and the texture coordinates are generated based on the result of the\nangle between the vertex normal and the light vector. For positional lights, the surface-\nto-light vector needs to be computed per vertex; therefore, an expensive normalize per\nvertex is computed since the surface to light vector is different for each vertex. For\ndirectional lights, the light comes from the same direction at all points in the scene;\ntherefore, the direction is the same and the surface-to-light vector doesn't require\nrecomputation for each vertex. When performance is an issue, use directional light-\ning. In most cases in cartoon shading, the additional realism provided by positional\nlights is of little benefit.\nPreprocess\nThe preprocess consists of three steps for each material. First, calculate the illumi-\nnated diffuse color. Next, calculate the shadowed diffuse color. Finally, create a texture\nfor each material based on these colors. In this example, only a one-dimensional tex-\nture is needed, but using a two-dimensional texture works just as well and probably is\nbetter suited to the fast path with most graphics hardware and graphics APIs.\nIn the following process, C,- refers to the illuminated diffuse color, Cs refers to the\nshadowed diffuse color, Aff refers to the global ambient light, and Am and Af refer to\nthe ambient color for materials and lights, respectively.\nPreprocess Cartoon Shade:\n1 . Calculate the illuminated diffuse color.\n+ D;X Dm\n2. Calculate the shadowed diffuse color.\nCs = AgxAm+Al xAm\n3. For each material, create and store a one-dimensional texture map with two\ntexels containing the results of steps 1 and 2. Assuming the texture uses the\ntexture coordinate u, store C;at the u=l end of the texture and Cs at u=0.\nRuntime\nRuntime consists of setting up the texture pipeline with the preprocess texture, com-\nputing a dot product per vertex, and using this value to determine texture coordinates\nfor each vertex. L refers to the light vector and n refers to the vertex normal in the\nsteps that follow.\nRuntime Cartoon Shades\n1. Set up texture pipeline to make the texture computed in the preprocess\nthe active texture. Set the texture coordinate mode to clamp the texture\n\n\n446 \nSection 5 Graphics Display\ncoordinates generated. In general, we are not interested in multitexturing in\nthis step, so we set the texture combining function to replace.\n2. For each vertex, compute the dot product between the vertex normal and\nthe light direction vector, L • n. We also want to clamp the value so we do\nnot allow negatives, so the resultant equation is max/Z • n, 0}. See Listing\n5.2.1 and Figure 5.2.1.\n3. Disable lighting.\n4. Enable texture mapping.\n5. Render model.\nListing 5.2.1 Function for computing Toon texture coordinates\nSetTextureCoordinates(Mesh *pMesh, Light *pLight)\n//grab the light.\n//If there are multiple light source in the scene return the\n//greatest contributor\npLight->GetLightToWorldMatrix(&lightToWorldMat);\n//convert light direction in light space to light direction in\n//world space\nvector4 \nlightDir!nLightSpace.set(0,0,-1,0);\nvector4 lightDirlnWorldSpace;\nlightDirlnWorldSpace = lightToWorldMatrix * lightDirlnLightSpace;\n//convert light direction in world space to light direction in\n//model space\nmatrix4x4 *meshToWorldMatrix = pMesh->GetMeshToWorldMatrix();\nvector4 lightDirlnModelSpace;\nlightDirlnModelSpace = meshToWorldMatrix->inverse() *\nlightDirlnWorldSpace;\nlightDirlnModelSpace.normalize();\nint iNumVerts = pMesh->GetNumVerts();\n//for demonstration, we assume directional lights, point lights\n//would need a vector pointed from eye to vertex for each\n//dotproduct.\nfor(int iVert=0;iVert>iNumVerts;iVert++)\nvectors vert = mesh->GetVert(iVert);\nvectors normal = mesh->GetNormal(iVert);\nfloat fTexU.fTexV;\n//only negate if the light points from light to object\nfTexU = -normal->dotproduct(lightDir!nModelSpace);\n//max(L.n,0)\nif(texU < 0) texU = 0.0;\nfTexV = 0.0;\n\n\n5.2 Cartoon Rendering Using Texture Mapping and Programmable Vertex Shaders \n447\nN:\nu=0 \nu=l\nFIGURE 5.2.1 In this figure Nj, N2, #WN3 are the normal vectors at the surface. L\nrepresents the directional light vector. Note that when N; • L=0, where i= 1, we are at\nu=0 in the texture; when N; • L=.5, i=2, the transition point or hard boundary in the\ntexture occurs. This is when the transition occurs between the highlight and shadow\ncolor. Finally, when N; • L=l, n=3 and the texture coordinate \\i=\\is reached.\nmesh ->SetTextu reCoord(iVe rt,fTexU,fTexV);\nAlternatives\nThe preceding description details the typical cartoon shading style of two colors, one\nin highlight and one for shadow. Many alternatives can be used to achieve a variety of\neffects. For example, one can create a texture map with any number of colors to sim-\nulate the available color palette. As an extreme case it is even possible to approximate\nGouraud shading by using several colors in the texture, which we call gradient shad-\ning. Also, the texture can be filled with only black and white texels for a black-and-\nwhite shading style. Furthermore, you can adjust C, and Cs using a weighting factor to\nbrighten or darken the texture color for even more effects.\nUsing multitexturing it is possible to increase the flexibility of the algorithm\ndescribed previously. Multitexturing allows us to apply other textures with the base\ncartoon shading texture. For example, one may be creating an anime-style game with\ncartoon shading, but the characters are wearing camouflage pants. With multitextur-\ning, you can set up one texture to be the cartoon shading and the other texture to be\nthe camouflage texture for the character (Figure 5.2.2).\n\n\n448\nSection 5 Graphics Display\nFIGURE 5.2.2 In this figure, the duck model has been shaded with the technique\ndescribed previously and given in Listing 5.2.1.\nProgrammable Vertex Shaders\nModern graphics hardware and graphics APIs are evolving at an amazing pace. With\nthis new power comes performance that can be utilized effectively in implementing a\ncartoon shader. Programmable vertex shading provides two important benefits. One,\nit allows us to replace the lighting equation. In legacy graphics pipelines, the vertex-\nbased lighting equation was hard-wired into the API. This allowed hardware to be\noptimized for the specific lighting equation. Modern graphics architectures are being\ndeveloped that allow programming of the vertex shader. This allows us to replace the\ntraditional lighting equations with any lighting calculation we like. Obviously, there\nare hardware restrictions that will depend on the card for the size of the instruction\ncache, number and type of registers, instruction sets, and so forth. Hopefully, stan-\ndards will exist to provide consistency among hardware vendors. Software implemen-\ntations of vertex shaders are optimized to take advantage of SSE and SSE2\ninstructions on Intel CPUs.\nGiven that we have programmable vertex shaders, how does this help us with car-\ntoon shading? If the hardware exists, we are able to effectively move the runtime tex-\nture coordinate calculation off to the graphics unit. The preprocessing steps are the\nsame as before. We modify the runtime piece to load the registers on the graphics unit\nwith the normal and light information, and perform the dot product calculation on\nthe card. Finally, we load the texture coordinates computed into the appropriate tex-\nture register.\n\n\n5.2 Cartoon Rendering Using Texture Mapping and Programmable Vertex Shaders 449\nProgrammable Vertex Shader Runtime:\n1. Set up texture pipeline to make the texture computed in the preprocess the\nactive texture. Since we are using the programmable vertex shader, we do not\nneed to be concerned about setting up the texture coordinate generation\nmodes—we will do this on the graphics unit.\n2. Load the registers of the programmable vertex shader. What you need to\nload may depend on your specific application and where you are doing\nyour transformations, but normally you need to send the world to eye and\nprojection matrix. You also need to send down the vertex position to be\ntranslated as well as the vertex normal. Also, you need to send down the\nlight position to be used to compute texture coordinates. Since we are com-\nputing new texture coordinates, they do not need to be passed to the card.\nHowever, remember to make sure that the graphics unit expects texture\ncoordinates to be generated for the model. This can be mistakenly over-\nlooked when dealing with models that previously did not have texture\ncoordinates.\n3. Perform the transformation of the vertex position from world to screen\nspace.\n4. For each vertex, compute the dot product between the vertex normal and\nthe light direction vector, Z,- • N. Make sure the normal and light vector are\nin the same coordinate frames or the results will be incorrect. The simplest\nway to do this is to transform the light vector from light space to model\nspace. This can be done on the graphics unit or the CPU before being\nloaded into the constant registers of the vertex shader.\n5. Store the result of step 4 as the texture coordinate for the u texture coordinate.\nListing 5.2.2 DirectX 8.0 cartoon programmable vertex shader\nmm \n'-••••••••••^-\"•\"••••\"-•~—\"-' -.-- \n<••< \n•• \n-\"i\"™:-;;: :;• •*:: —.•:.-.:. \n::•:-'--—•-•-• •l~:~l::l\"\"^-:::i«::•- ;• \n..•...,„.„.., \n:™ \n.,„...,,.,,...,.,,.....,.,.... \n,„..,„. \n•••»••_•_••_ \n••••'••'.:\"--•.\"-. :••:- \n\";•••••••••;— \n;•••;;•; \n-.-.,...,... \n......,,.,...:s\nvs.1.0\nConstants specified by the app-must be loaded using\ndxSDevice->SetVertexShaderConstant(reg,&vector,nVectors)\ncO \n= ( 0, 0, 0, 0 )\nc8-c11 = world-view matrix\nc12-c15 = view matrix\nc20 \n= light direction (in model space)\nVertex components (as specified in the vertex DECL)\nvO \n= Position\nv3 \n= Normal\nInstructions\nm4x4 = 4x4 matrix translation, same as 4 dp3s\nmov \n= moves values from right to left operator\ndp3 \n= dot product\n\n\n450 \nSection 5 Graphics Display\n; Vertex transformation\nj--..-.---.., \n- _ \n__ \n. \n- \n_ _ _ _\n; Transform to view space (world matrix is identity)\nm4x4 r9, vO, p8\n; Transform to projection space\nm4x4 r10, r9, c12\n; Store output position\nmov oPos, r10\ns \n.. \n_ \n- \n- \n- _ - \n- - . _ _ - .\n; Lighting calculation - calculate texture coordinate\nt..-.. \n-_- \n_ \n, \n. - _ _ - . _ - _ \n_ _ _ .\n; light vector dot vertex normal\n; no max? Texturing mode set to CLAMP which clamps for us.\ndp3 oTO.x, c20, v3;\nConclusion\nTwo methods have been presented for cartoon shading, as well as the core techniques\nin the underlying algorithms. These techniques, combined with the \"Inker\" gem, can\nbe used to create cartoon environments for a unique look and feel in your game or\nimmersive experience. A variety of other effects can be achieved using different tex-\nturing techniques, including digital engraving, wood carving, limestone, marble,\nnewsprint, and more. Many can be made to run in real time by using the fundamen-\ntal approaches presented in this gem; namely, texture mapping and programmable\nshaders. With new hardware and APIs empowering us in new ways, computer graphi-\ncists will no doubt have fun in the coming years of PC evolution. If you are interested\nin exploring other rendering methods, see the References. [DietrichOO] discusses tech-\nniques using DirectX, [LakeOO] has a more elaborate list of academic references,\n[Gooch98] discusses a technique for technical illustration, and [Mark97] discusses a\nstatistical approach to inking. Good luck!\nReferences\n[DietrichOO] Dietrich, Sim, \"Cartoon Rendering and Advanced Texture Features of\nthe GeForce256 Texture Matrix, Projective Textures, Cube Maps, Texture Coor-\ndinate Generation and DOTPRODUCT3 Texture Blending,\" available online at\nwww.nvidia.com/Marketing/Developer/DevRel.nsf/WhitePapersFramePOpen-\nPage, 2000.\n[Gooch98] Gooch, Amy, Bruce Gooch, Peter Shirley, and Elizabeth Cohen. \"A Non-\nPhotorealistic Lighting Model for Automatic Technical Illustration.\" In Proceed-\nings ofACMSIGGRAPH98, pp. 447-452, 1998.\n[GoocnOl] Gooch, Bruce, and Amy Gooch. Non-Photorealistic Rendering, A.K.\nPeters, Ltd., 2001.\n[IntelOO] www.intel.com/ial/3dsoftware/doc.htm. Contains presentations, papers,\nand other references to Cartoon Shading, Multi-Resolution Meshes, Subdivision,\nand Character Animation. There is also an application that demonstrates cartoon\nshading, pencil sketching, and other NPR techniques, all running on animated\nmultiresolution meshes.\n",
      "page_number": 424,
      "chapter_number": 43,
      "summary": "This chapter covers segment 43 (pages 424-431). Key topics include texture, lighting, and rendering.",
      "keywords": [
        "Texture",
        "Programmable Vertex Shaders",
        "Vertex",
        "Cartoon Rendering",
        "texture coordinates",
        "Programmable Vertex",
        "Rendering",
        "Texture Mapping",
        "Vertex Shaders",
        "Cartoon",
        "Cartoon Shading",
        "light",
        "texture map",
        "vertex normal",
        "cartoon shading texture"
      ],
      "concepts": [
        "texture",
        "lighting",
        "rendering",
        "render",
        "vector",
        "cartoon",
        "coloring",
        "shading",
        "shade",
        "vertex"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 3",
          "chapter": 42,
          "title": "Segment 42 (pages 401-412)",
          "relevance_score": 0.77,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 3",
          "chapter": 36,
          "title": "Segment 36 (pages 347-355)",
          "relevance_score": 0.73,
          "method": "sentence_transformers"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 23,
          "title": "Segment 23 (pages 441-462)",
          "relevance_score": 0.73,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 1",
          "chapter": 59,
          "title": "Segment 59 (pages 570-580)",
          "relevance_score": 0.7,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 1",
          "chapter": 57,
          "title": "Segment 57 (pages 550-561)",
          "relevance_score": 0.68,
          "method": "sentence_transformers"
        }
      ]
    },
    {
      "number": 44,
      "title": "Segment 44 (pages 432-439)",
      "start_page": 432,
      "end_page": 439,
      "detection_method": "topic_boundary",
      "content": "5.2 Cartoon Rendering Using Texture Mapping and Programmable Vertex Shaders \n451\n[LakeOO] Lake, Adam, Carl Marshall, Mark Harris, Marc Blackstein, \"Stylized Ren-\ndering Techniques for Scalable Real-Time 3D ACM Animation,\" In Symposium\nof Non-Photorealistic Animation and Rendering (NPAR) 2000, pp. 13-20, 2000.\n[Mark97] Markosian, Lee, Michael Kowalski, Samuel Trychi, Lubomir Bourdev,\nDaniel Goldstein, and John Hughes. Real-Time Nonphotorealistic Rendering. In\nProceedings of ACM SIGGRAPH 97, pp. 113-122, 1997.\n\n\n5.3\nDynamic Per-Pixel Lighting\nTechniques\nDan Ginsburg and Dave Gosselin,\nATI Research\nginsburg@alum.wpi.edu and gosselin@ati.com\nA\ncommon method of performing dynamic lighting effects in games is to use\nvertex-based lighting techniques. A significant shortcoming of vertex-based\nlighting is that the geometry must be highly tessellated in order to even approach the\nquality of per-pixel lighting. This article presents several techniques that can be used\nto perform dynamic lighting effects on a per-pixel basis. These methods have the\nadvantage that they don't require highly tessellated geometry, and can often be per-\nformed at little performance cost on multitexturing graphics hardware.\n3D Textures for Dynamic Lightmapping\nThe first method of dynamic lighting we will examine is using a 3D texture for\ndynamic lightmapping. 3D textures can best be explained through their relation to\n2D textures. In traditional 2D texturing, two texture coordinates are present in each\nvertex and are interpolated across the face. Each of the two texture coordinates (s, t)\nrefers to the distance along one of the texture map dimensions (width and height). 3D\ntextures expand upon 2D textures by adding a third texture coordinate (r) that refers\nto the depth of the texture. A 3D texture can be thought of as depth number of slices\nof 2D textures (see Figure 5.3.1). The texture coordinate r is used to select which\nw\nA \nB\nFIGURE 5.3.1 A) 2D texture. B) 3D texture.\n452\n\n\n5.3 Dynamic Per-Pixel Lighting Techniques \n453\nFIGURE 5.3.2 Cross-section of the 3D lightmap. This actual lightmap is monochrome;\nthis picture rises color-coding to clearly show the mapfalloff. Red is highest intensity and\nblue is least. See color version in insert.\nof the 2D maps to access, and then coordinates (s, t) are used as normally in a 2D\ntexture.\nA natural use for 3D textures is in dynamic lightmapping. A typical application\nof dynamic lightmapping in games is having a moving light source that illuminates\nthe geometry in the scene. For example, a rocket fired from the player would dynam-\nically light the static game world geometry. A light of any shape can be created in a\n3D texture. A simple case would be a sphere light with linear falloff from the center.\nIn our example, a sphere light with quadratic falloff (Figure $.3.2) is used.\nThe 3D lightmap was generated with the following code:\nListing 5.3.1 Code to generate 3D lightmap with quadratic falloff\nfor(r = 0; r < MAP_SIZE; r++)\nfor(t = 0; t < MAP_SIZE; t++)\nfor(s = 0; s < MAP_SIZE; s++)\n{\nfloat DistSq = s * s + t * t + r * r ;\nif(DiStSq < RADIUS_SQ)\n{\nfloat FallOff = (RADIUS_SQ - DistSq) /\nRADIUS_SQ;\nFallOff *= FallOff;\nLightMapfr * MAP_SIZE * MAP_SIZE + t *\nMAP_SIZE + S] =\n255.Of * FallOff;\n\n\nSection 5 Graphics Display\nelse\nLightMap[r * MAP_SIZE * MAP_SI2E + t\nMAP_SIZE + s] = 0;\nThe 3D lightmap itself can be specified in OpenGL using the EXT_texture3D\nextension (part of OpenGL 1.2.1). The 3D texture is sent to OpenGL using glTexIm-\nage3D(), which behaves much like giTexImage2D(). The only difference is that the\ndepth of the image is specified, and the texel array contains width X height 'X depth texels.\nThe geometry in our example will be textured with a basemap (b) and will be\nmodulated with a moving light source (/) represented by the 3D lightmap texture.\nThe texture blending we wish to achieve is:\nResult = b * 1\nThe texture environment can be configured to perform this operation through\nOpenGL using ARB_multitexture as follows:\n// 3D texture lightmap on stage 0\nglActiveTextureARB(GL_TEXTUREO ARB) ;\nglTexEnvi(GL_TEXTURE_ENV, GL_TEXTURE_ENV_MODE, GL_REPLACE) ;\n// Basemap to be modulated by 3D texture\nglActiveTextureARB(GL_TEXTURE1_ARB);\nglTexEnvi(GL_TEXTURE_ENV, GL_TEXTURE_ENV_MODE , GL_MODULATE) ;\nGiven the light position (/) and radius (Ir), the texture coordinate at each vertex\n(v) to look up into the 3D lightmap can be calculated as follows:\ns = (v.x - 1.x) / Ir\nt = (v.y - l.y) / Ir\nr = (v.z - l.z) / Ir\nFortunately, this texture coordinate equation can be easily calculated in\nOpenGL using the texture matrix. First, the texture coordinate for each vertex is\nspecified to be the same as its position (s = v.x, t = v.y, r = v.z). Next, each texture\ncoordinate must be put into the space of the light by subtracting the light position.\nThe texture matrix can be used to perform this operation by adding a translation to\nthe texture matrix of minus the light position (— /). The texture coordinate now\nneeds to be divided by the radius of the light. The texture matrix can be used to per-\nform this operation by scaling the texture matrix by the reciprocal of the light radius\n(1/lr) in s, t, and r. The following block of code configures the texture matrix as\ndescribed using a uniform scale.\nglMatrixMode(GL_TEXTURE) ;\nglLoadldentityO ;\n\n\n5.3 Dynamic Per-Pixel Lighting Techniques\n455\nglScalef(1 / lr, 1 / lr, 1 / lr);\nglTranslatef(-1.x, -l.y, -l.z);\nNote that by using a nonuniform radius, the shape of the light could be modified\nto produce shapes other than a sphere without needing to modify the texture. For\nexample, making the scale in x larger than in y and z, the light would be shaped as an\nellipsoid.\nGiven this setup, each polygon is rendered with its basemap modulated by the\n3D lightmap. Figure 5.3.3 shows the effect achieved by this 3D lightmapping\ntechnique. \n' \n\"\nNote that while 3D textures are a natural method for performing dynamic per-\npixel point lights, 3D textures are not the most memory-efficient technique. In Game\nProgramming G^-—\"Attenuation Maps,\" Dietrich presents a method for performing\nper-pixel point lights using only 2D and ID textures.\nFIGURE 5.3.3 Basemap modulated by the 3D lightmap. See color version in insert.\n\n\n456 \nSection 5 Graphics Display\nDot3 Bump Mapping\nThe effect presented in the previous section using a 3D texture as a dynamic lightmap\nwill now be improved by adding per-pixel light perturbations to the surface. Several\navailable graphics cards provide this functionality through Dot3 bump mapping. In\nOpenGL, Dot3 bump mapping is exposed through the EXT_texture_env__dot3\nextension. This extension simply adds a new blend equation to the blend modes sup-\nported by EXT_texture_env_combine (GL_MODULATE, GLJNTERPOLATE,\netc.). The GL_DOT3_RGB equation performs the following computation:\nDest.r = Dest.g = Dest.b =4 * ((AO.r - 0.5) * (A1.r - 0.5) +\n(AO.g - 0.5) * (A1.g - 0.5) +\n(AO.b - 0.5) * (A1.b - 0.5))\nThis blend equation performs a dot product between the (r, g, b) vectors of any\ntwo color sources.\nIn order to allow for color values to represent vector components in the range\n[-1, 1], the color values are made signed by subtracting .5 from each component.\nHowever, by performing this subtraction and multiplying each component, the out-\ngoing color value is not scaled properly. In order to place the result of the dot product\nin the proper scale, it is multiplied by 4.\nUsing this equation, the normal vector (N) at each texel can be encoded into the\n(r, g, b) values of a texture. The light vector (L) in texture space can be encoded into\nthe (r, g, b) values of another source. The resultant dot product performed at blend\ntime yields the equation TV * L at each texel. This is the fundamental calculation that\nis needed for per-pixel bump mapping.\nThe texture map used for bump mapping will contain normals that will perturb\nthe light vector over the surface. In order to generate the bump map, a grayscale image\nrepresenting a heightfield of the original base map is authored. From this heightfield,\nthe bump map can be generated by calculating the change in texel height in each\ndirection.\nThe height differences can be calculated using a Sobel filter. The Sobel filter pro-\nvides two image filters that detect vertical and horizontal change.\ndx = I 0 0 0 I dy r 1 o ii\nI -2 0 2 I\n|_ 1 ° \n1J\nThe normal at each texel is then equal to (-dx, -dy, 1). This vector is normalized\nand placed into the color components at the texel in the bump map. Figure 5.3.4\nshows the bump map generated in the example.\nAt each vertex, the light vector will be stored in the primary color component.\nWith smooth shading on, this vector will be linearly interpolated across the face. The\ninterpolated vector will be used in each per-pixel dot product. This vector must be\n\n\n5.3 Dynamic Per-Pixel Lighting Techniques\n457\nFIGURE 5.3.4 Dot3 bump map texture generated from the beightfield using the Sobel\nfilter. See color version in insert.\ntransformed into the space of the bump map texture on each polygon before it can\nbe used in the dot product. For point lights, the world space light vector at each ver-\ntex is calculated by subtracting each vertex position from the center position of the\n3D light. In our case, anytime the 3D lightmap or the geometry moves, the tangent\nspace light vector must be recalculated. Note that to use Dot3 bump mapping with a\nstatic directional light, the tangent space light vector can be precalculated because the\nper-vertex light vector doesn't change.\nIn order to rotate the light vector into the space of the texture (known as tangent\nspace), a local coordinate system at each vertex is constructed. Three vectors define\nthis coordinate system: the vertex normal (N), a tangent to the surface (T), and the\nbinormal (B). The vertex normal is determined by taking the average of all the nor-\nmals to the faces that contain the vertex. The tangent vector is calculated by deter-\nmining the direction of increasing s or t texture coordinates along the face in the\nobject's coordinate system. The binormal is then calculated by taking the cross\n\n\n458 \nSection 5 Graphics Display\nproduct of the vertex normal and tangent vector. Given this coordinate basis, the light\nvector can be rotated into the space of the bump map using the following rotation\nmatrix:\n[\nT.x T.y T.z (Tl\nB.X B.y B.z 0 I\nN.X N.y N.Z 0 I\n0 0 \n0 \n1 J\nFinally, this tangent space light vector is stored in the primary color component\nof the vertex.\nGiven the Dot3 texture map (dotmap), the tangent space light vector (tl), the\nbasemap (b), and the 3D lightmap (/), we wish to perform the following texture\nblending:\nResult = (dotmap DOT3 tl) * b * 1\nAssuming hardware that has three orthogonal texture units, this can be achieved\nby configuring the texture environment as follows (in practice, this may need to be\ndone on multiple passes on many graphics cards):\n// dotmap DOTS tl on stage 0\nglActiveTextureARB(GL_TEXTUREO_ARB);\ng!TexEnvi(GL_TEXTURE_ENV, GL_TEXTURE ENV_MODE, GL_COMBINE_EXT);\nglTexEnvi(GL_TEXTURE_ENV, GL_COMBINEJ1GB_EXT, GL_DOT3_RGB_EXT) ;\nglTexEnvi(GL_TEXTURE_ENV, GL_SOURCEO_RGB_EXT,\nGL_PRIMARY_COLOR_EXT);\nglTexEnvi(GL_TEXTURE_ENV, GL_OPERANDO_RGB_EXT, GL_SRC_COLOR);\nglTexEnvi(GL_TEXTURE_ENV, GL_SOURCE1_RGB_EXT, GL_TEXTURE);\nglTexEnvi(GL_TEXTURE_ENV, GL_OPERAND1_RGB_EXT, GL_SRC_COLOR);\n// previous * basemap on stage 1\nglActiveTextureARB(GL_TEXTURE1_ARB);\nglTexEnvi(GL_TEXTURE_ENV, GL_TEXTURE_ENV_MODE, GL_COMBINE_EXT);\nglTexEnvi(GL_TEXTURE_ENV, GL_COMBINE_RGB_EXT, GL_MODULATE);\ng!TexEnvi(GL_TEXTURE_ENV, GL_SOURCEO_RGB_EXT, GL_PREVIOUS_EXT);\nglTexEnvi(GL_TEXTURE_ENV, GL_OPERANDO_RGB_EXT, GL_SRC_COLOR);\nglTexEnvi(GL_TEXTURE_ENV, GL_SOURCE1_RGB_EXT, GL_TEXTURE);\nglTexEnvi(GL_TEXTURE_ENV, GL_OPERAND1_RGB_EXT, GL_SRC_COLOR);\n// previous * lightmap on stage 2\nglActiveTextureARB(GL_TEXTURE2_ARB);\nglTexEnvi(GL_TEXTURE_ENV, GL_TEXTURE_ENV_MODE, GL_COMBINE_EXT);\nglTexEnvi(GL_TEXTURE_ENV, GL_COMBINE_RGB_EXT, GL_MODULATE);\ng!TexEnvi(GL_TEXTURE_ENV, GL_SOURCEO_RGB_EXT, GL_PREVIOUS_EXT);\nglTexEnvi(GL_TEXTURE_ENV, GL_OPERANDO_RGB_EXT, GL_SRC_COLOR);\nglTexEnvi(GL_TEXTURE_ENV, GL_SOURCE1_RGB_EXT, GL_TEXTURE);\nglTexEnvi(GL_TEXTURE_ENV, GL_OPERAND1_RGB_EXT, GL_SRC_COLOR);\nFigure 5.3.5 shows the results of this technique.\n",
      "page_number": 432,
      "chapter_number": 44,
      "summary": "This article presents several techniques that can be used\nto perform dynamic lighting effects on a per-pixel basis Key topics include texture, textured, and lighting.",
      "keywords": [
        "Texture",
        "Programmable Vertex Shaders",
        "Carl Marshall",
        "Mark Harris",
        "Marc Blackstein",
        "Stylized Ren",
        "ENV",
        "EXT",
        "texture coordinate",
        "light",
        "bump map texture",
        "RGB",
        "map",
        "texture map",
        "light vector"
      ],
      "concepts": [
        "texture",
        "textured",
        "lighting",
        "vectors",
        "color",
        "dot",
        "dots",
        "mapping",
        "map",
        "maps"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 1",
          "chapter": 54,
          "title": "Segment 54 (pages 523-530)",
          "relevance_score": 0.69,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 3",
          "chapter": 45,
          "title": "Segment 45 (pages 431-439)",
          "relevance_score": 0.65,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 3",
          "chapter": 48,
          "title": "Segment 48 (pages 456-465)",
          "relevance_score": 0.59,
          "method": "sentence_transformers"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 25,
          "title": "Segment 25 (pages 482-502)",
          "relevance_score": 0.55,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 1",
          "chapter": 60,
          "title": "Segment 60 (pages 581-588)",
          "relevance_score": 0.54,
          "method": "sentence_transformers"
        }
      ]
    },
    {
      "number": 45,
      "title": "Segment 45 (pages 440-449)",
      "start_page": 440,
      "end_page": 449,
      "detection_method": "topic_boundary",
      "content": "5.3 Dynamic Per-Pixel Lighting Techniques\n459\nFIGURE 5.3.5 Base map modulated by 3D lightmap with Dot3 bump mapping.\nSee color version in insert.\nCubemap Normalizer\nWe now have a bump-mapped object dynamically lit on a per-pixel basis. However,\nthere is one major shortcoming with the method presented. The tangent space light\nvector calculated at each vertex used in the Dot3 blend stage was stored in the pri-\nmary color component. By storing the light vector in the color component with\nsmooth shading enabled, the vector is linearly interpolated across the face. Unfortu-\nnately, the linearly interpolated vector will often fail to maintain its length of 1 across\nthe face. Figure 5.3.6 shows an example of two linearly interpolated 2D vectors. VI\nand V2 both have a length of 1, but when linearly interpolated, the resultant vector\nhas a length less than 1. This failure to maintain normalization results in decreased\nvisual quality, particularly when the geometry is not highly tessellated.\nIn order to correct this problem, a cubic environment map will be used to keep\nthe light vector normalized. The contents of the cube map at each texel will be the\nsame as the normalized texture coordinate used to look up into it. Instead of storing\nthe tangent space light vector in the primary color component, it will be stored as a\ntexture coordinate that will be used to look up into the cubemap. Since each texel in\n\n\n460 \nSection 5 Graphics Display\nFIGURE 5.3.6 The linear interpolation of two normalized vectors resulting in a vector\nwhose length is less than 1.\nthe map contains the normalized vector of the texture coordinate, the light vector will\nstay normalized when interpolated across the face.\nThe Dot3 operation using the cubemap can be done using two texture units by\nconfiguring the texture environment as follows:\n// Cubmap normalizer on stage 0, just pass it through\nglActiveTextureARB(GL_TEXTUREO_ARB);\ng!TexEnvi(GL_TEXTURE_ENV, GL_TEXTURE_ENV_MODE,\nGL_COMBINE_EXT);\nglTexEnvi(GL_TEXTURE_ENV, GL_COMBINE_RGB_EXT, GL_REPLACE);\nglTexEnvi(GL_TEXTURE_ENV, GL~SOURCEO_RGB_EXT, GL_TEXTURE);\nglTexEnvi(GL_TEXTURE_ENV, GL_OPERANDO_RGB_EXT, GL_SRC_COLOR);\n// dotmap DOT3 cubemap on stage 1\nglActiveTextureARB(GL_TEXTURE1_ARB);\nglTexEnvi(GL_TEXTURE_ENV, GL_TEXTURE_ENV_MODE,\nGL_COMBINE_EXT);\nglTexEnvi(GL_TEXTURE_ENV, GL_COMBINE_RGB_EXT,\nGL_DOT3_RGB_EXT);\nglTexEnvi(GL_TEXTURE_ENV, GL_SOURCEO_RGB_EXT,\nGL_PREVIOUS_EXT);\nglTexEnvi(GL_TEXTURE_ENV, GL_OPERANDO_RGB_EXT, GL_SRC_COLOR);\nglTexEnvi(GL_TEXTURE_ENV, GL_SOURCE1_RGB_EXT, GL_TEXTURE);\nglTexEnvi(GL_TEXTURE_ENV, GL_OPERAND1_RGB_EXT, GL_SRC_COLOR) ;\nFigure 5.3.7 shows the improved results by using the cubemap normalizer.\nPer-Pixel Spotlights\nIn addition to per-pixel point lights as we have implemented using a 3D lightmap,\nanother useful dynamic lighting technique is per-pixel spotlights. Instead of using a\n3D lightmap, we will use 2D texture to represent the light and project it onto each\nface. The contents of the 2D texture will be a cross-section of the spotlight cone con-\ntaining the attenuation falloff from the center. As with point lights, a tangent space\nlight vector from the spotlight will be placed in the color component of the vertex. A\nfalloff factor based on the distance from the tip of the cone to the vertex is placed in\nthe alpha channel. The tangent space light vector will be Dot3'd with the vectors in\n\n\n5.3 Dynamic Per-Pixel Lighting Techniques\n461\nFIGURE 5.3.7 Base map modulated by 3D lightmap with Dot3 bump mapping and\ncubemap normalizes See color version in insert.\nthe normal map. The interpolated alpha in the vertex color is modulated with the\ncolor to perform the distance attenuation.\nThe result of this Dot3 calculation now need to be modulated by the projected\nspotlight texture. The spotlight can be projected onto the face by configuring the tex-\nture matrix to perform the projection. The texture matrix is first set to represent the\nview from the spotlight by calculating the \"look-at\" matrix based on its position,\ndirection, and any vector perpendicular to the direction. The \"look-at\" texture matrk\nmust finally be multiplied by a matrix that represents the frustum created by the spot-\nlight. The texture coordinates for the spotlight texture will then simply be the world\ncoordinates of the vertex. The result of this texture look-up is modulated with the\nDOT3 calculation to get the final lighting.\nReferences\n[Blythe98] Blythe, David, \"Advanced Graphics Programming Techniques Using\nOpenGL\" available online at www.sgi.com/software/opengl/advanced98/notes/\nnotes.html\n\n\n462 \nSection 5 Graphics Display\n[DeLouraOO] DeLoura, Mark, Game Programming Gems, Charles River Media, 2000.\nDietrich, Sim, \"Attenuation Maps,\" pp. 543-548.\nDietrich, Sim, \"Hardware Bump Mapping,\" pp. 555-561.\n[Mitchell] Mitchell, Jason, \"Radeon Bump Mapping Tutorial,\" available online at\nwww.ati.com/na/pages/resource_centre/dev_rel/sdk/RadeonSDK/Html/Tutori-\nals/RadeonBumpMap.html\nARB_multitexture, EXT_texture_env_combine, and EXT_texture_env_dot3 spec\navailable online at http://oss.sgi.com/projects/ogl-sample/registry/\n\n\n5.4\nGenerating Procedural Clouds\nUsing 3D Hardware\nKim Pallister, Intel\nkim.pallister@intel.com\nA\ngreat number of the games we play take place in outdoor environments, and\nmost of those take place in environments that attempt to look much like the\nworld around us. Because of this, the realistic rendering of terrain has become some-\nthing of a holy grail for many game developers. Unfortunately, the modeling of the\nsky, and the clouds therein, does not get nearly as much attention, and is often added\nas an afterthought. Clouds usually end up being modeled with one or more layers of\nstatic scrolling textures. At first glance, these look OK, but they quickly give away\ntheir repetitive nature when looked at for an extended period.\nIn this gem, we'll set out to procedurally generate cloud textures that possess\nsome of the properties that real clouds exhibit. In addition, because textures typically\nreside in graphics subsystem memory, we'll aim to generate the procedural clouds\nalmost entirely using the graphics hardware. Finally, we'll address some ways to scale\nthe technique's quality and performance requirements in order to accommodate a\nrange of target machines.\nProperties of Clouds\nBy taking note of the characteristics of real clouds, it's possible to come up with a pri-\noritized feature list for the simulation. As with all real-time techniques, we may need\nto forsake some of these features in the interest of speed, but we'll worry about that\nlater.\nHere are a few things that we notice at first glance:\n• Clouds are animated. They both move across the sky as the wind pushes them\nalong, and change shape or \"evolve\" with time (as can be seen in any time-lapse\nfootage of clouds). Additionally, the amount of cloud in the sky changes with\ntime. This gives us a hint that there are three variables we'll need: the simulation\nrate, the wind speed, and something describing how overcast it is.\n• As the clouds change shape over time, small details change frequently, while\nlarger details take longer to change.\n• Clouds exhibit a great deal of self-similarity in their structure.\n463\n\n\n464 \nSection 5 Graphics Display\n• The level of cloud cover can also vary from a completely overcast sky to a clear\nblue sky with only a few isolated clouds (or none at all). As the level of cloud\ncover changes, so does the appearance of the clouds. In overcast conditions,\nclouds become gray and dark; in clear skies, clouds tend to be bright white\nagainst the blue backdrop of the clear sky.\n• Clouds are three-dimensional entities. They are lit by the sun on one side and fall\nin shadow on the other. On a smaller scale, its much more complex than that,\nwith clouds self shadowing and scattering light in all directions.\n• Clouds are lit much differently at sunrise and sunset, as the light of the sun tends\nto illuminate them from an orthogonal angle, or even from underneath.\n• Clouds tend to float at a common altitude, forming a cloud layer. Sometimes\nthere are multiple layers. Since each of these layers is a constant altitude above the\nearths curved surface, we'll likely use some kind of curved geometry for the layers\nof clouds.\n. . . and this is just some of what we see from the ground. In an application such as a\nflight simulator, where we could fly up and into the clouds, a whole new set of diffi-\nculties comes up. For this gem, we'll stick to the view from the ground.\nRandom Number Generation\nAs with almost any procedural texture, a good place to start is with the generation of\nsome noise. Noise is a term used to describe a primitive that is random in nature. The\nnoise primitive is a function that for a given input series (e.g., 1, 2, 3...), produces a\nseemingly random series of results (e.g., 0.52,—0.13,—0.38...). I say seemingly random\nbecause it must always produce the same result for a given input. This makes it\npseudo-random, allowing us to recreate the same result for a given input seed value.\nAdditionally, noise is often referred to as having a certain dimensionality (e.g., 2D\nnoise, 3D noise, etc). This just refers to the number of inputs that are used to map\ninto the random number function, much as one does a lookup into a multidimen-\nsional array. One of the dimensions is scaled by some factor (usually a prime number)\nlarge enough to keep repetitive patterns of results from showing up in an obvious\nfashion.\nThe generation of random numbers (or pseudo-random numbers) is a subject of\nmuch study. All approaches contain trade-offs between the complexity of the function\nand the quality of the result. A random number generator of high quality generates a\ngood distribution of the random values, and does not repeat for a very long time.\nLuckily, for the purposes of this gem, the results of a very simple random number\ngenerator will suffice. When we cover the specifics of the technique later, we'll be call-\ning the random number generator multiple times per pixel with different input \"seed\"\nvalues. The cumulative result of this will mask any obvious repetition that occurs.\nThe pseudo-random number generator (PRNG) we'll start with is shown in List-\ning 5.4.1. It works by using the input parameter x as the variable in a polynomial,\n\n\n5.4 \nGenerating Procedural Clouds Using 3D Hardware \n465\nwhere each term of the polynomial is multiplied by large prime number. By scaling\neach term of the polynomial differently, we get a long series before it repeats. The sign\nbit is then masked off, and the number is divided down to the 0—2 range, and is sub-\ntracted from 1, to give us a range of—1 to 1.\nListing 5.4.1 A simple pseudo-random number generator\nfloat PRNG( int x)\n{\nx = (x«13)*x;\nint Primel = 15731;\nint Prime2 = 789221;\nint Primes = 1376312589;\nreturn (1.0f - ((x * (x*x*Prime1 + Prime2) + Primes)\n& 7fffffff ) / 1073741824.0)\n}\nIn cases where multiple octaves are being used, you can increase the \"random-\nness\" of the PRNG by constructing an array of prime numbers and using different\nones for Primel and Primel, depending on the octave. For the purposes of this gem,\nusing the single set of primes in Listing 5.4.1 is sufficient\nSince we want to implement this in graphics hardware, and graphics hardware\ndoesn't allow us to do all of the code shown in Listing 5.4.1, we'll create a lookup table\nof the function in a 512x512 texture map. Using a 512x512 texture map gives us\n-260 thousand entries before the function repeats. We'll use this texture as a random\nnumber generator by copying part of this texture into a target texture, using a software-\ngenerated random number to offset the texture coordinates. This is illustrated in Fig-\nure 5.4.1. The copying is done using the graphics hardware to render our random\nnumber series texture to a quad in the target texture.\nStartlndex(x,y)\nFIGURE 5.4.1 A) The random number lookup table texture. B) The generated 32x32\nnoise texture.\n\n\n466 \nSection 5 Graphics Display\nBand-Limited Noise\nKen Perlin pioneered the technique of using band-limited noise as a rendering primi-\ntive. Band-limited means that the noise is limited to a certain frequency range, which\ncan be thought of as its maximum rate of change between samples. For our purposes,\nthis means that we want to be able to produce a series of random values spaced out\naccording to the frequency range, with intermediate points interpolating between\nthese random samples. We do this simply by indexing into our random number\nlookup table and upsampling by the desired amount, using the graphics hardware's\nbilinear filtering to do the interpolation for us. Getting rid of the high frequency\ncomponents will make for a procedural primitive with smoother, more natural-looking\ntransitions. This is illustrated in Figure 5.4.2.\n(a) \n(b)\nFIGURE 5.4.2 A) Sampling the random number lookup table texture to create an array of\nnoise. B, C) Using upsampling and filtering to create band-limited noise at the target\nresolution (the target frequency range).\nIt's worth noting here than in some cases when using noise to create procedural\ncontent, bilinear interpolation is insufficient, and a higher order filtering is needed to\nproduce adequate results. Luckily, this is one case where the lower quality bilinear fil-\ntering produces sufficient results.\nAn array of noise created in this fashion gives us a single noise primitive of a given\nfrequency. We'll refer to this as an octave of noise, since we will later combine multi-\nple octaves (multiples of the same frequency) together. First, though, we need to be\nable to animate our array of noise.\nAnimating an Octave of Noise\nfs?r: ::•:•;;;;:\":•\"\"::•:.-v::1:\":1::1;-.'\"'\":'\"'::;.:::::1::1\"\":':.:\" r.r\":\\'™™'.r:~\"~r:r\"'::-'\"~r.r:..—•;:.l™r\":;:;:l:r::1^-\"': .::™.r. ~:^~\"~:; ..::.•\". \".'.'>*../.::\"' r^~.:'.~:~:\"~ ~\" :'\"~:r:\":\"'r -\"•.•-—--..: ,™:v: :™:-\"-.\"\"'::'-'-$\nIf we want to animate an octave of noise, we can look at time as a third dimension\nthat we can use to index into our random number generator. The way we'll imple-\nment this using the graphics hardware is to periodically save off our noise texture,\ncreate a new one, and then interpolate between the two from one update to the\nnext. The rate at which we update the texture determines the frequency in this third\ndimension.\nThe interpolation is illustrated in Figure 5.4.3. This is one case where using lin-\near interpolation results in some artifacts, as the noise becomes more \"focused\" at the\n\n\n5.4 Generating Procedural Clouds Using 3D Hardware \n467\nJ\nFIGURE 5.4.3. Interpolating between noise updates to animate an octave of noise. Result =\nPreviousUpdate * (1-(T1-TO)/(T2-TO)) + NewUpdate * (Tl-TO)/(T2-TO). TO is the previous\nupdate time, T2 is the new update time, and Tl is the current time between updates.\nactual sample points. Again, this artifact is not apparent after the noise is incorporated\ninto the final effect, as we'll see. Still, it's worth keeping in mind. If we were willing to\nsacrifice enough fill rate, we could maintain octaves for multiple points in time and\nuse a higher order interpolation scheme to achieve a better result.\nSumming Octaves into Turbulent Noise\nA commonly used technique in procedural texture generation is to use a fractal sum,\nwhich is a summation of scaled harmonics of the basic noise function. This is referred\nto as fractional Brownian motion, or fBm, and is used in all types of procedural ren-\ndering techniques, such as fractal terrain, many types of procedural textures, and so\nforth. The fractal sum is shown in Equation 5.4.1. In it, a determines how we step\nacross the frequency spectrum (a is most commonly 2, giving us f, 2f, 4f, ...), and b\ndetermines the amplitude of the contribution of each component in the series.\nJV-1\nFortunately, a value of 2 for a is both commonly used in the generation of proce-\ndural textures, and is well suited to our hardware implementation, as we can simply\nimplement the octaves of noise as a series of texture maps whose sizes are a series of\npowers of 2.\nUsing a value of 2 for b is also both commonly used and makes our implementa-\ntion easier. The composition of the octaves of noise can be done by performing mul-\ntiple render passes using a simple blend, as shown in the pseudocode in Listing 5.4.2.\nListing 5.4.2 Noise octave composition\n//note that ScaleFactor is needed to keep results in the\n// 0-1 range, it changes {1 + 1/2 + 1/4 + ...} to {1/2 + 1/4 + ...}\n\n\n468\nSection 5 Graphics Display\nfloat ScaleFactor =0.5\nfloat FractalSum = 0.0\nfor i = 1 to NumOctaves\n{\nFractalSum = FractalSum*0.5 + ScaleFactor *\nNoiseOctave(NumOctaves-i)\nFigure 5.4.4 illustrates the process of animating the different octaves between\nupdates, and building the composited turbulent noise texture.\nPrevious Updates\nAnimated Octaves\nCurrent Updates\nOctave 0\nOctave 1\nOctave 2\nOctave 3\n1/2 Octave 0 + 1/4 Octave 1 +\n1/8 Octave 2 + 1/16 Octave 4 =\nFIGURE 5.4.4 Composition of several octaves of animated noise.\n",
      "page_number": 440,
      "chapter_number": 45,
      "summary": "Instead of using a\n3D lightmap, we will use 2D texture to represent the light and project it onto each\nface Key topics include texture, clouds, and noise.",
      "keywords": [
        "texture",
        "noise",
        "Clouds",
        "Random Number",
        "ENV",
        "EXT",
        "noise texture",
        "number",
        "Random",
        "light vector",
        "octave",
        "random number generator",
        "graphics hardware",
        "Generating Procedural Clouds",
        "Graphics"
      ],
      "concepts": [
        "texture",
        "clouds",
        "noise",
        "map",
        "mapping",
        "maps",
        "resultant",
        "resulting",
        "interpolated",
        "interpolation"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 3",
          "chapter": 45,
          "title": "Segment 45 (pages 431-439)",
          "relevance_score": 0.64,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 1",
          "chapter": 60,
          "title": "Segment 60 (pages 581-588)",
          "relevance_score": 0.62,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 3",
          "chapter": 48,
          "title": "Segment 48 (pages 456-465)",
          "relevance_score": 0.61,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 1",
          "chapter": 54,
          "title": "Segment 54 (pages 523-530)",
          "relevance_score": 0.59,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 1",
          "chapter": 57,
          "title": "Segment 57 (pages 550-561)",
          "relevance_score": 0.55,
          "method": "sentence_transformers"
        }
      ]
    },
    {
      "number": 46,
      "title": "Segment 46 (pages 450-457)",
      "start_page": 450,
      "end_page": 457,
      "detection_method": "topic_boundary",
      "content": "5.4 Generating Procedural Clouds Using 3D Hardware \n469\nMaking Clouds from \"Vapor\"\nNow that we have a texture map of animated, turbulent-looking noise, we need to do\na few steps to turn it into clouds. Ideally, we'd like to use the noise as input to some\nsort of exponential function, giving us a sharp \"condensation level\" above which\nclouds would be visible, below which they would not. However, since this is an oper-\nation not available to us in a graphics chip, we'll have to use another method. There\nare several ways to tackle this.\nThe simplest way is to do a subtraction. Subtracting a fixed value from the texture\nclamps the texture at 0 where the noise was below that fixed value, isolating some\nclouds. This is illustrated in Figure 5-4.5.\nFIGURE 5.4.5 Subtracting a fixed value to get isolated clouds.\nUnfortunately, we lose some of the dynamic range in the remaining clouds. We\ncan compensate for this, however, by oversaturating and modulating with vertex col-\nors and varying this. This is the method we use in the accompanying sample code.\nAnother way would be to have all the layers of texture that we have talked about so\nfar have an alpha channel. This would let you do the subtraction and the clamping as\nin the previous test, but only on the alpha, and then do an alpha test to mask off the\nregion without clouds without losing any dynamic range in die clouds themselves. A\ndifferent problem occurs here, however. Since the alpha test is done before any filter-\ning, rough jagged edges occur unless we use a really high-resolution destination texture.\nAnother way that may be better still would be to use some sort of dependent tex-\nture lookup, where one texture's color value affects the location from which a texel is\nfetched in a subsequent stage. One example of a texture- dependent lookup is the\nBumpEnvMap render state supported by some hardware under DirectX. In the\nfuture, as more hardware supports this type of operation, it may become feasible to\nencode an exponential function in a texture map and simply look up the result.\nMapping It to the Sky Geometry\nHaving prepared the cloud texture in Figure 5.4.5, we can map it to the sky geometry.\nYour choice of geometry depends on your application. The sample application uses\nsomething we've called a \"skyplane,\" which is simply a rectangular grid of triangles,\nwith the vertices pulled down over die radius of a sphere. You can imagine this as\ndropping a piece of cloth over the surface of a beach ball. It's not perfect, but makes\nmapping the texture easy. The skyplane is illustrated in Figure 5.4.6.\n\n\n470\nSection 5 Graphics Display\nFIGURE 5.4.6 Terrain geometry and the skyplane used for the cloud texture.\nFeature Creep\nAt this point, we can do many things to the clouds, depending on how much applica-\ntion time and graphics hardware fill-rate we want to consume. Some of these are\nimplemented in the sample code; others are listed to provide you with ideas for your\nown implementation. Some of the things that can be added include:\n• Noise-driven wind direction, cloud cover. Some dramatic results can be achieved\nby using other noise functions to modify some of our other variables over time, so\nthat, for example, the wind can change direction and the level of cloud can\nincrease or decrease over hours or days.\n• Embossing the clouds to give them a 3D appearance. This will require an extra\npass, and will require some modification of the vertex UV values. The vertices are\ngiven a second set of texture coordinates and are offset/scaled according to the\ndirection of the sun. The clouds are darkened on the side away from the sun, and\nbrightened on the side toward the sun.\n• The clouds can cast shadows on the ground simply by using the end result texture\nwith a subtractive blend. Your terrain will need to have another set of texture\ncoordinates, or will have to use texture projection in order to do this.\n• Modify lighting and/or lens flare intensity. Since we know how the texture is\nmapped to the geometry, and we know the angle of our sun, we can calculate the\n\n\n5.4 \nGenerating Procedural Clouds Using 3D Hardware \n471\nexact texel or group of texels corresponding to where the sun is in our line of\nsight. We can use this to vary the level of lighting on our terrain, or to fade out a\nlens flare temporarily. Note that when modifying lighting, increased cloud cover\nshould decrease the intensity of the directional light of your \"sun\" in the scene,\nbut should increase the ambient level, since in reality the clouds will scatter the\nsunlight in all directions.\nHardware Limitations\nAllowing the graphics hardware to do much of the grunt work in this technique\nallows us to achieve better performance than we'd be able to achieve if we had to man-\nually lock and modify the texture at every frame. Unfortunately, it comes with some\ndrawbacks as well. The drawbacks fall in four areas:\n• Render-to-texture support. The technique spelled out in this gem uses this\ncapability extensively. However, support for rendering to texture surfaces is far\nfrom ubiquitous. Detecting support for the capability has become easier with\nmore recent API releases, but can still be tricky. In cases where rendering to tex-\nture surfaces is not supported, a workaround of copying from frame buffer to tex-\nture can be used, but performance may suffer.\n• Limited precision. Current hardware stores texture and render target values as\nintegers, usually in 32 or 16 bits per pixel. Because we are essentially working in\n\"monochrome,\" generating a texture in shades of gray, we are limited to 8 bits per\npixel, and in the worst case, 4! The latter gives noticeable artifacts. Note that this\nmeans that the high-frequency octaves are only contributing a few bits of color\ndata to the final result due to this problem.\n• Limited dynamic range. Because the integer values represent data in the 0-1\nrange, we are forced to scale and offset values to fit in this range. Since our noise\nfunction originally returned values in the -1 to 1 range, we had to compress these\nto fit them into our available range. This requires extra work, and also amplifies\nthe artifacts from the limited precision\n• Limited hardware instruction set and capabilities. The limited instruction set\nof the graphics hardware limits us in terms of what we are able to do. It would\nhave been nice to feed the turbulent noise texture into a power function, perhaps\nas the exponent, to generate some interesting results, but we are instead limited to\nsimple arithmetic operations. As well, we make much use of render-to-texture,\nwhich isn't available on all hardware. In the future, as hardware capabilities\nincrease, this will be less of an issue.\nMaking It Scale\nIf we want to use this technique in a commercial game project, and are targeting a\nplatform such as the PC, where performance can vary from one machine to the next,\nthen we need to worry about scalability of the technique. Even if targeting a fixed\n\n\n472\nSection 5 Graphics Display\nplatform, the game may have a varying load, and we may want to scale back the qual-\nity and performance requirements of the technique in heavy load situations.\nThere are several ways in which the technique can be scaled:\n• Texture resolution. The resolution of the textures used at the various intermedi-\nary stages could be reduced, saving memory and fill-rate consumption. Note that\nscaling color depth is most likely not an option here, since the artifacts show up\npretty quickly when using 16bpp textures.\n• Texture update rate. Not every texture need be updated per frame. Particularly if\nthe simulation rate is slow, the interpolating textures do not need to be updated\nat every frame as we did in the sample code.\n• Number of octaves used. The sample code uses four octaves of noise, but using\nthree might provide an acceptable result. Similarly, five octaves might give slightly\nbetter quality on systems that have the horsepower.\nConclusion\nmm \n; \n:-: \n:r\"::-;:::::; \nr: \n;\"\":;• \n--7:::. \n—-'-•::\" ~\" \n:;-:;;: •—-•••:::•—-•\"••--:•-••:;•::,: -™:r:~:::: ::•: -•-'•r:;-::^--\":-vi::::'::\"::\"r\"-:;-.v;;:::-1\"-»\nFigure 5.4.7 displays the final result of the procedural cloud example program.\n*a^p^ta»%s«\n\"*\"\"'\"*\"\nFIGURE 5.4.7 Final result of procedural cloud example program.\n\n\n5.4 Generating Procedural Clouds Using 3D Hardware \n473\nWe hope this technique has provided you with some insight into procedural\ntexture generation, using clouds as an example, and how to get graphics hardware\nto do much of the per-pixel work needed in generating dynamic procedural textures.\nAs hardware grows more capable, so will the techniques in which we can generate\nthese textures in real time. We encourage you to try your own experiments and share\nthem with the development community.\nReferences\n[Ebert et al, 98] Ebert, David S., et al, Texturing and Modeling: A Procedural Approach,\nAP Professional Inc., 1999. ISBN: 0-12-228730-4.\n[Elias99] Elias, Hugo, \"Cloud Cover,\" available online at http://freespace.virgin.net/\nhugo.elias/models/m_clouds.htm, offers a software-only technique similar to this\none.\n[Pallister99] Pallister, Kim, \"Rendering to Texture Surfaces Using DirectX 7\", avail-\nable online at www.gamasutra.com/features/19991112/pallister_01.htm\n\n\n5.5\nTexture Masking for Faster\nLens Flare\nChris Maughan, NVIDIA Corporation\ncmaughan@nvidia.com\nT\nhis gem introduces a novel way in which to generate texture information from\npixels already rendered to the frame buffer. The technique can be used in several\ndifferent ways, but is presented here as a solution to the common problem of\noccluded lens flare. Many games attempt to read back pixels generated in the frame\nbuffer in order to determine exactly what was visible in the final scene. I will present\na technique that works without CPU assistance, and does not require reading\ndata from the graphics card. I will also outline the reasons why reading back infor-\nmation from the graphics card can be a costly operation and should be avoided if\npossible.\nLens Flare Occlusion\nMany modern games add lens flare to the scene to increase realism. The lens flare is\nusually applied as the last item in the scene, using a 2D texture map rendered as a bill-\nboard over the frame. A complication with this technique is that objects in the scene\ncan occlude the sun image, and in this case, the correct visual result is a lessening of\nthe lens flare intensity. A good way to visualize this is to imagine yourself driving\nalong a road lined with trees on a sunny day; if the sun is below the tree line, you will\nexperience a flickering as your viewpoint through the trees changes and the amount of\nlight reaching your eyes varies.\nThe usual approach to detecting the occlusion of the sun is to first render the\nobjects in the scene, including the sun itself. Then we read back the frame buffer\ndata around where the sun pixels would be and deduce the amount of sun visible in\nthe scene. We can do this in two ways: we can read back the color buffer and look\nfor values that match our sun color, or we can read back the Z-buffer and look for Z\nvalues that are as far away as the sun. The ratio of visible to occluded sun pixels\ngives us a handy approximation of the intensity of the lens flare. We are now ready to\ndraw our lens flare by blending it onto the final scene using an alpha value to set its\nintensity.\n474\n\n\n5.5 Texture Masking for Faster Lens Flare \n475\nHardware Issues\nThe preceding approach is generally taken when rendering lens flare in games. While\nit can work well, it causes unnecessary stalls in the graphics pipeline that can seriously\nimpair performance.\nModern graphics pipelines are very deep. Polygon data is not only queued inside\nthe graphic chip pipeline, but it is also queued in a large \"staging\" buffer. Typically,\nmany thousands of polygons will be queued in the staging buffer by the game, and the\ngraphics chip will drain the buffer as it draws polygons into the frame buffer. In a\ngood parallel system, the game can be doing useful work on the CPU, such as physics,\nAI, and so forth, while the graphics chip (GPU) is draining the staging buffers.\nIndeed, this is to be encouraged if the maximum performance of the system is to be\nachieved. Figure 5.5.1 illustrates a system with optimal parallelism.\nM \n- \nCPU \nPreparing \nScene \n3\nSubmit Scene 2\nDo Network\nDoAl\nDo Physics\nCPU Activity \nSubmit Scene 2 \nDo Network \nDoAl \nDo Physics \nI \nSubmit Scene 3\nDraw Scene 1 \nPage Flip\nDraw Scene 2\n^_ \nGPUDrawing \n__M \nGPUDrawing Scene 2 \n-\nocsne l\nFIGURE 5.5.1 Parallelism of the GPU I CPU in an ideal game engine.\nNow consider the situation that occurs when the game has submitted all the\npolygons for the current scene to the graphics chip. Much of the scene may still be\nqueued in staging buffers and will not be drawn for some time. The next thing our\ngame wants to do is to read back the contents of the scene to determine the sun vis-\nibility for the lens flare calculation. Here lies the first part of our problem. In order\nto read the completed scene from the frame buffer, we must wait for the rendering to\ncomplete, and in order for this to happen, the whole pipeline must be flushed. While\nwaiting for this to occur, the CPU is effectively unused, as it is simply idle inside the\ngraphics card driver waiting for the rendering to complete. Ideally, we want the GPU\nand the CPU to be concurrently active at all times. One potential solution to this\nproblem is to insert our physics/AI code after the scene render, but before the lens\nflare calculation. In this way, the CPU will be busy while the GPU is rendering the\npolygons.\nIn this case, if our CPU work is more than the GPU work, then we do not have a\nproblem—although arguably the system is unbalanced because the GPU is waiting\nfor the CPU to finish its work, when it could be doing more rendering (Figure 5.5.2).\n\n\n476\nSection 5 Graphics Display\nCPU Submitting\nScene 2\nCPU Activity\nSubmit Scene 2\n-H-\nCPU Waiting forGPUto Finish Scene 2\nLock / Read Frame Buffer\nSubmit Flare\nGPU Activity\nDraw Scene 1\n^ \nGPUDrs\nScene 1\nPage Flip\nDraw Scene 2\nDraw Flare\nFIGURE 5.5.2 Pipeline stall caused by flush at end of rendering.\nIf our CPU work is less than the GPU work, we will again stall when we try to\nread back the lens flare data. This is undesirable because ideally we would like to be\npreparing the next frame of the game on the CPU while the last one completes on the\nGPU (Figure 5.5.3). Parallelism is the key here, and inserting any stalls can hurt it\nconsiderably.\nThe story does not, however, end here. After losing our concurrency, there is\nanother problem. Reading back data from a current generation graphics card is a slow\noperation, and in some cases cannot be done at all.\nWhile most graphics cards run at AGP 2x/4x speeds when written to, reading\nback from them is still limited to PCI speeds—this is inherent in the nature of the\nAGP bus design as it stands today. The result is that for a 32-bit frame buffer, we can\nonly read pixels at a maximum rate of 66Mhz, with no caching or bursting behavior.\nTherefore, reading an area of 256 * 256 from the graphics card will take\n1 / (66,000,000 / (256 x 256)) = -1 millisecond.\nThis assumes a 256-square pixel area of the sun projected onto the screen. If we\nare standing nearer to the light source—for example, a street-lamp—then the pro-\njected area can vary quite considerably until the read back becomes very significant.\nEven if we are willing to take this hit in performance, there is no guarantee that the\nCPU Submitting\nScene 2\nCPU Preparing\nScene 3\nCPU Activity\nGPUActivity\n(CPU Load\nheavier than I\nLoad)\nSubmit Scene 2\nNetwork/ Physics /Al\nLock/Read\nFrame\nBuffer\nDraw Scene 1\nPage Flip\nDraw Scene 2\nGPU Idle \n|\nGPUDrawing\nScene 1\nGPUDrawing\nScene 2\nGPUWaiting for CPU to finish\nFIGURE 5.5.3 Pipeline stall caused by flush before end of frame, after CPU work.\nSubmit Flare\nDraw Flare\n",
      "page_number": 450,
      "chapter_number": 46,
      "summary": "This chapter covers segment 46 (pages 450-457). Key topics include texture, scene, and clouds. Ideally, we'd like to use the noise as input to some\nsort of exponential function, giving us a sharp \"condensation level\" above which\nclouds would be visible, below which they would not.",
      "keywords": [
        "scene",
        "lens flare",
        "texture",
        "CPU",
        "Clouds",
        "flare",
        "graphics",
        "Generating Procedural Clouds",
        "Draw Scene",
        "Submit Scene",
        "Hardware",
        "frame buffer",
        "CPU Preparing Scene",
        "sun",
        "lens"
      ],
      "concepts": [
        "texture",
        "scene",
        "clouds",
        "hardware",
        "value",
        "cpu",
        "result",
        "game",
        "work",
        "limitations"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 8",
          "chapter": 4,
          "title": "Segment 4 (pages 31-40)",
          "relevance_score": 0.54,
          "method": "sentence_transformers"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 25,
          "title": "Segment 25 (pages 482-502)",
          "relevance_score": 0.53,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 7",
          "chapter": 47,
          "title": "Segment 47 (pages 453-467)",
          "relevance_score": 0.5,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 3",
          "chapter": 45,
          "title": "Segment 45 (pages 431-439)",
          "relevance_score": 0.49,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 3",
          "chapter": 46,
          "title": "Segment 46 (pages 440-447)",
          "relevance_score": 0.49,
          "method": "sentence_transformers"
        }
      ]
    },
    {
      "number": 47,
      "title": "Segment 47 (pages 458-468)",
      "start_page": 458,
      "end_page": 468,
      "detection_method": "topic_boundary",
      "content": "5.5 Texture Masking for Faster Lens Flare \n477\ngraphics card will allow us to read back the data at all; in fact, many do not. Most will\nnot allow reading of the Z-Buffer, many do not allow reading of the frame buffer, and\nnone will allow reading of an antialiased buffer.\nTexture Masking\nHow can we alleviate the stalls caused by reading the frame buffer? We arrive at the\nsolution through a bit of lateral thinking. We know that we cannot pass a value down\nfrom the CPU to modulate the lens flare brightness, for the reasons outlined previ-\nously. This leaves only one possibility: that we modulate the lens flare value with data\nalready generated in the graphics memory on the card. Such a value must be in the\nform of a texel in a texture map, and this texel needs to contain either a luminance\ncolor value or an alpha value. We know that we can render to a texture map in\nDirect3D or OpenGL. The remaining problem is how we actually generate this texel\nbased on a set of source pixels. The solution lies in the alpha blending capabilities of\nthe GPU. The alpha blending unit is basically an adder, which adds a value in the\nGPU to one on the frame buffer, and can be used to accumulate color information.\nAdd to that the realization that objects in our scene are rendered in a color of our\nchoosing, and a suitable solution presents itself. The following steps show how to\nachieve the result we need.\nStep 1\nCreate a texture map of 16x16 texels. Call this the sun map. We will be rendering the\nsun itself and the occluding geometry onto this map. The surface format should have\nat least 8 bits per color component. On typical graphics hardware, this equates to a\n32-bit ARGB surface. The sun map is chosen to be 16x16 because it contains 256 tex-\nels. As we will see later, we are not limited to a 16x16 size, and can play tricks with fil-\ntering to reduce it if necessary.\nStep 2\nCreate a 1x1 texture map. This is the intensity map. This is the final destination of our\nintensity data. We only need a single texel of information, but of course, this texture\ncan be as big as needed to satisfy particular hardware requirements. Again, the format\nof this surface should be at least 8 bits per color component.\nStep 3\nRender the portion of the scene containing the sun into the sun map. There are many\nways to do this, but we choose a simple approach. We orient the viewer to look directly\nat the center of the sun. We also set the projection matrix so that the sun fills the view-\nport. The front plane is just beyond the eye; the back plane is just behind the sun. The\nsun map is cleared to black. We render one of two colors to the sun map. The image of\nthe sun itself is rendered in white. The occluding geometry is rendered in black, thus\n\n\n478 \nSection 5 Graphics Display\ncovering any of the sun values already rendered. If the sun is rendered first, Z-BufFering\nis not required, as we are just interested in the occlusion, not the depth ordering. The\nsun map now contains 256 values, some of which are white, some of which are black.\nIn 32-bit color, this means that the frame buffer contains OxFFFFFFFF or\n0x00000000. Note that for consistency, I set up the alpha channel in the same way as\nthe color channels, enabling the option of alpha blending or color blending.\nStep 4\nRender 256 pixels to the 1x1 intensity map. Draw them using point-lists or point-\nsprites if the API/hardware supports them, as they require less transform work than\nfull triangles or quads. Set texture coordinates so that each sun map texel is referenced\nonce. Set the alpha blend unit to add the color information of each of the source sun\nmap texels to the destination intensity map. We also want to sample only one texel at\na time from the sun map, so we set texture sampling to point sampling mode. Note\nthat we are writing to a single destination pixel multiple times, with different source\ntexels. One further step is that we blend each sun map texel with a constant value of\n0x01010101. This is actually 1/255 in each of the color channels. The result is that\nthe modulated sun map values will either be 0x01010101 if the source sun map texel\nis white, or 0 if the source sun map texel is black. I choose white and black as values\nin the sun map because these are generally easy to achieve during rendering, and can\nbe displayed for diagnostic purposes in the demo.\nThe trick here is that we are adding 256 values from the sun map, to form a pos-\nsible range of 256 values in the intensity map. The brighter the pixel in the intensity\nmap, the more visible sun pixels there are in the sun map, and hence the scene itself.\nWe have \"masked\" out the texture results of a previous rendering and added them\ntogether. As we will see later, this texture masking approach can be very useful for var-\nious applications.\nThe whole process has used the GPU to generate lens flare intensity from infor-\nmation in the frame buffer. Because the GPU pipeline is serialized, we know that the\nintensity information will be written before we generate our lens flare, and that the\npipeline does not require a flush during the operations discussed earlier. Further,\nbecause we have decoupled lens flare intensity generation from scene rendering, we\ncan perform these steps at any point, and potentially use the resulting value during\nrendering of the actual scene rather than at the end. We could perhaps use this value\nto modify the ambient intensity of the scene to simulate the viewer's pupils' reaction\nto the light—an option that is not open to us with the lock method unless we want to\nrender the entire scene twice.\nPerformance Considerations\nThe presented algorithm may seem like a lengthy procedure, but is in fact a relatively\ninexpensive operation when compared to reading the frame buffer and flushing the\npipeline. Consider that we are adding a little GPU work at the end of the frame,\n\n\n5.5 Texture Masking for Faster Lens Flare \n479\nwhich can continue to run in parallel with the rest of our engine. The caveat is that\nthe rendering of the sun map must be quick. We can ensure that this is the case by\nconsidering that the sun is usually above ground, and that the field of view to the sun\nis actually very small. This considerably reduces the number of objects we have to\nconsider, and allows quick rejection of those that we do via frustum culling. We can\ndo early-out rejection if we determine that any of our objects completely occlude the\nsun, and hence we do not draw the lens flare at all. A further option would be to ren-\nder the potential occluders with less geometric detail.\nAnother performance concern may be the rendering of the 256 blended polygons\nwe use to find the intensity result, but this isn't a problem because a modern GPU can\nrender about 40 million points per second—a fraction of the time it will take to read\nback a potentially large amount of data from the frame buffer, issues of concurrency\naside. In addition, reading back data from the frame buffer involves the CPU, which\nwe are trying to free up for nongraphics tasks.\nImprovements\nThe preceding scheme works well, and it gives a good approximate result. One obvious\ncriticism of the technique is that the sun is typically a circular object and the sun map we\nare using is a square texture. In fact, this is not a problem, as we can sample any texels we\nlike from the source sun map, including a circular sampling pattern. Of course, we need\nto make the sun map larger in order for it to cover the required number of samples.\nIf we wish, we can only sample a selection of the sun map texels. To do this, we\nsimply sample the required number of texels in the sun map, and change the modu-\nlate operation we use when writing to the intensity map to scale up our results.\nNote that we are solving the lens flare problem as an example, but many of the\ntechniques are reusable in other situations. Perhaps the intensity value could be used\nto darken the scene to mimic overexposure effects, or to add silhouettes or halos to\ncharacters. In fact, once we realize that the GPU has great flexibility as a mathemati-\ncal solver, we can modify our algorithm in a number of ways, using the GPU as a gen-\neral parallel mathematics engine. For example, we can use texture filtering to sample\nfour texels at a time, giving an average result for four samples. In our previous exam-\nple, we only need to draw 64 points to get our intensity map results if we rely on\nbilinear filtering to get the average intensity of the four samples. We can also do sev-\neral mathematical operations by varying the blending operation, such as using modu-\nlation to scale values. This is useful if we wish to accumulate more samples in the\nintensity map, because we can use the modulation to add scaling to our intensity map\nresults at the expense of dynamic range.\nSample Code\nif •;.«& \"*§ \nThe sample demo on the companion CD-ROM gives a good idea of the performance\nON me co \ndifference between the locking and texture masking techniques, and shows how to\n\n\n480 \nSection 5 Graphics Display\nimplement the algorithm as described. Options are also available on the menu to\nenable the display of the sun map and the intensity map.\nWhen running the demo on my target system, I take about a 50-percent frame-\nrate hit for using the lock method versus the texture masking method. The perfor-\nmance delta also increases the larger the frame buffer becomes. Typical numbers for\nthe opening scene are as follows:\nTexture Masking (600x500x32bits) = 53.5 fps\nFrame Buffer Locking (600x500x32bits) = 27.8fps\nThe source is heavily commented and should be easy to follow. I used Direct3D\nversion 8 to write the demo, but the concepts are identical for OpenGL. See the\ns~~z- B^ \nREADME included with the application on the CD for more information on how to\n£,'•:\" *JC •*\"' : '•-%\n5<-ffii^ \nrun ,-he demo and analyze the results. Detail is also included on how to use the\n\"Increase CPU Work\" option in the demo to study the hit to system parallelism from\nusing the lock call versus the texture masking technique.\nAlternative Approaches\nThere are two alternative approaches to lens flare that should be mentioned for\ncompleteness:\n• Sometimes, a geometry-based approach is taken to determine the visibility of the\nflare. The approach is to scan the geometry and do ray intersection tests to deter-\nmine visibility of a grid of sun pixels. While this works, it can be costly in terms\nof CPU compute time, and is not a useful approach when using billboards, as the\nsource textures have to be scanned for \"holes.\"\n• Some graphics cards have the ability to do asynchronous readback of the frame\nbuffer data. In this case, the light source area is uploaded in parallel with the ren-\ndering of the rest of the scene. This can be useful assuming that there is a suitable\npoint in the scene after occlusion objects are drawn in which to start the read-\nback, but before the rest of the scenery or lighting work is done. This method\ndoes of course rely on the support from the API to read back the data asynchro-\nnously, and support from the hardware to upload the data. At the time of writing,\nthis support is not available in Direct3D or OpenGL, although extensions to\nboth APIs have been proposed.\nReferences\n[KingOO] Yossarian King, \"2D Lens Flare,\" Game Programming Gems, Charles River\nMedia Inc. 2000: pp. 515-518.\n\n\nPractical Priority Buffer\nShadows\nD. Sim Dietrich Jr., Nvidia Corporation\nsdietrich@nvidia.com\nA\ns game graphics become more sophisticated in certain areas, others begin to look\nprimitive by comparison, thus breaking the consistency so essential to an immer-\nsive experience. One example of this phenomenon is the advent of detailed per-pixel\nlighting, which can be applied to the entire scene in real time (see the \"Dynamic Per-\nPixel Lighting\" gem). Unfortunately, the visual complexity of the lighting outshines\nthe shadow techniques employed by many games. This gem presents a set of tech-\nniques to improve the utility of priority buffers, first introduced in [Hourcade85].\nAlong the way, we will explore other shadow techniques, and close by discussing how\nto create useful hybrid techniques.\nShadows are very tricky in real-time graphics, because they are truly a scene-graph\nlevel problem, perhaps most naturally solved on the CPU. However, to achieve\nthe detailed results and performance we seek, we must leverage graphics hardware to\nsolve the shadow test on a per-pixel basis. Some graphics hardware currently has\nnative shadow support, including priority buffers and shadow depth buffers. However,\nsince none of these are available through a single standard interface, we will concen-\ntrate on generic techniques that should work with modern PC graphics hardware\nthrough either Direct3D or OpenGL.\nSome of the shadow techniques employed by modern games are shadow volumes,\ndepth buffer shadows, and. priority buffer shadows. Each has various advantages and dis-\nadvantages, briefly outlined in Table 5.6.1.\nShadow depth buffers [Williams78] work by using the Z-buffer or a texture that\nrepresents per-pixel depth from the light. We will focus on techniques that work with\ntexturing, to maximize the utility of the techniques across graphics hardware. Shadow\ndepth buffers work like so:\nBuffer Creation Phase:\nFor each Light\nClear Depth Buffer Texture to Oxff\nFor each Object in Light's Viewing Frustum\n481\n\n\n482\nSection 5 Graphics Display\nTable 5.6.1 Comparison of Real-Time Shadow Techniques\nPriority Buffers\nDepth Buffers\nOnly convex pieces can\nself-shadow properly\nShadow Volumes\nCPU Work\nRender To Texture\nRequired\nFill Requirements\nSelf Shadowing\nVery Low\nPer-Light Setup\nObject Sorting\nYes\nMedium\nDepends on size of\nshadow map\nPartial\nVery Low\nPer-Light Setup\nYes\nMedium\nDepends on size of\nshadow map\nYes\nHigh\nPer-Light Setup\nPer-Object Shadow\nVolume Creation\nNo\nHigh\nDepends on complexity\nof shadow volume and\ncamera position\nYes\nPrecision\nAliasing Artifacts\nGPU Complexity\nTypically 8-24 bits of\nID\nRange independent\n8-24 bits of ID\nTypically spread across\nlights' range\nYes\nBetween Adjacent\nObjects\n0 ( N * M * R * P )\nN = Vertices of caster\nR = Vertices of receiver\nP = Number of receivers\nM = Size of shadow map\nYes\nDepending on Depth\nPrecision & Light Range\n0 ( N * M * R * P )\nN = Vertices of caster\nR = Vertices of receiver\nP = Number of receivers\nM = Size of shadow map\nNo limit to accuracy\nDirectional Lights\nSpot Lights\nPoint Lights\nYes\nYes\nYes\nYes\nYes\nYes\nWith less precision\nYes\nYes\nYes\nNo\n0 ( N * R * P * E )\nN = Vertices of caster\nR = Vertices of receiver\nP = Number of receivers\nE = Depth complexity\nof shadow volume\nCompute Per-Pixel Depth from Light from 0x0 to Oxff\nRender Object into Texture, using Depth as the color\nShadow Testing Phase:\nFor each light\nCreate texture matrix to move vertices from view space to\nLight's view space\nFor each Object in Player's Viewing Frustum\nCompute Per-Pixel Depth exactly as above\nSelect Depth Buffer as a Texture\nFor each vertex\nProject vertices to the Depth Buffer Texture\nFor each pixel of Object\nCompare Computed Depth to Closest Projected Depth\n\n\n5.6 Practical Priority Buffer Shadows \n483\nIf Computed Depth > Closest Projected Depth\nPixel is in Shadow\nElse\nPixel is Lit\nPriority buffers work by first assigning each \"Object\" a unique ID from 0x0 to\nOxFE. An object is defined as something that can't shadow itself. Examples of objects\nwith perfect shadowing through this technique are convex objects and individual tri-\nangles. Priority buffer shadows work like so:\nBuffer Creation Phase:\nFor each Light\nSet Priority Buffer Texture as the Render Target\nClear Priority Buffer Texture to Oxff\nFor each Object in Light's Viewing Frustum\nAssign ID from nearest to Light = 0x0 to farthest from Light\n<=OxFE\nRender Object into Texture, using ID as the color\nShadow Testing Phase:\nFor each light\nCreate texture matrix to move vertices from view space to\nLight's view space\nFor each Object in Player's Viewing Frustum\nSelect ID as a constant color\nSelect Priority Buffer as a Texture\nFor each vertex\nProject vertices to the Priority Buffer Texture\nFor each pixel of Object\nCompare constant ID to Closest Projected ID\nIf Constant ID > Closest Projected ID\nPixel is in Shadow\nElse\nPixel is Lit\nComparing Priority Buffers to Depth Buffers\nPriority buffers and depth buffers are very similar techniques—we could even use the\nsame pixel shader program or texture stage setup to perform either method.\nDepth buffers have the advantage that each pixel is treated individually by having\nits own depth value measured from the light. This allows this technique to perform\nself-shadowing.\nOne downside of depth buffer shadows is that the depth from the light is typi-\ncally computed over the light's entire range of influence. If we use an 8-bit color or\nalpha channel to represent depth from the light as in our previous example, only 8\nbits are available for the entire light's range. This is not adequate precision for many\nscenes to support both proper inter-object shadows as well as intra-object self-\nshadowing (Figure 5.6.1).\n\n\nSection 5 Graphics Display\nAt Light |—^—— \n——^^1 ^ Light's Maximum Range\nFIGURE 5.6.1 Depth from light.\nPriority buffers overcome this difficulty by assigning each object its own ID,\nbased on its sort order in terms of distance from the light. This way, the precision is\neffectively infinite over the entire range. Any range can be equally accommodated, at\nthe cost of losing self-shadowing. Because each object has its own ID, individual sec-\ntions of the object can't shadow each other.\nFigure 5.6.2 is an example where two chairs are rendered with different IDs from\nthe point of view of the light. The background is normally white, but is cleared to\nblack to make the chairs show up better.\nFIGURE 5.6.2 Priority buffer from light's view point.\nThere are several ways to overcome the self-shadowing problem without special-\nized hardware. One way is to break up the model into convex pieces, perhaps each\nhierarchy level of an animated model or even down to the individual triangle level.\nOne natural approach for static geometry is to break up the world into convex pieces\nusing OctTree or BSP nodes, and assign an ID to each node. Unfortunately, this\napproach exacerbates a serious problem—aliasing.\nResolving Aliasing Problems\nAliasing artifacts most obviously occur when two nonoverlapping objects with differ-\nent object IDs shadow each other. This occurs due to the simple fact that the back\nbuffer and priority buffer texture are at different resolutions and different orienta-\ntions. This causes a point sample of the priority buffer to fall somewhere within one\ntexel of the desired sampling location. Sometimes the sample selects the desired texel,\nsometimes one of its neighbors (Figure 5.6.3).\n\n\n5.6 Practical Priority Buffer Shadows\n485\nFIGURE 5.6.3 The dashed line shows the texture sample positions lined up with the\npriority buffer. This mismatch of size and orientation causes aliasing.\nBilinear filtering is used for texture mapping in order to reduce this type of alias-\ning by performing a weighted average of a 2x2 footprint of texels. Unfortunately, aver-\naging object IDs makes no sense. If we have texels with object ID 100 and 200, and\nwe average them, we get object ID 150. This object ID may represent a completely\ndifferent object, so we see that straight bilinear filtering won't do the trick.\nOne way to solve the aliasing problem is to offset the texture by half a texel so that\nthe sample falls exactly in between a 2x2 area of texels. Then, perform the shadow test\nfour times, and only allow a shadow when all four samples agree that the pixel should\nbe in shadow. This solves the aliasing problem, but costs four texture fetches, and\nmultiple passes on dual-texture hardware.\nAn improvement to this technique is to \"pre-jitter\" the priority buffer. After cre-\nating the priority buffer as we did earlier, by putting the object ID in the alpha chan-\nnel of the priority buffer, we perform another render-to-texture pass into a texture the\nsame size as the original priority buffer. With this pass, we perform the \"pre-jitter\" by\ntaking the four texels that neighbor the original sample location in the priority buffer,\nand replicating them into R, G, B, and A of the destination color.\nThis way, during the shadow testing phase, a single texture fetch of the \"pre-\njittered priority buffer\" gives all four neighboring samples. With a bit of per-pixel\nmath, all four shadow tests can be computed at once, their results combined, and the\naliasing eliminated, by only shadowing the pixel if all four tests agree it should be in\nshadow (Figure 5.6.4).\nThis pre-jitter technique is useful because there is only one jitter step per frame,\nbut many shadow testing operations, so it exploits coherency for faster rendering.\nFigure 5.6.5 is a pre-jittered version of Figure 5.6.4. Note how the chairs have a\ncolored outline, which indicates that the R, G, and B channels represent different IDs\nafter jittering.\n\n\n486\nSection 5 Graphics Display\nFIGURE 5.6.4 The dashed line shows the\ntexture sample positions lined up with the four\nnearest neighbors of the priority buffer.\nFIGURE 5.6.5 Pre-jittered priority buffer from\nthe light's view point.\nHybrid Approaches\nPerhaps the best use of priority buffer shadows is to use them for inter-object shadows\nbetween objects that don't come close to intersecting, and thus won't alias, and use\nanother technique altogether to handle self-shadowing. So, if two objects are far\nenough apart such their bounding spheres don't intersect, the priority buffer method\nis used to shadow the further one with the closer one. In the case where the bounding\nspheres do intersect, there is a chance that the objects may alias with each other, so\nthey use the same object ID, and they must be shadowed with the self-shadow test.\nOne approach that combines priority buffers for inter-object shadows and depth\nbuffers for self-shadowing is to encode the 8-bit object ID into the red channel of a\ntexture in a vertical ramp, and an 8-bit depth in the green channel in a horizontal\nramp. The idea here is that the 8-bit depth buffer is only used for self-shadowing\nwithin a single object, so the 8 bits can be spread across a single object's range. This\ngets around a major problem with standard depth buffer shadows: limited precision\nacross the light's range (Figure 5.6.6).\nObject 2\nDepth Range 1 \nDepth Range 2\nFIGURE 5.6.6 Depth measured across each object.\n\n\n5.6 Practical Priority Buffer Shadows \n487\nThe technique to perform this dual shadow test is a subtraction and a dot prod-\nuct, replicated into the alpha channel. Alpha testing can be used to determine\nwhether a pixel is in shadow, thus allowing this technique to work on any hardware\nwith dual texturing and a dot product operation.\nAnother hybrid approach is to use stencil shadow volumes only for self-shadowing.\nAfter computing the shadow volume edges, we can extrude them only to the edge of\nthe object's bounding box, instead of extending them to the limit of the light's range.\nThis reduces the impact of the major drawback to stencil shadow volumes—the fill\nrate cost when the shadow volume extends across the camera's view plane. By restrict-\ning them to self-shadowing only, we also have the benefit that we can completely skip\nthe self-shadowing test for objects outside the viewing frustum.\nYet another way to achieve self-shadowing with priority buffers is to perform ray\ncasts of each vertex to the light source on the CPU, and check for the ray intersecting\nthe object. If the ray intersects a solid portion of the object, set the alpha channel of\nthe vertex diffuse color to zero. During the lighting process, modulate this alpha value\nwith the lighting contribution of the light. As shown previously, this could be per-\nformed only on objects in the viewing frustum, and even dropped altogether for dis-\ntant objects. A variant on this approach is to perform the test only on chunks of the\nmodel—say, one for each model hierarchy level—like the shoulder or forearm. This\nmakes a nice level-of-detail option for distant and/or unimportant models.\nSummary\nPriority buffers are a great way to get inter-object shadows that bypasses the issue of\nlimited precision across a light's range. Although standard priority buffers are not\nideal for handling self-shadowing, other techniques can be paired with them to\nachieve a complete shadowing solution for real-time games.\nReferences\n[DietrichOO] Dietrich, D. Sim, \"GDC 2001 Presentation—Shadow Techniques,\"\nwww.nvidia.com/marketing/developer/devrel.nsf/bookmark/04l9FBACDE043\nABF88256A1800664C06.\n[Hourcade85] Hourcade, J.C., and A. Nicolas, \"Algorithms for Antialiased Cast\nShadows,\" Computers and Graphics, vol. 9, no. 3, pp. 259-265, 1985.\n[Williams78] Williams, Lance, 'Casting Curved Shadows on Curved Surfaces,\"\nComputer Graphics (SIGGRAPH 78 Proceedings), vol. 12, no.3, pp. 270-274,\nAugust 1978.\n",
      "page_number": 458,
      "chapter_number": 47,
      "summary": "Add to that the realization that objects in our scene are rendered in a color of our\nchoosing, and a suitable solution presents itself Key topics include shadows, objects, and texture.",
      "keywords": [
        "priority buffer shadows",
        "Priority Buffer",
        "Priority Buffer Texture",
        "shadow depth buffers",
        "sun map",
        "buffer",
        "Depth Buffer Texture",
        "buffer shadows",
        "depth buffers",
        "shadow",
        "Texture",
        "Practical Priority Buffer",
        "Buffer Texture",
        "map",
        "depth"
      ],
      "concepts": [
        "shadows",
        "objects",
        "texture",
        "depth",
        "light",
        "sample",
        "sampling",
        "buffer",
        "priority",
        "color"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 1",
          "chapter": 57,
          "title": "Segment 57 (pages 550-561)",
          "relevance_score": 0.66,
          "method": "sentence_transformers"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 23,
          "title": "Segment 23 (pages 441-462)",
          "relevance_score": 0.65,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 1",
          "chapter": 59,
          "title": "Segment 59 (pages 570-580)",
          "relevance_score": 0.6,
          "method": "sentence_transformers"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 25,
          "title": "Segment 25 (pages 482-502)",
          "relevance_score": 0.6,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 3",
          "chapter": 48,
          "title": "Segment 48 (pages 456-465)",
          "relevance_score": 0.57,
          "method": "sentence_transformers"
        }
      ]
    },
    {
      "number": 48,
      "title": "Segment 48 (pages 469-476)",
      "start_page": 469,
      "end_page": 476,
      "detection_method": "topic_boundary",
      "content": "5.7\nImpostors: Adding Clutter\nTom Forsyth, Mucky Foot Productions\ntomf@muckyfoot.com\nf mpostoring is a term that is probably not familiar to many reading this. However,\nthe concept may be—it has surfaced in various forms many times in the history of\n3D graphics. Simply put, it is about using sprites in a 3D scene, but instead of an\nartist drawing or rendering the sprites beforehand, they are updated on the fly. (In\nfact, the academic version of impostoring started when rendering things such as\ncityscapes for VR fly-throughs, and was not updated dynamically—that came in later\nversions. However, the dynamic update version is far more interesting to games, since\nby their nature they deal with scenes that change.)\nInstead of rendering a high-triangle object every frame, the high-triangle object is\noccasionally rendered to a texture—usually on the order of once every 5 to 50 frames.\nEvery frame this texture is mapped onto a much lower-triangle object which is drawn\nin place of the complex object.\nThe main target for impostors is scenes with lots of small static objects in them—\nclutter. Each of these objects will use an impostor, and most will be redrawn at a\nmuch lower rate than the main scene's frame rate. By doing this, the perceived trian-\ngle density is far higher than the actual density, and the visual quality allowed by all\nthese incidental objects considerably increases the realism of the scene. The main dif-\nference between an office or house in a computer game and the real thing is the\namount of clutter present.\nAlthough newer cards have huge triangle throughput, using impostors is still of\ngreat benefit. The bus bandwidth (in the case of the PC, this is the AGP bus) is usu-\nally a bottleneck, and reducing this for some objects allows greater triangle detail to be\nused on others. An impostor is a single texture, whereas rendering the object normally\nmay require multiple textures and multiple texture layers—changing texture flushes\nthe hardware's texture cache and may require extra texture management from the dri-\nver, the API, or the application. Drawing the object each frame requires that it be lit\neach frame, even if the lighting has not changed, and as lighting techniques become\nmore sophisticated, lighting becomes more expensive. Finally, there is usually plenty\nof application overhead associated with drawing an object, even before a single API\ncall is made—using impostors can avoid much of that work.\n488\n\n\n5.7 Impostors: Adding Clutter \n489\nThe Whole Process\nImpostoring involves a few key parts, which will be addressed separately:\n• Rendering the impostor texture on the screen each frame. I call this \"rendering\"\nthe impostor.\n• Rendering the impostor's mesh at low speeds to the texture. I call this \"updating\"\nthe impostor.\n• Deciding when to update the impostor, and when to leave it.\n• Driving the hardware efficiently.\nRendering the Impostor:\nONE:INVSRCALPHA\nAn impostor is essentially a color picture with an alpha channel that defines that pic-\nture's opacity in some way. Given that, there are basically two choices for this sort of\nblending: premultiplied alpha and \"normal\" blended alpha.\nNormal alpha is the standard SRCALPHA:INVSRCALPHA style. The other\nstyle is premultiplied alpha— the ONE:INVSRCALPHA style.\nWhich one to use depends on which produces the correct result when rendering\nan alpha-blended object into an impostor, and then rendering the impostor to the\nscreen. A pixel P is rendered to an impostor texture (which is cleared to black) to pro-\nduce an impostor pixel I, and then that is rendered on top of the existing framebuffer\npixel F, to produce result pixel R.\nIf using non-premultiplied alpha, the desired result is:\nThe render to the impostor produces the result:\nAnd rendering this to the framebuffer produces:\n= P x Pa x Pa x Pa + F x ( 1 - Pa x />„)\nThis is pretty useless, and very little like the desired result. With premultiplied alpha,\nthe desired result is:\nR = P+Fx(l-Pa)\nThe render to the impostor produces this result:\n7=P+Ox(l- JP a)\n\n\n490 \nSection 5 Graphics Display\nRendering to the framebuffer produces this:\n= P+Fx(l-Pa)\nwhich is perfect. Premultiplied alpha is not used by many apps, but it is fairly simple\nto adapt an existing engine to use it.\nOne thing to note is that it is now important to be precise about the alpha-\nchannel result even when rendering opaque triangles, since the result will be written\nto the impostor, and will influence the result when die impostor is rendered to the\nscreen. Non-alpha-blended (i.e., opaque) rendering to the impostor must ensure that\nthe alpha result is 1 , or the background will show through. Fortunately, this is fairly\neasy to do, but it does require more care with the alpha-channel result than is nor-\nmally taken.\nOne problem with impostoring is that alpha-blend effects rendered into an\nimpostor must be capable of expressing their effect within the premultiplied alpha\nscheme. This means that effects such as multiplicative color blends (basically, any-\nthing with a COLOR argument in the alpha-blend) will not work as intended,\nbecause the impostor has only a single alpha channel to express the amount of back-\nground to allow through. Fortunately, these sorts of effects are rarely used on objects\nthat are suitable for impostoring. Note that this only applies to actual translucent\neffects — opaque multipass rendering that uses alpha blending to combine the passes\n(e.g., light maps, detail maps, etc.) will be fine, as long as the final alpha-channel value\nis carefully controlled.\nBillboard Quad\nThe most obvious way to render the impostor is to simply render a quad representing\nthe impostored object. This gives a perfect result as long as the neither the object or\nthe camera move.\nUnfortunately, pixels are not all the app has to worry about in a 3D scene; there\nis also depth to consider. A quad can only represent a single plane of depth, but the\nobject it represents will cover multiple depths.\nSo, for the quad, the app needs to decide at what depth to draw. Unfortunately,\nfor some of the most common applications, there is no single depth that is appropri-\nate. As can be seen in Figure 5.7.1, our impostored hero is standing between two\nwalls. Unfortunately, his feet are sticking through the near wall, and his head has van-\nished through the far wall. Quads are no good if an impostored object is going to be\nclose to other objects. They may be quite good for flying objects that don't usually get\ntoo close to things, though, such as aircraft in a flight simulation.\nCuboid\nThe next approximation is a bounding box. Instead of a quad, the object-space\nbounding box of the object is drawn, with the impostor texture projected on it.\n\n\n5.7 Impostors: Adding Clutter\n491\nFIGURE 5.7.1 Side view and rendered view of a billboard impostor showing Z-buffer\nproblems.\nBecause the bounding box is a real 3D object, its Z-buffer properties can be con-\ntrolled far better than those of a screen-aligned quad. In particular, its Z-buffer prop-\nerties are now independent of the camera position—they only depend on the object\nposition and orientatipn, which is one less thing the app has to worry about.\nBounding boxes actually work quite well. Most things in everyday life fill their\nbounding boxes nicely, and artifacts from intersections between bounding boxes are\nrare. Note that only the front or back of the bounding box is drawn. Either can be\nused, but I recommend the front, because many objects fill their bounding boxes, so\nusing the front side gives a parallax shift that is similar to the real object when the\ncamera moves.\nAlthough a bounding box is more complex than a quad, it's not much more com-\nplex—12 tris is not going to break the triangle budget now that typical scenes have\nhundreds of thousands of triangles. The increase in Z-buffering stability compared to\na single quad is definitely worth the effort.\nBounding Object\nThere are plenty of objects for which a bounding box is not a good enough approxi-\nmation, and using one leads to unnecessary Z-buffer clashes. Another factor to con-\nsider in choosing the shape of the impostor is parallax error. Most 3D scenes have a\nlarge number of elements that are stationary, but the camera will still be moving\nthrough that scene. A box painted with a picture of something on it is not going to\nlook like that something for long when the camera starts moving. Although increasing\n\n\n492 \nSection 5 Graphics Display\nthe rate at which the impostor is updated can help, this just burns pixel and triangle\nrates far faster for not all that much benefit—the eye very quickly notices the lack of\nparallax as it moves.\nUsing an impostor object that is closer to the real shape of the object, although\nstill with a very low triangle count, can give a good improvement over a bounding\nbox. The main restriction on the shape is that it needs to fully enclose the object; oth-\nerwise, the impostor image may be bigger onscreen than the impostor object being\nused, and the edge of the image will not get drawn. The other restriction is that the\nobject must usually be convex to prevent self-sorting problems, because the impostor\ntexture is drawn with alpha blending.\nImage Warping\nOne of the problems with the impostor object is that it must be both convex and\nlarger than the thing it represents. The former is required to prevent pixels being ren-\ndered twice, and the latter to prevent some pixels not being rendered at all. However,\nthis inevitably means that the parallax as the object rotates (or the camera moves) is\nnot going to be correct, because the impostor object is bound to be larger than the\nimage it represents. Using a higher-tri impostor object can help reduce this in the case\nof entirely convex source objects. However, for nonconvex source objects, this does\nnot noticeably improve matters—the impostor object must remain convex, and no\namount of tris will allow it to match a concave object.\nAnother way to deal with this is to move the texture coordinates at each vertex\neach frame. The tri counts involved are fairly low, so a bit more work at each vertex is\nunlikely to hurt performance much. The principle is fairly simple—figure out where\non the real object (and thus the impostor texture image) each impostor objects vertex\nlies when viewed from a certain angle. As this viewing angle changes, the texel that the\nvertex lies over will change. Therefore, for a new viewing angle, trace the line from the\nviewer through the impostor object vertex to the original object. Then work out\nwhich texel this part of the object was originally drawn to, and set the UV coordinates\nof this vertex accordingly.\nNice Theory, What Can We Get Away With?\nThis is expensive and fiddly to implement. It also has loads of problem cases, such as\nthe vertex raytrace falling down a visually insignificant \"chasm\" in the object and,\nbecause of the low density of vertices in the impostor object, producing large warps\nover the image. Another problem is what to do with vertices at the edge of the impos-\ntor object that do not map to any part of the real object at all—what happens to\nthem? Some type of interpolation seems to be needed from the visible edges of the\nobject out to these vertices. This is the type of work that an app does not want to be\ndoing at runtime, however few vertices it involves.\nIn practice, what I have found to be far simpler, and works just fine, is to give each\nvertex a \"parallax factor\"—the number of image texels to move per degree of viewer\n\n\n5.7 Impostors: Adding Clutter \n493\nmovement. This is a factor usually tweaked by hand, and easily determines the vertex's\ntexel coordinates at runtime. This factor is only done once for each impostor object\nvertex, and hand-tweaking around 8 to 10 vertices per object does not take long.\nAlternatively, to generate these parallax values automatically for most real-world\nobjects, find the nearest real-object vertex to each bounding object vertex. This dis-\ntance is then proportional to the parallax factor required. The actual value depends on\nexactly how the factor is applied to the UV values, which depends on how the texture\nis mapped to the impostor object. For more complex objects, such as highly irregular,\nspiky, holed, or multilayered objects, it may still be better to hand-tweak the factors.\nThis method finds the nearest vertex, but for these objects, it may be more appropri-\nate to use some sort of average instead.\nEven this simple method may not be possible because the objects are generated\ndynamically; for example, through animation. In this case, using a bounding cuboid\nand assuming an ellipsoid object inside works remarkably well for such a primitive\napproximation. It certainly works better than having no texture coordinate\nchanges at all.\nUpdate Heuristics\nOn each frame, for each impostor, the decision needs to be made whether to update it\nthat frame. A number of factors contribute to this decision. In all these cases, some\nsort of screen-space error estimate is made for each factor, and the factors summed. If\nthis sum is over a global factor (which may be static, object-specific in some way, or\ndynamic to try to maintain a certain frame rate), the impostor is updated.\nAnimation\nAnimation changes the appearance of the object, and at some point the error is going\nto grow too great. This can be quantified by a delta between the animation frame the\nimpostor was rendered with, and the animation frame that would have been used if\nthe object were not impostored. Doing this precisely requires the object to be ani-\nmated each frame, even if an update is not needed. This can be quite a large part of\nthe expense of rendering an object, and it is a good idea to try to avoid a complete ani-\nmation step. The easiest way I have found is to do a preprocessing step on each ani-\nmation and find the largest distance that any vertex moves during the animation.\nDivide by the length (in time) of the animation, and thus find a \"maximum error per\nsecond\" measure for the animation. This is easy to do in a brute-force way, and since\nit is a preprocessing step, this is perfectly reasonable.\nNote that the human eye is absolutely superb at extracting humanoid movement\nfrom images just a few pixels high. Impostoring this motion, effectively reducing its\neffective frame rate, can be surprisingly noticeable, even at very slight levels. It is a\ngood idea to have an extra bias on these animations that can place even more empha-\nsis on them than simple mathematical screen-space error. This effectively rules out\nimpostoring for anything but slight animations on distant objects.\n\n\n494 \nSection 5 Graphics Display\nLighting\nIf the lighting changes significantly on the object, it will need to be updated. Since\nlighting systems are extremely varied between 3D engines, this requires fairly engine-\nspecific routines to decide what the equivalent screen-space error is. Lighting a point\nat the center of the object using the six cardinal normals and comparing RGB differ-\nences between the current conditions and those when the impostor was created gives\na fairly good idea of how the lighting has changed. Multiplying this by object size and\ndividing by the distance from the camera then gives a rough screen-space error.\nViewing Angle\nChanging the viewing angle is probably the most obvious factor that decides an\nimpostor update. Note that what is important is the vector from the camera to the\nobject in object space. This will change when the object rotates, and also when the\ncamera moves, both of which are important. The camera's direction of view is unim-\nportant—unless an enormous field of view is used, the object does not change appear-\nance much when the camera rotates, only when it moves.\nCamera Distance\nAs well as the direction from the object to the camera, the distance between the two is\nalso important. Although it does not change the actual appearance of the object, as\nthe camera moves directly toward the object, the impostor texture gradually enlarges.\nAfter a while, it becomes obvious that this is just an image that is being enlarged by\nbilinear filtering, and not a real polygonal object, and so needs updating. This update\nwill render to a larger texture, and so give more detail.\nGame-Specific Heuristics\nMany games also have specific heuristics that can be used to tweak these update rates.\nA common one for FPS games is that objects near the center of the view are usually\nthe ones the player is looking at. These should get a slight boost to their update rates\nby dropping the acceptable screen error.\nFor mouse-driven games such as god games and RTS games, a similar tweak can\nbe made to objects underneath the mouse cursor, for exactly the same reasons.\nA distinction can also be made between \"scenery\" and \"important\" objects. Items\nthat are purely in the scene to create an ambience, but are not usually involved in the\ngameplay, can be assigned a relatively large screen error. The player will not be exam-\nining them terribly closely—his or her attention is likely to be elsewhere. Therefore,\nthese objects can be \"more wrong\" before the player notices the error.\nEfficiency\nThe main efficiency hit on most cards is changing the render target. This causes flush-\ning of many internal caches and states, and on some cards causes a flush of the entire\n\n\n5.7 Impostors: Adding Clutter \n495\nrendering pipeline. The main efficiency aim is to minimize these changes. The best\nway to do this is to wait until the end of the current scene, batching up the required\nupdates to the impostor textures, rather than doing them as they are needed. Use large\nrender targets, and at the end of the scene, pick the emptiest render target and render\nmultiple impostor images to subregions of that texture.\nPrediction\nWhen updating an impostor, the current state of the object is rendered to the texture.\nThis is then faded in over a few frames, and then preserved for a few frames more,\nbefore in turn being replaced by a newer render. This does mean that what is visible\nonscreen is always out of date.\nThis can be improved by doing some forward prediction of impostor state. The\nidea is to predict what the impostor is going to look like halfway through its lifetime.\nIf an object is currently being updated every sixth frame, when updating the impos-\ntor, the state of the impostor (orientation, position, lighting, animation, etc.) should\nbe forward-predicted by three frames.\nWith games such as first-person-shooters, objects in the world are basically split\ninto two distinct categories: those that almost never move (walls, furniture, clutter),\nand those that move erratically (players). The movement of the players is notoriously\nhard to predict, and it is probably a waste of time trying to impostor players.\nOn the other hand, impostoring the scenery and furniture is a far more viable\nproposition. Prediction for them is trivial—they almost never move. And when they\ndo move, they usually move under control of a player; in other words, erratically. The\neasiest thing is to simply disable impostoring for the duration of the movement.\nFor god games and Real-Time Strategy (RTS) games, the problems are similar, but\nthe movement of the camera is very different. It is usually a bird's-eye view, and most of\nthe time it is either static (while issuing orders to units), or moving at constant speed\nover the map to get to a different area. Small, erratic movements are rare, which is for-\ntunate since these are extremely hard to predict. Prediction of moving objects can also\nbe very useful in these games, since most of them are Al-controlled. Much of the time,\nthe objects are either stationary or walking in straight lines to a destination, both of\nwhich are easy to predict. However, both camera movement and object movement can\nchange abruptly, and when they do, the best thing is to flag the impostor for an update\nvery soon, or even to temporarily disable impostoring altogether.\nSummary\nImpostoring is useful when trying to draw scenes with lots of fairly static objects in\nthem. The raw triangle count will overwhelm any bus and graphics device that tries to\nrender them at top detail, and progressive mesh methods can only do a certain\namount to reduce the workload—texture changes and animation are extremely diffi-\ncult to reduce in this way.\n",
      "page_number": 469,
      "chapter_number": 48,
      "summary": "This chapter covers segment 48 (pages 469-476). Key topics include object, impostors, and rendering. Every frame this texture is mapped onto a much lower-triangle object which is drawn\nin place of the complex object.",
      "keywords": [
        "impostor object",
        "object",
        "impostor",
        "impostor object vertex",
        "impostor texture",
        "texture",
        "rendering",
        "Adding Clutter",
        "frame",
        "camera",
        "object vertex",
        "alpha",
        "bounding",
        "Mucky Foot Productions",
        "vertex"
      ],
      "concepts": [
        "object",
        "impostors",
        "rendering",
        "render",
        "texture",
        "triangle",
        "change",
        "changed",
        "pixel",
        "alpha"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 7",
          "chapter": 46,
          "title": "Segment 46 (pages 443-452)",
          "relevance_score": 0.73,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 1",
          "chapter": 57,
          "title": "Segment 57 (pages 550-561)",
          "relevance_score": 0.68,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 7",
          "chapter": 49,
          "title": "Segment 49 (pages 479-486)",
          "relevance_score": 0.68,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 3",
          "chapter": 36,
          "title": "Segment 36 (pages 347-355)",
          "relevance_score": 0.65,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 3",
          "chapter": 42,
          "title": "Segment 42 (pages 401-412)",
          "relevance_score": 0.64,
          "method": "sentence_transformers"
        }
      ]
    },
    {
      "number": 49,
      "title": "Segment 49 (pages 477-489)",
      "start_page": 477,
      "end_page": 489,
      "detection_method": "topic_boundary",
      "content": "Section 5 Graphics Display\nImpostoring is most effective on static objects some distance from the camera.\nIntroducing this sort of clutter into games increases the visual quality substantially,\nespecially since each object is still a real independent 3D object that players can inter-\nact with if they wish. It also allows key objects to be \"hidden in plain sight\" amongst\na lot of other objects—something that has been extremely difficult to do with existing\ntechniques and the limited number of objects available in a scene.\nEven an implementation using a bounding box and some simple math produces\ngood results for the incidental objects that are currently missing from games, but pro-\nduce far more realistic scenes.\n\n\n5.8\nOperations for Hardware-\nAccelerated Procedural\nTexture Animation\nGreg James, NVIDIA Corporation\ngjames@nvidia.com\nC\nonsumer-level 3D accelerators have come a long way in recent years. Today's\nmost advanced chips sample four textures per pass and offer powerful texture\naddressing and pixel processing operations. Among these are dependent texture reads,\nwhere the color value sampled from one texture is used to perturb the coordinates of\na subsequent texture read. Dependent texture reads combined with the ability to ren-\nder to a color buffer and use that buffer as a source texture in later rendering make it\npossible to generate interesting textures and texture animations entirely on the graph-\nics processor. With texel sampling rates close to one billion per second, these proce-\ndural texture effects run very fast and are practical for real-time 3D-accelerated scenes.\nTechniques for procedural texture generation have been with us from the early\ndays of computer graphics. There are various algorithms for mimicking natural phe-\nnomena and generating complex emergent patterns [Ebert98]. Procedural texture\nanimation is excellent for a wide range of effects while using a tiny fraction of the\nmemory and storage that a prerendered or \"canned\" animation would require. Mem-\nory to hold two or three full frames is often all that is required to generate an endless\nnon-repeating animation. User input can be applied to these animations on the fly,\nand this interactivity enables richer and more engaging virtual scenes.\nThis gem covers a few fundamental operations for generating procedural anima-\ntions, and puts these to use in specific examples that simulate fire, smoke, water,\nor perform image processing. With today's consumer hardware, we can even run com-\nplex cellular automata programs entirely within the rendering of a 3D accelerator and\nput the resulting animations to use in various effects.\nHardware Operations\nWe will focus on two rendering operations that give rise to interesting procedural tex-\nture effects. The first is four-sample texture sampling from adjacent texels of an\nimage, and the second is 2D dependent green-blue texture addressing. These opera-\ntions are supported in the two most common APIs: OpenGL and Microsoft's\n497\n\n\nSection 5 Graphics Display\nDirectXS. For the four-way multisampling, we will use a vertex program that is\nloaded into the graphics processor and operates on the incoming vertex position and\ntexture coordinates. These vertex programs are DirectXS's \"Vertex Shaders\" [DXS'OO]\nand what is currently the NVIDIA NV_vertex_program extension to OpenGL\n[NVExt2001]. For our examples, this vertex program establishes the appropriate\ncoordinates for neighbor texel sampling in each of the four texture stages that feed the\npixel engine. This pixel engine will combine the samples for various effects, and can\nalso further manipulate the samples with the dependent texture addressing opera-\ntions. The pixel engine is also programmable as exposed through DirectX 8's \"Pixel\nShader\" programs and NVIDIA's NV_texture_shader extension. First, we examine the\nvertex processing operations.\nNeighbor Sampling for Blur, Convolution, and Physics\nMany procedural texture algorithms rely on sampling a texel's neighbors and filtering\nor blurring these samples to create a new color value. We can accomplish this neigh-\nbor sampling for all the texels of a source texture by rendering it into a color buffer of\nthe same resolution as the texture while using four-texture multisampling. The source\ntexture is selected into all texturing units, and a vertex program generates four sets of\nindependent texture coordinates, each offset by the distance to one of the texels\nneighbors. By rendering a single quad with texture coordinates from 0.0 to 1.0, which\nexactly covers the render target, and setting each texture coordinate offset to zero,\neach texel of the destination would sample from its single source texel four times. We\nwould end up with an exact copy of the source texture. By offsetting each texture\ncoordinate by a vector to a neighboring texel, each pixel of the destination samples\nfrom four of its neighbors in the source. We can convolve the samples (combine them\nwith various scale factors) in the pixel engine however we like.\nIf we use point sampling, four-sample multitexturing hardware gives us up to\nfour neighbor samples per pass. If we enable bilinear filtering, each offset sample\ndraws upon four texels, so we could potentially sample 16 neighbors per pass. The\nweighting of texels within each 2x2 bilinear sample is determined by the precise tex-\nture coordinate placement. For example, we could grab and average all eight of a\ntexels nearest neighbors by placing four bilinear samples exactly between pairs of\nneighboring texels. Figure 5.8.1b shows this, and Listing 5.8.1 presents code for\nneighbor sampling on four-sample multitexturing hardware. The 'X' of Figure 5.8.1\ndenotes the texel being rendered to the destination, and the dots indicate the sample\nlocations from the source texture used to render it. We can select between various sets\nof sample locations (A or B in this case) by using the vertex shader indexing variable\naO. x. The value of the indexing variable is loaded from a shader constant value that is\nset before rendering.\n\n\n5.8 Operations for Hardware-Accelerated Procedural Texture Animation\n499\nOffsets A\nOffsets B\nFIGURE 5.8.1 Texel sampling for the code of Listing 5.8.1, showing the sample pattern\nwhen the texel marked by the X is being rendered. The vertex program's texture\ncoordinates as iterated in each texture unit T[0-3] are marked with dots. The hollow\ncircle marks where a sample of texture coordinate offiet (0.0, 0.0) would fall, illustrating\nthe need for the s_of f and t_of f half-texel offiets. Each texel is of dimension (si, tl)\naccording to Listing 5.8.1.\nListing 5.8.1. Code and vertex program for sampling each texel's\nneighbors\nRenderFullCoverageQuadO renders a single quad with input texture coordinates\nfrom 0.0 to 1.0 in each axis, which exactly covers the render target. These coordinates\nare offset four ways into the four output oT[0-3] texture coordinates so that as each\npixel is rendered, it draws upon neighboring texels for its result. All-caps variables are\n#defines to appropriate indices into vertex shader constant memory.\nfloat s1 = 1.0f / texture_resolution_x; // one texel width\nfloat t1 = 1.0f / texture_resolution_y; // one texel height\nfloat s_off = s1 / 2.Of; \n/ / t o sample texel center\nfloat t_off = t1 / 2.Of;\n// s,t,r,q offsets for 4 nearest neighbors (bilinear or point)\nfloat offset_al[4] = { -si + s_off, O.Of + t_off, O.Of,\nO.Of};\nfloat offset_a2[4] = { s1 + s_off, O.Of + t off, O.Of,\nO.Of};\nfloat offset_a3[4] = { O.Of + s_off, t1 \n+ t off, O.Of,\nO.Of};\nfloat offset_a4[4] = { O.Of + s_off, -t1 \n+ t_off, O.Of,\nO.Of};\n// s,t,r,q offsets for 8 surrounding neighbors (use bilinear)\nfloat offset_bl[4] = { s1/2.0f + s_off, tl \n+ t_off, O.Of,\nO.Of};\nfloat offset_b2[4] = { -s1 \n+ s_off, t1/2.0f + t_off, O.Of,\nO.Of};\nfloat offset_b3[4] = { -s1/2.0f + s_off, -t1 \n+ t_off, O.Of,\nO.Of};\n\n\n500 \nSection 5 Graphics Display\nfloat offset_b4[4] = { s1 \n+ s_off, -tl/2.0f + t_off, O.Of,\nO.Of};\nSetVShaderConstants((TO_BASE .. T3_BASE) + SET_A, offset_a1 ..\noffset_a4);\nSetVShaderConstants((TO_BASE .. T3_BASE) + SET_B, offset_b1 ..\noffset_b4);\nSetVShaderConstants( OFFSET_TO_USE, use_a ? SET_A : SET_B );\nRenderFullCoverageQuad();\nVertex Program\n; vO = vertex position\n; v1 = vertex texture coordinate\n; Transform vertex position to clip space. \n4-vec * 4x4-matrix\ndp4 OPOS.X, vO, C[ WORLDVIEWPROJJ) ]\ndp4 oPos.y, vO, C[ WORLDVIEWPROJ_1 j\ndp4 OPos.z, VO, C[ WORLDVIEWPROJ_2 ]\ndp4 OPOS.W, vO, C[ WORLDVIEWPROJ_3 ]\n; Read which set of offsets to use - set A or B\nmov aO.x, c[OFFSET_TO_USE ].x\n; Write S,T,R,Q coordinates to all four texture stages, offsetting\n; \neach by either offset_a(1-4) or offset_b(1-4)\nadd oTO, v1, c[ aO.x + TO_BASE ]\nadd oT1, v1, c[ aO.x + T1_BASE ]\nadd oT2, vl, c[ aO.x + T2_BASE ]\nadd oT3, v1, c[ aO.x + T3_BASE ]\nIt is important to note that for this case of rendering a full coverage quad to a\nbuffer with the same resolution as the source texture, a texture coordinate offset of\n(0,0) would sample from the upper left (lowest coordinate point) of each texel. To\nsample from the exact texel center, we must either add half a texel width and height to\nthe offset or move the quad by half a pixel in each axis. Listing 5.8.1 chooses to add\nhalf a texel width and height. It is essential to understand these half-texel offsets when\nusing bilinear filtering. Without this, the bilinear sample will grab potentially unde-\nsired neighbors and produce very different results. It is essential to test and know\nexactly where texture samples are placed for procedural texture algorithms to work as\nexpected. Conway's \"Game of Life\" described later in this gem makes a good test case.\nThe four resulting texture samples can be combined in the programmable pixel\nengine for various effects. By using the resulting image as a new source texture and\napplying the neighbor sampling again and again to create subsequent frames, a wide\nvariety of interesting texture animations is possible. If the four samples are averaged,\nthe result is a blurring of the source image. By introducing an additional (s,t) scrolling\namount to the offsets presented previously, we can blur and scroll a source image over\nsuccessive frames. As we blur and scroll, we can jitter the scrolling vector used in each\nframe and multiply each sample color by various RGBA values to fade or alter the\ncolor. If we supply a steady input to the blur and upward scroll by first rendering\n\n\n5.8 \nOperations for Hardware-Accelerated Procedural Texture Animation\n501\nA.\nTexture 1\nSource \"Embers\"\nblur + scroll \nblur + scroll\nTexture 2\nB.\nFIGURE 5.8.2 Fire and smoke animation using Listing 5.8.1 s offiets A with a scroll offset. The bright\n\"embers\" at the bottom are rendered to the texture each frame before blurring and scrolling upward.\nB) shows the progression of rendering operations.\nbright source pixels or \"embers\" in the bottom of the texture for each frame, the result\nis the fire and smoke effect of Figure 5.8.2. Using just two 128x128 32-bit textures,\nthis effect runs endlessly without repetition at over 500 frames per second on a mod-\nern graphics card. Because we cannot simultaneously render to a texture and use it as\na source, we must use two textures and ping-pong back and forth between them. One\nis used as the previous frame source, and the other as the current frame destination.\nRather than averaging neighbor samples to blur, we can compute the differences\nbetween samples and raise this to a power for high contrast. Using Listing 5.8.1's off-\nsets A and reducing the magnitude of the offsets to partially sample the center texel,\nwe can perform edge detection in a hardware pixel shader program, as implemented\nby Matthias Wloka [Wloka2000] and shown in Figure 5.8.3. Another curious\n\"frosted glass\" effect is produced by blurring the source and differencing this blur\nfrom the original image. Figure 5.8.3d shows the result of ( src DIFF ( src DIFF(\nBLUR(src))), where DIFF is the absolute value of the difference in RGB color.\nNeighbor sampling and differencing can also be used to implement the physics of\nheight-field-based water in successive render-to-texture operations. An algorithm for\nheight-field water with vertex geometry on the CPU is presented in Game Program-\nming Gems [GomezOO]. We can develop this into a series of rendering operations that\nuse textures to represent the water height, velocity, and force. Each texel takes the\nplace of a vertex in Gomez's implementation. Instead of sampling neighboring ver-\ntices on the CPU, we sample neighboring texels on the graphics processor. Our imple-\nmentation involves six textures. Two textures represent the height of the water as\n\n\n502\nSection 5 Graphics Display\na.\nc.\nFIGURE 5.8.3 Edge detection and image processing. A) is the original image. B) is the\nresult of an edge detection in programmable pixel hardware. C) shows a 50-percent blend\nof a and b. D) is the original minus the difference between the original and a blur of the\noriginal.\ngrayscale color values (height maps), with one texture for the heights at the current\ntime step and one for the heights at the previous time step. Similarly, two textures rep-\nresent the velocity of the water, and two are used to accumulate the nearest-neighbor\nforces acting on each texel. Figure 5.8.4 shows four frames in the progression of an\nanimation using this technique, and despite the use of six 256x256 32-bit textures\nand four rendering passes per time step, the animation maintains a rate of over 450\nFIGURE 5.8.4 Initial condition and three frames of height-based water animation in the pixel\nprocessing of a 3D accelerator. Six textures are used in generating subsequent time steps, although only\nthe output height texture is shown here.\n\n\n5.8 Operations for Hardware-Accelerated Procedural Texture Animation\n503\nFIGURE 5.8.5 Six state textures used for height-based water animation. Hm is height for the most\nrecent time step. Fl and F2 are used to accumulate the force that will act on each texel height. The\nresulting F2 is applied to the previous time step's velocity V^.;, and the resulting velocity Vm is\napplied to the height to create the height field at the next time step //w+/. Scale factors for \"mass\" and\n\"time\" that are multiplied into the texel values are not shown.\ntime steps per second. Figure 5.8.5 shows the progression of textures used in generat-\ning one time step.\nThe hardware used for this example operates internally on 9-bit per component\nsigned color values, and this gives rise to inaccuracy. Low bit values are easily lost, pro-\nducing rounding errors in the physics that cause the system to decay to zero or grow\nto saturation. The nearest-neighbor sampling can also produce high-frequency oscil-\nlation between texel values that appears as noise. These problems are lessened by\ndamping the system with blurring and adding a restoring force that pulls all heights\ngently to a midrange value. The blurring is accomplished by using bilinear filtering\nwith neighbor offsets slightly greater than one texel width or height. The system can\nbe driven by occasionally rendering seed droplets to the texture at random locations.\nBy experimenting with the scale factors at which blurring, force, and velocity are\napplied, a stable endless animation is not difficult to achieve.\nAnimated grayscale height maps are useful, but we can go a step farther and use\nnearest-neighbor sampling to create an RGB normal map from the grayscale map.\nThis normal map can then be used for realistic dot product bump mapping\n[Moller99]. The normal map can be created in a single render-to-texture pass on the\ngraphics processor, and this avoids costly CPU work, texture memory copies, and\ngraphics pipeline stalls. Creating normal maps in hardware this way is an elegant\nmeans of updating and animating the surface detail they represent. Grayscale height\nfeatures such as bullet holes, cracks, and so forth can be rendered into the height map\n\n\n504 \nSection 5 Graphics Display\nas the game is running, and this is then converted to a normal map on the fly. The\nconversion is comparable in speed to the fire and smoke effect discussed earlier. List-\ning 5.8.2 shows a pixel program for creating an RGB normal map from a grayscale\nheight map in a single pass on four-sample multitexture hardware. It uses an approxi-\nmation in normalizing the resulting RGB texels, and the result works very well for\nlighting and reflection calculations. Two passes and a dependent texture read opera-\ntion could be used to produce exactly normalized RGB vectors.\nUse texel offsets A from Listing 1.\nListing 5.8.2 Code for RGB normal map creation in hardware from a\ngrayscale height texture. The grayscale image is\nselected into all four texture stages, and offsets A from\nListing 5.8.1 are used.\nPixel Program;\n// Creates an RGB normal map from an input grayscale height map\n// Pairing of RGB and Alpha instructions is not used\n// \nNormal map parameterization is [0,1] so 0.5 = zero component\n// \nalong that axis (value of 127 stored in the texture).\n// \nRed \n= positive S axis\n// \nGreen = positive T axis\n// \nBlue = positive R axis (up out of page)\n// Declare pixel shader version\nps.1.1\ndef c5, 1.0, 0.0, 0.0, 1.0 \n// red mask for s axis component\ndef c6, 0.0, 1.0, 0.0, 1.0 \n// green mask for t axis component\ndef c4, 0.0, 0.0, 1.0, 1.0 \n// blue mask for r axis component\n// (blue = up out of texture)\ndef c2, 0.5, 0.5, 0.0, 0.0 \n// 0.5 bias for red & green\ndef c1, 1.0, 1.0, 0.0, 0.0 \n// color mask for red & green\nget colors from all 4 texture stages\nto = -s, 0\nt1 = +s, 0\nt2 = 0, +t\nt3 = 0, -t\n// Select source grayscale texture into all 4 texture stages\n// Sample all 4 texture stages\ntex to \n// to = RGBA texel at coordinate offset by\n// \n(-s, 0)\ntex t1 \n// t1 = (+s, 0)\ntex t2 \n// t2 = ( 0,+t)\ntex t3 \n// t3 = ( 0,-t)\n\n\n5.8 Operations for Hardware-Accelerated Procedural Texture Animation \n505\nsub_x4 rO, to, t1 \n// rO = (tO-t1)*4 = s axis height slope\n// Use _x4 to increase low contrast grayscale\n// input\nmul \nto, rO, c5 \n// to = rO * red mask = red component only\n// Use to as temp storage\nsub_x4 M, t3, t2 \n// r-1 = (t3-t2)*4 = t axis height slope\nmad \nrO, r-1, c6, to \n// rO = M.green + to = s and t result in\nred,green\nmul \nt1, rO, rO \n// t1 = square s and t components\n// Use t1 as temporary storage\ndp3_d2 n, 1-tl, c1 \n// rl.rgb = (1 - s\"2 + 1 - tA2 )/2\n// (1-s\"2) is approx sqrt(1-s*2) for small s\nadd rO, rO, c2 \n// rO = rO + 0.5 red + 0 . 5 green\n// shifts signed values to [0,1]\nmad rO, M, c4, rO \n// RGB = (r+0, g+0, 0+blue )\n// output = rO\nDependent Texture Addressing\nWe have seen that a simple multisample operation can go a long way to produce var-\nious effects. There are other more sophisticated and powerful texture operations at\nour disposal. Dependent texture address operations enable us to fetch texture samples\nfrom one texture based on the colors of another texture, or to fetch based on the dot\nproducts of iterated texture coordinates and texture colors. This gem covers only\none of the more simple dependent texture operations: the dependent green-blue\ntexture addressing operation expressed as DXS's texreg2gb instruction, or the\nGL_DEPENDENT_GB_TEXTURE_2D_NV extension to OpenGL.\nDependent green-blue addressing is a straightforward process. For the pixel being\nrendered, the hardware fetches the source texture's color at that pixel. The green com-\nponent of this color is used as the S (horizontal) coordinate of a fetch into another\ntexture. The blue component is used as the T (vertical) coordinate. Figure 5.8.6 illus-\ntrates this with a 3x3 source texture.\nTexture 2 can have any size relative to Texture 1; however, if Texture 1 holds 8-bit\ngreen and blue values, then any resolution of Texture 2 greater than 256 is pointless,\nas the fine resolution cannot be accessed by the coarse 8-bit values. Texture 2 provides\nan arbitrary lookup table for the Texture 1 input, and this can be used with render-to-\ntexture operations to run some very sophisticated programs entirely within in the\npixel hardware. We'll refer to Texture 1 as the \"input\" texture, and Texture 2 as the\n\"rules\" texture, because Texture 2 determines how an input color maps to a result.\nWith render-to-texture operations, we can use one or several texture maps to\nstore intermediate logic results. We can also generate the input and rules maps on the\nfly based on previous results or user input. As you can imagine, there's quite a lot of\nflexibility here, and we haven't even considered dependent alpha-red lookups or the\ndot product address operations! Since the green-blue addressing operation relies on\n\n\n506\nSection 5 Graphics Display\nG-B Addressing\nTexture 1 \nTexture 2 \nResult\nFIGURE 5.8.6 Dependent green-blue texture addressing. The Texture 1 source is sampled\nat the points indicated. Each texel of Texture 1 determines the coordinate at which to\nsample from Texture 2, the \"rules\" texture. The resulting color from Texture 2 is output as\nthe result.\nspecific texture colors that are probably not the best colors for displaying in a scene, it\nis a good idea (and trivial) to add a second dependent lookup into a color table. This\nsecond operation maps the results of the procedural texture to any RGBA values for\ndisplay in the scene. It creates a final output texture, so the user never sees the under-\nlying green-blue textures driving the calculations. Our final example involves com-\nbining neighbor sampling and dependent lookups to run Conway's \"Game of Life\"\non a graphics processor.\nConway's \"Game of Life\" in Hardware\nJohn Conway's \"Game of Life\" [Gardner70] is a popular cellular automata program.\nThough it does not at first seem relevant or of much use to the average computer\ngame, it is familiar territory in which to work, and the basic operations of running the\ngame on a graphics chip are applicable to other procedural techniques. The game can\nproduce interesting patterns of correlated noise that are useful in driving other effects;\nfor example, the embers in the fire and smoke effect shown previously. Implementing\nthis game on your own platform is a good way to verify that the hardware is doing\nexactly what you expect. The game has easily recognizable cyclical patterns and\ndepends sensitively on proper texel sample placement, making it easy to determine\nwhen you have your sampling correct.\nIn Conway's \"Game of Life,\" each cell begins as either \"on\" or \"off,\" which we\nrepresent by a texture map of white or black texels, respectively. The rules for creating\nthe next generation are, for every cell on the map:\n\n\n5.8 Operations for Hardware-Accelerated Procedural Texture Animation\n507\n1. If a cell is on and has two or three neighbors on, the cell remains on in the\nnext generation.\n2. If a cell is on and has fewer than two or greater than three neighbors on, the\ncell is turned off in the next generation.\n3. If a cell is off and has three neighbors on, the cell is turned on in the next\ngeneration.\nThe game requires that we sample eight neighbors and the center cell, and apply\nlogic to the result of the sampling. The OpenGL \"Red Book\" [Neider93] outlines a\ntechnique for running the game using a hardware stencil buffer, but we can imple-\nment it in a more flexible manner using fewer passes with hardware capable of depen-\ndent texture addressing.\nOur approach is to create a render target color buffer of the same resolution as the\nfield of cells. Beginning with black at each texel of this buffer, we render colors addi-\ntively from the source cell field for each of the eight neighbor texels and the center\ntexel. Each neighbor texel of the source is multiplied by 1/8 green and added to the\ndestination, and the center texel is multiplied by full blue and added in. In practice,\nwe use bilinear sampling and the B offsets of Listing 5.8.1 to sample two neighbors at\nonce, and multiply the sample by 1/4 green. A second pass samples, the center texel\nmultiplied by blue. The result is a color that encodes the condition of each source\ntexel in relation to the rules of the game. Each cell's neighbor count ranges from 0 to\nGreen channel\nneighbor count\nDependent green-blue\naddress operation\n(1,1)\nd. Rules map \ne\nFIGURE 5.8.7 Steps in the production of the next generation of cells in Conways \"Game of Life. \"A) is\nthe initial cell field. B) is the green component of the condition texture that is each 'cell's number of\nactive neighbors. C) is the blue component of the condition that reflects whether the cell is on or off.\nD) is an 8x2 pixel texture that encodes the rules of the game. E) is the resulting generation of cells\nthat will be used again as the new input a.\n\n\n508 \nSections Graphics Display\n1.0 in green, and the cell's \"on\" or \"off\" state is 0 or 1 in blue. Each green-blue texel is\nthen used as the input for a dependent green-blue address operation. The operation\nreads from an 8x2 pixel rules texture that determines the color (white or black) of the\ntexel in the next generation. This rules texture is black at all texels except those at\n(2,1), (3,1), and (3,0), which are white. These white pixels are those that the rules of\nthe game determine to be \"on\" in the next generation. Figure 5.8.7 shows an initial\ngeneration source texture, the green-blue condition rendered from it, the rules tex-\nture, and the subsequent generation produced.\nThis simulation depends on the source texels being white and the intermediate\nbeing green-blue. We could easily perform an additional dependent texture read from\nthe source or intermediate into an arbitrary color ramp to create a separate texture for\nuse in rendering the scene. Also, there is no need to limit the rules texture to 8x2 pix-\nels. Any size texture could be loaded, and this texture could encode highly complex\nrules, or rules that spawn pixels of any RGB value. See the online examples and source\ncode mentioned below for a glimpse of the possibilities.\nFuture Work\nAs graphics processors draw more texture samples per rendering pass, the 8-bit color\ncomponents and internal pixel processing operations of today's hardware are squeezed\nfor precision. It is all too easy to end up with color banding or other rendering arti-\nfacts. Future generations of hardware will almost certainly need higher precision for-\nmats, and with 16 or 32 bits per color component, there are great opportunities for\nhardware-accelerated procedural texture effects.\nProblems of limited precision were mentioned earlier in the water simulation. 16-\nbit floating point values would virtually eliminate these. Higher precision floating-\npoint values in textures and pixel calculations could enable fluid flow simulations and\nlattice grid-based Navier-Stokes algorithms to run in graphics hardware [Witting99].\nCPU implementations of these algorithms are already close to real time in special\neffects houses and graphics research. Increased precision of render target buffers will\nalso enable hardware-accelerated advanced lighting calculations that involve simple\nFresnel integrals, wave propagation, and diffraction effects [Feynman85][Stam99].\nCellular automata programs give rise to a wealth of interesting animations and\nrjatterns with various degrees of correlation. Cellular automata programs do have the\ndisadvantage of being difficult to control and engineer to a specific pattern or effect,\nbut collections of discovered programs and convenient browsing programs exist on\nthe Internet. Work on lattice gas automata (generally 2D surface simulations) may\nalso provide useful animated patterns.\nThe future of real-time procedural texturing and animation is filled with promise.\nThere is a vast landscape of techniques and effects to explore, and these certainly have\nthe power to bring added realism and variety to interactive 3D games.\n",
      "page_number": 477,
      "chapter_number": 49,
      "summary": "This gem covers a few fundamental operations for generating procedural anima-\ntions, and puts these to use in specific examples that simulate fire, smoke, water,\nor perform image processing Key topics include texture, sample, and colors.",
      "keywords": [
        "Texture",
        "Procedural texture animation",
        "procedural texture",
        "source texture",
        "Texture Animation",
        "texel",
        "Hardware-Accelerated Procedural Texture",
        "dependent texture",
        "texture coordinates",
        "texture addressing",
        "texture coordinate offset",
        "texture samples",
        "offset",
        "Operations",
        "source"
      ],
      "concepts": [
        "texture",
        "sample",
        "colors",
        "operations",
        "operates",
        "operation",
        "animation",
        "animations",
        "animated",
        "neighbor"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 3",
          "chapter": 46,
          "title": "Segment 46 (pages 440-447)",
          "relevance_score": 0.62,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 3",
          "chapter": 47,
          "title": "Segment 47 (pages 448-455)",
          "relevance_score": 0.58,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 7",
          "chapter": 48,
          "title": "Segment 48 (pages 468-478)",
          "relevance_score": 0.58,
          "method": "sentence_transformers"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 23,
          "title": "Segment 23 (pages 441-462)",
          "relevance_score": 0.56,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 3",
          "chapter": 45,
          "title": "Segment 45 (pages 431-439)",
          "relevance_score": 0.55,
          "method": "sentence_transformers"
        }
      ]
    },
    {
      "number": 50,
      "title": "Segment 50 (pages 490-497)",
      "start_page": 490,
      "end_page": 497,
      "detection_method": "topic_boundary",
      "content": "5.8 Operations for Hardware-Accelerated Procedural Texture Animation \n509\nAcknowledgments\nSpecial thanks to Matthias Wloka for his work on multisampling and hardware image\nconvolution, and to my co-workers at Nvidia for inspiring and enabling such amazing\ngraphics hardware.\nCode Samples\nDirectX 8 code for the preceding examples is posted on Nvidia's public Developer\nWeb site (www.nvidia.com/Developer/DX8) for you to download and experiment\nwith. The samples can be run in the DX8 SDK's reference rasterizer or on hardware\nthat supports DX8 Vertex Shaders vl.l and Pixel Shaders vl.l.\nReferences \n_\n[Ebert98] Ebert, David S., et al, Texturing and Modeling: A Procedural Approach, Aca-\ndemic Press, 1998 [ISBN 0-12-228739-4].\n[DXS'OO] Microsoft Corporation, DirectXS SDK, available online at http://msdn\n.microsoft.com/directx/, November, 2000.\n[NVExt2001] Nvidia Corporation, \"Nvidia OpenGL Extensions Specifications\"\n(nvOpenGLSpecs.pdf). available online at www.nvidia.com/opengl/OpenGLSpecs,\nMarch 2001.\n[Wloka2000] Wloka, Matthias, \"Filter Blitting,\" available online at www.nvidia.com\\\nDeveloper/DX8, November 2000.\n[Gomez2000] Gomez, Miguel, \"Interactive Simulation of Water Surfaces,\" Game\nProgramming Gems, Charles River Media Inc., 2000: pp. 187-194.\n[Moller99] Moller, Tomas, and Haines, Eric, Real-Time Rendering, A K Peters, Ltd.,\n1999.\n[Gardner70] Gardner, Martin, \"Mathematical Games,\" Scientific American, vol. 223,\nno. 4, October 1970, pp. 120-123.\n[Neider93] Neider, Jackie, et al, OpenGL Programming Guide, Addison-Wesley Pub-\nlishing Co., 1993: pp. 407^409.\n[Witting99] Witting, Patrick, \"Computational Fluid Dynamics in a Traditional Ani-\nmation Environment,\" Computer Graphics Proceedings (SIGGRAPH 1999) pp.\n129-136.\n[Feynman85] Feynamn, Richard P., QED: The Strange Theory of Light and Matter,\nPrinceton University Press, 1985, pp. 37-76. Although he does not label it a\n\"Fresnel integral,\" this is the name for the calculation he explains in Chapter 2.\nThis powerful mathematics accounts for all phenomena in the propagation of\nlight by a large sum of a few simple terms.\n[Stam99] Stam, Joe, \"Diffraction Shaders,\" Computer Graphics Proceedings (SIG-\nGRAPH 1999) pp. 101-110.\nGomez, Miguel, \"Implicit Euler Integration for Numerical Stability,\" Game Program-\nming Gems, Charles River Media Inc., 2000: pp. 117-181.\n\n\n6.1\nBridge\nGame Audio Design Patterns\nScott Patterson\nscottp@tonebyte.com\nD\nesign pattern concepts have achieved great popularity in recent years. Really,\ndesign patterns have been in use for a long time, and recently we have been get-\nting better at categorizing and identifying them. Object-oriented programming lan-\nguages are commonly associated with design pattern implementations, but even\nprogramming languages that are not identified as object oriented can provide effective\nobject pattern implementations. Design patterns can also serve as an inspiration when\nbuilding a code system. In this gem, we will use them as an inspiration for an audio\ninterface design. This discussion assumes that we are audio interface designers and\nour clients are game programmers. We want to supply an audio interface to our\nclients that is convenient, flexible, and powerful. We will present brief summaries of\nsome design patterns and how we can relate them to audio interface design.\n\"Decouple an abstraction from its implementation so that the two can vary\nindependently.\"\nSound Identifiers\nAn effective way of decoupling an abstraction from its implementation is to pass iden-\ntifiers rather than things such as class pointers or references. Identifiers can be defined\nas numbers or strings. Since we are talking about audio, we are talking about an iden-\ntifier for each particular sound. We can start and stop a sound by passing its identifier.\nHow the audio system actually does the work to start and stop the sound is com-\npletely decoupled from the client of our API.\nvoid StartSound( int nSoundld );\nvoid StopSound( int nSoundld );\nAlso hidden is the way in which sounds are loaded and accessed. We can provide\nsimilar calls to load and unload a particular sound.\nvoid LoadSound( int nSoundld );\nvoid UnloadSound( int nSoundld );\n514\n\n\n6.1 Game Audio Design Patterns \n515\nPerhaps more useful is yet another identifier system for collections of sounds.\nNow we can load and unload many sounds at a time.\nvoid LoadSoundCollectionf int nSoundCollectionld );\nvoid UnloadSoundCollection( int nSoundCollectionld );\nIt may be useful to know if a sound is currently loaded,\nbool IsSoundLoaded( int nSoundld );\nIf we try to start a sound that is not loaded, the response could be to play no\nsound or play an error sound.\nFacade\n\"Provide a unified interface to a set of interfaces in a subsystem. Facade defines a\nhigher-level interface that makes the subsystem easier to use.\"\nSubsystem Control\nWhen writing an audio API for game programmers to use, the goal is to hide any\ntedious complexity of the audio system and cover the needs of all parts of the game.\nWriting an API with this type of goal is much like designing a class with the Facade\ndesign pattern. The complexity of the audio system is hidden from the complexity of\nthe game code, and the connection between the two systems is our API.\nWe may have more than one method available to produce sounds, but having the\nsame interface to control these sounds makes the audio subsystem easier to use. Calls\nto set and get master volume may look simple enough, but actually may update more\nthan one audio subsystem internally.\nfloat SetMasterVolume( float fVolume );\nfloat GetMasterVolumeO;\nAudio subsystems related to hardware synthesis, software synthesis, and stream-\ning code may all be updated from calls such as these, but this complexity is hidden.\nSimilar complexity may be hidden in a call that stops all sounds currently playing.\nvoid StopAllSounds();\nComposite\n\"Compose objects into tree structures to represent part-whole hierarchies. Composite\nlets clients treat individual objects and compositions of objects uniformly.\"\nEngine Control\nSomething like a car engine may actually be composed of many different sounds.\nThere may be rumbles, whines, clanks, and sputters all happening in concert. The\n\n\n516 \nSections Audio Programming\nvolume and pitch and other parameters of these sounds may be mapped to various\ngame parameters such as engine type, throttle level, power level, current speed, and\nmany others. In this case, we may want to hide this complexity and provide functions\nspecific to the type of engine we are controlling.\nvoid StartEngine( Carlnstance_t *pObject );\nvoid UpdateEngine( Carlnstance_t *pObject );\nvoid StopEnginef Carlnstance_t *pObject );\nNow the internal audio code can interpret the states and parameters available in\nthe given Carlnstance_t object and translate them into the control of one or more\nsounds. Our client is able to treat engine control the same way, whether we are con-\ntrolling an individual sound object or compositions of sound objects.\nAmbience Control\nControl of ambient sounds can also be a situation that exhibits composite behavior. If\nwe want to simulate an environment such as a jungle, we may be randomly playing\nmany animal sounds. In this case, we may not have a structure in the game called\nJungle_t, but we may know our distance from the jungle area and how excited the ani-\nmals are.\nvoid Start Jungle ( float f Distance, float f Activity );\nvoid UpdateJungle( float f Distance, float f Activity );\nvoid StopJungle() ;\n\"Provide a surrogate or placeholder for another object to control access to it.\"\nHandles\nHandles provide just such a placeholder for another object to control access through.\nWhen we start a particular instance of a sound, we may want to continue to control\nthat instance over time. Our control parameters may be anything from 3D position\ninformation to direct control over things such as volume, pitch, pan, or effects. Our\nstart function returns a handle, and our update and stop functions use this handle to\naccess the sound instance.\nHandle_t StartHandledSound( int nSoundld, const ControlParamsjt &cp) ;\nvoid UpdateHandledSound( Handle_t hSound, const ControlParams_t &cp) ;\nvoid StopHandledSound( Handle_t hSound );\nA discussion on handles can be found in [BilasOO] .\n\n\n6.1 Game Audio Design Patterns \n517\nDecorator\n\"Attach additional responsibilities to an object dynamically. Decorators provide a flex-\nible alternative to subclassing for extending functionality.\"\nUser Data\nOne way to allow dynamic responsibilities and associations to be given to an object is\nto provide user data access. If we provide a user data field that clients can set per\ninstance of a sound, we can help clients link other responsibilities with sound\ninstances. We can add user data access functions to our handled sound interface.\nvoid SetHandledSoundUserData( Handle_t hSound, UserData_t User-Data );\nUserData_t GetHandledSoundUserData( Handle_t hSound );\nCallbacks\nWe can also provide a callback field that clients can set per instance of a sound. This\ncallback could be defined to be triggered when a sound loops or has played for a cer-\ntain amount of time.\nvoid SetHandledSoundCallback( Handle_t hSound, CallbackFuncPtr_t pCB );\nvoid ClearHandledSoundCallback( Handle_t hSound );\nCommand\n\"Encapsulate a request as an object, thereby letting you parameterize clients with dif-\nferent requests, queue or log requests, and support undoable operations.\"\nCommand Queues\nWe can put some or all calls to our audio API in a command queue that is processed\nonce per game frame. We could look through this queue to determine if the same\nsound is being called more than once per frame, or whether a sound has been started\nand stopped before it had a chance to play. Viewing this queue can provide an impor-\ntant aid during debugging.\nSpeech Systems\nA speech system benefits from command queuing. Since more than one character\nmay want to talk at one time, we can look through the queue of requests to determine\nwho should speak next. There may also be times when we want to stop any further\nspeaking so we clear the queue.\nvoid PostSpeechRequest( int nSpeakerld, int nPhrase );\nvoid ClearSpeechQueue();\n\n\n518 \nSections Audio Programming\nMemento\n\"Without violating encapsulation, capture and externalize an object's internal state so\nthat the object can be restored to this state later.\"\nPause and Restart\nWhen we want to pause all sounds, we could return a handle to a state that can be\nused to restart those sounds later.\nStateHandle_t PauseAllSounds();\nvoid RestartAllSounds( StateHandle_t hState );\nObserver\n\"Define a one-to-many dependency between objects so that when one object changes\nstate, all its dependents are notified and updated automatically.\"\nDynamic Types\nIf we can pass a type number to a sound that we are starting, we could later reference\nthat sound and any others that have been given the same type. For example, if we start\nall the sounds for a particular character with the same type number, then we can later\nturn off those sounds with one call.\nvoid StartSoundWithTypef int nSoundld, int nTypeld );\nvoid StopAllSoundsWithType( int nTypeld );\nWe can also update all sounds of a particular type,\nvoid UpdateSoundsWithType( int nTypeld, const ControlParams_t &cp);\nWe can also associate behaviors such as default priority and default volume with\ntypes.\nvoid SetDefaultPriorityForType( int nTypeld, int nDefaultPriority );\nvoid SetDefaultVolumeForType( int nTypeld, float fDefaultVolume );\nIt is assumed here that a priority system is in place to determine which sounds\nshould play if limited buffers are available.\nBig Ball Of Mud \n(also known as Spaghetti Code)\nThe last design pattern I want to mention is the Big Ball of Mud. The paper with this\ntitle, written by Brian Foote and Joseph Yoder, is a witty and insightful categorization\nof patterns that can creep into a project quite naturally. In a way, the Big Ball of Mud\nis the pattern we all want to avoid, but conversely it is a pattern that may be impossi-\nble to avoid. Therefore, the wisdom here is that whether you know design patterns or\n\n\n6.1 \nGame Audio Design Patterns \n519\nnot, you may be implementing the patterns that can lead to a Big Bull of Mud any-\nway, namely: Throwaway Code, Piecemeal Growth, Keep It Working, Shearing Lay-\ners, and Sweeping It Under the Rug.\nSo, how does the Big Ball of Mud pattern relate to audio and game program-\nming? Our first goal might be to keep our audio system's internal code from being a\nBig Ball of Mud. Our second goal might be to keep the rest of the game code from\nbeing a Big Ball of Mud. We have some influence over the code organization by pro-\nviding useful features in our audio API. We can also provide API features to help\ndebug audio problems. Therefore, even if Mud prevails, our audio API can provide\nfeatures for swamp navigation.\nStatus Functions\nProviding status functions can help us find common problems. We can return specific\nvalues in response to specific requests such as the number of voices playing. We can\nalso return a string ready for display in response to more general requests such as\nsound status.\nint \nGetNumberOfSoundsPlayingO;\nbool IsSoundPlaying( int nSoundld );\nstring GetAudioStatusO;\nvoid GetDescriptionsOfSoundsPlaying( list<string> &Stringl_ist );\nLogging Functions\nWe can provide a logging system that records audio system activity. The logging\nrecords could be directed to different types of output such as stdout or a file or a dis-\nplay. We can also provide a detail-level control to determine how much information is\nrecorded. One detail level might just record all audio API calls and parameters passed.\nAnother detail level might include internal sound buffer allocation information and\nother internal state information.\nvoid EnableLogging();\nvoid DisableLogging();\nvoid SetLoggingDetailLevel( int nDetailLevel );\nvoid SetLoggingOutputType( int nOutputType );\nSystem Disable\nSometimes the easiest way to determine if the audio system is causing problems with\nthe game is to disable the audio system completely. When the audio system is dis-\nabled, all calls to audio API functions simply do no work. If problems still persist after\ndisabling the audio system, then we can eliminate it as a cause. Disabling a system\nsuch as this can also make some game debugging situations less complicated.\nvoid AudioSystemEnable();\nvoid AudioSystemDisable();\n\n\n520 \nSection 6 Audio Programming\nConclusion\nUsing design patterns as an inspiration, we have outlined useful features for a game\naudio API. Whether we are revving engines, on a jungle safari, or just navigating the\nswamps, we want to make our clients happy.\nReferences\n[Gamma94] Gamma, et al., Design Patterns, Addison-Wesley Longman, Inc., 1994.\n[Foote99] Foote, Brian, and Yoder, Joseph, Big Ball of Mud, www.Taputan.org/mud/\n[BilasOO] Bilas, Scott, \"A Generic Handle-Based Resource Manager,\" Game Program-\nming Gems, Charles River Media, 2000: pp. 68-79.\n",
      "page_number": 490,
      "chapter_number": 50,
      "summary": "This chapter covers segment 50 (pages 490-497). Key topics include void, sound, and game. Code Samples\nDirectX 8 code for the preceding examples is posted on Nvidia's public Developer\nWeb site (www.nvidia.com/Developer/DX8) for you to download and experiment\nwith.",
      "keywords": [
        "Procedural Texture Animation",
        "Texture Animation",
        "Game Audio Design",
        "Audio",
        "Audio Design Patterns",
        "Hardware-Accelerated Procedural Texture",
        "audio API",
        "void",
        "Design Patterns",
        "audio system",
        "Game Audio",
        "Game",
        "Sound",
        "Big Ball",
        "Audio Design"
      ],
      "concepts": [
        "void",
        "sound",
        "game",
        "programming",
        "program",
        "function",
        "functionality",
        "audio",
        "code",
        "handles"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 8",
          "chapter": 53,
          "title": "Segment 53 (pages 511-519)",
          "relevance_score": 0.68,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 7",
          "chapter": 63,
          "title": "Segment 63 (pages 609-616)",
          "relevance_score": 0.62,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 52,
          "title": "Segment 52 (pages 499-510)",
          "relevance_score": 0.62,
          "method": "sentence_transformers"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 3,
          "title": "Segment 3 (pages 42-63)",
          "relevance_score": 0.61,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 7",
          "chapter": 62,
          "title": "Segment 62 (pages 601-608)",
          "relevance_score": 0.59,
          "method": "sentence_transformers"
        }
      ]
    },
    {
      "number": 51,
      "title": "Segment 51 (pages 498-505)",
      "start_page": 498,
      "end_page": 505,
      "detection_method": "topic_boundary",
      "content": "6.2\nA Technique to Instantaneously\nReuse Voices in a\nSample-based Synthesizer\nThomas Engel, Factor 5\ntengel@factor5.com\nS\nynthesizers typically offer a limited number of voices that can be active at any\ngiven time, so complex allocation schemes are used to make the best use of the\nvoices that are available. Allocating a voice at any given time is easy as long as free\nvoices are available, but becomes quite tricky when this is not the case, requiring voices\nto be reused. The difficulty results from the amplitude difference between the current\nactive sample and the next sample to be played, resulting in a sharp pop or click sound\n(see Figure 6.2.1). This gem presents a technique to accomplish this without any\nmajor calculation time or memory overhead.\nFIGURE 6.2.1 The amplitude difference between samples can create a distracting click.\nThe Problem\nTo reuse an active voice for playback of another sample, you might try slowly lower-\ning the volume of the current sample and immediately starting the playback of the\nnew sample. This would nicely avoid any clicks or pops caused by abruptly stopping\nthe old sample, and would start the new sample prompdy.\n521\n\n\n522\nSection 6 Audio Programming\nThis is unfortunately not very practical since two voices are needed to handle this\nproperly—and all this at a time when voices are no longer available. A possible solu-\ntion to this problem would be to reserve a number of voices for just this case. Unfor-\ntunately, this also has major drawbacks. First, hardware resources are lost since you\nhave to guarantee the availability of some extra voices at all times. Second, the num-\nber of voices that could be reallocated at once would be limited by the number of\nextra voices reserved for this purpose, making this a rather impractical solution.\nYou can remove the need for two voices by serializing the method: first fade out\nthe old sample, and then start the new sample on the same voice. This delays the start\nof the new voice and lowers the volume of the old voice quite a bit earlier than one\nwould like. It also can be very problematic when playing back a musical composition\nbecause the delay is very noticeable. The effect of the delay can be minimized by\ndelaying all voice starts, no matter if reusing voices or not. This nevertheless intro-\nduces an extra global delay to the audio pipeline, and makes it more difficult to\nhandle the voices due to added complexity.\nA more elegant solution is needed.\nAn Idea for a Solution\nThe basic idea for the solution is found within a simple question, or rather, the answer\nto it: What is sound? Answer: sound is a change in air pressure and, therefore, a\nchange in the amplitude of the output signal. A constant output signal, no matter\nwhat the amplitude, will not be audible. Reallocating a voice results in a sudden,\nunwanted change in amplitude that generates a sharp pop sound. This sound would\nalso be audible if one were to switch off the old sample even without starting a second\nsample.\nThe idea now is not only to stop any change or oscillation of the old sample, but\nalso to keep its last amplitude active in the output sum. A single sample being stopped\nwould look something like Figure 6.2.2.\nThis output would not generate any click or pop since there is no sudden ampli-\ntude change.\nFIGURE 6.2.2 Holding the last amplitude from a sample prevents an undesiredpop\nsound.\n\n\n6.2 A Technique to Instantaneously Reuse Voices In a Sample-based Synthesizer \n523\nThe Solution\nThe effect outlined previously can be put to good use to solve our problem. Halting\nthe oscillation of a voice but not dropping its last amplitude simplifies things quite a\nbit, since all logic concerned with fetching new samples or handling the pitch for the\nold voice can be dropped as soon as the new sample is started.\nThe output would look something like Figure 6.2.3.\nFIGURE 6.2.3 Starting the second sample at the final amplitude of the first.\nThis has an obvious drawback: by simply halting the old voice we introduce a\npotentially high DC offset to the output signal, which, due to the limited maximum\namplitude of the output sample, may cause the output quality to drop significantly\nbecause of clipping artifacts.\nTwo simple approaches can limit, and, in most cases, completely remove such\nartifacts. First, one should use a mix buffer of more than 16 bits to generate the final\noutput signal. This extends the maximum amplitude, which can be internally han-\ndled. Since the DC offset will be handled together with other voices that again can\nlower the amplitude, this actually reduces artifacts quite dramatically. The most\nimportant step nevertheless is to lower the DC offset quickly to zero. One basically\nhas to fade out the halted old sample (Figure 6.2.4).\nAll this would still require separate logic to handle the halted old sample for each\nvoice to avoid limiting the number of voices that can be reused at once. But is this\nreally true? In fact, one could handle all DC offsets introduced by voices being reused\nin one very simple handler.\nFIGURE 6.2.4 Fading the initial sample to zero.\n\n\n524\nSection 6 \nAudio Programming\nThe logic is as follows: each time a voice is reused, the last value mixed into the\nsum by the old sample on this particular voice will be added to a global DC offset\nvalue. This value in turn will be added to the output signal once all voices are\nprocessed.\nTo get rid of this DC offset, which as outlined previously is necessary but\nunwanted, one lowers the DC offset sum on a per-sample basis over a certain time.\nThis can be very efficiently done and does not introduce any further artifacts if not\nperformed too rapidly. A period of about five milliseconds is usually slow enough to\nlower even a full amplitude DC offset to zero (Figure 6.2.5).\nFIGURE 6.2.5 Fading the initial sample to zero while playing the second sample.\nConclusion\nIn practice, the theoretical negative side effects caused by the DC offset are close to\ninaudible. One would have to reuse extreme numbers of voices at high amplitudes to\nachieve some audible effect when using at least a 24-bit mix buffer.\nAt the same time, the benefits of this method are huge. One can reuse a voice on\na moment's notice with no delay and with no audible artifacts in the output signal.\nThe overhead needed to implement this method is minimal. The method can, widi\nsome extra work, be used in systems that feature multichannel hardware playback of\nsamples. Just one voice has to be set aside to contain the DC offset values to be added\nin the form of a sample data stream generated by the CPU following the algorithm\noutlined in this gem.\n\n\n6.3\nSoftware-based DSP Effects\nfan Lewis, Acclaim Studios\nilewis@acclaim.com\nT\nhis gem introduces basic DSP concepts and techniques that can be cheaply\nimplemented on today's PCs and next-generation consoles, including filtering,\nconvolution, delay, and interpolation.\nDSP Technique\nFiltering\nPurpose\nOcclusion and 3D sound effects\nPhysical modeling effects such as strain on engines\nConvolution\nDelay\nInterpolation\nHead-Related Transfer Functions (HRTFs)\nAccurately simulating real acoustic spaces\nEchoes from walls or terrain\nPitch shifting\nSample rate conversion\nFiltering\nFiltering is actually a special case of convolution, but merits its own section because it\nis far simpler to implement quickly than general convolution.\nTo filter an audio signal is to emphasize or deemphasize certain frequency com-\nponents, much like the \"bass\" and \"treble\" knobs on your stereo. The effect of this is\nextremely difficult to see on a graph of the waveform, but is immediately recognizable\nto the ear. For instance, applying a low-pass filter tends to make the wave sound muf-\nfled, and applying a high-pass filter tends to make the wave sound thin.\nThe general form of a filter is a loop where a set of values (filter coefficients) are\nmultiplied with the incoming samples, and then added together. The first filter coef-\nficient is multiplied with the current sample, the second with the previous sample,\nand so forth, so the code looks something like this:\nfor (k = 0; k < nCoefficients; k++)\n{\noutput+=coefficient[k] * (*(input-k));\n525\n\n\n526 \nSection 6 Audio Programming\nThis type of filter is called an FIR, or Finite Impulse Response filter, because its\noutput will always decay to zero in a predictable amount of time after the input decays\nto zero. A slightly less acoustically \"stable,\" but more powerful filter is the IIR, or Infi-\nnite Impulse Response filter. This design feeds the filter outputs back into the input\nin a form something like this:\nfor (k = 0; k < nCoefficients; k++)\n{\noutput+=coefficient[k] * input[n-k] +\nfeedback_coefficient[k] * previousOutput[n-k];\n}\nAfter each sample is computed, of course, the contents of the previous Output[]\narray are shifted up by one, and the current output is placed into the bottom position.\nThis looks more complex, but the upside is that the number of coefficients can be\nmuch smaller than the equivalent FIR implementation.\nAlthough there are hundreds of filters available, most have musical purposes and\ntend to be more complex than what you need for games. The sample code uses a vari-\nant of the music-DSP source code archive's simple Chamberlin filter [DeJongOl],\nwhich in its full form provides a high pass, low pass, notch, and bandpass filter that is\nextremely cheap and easy to implement.\nFilters work really well with SIMD hardware and even vector hardware, because\nthey're nothing but strings of multiply-accumulates.\nConvolution\nConvolution is the process of taking two signals and multiplying them together so\nthat the first signal takes on the characteristics of the second. For instance, say you\nhad a level set in an old cathedral. You could literally make a recording of an\n\"impulse\" (a very short sound spike, like a balloon popping) in any handy Gothic\ncathedral, convolve that impulse with your game sounds, and presto!—your game\nsounds like it's inside that very cathedral. Unfortunately, convolution is extremely\nexpensive—mostly because each output sample is the sum of one input sample multi-\nplied by ALL of the impulse samples. To understand the code, think of each sample in\nthe impulse file as being a coefficient in the FIR filter described earlier. This only\nreally works for very short impulses.\nA good collection of short impulses is the set of Head Related Transfer Functions\n(HRTFs) available at the MIT media lab [Gardner94]. Convolving with the appro-\npriate HRTF gives the illusion of placing the sound in three-dimensional space.\nA faster method of convolution involves translating both signals into the fre-\nquency domain (where each sample represents a frequency like on a spectroscope,\nrather than an amplitude like on an oscilloscope) using the Fast Fourier transform\n[Press92]. This can be useful if you're already storing samples in the frequency\ndomain. Some methods of compression do use the FFT or one of its variants; for\n\n\n6.3 Software-based DSP Effects \n527\ninstance, MP3 compression uses a variant called the Discrete Cosine Transform\n(DCT).\nA digital delay is probably the easiest DSP effect to generate. It takes very little CPU,\nbut it does require some RAM. The algorithm is simple: for each sample, push a copy\nof the sample onto a queue or circular buffer. Then read the oldest sample out of the\nbuffer and mix it with the output.\nDelayBuffer.push(input);\nOutput=input + DelayBuffer.pop() * delayGain;\nThe length of the buffer determines the length of the delay. Usually you'll want to\nscale the delay volume by some factor (delayGain in the preceding example). A simple\ndelay can add an echo to a big outdoor scene, for instance.\nMore interesting delays are regenerative. In a regenerative delay, the scaled delay\noutput samples are fed back into the delay buffer, producing a multiple echo effect\nthat more accurately simulates natural spaces. Since the gain of each sample is reduced\nevery time it gets recycled, eventually the echoes die away into nothing. The time it\ntakes for the delay to die away is determined by the amount of attenuation you apply\nto each sample. Apply a lot, and you get a \"slap-back\" effect with very little presence,\nlike you would at the edge of a canyon or near the wall of a very large building. Apply\nless attenuation, and you get a dense stream of echoes more like what you'd hear\ninside a cathedral or an echoing cavern.\nAn even more sophisticated reverb effect is the multi-tap reverb. In the multi-tap\nalgorithm, a copy of the input sample is not only pushed onto the tail of the delay\nbuffer, but inserted into other locations (\"taps\") in the buffer as well. This allows for\nmuch denser echoes and more realistic effects. For instance, a sound made in a large\nrectangular room might be pushed into the delay buffer four times, one for each wall\nthe sound bounced off. The exact position of each tap in the buffer could be dynam-\nically determined based on how far the source of the sound is from each wall.\nThe ultimate in spatial realism comes from DSP reverberation algorithms, which\nare an even more complex variation on the basic delay theme. Reverberation algo-\nrithms are generally too expensive to implement in software. With a growing trend to\nimplement hardware reverb processors on PC soundcards (for example, Creative's\nEAX extensions) and next-generation game consoles, this article will not try to\ndescribe reverb algorithms in depth.\nInterpolation\nInterpolation is the art of determining values for nonexistent samples, based on the\nvalues for known samples. That might seem a little esoteric, but the principle is one\nyou use all the time in many areas of game programming. For instance, bilinear\n\n\n528 \nSection 6 Audio Programming\ntexture filtering is a form of interpolation, where you might use as few as 4 or 5 texels\nto cover 10 or 20 onscreen pixels. Resampling is the primary use of interpolation in\naudio. One of the most effective ways to compress audio is to reduce its sample rate,\nespecially if the audio contains very few high-frequency components.\nSample-rate conversion (and pitch shifting, which is by and large the same thing)\ncan use one of several algorithms. They are listed here from least to most expensive:\n• Sample doubling, used when the ratio between the target sample rate and the\nsource sample rate is a multiple of two.\n• Sample averaging, where the target sample is computed to be the average of the\nvalues of the two closest points.\n• Linear interpolation, similar to sample averaging except that the average is\nweighted—more weight is given to the value of the closer point.\n• \nCubic interpolation, where the nearest 3-7 points (reportedly 5 points gives the\nbest results [DeJongOl]) are approximated using a spline function, and the value\nof the target point is the value of the spline at that point.\nCubic interpolation does give a decidedly better result than the other forms of\nresampling, although surprisingly, all of the other forms sound about the same. In a\ncase where the resample ratio is not a power of 2, simple sample averaging is the best\nchoice if CPU cycles are at a premium. This gives a reasonable result for pitch shifting\nwhere the ratio between the source and target sample rates is between .75 and 1.5.\nCubic sampling can get you higher ratios without sounding terrible, but no simple\nresampling algorithm will ever avoid the dreaded \"Mickey Mouse\" effect. To get rid of\n\"Mickey Mouse,\" you've got to do formant-corrected pitch shifting, which involves\nsome extremely complicated calculations that are far beyond the scope of this gem.\nReferences\n[BoresOl] \"Bores Signal Processing. Introduction to DSP,\" www.bores.com/courses/\nintro/ (4 March 2001)\n[DeJongOl] Dejong, Bram, \"The Music-DSP Source Code Archive,\" www.\nsmartelectronix.com/musicdsp/ (4 March 2001)\n[Gardner94] Gardner, Bill, and Martin, Keith (1994). \"HRTF Measurements of a\nKEMAR Dummy-Head Microphone.\" MIT Media Lab, http://sound.media\n.mit.edu/KEMAR.html (4 March 2001).\n[Iowegian99] lowegian International Corp. (1999), DSPGuru, www.dspguru.com/\n(4 March 2001).\n[Kosbar98] Kosbar, Kurt L. (1998), \"Introduction to Digital Signal Processing\n(DSP),\" www.siglab.ece.umr.edu/ee301/dsp/intro/index.html (4 March 2001).\n[Press92] Press, William H., et al, Numerical Recipes In C, Cambridge University\nPress, 1992, www.ulib.org/webRoot/Books/Numerical_Recipes/ (4 March 2001).\n[SprengerOl] Sprenger, Stephan M, \"The DSP Dimension,\" www.dspdimension\n.com/(4 March 2001).\n",
      "page_number": 498,
      "chapter_number": 51,
      "summary": "This gem presents a technique to accomplish this without any\nmajor calculation time or memory overhead Key topics include sample, sampling, and filtering.",
      "keywords": [
        "sample",
        "Voices",
        "output",
        "output signal",
        "delay",
        "delay output samples",
        "sound",
        "amplitude",
        "DSP",
        "filter",
        "output sample",
        "Sample rate",
        "signal",
        "time",
        "effect"
      ],
      "concepts": [
        "sample",
        "sampling",
        "filtering",
        "filter",
        "sound",
        "effect",
        "delays",
        "output",
        "voices",
        "march"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 7",
          "chapter": 39,
          "title": "Segment 39 (pages 361-371)",
          "relevance_score": 0.54,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 52,
          "title": "Segment 52 (pages 499-510)",
          "relevance_score": 0.54,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 7",
          "chapter": 37,
          "title": "Segment 37 (pages 345-352)",
          "relevance_score": 0.51,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 3",
          "chapter": 65,
          "title": "Segment 65 (pages 610-617)",
          "relevance_score": 0.5,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 3",
          "chapter": 63,
          "title": "Segment 63 (pages 593-601)",
          "relevance_score": 0.48,
          "method": "sentence_transformers"
        }
      ]
    },
    {
      "number": 52,
      "title": "Segment 52 (pages 506-515)",
      "start_page": 506,
      "end_page": 515,
      "detection_method": "topic_boundary",
      "content": "6.4\nInteractive Processing\nPipeline for Digital Audio\nKeith Weiner, DiamondWare Ltd.\nkeith@dw.com\nIntroduction\nAlgorithms for Digital Signal Processing (DSP) have been readily available for a long\ntime. Games haven't used them much, probably because of the high CPU cost. Today,\nhowever, gigahertz processors are cheap and are getting cheaper. They allow room for\na certain amount of audio processing, even after the graphics engine, AI engine, and\nphysics engine all get their share.\nGames (and other applications) have a need for an audio processing pipeline. The\ngoal is to allow a set of DSP functions with corresponding parameters to be specified\nfor a sound. Other sounds may pass through a different set of DSP functions and/or\nuse a different set of parameters.\nA block diagram of an audio system is shown in Figure 6.4.1. A full architecture\nwould stream sounds from any source, decrypt if necessary, decompress if necessary,\nprocess, mix, and then output. This gem describes the block labeled \"Processing.\"\nThis gem presents a lightweight, but general-purpose architecture. \"General pur-\npose\" is meant in two respects here. First, it allows any type of processing, even a\nspeed changer. Speed changers are tricky because they necessitate a buffer length\nchange. It gets even trickier if you want to allow parameter changes on the fly. Second,\nit's completely OS independent, and could be used on Linux as easily as Windows.\nThe architecture demonstrated in this article has been used in device drivers, a\ngeneral-purpose audio API/engine, and a telephony media control component.\nConstraints\nIn thinking about, and designing a system, a good way to get focused is to define the\nproblem and all of the constraints for the solution. We've already begun, but I'd like\nto spell out all of the requirements in one list, and then discuss each item.\n• Supports A^ sounds.\n• Each sound can pass through A^DSP functions.\n529\n\n\nSound 1\nSource (file, http,CD,\nmemory buffer, etc.)\n~~TT~^\nDecryption\n_xH\nDecompression\n4^\nProcessing\nr^. ...\nSound 2\nSource (file, http,CD,\nmemory buffer, etc.)\nzm:\nDecryption\nL^^\nDecompression\nZLTZ\nProcessing\nSound 3\nSource (file, http.CD,\nmemory buffer, etc.)\n~^±\nDecryption\n~^-£~\nDecompression\n~^r~\nProcessing\n^ \n1\nFIGURE 6.4.1 An audio processing system.\n530\n\n\nInteractive Processing Pipeline for Digital Audio \n531\n• Any parameter for any DSP function may be changed at any time.\n• Any function may impose a length change.\n• Efficient, this is for games on PCs, not scientific research on supercomputers.\n• Makes it easier to write DSP functions.\nLet's drill down into each item. First, we said N sounds. Monophonic sound\nengines have been obsolete since around 1994. If we store all DSP function and para-\nmeter information in the instance data of each sound, this will allow us to handle an\nunlimited number of sounds without having extra complexity.\nNext is the requirement to support N DSP functions per sound. This is the\nessence of the gem. If we wanted to pass a sound through only a single DSP function,\nwe wouldn't need a pipeline!\nParameters may be changed at any time. This is the heart of interactivity. In a\ngame, the sound designer doesn't know what will happen, or when it will happen. At\nany time, the user could enter the concrete pipe, and then certain sounds would have\nto have a reverb.\nPerhaps it's not that often that you want to slow down or speed up a sound you're\nplaying, but sometimes you do. As long as we're building a general-purpose engine,\nwe may as well support this operation. A speed-changing DSP function, in the con-\ntext of our pipeline, is any function that outputs a different number of samples than\nit uses for input. The classic example of a DSP function which slows down music is\nonly one type of speed changer. A reverb function may be categorized as a speed\nchanger (though it is actually more of a length changer) if it can generate output past\nthe end of its input; in other words, it allows the last reverberations to fade to silence\nbefore stopping.\nThe audio system should be efficient. Hopefully the pipeline itself doesn't con-\nsume a lot of CPU cycles, but we can be careful not to cause any unnecessary copying\nof memory; for example, if a DSP function returns \"I have no work to do,\" no mem-\nory copying should be performed.\nThe goal of any general-purpose API is to save work, not create work. An audio\nengine is built only once. There are many types of DSP functions. We should handle\nas much ancillary work as possible, so that each DSP function implements an algo-\nrithm and not much else.\nDiscussion\nThroughout this section, I will discuss what happens for one sound. Multiple sound\nsupport does not become a relevant factor until the mix stage.\nLooking again at Figure 6.4.1, we see that the audio input to our little world\ncomes from the decompressor (if present, or else from the input stream manager). The\noutput goes to the mixing engine (which may be DirectSound or another system).\nThis is asymmetrical. While the input side is relatively flexible (it should be able\nto supply us with as many samples of audio as we request, within reason), the output\n\n\n532 \nSection 6 Audio Programming\nside is inflexible. The mixing engine needs a certain number of samples from our\nstream; it cannot handle anything more, and if we try to pass it anything less it will\ncontinue mixing—without our sound, which will have a gap in it.\nThis is so important a rule that it should be stated again: the output of the audio\nprocessing pipeline must be determined by the needs of the mix engine. That's what\ndetermines how many samples we are to output.\nThere is only one type of inflexibility imposed by the input stream: EOF. When\nthe stream reaches the end, the processing engine needs to know.\nSo, let's say the mix is done in a fixed buffer of 16,384 samples. This means that\nit waits until it needs that many samples, and then triggers the audio processing.\nTherefore, the audio processing pipeline must output 16,384 samples.\nHow many samples does the pipeline need for input? We don't know that yet. So\nfar, we know only that the last function in the chain must output 16,384 samples.\nHow many samples does this function need for input?\nWe don't know that either, but we can find out. We can ask it! The mixer wants\n16,384 samples. The last function in the chain, with its current parameter set, says it\nwants 24,576 samples of input to produce 16,384 of output. To determine how many\nsamples of input to obtain from the stream, we continue traversing the chain of DSP\nfunctions backward. We go backward because we know the number of samples out-\nput at the end, but not the number of samples input at the beginning.\nOnce we're done with this phase, we can obtain the requested number of samples\nfrom the input stream, and pass them to the first function in the chain. We can take\nits output and pass it to the second function, and so forth. At the end, theoretically,\nwe have the right number of samples to send to the mix engine.\nWhat if that assumption is broken? What if a DSP function produces fewer sam-\nples than it was supposed to? The next DSP function in the chain must be given the\nnew, smaller buffer. It must produce output as well as it can. At the end, there may be\na shortfall. We treat this shortfall as the desired output for a second iteration, query\nbackward up the chain, and then process data a second time. We do this until we\neither run out of input samples, or fill the output buffer. For the sake of efficiency,\nDSP functions should be implemented in a manner such that they don't frivolously\nmisreport their expected input requirements. This is a feature that should only be\nused if computing the exact number of input samples required would require sub-\nstantial processing (for example, if the DSP function would have to actually process\nthe audio to know exactly how many samples it would need).\nWhat if a DSP function \"eats\" fewer samples than requested? This is a trickier\ncase to program. The pipeline must provide a buffer between each pair of DSP func-\ntions in the chain. The buffer between function #2 and function #3 holds underflow\ndata from function #3.\nWhat if a DSP function produces too many output samples? Well, it shouldn't do\nthat! Seriously, the obvious way to handle this case is to buffer it, but that is not\ndemonstrated in the code for this gem.\n\n\n6.4 Interactive Processing Pipeline for Digital Audio \n533\nThis raises a point: DSP functions are not commutative. Order matters. This is\nnot merely a limitation of the buffering system I just proposed, but also of the nature\nof processing. If one changes the pitch of a sound and then imposes a reverb, the result\nwill sound different than if one applies a reverb and then changes the pitch. Therefore,\nwe're not worried that our proposed architecture imposes this requirement as well.\nDetails\nWe're envisioning an audio processing pipeline that's called whenever the mixing\nengine needs more data for a sound channel. It may be implemented as a callback, if\nthe mix engine is driven by interrupts, or as a regular function if the status of the mix\nbuffer is polled.\nThe processing engine must call the input stream manager to request raw data for\nthe sound channel. It may return a full buffer, or less if the sound has reached the end.\nThe processing engine can call each DSP function with several messages. So far,\nwe've discussed a query to determine how many input samples are needed to produce\nthe required output, and of course the output call itself.\nWe ought to add two more: firstcall and lastcall. Firstcall is the first message sent to\na DSP function, to let it allocate instance data, and lastcall allows it to free that data.\nTo implement a DSP function to plug into diis architecture, the programmer\nmust provide a single entry point that's capable of properly handing firstcall (initial-\nization), lastcall (shutdown), query, and output messages. This entry point is given a\nsingle struct that contains the command number, input and output buffers and\nlengths, and two other items. One of these is a pointer to DSP-specific parameters,\nwhich is passed down from the application (presumably controlling all of this). Exam-\nples of DSP-specific parameters would be room size for a reverb, ratio for a speed\nchanger, and so forth. The other item is private instance data allocated and main-\ntained by the DSP function itself.\nImplementing the engine is somewhat more complex, but this was our intent.\nMake this one piece intelligent so that the many DSP pieces are quick and easy to\nimplement.\nThe processing engine uses three buffers: a source, a destination, and an accumu-\nlation buffer. During processing, the buffers swap roles, so the engine uses buf [0],\nbuf [1 ], and buf [2]. The reason is that the destination (output) of DSP function #1\nbecomes the source (input) of DSP function #2.\nSimilarly, if the last DSP function in the chain outputs less than the amount\nrequired by the mixing engine, its destination buffer becomes the accumulation\nbuffer. After the next iteration of the chain, the accumulation buffer is prepended to\nthe new destination buffer.\nThe Code\nLet's look at the source code to the main entry point.\n\n\n534\nSection 6 \nAudio Programming\nvoid dsp_ProcessAudio(dsp_AUDIO *audio)\naudio->src = 0;\naudio->dst = 1;\naudio->acc = 2;\nbfbuf_WIPE(audio->buf[audio->src]);\nbfbuf_WIPE(audio->buf[audio->dst]);\nbfbuf_WIPE(audio->buf[audio->acc]);\naudio->samps = 0;\nwhile ((audio->samps < audio->sampsneeded) && (!audio->done))\nSWAP(audio->acc, audio->dst);\nQueryDSPIn(audio);\nstream_GetData(audio);\nDoDSP(audio);\nbfbuf_MoveAll(audio->buf[audio->dst], \naudio->buf[audio->acc]);\nON me a\nON me CD\nOne last explanation is necessary before this code makes sense. A bfbufis a data\nstructure of my own invention. A backfill buffer is a memory buffer designed to make\nit easy to prepend data. The contents are always aligned flush with the end, so that\nprepending is done with a simple memcpy (). The source code to BFBUF.C is included\non the companion CD-ROM.\nIt turns out that the prepend operation is the one we need to handle the under-\nflow buffers in the DSP chain itself. Therefore, I've implemented the outer loop to\nuse a prepend to take the partial buffer from the previous iteration and add it to the\ncurrent partial buffer. This could just as easily have been implemented to append the\ncurrent partial buffer to the previous partial buffer. When you make yourself a new\nhammer, and you feel clever about it, you have a tendency to see everything as a nail.\nLet's walk through the function. Its sole parameter is a pointer to a struct defined\nin the code on the CD. There are three backfill buffers, which we initialize to empty,\nand assign their initial semantics.\nWe have a loop that iterates until we run out of source data, or until the output\nbuffer is full. For the first iteration, the swap is meaningless and does nothing.\nThe rest is simple. First, we determine how many input samples are needed, get\nthem, and process. Then, we prepend the accumulated samples from previous itera-\ntions (if any) to the current destination.\nstream_GetData() is the call to the input stream manager (external to DSP.C). It's\nimportant to understand that this function must put the samples in the destination\nbuffer. As we'll see, DoDSP () swaps the source and destination buffers at the beginning.\nNow let's look at the query function.\n\n\n6.4 Interactive Processing Pipeline for Digital Audio \n535\nstatic void QueryDSPIn(dsp_AUDIO *audio)\n{\ndsp_PARAMS params;\ndsp_DSP *dsp;\nDWORD underlen;\nDWORD x;\nparams.cmd \n= dsp_QUERYACTIN;\nparams. actualin = audio->sampsneeded - audio->samps;\nfor (x=0;x<audio->numdsps;x++)\n{\ndsp = &(audio->dsp[audio->numdsps - x - 1]);\nparams. dstlen = params. actualin;\n(*dsp->callback) (&params) ;\nunderlen = bfbuf_GETDATALEN(dsp->underbuf ) ;\ndsp->inreq = (underlen < params. actualin) ?\nparams. actualin - underlen : 0;\ndsp->outreq = params. dstlen;\nNotice how the function begins by knowing how many samples remain (audio ->\nsampsneeded — audio->samps). It sets this up where the code in the loop expects to\nfind it from a previous iteration. Alternatively, I could have coded this with a goto to\nenter the loop in the middle, but that seemed a less elegant solution.\nThe loop itself traverses all the DSP filters used by the sound in reverse order. For\neach, it sets up a parameter to specify the desired number of output samples, and\nmakes the call. Then it subtracts the number of samples stored in the underflow\nbuffer from a previous iteration of processing. The result may be zero, if the previous\niteration had sufficient samples left over. In this case, the filter needs no more input;\nall the input it requested is already waiting for it in our underflow buffer!\nEach DSP stores how many input samples it needs, and the expected output (the\nnumber of samples requested by the next item in the chain).\nThe meat of the Gem is the DoDSP( ) function.\nstatic void DoDSP(dsp_AUDIO *audio)\n{\nbfbuf_BUFFER *srcbuf;\nbfbuf_BUFFER *dstbuf;\ndsp_PARAMS params;\ndsp_DSP *dsp;\nDWORD x;\nparams.cmd = dsp_OUTPUT;\nfor (x=0;x<audio->numdsps;x++)\n\n\n536 \nSection 6 Audio Programming\ndsp = &(audio->dsp[x]);\nSWAP(audio->src, audio ->dst);\nsrcbuf = audio->buf[audio->src];\ndstbuf = audio->buf[audio->dst];\nbfbuf_MoveAll(srcbuf, dsp->underbuf);\nbfbuf_SetDataLen(dstbuf, dsp->outreq);\nbfbuf_GetBufStart(srcbuf, &(params.lsrc), &(params.rsrc));\nbfbuf_GetBufStart(dstbuf, &(params.ldst), &(params.rdst));\nparams.srclen \n= bfbuf_GETDATALEN(srcbuf);\nparams.dstlen \n= bfbuf J3ETDATALEN(dstbuf);\nparams.dspspecific = dsp->dspspecific;\nparams.privdata \n= dsp->privdata;\n(*dsp->callback)(&params);\nif (params.nowork)\n{\nbfbuf_WIPE(dstbuf);\nSWAP(audio->src, audio->dst);\nparams.actualout = params.srclen;\n}\nelse\n{\nif (params.actualout < bfbuf_GETDATALEN(dstbuf))\n{\nbfbuf_ChokeUp(dstbuf, params.actualout);\n}\nif (params.actualin < bfbuf_GETDATALEN(srcbuf))\n{\nbfbuf_Eat(srcbuf, params.actualin);\nbfbuf_MoveAll(dsp->underbuf, srcbuf);\n}\nelse\n{\nbfbuf_WIPE(srcbuf);\n}\n}\n}\naudio->samps += params.actualout;\n}\nAt first, the initial swap of source and destination looks funny. Each DSP func-\ntion is given the previous function's output (destination) for its own input (source).\nThis also makes it easy to handle the case when a DSP reports that it has done no\nwork.\nThere's some variable setup, and then four calls to this mysterious backfill buffer\nmanager. First, we fetch all underflow samples from the previous iteration. Note: this\n\n\n6.4 Interactive Processing Pipeline for Digital Audio \n537\nis stored on a per-DSP basis. The underflow for DSP function #1 is different from the\nunderflow for DSP function #2, and must be kept separate.\nNext, we set up the expected size of the destination backfill buffer. If this turns\nout to be wrong, we'll fix it later. Finally, we obtain pointers to the current beginnings\nof the buffers. Notice that left and right are stored separately. This makes DSP pro-\ncessing easier, as well as the eventual move to multichannel audio (for example, 5.1).\nWe do some straightforward parameter setup. Notice how we provide the DSP\nwith both a pointer to function-specific parameters, and its own instance data for this\nsound.\nAfter the call, if the function did no work, we set the destination buffer to empty,\nand swap destination with source (so the destination is now the one with samples in\nit) to prepare for the next iteration, which will swap again.\nOtherwise, something was done by the function, so we check to see if the DSP\ngenerated less than a full buffer. The choke up is the only BFBUF operation that must\ndo a memory move.\nThen we check to see if the function consumed less than all of the input data sup-\nplied to it. If so, we buffer it as underflow. Otherwise, we just mark the source buffer\nas empty.\nExtra Commentary\nThis isn't the easiest code to read, but it's nice and efficient, which is what counts! No\ncycles are wasted unless a DSP generates too little data, and there's not much to do\nabout that except iterate the whole chain again hoping we'll get enough data.\nNotice how each time dsp_ProcessAudio() is called, the parameters for all of the\nDSP functions could have changed. This code forms the core of an audio processing\nengine that meets all of the criteria we enumerated earlier.\nBuilding it was not only possible, but it wasn't as hard as it seemed it would be.\nTwo functions have been omitted from the text (they're on the CD). dsp_New-\n^r'^Hs, \nSound () must be called when a new sound is added to the system, and dsp_Delete-\nONWCD \nSound () must be called when a sound is removed from the system. This is important\nbecause it's not obvious from the code presented thus far. There is a call to the stream\nmanager, and that call sets audio->done if the stream reaches the end.\nWhatever code calls dsp_ProcessAudio() must check this bit, and then call\ndsp_DeleteSound() if appropriate. The tricky part is to wait until the sound is done\n(in other words, audio->samps is 0). DSP functions (such as echo) may retain their\nown internal buffers. Regardless of how they determine when to eat input samples\nand produce nothing (when given a request for output and when provided with less\ninput than requested) they must output whatever they can. This way, the DSP engine\nknows that when a stream reaches the end, and the DSP function chain produces no\noutput, the last reverberations or echoes of the sound are done, and the sound may\nsafely be deleted without causing an audible truncation.\n\n\n538 \nSection 6 Audio Programming\nFrom an architectural standpoint, this is admittedly somewhat weak. It is possible\nto design a more elegant, self-contained solution to this problem inside DSP.C. A\nrelated limitation is that the dsp_AUDIO struct and its dsp_DSP array are allocated\noutside as well. There is entirely too much management of DSP-related memory\nstructures, parameters, and so forth, outside the DSP engine. This is done primarily\nto keep the code clean and easy to understand.\nThere are two functional limitations (the previous are considered to be structural\nor architectural) to discuss. First, the code doesn't handle the case of when a DSP\nfunction overflows. The quick excuse is that no function should ever output more\ndata than is requested of it. It could also be argued that those few functions that\nwould want to, can simply maintain an internal buffer. This isn't satisfactory because\nwe've gone to great lengths to make sure that DSP functions are small, lightweight,\nand easy. The real answer is that this would add considerably to code size and com-\nplexity (including in BFBUF.C), and provide a (comparatively) marginal value. This\ncode is not really a robust commercial implementation, and adding something like\noverflow protection (including the algorithms to determine how big is big enough,\netc.) just wouldn't make sense before putting in DEBUG error-checking, for example.\nThe other missing feature is that there is no way to add or remove DSP functions\nafter a sound is created. This can be worked around as long as all DSP functions have\na parameter to indicate \"passthru.\" Then, just make sure each sound is created with all\nof the DSP functions that you'll possibly want to use on it at any point during its life-\ntime. It's not inefficient, and it works (although it is a bit clunky).\nIt would be a bad kludge, but you could actually add new DSP functions to the\nend of the list (as long as you provided a way to do firstcall processing for them).\nConclusion\nThe essence of this gem demonstrates how to build a basic DSP pipeline that supports\npassing a sound channel through a chain of DSP filters, each of which can do any-\nthing to the stream that it wants.\nIn order to support DSPs that may wish to change the size of the buffer as they\nprocess, we need a query call to ask the DSP \"if we want N samples of output, how\nmany samples of input do you estimate you'll need?\" We do this query in reverse\norder.\nIn addition, we added support for two underflow conditions: generating too little\ndata, and eating too little input. These weren't too hard to support with the help of an\ninnovative data structure: the backfill buffer. The concept is the most difficult thing\nONTHCCD \n-with this. As you'll see on the CD, the code is straightforward, if not trivial.\nWith this engine, and some glue logic, it's possible to do any type of audio pro-\ncessing that a game will need. Indeed, it could support a whole professional audio stu-\ndio for music production and performance.\n",
      "page_number": 506,
      "chapter_number": 52,
      "summary": "This gem describes the block labeled \"Processing.\"\nThis gem presents a lightweight, but general-purpose architecture Key topics include audio, functions, and function. Covers function.",
      "keywords": [
        "DSP",
        "DSP function",
        "Audio",
        "function",
        "audio processing pipeline",
        "audio processing",
        "buffer",
        "samples",
        "Processing",
        "sound",
        "Audio Programming dsp",
        "DSP function produces",
        "input",
        "output",
        "processing pipeline"
      ],
      "concepts": [
        "audio",
        "functions",
        "function",
        "functional",
        "buffer",
        "buffering",
        "sound",
        "processing",
        "process",
        "data"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 8",
          "chapter": 53,
          "title": "Segment 53 (pages 511-519)",
          "relevance_score": 0.65,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 7",
          "chapter": 63,
          "title": "Segment 63 (pages 609-616)",
          "relevance_score": 0.57,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 7",
          "chapter": 61,
          "title": "Segment 61 (pages 593-600)",
          "relevance_score": 0.56,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 7",
          "chapter": 59,
          "title": "Segment 59 (pages 567-580)",
          "relevance_score": 0.55,
          "method": "sentence_transformers"
        },
        {
          "book": "operating_systems_three_easy_pieces",
          "chapter": 8,
          "title": "Segment 8 (pages 57-67)",
          "relevance_score": 0.55,
          "method": "sentence_transformers"
        }
      ]
    },
    {
      "number": 53,
      "title": "Segment 53 (pages 516-524)",
      "start_page": 516,
      "end_page": 524,
      "detection_method": "topic_boundary",
      "content": "6.5\nA Basic Music Sequencer\nfor Games\nScott Patterson\nscottp@tonebyte.com\nT\nhis gem describes how to make a basic music sequencer. First, we will start with a\ncomparison of music streaming and music sequencing. Then, we will review\nsome important concepts from the MIDI music language, outline a basic computer\nmusic language implementation, and then discuss the coding issues that relate to tim-\ning and synthesis control.\nStreaming vs. Sequencing\nMusic in games is generally played back in one of two ways: either as a stream of sam-\nple data or as a sequence of instructions to an audio synthesis system. It is also possi-\nble that music playback may involve a combination of both methods. Individually,\nthe methods have some pros and cons that depend on the hardware systems available.\nTo be combined, synchronization issues must be addressed as well.\nStreaming Method Pros\n• Audio hardware requirements are minimal.\n• Music development and integration with the game is easy.\n• Music quality is only limited by the sample rate and number of channels of the\nstream data.\nStreaming Method Cons\n• Music data plays the same way each time.\n• There can be latency in the start and stop of the stream.\n• There may be latency problems when looping a stream or switching streams.\n• There may be large memory buffer requirements.\n• Certain resources may be tied up during playback such as DMA hardware and\nstorage device hardware.\n• If the stream data is not compressed, it will take significant storage space.\n• If the stream data is compressed, it will require hardware or software decompres-\nsion resources.\n539\n\n\n540 \nSection 6 Audio Programming\n• It may not be possible to cross-fade two different streams depending on hardware\nlimitations, so the only choice available may be fading to or from silence.\nSequencing Method Pros\n• No latency problems when starting or stopping the music.\n• No latency problems when looping or switching music.\n• If audio memory is available, sample data memory will not compete with game\ndata memory.\n• Resources such as DMA hardware and storage device hardware may not be\nrequired for music playback and will be free for die game to use at any time.\n• A great deal of music styles and variations can be produced from a relatively small\nsample data set.\n• Music data can be dynamically altered at runtime to create unique game and\nmusic interactions.\nSequencing Method Cons\n• Voices for music may compete with voices needed for other game audio.\n• Music development and integration with the game is more complex.\n• Music quality may be limited by synthesis capabilities.\n• Music quality may be limited by available sample memory.\nCore Computer Music Concepts\nLet's now review core computer music concepts, and build our music command\nlanguage.\nEvent Blocks\nMusic can be described as events or commands occurring over time. Therefore, we\ncan build our music command language with \"event blocks\" composed of three ele-\nments: time, event type, and event details. We will store the time relative to previous\nevents and call it a delta-time. The event type will be identified with a number, and\nthe event details will be zero or more parameters diat are defined by the event type\n(Figure 6.5.1).\nBy using a sequence of event blocks we can describe any combination of events\nand time intervals. Therefore, building our computer music language is now a task of\nDelta Time / Event Type / Event Parameters\nFIGURE 6.5.1 Event block.\n\n\n6.5 A Basic Music Sequencer for Games \n541\nchoosing how to store the delta time, choosing the event types to support, and choos-\ning the parameters supplied for each event type.\nMIDI (Musical Instrument Digital Interface) Music\nThe MIDI specification has been around for a long time. Most music composition\nand sequencing software provides compatibility with MIDI input and output ports\nfor recording and playback. These software products also provide options to save and\nload MIDI files. Since we are creating our own computer music language, a good\nplace to start will be learning the MIDI specification and its file format. We can then\nconvert MIDI file data to our own custom data.\nThe word interface in MIDI refers to the fact that it is a specification for commu-\nnication between musical devices. In making a music sequencer for games, we aren't as\ninterested in musical device communication as we are in music playback on a partic-\nular machine. Therefore, my introduction to MIDI will include only the parts that\nrelate directly to making our music sequencer for games.\nMIDI Event Types\nThe MIDI specification defines several events called the channel voice messages.\nMIDI originated as a virtual piano keyboard communication language, so terms such\nas attack velocity, release velocity, pitch wheel, and key pressure all refer to actions\napplied to a virtual piano keyboard (Table 6.5.1).\nThe channel voice messages are the core musical control events defined by MIDI.\nThe Program Change event defines what instrument definition to use. The Note On\nand Note Off events do as they suggest, and the remaining events update various\naudio playback parameters to new values. Since the Control Change event specifies a\nTable 6.5.1 MIDI Channel Voice Messages\nEvent Type\nNote Off\nNote On\nPitch Wheel\nControl Change\nProgram Change\nPoly Key Pressure\nChannel Pressure\nEvent Parameters\nNote Number\nRelease Velocity\nNote Number\nAttack Velocity\nPitch Bend LSB\nPitch Bend MSB\nController ID\nController Value\nProgram Number\nNote Number\nPressure Value\nPressure Value\n\n\nSection 6 Audio Programming\nController ID parameter, it can be used for many different types of audio control.\nTwo of die most commonly used Controller IDs are 7 for Volume and 10 for Pan.\nThere are also meta-events defined in die MIDI file format 1.0 specification.\nTable 6.5.2 lists a selection that will be important to us.\nThe End of Track meta-event defines the end of a series of event blocks, and the\nSet Tempo meta-event defines how fast to step through die delta time values of event\nblocks. The Time Signature and Key Signature meta-events do not change the way\nthat MIDI music plays, but are commonly used for organizing die visual display of\nmusic data. We can use these meta-events as special markers for our own organization\nor synchronization purposes. The remaining meta-events I have listed store string\ndata. We can store custom information in these strings to be used in our conversion\nfrom die MIDI format to a custom format.\nMIDI Channels and Tracks\nThe \"channel\" in MIDI channel voice messages refers to the fact that each MIDI\nevent block also contains a channel number from 1 to 16 (0 to 15). The channel con-\ncept makes it possible to send MIDI commands to more than one target over a serial\nconnection. It would also be possible for us to store our music data as a single serial\nstream and assign channels to each message. An advantage of this method is that pro-\nTable 6.5.2 Selected MIDI Meta-Event Types\nMeta-Event Type \nMeta-Event Parameters\nEnd of Track\nSet Tempo \nTempo Number\nTime Signature \nNumerator\nDenominator\nMIDI clocks per metronome click\n32nd-notes in a MIDI quarter-note\nKey Signature \nSharps/Flats Indicator\nMajor or Minor Indicator\nText Event \nString Length\n__ \nString Data\nSequence/Track Name \nString Length\nString Data\nInstrument Name \nString Length\nString Data\nLyric \nString Length\nString Data\nMarker \nString Length\nString Data\nCue Point \nString Length\nString Data\n\n\n6.5 A Basic Music Sequencer for Games \n543\ncessing a single stream of data would work well for CPU caching. A disadvantage of\nthis method is that track data organization would not be flexible and independent.\nIt so happens that the MIDI file format 1.0 specification defines \"format 0\" files\nthat have all information combined in one track, and \"format 1\" files that have any\nnumber of tracks.\nThe basic music sequencer that we will present processes any number of tracks\nindependently and does not have a channel concept.\nComputer Music Sequencer Implementation\nNow we are at the point where we can determine our own custom computer music\nlanguage. For the purposes of this gem we will choose to implement event types that\nare very similar to MIDI event types. You can create your own additional event types\nfor your own needs.\nSequences, Tracks, Events, Instruments, and\nVoices\nLet's quickly cover the terminology used in the rest of this paper. A sequence is a col-\nlection of tracks that run simultaneously. Each track is a series of event blocks that we\ndefined earlier. There is always a single current instrument on each track. Every Note\nOn event in a track will start a voice of the current instrument. The corresponding\nNote Off event will turn this voice off. Many types of events in a track will modify the\nstate of the track's voices.\nThe sequencer data structures described later show an implementation of these\nrelationships.\nSequencer Event Types\nAs a first step in creating our basic music sequencer we will come up with a list of\nevent types that we want to support. These are displayed in Table 6.5.3.\nTable 6.5.3. Event Type Ideas\nEvent Types \nNotes\nNote Control \nThese work like the traditional MIDI events\nNote Off \nKey\nRelease velocity (optional)\nNote On \nKey\nAttack velocity\n(continues)\n\n\n544\nSection 6 Audio Programming\nTable 6.5.3. (Continued)\nEvent Types\nImmediate Modifications\nSetVolume\nSetPitchBend\nNotes\nThese work like the traditional MIDI events\nValue\nValue\nSetPan\nValue\nSetEffect\nAny effect type\nValue\nSetlnstrument\nProgram change\nSetTempo\nValue\nTarget Modifications\nSetTarget\nTarget an event value rather than setting it\nTime format and duration to target value\nBasic modification type and data\nArrangement\nTrack End\nTrack Marker\nJump to Track\nGosub to Track\nEnds track playback\nAdditional entry points, sync points.\nJump to new track data\nJump to new track data, returns when done\nCallback\nCallback\nCalls game code, could change test values\nNote Control\nIt is pretty hard to make music without notes. Following the MIDI tradition, we asso-\nciate a key number and velocity with notes. The MIDI Note Off message includes a\nrelease velocity, but it is our option to include this for our sequencer.\nImmediate Modifications\nThese event types are quite similar to certain MIDI messages. This will make conver-\nsion from MIDI files for these events easy. These events also represent immediate\nupdates of synth hardware. Values may be absolute or relative depending on the event\ntype.\nTarget Modifications\nThese event types interpolate from current value to destination value over a given\ntime rather than changing settings immediately. Target modifications have the advan-\ntage of being able to describe a curve of parameter values with a single command\nrather than the many immediate modification commands needed to achieve the same\neffect.\nArrangement\nThese event types switch us to different sections of music data.\n\n\n6.5 \nA Basic Music Sequencer for Games \n545\nCallback\nThese event types generate callbacks to functions that have been registered with the\nmusic sequencer.\nSequencer Data Structures\nThe abbreviated data structures that we could use for our music sequencer are listed\nin Listing 6.5.1.\nListing 6.5.1 Music sequencer data structures\ntypedef list< Sequence_t * > SequencePtrList_t;\ntypedef list< Track_t * > \nTrackPtrListjt;\ntypedef list< Voice_t * > \nVoicePtrList_t;\nclass MusicSequencer_t {\nMusicSequencerState_t State;\nSequencePtrList_t \nActiveSequencePtrList;\nSequencePtrList_t \nFreeSequencePtrList;\nTrackPtrList_t \nActiveTrackPtrList;\nTrackPtrList_t \nFreeTrackPtrList;\nVoicePtrList_t \nActiveVoicePtrList;\nVoicePtrList_t \nFreeVoicePtrList;\n};\nclass SequenceState_t {\nTempo_t Tempo;\nVolume_t Volume;\n};\nclass Sequence_t {\nSequenceState_t State;\nTimeUnit_t \nTimeElapsed;\nTimeUnit_t \nTimeStep;\nTrackPtrList_t TrackPtrList;\n};\nclass TrackState_t {\nVolume_t \nVolume;\nPitchBend_t PitchBend;\nPan_t \nPan;\nEffect_t \nEffect;\n};\nclass Track_t {\nTrackState_t \nState;\nSequence_t \n*pOwner;\nchar \n*pEvent;\nInstrument_t *plnstrument;\nVoicePtrList_t VoicePtrList;\n};\nclass VoiceState_t {\n\n\n546 \nSection 6 Audio Programming\nSynthVolume_t Volume;\nSynthPitch_t \nPitch;\nSynthPan_t \nPan;\nSynthEffectjt Effect;\n};\nclass Voice_t {\nVoiceState_t \nState;\nTrack_t \n*pOwner;\nint \nnKey;\n};\nHere we show the MusicSequencer_t class that holds the lists of active and free\nsequences, tracks, and voices. We also see that sequences, tracks, and voices each have\na notion of state and some example parameters of those states are shown. A\nSequence_t has a TmckPtrList that holds the tracks owned by the sequence. A Track_t\nhas a VoicePtrList that holds the voices owned by the track. A Voice_t has zpOwner\nthat points to the track that owns the voice. A Track_t has apOwner that points to the\nsequence that owns the track. These parent and child data structures help us query\nand update information up and down our hierarchy, whether we are operating on\nsequences, tracks, or voices.\nEvent Data Structures\nTo implement the event type commands, we can have the event type command num-\nbers correspond to an array lookup that holds the relevant function pointer and the\nbyte length of the event type and parameters. Listing 6.5.2 shows this code. The func-\ntion pointers give us a quick way to get to the code associated with each event type.\nThe byte lengths give us a quick way to step to the next event block.\nListing 6.5.2 Event type data structures\n// Example Note Off Event Block\ntypedef struct {\nchar nEventType;\nchar nKey;\n//no release velocity\n} NoteOff_EventBlock_t;\nvoid NoteOff_Function( Track_t *pTrack )\n{\n// the pEvent is pointing at our event block\nNoteOff_EventBlock_t *pNoteOffEB =\n(NoteOff_EventBlock_t *)pEvent;\n// walk through this track's voices and turn off\n// any that have pVoice->nKey == pNoteOffEB->nKey\n}\n// Example Note On Event Block\n\n\n6.5 A Basic Music Sequencer for Games \n547\ntypedef struct {\nchar nEventType;\nchar nKey;\nchar nVelocity;\n} NoteOn_EventBlock_t;\nvoid NoteOn_Function( Track_t *pTrack )\n{\n// the pEvent is pointing at our event block\nNoteOn_EventBlock_t *pNoteOnEB = (NoteOn_EventBlock_t *)pEvent;\n// try to get a voice from the free list or\n// try to get a voice from the active list if possible\n// if we have a voice, turn it on with the pNoteOnEB->nKey\n// and pNoteOnEB->nVelocity and other state information\nenum enumEventType\n{\nEVENT_TYPE_NOTEOFF ,\nEVENT_TYPE_NOTEON,\nEVENT_TYPE_COUNT\ntypedef void (*EventFuncPtr_t) (Track_t *);\ntypedef struct {\nEventFuncPtr_t pFunc; \n// pointer to command function\nint \nnLength; // byte length of command\n} EventTypes_t;\nstatic EventTypes_t aET[EVENT_TYPE_COUNT] = {\n{ NoteOff_Function, sizeof (NoteOff_EventBlock_t) },\n{ NoteOn_Function, sizeof (NoteOn_EventBlock_t) },\nHere we show that we can give each event type a number that can be used to call\nup an EventType$_t structure from an array. The EventTypes_t structure contains the\nfunction pointer to call for the given event type and the length of the command ID\nand parameters. Being able to define our own command numbers and have them cor-\nrespond to array entries like this provides an alternative to switch statements.\nThe Audio Frame and Update Interval\nDifferent computer systems have different ways of providing timing callbacks or\nthreads that wake up at specific intervals. I will simply assume that we can have a\nfunction called at a specific interval referred to as the audio callback. We can think of\n",
      "page_number": 516,
      "chapter_number": 53,
      "summary": "First, we will start with a\ncomparison of music streaming and music sequencing Key topics include event, music, and musical. Sequencing\nMusic in games is generally played back in one of two ways: either as a stream of sam-\nple data or as a sequence of instructions to an audio synthesis system.",
      "keywords": [
        "Music",
        "Basic Music Sequencer",
        "Event",
        "Music Sequencer",
        "event type",
        "MIDI",
        "MIDI Event Types",
        "data",
        "Track",
        "Basic Music",
        "Music data",
        "type",
        "MIDI Event",
        "computer music",
        "string data"
      ],
      "concepts": [
        "event",
        "music",
        "musical",
        "midi",
        "data",
        "track",
        "values",
        "sequencer",
        "sequence",
        "notes"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 7",
          "chapter": 39,
          "title": "Segment 39 (pages 361-371)",
          "relevance_score": 0.48,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 7",
          "chapter": 36,
          "title": "Segment 36 (pages 337-344)",
          "relevance_score": 0.45,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 7",
          "chapter": 40,
          "title": "Segment 40 (pages 372-380)",
          "relevance_score": 0.45,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 7",
          "chapter": 61,
          "title": "Segment 61 (pages 593-600)",
          "relevance_score": 0.45,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 50,
          "title": "Segment 50 (pages 481-489)",
          "relevance_score": 0.45,
          "method": "sentence_transformers"
        }
      ]
    },
    {
      "number": 54,
      "title": "Segment 54 (pages 525-535)",
      "start_page": 525,
      "end_page": 535,
      "detection_method": "topic_boundary",
      "content": "548 \nSection 6 Audio Programming\nthe time between these callbacks as the audio frame. During each callback, we need to\nupdate our notion of how much time will pass during the next audio frame, and we\nneed to send out all of the commands that are due to occur over diis time.\nIndependent of the audio callback rate we will also have an update interval. The\nupdate interval determines the amount of time we will step when sending out low-\nlevel commands. For example, we could have an audio callback that occurs once every\nsecond with the update interval at 120 times a second, which would require stepping\nthrough 120 time intervals per callback. Another possibility is that we could have an\naudio callback that occurs 60 times a second with the update interval at 120 times a\nsecond, which would require stepping through two time intervals per callback.\nListing 6.5.3 is an outline of the audio callback code.\nListing 6.5.3 The audio frame\n// This function is called by the timer callback\nstatic void OSys_AudioCallback(void)\n{\n// protect against callback reentrance\n// determine the number of update intervals required\n//to deliver during this callback\n// begin critical section\nOSys_BeginAudioCriticalSection();\n// for the number of update intervals required on this frame\n// {\n// \niterate over sequences\n// \nperform per sequence operations\niterate over tracks\nperform per track operations\n//\n// \nsend low-level commands for this time step\n// \nmove to next time step\n// }\n// end critical section\nOSys_EndAudioCriticalSection();\n}\nSince our callback may happen while other code is executing, this means it might\nhappen when we are changing data structures for the music sequencer. We protect\nagainst this by using the critical section method specific to our operating system.\nTiming Calculations\nIn order to play our music data at different rates, we need to work out how to step\nthrough our music data based on three parameters: the music tempo, the update\ninterval, and the resolution of our music time format.\n\n\n6.5 A Basic Music Sequencer for Games \n549\n• Music tempo is described in beats per minute (BPM).\n• The update interval is described in updates per second (UPS).\n• Music time resolution is described in parts per quarter note (PPQ).\nWe are looking for the amount of music time to increment for each audio call-\nback. We can call this parts per update (PPU).\nIf we consider beats per minute (BPM) to be the same as quarter notes per minute\n(QPM), then the equation is:\nPPU = QPM * PPQ* (I/UPS) * (lMinute/60Seconds)\nIf we store this PPU number as a 16.16 fixed point number, the final code is\n(Listing 6.5.4):\nListing 6.5.4 Time step calculation\nunsigned long CalcTimeStep( unsigned short qpm,\nunsigned short ppq,\nunsigned short ups)\n{\nunsigned long ppu;\nunsigned long temp;\ntemp = (unsigned long)qpm * (unsigned long)ppq;\nif( temp < 0x10000 )\n{\nppu = ((temp * 0x10000) / 60)\n/ (unsigned long)ups;\n} else {\nppu = ((temp / 60) * 0x10000)\n/ (unsigned long)ups;\n}\nreturn(ppu);\n}\nOur calculation here does a little range checking during the calculation to make\nsure that we obtain as accurate a 16.16 result as possible given that the input numbers\ncan range in value.\nWe recalculate the parts-per-update value any time that a sequence's tempo\nchanges. This parts-per-update value is placed in our TimeStep variable in our sequence\nstructure. Since these time parameters are in the sequence structure, we can only change\nthe tempo for the entire sequence. If we wanted to change tempo for each track indi-\nvidually, we could put these parameters and die tempo setting in the track structure.\nAudio Synthesis Control\nConnecting Synth to Sequencer\nAn important issue for our music sequencer implementation is how music event para-\nmeters are mapped to audio synthesis parameters. This is where music sequencer code\n\n\n550 \nSection 6 Audio Programming\ncan get very platform specific. In order to keep the code as cross-platform as possible,\nI will call a software synthesizer interface from our sequencer code.\nOne important part of connecting our audio synthesis to our music sequencer is\nthe Setlnstrument event type. The Program Change parameters of Setlnstrument\nCommand is used as an index into a table of instrument definitions. The address of\nthis table entry is used to set the ^Instrument field of our Track data structure. When\na Note On command occurs, the parameters from the plnstrument are transferred to\nthe voice to be started. You can view these details in the accompanying source code.\nThe capabilities of the audio synthesis system that we are using will determine\ninstrument definition and even definition details. As a result, there will be certain\ntypes of control we will have available and music will have to be written with these\ncontrol issues in mind.\nThe Code\nThe example code on the CD-ROM shows how to play music using our custom\nmusic sequencer language. This includes how to step through the music data of each\ntrack of each sequence, and how to code the event types for a particular synth inter-\nface. Of the event type ideas presented, the code implements the NoteOn, NoteOff,\nSetPan, Setlnstrument, and TrackEnd commands.\n^|' c> 4 \nThe example code uses a cross-platform audio engine called CSyn. The CSyn\nON me CD \nlibrary provided on the CD-ROM is for demonstration purposes only.\nConclusions\nWe covered the details of a basic music sequencer. Important MIDI concepts have\nbeen presented, as well as our custom music language. Implementation details of data\nstructures, event types, and timing were presented. Finally, the code is there to play\nwith and customize for your own needs. Enjoy!\nReferences\nCSyn audio engine, www.softsynth.com/csyn.\n\n\n6.6\nAn Interactive Music\nSequencer for Games\nScott Patterson\nscottp@tonebyte.com\nG\names are interactive. This means that a player has control over the game in some\nway, and the game asks the player to use his or her control to interact in some\nway. This control and interaction is the foundation of gameplay that is immersive and\nentertaining.\nIt is natural to want to mix the immersiveness of control and interaction in com-\nputer games with the immersiveness of music. How do we control music? How can\nwe create musical interaction? \"What kind of musical meanings can we generate? This\nis the motivation for this gem.\nBuilding on the concepts and code from the basic music sequencer, we now will\ndiscuss features that provide interactive control. Specifically, we will discuss the ability\nto modify parameters on the sequence level and track level.\nMaking interactive music can be viewed as controlling a puppet. We need to pull\nthe right strings to make it seem alive. And if we pull the right strings to control the\nway the music plays, we may even pull the emotional strings of our game player. In\norder to discuss what types of emotional strings might be available, we've generated a\nlist of associations and meanings that music can convey. We then cover transitions,\ntransition types, control granularity, and target control. Finally, we present a few\ndesign examples.\nMusical Associations\nMusic is its own form of entertainment. We listen for styles, attitudes, technology,\nimprovisation, composition, and skilled performances and interpretations. Our mem-\nories associate music with past situations, friends, and places. While some associations\nmay be personal and specific, others are quite common and generally accepted. We\nmay associate a particular song with a particular person. We may associate a particular\nstyle of music with a particular geographical location. We may associate the \"mood\"\nof some music widi love, hate, contentment, or anger (Table 6.6.1).\n551\n\n\n552\nSection 6 Audio Programming\nTable 6.6.1 Music Associations\nCategory / Type\nAge Groups\nActivities\nCultures\nTime Periods\nLocations\nMood\nTension\nStrength\nReward\nDefeat\nDescription\nChildren, teenage, college, mature\nSports, chase, battle, puzzles\nThemes, styles, anthems\nHistorical, futuristic\nGeographical, magical, space exploration\nHumor, serious\nRelaxed, tense\nPowerful or weak\nPride, confident and energetic\nRidicule, goofy and taunting\nMusical Meaning\nIf we want our music to be interactive, we should know the different meanings that\nwe wish to convey with the music. Some of the meanings that we might want to\nattach to the control of music are categorized in Table 6.6.2.\nTable 6.6.2 Musical Meanings\nCategory / Type\nDescription\nSelf\nHealth\nPower\nSkill\nMood\nFamiliar\nOthers\nFriends\nEnemies\nLove\nHate\nFamiliar\nLocation\nSecrets\nHints\nSafety\nDanger\nMagic\nFamiliar\nWhat state is the player in?\nConfidence in the music.\nStrength in the music.\nSharpness and agility in the music.\nHeaviness or lightness in the music.\nMusic that is familiar to certain player states in the game.\nWhat state are nonplayer characters in?\nPleasing attitude in the music.\nHarsh attitude in the music.\nSweetness in the music.\nViolence in the music.\nMusic that is familiar to certain nonplayer character states in the game.\nWhat is our current location like?\nOccasional secret melodies or instruments play.\nSudden burst when looking the right way.\nEven, predictable music.\nIrregular, ominous music.\nChimes, and echoes, and sprinkles in the music.\nMusic that is familiar to a common location in the game.\n\n\n6.6 An Interactive Music Sequencer for Games \n, \n553\nTable 6.6.2 (Continued)\nCategory / Type\nSituation\nSafety\nDanger\nMagic\nPreparation for Bartle\nTension\nAdrenaline\nTime is Running Out\nChallenge Level\nReward\nFailure\nFamiliar\nDescription\nWhat kind of situation are we in?\nEven, predictable music.\nIrregular, ominous music.\nChimes, and echoes, and sprinkles in the music.\nDrums of war. Mechanized beats.\nSharp tones and dynamic changes.\nTempo is up. Mechanized beats.\nTempo is up. Chaotic passages.\nComplicated layering, added effects.\nTriumphant music.\nWhimpering or taunting music.\nMusic that is familiar to a common situation in the game.\nTransitions\nTransitions can be defined as one or more changes occurring over a time interval. A\ntransition might mean an interpolation of some type of state data done over a specific\ntime interval. In addition, a transition might mean a new track section, musical\ncadence, key change, or other compositional technique. A transition could be a com-\nbination of these things.\nTransitions may be triggered by a combination of game logic and music language\nlogic. It is useful to provide API functions for game code to directly set target states.\nThese types of implicit and explicit controls over transitions are another key element\nof the interactive control of music.\nTransition Types\nSome of the many transition types are mentioned in Table 6.6.3.\nThe simplest way to use music interactively is to simply switch music. If we have\none composition that is considered traveling music, and one composition that is con-\nsidered battle music, then when we stop traveling in the game to have a battle, the\nmusic switches at the same time. This type of musical interactivity is very common\nand very useful. We could even use a basic music sequencer to simply stop one tune\nand start another. If we want our transitions between tunes to be more musical or sub-\ntle, then we need more sophisticated functionality from our music sequencer. We\nmight want to overlap the two tunes so that one is heard to be fading off as the other\nfades in. We might want to have the tunes synchronized in some way as they go\nthrough this transition.\nTo use music interactively is not the same as making interactive music. This would\nmean that we actually change the character of a music composition through various\ncontrol methods. What if we want to gradually switch the timbres of instruments in\n\n\nSection 6 Audio Programming\nTable 6.6.3 Music Transition Types\nTransition Type\nDescription\nQuick\nSlow\nFading\nIntensity\nEffects\nKey\nChord\nHarmony\nMelody\nAccompaniment\nPercussion\nTransposing\nLayering\nFills\nRhythmic\nRandomness\nInstrument\nTiming\nMusic that stomps on previous music\nSubtle alterations and state changes\nFading whole sequences or just some tracks\nInstrument dynamics\nAny synthesis parameter changing\nCompositional changes\nCompositional changes\nCompositional changes\nCompositional changes\nCompositional changes\nCompositional changes\nCompositional changes\nCompositional changes\nEnter from any beat position, push music decoration events in to a queue\nLagging, ahead, modified swing\nControlled randomness of varying parameters\nSwitching instruments\nSwitching tempo\nthe music to make it seem more dangerous? What if we also want to gradually change\nthe mix of the music to emphasize our new instrument timbres and bring up the per-\ncussion? Now we are talking about interactive music. If we can design manageable\nways to control this complexity, we will have something pretty impressive.\nControl Granularity\nThe many ways to define and control volume are a great example of the levels of gran-\nularity available for music parameters. These volume control types are listed in Table\n6.6.4.\nWe can see that there can be many levels of control for certain audio parameters.\nWe might even want to group controls. It is useful to define the set of track volumes\nin a sequence as a mix. We can then command a sequence to switch to a given mix\ndefinition either immediately or gradually. We might want to externally control\nsomething like a sequence volume to turn it down while a character is talking. In\naddition, we might want to set up internal relationships such as ducking one\nsequence's volume when another sequence is playing.\n\n\n6.6 An Interactive Music Sequencer for Games \n555\nTable 6.6.4 Volume Types\nVolume Controls\nMaster\nMusic\nSequence\nTrack\nInstrument\nNote\nVoice\nDescription\nControls all audio.\nThe music volume controls all musical sequences.\nA sequence volume can be used to do fade in or fade out or ducking.\nEach track of a sequence has a volume. It is useful when creating music to be able\nto define the balance between tracks and to control crescendo and decrescendo.\nInstrument definitions may include volume. When defining instruments, we may\nwant a volume control so that the instrument can be programmed to have similar\nvolume range characteristics as other instruments.\nThe velocity parameter of a note. It is useful when creating music to have this\nbuilt-in volume control per note.\nThe value we pass to a particular synthesis voice. This value is determined from a\ncombination of the other volume types.\nTarget Control\nWhen we switch any parameter, we may want to do so immediately or gradually. To\nchoose the gradual behavior, we set a target volume and timeframe for the transition.\nInternally, the parameter is interpolated from its original level to its target level over\nthe given timeframe.\nWhen audio synthesis is involved, even if you are setting immediate parameter\nvalues, the internal synthesis behavior might actually result in a quick interpolated\ntransition from the original value to the \"immediate\" value over a short period of\ntime. In addition, some synthesis parameters might only allow modification before a\nvoice has been turned on and not while it is playing.\nThe abbreviated data structures for our music sequencer with new target controls\nare shown in Listing 6.6.1\nListing 6.6.1 Sequencer data structures with target control\ntypedef list< Sequence_t * > SequencePtrListjt;\ntypedef list< Track_t * > \nTrackPtrList_t;\ntypedef list< Voice_t * > \nVoicePtrList_t;\nclass MusicSequencer_t {\nMusicSequencerState_t State;\nSequencePtrList_t \nActiveSequencePtrList;\nSequencePtrList_t \nFreeSequencePtrList ;\nTrackPtrList_t \nActiveTrackPtrList ;\nTrackPtrl_ist_t \nFreeTrackPtrList;\nVoicePtrList_t \nActiveVoicePtrList ;\nVoicePtrList_t \nFreeVoicePtrList;\nclass SequenceState_t {\n\n\n556 \nSection 6 Audio Programming\nTempo_t \nTempo;\nVolume_t Volume;\n};\nclass Sequence_t {\nSequenceState_t \nState;\nSequenceState_t \nTargetState; \n// Interactive feature\nSequencelnterpolator_t Interpolator; \n// Interactive feature\nTimeUnit_t \nTimeElapsed;\nTimeUnit_t \nTimeStep;\nTrackPtrList_t \nTrackPtrList;\n};\nclass TrackState_t {\nVolume_t \nVolume;\nPitchBend_t PitchBend;\nPan_t \nPan;\nEffect_t \nEffect;\n};\nclass Track_t {\nTrackState_t \nState;\nTrackState_t \nTargetState; \n// Interactive feature\nTracklnterpolator_t Interpolator; \n// Interactive feature\nSequence_t \n*pOwner;\nchar \n*pEvent;\nInstrument_t \n*plnstrument;\nVoicePtrl_ist_t \nVoicePtrList;\n};\nHere we show new additions to our sequence and track data structures that allow\nus to interpolate from our current states to new target states. The TargetState and Inter-\npolator members define what the target values are and how fast to step toward them.\nDesign Examples\nThere are four important factors in the discussion of interactive music: game design,\ngame programming, music design, and music programming. Music programming is\ninfluenced by the other factors in the following ways:\n• Game design will influence music design.\n• Music design will influence music programming.\n• Game design will influence game programming.\n• Game programming will influence music programming.\nTo point out these influences, I will describe some interactive music design examples.\nDesign Example #1\nGame design: Through player skill, a character can achieve a powered-up state. This\nstate can last a very long time and a sound effect might get monotonous. We\nwant to hear his energy in the music.\n\n\n6.6 An Interactive Musfc Sequencer for Games \n557\nMusic design: Transition the melody and percussion track instruments to add DSP\neffects that add color and depth to the instruments.\nProgramming design: Two sequence states are created, and the game can choose\nwhen to set each target state.\nSummary: The music responds to the player's attributes. This way, the music tells\nthe player how he or she is doing.\nDesign Example #2\nGame design: When our player goes near a dangerous location in a level, we may\nwant to hint at that approaching danger, using the music to do so.\nMusic design: Fade down the main melody track and fade up die danger melody track.\nProgramming design: Based on distance from the location, set the track target\nstates for volume.\nSummary: The music responds to the player's location. This way, the music tells the\nplayer that there are new things to expect from this place.\nDesign Example #3\nGame design: Let's say we have a game design where we change from day to night.\nAssuming that the player's role is more offensive in the day and more defensive\nat night, we'll want energy music during the day, and tense and scary music at\nnight.\nMusic design: To keep it simple, we will describe three tracks of the music: melody,\naccompaniment, and percussion. We will define \"energy,\" \"mellow,\" and\n\"creepy\" versions of each of the three tracks. Again, keeping it simple, we will\ndefine \"energy,\" \"mellow,\" and \"creepy\" versions of each of the instruments for\neach track.\nWe could describe our transition table like Table 6.6.5.\nStop at each column in the table and you can see a different stage of the music.\nWe can consider each column a keyframe for our music control parameters. We can\nuse the control value shown to interpolate between the keyframes.\nTable 6.6.5 Day-to-Night Transitions\nGame Time\nControl Value\nMelody Track\nMelody Instrument\nAccompaniment Track\nAccompaniment Instrument\nPercussion Track\nPercussion Instrument\n12noon\n0.0\nEnergy\nEnergy\nEnergy\nEnergy\nEnergy\nEnergy\n3pm\n0.25\nEnergy\nMellow\nMellow\nEnergy\nEnergy\nEnergy\n6pm\n0.50\nCreepy\nMellow\nMellow\nMellow\nEnergy\nEnergy\n9pm\n0.75\nCreepy\nCreepy\nMellow\nCreepy\nMellow\nMellow\n1 2midnight\n1.0\nCreepy\nCreepy\nCreepy\nCreepy\nCreepy\nCreepy\n\n\n558 \nSection 6 Audio Programming\nProgramming design: We generate our control value based on the game time. This\ncontrol value is used to interpolate between instrument states and track states.\nTherefore, when our game time reaches 3 P.M., the melody instrument has fully\ntransitioned to the \"mellow\" state. When our game time reaches 6 P.M., the\n\"energy\" melody track has faded down and the \"creepy\" melody track has faded\nup.\nSummary: The music responds to the game state. This way, die music tells the\nplayer something about how to play die game, or how the game is progressing,\nor what to expect next.\nThe Code\nBuilding on die code presented in the basic music sequencer gem, die example code\nshows how to play music that can be interactively modified to new target states.\nThe example code uses a cross-platform audio engine called CSyn. The CSyn\nlibrary provided on the CD-ROM is for demonstration purposes only.\nConclusion\nThe reasons for developing your own interactive music sequencer code are the same as\nthe reasons for any code development. You may want standard features across many\nplatforms. There may not be systems available that meet your needs. You may want\nan implementation that you can optimize for delivering the particular features you\nneed. You may want control over your own code to provide improvements, enhance-\nments, and reliability in line with internal scheduling requirements.\nIn this discussion, we covered many motivations and implementation ideas for\ninteractive music. We presented some core programming concepts that can give us the\nflexibility and control we need. We pointed out the design influences, meanings, and\ntransition types. The next thing to do with all of these ideas is to implement your own\ninteractive music sequencer and make sure interactive music is part of your game's\ndesign.\nReferences\nCSyn audio engine, www.softsynth.com/csyn.\n",
      "page_number": 525,
      "chapter_number": 54,
      "summary": "Independent of the audio callback rate we will also have an update interval Key topics include music, musical, and control. Listing 6.5.3 is an outline of the audio callback code.",
      "keywords": [
        "music",
        "music sequencer",
        "Interactive Music",
        "Interactive Music Sequencer",
        "game",
        "Basic Music Sequencer",
        "Control",
        "Audio",
        "music design",
        "time",
        "music sequencer code",
        "track",
        "sequencer",
        "Interactive",
        "code"
      ],
      "concepts": [
        "music",
        "musical",
        "control",
        "controlling",
        "instrument",
        "instruments",
        "time",
        "timing",
        "sequences",
        "sequencer"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 8",
          "chapter": 52,
          "title": "Segment 52 (pages 499-510)",
          "relevance_score": 0.54,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 7",
          "chapter": 61,
          "title": "Segment 61 (pages 593-600)",
          "relevance_score": 0.51,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 7",
          "chapter": 36,
          "title": "Segment 36 (pages 337-344)",
          "relevance_score": 0.49,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 51,
          "title": "Segment 51 (pages 490-498)",
          "relevance_score": 0.49,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 7",
          "chapter": 50,
          "title": "Segment 50 (pages 487-494)",
          "relevance_score": 0.48,
          "method": "sentence_transformers"
        }
      ]
    },
    {
      "number": 55,
      "title": "Segment 55 (pages 536-543)",
      "start_page": 536,
      "end_page": 543,
      "detection_method": "topic_boundary",
      "content": "6.7\nA Low-Level Sound API\nIan Lewis, Acclaim Studios\nilewis@acclaim.com\nT\nhis gem describes a platform-independent, low-level sound API suitable for\ngames. This API could be a wrapper for DirectSound, OpenAL, or console-\nspecific APIs. A DirectSound reference implementation is provided on the CD.\nThe goal of the API is to provide a platform-independent, extensible API in C++.\nThe basic functionality must support:\n• Hardware-accelerated mixing\n• Software mixing and processing\n• One-shot and looping sounds\n• Wave caching\nIn addition, each feature must be extensible to support new platforms and features.\nCore Classes\nCWave \nWraps a wave audio source. Waves are always accessed indirectly\nby the output stage, so they can be cached and reused.\nCWavePtr \nIterator class for indirectly accessing a CWave. CWavePtr's main\nfunction is to fill a user-supplied buffer with bytes from the wave\nto which it points. CWavePtr maintains a current position and a\nloop flag to make sure the bytes come from the correct place in\nthe wave.\nThe base class is fully functional, but it can be extended if\nextra processing is needed. For instance, you might extend\nCWavePtr to convert a 16-bit PCM input source into floating-\npoint data, or to convert an ADPCM-encoded source into\nstandard PCM. CWavePtr can also be extended to provide\nplatform-specific memory functions. For instance, some console\nplatforms contain both areas of memory that are directly CPU-\naccessible, and memory areas that cannot be directly accessed by\nthe CPU. A CWavePtr-derived class might automatically move\nmemory from non-CPU-accessible to CPU-accessible RAM.\n559\n\n\n560\nSection 6 Audio Programming\nCMixer \nEncapsulates channel allocation and updating. Has a virtual\ntick() routine that should be called once per frame. (This is\nperhaps less elegant than running the mixer on a separate thread,\nas DirectSound does, but threads are hardly cross-platform...\nand since most threading OSs have a thread timeslice that is\ngreater than the length of a 60-Hz frame, threading can often\ncause more problems than it solves.)\nThe mixer can be extended to handle various hardware\narchitectures. The base class mixer does not allocate any memory\nfor channels, since derived class mixers may want to use their\nown channel implementations.\nCMixer: :channel \nThe base channel class is tightly coupled with CMixer, so it's\nimplemented as an inner class. Channels are responsible for\nmanaging a CWavePtr, which is the input to that channel. The\nchannel class extracts data from the CWavePtr on demand, keeps\ntrack of whether the CWavePtr is still playing or has (in the case\nof one-shot sounds) finished, and deletes the CWavePtr when it\nis done\nThe channel class can also be extended to meet varying\nneeds. The sample source for this article contains\nimplementations for a DirectSound accelerated channel and a\nsoftware-based mixer channel.\nCMixer-channel also contains a virtual tick() function,\nwhich is called from the base CMixer: :tick(). This allows\nplatform-specific channel implementations to perform hardware\nhousekeeping. For instance, the\nCDirectSoundAcceleratedChannel implementation uses tick() to\napply the channel's gain and pan parameters to the hardware\nbuffer\nCAudioBufTer \nEncapsulates a pointer to audio data and a length. Used to pass\ndata around the system.\nCWaveDesc \nEncapsulates a platform-independent wave description. It\nstrongly resembles Microsoft's WAVEFORMATEX, but contains\nsome extra fields for platform independence.\non me co\nThe sample source on the CD contains implementation classes for various\nDirectSound-based classes, showing how hardware acceleration, software mixing, and\nDSP-style processing can be worked into the base classes. This implementation is, of\ncourse, not optimized and is written more for readability than for performance.\n\n\nAPPENDIX\nAbout the CD-ROM\nThe CD-ROM that accompanies this book contains a wide variety of useful informa-\ntion designed to make your life easier as a game developer. Here are some of the things\nthat are included on the disc:\n• All of the gem source code listed in the book\n• Demos of many of the techniques described in the book\n• The DirectX SDK\n• The glSetup Monolithic version\n• The OpenGL Utility Toolkit (GLUT)\n• High-resolution versions of the color plates\n• Links to useful and interesting game development sites\nComplete installation and usage instructions are included on the CD-ROM in\nthe AboutThisCD.htm file. Please read this first.\nAlso, be sure to visit the Web site www.GameProgrammingGems.com, for more\ninformation about the series and about game programming!\n561\n\n\nIndex\nA* algorithm, 250\npathfinding and, 315, 325\nwaypoints and, 315\nAbstract interfaces\ndescribed and defined, 20-22\ndisadvantages of, 26-27\nfactories, 22-23\nas traits, 23-26\nvirtual destructors, 23\nAccidental complexity, 258-259\nAlgorithms\nA* algorithm, 250, 315, 325\nBloom Filter algorithm, 133\ncollision detection, 228-238\ncombinatorial search algorithms, 354\nline / line intersection, 191\nMarching Cubes algorithm, 229\nrandom number generator algorithm, 130\nRecursive Dimensional Clustering (RDC), 228-238\nAliasing\nbilinear filtering and, 485\n\"pre-jitter\" technique, 485—486\nshadows and aliasing problems, 484-486\nAlignment, flocking rule, 330\nAllocateMemoryO routine on CD, 67\n\"Alt-Tab\" problem, 82-83\nAnimation\nbone animation keys, 148\nclouds, procedural texture generation, 463-473\nmesh deformation and skin calculation, 149\nprojective self-shadowing techniques for characters,\n421-424\nsimple animation scheme, 429-431\nSuper Mario 64 controls, 431\nsystem time and smooth animation, 148\nthird-person control schemes for, 425-432\n3ds max skin exporter and animation toolkit,\n141-152\nSee also Bones\nAPI functions, explicit DLL loading and, 36\nArtificial Intelligence (AI)\naccidental complexity, 258-259\narchitecture, 251-272\nbehavioral module, 266\ndecision making and intelligent agents, 287\ndistributed processing, 253\nemergent behavior to avoid scripting, 255\nevent-driven behaviors, 251-252\nflocking, 330-336\nfuzzy logic, 343-350, 347\nfuzzy state machines (FuSM), 337-341\ngame programming vs. academic research,\n249-250\ninfluence mapping, 287-297\ninnovations in, 256\nLevel-of-DetailAI,254\nmanager entities and centralized cooperation,\n252-253\nneural networks, MLPs, 351-357\npathfinding, 152, 252, 274-275\npersonalities and, 306, 332-333\npolling, 251-252\nprecomputing and preprocessing, 255\nproblem solving shortcuts, 254\nprocessing issues, 253-254\nprocessing peaks, avoiding, 253\nreal-time strategy issues, 272-306\nredundant calculations, reducing, 252\ntactical decisions, 287-316\nterrain reasoning, 307-316\nupdating data, 255-256\nSee also Micro-threads, AI architecture\nArtificial Life by Steven Levy, 335\nAudio design patterns\nBig Ball of Mud (spaghetti code) audio design\npattern, 518-519\nbridge audio design pattern, 514-515\ncommand audio design pattern, 517\ncomposite audio design pattern, 515-516\ndecorator audio design pattern, 517\nfacade audio design pattern, 515\nmomento audio design pattern, 518\nobserver audio design pattern, 518\nproxy audio design pattern, 516\nAudio processing pipelines, interactive, 529-538\nbackfill buffers in, 534-537\n563\n\n\n564\nIndex\nAudio programming\naudio design patterns, 514-520\nDigital Signal Processing (DSP) techniques,\n525-528\ninteractive processing pipeline for digital audio,\n529-538\nlow-level sound API, 559-560\nmusic sequencers, 539-558\nsample-based synthesizer for voices, 521-524\nAudio systems\ndescribed, 529-531\nschematic illustration of, 530\nAuthors, bios and contact information for, xix-xxxfi\nAvoidance, flocking rule, 330\nAxis-aligned bounding box (AABB) tree structures\nbuilding AABB trees, 390\ncompressing AABB trees, 390-391\ndescribed, 388\nextent value approximation, 391\nredundancy in, 392\nresources required, runtime costs, 393\nAxis-aligned bounding boxes, 389\nBackfill buffers for underflow data, 534-537\nBand-limited noise, 466\nBehavioral classes, 53\nhierarchy for, 54-55\nBehaviors\nactive behaviors and brain classes, 267\nAI design and, 265-268\nbehavioral module example, 266\nCombs method and fuzzy logic for, 342-350\nemergent behaviors, 255, 332-333\nevent-driven behaviors for AI optimization, 251-252\nflocking, 330-336\nTemplate Method pattern for assigning, 55\nBinary space partitioning (BSP) trees, 388\nBit maps and bit mapping, fast bit blitter for, 92-99\nBlitters, 92-99\nBloom, Burton H., 133\nBloom Filters, 133-140\ndefinitions related to, 134-135\ndescribed, 134\nexceptions lists and, 139-140\nflow chart illustrated, 136\ntuning, 135-138\nuse fundamentals, 137\nBlurring\nSee under Influence maps\nBones\nbone animation keys, 148\nbone assignments, 150-151\nposition and rotation of, 148-149\nsegmenting character geometry and, 421—422\nweighting, 146-148\nBoolean values, text parsers, 115\nBottlenecks, profiling module for identifying, 74-79\nBounding volume trees, 389\nBounds violations, defined and described, 69\nBrains\nbrain classes, 267-269\nbrain queues and cyclic commands, 274-278\nBridge audio design pattern, 514-515\nBSP (binary space partitioning) trees, 388\nBuffers\nbackfill buffers for underflow data, 534-537\nindex buffers, 372-375, 378-379\npriority buffers vs. depth buffers, 483\npriority buffers described, 483\npriority buffers used for shadows, 481-487\nBugs and debugging\nabstract interfaces and, 26\ncode bloat and, 11\ndeprecated functions and, 63\ndrop-in debug memory manager, 66-73\nOutputDebugString (), Windows NT, 263\nreproducing bugs, 105-106\nstructured exception handling and micro-threads,\n263\nC++\ndeprecation facilities for, 62-65\nexporting classes from DLLs, 28-32\nimplicit linking support in, 33-34\noptimization techniques, 5-15\nproperty class for generic member access, 46-50\nrecursive searching, 89-90\nstack winding and, 88-90\nCache misses, 18\nCallbacks, 545, 547-549\nCamera cuts, 220, 225-226\nCameras\ncamera cuts, 220, 225-226\nflythrough paths for, 220-227\nfree-floating cameras, 425\nimpostoring and camera distance, 494\nlens-flare effects, 474-480\norientation interpolation, 222-223\nposition interpolation, 220-222\nweb cameras, 153-162\nCartoon rendering\nprogrammable vertex shaders and, 444-451\nsilhouette edge detection and, 436-443\ntexture mapping and, 444-451\nCaustics, simulating water in a fish tank, 402-405\nCellular automata, 506-508\n\n\nIndex\n565\nChild classes, data 43-44\nCiphers as mixing functions, 129\nClasses\nexporting from DLLs, 28-30\nSee also Specific classes\nClass member functions, exporting from DLLs, 30-31\nClosed-form equations, used to calculate nearest points\non lines, 194-198\nClouds\nadditional features for procedural clouds, 470-471\ncharacteristics of, 463-464\nFBM fractals used to create, 245\nmapping to skyplane, 469-470\nprocedural cloud generation, 463-473\nrandom number generation and, 464-465\nscalability of procedural generation techniques,\n471-472\n\"vapor\" creation, 469\nClutter. See Impostors\nCode bloat, 11-12\naccidental complexity in AI, 258-259\ninline functions and, 18\nCohesion, flocking rule, 330\nCollision detection\naltitude relative to collision plane, 182-183\nbrute-force comparison algorithm for, 228\ndistance to collision point, 184-185\nfinding pairs with RDC, 234-235\nkickback collisions, 187-188\nline / line intersections, 191-204\nlocation of collision point, 183-184\nRecursive Dimensional Clustering (RDC), 228-238\nreflected vectors (bounces), 185-187\nvector / plane intersections, 182-190\nSee also Collisions\nCollisions\nwith damping, 188-190\npathfinding and, 317-323\nsphere-to-plane collisions, 189-190\nSee also Collision detection\nCollision shapes, selecting, 318-321\nCombs, William, 343\nCombs Method for managing exponential growth,\n343-349\nproof for, 348-349\nCOM interface search, alternatives to, 46-50\nCommand audio design pattern, 517\nCommand queues, audio design and, 517\nComposite audio design pattern, 515-516\nComputation, history and development of, 165-166\nConstructors\nexplicit vs. implicit, 8\noptimization and, 7-8\nControl schemes\ncamera-oriented controls, 425\ncharacter rotation and input, 427—428\nconverting player's input for third-person control\nsystems, 425-427\ndampening formula for smooth character control,\n427-428\nsimple animation scheme, 429-431\nthird-person control of animated characters,\n425-432\nConvolution, 526-527\nConway, John, 506\nCore editor modules, generic, 46—50\nCosine functions, lookup tables for, 174-175\nCramer's rule, 196-197\nCreational dependencies, 302-304\nCryptographic hashes as mixing functions, 129\nCube environment mapping, 419\nCubemap normalization, 459-460\nCubic interpolation, DSP techniques, 528\nCulling, sphere trees for, 384-387\nCycle counters, 180\nDampening formula for smooth character control,\n427-^28\nDatabases\ngame save databases and persistent type information,\n44\ntweakable instance database, 123-124\nData files, preprocessing, 113-114\nDeAllocateMemoryO routine on CD, 67\nDebugging. See Bugs and debugging\nDecals\nalgorithm for, 41 I^il3\non complex surfaces, 411-415\ndefined, 411\ntriangle clipping and, 413-414\nDecorator audio design pattern, 517\nDependency\ncreational dependencies, 302-304\nand resource allocation trees, 302-304\nvulnerable dependencies, 304-305\nDEPRECATE macro, 64-65\nDeprecation\nadding facilities to C++, 62-65\nimplementation of, 64-65\nDesirability values, 290-292\nDestructors, virtual destructors in abstract interfaces,\n23\nDeterminism\ndefined, 105\nrandom numbers and, 109\nSee also Predictability\n\n\n566\nIndex\nDigital Signal Processing (DSP)\nconvolution, 526-527\ncubic interpolation, DSP techniques, 528\ndelays, 527\nfiltering technique, 525-526\ninteractive audio processing pipeline, 529-538\ninterpolation, 528\nlinear interpolation, DSP techniques, 528\nreverberation effects, 527\nsample averaging, DSP interpolation, 528\nsample doubling, DSP interpolation, 528\nDigital Signal Processing (DSP) techniques, 525-528\nDirectX, DLLs and required components, 34—36\nDLLs. See Dynamic Link Libraries (DLLs)\nDot3 Bump mapping, 456—459\nDrop-in debug memory manager\nlogging, 68-70\nmemory allocation and deallocation routines, 67-68\nreports from, 70-71\nDynamic_cast operator, 42\nDynamic Link Libraries (DLLs)\nAPI functions, 36\nclass member functions, exporting, 30-31\nDirect X components and, 34-36\nexplicit vs. implicit linking and, 33-34\nexporting C++ classes from, 28-32\nFreeLibrary, 34\nGetProcAddress, 34-36, 37\nLoadLibrary, 34, 37\nmemory-tracking programs and, 29\nOS specific features, 36-37\nvirtual class member functions, exporting, 31-32\nDynamic type information (DTI) class\ndescribed, 38-39\nexposing and querying, 39-40\ngeneric objects and, 41-43\ninheritance and IsA function, 40-41\nEconomic systems, resource allocation trees and, 302,\n304\nEdge collapse, binned vertices, 365\nEdge detection, 502\nsilhouette edge detection and rendering, 436—443\nEdge split, defined, 365\nEfficiency. See Optimization\nEmergent behaviors, 255, 332-333\nEncryption, 104\nEntities\ndeath of entities, AI management strategies, 269-270\nEntity class and subclass, 54-55\nentity managers and cooperation among AI agents,\n252-253\nruntime strategies for, 58-60\nException lists, 139-140\nExponential growth, Combs Method to manage,\n343-349\nExported classes, 50, 56-57\nFacade audio design pattern, 515\nFactories\ndefined and described, 57-58\nEntity factories, 57\ngame entity factory, 51-61\nFactories, abstract interfaces and, 22-23\nFBM (fractal brownian motion) fractals. See Fractal\nbrownian motion (FBM) fractals\nFibers, cooperatively multi-tasking threads, 260\nFile lump structure, 101\nFiles, management using resource files, 100-104\nFilters and filtering\nbilinear filtering and aliasing, 485\nBloom Filters, 133-140\nFinite Impulse Response (FIR) filters, 525-526\ntexture filtering, 418, 479\nFinite Impulse Response (FIR) filters, 525-526\nFish tanks, simulating refraction effects in, 402-405\nclip planes and stencil buffer, 404-405\nprecomputations, 403\nscale factor for tank, 403—404\nshear factor for tank, 404\nFixed Up method vs. parallel transport frames, 218\nFloating-point numbers\nabsolute values, 174\narbitrary functions, 177-179\nclamping values to a specific range, 173—174\ndefined, 167\nfloat/int conversions, 169-172\nIEEE floating-point format, 168-169\ninitial state variations and, 108\ninteger comparisons, 173\nIntel architecture and, 261\nlinear quantization, 178\nlogarithmic quantization, 178-179\nperformance measurement after optimization, 180\npropagated influence values and, 293\nsign test for, 172\nsquare root optimization and, 176-177\ntext parsers, 115\nFloats. See Floating-point numbers\nFlocking, 330-336\nboids, varieties of, 332-333\nrules of, 330-331\nFlocking with Teeth demo, 334\nFlythrough paths\nnatural cubic splines and, 221-222\nquaternion-based flythrough paths, 220-227\n\n\nIndex\n567\nFlyweight classes, 53\nFlyweight objects\ndescribed, 52\nState And Media Manager (SAMMy), 52-54\nFog-of-War (FOW)\ndefined, 280\nvisibility and, 279\nFormats\nfast bit blitter for conversion of, 92-99\nMRC file format for exporting, 142-143\nFractal brownian motion (FBM) fractals\nclouds created with, 245\ndescribed, 241-242\nlandscapes created with, 245\nnoise generator implementation, 242-245\nturbulent noise function, 467\nFractals\ndefined, 239\nfault fractals, 240-241\nmultifractals, 244-245\nplasma fractals, 240\nprogramming, 239-246\nterrain creation, 239, 246\nSee also Fractal brownian motion (FBM) fractals\nFreeQ, 9\nFreeLibrary, 34\nFree lists, memory management and, 9\nFrenet Frames vs. parallel transport frames, 217-218\nFunction pointers, used within C++ classes, 59—60\nFunctions\nchaining and TempRet routine, 86-87\ndeprecated functions, 62-65\nexporting from DLLs, 28\nFuzzy logic\ncombinatorial explosions and, 342-350\nCombs Method and, 343, 348-349\nCombs Method rules for, 344-348\ndefined, 337\nsets in, 342\ntraditional rules for, 343-344\nvariables in, 342\nFuzzy state machines (FuSM), 337-341\nadapting generic FSMs, 339-341\nincreasing gameplay with, 338-339\nuses in games, 339\nGame engines\ndata-driven development, 51-61\nGPU / CPU parallelism, 475\ninput recording and, 105-111\n\"Game of Life,\" 506-508\nGaussian elimination, 196-197\nGenRandQ, 131-132\nGeometry management of 3D models\naxis-aligned bounding box (AABB) trees and,\n388-393\ncube environment mapping, 419\ndecals on complex surface, 411-415\nprojective self-shadowing techniques, 421-424\nquadtree lookup, direct access, 394—401\nsegmenting character geometry, 421-422\nskyboxes and distant scenery, 416-420\nsphere trees and, 384-387\nterrain creation with interlocking tiles, 377-383\nVIPM methods, comparison of, 363-376\nGetProcAddress function, 34\nGraphical User Interfaces (GUIs), tweaker interface\nGUI, 124-125\nGraphics display\nhardware accelerated procedural texture animation\nand, 497-509\nhardware limitations and, 508\nimpostoring, 488^496\nlens flare using texture masking, 474-480\nper-pixel lighting techniques, 452—462\npipeline stalls, 475-477\nprint-resolution of screenshots, 406-410\nsilhouette edge detection and rendering, 436-443\ntexture mapping and programmable vertex shaders,\n444-451\n/GR switch, 42\nGUIDs, text parsers, 116\nHandles, used in proxy audio design, 516\nHardware\ncloud generation with, 463-473\ndisadvantages when used for procedural textures, 471\nprocedural rexture animation and, 497-509\nrendering print-resolution screenshots with, 406-410\nas source for random numbers, 129\nHashing functions, 129, 134\nHash Table template, 48\nHeader files, 101-102, 113-114\nHeight advantage, as tactical assessment factor, 296\nHerding. See Flocking\nHierarchies\nBehavior class hierarchy, 54-55\nof C++ classes, method for describing, 51-61\nIEEE floating-point format, 168-169\nImpostors\nbillboard quad rendering, 490\nbounding object rendering, 491-492\ncamera distance and updates, 494\ncuboid rendering, 490-491\ndescribed, 488\n",
      "page_number": 536,
      "chapter_number": 55,
      "summary": "This chapter covers segment 55 (pages 536-543). Key topics include functionality, function, and functions. Covers design, pattern. The basic functionality must support:\n• Hardware-accelerated mixing\n• Software mixing and processing\n• One-shot and looping sounds\n• Wave caching\nIn addition, each feature must be extensible to support new platforms and features.",
      "keywords": [
        "audio design pattern",
        "Audio design",
        "design pattern",
        "audio",
        "Low-Level Sound API",
        "design",
        "API",
        "Sound API",
        "pattern",
        "Classes",
        "functions",
        "processing",
        "API functions",
        "channel",
        "command audio design"
      ],
      "concepts": [
        "functionality",
        "function",
        "functions",
        "classes",
        "audio",
        "describes",
        "describing",
        "defined",
        "technique",
        "patterns"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 8",
          "chapter": 53,
          "title": "Segment 53 (pages 511-519)",
          "relevance_score": 0.74,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 7",
          "chapter": 63,
          "title": "Segment 63 (pages 609-616)",
          "relevance_score": 0.71,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 52,
          "title": "Segment 52 (pages 499-510)",
          "relevance_score": 0.68,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 7",
          "chapter": 61,
          "title": "Segment 61 (pages 593-600)",
          "relevance_score": 0.67,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 7",
          "chapter": 37,
          "title": "Segment 37 (pages 345-352)",
          "relevance_score": 0.63,
          "method": "sentence_transformers"
        }
      ]
    },
    {
      "number": 56,
      "title": "Segment 56 (pages 544-551)",
      "start_page": 544,
      "end_page": 551,
      "detection_method": "topic_boundary",
      "content": "568\nIndex\nImpostors (cont.)\ngame-specific updates, 494\nimage warping and, 492\nlighting and updates, 494\nprediction of impostor states, 495\nrendering, 489-493\nupdate heuristics, 493-494\nuses of, 495-496\nviewing angles and updates, 494\nIncrement functions, optimization and, 7\nIndex buffers\nin sliding window VIPM, 372-375\nas tile templates, 378-379, 380\nInfluence maps\nAI optimizations, 256\ncell data types, 289-290\ncell size, determining optimal, 292\ndescribed, 287-289\ndesirability values, 290-292\nfalloff rules, 292-293\ninfluence propagation (smoothing or blurring),\n292-293\nrefreshing influence maps, 295-296\nterrain and impacts on, 293-297\nin 3D environments, 296\nInheritance\nabstract interfaces as traits and, 23-26\nIsA function and dynamic type information (DTI)\nclass, 40-41\nmultiple inheritance, 45\nInitializer lists, 6-7\nInking for nonphotorealistic rendering\nadvanced texture features and inking, 442\nedge-based inking, 438-440\ninking described, 436-437\nprogrammable vertex shader inking, 440-442\nInline functions, 11-12\nadvantages of, 16-18\ncode bloat and, 18\nvs. macros, 16-19\nparameter types and, 18\nInline keywords, Microsoft specific keywords, 19\nInlining. See Inline functions\nInput recording\nbug reproduction with, 105-106\ngame movie creation, 107\nmeasuring optimization with, 107\nmultiplayer uses of, 107, 110\npredictability and, 107-108\nreplaying interesting games, 106\ntesting techniques for, 110\nuses of, 105-107\nInputs\nconverting player's input for third-person control\nsystems, 425-427\nrandom number generators and, 128-129\nInstruction pointers, 260-261\nIntegers\ninteger / float conversions, 169-172\ntext parsers, 115\nInteraction\ninteractive audio processing pipeline, 529-538\ninteractive music sequencer, 551-558\nweb-cams for multiplayer games, 153\nInterface functions, deprecation facilities and, 62-65\nInterpolation\ncubemap normalizer to correct problems, 459-460\ndefined, 527\nDSP and linear interpolation, 528\nspline interpolation technique, 224-225\nvectors across line or plane, 189\nIntersections, techniques for calculating, 191-204\nIsA function, dynamic type information (DTI) class\nand inheritance, 40—41\nK-d trees, 388\nKeywords, text parsers, 115\nLandscapes. See Terrain\nLazy evaluation, 254\nLens flares\nasynchronous readback of buffer data, 480\ngeometry-based approaches, 480\nhardware issues, 475-477\nocclusion, 474\ntexture masking demo, 479—480\ntexture masking for, 474, 477-478\nLevel-of-Detail (LOD)\nAI optimization, 254\ntile landscapes and determination of detail, 380\nLevy, Steven, author of Artificial Life, 335\nLights and lighting\ncode for 3D lightmap with quadratic falloff,\n453-455\nDot3 Bump mapping, 456—459\nimpostoring and, 494\nlight maps, 452-459\nper-pixel spotlights, 460-461\nper-pixel techniques, 452—462\nSee also Shadows\nLinear programming\n\"Alt-Tab\" problem in multitasking, 82-83\nmultithreading, 81-84\nsurfaces, video memory and loss of information,\n83-84\nfor Windows-based games, 80-84\n\n\nIndex\n569\nLinear quantization and floating-point numbers, 178\nLine-of-Sight (LOS)\ndefined, 280\nLOS radius defined, 280\nLOS search systems, 279-286\ntemplates, 281-283\nLines and line segments\ndegenerate lines, 198-199\nfinite line segments, 200-203\nintersection calculation, 191-204\nnearest points calculated with closed-form solution\nequations, 194-200\nnearest points on finite segments, 200-202\nparallel lines, 199, 201-202\nLinking, explicit vs. implicit, 33-34\nLoadLibrary function, 34\nLocations\ntactical analysis of, 309-310, 315\nterrain reasoning for 3D games, 307-316\nLogarithmic quantization and floating-point numbers,\n178\nLogs and logging\naudio system activity and, 519\nmemory manager logging, 68-70\nLookup tables, for trig functions, 174-176\nLoops, object construction and, 6\nLOS. See Line-of-Sight (LOS)\nMacros\nDEPRECA TE macro, 64-65\nvs. inline functions, 16-19\nstate machines created with, 19\nMallocQ, 9, 67-68\nMaps\ncombined visibility maps, 283-286\ncubemap normalizer to correct interpolation\nproblems, 459-460\nDot3 Bump mapping, 456-459\nheight maps, 503-504\ninterlocking landscape tiles and height maps,\n379-380\nlightmapping, 3D textures, 452—459\nplayer visibility maps, 281-282\nshadow maps, 422\nMAX. See 3ds max skin exporter and animation toolkit\nMemcpyO, 13\nMemory\nAABB tree optimizations, 388-393\nbounds violations, 69\ncode bloat and, 11-12\ndrop-in debug memory manager, 66-73\nfragmentation and Standard Template Library\n(STL), 13-14\nfreeO, 9, 67-68\ninline functions and, 18\nleaks, 70-71\nmanaging for optimization, 9\nmemcpyO, 13\nmemory tracking, 29, 66-73\nMFC's memory manager, 72\nprocedural textures to spare, 497\nStandard Template Library and, 12—14\nVIPM memory costs, 363-364\nSee also Memory allocation\nMemory allocation\nallocating for stacks, 262\nalternatives to mallocQ, callocQ, reallocQ, andfrecQ,\n67-68\nmallocO, 9, 67-68\nweb camera allocation, 155-156\nMemory managers, drop-in debug memory manager,\n66-73\nMeshes\ndeformation and skin calculations, 149\nexporting to file, 149-150\nReal-Time Optimally Adapting Meshes (ROAM),\n377-378\nresolution defined, 365\nView Dependent Progressive Meshes (VDPM),\n377-378\nView-Independent Progressive Meshing (VIPM),\n363-376\nMessage pumps, alternatives to, 80-84\nMetaball clusters, RDC algorithm and Marching Cubes\nalgorithm, 229\nMFC, new and delete operators in, 72\nMicro-threads, AI architecture\n\"brains\" to run, 267-268\nloading and saving, 263\nstack management, 262\nstate machine coding and, 265-266\nstructured exception handling, 263\nswitching between threads, 260-262\ntroubleshooting, complications, 263\nMIDI (Musical Instrument Digital Interface),\n541-543\nMinkowski sums, 319-322\n\"lazy man's Minkowski sum,\" 321-322\nMirages, 286\nMixing functions and randomness, 129\nMLPs. See Multiplayer perceptrons (MLPs)\nModules\nfile management using resources files, 102-104\ngame profiling, 74-79\nmemory-tracking module, 66-73\nMomento audio design pattern, 518\n\n\n570\nIndex\nMotion\nforward motion and animation, 428—429\nparallel transport frames for orienting moving\nobjects, 216-217\nMotion detection, web cameras and, 157-158\nMovies, input recording to create game movies, 107\nMRC file format, 142-143\nMultiplayer games\ninput recording and, 107, 110\nweb-cam interaction for, 153\nMultiplayer perceptrons (MLPs)\ncollecting data for, 354-355\ndescribed, 351-353\ninput selection and training, 353-354\nperturbation searches and, 355-356\nresources required for, 356-357\ntraining, 353-354, 355-356\nMultitasking in games, 82-83\nMultithreading, 81-84\nMusic\nassociations with, 551-552\nbasic music sequencer, 539-550\ncallbacks, 545, 547-549\ncontrol granularity, 554-555\nevent blocks, 540-541\nevent data structures, 546-547\nmeanings of, 552-553\nMIDI (Musical Instrument Digital Interface),\n541-543\nmodifications, 544\nnote control, 544\nsequencer data structures, 545-546\nsequencer implementation, 543-549\nsequencing methods, 539-540\nstreaming method, 539-540\nsynthesizer / sequencer connection, 549-550\ntiming calculations, 548-549\ntransitions in, 553-554\nvolume control, 554-555\nMusical Instrument Digital Interface (MIDI), 541-543\nMusic design, factors for interactive music, 556-558\nNearest-point calculation, closed-form equations for,\n194-198\nNeural networks, multiplayer perceptrons (MLPs),\n351-357\nNodes, export routines and, 144-145\nNoise\nanimating an octave of noise, 466-468\nband-limited noise, 466\nfractals and pink noise, 241-242\nPerlin noise, 466\nturbulent noise creation, 467—468\nNonphotorealistic rendering (NPR)\ninking for cartoon rendering, 436-443\npainting for cartoon rendering, 444—451\nNvidia's Developer Web site, 509\nObjects\nconstruction and destruction of, 5-8\ngeneric member access, 46-50\ngeneric objects, 41-43\norientation of moving objects, 215-219\npreallocation and caching of, 8\nRDC algorithm to find groups, 229\nObserver audio design pattern, 518\nObstacles, defined, 331\nOctrees, 388\nvs. sphere trees, 385\nOpenGL, texture wrapping settings for skyboxes, 418\nOperators\noptimization and return by value, 7\ntext parsers, 115\nOptimization\nArtificial Intelligence strategies, 251—257\nfor C++ games, 5-15\ncode size and, 11-12\nconstructors and, 7-8\nevent-driven behaviors vs. polling, 251-252\nimpostoring and render targets, 494-495\nincrement functions and, 7\ninitializer lists, 6-7\nLOS templates for player visibility systems, 281-283\nmanager entities to centralize cooperation, 252-253\nmeasuring with input recording, 106\nmemory management techniques for, 9\nmemory usage, 66-73\nobject construction and destruction, 5-8\nobject preallocation and caching, 8\noperators, 7\nof points-of-visibility pathfinding, 324—329\nprofiling for, 5\nquadtree access routines, 394-401\nredundant calculations, 252\nStandard Template Library and, 12-14\ntemplates and, 14\ntrigonometric functions and, 213-214\nvirtual functions and, 9—11\nOS threads, 260\nPage faults, 18\nPainting for nonphotorealistic rendering\ncomputing Toon texture coordinates, 438—440,\n446-448\npainting described, 444-445\nprogrammable vertex shaders, 448-450\n\n\nIndex\n571\nParallax values, 492-493\nParallel transport frames\ncalculation of, 215-216\nvs. Fixed Up method, 218\nvs. Frenet Frames, 217-218\nused to orient objects, 215-219\nParameter types, inline functions and, 18\nParser class of parsing system, 114-116\nPassability, as tactical assessment factor, 296\nPathfinding\nAI pathfinding, 152, 274-275\ncollisions and, 317-323\ndistributed processing for optimization, 253-254\nhierarchical on-demand pathfinding, 254—255\nprecomputing propagated influence values, 294—295\nredundant computations and, 252\ntile-based pathfinding, 325\nwaypoint queuing and, 274-275\nSee also Points-of-visibility pathfinding\nPaths\nquaternion-based flythrough paths, 220-227\nSee also Trajectories\nPatrolling, command queuing in RTS, 275-278\nPauses, in audio design, 518\nPerformance\nBloom Filter to improve, 133-140\ncommercially available tools for tuning, 75\ncycle counters, 180\nfloating-point numbers and, 167-181\nmeasuring, 180\nprofiling module, 74-79\nsearching systems for tile-based games, 279\ntuning with commercially available tools, 75\nSee also Optimization\nPer-pixel spotlights, 460-461\nPersistent type information, 43-44\nPersonality, creating in AI, 306, 332-333\nPerturbation searches, 355-356\nPlayers\ndefined, 280\npersonalities for AI players, 306\nPlayer visibility systems, 279-286\ncombined visibility maps, 283-286\nLOS templates, 281-283\nmaps, 281-286\nmirages, 286\nplayer visibility maps, 281-282\nPointers\nfunction pointers used within C++ classes, 59-60\ninstruction pointers, 260-261\nsmart pointer systems, 269\nstack pointers, 260-261\ntracking pointers, 271\nPoints-of-visibility pathfinding\ncollision models for, 318\ncollision shape selection, 322-323\nexpanded geometry for, 317-323\nMinkowski sums of polygons, 319-322\noptimization of, 324-329\nsilhouette points and, 325-326\nsilhouette zones and, 327-329\nspatial partitioning, 329\nvs. tile-based pathfinding, 325\nPolygonal pathfinding. See Points-of-visibility\npathfinding\nPostincrement functions, 7\nPrecalculating. See Preprocessing\nPrecomputing. See Preprocessing\nPredators and Prey flocking demo, 330-336\nPredictability, 105\ngenuine randomness and, 127—128\ninitial state predictability, 108\ninputs and, 109-110\nprotecting game predictability, 107-108\npseudo-random numbers and, 127\nrandom numbers, 109\nPreincrement functions, 7\nPreprocessing\nAI optimization and, 255\nof data files, 113-114\ninfluence maps, 293—297\npropagated influence values, 294-295\nsegmenting character geometry, 421-422\nPrint resolution of screen shots, 406-410\nalgorithm for, 406-409\nProbability, strategic inference using dependency\ngraphs, 305\nProcedural textures\ncloud generation, 463-473\ndependent texture addressing, 505-506\nhardware accelerated animations, 497-509\nheight-field water as, 501-503\nneighbor sampling and, 498-504\nsampling methods, 485-504\nscalability of, 471-472\nProfiling modules\narchitecture, 76-77\nbasic mechanisms for, 74-75\nbuilt-in game profiling module, 74-79\ndata analysis, 78\nimplementation, 78-79\nperformance counter manager (IPerfCounterMan),\n76\nProjective shadowing techniques, 421—424\nProperties, alternatives to Borland's proprietary, 46-50\nProxy audio design pattern, 516\n\n\n572\nIndex\nPseudo-random numbers\ncloud generation and, 464-465\npseudorandomness described, 127\npseudo-random number generators, 109, 465\nsimple pseudo-random number generator code, 465\nQuadtrees\naccess routine optimization, 394-401\nvs. sphere trees, 385\nQuadtrees, direct access lookup\nconditions and requirements, 395-396\nlevel determination, 396-398, 401\nlocation of target node, 399\ntraversing, 399\ntuning, 399-400\nQuaternions\nflythrough paths and, 220-227\nas orientation data, 222-223\nselective negation to preprocess, 220, 223-224\nsingularity in rational mapping, 225\nspline interpolation technique, 224-225\nRAM-code. See Self-modifying code\nRand() function, alternatives to, 109\nRandom number generation\nimplementation of, 130-131\nnoise generation using, 242-244\nprocedural cloud generation and, 464-465\nspeed limitations of process, 129-130\nRandom numbers and randomness, 109\nhardware as source, 129\nmixing functions and, 129\nrandom number generators, 127-132\nRay tracing , sphere trees for, 384-387\nReal-Time Optimally Adapting Meshes (ROAM),\n377-378\nReal-time strategy (RTS) games\ncommand queuing for, 273-278\ncommands for, 273\ncyclic commands (patrolling example), 275-278\nLine-of-Sight searching systems for, 279-286\nwaypoint queuing and pathfinding, 274-275\nRecursive Dimensional Clustering (RDC), 228-238\npseudocode for RDC algorithm, 235-236\nrecursion and time complexity, 236-237\nsteps for, 232, 234\nReflections, 405\nRefraction, simulating refraction effects, 402—405\nReplays, input recording to replay interesting games,\n106\nResource allocation trees, 298-300\ncurrent resource allocation, determining, 300-301\ndependency graphs, 302-304\ndesired resource allocation, calculating, 300\nmeasuring values in branches of, 302\npersonality creation and, 306\nstrategic decision making, 301-302\nResource files\ndefined and described, 100\nimplementation of modules, 102-104\nresource system design, 101-102\nused for file management, 100-104\nRTS. See Real-time strategy games (RTS)\nRTTI. See Runtime type information (RTTI)\nRuntime type identification (RTTI)\nComponent Object Model (COM) as alternative to,\n24\nRuntime type information (RTTI)\ncode bloat and, 12\noptimization, 14\nRTTI typeidO, 125-126\nScreen shots, print resolution, 406-410\nScripting\nalternatives to, 51-60\nemergent behaviors as alternative to, 255\nmicro-threads and scripting languages, 264\nSearches\nCOM interface searches, alternatives to, 46—50\nperturbation searches, 355-356\nquadtree search implementation code, 400\nrecursive searching and C++, 89-90\nsphere trees for range searching, 384-387\ntile-based game search systems, 279-286\nSelf-modifying code\ndefined and described, 91-92\nfast bit blitter example, 92-99\nSelf-shadowing\naliasing problems and, 484-486\nhybrid approaches, 486-487\nwith projective textures, 421-424\nSeparation, flocking rule, 330\nSequencers, music\nbasic music sequencer, 539-550\ninteractive sequencer, 551-558\ntarget controls, 555-556\nShadow maps, 421-424\nShadows\naliasing problems, 484-486\nbrute-force rendering, 423\ncast by procedural clouds, 470\nhybrid approaches for, 486—487\ninter-object shadows, 486-487\npriority buffer shadows, 481^487\nreal-time techniques compared, 481-482\nself-shadowing, 421-424, 484-487\n\n\nIndex\n573\nshadow maps, 421-424\nSICLump module, 102-103\nSICResourceFile module, 103-104\nSign test (positive / negative) for floating-point\nnumbers, 172\nSilhouette edge detection (SED)\nadvanced texture features and inking, 442\nboundary edges, 437-438\ncrease edges, 437-438\nedge-based inking, 438-440\ninking described, 436-437\nprogrammable vertex shader inking, 440—442\nSilhouette points and zones, pathfinding, 325-329\nSine functions, lookup tables for, 174—175\nSkeletal representations. See Bones\nSkip strips VIPM method described, 368-370\nmixed-mode skip strips, 372\nmultilevel skip strips, 369-370\nSkyboxes\nalternatives to, 419\ndescribed, 416\nrendering, 418\nrendering distant scenery with, 416-420\nresolution, 416-417\nsize, calculating maximum, 418\ntextures for, 419\nSkyplanes, mapping procedural clouds to, 469-470\nSmoothing.\nSee under Influence maps\nSorting methods, hierarchical, 388-389\nSound\nabstract interface to create sound system, 20-22\nambient sound, 516\ndefined, 522\nechoes, 527\nlow-level sound API, 559-560\npredictability and playback, 108\nreverberation effects, 527\nsample-based synthesizer to reuse voices, 521-524\nspeech systems and command queuing, 517\ntroubleshooting, 519\nvolume controls, 554-555\nSee also Audio design patterns; Audio programming;\nMusic\nSpatial partitioning, used with silhouette zones, 329\nSpeech systems and command queuing, 517\nSpeed. See Optimization\nSphere trees, 384-387\nbounding spheres, 384—385\ndemo and algorithm, 385-387\nuses of, 385\nSplines\nnatural cubic splines and flythrough paths, 221-222\nopen vs. closed, 221-222\nSpotlights, per-pixel, 460-461\nSprites. See Impostors\nSquare roots, logarithmic optimization of, 176-177\nSrandQ, 109\nStack pointers, 260-261\nStacks\ncopying, 262\nstack management and micro-threads, 262\nstack winding, 85-90\nStack winding, 85-90\nrecursion and, 89-90\ntemporary return routine, 85-86\nthunking and, 88-89\nStandard Template Library (STL)\nmemory fragmentation, 13-14\noptimization and, 12-14\nState And Media Manager (SAMMy), 52-54\nState machines\ncreating with macros, 19\nSee also Micro-threads, AI architecture\nStatus functions in audio design, 519\nStrategic assessment techniques, 298-306\nresource allocation trees, 298-300\nStrategic decision making\nand resource allocation trees, 301-302\nstrategic inference, 305\nStrategy games\nLine-of-Sight searching systems for, 279-286\nstrategic assessment techniques, 298-306\nStreaming vs. sequencing method for music, 539-540\nStrings, text parsers, 115\nStructured exception handling (Win 32), 263\nSuper Mario 64, third-person control scheme, 425-432\nanimation analyzed, 431\nSurfaces, loss of surface information, 83-84\nSurvival, flocking rule, 331\nSwapThreads () routine, 261\nSwarming. See Flocking\nSyntax errors, memory tracking and, 71\nTactical analysis and assessment\nheight advantage, 296\nof locations, 309-310\ntactical analysis of locations, 309-310\ntactical values, converting to waypoint properties,\n310\nvisibility, 296-297\nTarget identification, Line-of-Sight systems, 279-286\nTemplate Method pattern, 55\nTemplates, optimization and, 14\nTemplate specialization, type information provided\nusing, 120-121\n\n\n574\nIndex\nTerrain\nfractals to create realistic landscapes, 239, 246\ninfluence maps and, 293—297\ninterlocking tiles method, 377- 383\nreasoning for 3D games, 307-316\nskyboxes for rendering distant scenery, 416—420\nSee also Terrain reasoning\nTerrain reasoning\ncomputing waypoint properties, 310-313\nresources required for algorithm, 314—315\nwaypoints, 308-309\nText files\nadvantages and disadvantages, 112\nparsing systems, 112-117\nText parsers, 112-117\nBoolean values, 115\nfloating-point numbers, 115\nGUIDs, 116\nintegers, 115\nkeywords, 115\noperators, 115\nParser class, 116\nstrings, 115\nToken class, 114-115\nTokenFile class, 116\nTokenList class, 116\nvariables, 115\nTexture filtering, 479\nto reduce stretching, 418\nTextures\ndependent texture reads, 497\nfiltering to reduce stretching, 418\nfour-sample texture sampling, 497-498\ngreen-blue texture addressing, 497—498, 505-506\nself-shadowing with projective textures, 421—424\nfor skyboxes, 419\n3D textures for light mapping, 452-459\nuploading web-cam data, 160-161\nSee also Procedural textures\nThreads\nfibers (multi-tasking threads), 260\nOS threads, 160\nSee also Micro-threads, AI architecture\n3ds max skin exporter and animation toolkit\nbone animation keys, 148\nbone structure and hierarchy, 146\nbone weighting (influence values), 146—148\nmesh data and, 145-146\nMRC file format for exporting, 142-143\nnodes and, 144-145\nsteps to use, 148-149\nThunks and thunking, defined and described, 88\nTile-based games, Line-of-Sight searching systems for,\n279-286\nTiles\ndefined, 280\nsearching systems for tile-based games, 279\ntile-based pathfinding, 325\nSee also Tiles, interlocking landscape\nTiles, interlocking landscape\ndetail levels for, 380-382\nand height maps, 379-380\nlinking pieces explained, 381-382\nrendering method for, 382\nTime\nposition and velocity as function of, 206-207\nsmooth animation and, 148\ntime complexity and RDC, 236-237\nTimers, for AI agents, 253\nToken class of parsing system, 114-116\nTokenFiles class of parsing system, 117\nTokenList class of parsing system, 116\nTools, 3-4\nobject creation tools, 51-61\nperformance tuning, commercially available, 75\nprofiling module, 74-79\nTracks, audio, defined, 543\nTrajectories\nangles of elevation and, 207-210\nflight time calculations, 212\ngravity's influence, 205-206\ninitial velocity, 210-211\ninverse trajectory determination, 205-214\nmaximum height calculations, 211—212\nmultiple variables and, 212-213\ntime, position and velocity as function of, 206-207\nTransparency, exported classes and, 56-57\nTrigonometric functions\nlookup tables for, 174-176\noptimizations and, 213-214\nTroubleshooting\naudio design, 519\nmemory tracking programs, 29\nvoices in synthesizers, 521-524\nTweakableBase_c class, 121-122\nTuieaker_c class, 122-123\nTweakerInstanceDB_c class, 123\nTweaker interface, 118-126\nclasses, schematic illustrating, 119\ndesign, 118\ntype information for, 120-121\nType information code of tweaker interface, 125\nTypes\ndefined and described, 38\ndynamic type information (DTI) class, 38-43\n\n\nIndex\n575\ndynamic types in audio design, 518\npersistent type information, 43-44\nUpdates\nArtificial Intelligence (AI) data updates, 255-256\naudio frame and intervals, 547\nmotion detection to avoid unnecessary, 157-158\ntweaking update rates, 494\nupdate heuristics for impostors, 493-494\nUpdateWoM function, \n80-81\nValues\nabsolute values, 174\nclamping to a specific range, 173-174\nfloating-point number tricks, 173-174\ntactical values, converting to waypoint properties,\n310\nVariables\nabstract variables as MLP inputs, 354\nfuzzy variables, 342\ninfluence maps to track, 289-290\ntext parsers, 115\ntweaking, 118-126\nVectors\ndamped reflection vectors, 188-190\ninterpolating across line or plane, 189\nin MAX, 145\nreflected off collision planes, 185-188\nStandard Template Library vectors, 12-13\nVertex-cache coherency, 364, 375\nVertices, binned vertices, 365\nView Dependent Progressive Meshes (VDPM),\n377-378\nView-Independent Progressive Meshing (VIPM)\ncomparison of methods, 376\nmixed-mode method described, 365-368\nresources required for, 363-364\nskip strips method described, 368-370\nsliding window method described, 372-375\nvanilla method described, 365-368\nVirtual class member functions, exporting from DLLs,\n31-32\nVirtual functions, 9-11\nVisibility\nas tactical assessment factor, 296-297\nSee also Player visibility systems\nVoices, defined, 543\nVoices, sample-based synthesizers to reuse, 521-524\nVulnerability, as tactical assessment factor, 296\nWater\nheight-field water as procedural texture, 501-503\nsimulating refraction in a fish tank, 402—4:05\nWaypoints, 308\nA* pathfinding and, 315\nuses of waypoint-based reasoning, 315\nwaypoint properties, 310-313\nWeb addresses\nartificial intelligence sites, 336\nfor authors, xix—xxxii\nCSyn audio engine, 558\nflocking and steering behaviors, 335\nNvidia's Developer site, 509\nSquid web-caching program, 140\nWeb cameras\nBGR pixels, 158\ncapture window initialization, 153—158\ncartoon-like images, 159-160\ndata manipulation, 158-162\ndata retrieval, 156\ndestroying windows, 161-162\ngrayscale conversion, 159\nmemory allocation for, 155-156\nmotion detection, 157-158\nin multi-player games, 153\ntextures, uploading, 160-161\nWeighting\nbones, 146-148\nmesh deformation and, 149\nWorld, defined for tile-based games, 280\n",
      "page_number": 544,
      "chapter_number": 56,
      "summary": "This chapter covers segment 56 (pages 544-551). Key topics include function, texture, and game. See Points-of-visibility\npathfinding\nPostincrement functions, 7\nPrecalculating.",
      "keywords": [
        "functions",
        "Standard Template Library",
        "maps",
        "systems",
        "memory",
        "optimization",
        "games",
        "type information",
        "Template Library",
        "audio design",
        "audio",
        "defined",
        "texture",
        "pathfinding",
        "Inline functions"
      ],
      "concepts": [
        "function",
        "texture",
        "game",
        "maps",
        "mapping",
        "optimizations",
        "optimal",
        "optimally",
        "classes",
        "defined"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 7",
          "chapter": 63,
          "title": "Segment 63 (pages 609-616)",
          "relevance_score": 0.77,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 7",
          "chapter": 62,
          "title": "Segment 62 (pages 601-608)",
          "relevance_score": 0.7,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 53,
          "title": "Segment 53 (pages 511-519)",
          "relevance_score": 0.7,
          "method": "sentence_transformers"
        },
        {
          "book": "Game Programming Gems 7",
          "chapter": 64,
          "title": "Segment 64 (pages 617-624)",
          "relevance_score": 0.68,
          "method": "sentence_transformers"
        },
        {
          "book": "More Effective C++",
          "chapter": 29,
          "title": "Segment 29 (pages 293-301)",
          "relevance_score": 0.67,
          "method": "sentence_transformers"
        }
      ]
    }
  ],
  "pages": [
    {
      "page_number": 1,
      "chapter": null,
      "content": "GameGems II\nConverted by Borz\nborzpro @yahoo .com\n2002.12.01\n",
      "content_length": 61,
      "extraction_method": "Direct"
    },
    {
      "page_number": 2,
      "chapter": null,
      "content": "Optimization for C++ Games\nAndrew Kirmse, LucasArts Entertainment\nark@alum.mit.edu\nW\nell-written C++ games are often more maintainable and reusable than their\nplain C counterparts are—but is it worth it? Can complex C++ programs hope\nto match traditional C programs in speed?\nWith a good compiler and thorough knowledge of the language, it is indeed pos-\nsible to create efficient games in C++. This gem describes techniques you can use to\nspeed up games in particular. It assumes that you're already convinced of the benefits\nof using C++, and that you're familiar with the general principles of optimization (see\nFurther Investigations for these).\nOne general principle that merits repeating is the absolute importance of profil-\ning. In the absence of profiling, programmers tend to make two types of mistakes.\nFirst, they optimize the wrong code. The great majority of a program is not perfor-\nmance critical, so any time spent speeding it up is wasted. Intuition about which code\nis performance critical is untrustworthy—only by direct measurement can you be\nsure. Second, programmers sometimes make \"optimizations\" that actually slow down\nthe code. This is particularly a problem in C++, where a deceptively simple line can\nactually generate a significant amount of machine code. Examine your compiler's out-\nput, and profile often.\nObject Construction and Destruction\nThe creation and destruction of objects is a central concept in C++, and is the main\narea where the compiler generates code \"behind your back.\" Poorly designed pro-\ngrams can spend substantial time calling constructors, copying objects, and generat-\ning costly temporary objects. Fortunately, common sense and a few simple rules can\nmake object-heavy code run within a hair's breadth of the speed of C.\n• Delay construction of objects until they're needed.\nThe fastest code is that which never runs; why create an object if you're not\ngoing to use it? Thus, in the following code:\nvoid Function(int arg)\n5\nG\n1.1\nm \n\"'\n",
      "content_length": 1993,
      "extraction_method": "Direct"
    },
    {
      "page_number": 3,
      "chapter": null,
      "content": "Section 1 General Programming\nObject obj;\nif (arg *= 0)\nreturn;\neven when arg is zero, we pay the cost of calling Object's constructor and destruc-\ntor. If arg is often zero, and especially if Object itself allocates memory, this waste\ncan add up in a hurry. The solution, of course, is to move the declaration of obj\nuntil after the //check.\nBe careful about declaring nontrivial objects in loops, however. If you delay con-\nstruction of an object until it's needed in a loop, you'll pay for the construction\nand destruction of the object on every iteration. It's better to declare the object\nbefore the loop and pay these costs only once. If a function is called inside an\ninner loop, and the function creates an object on the stack, you could instead cre-\nate the object outside the loop and pass it by reference to the function.\nUse initializer lists.\nConsider the following class:\nclass Vehicle\n{\npublic:\nVehicle(const std::string &name) // Don't do this!\n{\nmName = name;\n}\nprivate:\nstd: : string mName;\nBecause member variables are constructed before the body of the constructor is\ninvoked, this code calls the constructor for the string mName, and then calls the\n= operator to copy in the object's name. What's particularly bad about this exam-\nple is that the default constructor for string may well allocate memory — in fact,\nmore memory than may be necessary to hold the actual name assigned to the\nvariable in the constructor for Vehicle. The following code is much better, and\navoids the call to operator =. Further, given more information (in this case, the\nactual string to be stored), the nondefault string constructor can often be more\nefficient, and the compiler may be able to optimize away the Vehicle constructor\ninvocation when the body is empty:\nclass Vehicle\n{\npublic:\nVehicle(const std::string &name) : mName(name)\n{\n}\nprivate:\n",
      "content_length": 1852,
      "extraction_method": "Direct"
    },
    {
      "page_number": 4,
      "chapter": null,
      "content": "1.1 Optimization for C++ Games\nstd::string mName;\nPrefer preincrement to postincrement.\nThe problem with writing x = y++ is that the increment function has to make a\ncopy of the original value of y, increment y, and then return the original value.\nThus, postincrement involves the construction of a temporary object, while\npreincrement doesn't. For integers, there's no additional overhead, but for user-\ndefined types, this is wasteful. You should use preincrement whenever you have\nthe option. You almost always have the option in for loop iterators.\nAvoid operators that return by value.\nThe canonical way to write vector addition in C++ is this:\nVector operator+(const Vector &v1, const Vector &v2)\nThis operator must return a new Vector object, and furthermore, it must return\nit by value. While this allows useful and readable expressions like v = v 1 + z>2, the\ncost of a temporary construction and a Vector copy is usually too much for some-\nthing called as often as vector addition. It's sometimes possible to arrange code so\nthat the compiler is able to optimize away the temporary object (this is known\nas the \"return value optimization\"), but in general, it's better to swallow your\npride and write the slightly uglier, but usually faster:\nvoid Vector::Add(const Vector &v1, const Vector &v2)\nNote that operator+= doesn't suffer from the same problem, as it modifies its\nfirst argument in place, and doesn't need to return a temporary. Thus, you should\nuse operators like += instead of + when possible.\nUse lightweight constructors.\nShould the constructor for the Vector class in the previous example initialize its\nelements to zero? This may come in handy in a few spots in your code, but it\nforces every caller to pay the price of the initialization, whether they use it or not.\nIn particular, temporary vectors and member variables will implicitly incur the\nextra cost.\nA good compiler may well optimize away some of the extra code, but why take\nthe chance? As a general rule, you want an object's constructor to initialize each of\nits member variables, because uninitialized data can lead to subtle bugs. However,\nin small classes that are frequently instantiated, especially as temporaries, you\nshould be prepared to compromise this rule for performance. Prime candidates in\nmany games are the Vector and Matrix classes. These classes should provide medi-\nods (or alternate constructors) to set themselves to zero and the identity, respec-\ntively, but the default constructor should be empty.\n",
      "content_length": 2510,
      "extraction_method": "Direct"
    },
    {
      "page_number": 5,
      "chapter": null,
      "content": "Section 1 General Programming\nAs a corollary to this principle, you should provide additional constructors to\nclasses where this will improve performance. If the Vehicle class in our second\nexample were instead written like this:\nclass Vehicle\n{ \n.\npublic:\nVehicle ()\nvoid SetName(const std: :string &name)\n{\nmName = name;\nprivate:\nstd: : string mName;\nwe'd incur the cost of constructing mName, and then setting it again later via Set-\nName(). Similarly, it's cheaper to use copy constructors than to construct an\nobject and then call operator=. Prefer constructing an object this way — Vehicle\nvl(v2) — to this way — Vehicle vl; vl = v2;.\nIf you want to prevent the compiler from automatically copying an object for\nyou, declare a private copy constructor and operator= for the object's class, but\ndon't implement either function. Any attempt to copy the object will then result\nin a compile-time error. Also get into the habit of declaring single-argument con-\nstructors as explicit, unless you mean to use them as type conversions. This pre-\nvents the compiler from generating hidden temporary objects when converting\ntypes.\nPreallocate and cache objects.\nA game will typically have a few classes that it allocates and frees frequently, such\nas weapons or particles. In a C game, you'd typically allocate a big array up front\nand use them as necessary. With a little planning, you can do the same thing in\nC++. The idea is that instead of continually constructing and destructing objects,\nyou request new ones and return old ones to a cache. The cache can be imple-\nmented as a template, so that it works for any class, provided that the class has a\ndefault constructor. Code for a sample cache class template is on the accompany-\ning CD.\nYou can either allocate objects to fill the cache as you need them, or preallocate\nall of the objects up front. If, in addition, you maintain a stack discipline on the\nobjects (meaning that before you delete object X, you first delete all objects allo-\ncated after X), you can allocate the cache in a contiguous block of memory.\n",
      "content_length": 2072,
      "extraction_method": "Direct"
    },
    {
      "page_number": 6,
      "chapter": null,
      "content": "1.1 Optimization for C++Games \n9\nMemory Management \n—•\nC++ applications generally need to be more aware of the details of memory manage-\nment than C applications do. In C, all allocations are explicit though mallocQ and\nfreeQ, while C++ can implicitly allocate memory while constructing temporary\nobjects and member variables. Most C++ games (like most C games) will require their\nown memory manager.\nBecause a C++ game is likely to perform many allocations, it must be especially\ncareful about fragmenting the heap. One option is to take one of the traditional\napproaches: either don't allocate any memory at all after the game starts up, or main-\ntain a large contiguous block of memory that is periodically freed (between levels, for\nexample). On modern machines, such draconian measures are not necessary, if you're\nwilling to be vigilant about your memory usage.\nThe first step is to override the global new and delete operators. Use custom imple-\nmentations of diese operators to redirect the game's most common allocations away\nfrom mallocQ and into preallocated blocks of memory. For example, if you find that you\nhave at most 10,000 4-byte allocations outstanding at any one time, you should allocate\n40,000 bytes up front and issue blocks out as necessary. To keep track of which blocks\nare free, maintain a. free list by pointing each free block to the next free block. On allo-\ncation, remove the front block from the list, and on deallocation, add the freed block to\nthe front again. Figure 1.1.1 illustrates how the free list of small blocks might wind its\nway through a contiguous larger block after a sequence of allocations and frees.\nused\nfree\nused\nused\nt\nfree\nfree\n_ _ \nA .\n~ .~ \nT\nFIGURE 1.1.1 \nA linked free list.\nYou'll typically find that a game has many small, short-lived allocations, and thus\nyou'll want to reserve space for many small blocks. Reserving many larger blocks\nwastes a substantial amount of memory for those blocks that are not currently in use;\nabove a certain size, you'll want to pass allocations off to a separate large block alloca-\ntor, or just to mallocQ.\nVirtual Functions\nCritics of C++ in games often point to virtual functions as a mysterious feature\nthat drains performance. Conceptually, the mechanism is simple. To generate a virtual\nfunction call on an object, the compiler accesses the objects virtual function table,\n",
      "content_length": 2374,
      "extraction_method": "Direct"
    },
    {
      "page_number": 7,
      "chapter": null,
      "content": "10 \nSection 1 General Programming\nretrieves a pointer to the member function, sets up the call, and jumps to the member\nfunction's address. This is to be compared with a function call in C, where the com-\npiler sets up the call and jumps to a fixed address. The extra overhead for the virtual\nfunction call is die indirection to die virtual function table; because the address of the\ncall isn't known in advance, there can also be a penalty for missing the processor's\ninstruction cache.\nAny substantial C++ program will make heavy use of virtual functions, so the idea\nis to avoid these calls in performance-critical areas. Here is a typical example:\nclass BaseClass\n{\npublic:\nvirtual char *GetPointer() = 0;\n};\nclass Class\"! : public BaseClass\n{\nvirtual char *GetPointer();\n>;\nclass Class2 : public BaseClass\n{\nvirtual char *GetPointer();\n}|\nvoid Function(BaseClass *pObj)\n{\nchar *ptr = pObj->GetPointer();\n}\nIf FunctionQ is performance critical, we want to change die call to GetPointer\nfrom virtual to inline. One way to do this is to add a new protected data member to\nBaseClass, which is returned by an inline version of GetPointerQ, and set the data\nmember in each class:\nclass BaseClass\n{\npublic:\ninline char *GetPointerFast()\n{\nreturn mpPointer;\n}\nprotected:\ninline void SetPointer(char *pData)\n{\nmpData = pData;\n}\nprivate:\nchar *mpData;\n",
      "content_length": 1347,
      "extraction_method": "Direct"
    },
    {
      "page_number": 8,
      "chapter": null,
      "content": "1.1 \nOptimization for C++Games \n, \n. \n11\n// classl and class2 call SetPointer as necessary\n//in member functions\nvoid Function(BaseClass *pObj)\n{\nchar *ptr = pObj->GetPointerFast();\n}\nA more drastic measure is to rearrange your class hierarchy. If Classl and Class2\nhave only slight differences, it might be worth combining them into a single class,\nwith a flag indicating whether you want the class to behave like Classl or Class2 at\nruntime. With this change (and the removal of the pure virtual BaseClass), the Get-\nPointer function in the previous example can again be made inline. This transforma-\ntion is far from elegant, but in inner loops on machines with small caches, you'd be\nwilling to do much worse to get rid of a virtual function call.\nAlthough each new virtual function adds only the size of a pointer to a per-class\ntable (usually a negligible cost), the yzrtf virtual function in a class requires a pointer to\nthe virtual function table on a pet-object basis. This means that you don't want to have\nany virtual functions at all in small, frequently used classes where this extra overhead\nis unacceptable. Because inheritance generally requires the use of one or more virtual\nfunctions (a virtual destructor if nothing else), you don't want any hierarchy for small,\nheavily used objects.\nCode Size\nCompilers have a somewhat deserved reputation for generating bloated code for C++.\nBecause memory is limited, and because small is fast, it's important to make your exe-\ncutable as small as possible. The first thing to do is get the compiler on your side. If\nyour compiler stores debugging information in the executable, disable the generation\nof debugging information. (Note that Microsoft Visual C++ stores debugging infor-\nmation separate from the executable, so this may not be necessary.) Exception handling\ngenerates extra code; get rid of as much exception-generating code as possible. Make\nsure the linker is configured to strip out unused functions and classes. Enable the com-\npiler's highest level of optimization, and try setting it to optimize for size instead of\nspeed—sometimes this actually produces faster code because of better instruction\ncache coherency. (Be sure to verify that intrinsic functions are still enabled if you use\nthis setting.) Get rid of all of your space-wasting strings in debugging print statements,\nand have the compiler combine duplicate constant strings into single instances.\nInlining is often the culprit behind suspiciously large functions. Compilers are\nfree to respect or ignore your inline keywords, and they may well inline functions\nwithout telling you. This is another reason to keep your constructors lightweight, so\nthat objects on the stack don't wind up generating lots of inline code. Also be careful\nof overloaded operators; a simple expression like ml = m2 * m3 can generate a ton of\n",
      "content_length": 2858,
      "extraction_method": "Direct"
    },
    {
      "page_number": 9,
      "chapter": null,
      "content": "12 \nSection 1 General Programming\ninline code if m2 and m3 are matrices. Get to know your compiler's settings for inlin-\ning functions thoroughly.\nEnabling runtime type information (RTTI) requires the compiler to generate\nsome static information for (just about) every class in your program. RTTI is typically\nenabled so that code can call dynamic_cast and determine an object's type. Consider\navoiding RTTI and dynamic_cast entirely in order to save space (in addition,\ndynamic_cast is quite expensive in some implementations). Instead, when you really\nneed to have different behavior based on type, add a virtual function that behaves dif-\nferently. This is better object-oriented design anyway. (Note that this doesn't apply to\nstatic_cast, which is just like a C-style cast in performance.)\nThe Standard Template Library\nThe Standard Template Library (STL) is a set of templates that implement common\ndata structures and algorithms, such as dynamic arrays (called vectors), sets, and\nmaps. Using the STL can save you a great deal of time that you'd otherwise spend\nwriting and debugging these containers yourself. Once again, though, you need to be\naware of the details of your STL implementation if you want maximum efficiency.\nIn order to allow the maximum range of implementations, the STL standard is\nsilent in the area of memory allocation. Each operation on an STL container has cer-\ntain performance guarantees; for example, insertion into a set takes O(log n) time.\nHowever, there are no guarantees on a container's memory usage.\nLet's go into detail on a very common problem in game development: you want\nto store a bunch of objects (we'll call it a list of objects, though we won't necessarily\nstore it in an STL list). Usually you want each object to appear in a list only once, so\nthat you don't have to worry about accidentally inserting the object into the collection\nif it's already there. An STL set ignores duplicates, has O(log n) insertion, deletion,\nand lookup—the perfect choice, right?\nMaybe. While it's true that most operations on a set are O(log n), this notation\nhides a potentially large constant. Although the collection's memory usage is imple-\nmentation dependent, many implementations are based on a red-black tree, where\neach node of the tree stores an element of the collection. It's common practice to allo-\ncate a node of the tree every time an element is inserted, and to free a node every time\nan element is removed. Depending on how often you insert and remove elements, the\ntime spent in the memory allocator can overshadow any algorithmic savings you\ngained from using a set.\nAn alternative solution uses an STL vector to store elements. A vector is guaran-\nteed to have amortized constant-time insertion at the end of the collection. What this\nmeans in practice is that a vector typically reallocates memory only on occasion, say,\ndoubling its size whenever it's full. When using a vector to store a list of unique ele-\nments, you first check the vector to see if the element is already there, and if it isn't,\nyou add it to the back. Checking the entire vector will take O(n) time, but the con-\nstant involved is likely to be small. That's because all of the elements of a vector are\n",
      "content_length": 3230,
      "extraction_method": "Direct"
    },
    {
      "page_number": 10,
      "chapter": null,
      "content": "1.1 Optimization for C++Games \n13\ntypically stored contiguously in memory, so checking the entire vector is a cache-\nfriendly operation. Checking an entire set may well thrash the memory cache, as indi-\nvidual elements of the red-black tree could be scattered all over memory. Also\nconsider that a set must maintain a significant amount of overhead to set up the tree.\nIf all you're storing is object pointers, a set can easily require three to four times the\nmemory of a vector to store the same objects.\nDeletion from a set is O(log n), which seems fast until you consider that it prob-\nably also involves a call to free(). Deletion from a vector is O(n), because everything\nfrom the deleted element to the end of the vector must be copied over one position.\nHowever, if the elements of the vector are just pointers, the copying can all be done in\na single call to memcpyO, which is typically very fast. (This is one reason why it's usu-\nally preferable to store pointers to objects in STL collections, as opposed to objects\nthemselves. If you store objects directly, many extra constructors get invoked during\noperations such as deletion.)\nIf you're still not convinced that sets and maps can often be more trouble than\nthey're worth, consider the cost of iterating over a collection, specifically:\nfor (Collection::iterator it = collection.begin();\nit != collection.end(); ++it)\nIf Collection is a vector, then ++it is a pointer increment—one machine instruc-\ntion. But when Collection is a set or a map, ++it involves traversing to the next node\nof a red-black tree, a relatively complicated operation that is also much more likely to\ncause a cache miss, because tree nodes may be scattered all over memory.\nOf course, if you're storing a very large number of items in a collection, and doing\nlots of membership queries, a set's O(log n) performance could very well be worth the\nmemory cost. Similarly, if you're only using the collection infrequently, the perfor-\nmance difference may be irrelevant. You should do performance measurements to\ndetermine what values of n make a set faster. You may be surprised to find that vectors\noutperform sets for all values that your game will typically use.\nThat's not quite the last word on STL memory usage, however. It's important to\nknow if a collection actually frees its memory when you call the clear() method. If not,\nmemory fragmentation can result. For example, if you start a game with an empty\nvector, add elements to the vector as the game progresses, and then call clear() when\nthe player restarts, the vector may not actually free its memory at all. The empty vec-\ntor's memory could still be taking up space somewhere in the heap, fragmenting it.\nThere are two ways around this problem, if indeed your implementation works this\nway. First, you can call reserveQ when the vector is created, reserving enough space for\nthe maximum number of elements that you'll ever need. If that's impractical, you can\nexplicitly force the vector to free its memory this way:\nvector<int> v;\n// ... elements are inserted into v here\nvector<int>().swap(v); // causes v to free its memory\n",
      "content_length": 3129,
      "extraction_method": "Direct"
    },
    {
      "page_number": 11,
      "chapter": null,
      "content": "14 \nSection 1 General Programming\nSets, lists, and maps typically don't have this problem, because they allocate and\nfree each element separately.\nAdvanced Features\nJust because a language has a feature doesn't mean you have to use it. Seemingly sim-\nple features can have very poor performance, while other seemingly complicated fea-\ntures can in fact perform well. The darkest corners of C++ are highly compiler\ndependent — make sure you know the costs before using them.\nC++ strings are an example of a feature that sounds great on paper, but should be\navoided where performance matters. Consider the following code:\nvoid Function (const std: :string &str)\nFunction (\"hello\");\nThe call to FunctionQ invokes a constructor for a string given a const char *. In\none commercial implementation, this constructor performs a mallocQ, a strlenQ, and\na memcpyO, and the destructor immediately does some nontrivial work (because this\nimplementation's strings are reference counted) followed by a freeQ- The memory\nthat's allocated is basically a waste, because the string \"hello\" is already in the pro-\ngram's data segment; we've effectively duplicated it in memory. If FunctionQ had\ninstead been declared as taking a const char *, there would be no overhead to the call.\nThat's a high price to pay for the convenience of manipulating strings.\nTemplates are an example of the opposite extreme of efficiency. According to the\nlanguage standard, the compiler generates code for a template when the template is\ninstantiated with a particular type. In theory, it sounds like a single template declara-\ntion would lead to massive amounts of nearly identical code. If you have a vector of\nClassl pointers, and a vector of Class2 pointers, you'll wind up with two copies of vec-\ntor in your executable.\nThe reality for most compilers is usually better. First, only template member\nfunctions that are actually called have any code generated for them. Second, the com-\npiler is allowed to generate only one copy of the code, if correct behavior is preserved.\nYou'll generally find that in the vector example given previously, only a single copy of\ncode (probably for vector<void *>) will be generated. Given a good compiler, tem-\nplates give you all the convenience of generic programming, while maintaining high\nperformance.\nSome features of C++, such as initializer lists and preincrement, generally increase\nperformance, while other features such as overloaded operators and RTTI look\nequally innocent but carry serious performance penalties. STL collections illustrate\nhow blindly trusting in a function's documented algorithmic running time can lead\nyou astray. Avoid the potentially slow features of the language and libraries, and spend\n",
      "content_length": 2728,
      "extraction_method": "Direct"
    },
    {
      "page_number": 12,
      "chapter": null,
      "content": "1.1 Optimization for C++Games \n15\nsome time becoming familiar with the options in your profiler and compiler. You'll\nquickly learn to design for speed and hunt down the performance problems in your\ngame.\nFurther Investigations\nThanks to Pete Isensee and Christopher Kirmse for reviewing this gem.\nGormen, Thomas, Charles Leiserson, and Ronald Rivest, Introduction to Algorithms,\nCambridge, Massachusetts, MIT Press, 1990.\nIsensee, Peter, C++ Optimization Strategies and Techniques, www.tantalon.com/\npete/cppopt/main.htm.\nKoenig, Andrew, \"Pre- or Postfix Increment,\" The C++ Report, June, 1999.\nMeyers, Scott, Effective C++, Second Edition, Reading, Massachusetts: Addison-\nWesley Publishing Co., 1998.\nSutter, Herb, Guru of the Week #54: Using Vector and Deque, www.gotw.ca/\ngotw/054.htm.\n",
      "content_length": 790,
      "extraction_method": "Direct"
    },
    {
      "page_number": 13,
      "chapter": null,
      "content": "1.2\nInline Functions Versus Macros\nPeter Dalton, Evans & Sutherland\npdalton@xmission.com\nien it comes to game programming, the need for fast, efficient functions cannot\nbe overstated, especially functions that are executed multiple times per frame.\nMany programmers rely heavily on macros when dealing with common, time-critical\nroutines because they eliminate the calling/returning sequence required by functions\nthat are sensitive to the overhead of function calls. However, using the tfdefine directive\nto implement macros diat look like functions is more problematic than it is worth.\nAdvantages of Inline Functions\nThrough the use of inline functions, many of the inherent disadvantages of macros\ncan easily be avoided. Take, for example, the following macro definition:\n#define max(a,b) ((a) > (b) ? (a) : (b))\nLet's look at what would happen if we called the macro with die following para-\nmeters: max(++x, y). If x = 5 and j/ = 3, the macro will return a value of 7 rather than\nthe expected value of 6. This illustrates the most common side effect of macros, the\nfact that expressions passed as arguments can be evaluated more than once. To avoid\nthis problem, we could have used an inline function to accomplish die same goal:\ninline int max(int a, int b) { return (a > b ? a : b); }\nBy using the inline method, we are guaranteed that all parameters will only be\nevaluated once because they must, by definition, follow all the protocols and type\nsafety enforced on normal functions.\nAnother problem that plagues macros, operator precedence, follows from die\nsame problem presented previously, illustrated in the following macro:\n#define square(x) (x*x)\nIf we were to call this macro with the expression 2+1, it should become obvious\nthat die macro would return a result of 5 instead of the expected 9. The problem here\nis that the multiplication operator has a higher precedence than the addition operator\n16\n",
      "content_length": 1918,
      "extraction_method": "Direct"
    },
    {
      "page_number": 14,
      "chapter": null,
      "content": "1.2 Inline Functions Versus Macros \n17\nhas. While wrapping all of the expressions within parentheses would remedy this\nproblem, it could have easily been avoided through the use of inline functions.\nThe other major pitfall surrounding macros has to deal with multiple-statement\nmacros, and guaranteeing that all statements within the macro are executed properly.\nAgain, let's look at a simple macro used to clamp any given number between zero and\none:\n#define clamp(a) \n\\\nif (a > 1.0) a = 1.0; \\\nif (a < 0.0) a = 0.0;\nIf we were to use the macro within the following loop:\nfor (int ii = 0 ; ii < N; ++ii)\nclamp( numbersToBeClamped[ii] );\nthe numbers would not be clamped if they were less than zero. Only upon termina-\ntion of the for loop when « == N would the expression if(numbersToBeClamped[ii] <\n0.0) be evaluated. This is also very problematic, because the index variable « is now\nout of range and could easily result is a memory bounds violation that could crash the\nprogram. While replacing the macro with an inline function to perform the same\nfunctionality is not the only solution, it is the cleanest.\nGiven these inherent disadvantages associated with macros, let's run through the\nadvantages of inline functions:\n• Inline functions follow all the protocols of type safety enforced on normal func-\ntions. This ensures that unexpected or invalid parameters are not passed as\narguments.\n• Inline functions are specified using the same syntax as any other function, except\nfor the inline keyword in the function declaration.\n• Expressions passed as arguments to inline functions are evaluated prior to enter-\ning the function body; thus, expressions are evaluated only once. As shown previ-\nously, expressions passed to macros can be evaluated more than once and may\nresult in unsafe and unexpected side effects.\n• It is possible to debug inline functions using debuggers such as Microsoft's Visual\nC++. This is not possible with macros because the macro is expanded before the\nparser takes over and the program's symbol tables are created.\n• Inline functions arguably increase the procedure's readability and maintainability\nbecause they use the same syntax as regular function calls, yet do not modify para-\nmeters unexpectedly.\nInline functions also outperform ordinary functions by eliminating the overhead\nof function calls. This includes tasks such as stack-frame setup, parameter passing,\nstack-frame restoration, and the returning sequence. Besides these key advantages,\ninline functions also provide the compiler with the ability to perform improved code\n",
      "content_length": 2573,
      "extraction_method": "Direct"
    },
    {
      "page_number": 15,
      "chapter": null,
      "content": "18 \nSection 1 General Programming\noptimizations. By replacing inline functions with code, the inserted code is subject to\nadditional optimizations that would not otherwise be possible, because most compil-\ners do not perform interprocedural optimizations. Allowing the compiler to perform\nglobal optimizations such as common subexpression elimination and loop invariant\nremoval can dramatically improve both speed and size.\nThe only limitation to inline functions that is not present within macros is the\nrestriction on parameter types. Macros allow for any possible type to be passed as a\nparameter; however, inline functions only allow for the specified parameter type in\norder to enforce type safety. We can overcome this limitation through the use of inline\ntemplate functions, which allow us to accept any parameter type and enforce type\nsafety, yet still provide all the benefits associated with inline functions.\nWhen to Use Inline Functions\njj^.,,.,..^.....™,...,....,,,..,...........,,,........... \n.....,..,.„.,_,.,_.....„,,„„,.,....„„...._„„..,,..,...„„_.„„„,,„,„,„„..,.....,,„.,„ \n.,..,...,.„.,„., ,,,^... ..;„„..,,,....,.....™?i[.^,,.,.,.,..„,..,... ;.,..,^,:rr,.„,..-,,,...,,„,.,. ...s^ \n•.•..-\"!••!\nWhy don't we make every function an inline function? Wouldn't this eliminate the\nfunction overhead for the entire program, resulting in faster fill rates and response\ntimes? Obviously, the answer to these questions is no. While code expansion can\nimprove speed by eliminating function overhead and allowing for interprocedural\ncompiler optimizations, this is all done at the expense of code size. When examining\nthe performance of a program, two factors need to be weighed: execution speed\nand the actual code size. Increasing code size takes up more memory, which is a pre-\ncious commodity, and also bogs down the execution speed. As the memory require-\nments for a program increase, so does the likelihood of cache misses and page faults.\nWhile a cache miss will cause a minor delay, a page fault will always result in a major\ndelay because the virtual memory location is not in physical memory and must\nbe fetched from disk. On a Pentium II 400 MHz desktop machine, a hard page fault\nwill result in an approximately 10 millisecond penalty, or about 4,000,000 CPU\ncycles [Heller99].\nIf inline functions are not always a win, then when exactly should we use them?\nThe answer to this question really depends on the situation and thus must rely heav-\nily on the judgment of the programmer. However, here are some guidelines for when\ninline functions work well:\n• Small methods, such as accessors for private data members.\n• Functions returning state information about an object.\n• Small functions, typically three lines or less.\n• Small functions that are called repeatedly; for example, within a time-critical ren-\ndering loop.\nLonger functions that spend proportionately less time in the calling/returning\nsequence will benefit less from inlining. However, used correctly, inlining can greatly\nincrease procedure performance.\n",
      "content_length": 3041,
      "extraction_method": "Direct"
    },
    {
      "page_number": 16,
      "chapter": null,
      "content": "1.2 Inline Functions Versus Macros \n19\nWhen to Use Macros\nDespite the problems associated with macros, there are a few circumstances in which\nthey are invaluable. For example, macros can be used to create small pseudo-languages\nthat can be quite powerful. A set of macros can provide the framework that makes cre-\nating state machines a breeze, while being very debuggable and bulletproof. For an\nexcellent example of this technique, refer to the \"Designing a General Robust AI\nEngine\" article referenced at the end of this gem [RabinOO]. Another example might\nbe printing enumerated types to the screen. For example:\ntfdefine CaseEnum(a) \ncase(a) : PrintEnum( #a )\nswitch (msg_passed_in) {\nCaseEnum( MSG_YouWereHit );\nReactToHit();\nbreak;\nCaseEnum( MSG_GameReset );\nResetGameLogic();\nbreak;\n}\nHere, PrintEnumQ is a macro that prints a string to the screen. The # is the\nstringizing operator that converts macro parameters to string constants [MSDN].\nThus, there is no need to create a look-up table of all enums to strings (which are usu-\nally poorly maintained) in order to retrieve invaluable debug information.\nThe key to avoiding the problems associated with macros is, first, to understand\nthe problems, and, second, to know the alternative implementations.\nMicrosoft Specifics\nBesides the standard inline keyword, Microsoft's Visual C++ compiler provides sup-\nport for two additional keywords. The \ninline keyword instructs the compiler to\ngenerate a cost/benefit analysis and to only inline the function if it proves beneficial.\nThe \nforceinline keyword instructs the compiler to always inline the function.\nDespite using these keywords, there are certain circumstances in which the compiler\ncannot comply as noted by Microsoft's documentation [MSDN].\nReferences\n[Heller99] Heller, Martin, Developing Optimized Code with Microsoft Visual C++ 6.0,\nMicrosoft MSDN Library, January 2000.\n[McConnell93] McConnell, Steve, Code Complete, Microsoft Press, 1993.\n[MSDN] Microsoft Developer Network Library, http://msdn.microsoft.com.\n[Myers98] Myers, Scott, Effective C++, Second Edition, Addison-Wesley Longman,\nInc., 1998.\n[RabinOO] Rabin, Steve, \"Designing a General Robust AI Engine,\" Game Program-\nming Gems. Charles River Media, 2000; pp. 221-236.\n",
      "content_length": 2254,
      "extraction_method": "Direct"
    },
    {
      "page_number": 17,
      "chapter": null,
      "content": "1.3\nProgramming with\nAbstract Interfaces\nNoel Llopis, Meyer/Glass Interactive\nnllopis@mgigames.com\nT\nhe concept of abstract interfaces is simple yet powerful. It allows us to completely\nseparate the interface from its implementation. This has some very useful\nconsequences:\n• It is easy to switch among different implementations for the code without affect-\ning the rest of the game. This is particularly useful when experimenting with dif-\nferent algorithms, or for changing implementations on different platforms.\n• The implementations can be changed at runtime. For example, if the graphics\nTenderer is implemented through an abstract interface, it is possible to choose\nbetween a software Tenderer or a hardware-accelerated one while the game is\nrunning.\n• The implementation details are completely hidden from the user of the interface.\nThis will result in fewer header files included all over the project, faster recompile\ntimes, and fewer times when die whole project needs to be completely recompiled.\n• New implementations of existing interfaces can be added to the game effortlessly,\nand potentially even after it has been compiled and released. This makes it possi-\nble to easily extend the game by providing updates or user-defined modifications.\nAbstract Interfaces\nIn C++, an abstract interface is nothing more than a base class that has only public\npure virtual functions. A pure virtual function is a type of virtual member function\nthat has no implementation. Any derived class must implement those functions, or\nelse the compiler prevents instantiaton of that class. Pure virtual functions are indi-\ncated by adding = 0 after their declaration.\nThe following is an example of an abstract interface for a minimal sound system.\nThis interface would be declared in a header file by itself:\n//In SoundSystem.h\nclass ISoundSystem {\npublic:\n20\n",
      "content_length": 1856,
      "extraction_method": "Direct"
    },
    {
      "page_number": 18,
      "chapter": null,
      "content": "1.3 Programming with Abstract Interfaces \n21\nvirtual ~ISoundSystem() {};\nvirtual bool PlaySound ( handle hSound ) = 0;\nvirtual bool StopSound ( handle hSound ) = 0;\nThe abstract interface provides no implementation whatsoever. All it does is\ndefine the rules by which the rest of the world may use the sound system. As long as\nthe users of the interface know about ISoundSystem, they can use any sound system\nimplementation we provide.\nThe following header file shows an example of an implementation of the previous\ninterface:\n/ / I n \nSoundSystemSoftware.h\n#include \"SoundSystem.h\"\nclass SoundSystemSoftware : public ISoundSystem {\npublic:\nvirtual -SoundSystemSoftware () ;\nvirtual bool PlaySound ( handle hSound ) ;\nvirtual bool StopSound ( handle hSound ) ;\n// The rest of the functions in the implementation\n};\nWe would obviously need to provide the actual implementation for each of those\nfunctions in the corresponding .cpp file.\nTo use this class, you would have to do the following:\nISoundSystem * pSoundSystem = new SoundSystemSoftware () ;\n// Now we're ready to use it\npSoundSystem->PlaySound ( hSound );\nSo, what have we accomplished by creating our sound system in this roundabout\nway? Almost everything that we promised at the start:\n• It is easy to create another implementation of the sound system (maybe a hard-\nware version). All that is needed is to create a new class that inherits from\nISoundSystem, instantiate it instead of SoundSystemSoftwareQ, and everything else\nwill work the same way without any more changes.\n• We can switch between the two classes at runtime. As long as pSoundSystem\npoints to a valid object, the rest of the program doesn't know which one it is\nusing, so we can change them at will. Obviously, we have to be careful with spe-\ncific class restrictions. For example, some classes will keep some state information\nor require initialization before being used for the first time.\n• We have hidden all the implementation details from the user. By implementing\nthe interface we are committed to providing the documented behavior no matter\nwhat our implementation is. The code is much cleaner than the equivalent code\n",
      "content_length": 2157,
      "extraction_method": "Direct"
    },
    {
      "page_number": 19,
      "chapter": null,
      "content": "22 \nSection 1 General Programming\nfull of //\"statements checking for one type of sound system or another. Maintain-\ning the code is also much easier.\nAdding a Factory\nThere is one detail that we haven't covered yet: we haven't completely hidden the spe-\ncific implementations from the users. After all, the users are still doing a new on the\nclass of the specific implementation they want to use. The problem with this is that\nthey need to #include the header file with the declaration of the implementation.\nUnfortunately, the way C++ was designed, when users #include a header file, they can\nalso get a lot of extra information on the implementation details of that class that they\nshould know nothing about. They will see all the private and protected members, and\nthey might even include extra header files that are only used in the implementation of\nthe class.\nTo make matters worse, the users of the interface now know exactly what type of\nclass their interface pointer points to, and they could be tempted to cast it to its real\ntype to access some \"special features\" or rely on some implementation-specific behav-\nior. As soon as this happens, we lose many of the benefits we gained by structuring\nour design into abstract interfaces, so this is something that should be avoided as\nmuch as possible.\nThe solution is to use an abstract factory [Gamma95], which is a class whose sole\npurpose is to instantiate a specific implementation for an interface when asked for it.\nThe following is an example of a basic factory for our sound system:\n/ / I n SoundSystemFactory.h\nclass ISoundSystem;\nclass SoundSystemFactory {\npublic:\nenum SoundSystemType {\nSOUND_SOFTWARE,\nSOUND_HARDWARE,\nSOUND_SOMETH I NGE LSE\n};\nstatic ISoundSystem * CreateSoundSystem(SoundSystemType type);\n//In SoundSystemFactory. cpp\n^include \"SoundSystemSof tware . h\"\n^include \"SoundSystemHardware . h\"\n#include \"SoundSYstemSomethingElse . h\"\nISoundSystem * SoundSystemFactory: :CreateSoundSystem ( SoundSystemType\n_type )\n{\nISoundSystem * pSystem;\n",
      "content_length": 2021,
      "extraction_method": "Direct"
    },
    {
      "page_number": 20,
      "chapter": null,
      "content": "1.3 Programming with Abstract Interfaces \n23\nswitch ( type ) {\ncase SOUND_SOFTWARE:\npSystem = new SoundSystemSoftwaref);\nbreak;\ncase SOUND_HARDWARE:\npSystem = new SoundSystemHardwareO;\nbreak;\ncase SOUND_SOMETHINGELSE:\npSystem = new SoundSystemSomethingElse();\nbreak;\ndefault:\npSystem = NULL;\nreturn pSystem;\nNow we have solved the problem. The user need only include SoundSystemFac-\ntory. h and SoundSystem.h. As a matter of fact, we don't even have to make the rest of\ndie header files available. To use a specific sound system, the user can now write:\nISoundSystem * pSoundSystem;\npSoundSystem = SoundSystemFactory::CreateSoundSystem\n(SoundSystemFactory::SOUND_SOFTWARE);\n// Now we're ready to use it\npSoundSystem->PlaySound ( hSound );\nWe need to always include a virtual destructor in our abstract interfaces. If\nwe don't, C++ will automatically generate a nonvirtual destructor, which\nwill cause the real destructor of our specific implementation not to be called\n(and that is usually a hard bug to track down). Unlike normal member\nfunctions, we can't just provide a pure virtual destructor, so we need to create\nan empty function to keep the compiler happy.\nAbstract Interfaces as Traits\nA slightly different way to think of abstract interfaces is to consider an interface as a\nset of behaviors. If a class implements an interface, that class is making a promise that\nit will behave in certain ways. For example, the following is an interface used by\nobjects that can be rendered to the screen:\nclass IRenderable {\npublic:\nvirtual -IRenderable() {};\nvirtual bool Render () = 0;\nWe can design a class to represent 3D objects that inherits from IRenderable and\nprovides its own method to render itself on the screen. Similarly, we could have a\n",
      "content_length": 1749,
      "extraction_method": "Direct"
    },
    {
      "page_number": 21,
      "chapter": null,
      "content": "Section 1 General Programming\nterrain class that also inherits from IRenderable and provides a completely different\nrendering method.\nclass GenericSDObject : public IRenderable {\npublic:\nvirtual ~Generic3DObject() ;\nvirtual bool Render();\n// Rest of the functions here\n};\nThe render loop will iterate through all the objects, and if they can be rendered,\nit calls their RenderQ function. The real power of the interface comes again from hid-\ning the real implementation from the interface: now it is possible to add a completely\nnew type of object, and as long as it presents the IRenderable interface, the rendering\nloop will be able to render it like any other object. Without abstract interfaces, the\nrender loop would have to know about the specific types of object (generic 3D object,\nterrain, and so on) and decide whether to call their particular render functions. Cre-\nating a new type of render-capable object would require changing the render loop\nalong with many other parts of the code.\nWe can check whether an object inherits from IRenderable to know if it can be\nrendered. Unfortunately, that requires that the compiler's RTTI (Run Time Type\nIdentification) option be turned on when the code is compiled. There is usually a per-\nformance and memory cost to have RTTI enabled, so many games have it turned off\nin their projects. We could use our own custom RTTI, but instead, let's go the way of\nCOM (Microsoft's Component Object Model) and provide a Querylnterface function\n[Rogerson97] .\nIf the object in question implements a particular interface, then Querylnterface\ncasts the incoming pointer to the interface and returns true. To create our own Query-\nInterface function, we need to have a base class from which all of the related objects\nthat inherit from a set of interfaces derive. We could even make that base class itself an\ninterface like COM's lUnknown, but that makes things more complicated.\nclass GameObject {\npublic:\nenum GamelnterfaceType \n{\nIRENDERABLE,\nIOTHERINTERFACE\nvirtual bool Querylnterface (const GamelnterfaceType type,\nvoid ** pObj ) ;\n// The rest of the GameObject declaration\nThe implementation of Querylnterface for a plain game object would be trivial.\nBecause it's not implementing any interface, it will always return false.\n",
      "content_length": 2273,
      "extraction_method": "Direct"
    },
    {
      "page_number": 22,
      "chapter": null,
      "content": "1.3 Programming with Abstract Interfaces \n25\nbool GameObject: :QueryInterface (const GamelnterfaceType type,\nvoid ** pObj ) {\nreturn false;\nThe implementation of a 3D object class is different from that of GameObject,\nbecause it will implement the IRenderable interface.\nclass 3DObject : public GameObject, public IRenderable {\npublic:\nvirtual -3DObject();\nvirtual bool Querylnterface (const GamelnterfaceType type,\nvoid ** pObj ) ;\nvirtual bool Render();\n// Some more functions if needed\nbool SDObject: :QueryInterface (const GamelnterfaceType type,\nvoid ** pObj ) {\nbool bSuccess = false;\nif ( type == GameObject:: IRENDERABLE ) {\n*pObj = static_cast<IRenderable *>(this);\nbSuccess = true;\n}\nreturn bSuccess;\nIt is the responsibility of the 3DObject class to override Querylnterface, check for\nwhat interfaces it supports, and do the appropriate casting.\nNow, let's look at the render loop, which is simple and flexible and knows noth-\ning about the type of objects it is rendering.\nIRenderable * pRenderable;\nfor ( all the objects we want to render ) {\nif ( pGameObject->QueryInterface (GameObject: : IRENDERABLE,\n(void**)&pRenderable) )\n{\npRenderable->Render ( ) ;\nNow we're ready to deliver the last of the promises of abstract interfaces listed at\nthe beginning of this gem: effortlessly adding new implementations. With such a ren-\nder loop, if we give it new types of objects and some of them implemented the IRen-\nderable interface, everything would work as expected without the need to change the\nrender loop. The easiest way to introduce the new object types would be to simply re-\nlink the project with the updated libraries or code that contains the new classes.\nAlthough beyond the scope of this gem, we could add new types of objects at runtime\nthrough DLLs or an equivalent mechanism available on the target platform. This\nenhancement would allow us to release new game objects or game updates without\n",
      "content_length": 1918,
      "extraction_method": "Direct"
    },
    {
      "page_number": 23,
      "chapter": null,
      "content": "26 \nSection 1 General Programming\nthe need to patch the executable. Users could also use this method to easily create\nmodifications for our game.\nNotice that nothing is stopping us from inheriting from multiple interfaces. All it\nwill mean is that the class that inherits from multiple interfaces is now providing all\nthe services specified by each of the interfaces. For example, we could have an IColl-\nidable interface for objects that need to have collision detection done. A 3D object\ncould inherit from both IRenderable and ICollidable, but a class representing smoke\nwould only inherit from IRenderable.\nA word of warning, however: while using multiple abstract interfaces is a power-\nful technique, it can also lead to overly complicated designs that don't provide any\nadvantages over designs with single inheritance. Also, multiple inheritance doesn't\nwork well for dynamic characteristics, and should rather be used for permanent char-\nacteristics intrinsic to an object.\nEven though many people advise staying away from multiple inheritance, this is a\ncase where it is useful and it does not have any major drawbacks. Inheriting from at\nmost one real parent class and multiple interface functions should not result in the\ndreaded diamond-shaped inheritance tree (where the parents of both our parents are\nthe same class) or many of the other usual drawbacks of multiple inheritance.\nEverything Has a Cost\nSo far, we have seen that abstract interfaces have many attractive features. However, all\nof these features come at a price. Most of the time, the advantages of using abstract\ninterfaces outweigh any potential problems, but it is important to be aware of the\ndrawbacks and limitations of this technique.\nFirst, the design becomes more complex. For someone not used to abstract inter-\nfaces, the extra classes and the querying of interfaces could look confusing at first\nsight. It should only be used where it makes a difference, not indiscriminately all over\nthe game; otherwise, it will only obscure the design and get in the way.\nWith the abstract interfaces, we did such a good job hiding all of the private\nimplementations that they actually can become harder to debug. If all we have is a\nvariable of type IRenderable*, we won't be able to see the private contents of the real\nobject it points to in the debugger's interactive watch window without a lot of tedious\ncasting. On the other hand, most of the time we shouldn't have to worry about it.\nBecause the implementation is well isolated and tested by itself, all we should care\nabout is using the interface correctly.\nAnother disadvantage is that it is not possible to extend an existing abstract inter-\nface through inheritance. Going back to our first example, maybe we would have\nliked to extend the SoundSystemHardware class to add a few functions specific to the\ngame. Unfortunately, we don't have access to the class implementation any more, and\nwe certainly can't inherit from it and extend it. It is still possible either to modify the\nexisting interface or provide a new interface using a derived class, but it will all have to\nbe done from the implementation side, and not from within the game code.\n",
      "content_length": 3185,
      "extraction_method": "Direct"
    },
    {
      "page_number": 24,
      "chapter": null,
      "content": "1.3 Programming with Abstract Interfaces \n27\nFinally, notice that every single function in an abstract interface is a virtual func-\ntion. This means that every time one of these functions is called through the abstract\ninterface, the computer will have to go through one extra level of indirection. This is\ntypically not a problem with modern computers and game consoles, as long as we\navoid using interfaces for functions that are called from within inner loops. For exam-\nple, creating an interface with a DrawPolygonQ or SetScreenPointQ function would\nprobably not be a good idea.\nConclusion\nAbstract interfaces are a powerful technique that can be put to good use with very lit-\ntle overhead or structural changes. It is important to know how it can be best used,\nand when it is better to do things a different way. Perfect candidates for abstract inter-\nfaces are modules that can be replaced (graphics Tenderers, spatial databases, AI\nbehaviors), or any sort of pluggable or user-extendable modules (tool extensions,\ngame behaviors).\nReferences\n[Gamma95] Gamma, Eric et al, Design Patterns, Addison-Wesley, 1995.\n[Lakos96] Lakos, John, Large Scale C++ Software Design, Addison-Wesley, 1996.\n[Rogerson97] Rogerson, Dale, Inside COM. Microsoft Press, 1997.\n",
      "content_length": 1261,
      "extraction_method": "Direct"
    },
    {
      "page_number": 25,
      "chapter": null,
      "content": "1.4\nExporting C++ Classes from DLLs\nHerb Marselas, Ensemble Studios\nhmarselas@ensemblestudios.com\nE\nxporting a C++ class from a Dynamic Link Library (DLL) for use by another\napplication is an easy way to encapsulate instanced functionality or to share\nderivable functionality without having to share the source code of the exported class.\nThis method is in some ways similar to Microsoft COM, but is lighter weight, easier\nto derive from, and provides a simpler interface.\nExporting a Function\nAt the most basic level, there is little difference between exporting a function or a class\nfrom a DLL. To export myExportedFunction from a DLL, the value _BUILDING_\nMY_DLL is defined in the preprocessor options of the DLL project, and not in the\nprojects that use the DLL. This causes DLLFUNCTION to be replaced by\n__decbpec(dllexport) when building the DLL, and __deckpec(dllimport) when build-\ning the projects that use the DLL.\n#ifdef _BUILDING_MY_DLL\ntfdefine DLLFUNCTION _declspec(dllexport) // defined if building the\n// DLL\n#else\ntfdefine DLLFUNCTION _declspec(dllimport) // defined if building the\n// application\n#endif\nDLLFUNCTION long myExportedFunction(void);\nExporting a Class\nExporting a C++ class from a DLL is slightly more complicated because there are sev-\neral alternatives. In the simplest case, the class itself is exported. As before, the DLL-\nFUNCTION macro is used to declare the class exported by the DLL, or imported by\nthe application.\n28\n",
      "content_length": 1460,
      "extraction_method": "Direct"
    },
    {
      "page_number": 26,
      "chapter": null,
      "content": "1.4 Exporting C++ Classes from DLLs \n29\ntfifdef \n_BUILDING_MY_DLL\ntfdefine DLLFUNCTION _declspec(dllexport)\n#else\ntfdefine DLLFUNCTION _ declspec(dllimport)\ntfendif\nclass DLLFUNCTION CMyExportedClass\n{\npublic:\nCMyExportedClass(void) : mdwValue(O) { }\nvoid setValue(long dwValue) { mdwValue = dwValue; }\nlong getValue(void) { return mdwValue; }\nlong clearValue(void) ;\nprivate:\nlong mdwValue;\nIf the DLL containing the class is implicitly linked (in other words, the project\nlinks with the DLL's lib file), then using the class is as simple as declaring an instance\nof the class CMyExportedClass. This also enables derivation from this class as if it were\ndeclared directly in the application. The declaration of a derived class in the applica-\ntion is made normally without any additional declarations.\nclass CMyApplicationClass : public CMyExportedClass\n{\npublic:\nCMyApplicationClass ( void )\nThere is one potential problem with declaring or allocating a class exported from\na DLL in an application: it may confuse some memory-tracking programs and cause\nthem to misreport memory allocations or deletions. To fix this problem, helper func-\ntions that allocate and destroy instances of the exported class must be added to the\nDLL. All users of the exported class should call the allocation function to create an\ninstance of it, and the deletion function to destroy it. Of course, the drawback to this\nis that it prevents deriving from the exported class in the application. If deriving an\napplication-side class from the exported class is important, and the project uses a\nmemory-tracking program, then this program will either need to understand what's\ngoing on or be replaced by a new memory-tracking program.\n",
      "content_length": 1712,
      "extraction_method": "Direct"
    },
    {
      "page_number": 27,
      "chapter": null,
      "content": "30 \nSection 1 General Programming\n#ifdef _BUILDING_MY_DLL\n#define DLLFUNCTION _declspec(dllexport)\n#else\n#define DLLFUNCTION _declspec(dllimport)\n#endif\nclass DLLFUNCTION CMyExportedClass\n{\npublic:\nCMyExportedClass(void) : mdwValue(O) { }\nvoid setValue(long dwValue) { mdwValue = dwValue; }\nlong getValue(void) { return mdwValue; }\nlong clearValue(void);\nprivate:\nlong mdwValue;\n};\nCMyExportedClass *createMyExportedClass(void) {\nreturn new CMyExportedClass; }\nvoid deleteMyExportedClass(CMyExportedClass *pclass) {\ndelete pclass; }\nExporting Class Member Functions\nEven with the helper functions added, because the class itself is being exported from\nthe DLL, it is still possible that users could create instances of the class without calling\nthe createMyExportedCLtss helper function. This problem is easily solved by moving the\nexport specification from the class level to the individual functions to which the users\nof the class need access. Then the application using the class can no longer create an\ninstance of the class itself. Instead, it must call the createMyExportedCLtss helper func-\ntion to create an instance of the class, and deleteMyExportedClass when it wishes to\ndestroy the class.\nclass CMyExportedClass\n{\npublic:\nCMyExportedClass(void) : mdwValue(O) { }\nDLLFUNCTION void setValue(long dwValue) { mdwValue = dwValue; }\nDLLFUNCTION long getValue(void) { return mdwValue; }\nlong clear-Value (void);\nprivate:\nlong mdwValue;\n};\nCMyExportedClass *createMyExportedClass(void) {\nreturn new CMyExportedClass; }\nvoid deleteMyExportedClass(CMyExportedClass *pclass) {\ndelete pclass; }\n",
      "content_length": 1597,
      "extraction_method": "Direct"
    },
    {
      "page_number": 28,
      "chapter": null,
      "content": "1.4 Exporting C++ Classes from DLLs \n31\nIt should also be noted that although CMyExportedClass::clearValue is a public\nmember function, it can no longer be called by users of the class outside the DLL, as\nit is not declared as dllexported. This can be a powerful tool for a complex class that\nneeds to make some functions publicly accessible to users of the class outside the\nDLL, yet still needs to have other public functions for use inside the DLL itself. An\nexample of this strategy in practice is the SDK for Discreet's 3D Studio MAX. Most\nof the classes have a mix of exported and nonexported functions. This allows die user\nof the SDK to access or derive functionality as needed from the exported member\nfunctions, while enabling the developers of the SDK to have their own set of inter-\nnally available member functions.\nExporting Virtual Class Member Functions\nOne potential problem should be noted for users of Microsoft Visual C++ 6. If you\nare attempting to export the member functions of a class, and you are not linking\nwith the lib file of the DLL that exports the class (you're using LoadLibrary to load\nthe DLL at runtime), you will get an \"unresolved external symbol\" for each function\nyou reference if inline function expansion is disabled. This can happen regardless of\nwhether the function is declared completely in the header. One fix for this is to\nchange the inline function expansion to \"Only \ninline\" or \"Any Suitable.\" Unfortu-\nnately, this may conflict with your desire to actually have inline function expansion\ndisabled in a debug build. An alternate fix is to declare the functions virtual. The vir-\ntual declaration will cause the correct code to be generated, regardless of the setting of\nthe inline function expansion option. In many circumstances, you'll likely want to\ndeclare exported member functions virtual anyway, so that you can both work around\nthe potential Visual C++ problem and allow the user to override member functions as\nnecessary.\nclass CMyExportedClass\n{\npublic:\nCMyExportedClass(void) : mdwValue(O) { }\nDLLFUNCTION virtual void setValue(long dwValue) { mdwValue =\ndwValue; }\nDLLFUNCTION virtual long getValue(void) { return mdwValue; }\nlong clearValue(void);\nprivate:\nlong mdwValue;\n};\nWith exported virtual member functions, deriving from the exported class on the\napplication side is the same as if the exported class were declared completely in the\napplication itself.\n",
      "content_length": 2426,
      "extraction_method": "Direct"
    },
    {
      "page_number": 29,
      "chapter": null,
      "content": "32 \nSection 1 General Programming\nclass CMyApplicationClass : public CMyExportedClass\n{\npublic:\nCMyApplicationClass (void) \n{ }\nvirtual void setValue(long dwValue);\nvirtual long getValue(void) ;\nSummary\nExporting a class from a DLL is an easy and powerful way to share functionality with-\nout sharing source code. It can give the application all the benefits of a structured C++\nclass to use, derive from, or overload, while allowing the creator of the class to keep\ninternal functions and variables safely hidden away.\n",
      "content_length": 520,
      "extraction_method": "Direct"
    },
    {
      "page_number": 30,
      "chapter": null,
      "content": "1.5\nProtect Yourself from DLL Hell\nand Missing OS Functions\nHerb Marselas, Ensemble Studios\nhmarselas@ensemblestudios.com\nD\nynamic Link Libraries (DLLs) are a powerful feature of Microsoft Windows.\nThey have many uses, including sharing executable code and abstracting out\ndevice differences. Unfortunately, relying on DLLs can be problematic due to their\nstandalone nature. If an application relies on a DLL that doesn't exist on the user's\ncomputer, attempting to run it will result in a \"DLL Not Found\" message that's not\nhelpful to the average user. If the DLL does exist on the user's computer, there's no\nway to tell if the DLL is valid (at least as far as the application is concerned) if it's\nautomatically loaded when the application starts up.\nBad DLL versions can easily find their way onto a system as the user installs and\nuninstalls other programs. Alternatively, there can even be differences in system DLLs\namong different Windows platforms and service packs. In these cases, the user may\neither get the cryptic \"DynaLink Error!\" message if the function being linked to in the\nDLL doesn't exist, or worse yet, the application will crash. All of these problems with\nfinding and loading the correct DLL are often referred to as \"DLL Hell.\" Fortunately,\nthere are several ways to protect against falling into this particular hell.\nImplicit vs. Explicit Linking\nThe first line of defense in protecting against bad DLLs is to make sure that the nec-\nessary DLLs exist on the user's computer and are a version with which the application\ncan work. This must be done before attempting to use any of their functionality.\nNormally, DLLs are linked to an application by specifying their eponymous lib\nfile in the link line. This is known as implicit DLL loading, or implicit linking. By link-\ning to the lib file, the operating system will automatically search for and load the\nmatching DLL when a program runs. This method assumes that the DLL exists, that\nWindows can find it, and that it's a version with which the program can work.\nMicrosoft Visual C++ also supports three other methods of implicit linking. First,\nincluding a DLL's lib file directly into a project is just like adding it on the link line.\nSecond, if a project includes a subproject that builds a DLL, the DLL's lib file is\n33\n",
      "content_length": 2303,
      "extraction_method": "Direct"
    },
    {
      "page_number": 31,
      "chapter": null,
      "content": "34 \nSection 1 General Programming\nautomatically linked with the project by default. Finally, a lib can be linked to an\napplication using the #pragma comment (lib \"libname\") directive.\nThe remedy to this situation of implicit linking and loading is to explicitly load\nthe DLL. This is done by not linking to the DLL's lib file in the link line, and remov-\ning any #pragma comment directives that would link to a library. If a subproject in\nVisual C++ builds a DLL, the link property page of the subproject should be changed\nby checking the \"Doesn't produce .LIB\" option. By explicitly loading the DLL, the\ncode can handle each error that could occur, making sure the DLL exists, making sure\nthe functions required are present, and so forth.\nLoadLibrary and GetProcAddress\nWhen a DLL is implicitly loaded using a lib file, the functions can be called directly\nin the application's code, and the OS loader does all the work of loading DLLs and\nresolving function references. When switching to explicit linking, the functions must\ninstead be called indirectly through a manually resolved function pointer. To do this,\nthe DLL that contains the function must be explicitly loaded using the LoadLibrary\nfunction, and then we can retrieve a pointer to the function using GetProcAddress.\nHMODULE LoadLibrary(LPCTSTR IpFileName);\nFARPROC GetProcAddress(HMODULE hModule, LPCSTR IpProcName);\nBOOL FreeLibrary(HMODULE hModule);\nLoadLibrary searches for the specified DLL, loads it into the applications process\nspace if it is found, and returns a handle to this new module. GetProcAddress is then\nused to create a function pointer to each function in the DLL that will be used by the\ngame. When an explicitly loaded DLL is no longer needed, it should be freed using\nFreeLibrary. After calling FreeLibrary, the module handle is no longer considered valid.\nEvery LoadLibrary call must be matched with a FreeLibrary call. This is necessary\nbecause Windows increments a reference count on each DLL per process when it is\nloaded either implicitly by the executable or another DLL, or by calling LoadLibrary.\nThis reference count is decremented by calling FreeLibrary, or unloading the exe-\ncutable or DLL that loaded this DLL. When the reference count for a given DLL\nreaches zero, Windows knows it can safely unload the DLL.\nGuarding Against DirectX\nOne of the problems we have often found is that the required versions of DirectX\ncomponents are not installed, or the install is corrupt in some way. To protect our\ngame against these problems, we explicitly load the DirectX components we need. If\nwe were to implicitly link to Directlnput in DirectX 8, we would have added the din-\nputS.lib to our link line and used the following code:\n",
      "content_length": 2722,
      "extraction_method": "Direct"
    },
    {
      "page_number": 32,
      "chapter": null,
      "content": "1.5 Protect Yourself from DLL Hell and Missing OS Functions \n35\nIDirectlnputS *pDInput;\nHRESULT hr = DirectInput8Create(hInstance, DIRECTINPUT_VERSION,\nIID_IDirectInput8,\n(LPVOID*) & pDInput, 0);\nif \n(FAILED(hr))\n{\n// handle error - initialization error\n}\nThe explicit DLL loading case effectively adds two more lines of code, but the\napplication is now protected against dinput8.dll not being found, or of it being cor-\nrupt in some way.\ntypedef HRESULT (WINAPI* DirectInput8Create_PROC)\n(HINSTANCE hinst, DWORD dwVersion, REFIID riidltf,\nLPVOID* ppvOut,\nLPUNKNOWN punkOuter);\nHMODULE hDInputLib = LoadLibrary( \"dinput8.dll\") ;\nif (! hDInputLib)\n{\n// handle error - DInput 8 not found. Is it installed incorrectly\n// or at all?\nDirectInput8Create_PROC diCreate;\ndiCreate = (DirectInput8Create_PROC)\nGetProcAddress(hDInputLib, \"DirectlnputSCreate\") ;\nif (! diCreate)\n{\n// handle error - DInput 8 exists, but the function can't be\n// found.\nHRESULT hr = (diCreate) (hlnstance, DIRECTINPUT_VERSION,\nI ID_IDirect Inputs,\n(LPVOID*) &mDirectInput, NULL);\nif \n(FAILED(hr))\n{\n// handle error - initialization error\nFirst, a function pointer typedef is created that reflects the function Direct-\nlnputSCreate. The DLL is then loaded using LoadLibrary. If the dinput8.dll was\nloaded successfully, we then attempt to find the function DirectlnputSCreate using\nGetProcAddress. GetProcAddress returns a pointer to the function if it is found, or\nNULL if the function cannot be found. We then check to make sure the function\npointer is valid. Finally, we call DirectlnputSCreate through the function pointer to\ninitialize Directlnput.\n",
      "content_length": 1622,
      "extraction_method": "Direct"
    },
    {
      "page_number": 33,
      "chapter": null,
      "content": "36 \nSection 1 General Programming\nIf there were more functions that needed to be retrieved from the DLL, a func-\ntion pointer typedefand variable would be declared for each. It might be sufficient to\nonly check for NULL when mapping the first function pointer using GetProcAddress.\nHowever, as more error handling is usually not a bad thing, checking every Get-\nProcAddress for a successful non-NULL return is probably a good thing to do.\nUsing OS-Specific Features \n_\nAnother issue that explicit DLL loading can resolve is when an application wants to\ntake advantage of a specific API function if it is available. There is an extensive num-\nber of extended functions ending in \"Ex\" that are supported under Windows NT or\n2000, and not available in Windows 95 or 98. These extended functions usually pro-\nvide more information or additional functionality than the original functions do .\nAn example of this is the CopyFileEx function, which provides the ability to can-\ncel a long file copy operation. Instead of calling it directly, kernel32.dll can be loaded\nusing LoadLibrary and the function again mapped with GetProcAddress. If we load\nkernel32.dll and find CopyFileEx, we use it. If we don't find it, we can use the regular\nCopyFile function. One other problem that must be avoided in this case is that Copy-\nFileEx is really only a #define replacement in the winbase.h header file that is replaced\nwith CopyFileExA or CopyFileExW if compiling for ASCII or wide Unicode charac-\nters, respectively.\ntypedef BOOL (WINAPI *CopyFileEx_PROC) (LPCTSTR IpExistingFileName,\nLPCTSTR IpNewFileName , \nLPPROGRESS_ROUTINE IpProgressRoutine, \nLPVOID\nIpData, LPBOOL pbCancel, DWORD dwCopyFlags) ;\nHMODULE hKerne!32 = LoadLibrary(\"kernel32.dH\") ;\nif \n(!hKerne!32)\n{\n// handle error - kernel32.dll not found. Wow! That's really bad\n}\nCopyFileEx_PROC pfnCopyFileEx;\npfnCopyFileEx = (CopyFileEx_PROC) GetProcAddress(hKernel32,\n\"CopyFileExA\") ;\nBOOL bReturn;\nif (pfnCopyFileEx)\n{\n/ / use CopyFileEx to copy the file\nbReturn = (pfnCopyFileEx) (pExistingFile, pDestinationFile, ...);\nelse\n// use the regular CopyFile function\nbReturn = CopyFilefpExistingFile, pDestinationFile, FALSE);\n",
      "content_length": 2171,
      "extraction_method": "Direct"
    },
    {
      "page_number": 34,
      "chapter": null,
      "content": "1.5 Protect Yourself from DLL Hell and Missing OS Functions \n37\nThe use of LoadLibrary and GetProcAddress can also be applied to game DLLs.\nOne example of this is the graphics support in a game engine currently under devel-\nopment at Ensemble Studios, where graphics support for Direct3D and OpenGL has\nbeen broken out into separate DLLs that are explicitly loaded as necessary. If\nDirect3D graphics support is needed, the Direct3D support DLL is loaded with\nLoadLibrary and the exported functions are mapped using GetProcAddress. This setup\nkeeps the main executable free from having to link implicitly with either dddS.lib or\nopengl32.lib.\nHowever, the supporting Direct3D DLL links implicitly with dddS.lib, and the\nsupporting OpenGL DLL links implicitly with opengl32. lib. This explicit loading of\nthe game's own DLLs by the main executable, and implicit loading by each graphics\nsubsystem solves several problems. First, if an attempt to load either library fails, it's\nlikely that that particular graphics subsystem files cannot be found or are corrupt. The\nmain program can then handle the error gracefully. The other problem that this\nsolves, which is more of an issue with OpenGL than Direct3D, is that if the engine\nwere to link explicitly to OpenGL, it would need a typedef and function pointer for\nevery OpenGL function it used. The implicit linking to the support DLL solves this\nproblem.\nSummary\nExplicit linking can act as a barrier against a number of common DLL problems that\nare encountered under Windows, including missing DLLs, or versions of DLLs that\naren't compatible with an application. While not a panacea, it can at least put the\napplication in control and allow any error to be handled gracefully instead of with a\ncryptic error message or an outright crash.\n",
      "content_length": 1788,
      "extraction_method": "Direct"
    },
    {
      "page_number": 35,
      "chapter": null,
      "content": "1.6\nDynamic Type Information\nScott Wakeling, Virgin Interactive\nscott@chronicreality.com\nA\ns developers continue to embrace object orientation, the systems that power\ngames are growing increasingly flexible, and inherently more complex. Such sys-\ntems now regularly contain many different types and classes; counts of over 1000 are\nnot unheard of. Coping with so many different types in a game engine can be a chal-\nlenge in itself. A type can really mean anything from a class, to a struct, to a standard\ndata type. This gem discusses managing types effectively by providing ways of query-\ning their relations to other types, or accessing information about their type at runtime\nfor query or debug purposes. Toward the end of the gem, an approach for supporting\npersistent objects is suggested with some ideas about how the method can be\nextended.\nIntroducing the Dynamic Type Information Class\nIn our efforts to harness the power of our types effectively, we'll be turning to the aid\nof one class in particular: the dynamic type information (DTI) class. This class will\nstore any information that we may need to know about the type of any given object or\nstructure. A minimal implementation of the class is given here:\nclass dtiClass\n{\nprivate:\nchar* szName;\ndtiClass* pdtiParent;\npublic:\ndtiClass();\ndtiClass( char* szSetName, dtiClass* pSetParent );\nvirtual -dtiClass();\nconst char* GetName();\nbool SetName( char* szSetName );\ndtiClass* GetParent();\nbool SetParent( dtiClass* pSetParent );\n38\n",
      "content_length": 1497,
      "extraction_method": "Direct"
    },
    {
      "page_number": 36,
      "chapter": null,
      "content": "1.6 Dynamic Type Information \n39\nIn order to instill DTI into our engine, all our classes will need a dtiClass as a sta-\ntic member. It's this class that allows us to access a class name for debug purposes and\nquery the dtiClass member of the class's parent. This member must permeate the class\ntree all the way from the root class down, thus ensuring that all game objects have\n'~^J^__J) \naccess to information about themselves and their parents. The implementation ofdti-\nONTHICO \nClass can be found in the code on the accompanying CD.\nExposing and Querying the DTI\nLet's see how we can begin to use DTI by implementing a very simple class tree as\ndescribed previously. Here is a code snippet showing a macro that helps us define our\nstatic dtiClass member, a basic root class, and simple initialization of the class's type\ninfo:\n#define EXPOSE_TYPE \\\npublic: \\\nstatic dtiClass Type;\nclass CRootClass\n{public:\nEXPOSE_TYPE;\nCRootClass() \n{};\nvirtual -CRootClass() {};\n};\ndtiClass CRootClass::Type( \"CRootClass\", NULL );\nBy including the EXPOSE_TYPE macro in all of our class definitions and initial-\nizing the static Type member correctly as shown, we've taken the first step toward\ninstilling dynamic type info in our game engine. We pass our class name and a pointer\nto the class's parent's dtiClass member. The dtiClass constructor does the rest, setting\nup the szName and pdtiParent members accordingly.\nWe can now query for an object's class name at runtime for debug purposes of\nother type-related cases, such as saving or loading a game. More on that later, but for\nnow, here's a quick line of code that will get us our class name:\n// Let's see what kind of object this pointer is pointing to\nconst char* szGetName = pSomePtr->Type.GetName();\nIn the original example, we passed NULL in to the dtiClass constructor as the\nclass's parent field because this is our root class. For classes that derive from others, we\njust need to specify the name of the parent class. For example, if we were to specify a\nchild class of our root, a basic definition might look something like this:\nclass CChildClass : public CRootClass\n{\nEXPOSE TYPE;\n",
      "content_length": 2139,
      "extraction_method": "Direct"
    },
    {
      "page_number": 37,
      "chapter": null,
      "content": "40 \nSection 1 General Programming\n// Constructor and virtual Destructor go here\n};\ndtiClass CChildClass::Type( \"CChildClass\", &CRootClass::Type );\nNow we have something of a class tree growing. We can access not only our class's\nname, but the name of its parent too, as long as its type has been exposed with the\nEXPOSE_TYPE macro. Here's a line of code that would get us our parent's name:\n// Let's see what kind of class this object is derived from\nchar* szParentName = pSomePtr->Type.GetParent()->GetName();\nNow that we have a simple class tree with DTI present and know how to use that\ninformation to query for class and parent names at runtime, we can move on to\nimplementing a useful method for safeguarding type casts, or simply querying an\nobject about its roots or general type.\nInheritance Means \"IsA\"\nObject orientation gave us the power of inheritance. With inheritance came polymor-\nphism, the ability for all our objects to be just one of many types at any one time. In\nmany cases, polymorphism is put to use in game programming to handle many types\nof objects in a safe, dynamic, and effective manner. This means we like to ensure that\nobjects are of compatible types before we cast them, thus preventing undefined\nbehavior. It also means we like to be able to check what type an object conforms to at\nruntime, rather than having to know from compiler time, and we like to be able to do\nall of these things quickly and easily.\nImagine that our game involves a number of different types of robots, some\npurely electronic, and some with mechanical parts, maybe fuel driven. Now assume\nfor instance that there is a certain type of weapon the player may have that is very\neffective against the purely electronic robots, but less so against their mechanical\ncounterparts. The classes that define these robots are very likely to be of the same\nbasic type, meaning they probably both inherit from the same generic robot base\nclass, and then go on to override certain functionality or add fresh attributes. To cope\nwith varying types of specialist child classes, we need to query their roots. We can\nextend the dtiClass introduced earlier to provide us with such a routine. We'll call the\nnew member function IsA, because inheritance can be seen to translate to \"is a type\nof.\" Here's the function:\nbool dtiClass::IsA( dtiClass* pType )\n{\ndtiClass* pStartType = this;\nwhile( pStartType )\n{\nif ( pStartType == pType )\n",
      "content_length": 2424,
      "extraction_method": "Direct"
    },
    {
      "page_number": 38,
      "chapter": null,
      "content": "1.6 Dynamic Type Information \n41\nreturn true;\nelse\npStartType = pStartType->GetParent();\nreturn false;\nIf we need to know whether a certain robot subclass is derived from a certain root\nclass, we just need to call IsA from the object's own dtiClass member, passing in the\nstatic dtiClass member of the root class. Here's a quick example:\nCRootClass* pRoot;\nCChildClass* pChild = new CChildClass();\nif ( pChild->Type.IsA( &CRootClass::Type ) )\npRoot = (CRootClass*)pChild;\nWe can see that the result of a quick IsA check tells us whether we are derived,\ndirectly or indirectly, from a given base class. Of course, we might use this fact to go\non and perform a safe casting operation, as in the preceding example. Or, maybe we'll\njust use the check to filter out certain types of game objects in a given area, given that\ntheir type makes them susceptible to a certain weapon or effect. If we decide that a\nsafe casting operation is something we'll need regularly, we can add the following\n^-—_1-^ \nfunction to the root object to simplify matters. Here's the definition and a quick\nexample; the function's implementation is on the accompanying CD:\n// SafeCast member function definition added to CRootClass\nvoid* SafeCast( dtiClass* pCastToType );\n// How to simplify the above operation\npRoot = (CRootClass*)pChild->SafeCast( &CRootClass::Type );\nIf the cast is not safe (in other words, the types are not related), dien the value will\nevaluate to nothing, and pRoot will be NULL.\nHandling Generic Objects\nGoing back to our simple game example, let's consider how we might cope with so\nmany different types of robot effectively. The answer starts off quite simple: we can\nmake use of polymorphism and just store pointers to them all in one big array of\ngeneric base class pointers. Even our more specialized robots can be stored here, such\nas CRobotMech (derived from CRobof), because polymorphism dictates that for any\ntype requirement, a derived type can always be supplied instead. Now we have our\nvast array of game objects, all stored as pointers to a given base class. We can iterate\n",
      "content_length": 2087,
      "extraction_method": "Direct"
    },
    {
      "page_number": 39,
      "chapter": null,
      "content": "42 \nSection 1 \nGeneral Programming\nover them safely, perhaps calling virtual functions on each and getting the more spe-\ncialized (overridden) routines carried out by default. This takes us halfway to han-\ndling vast numbers of game objects in a fast, safe, and generic way.\nAs part of our runtime type info solution, we have the IsA and SafeCast routines\nthat can query what general type an object is, and cast it safely up the class tree. This\nis often referred to as up-casting, and it takes us halfway to handling vast numbers of\ngame objects in a fast, safe, and generic way. The other half of the problem comes\nwith down-casting—casting a pointer to a generic base class safely down to a more spe-\ncialized subclass. If we want to iterate a list of root class pointers, and check whether\neach really points to a specific type of subclass, we need to make use of the dynamic\ncasting operator, introduced by C++.\nThe dynamic casting operator is used to convert among polymorphic types and is\nboth safe and informative. It even returns applicable feedback about the attempted\ncast. Here's the form it takes:\ndynamic_cast< type-id >(expression)\nThe first parameter we must pass in is the type we wish expression to conform to\nafter the cast has taken place. This can be a pointer or reference to one of our classes.\nIf it's a pointer, the parameter we pass in as expression must be a pointer, too. If we pass\na reference to a class, we must pass a modifiable l-value in the second parameter. Here\nare two examples:\n// Given a root object (RootObj), on pointer (pRoot) we\n// can down-cast like this\nCChildClass* pChild = dynamic_cast<CChildClass*>(pRoot);\nCChildClass& ChildObj = dynamic_cast<CChildClass&>(RootObj);\nTo gain access to these extended casting operators, we need to enable embedded\nruntime type information in the compiler settings (use the /GR switch for Microsoft\nVisual C++). If the requested cast cannot be made (for example, if the root pointer\ndoes not really point to anything more derived), the operator will simply fail and the\nexpression will evaluate to NULL. Therefore, from the preceding code snippet,\n(f :,js*:*:*'% pChild would evaluate to NULL IfpRoot really did only point to a CRootClass object.\nON me a> \nIf the cast of RootObj failed, an exception would be thrown, which could be contained\nwith a try I catch block (example is included on the companion CD-ROM).\nThe dynamic_cast operator lets us determine what type is really hidden behind a\npointer. Imagine we want to iterate through every robot in a certain radius and deter-\nmine which ones are mechanical models, and thus immune to the effects of a certain\nweapon. Given a list of generic CRobot pointers, we could iterate through these and\nperform dynamic casts on each, checking which ones are successful and which resolve\nto NULL, and thus exacting which ones were in fact mechanical. Finally, we can now\nsafely down-cast too, which completes our runtime type information solution. The\n",
      "content_length": 2979,
      "extraction_method": "Direct"
    },
    {
      "page_number": 40,
      "chapter": null,
      "content": "1.6 Dynamic Type information \n43\n/ c \n-., \ncode on the companion CD-ROM has a more extended example of using the\non m CD dynamic casting operator.\nImplementing Persistent Type Information\nNow that our objects no longer have an identity crisis and we're managing them effec-\ntively at runtime, we can move on to consider implementing a persistent object solu-\ntion, thus extending our type-related capabilities and allowing us to handle things\n,- c \") such as game saves or object repositories with ease. The first thing we need is a bare-\nmtmco \nbones implementation of a binary store where we can keep our object data. An exam-\nple implementation, CdtiBin can be found on the companion CD-ROM.\nThere are a number of utility member functions, but the two important points\nare the Stream member function, and the friend « operators that allow us to write\nout or load die basic data types of the language. We'll need to add an operator for each\nbasic type we want to persist. When Stream is called, the data will be either read from\nthe file or written, depending on the values of m_bLoading and m_bSaving.\nTo let our classes know how to work with the object repositories we need to add\nthe Serialize function, shown here:\nvirtual void Serialize( CdtiBin& ObjStore );\nNote that it is virtual and needs to be overridden for all child classes that have\nadditional data over their parents. If we add a simple integer member to CRootClass,\nwe would write the Serialize function like this:\nvoid CRootClass::Serialize( CdtiBin& ObjStore )\n{\nObjStore « iMemberlnt;\n}\nWe would have to be sure to provide the friend operator for integers and CdtiBin\nobjects. We could write object settings out to a file, and later load them back in and\nrepopulate fresh objects with die old data, thus ensuring a persistent object solution\nfor use in a game save routine. All types would thus know how to save themselves,\nmaking our game save routines much easier to implement.\nHowever, child classes need to write out their data and that of their parents.\nInstead of forcing the programmer to look up all data passed down from parents and\nadding it to each class's Serialize member, we need to give each class access to its par-\nent's Serialize routine. This allows child classes to write (or load) their inherited data\nbefore their own data. We use the DECLAREJSUPER macro for this:\n#define DECLARE_SUPER(SuperClass) \\\npublic: \\\ntypedef Superclass Super;\n",
      "content_length": 2430,
      "extraction_method": "Direct"
    },
    {
      "page_number": 41,
      "chapter": null,
      "content": "44 \nSection 1 General Programming\nclass CChildClass\nDECLARE_SUPER(CRootClass);\nThis farther extends our type solution by allowing our classes to call their imme-\ndiate parents' versions of functions, making our class trees more extensible.\nCRootClass doesn't need to declare its superclass because it doesn't have one, and\nthus its Serialize member only needs to cope with its own data. Here's how CChild-\nClass::Serialize calls CRootClass:Serialize before dealing with some of its own data\n(added specifically for the example):\nvoid CChildClass::Serialize( CdtiBin& ObjStore )\n{\nSuper::Serialize( ObjStore );\nObjStore « fMemberFloat « iAnotherlnt;\n}\nA friend operator for the float data type was added to support the above. Note\nthat the order in which attributes are saved and loaded is always the same. Code\nshowing how to create a binary store, write a couple of objects out, and then repopu-\nlate the objects' attributes can be found on the companion CD-ROM.\nAs long as object types are serialized in the same order both ways, their attributes\nwill remain persistent between saves and loads. Adding the correct friend operators to\nthe CdtiBin class adds support for basic data types. If we want to add user-defined\nstructures to our class members, we just need to write an operator for coping with that\nstruct. With this in place, all objects and types in the engine will know precisely how\nto save themselves out to a binary store and read themselves back in.\nApplying Persistent Type Information to a Game\nSave Database\nAs mentioned previously, objects need to be serialized out and loaded back in the\nsame order. The quickest and easiest method is to only save out one object to the\ngame saves, and then just load that one back in. If we can define any point in\nthe game by constructing some kind of game state object that knows precisely how to\nserialize itself either way, then we can write all our game data out in one hit, and read\nit back in at any point. Our game state object would no doubt contain arrays of\nobjects. As long as the custom array type knows how to serialize itself, and we have all\nthe correct CdtiBin operators written for our types, everything will work. Saving and\nloading a game will be a simple matter of managing the game from a high-level, all-\nencompassing containment class, calling just the one Serialize routine when needed.\n",
      "content_length": 2367,
      "extraction_method": "Direct"
    },
    {
      "page_number": 42,
      "chapter": null,
      "content": "1.6 Dynamic Type Information \n45\nConclusion\nThere is still more that could be done than just the solution described here. Support-\ning multiple inheritance wouldn't be difficult. Instead of storing just the one parent\npointer in our static dtiClass, we would store an array of as many parents a class had,\nspecifying the count and a variable number of type classes in a suitable macro, or by\nextending the dtiClass constructor. An object flagging system would also be useful,\nand would allow us to enforce special cases such as abstract base classes or objects we\nonly ever wanted to be contained in other classes, and never by themselves (\"con-\ntained classes\").\nReferences\n[Meyers98] Meyers, Scott D., Effective C++ 2ndEdition, Addison-Wesley, 1998.\n[Wilkie94] Wilkie, George, Object-Oriented Software Engineering, Addison-Wesley,\n1994.\n[EberlyOO] Eberly, David H., 3D Game Engine Design, Morgan Kauffman,\n1999-2000.\n[WakelingOl] Wakeling, Scott J., \"Coping with Class Trees,\" available online at\nwww.chronicreality.com/articles, March 12, 2001.\n",
      "content_length": 1048,
      "extraction_method": "Direct"
    },
    {
      "page_number": 43,
      "chapter": null,
      "content": "1.7\nA Property Class for Generic\nC++ Member Access\nCharles Cafrelli\nskywise@iquest.net\nP\nractically every game has a unique set of game objects, and any code that has to\nmanipulate those objects has to be written from scratch for each project. Take,\nfor example, an in-game editor, which has a simple purpose: to create, place, display,\nand edit object properties. Object creation is almost always specific to the game, or\ncan be handled by a class factory. Object placement is specific to the visualization\nengine, which makes reuse difficult, assuming it is even possible to visually place an\nobject on the map. In some cases, a generic map editor that can be toggled on and off\n(or possibly superimposed as a heads-up display) can be reused from game to game.\nTherefore, in theory, it should be possible to develop a core editor module that can be\nreused without having to rewrite the same code over and over again for each project.\nHowever, given that all games have unique objects, how does the editor know what to\ndisplay for editing purposes without rewriting the editor code?\nWhat we need is a general object interface that allows access to the internals of a\nclass. Borland's C++ Builder provides an excellent C++ declaration type called ^prop-\nerty that does this very thing, but alas, it is a proprietary extension and unusable out-\nside of Borland C++. Interestingly enough, C#, Microsoft's new programming\nlanguage developed by the creator of Borland C++ Builder, contains the same feature.\nMicrosoft's COM interface allows runtime querying of an object for its members, but\nit requires that we bind our objects to the COM interface, making them less portable\nthan straight C++. This leaves a \"roll-your-own\" solution, which can be more light-\nweight than COM, and more portable than proprietary extensions to the C++ lan-\nguage. This will allow code modules such as the in-game editor to be written just\nonce, and used across many engines.\nThe Code\nThe interface is broken into two classes: a Property class and a PropertySet class. Prop-\nerty is a container for one piece of data. It contains a union of pointers to different\ndata types, an enumeration for the type of data, and a string for the property name.\nThe full source code can be found on the companion CD.\n46\n",
      "content_length": 2284,
      "extraction_method": "Direct"
    },
    {
      "page_number": 44,
      "chapter": null,
      "content": "1.7 A Property Class for Generic C++ Member Access \n47\nclass Property\n{\nprotected:\nunion Data\n{\nint* m_int;\nfloat* m_float;\nstd::string* m_string;\nbool* m_bool;\nenum Type\n{\nINT,\nFLOAT,\nSTRING,\nBOOL,\nEMPTY\nData \nm_data;\nType \nm_type;\nstd:: string m_name;\nprotected:\nvoid EraseType() ;\nvoid Register(int* value);\nvoid Registerffloat* value);\nvoid Registerfstd: :string* new_string);\nvoid Registerfbool* value);\npublic:\nProperty () ;\nProperty(std: :string const& name);\nProperty(std: :string const& name, int* value);\nProperty (std :: string const& name, float* value);\nProperty (std :: string const& name, std::string* value);\nProperty (std :: string const& name, bool* value);\n-Property () ;\nbool SetUnknownValue(std: :string const& value);\nbool Set (int value) ;\nbool Set(float value);\nbool Set(std: :string const& value);\nbool Set(bool value);\nvoid SetNamefstd: :string const& name);\nstd:: string GetName() const;\nint Getlnt();\nfloat GetFloatf);\nstd:: string GetString();\nbool GetBool() ;\n",
      "content_length": 990,
      "extraction_method": "Direct"
    },
    {
      "page_number": 45,
      "chapter": null,
      "content": "48 \nSection 1 General Programming\nThe example code shows basic data types being used and stored, although these\ncould be easily expanded to handle any data type. Properties store only a pointer back\nto the original data. Properties do not actually declare their own objects, or allocate\ntheir own memory, so manipulating a property's data results in the original data's\nmemory being handled. Setting a value via the Set function automatically defines the\ntype of the property.\nProperties are constructed and manipulated through a PropertySet class. The\nPropertySet class contains the list of registered properties, the registration methods,\nand the lookup method.\nclass PropertySet\n{\nprotected:\nHashTable<Property>m_properties;\npublic:\nPropertySet();\nvirtual -PropertySet();\nvoid Register(std::string const& name, int* value);\nvoid Register(std::string const& name, float* value);\nvoid Register(std::string const& name, std::string* value);\nvoid Register(std::string const& name, bool* value);\n// look up a property\nProperty* Lookup(std::string const& name);\n// get a list of available properties\nbool SetValue(std::string const& name, std::string* value);\nbool Set(std::string const& name, std::string const& value);\nbool Set(std::string const& name, int value);\nbool Set(std::string const& name, float value);\nbool Set(std::string const& name, bool value);\nbool Set(std::string const& name, char* value);\n};\nThe PropertySet is organized around a HashTable object that organizes all of the\nstored properties using a standard hash table algorithm. The HashTable itself is a tem-\nplate that can be used to hash into different objects, and is included on the compan-\nONIHfCD \n• \nf^r-~.\nion UJ.\nWe derive the game object from the PropertySet class:\nclass GameObject : public PropertySet\n{\nint \nm_test;\n};\nAny properties or flags that need to be publicly exposed or used by other objects\nshould be registered, usually at construction time. For example:\nRegister(\"test_value\",&m_test);\n",
      "content_length": 1981,
      "extraction_method": "Direct"
    },
    {
      "page_number": 46,
      "chapter": null,
      "content": "1.7 A Property Class for Generic C++ Member Access \n49\nCalling objects can use the Lookup method to access the registered data.\nvoid Update(PropertySet& property_set)\n{\nProperty* test_value_property=\nproperty_set.Lookup(\"test_value\");\nint test_value = test_value_property->GetInt();\n// etc\n}\nAs all of the game objects are now of type PropertySet, and as all objects are usu-\nally stored in a master update list, it is a simple matter of handing the list pointer off\nto the in-game editor for processing. New derived object types simply have to register\ntheir additional properties to be handled by the editor. No additional coding is neces-\nsary because the editor is not concerned with the derived types. It is sometimes help-\nful to specify the type in a property name (such as \"Type\") to assist the user when\nvisually editing the object. It's also useful to make the property required, so that the\neditor could, for example, parse the property list into a \"tree\" style display.\nThis process also provides the additional benefit of decoupling the data from its\nname. For instance, internally, the data may be referred to as m_colour, but can be\nexposed as \"color.\"\nAdditional Uses\nThese classes were designed around a concentric ring design theory. The PropertySet\ncannot be used without the Property class. However, the Property class can be used on\nits own, or with another set type (for example, MultiMatrixedPropertySef) without\nrewriting the Property class itself. This is true of the HashTable inside the PropertySet\nclass as well. Smaller classes with distinct and well-defined purposes and uses are much\nmore reusable than large classes with many methods to handle every possible use.\nThe Property class can also be used to publicly expose methods that can be called\nfrom outside code via function pointers. With a small amount of additional coding,\nthis can also be used as a save state for a save game feature as well. It could also be used\nfor object messaging via networks. With the addition of a Send(std::string xml) and\nReceive(std::stringxml), the PropertySet could easily encode and decode XML messages\nthat contain the property values, or property values that need to be changed. The\nProperty!PropertySet classes could also be rewritten as templates to support different\nproperty types.\nIsolating the property data using \"get\" and \"set\" methods will allow for format\nconversion to and from the internal stored format. This will free the using code from\nneeding to know anything about the data type of the property, making it more versa-\ntile at the cost of a small speed hit when the types differ.\n",
      "content_length": 2619,
      "extraction_method": "Direct"
    },
    {
      "page_number": 47,
      "chapter": null,
      "content": "50 \nSection 1 General Programming\nAdditional Reading\nFowler, Martin, Kent Beck, John Brant, William Opdyke, Don Roberts, Refactoring,\nAddison-Wesley, ISBN: 0201485672.\nGamma, Erich, Richard Helm, Ralph Johnson, John Vlissides, Grady Booch, Design\nPatterns, Addison-Wesley, ISBN: 0201633612.\nLakos, John, Large-Scale C++ Software Design, Addison-Wesley, ISBN: 0201633620.\nMcConnell, Steve C., Code Complete: A Practical Handbook of Software Construction,\nMicrosoft Press, ISBN: 1556154844 (anything by McConnell is good).\nMeyers, Scott, Effective C++: 50 Specific Ways to Improve Your Programs and Design\n(2ndEdition), Addison-Wesley, ISBN: 0201924889.\nMeyers, Scott, More Effective C++: 35 New Ways to Improve Your Programs and\nDesigns, Addison-Wesley, ISBN: 020163371X.\n",
      "content_length": 771,
      "extraction_method": "Direct"
    },
    {
      "page_number": 48,
      "chapter": null,
      "content": "1.8\nA Game Entity Factory\nFrangois Dominic Laramee\nfrancoislaramee@videotron.ca\nI\nn recent years, scripting languages have proven invaluable to the game development\ncommunity. By isolating the elaboration and refinement of game entity behavior\nfrom the core of the code base, they have liberated level designers from the code-\ncompile-execute cycle, speeding up game testing and tweaking by orders of magni-\ntude, and freed senior programmers' time for more intricate assignments.\nHowever, for the data-driven development paradigm to work well, the game's\nengine must provide flexible entity construction and assembly services, so that the\nscripting language can provide individual entities with different operational strategies,\nreaction behaviors, and other parameters. This is the purpose of this gem: to describe\na hierarchy of C++ classes and a set of techniques that support data-driven develop-\nment on the engine side of things.\nThis simple framework was designed with the following goals in mind:\n• A separation of logical behavior and audio-visual behavior. A single Door class\ncan support however many variations of the concept as required, without concern\nfor size, number of key frames in animation sequences, etc.\n• Rapid development. Once a basic library of behaviors has been defined (which\ntakes surprisingly little time), new game entity classes can be added to the frame-\nwork with a minimum of new code, often in 15 minutes or less.\n• Avoiding code duplication. By assembling bits and pieces of behavior into new\nentities at runtime, the framework avoids the \"code bloat\" associated with script-\ning languages that compile to C/C++, for example.\nSeveral of the techniques in this gem are described in terms of patterns, detailed\nin the so-called \"Gang of Four's\" book Design Patterns [GoF94].\nComponents\nThe gem is built around three major components: flyweight objects, behavioral\nclasses and an object factory method. We will examine each in turn, and then look at\nhow they work together to equip the engine with the services required by data-driven\ndevelopment. Finally, we will discuss advanced ideas to make the system even more\n51\n",
      "content_length": 2157,
      "extraction_method": "Direct"
    },
    {
      "page_number": 49,
      "chapter": null,
      "content": "52 \nSection 1 General Programming\nflexible (at the cost of some code complexity) if a full-fledged scripting language is\nrequired by the project.\nFlyweight, Behavior, and Exported Classes\nBefore we go any further, we must make a distinction between the three types of\n\"classes\" to which a game entity will belong in this framework: its flyweight, behav-\nioral, and exported classes.\n• The flyweight class is the look and feel of the entity. In the code, the relationship\nbetween an entity and its flyweight class is implemented through object composi-\ntion: the entity owns a pointer to a flyweight that it uses to represent itself audio-\nvisually.\n• The behavioral class defines how the object interacts with the rest of the game\nworld. Behavioral classes are implemented as a traditional inheritance hierarchy,\nwith class Entity serving as abstract superclass for all others.\n• The exported class is how the object represents itself to the world. More of a con-\nvenience than a requirement, the exported class is implemented as an enum con-\nstant and allows an entity to advertise itself as several different object classes\nduring its lifetime.\nLet us now look at each in turn.\nFlyweight Objects\n[GoF94] describes flyweights as objects deprived of their context so that they can be\nshared and used in a variety of situations simultaneously; in other words, as a template\nor model for other objects. For a game entity, the flyweight-friendly information con-\nsists of:\n• Media content: Sound effects, 3D models, textures, animation files, etc.\n• Control structure: Finite state machine definition, scripts, and the like.\nAs you can see, this is just about everything except information on the current\nstatus of the entity (position, health, FSM state). Therefore, in a gaming context, the\n\\&iv\\ fly weight is rather unfortunate, because the flyweight can consume megabytes of\nmemory, while the context information would be small enough to fit within a crip-\npled toaster's core memory.\nSAMMy, Where Are You?\nMuch of a game entity's finite state machine deals with animation loops, deciding\nwhen to play a sound byte, and so forth. For example, after the player character is\nkilled in an arcade game, it may enter the resurrecting state and be flagged as invulner-\nable while the \"resurrection\" animation plays out; otherwise, an overeager monster\n",
      "content_length": 2348,
      "extraction_method": "Direct"
    },
    {
      "page_number": 50,
      "chapter": null,
      "content": "1 .8 A Game Entity Factory \n53\nmight hover about and score another kill during every frame of animation until the\nplayer resumes control over it. I call the part of the flyweight object that deals with\nthis the State And Media Manager, or SAMMy for short:\nclass StateAndMediaManager\n{\n// The various animation sequences available for the family\n//of entities\nAnimSequenceDescriptionStruct * sequences;\nint numAnimSequences;\n// A table of animation sequences to fire up when the entity's FSM\n// changes states out of SAMMy 's control\nint * stateToAnimTransitions;\nint numStateToAnimTransitions;\npublic:\n// Construction and destruction\n// StateAndMediaManager is always constructed by its owner entity,\n// which is in charge of opening its description file. Therefore,\n// the only parameter the constructor needs is a reference to an\n// input stream from which to read a set of animation sequence\n// descriptions.\nStateAndMediaManager () : sequences( 0 ), numAnimSequences ( 0 ),\nnumStateToAnimTransitions ( 0 ), stateToAnimTransitions ( 0 ) {}\nStateAndMediaManager ( istream & is ) ;\nvirtual -StateAndMediaManager () ;\nvoid Cleanup() ;\n// Input-output functions\nvoid Load( istream & is ) ;\nvoid Save( ostream & os ) ;\n// Look at an entity's current situation and update it according\n// to the description of its animation sequences\nvoid FC UpdateEntityStatef EntityStateStruct * state );\n// If the entity's FSM has just forced a change of state, the media\n// manager must follow suit, interrupt its current animation\n// sequence and choose a new one suitable to the new FSM state\nvoid FC AlignWithNewFSMState( EntityStateStruct * state );\n};\nTypically, SAMMy is the product of an entity-crafting tool, and it is loaded into\n(-*-^_^ the engine from a file when needed. The sample on the companion CD-ROM is built\nON mat\nSAMMy can be made as powerful and versatile as desired. In theory, SAMMy\ncould take care of all control functions: launching scripts, changing strategies, and so\nforth. However, this would be very awkward and require enormous effort; we will\ninstead choose to delegate most of the high-level control structure to the behavioral\nclass hierarchy, which can take care of it with a minute amount of code. (As a side\n",
      "content_length": 2230,
      "extraction_method": "Direct"
    },
    {
      "page_number": 51,
      "chapter": null,
      "content": "54 \nSection 1 General Programming\neffect of this sharing of duties, a single behavioral class like SecurityGuard, Door or\nExplosionFX will be able to handle entities based on multiple related flyweights, mak-\ning the system more flexible.)\nBehavioral Class Hierarchy\nThese are the actual C++ classes to which our entities will belong. The hierarchy has\n(at least) two levels:\n• An abstract base class Entity that defines the interface and commonalities\n• Concrete subclasses that derive from Entity and implement actual objects\nHere is a look at Entity's interface:\nclass Entity\n{\n// Some application-specific data\n// Flyweight and Exported Class information\nint exportedClassID;\nStateAndMediaManager * sammy;\npublic:\n// Constructors\n// Accessors\nint GetExportedClass() { return exportedClassID; }\nStateAndMediaManager * GetFlyweight() { return sammy; }\nvoid SetExportedClass( int newval ) { exportedClassID = newval; }\nvoid SetFlyweight( StateAndMediaManager * ns ) { sammy = ns; }\n// Factory method\nstatic Entity * EntityFactory( int exportedClassRequested );\nvirtual Entity * CloneEntityO = 0;\nvirtual bool Updateself()\n{\n//Do generic stuff here; looping through animations, etc.\nreturn true;\n}\nvirtual bool Handlelnteractions( Entity * target ) = 0;\n};\nAs you can see, adding a new class to the hierarchy may require very little work:\nin addition to constructors, at most three, and possibly only two, of the base class\nmethods must be overridden—and one of them is a one-liner.\n• Clone () is a simple redirection call to the copy constructor.\n• UpdateSelf () runs the entity's internal mechanics. For some, this may be as sim-\nple as calling the corresponding method in SAMMy to update the current anima-\ntion frame; for others, like the player character, it can be far more elaborate.\n",
      "content_length": 1791,
      "extraction_method": "Direct"
    },
    {
      "page_number": 52,
      "chapter": null,
      "content": "1.8 A Game Entity Factory \n55\n• Handlelnteractions() is called when the entity is supposed to determine\nwhether it should change its internal state in accordance to the behaviors and\npositions of other objects. The default implementation is empty; in other words,\nthe object is inert window-dressing.\n'\\^_^J \nThe companion CD-ROM contains examples of Entity subclasses, including one\nm m co \nof a player character driver.\nUsing the Template Method Pattern for\nBehavior Assignment\nIf your game features several related behavioral classes whose differences are easy to\ncircumscribe, you may be able to benefit from a technique known as the Template\nMethod pattern [GoF94]. This consists of a base class method that defines an algo-\nrithm in terms of subclass methods it calls through polymorphism.\nFor example, all types of PlayerEntity objects will need to query an input device\nand move themselves as part of their UpdateSelf () method, but how they do it may\ndepend on the input device being used, the character type (a FleetingRogue walks\nfaster than a OneLeggedBuddha), and so forth. Therefore, the PlayerEntity class may\ndefine UpdateSelf () in terms of pure virtual methods implemented only in its sub-\nclasses.\nclass PlayerDevice : public Entity\n{\n// ...\nvoid UpdateYourself();\nvoid QuerylnputDeviceO = 0; // No implementation in PlayerDevice\n};\nclass JoystickPlayerDevice : public PlayerDevice\n{\n// ...\nvoid QuerylnputDeviceO;\n};\nvoid PlayerDevice::UpdateYourself()\n{\n//do stuff common to all types of player devices\nQuerylnputDeviceO;\n//do more stuff\n}\nvoid JoystickPlayerDevice::QueryInputDevice()\n{\n//Do the actual work\n}\nUsed properly, the Template Method pattern can help minimize the need for the\ndreaded cut-and-paste programming, one of the most powerful \"anti-patterns\" leading\nto disaster in software engineering [Brown98]!\n",
      "content_length": 1841,
      "extraction_method": "Direct"
    },
    {
      "page_number": 53,
      "chapter": null,
      "content": "56 \nSection 1 General Programming\nExported Classes\nThe exported class is a convenience trick that you can use to make your entities' inter-\nnal state information transparent to the script writer. For example, let's say that you\nare programming Pac-Man's Handlelnteractions( ) method. You might start by look-\ning for a collision with one of the ghosts; what happens if one is found then depends\non whether the ghost is afraid (it gets eaten), returning to base after being eaten\n(nothing happens at all), or hunting (Pac-Man dies).\nvoid PacMan: :HandleInteractions( Entity * target )\n{\nif ( target ->GetClass() == GHOST && target ->GetState() == AFRAID )\n{\nscore += 100;\ntarget ->SendKillSignal( ) ;\nHowever, what if you need to add states to the Ghost object? For example, you\nmay want the ghost's SAMMy to include a \"Getting Scared\" animation loop, which is\nactive for one second once Pac-Man has run over a power pill. SAMMy would handle\nthis cleanly if you added a GettingScared state. However, you would now need to add\na test for the GettingScared state to the event handler.\nvoid PacMan: :HandleInteractions( Entity * target )\n{\nif ( target ->GetClass() == GHOST &&\n( target->GetState() == AFRAID ||\ntarget ->GetState() == GETTINGSCARED ) )\nThis is awkward, and would likely result in any number of updates to the event\nhandlers as you add states (none of which introduce anything new from the outside\nworld's perspective) to SAMMy during production. Instead, let's introduce the con-\ncept of the exported class, a value that can be queried from an Entity object and\ndescribes how it advertises itself to the world. The value is maintained within Update -\nSelf () and can take any number of forms; for simplicity's sake, let's pick an integer\nconstant selected from an enum list.\nenum { SCAREDGHOST, ACTIVEGHOST, DEADGHOST };\nThere is no need to export any information on transient, animation-related states\nlike GettingScared. To Pac-Man, a ghost can be dead, active, or scared — period.\nWhether it has just become scared two frames ago, has been completely terrified for a\nwhile, or is slowly gathering its wits back around itself is irrelevant. By using an\nexported class instead of an actual internal FSM state, a Ghost object can advertise\n",
      "content_length": 2252,
      "extraction_method": "Direct"
    },
    {
      "page_number": 54,
      "chapter": null,
      "content": "1.8 A Game Entity Factory \n57\nitself as a dead ghost, scared ghost, or active ghost, effectively shape-shifting into three\ndifferent entity classes at will from the outside world's perspective, all for the cost of\nan integer. Pac-Man's interaction handler would now look like this:\nvoid PacMan: :HandleInteractions( Entity * target )\n{\nif ( target ->GetExportedClass() == SCAREDGHOST )\n{\nscore += 100;\ntarget->SendKillSignal() \n;\nThe result is cleaner and will require far less maintenance work, as the number of\npossible exported classes for an Entity is usually small and easy to determine early on,\nwhile SAMMy's FSM can grow organically as new looks and effects are added to the\nobject during development.\nThe Entity Factory\nNow that we have all of these tools, it is time to put them to good use in object creation.\nA level file will contain several entity declarations, each of which may identify the\nentity's behavioral class, flyweight class, exported class, starting position and velocity,\nand any number of class-specific parameters (for example, hit points for monsters, a\nstarting timer for a bomb, a capacity for the players inventory, etc.) To keep things\nsimpler for us and for the level designer, let's make the fairly safe assumption that,\nwhile a behavioral class may advertise itself as any number of exported classes, an\nexported class can only be attached to a single behavioral class. This way, we eliminate\nthe need to specify the behavioral class in the level file, and isolate the class hierarchy\nfrom the tools and level designers. A snippet from a level file could therefore look like:\n<ENTITY Blinky>\n<EXPORTEDCLASS ActiveGhOSt>\n<XYZ_POSITION \n...>\nPARAMETERS \n...>\n</ENTITY>\nNow, let's add a factory method to the Entity class.\nA factory is a function whose job consists of constructing instances of any num-\nber of classes of objects on demand; in our case, the factory will handle requests for all\n(concrete) members of the behavioral class hierarchy. Programmatically, our factory\nmethod is very simple:\n• It owns a registry that describes the flyweights that have already been loaded into\nthe game and a list of the exported classes that belong to each behavioral class.\n• It loads flyweights when needed. If a request for an instance belonging to a fly-\nweight class that hasn't been seen yet is received, the first order of business is to\ncreate and load a SAMMy object for this flyweight.\n",
      "content_length": 2425,
      "extraction_method": "Direct"
    },
    {
      "page_number": 55,
      "chapter": null,
      "content": "58 \nSection 1 General Programming\n• If the request is for an additional instance of an already-loaded flyweight class, the\nfactory will clone the existing object (which now serves as a Prototype; yes, another\nGang of Four pattern!) so that it and its new brother can share flyweights effec-\ntively.\nHere is a snippet from the method:\nEntity * Entity::EntityFactory( int whichType )\n{\nEntity * ptr;\nswitch( whichType )\n{\ncase SCAREDGHOST:\nptr = new Ghost( SCAREDGHOST );\nbreak;\ncase ACTIVEGHOST:\nptr = new Ghost( ACTIVEGHOST );\nbreak;\nreturn ptr;\nSimple, right? Calling the method with an exported class as parameter returns a\npointer to an Entity subclass of the appropriate behavioral family.\nEntity * newEntity = Entity::EntityFactory( ACTIVEGHOST );\nThe code located on the companion CD-ROM also implements a simple trick\nused to load levels from standard text files: an entity's constructor receives the level file\nuimca \n^ an jstream parameter, and it can read its own class-specific parameters directly from\nit. The factory method therefore does not need to know anything about the internals\nof the subclasses it is responsible for creating.\nSelecting Strategies at Runtime\nThe techniques described so far work fine when a game contains a small number of\nbehavioral classes, or when entity actions are easy enough to define without scripts.\nHowever, what if extensive tweaking and experimentation with scripts is required?\nWhat if you need a way to change an entity's strategy at runtime, without necessarily\ninfluencing its behavioral classmates? This is where the Strategy pattern comes into\nplay. (It's the last one, I promise. I think.)\nLet's assume that your script compiler produces C code. What you need is a way\nto connect the C function created by the compiler with your behavioral class (or indi-\nvidual entity). This is where function pointers come into play.\n",
      "content_length": 1877,
      "extraction_method": "Direct"
    },
    {
      "page_number": 56,
      "chapter": null,
      "content": "1.8 A Game Entity Factory\nUsing Function Pointers within C++ Classes\nThe simplest and best way to plug a method into a class at runtime is through a func-\ntion pointer. A quick refresher: A C/C++ function pointer is a variable containing a\nmemory address, just like any other pointer, except that the object being pointed to is\na typed function defined by a nameless signature (in other words, a return type and a\nparameter list). Here is an example of a declaration of a pointer to a function taking\ntwo Entity objects and returning a Boolean value:\nbool (*interactPtr) (Entity * source, Entity * target);\nAssuming that there is a function with the appropriate signature in the code, for\nexample:\nbool TypicalRabbitInteractions( Entity * source, Entity * target )\nthen the variable interactPtr can be assigned to it, and the function called by deref-\nerencing the pointer, so that the following snippets are equivalent:\nOk = TypicalRabbitInteractions( BasilTheBunny, BigBadWolf );\nand\ninteractPtr = TypicalRabbitlnteractions;\nOk = (*interactPtr) ( BasilTheBunny, BigBadWolf );\nUsing function pointers inside classes is a little trickier, but not by much. The key\nidea is to declare the function generated by the script compiler to be a friend of the\nclass, so that it can access its private data members, and to pass it the special pointer\nthis, which represents the current object, as its first parameter.\nclass SomeEntity : public Entity\n{\n// The function pointer\nvoid ( * friendptr )( Entity * me, Entity * target );\npublic:\n// Declare one or more strategy functions as friends,\nfriend void Strategy! ( Entity * me, Entity * target );\n// The actual operation\nvoid Handlelnteractions( Entity * target )\n{\n(*friendptr) ( this, target );\n",
      "content_length": 1739,
      "extraction_method": "Direct"
    },
    {
      "page_number": 57,
      "chapter": null,
      "content": "60 \nSection 1 General Programming\nBasically, this is equivalent to doing by hand what the C++ compiler does for you\nwhen calling class methods: the C++ viable secretly adds \"this\" as a first parameter to\nevery method. Because any modern compiler will inline the function calls, there\nshould be no performance differential between calling a compiled script with this\nscheme and calling a regular method.\nNote that picking and choosing strategies at runtime through function pointers is\nalso a good way to reduce the number of behavioral classes in the hierarchy. In\nextreme cases, a single Entity class containing nothing but function pointer derefer-\nences for strategy elements may even be able to replace the entire hierarchy. This,\nhowever, runs the risk of obfuscating the code to a point of total opacity—proceed\nwith caution.\nFinally, if an entity is allowed to switch back and forth between several alternative\nstrategies depending on runtime considerations, this scheme allows each change to be\nimplemented through a simple pointer assignment: clean, fast, no hassles.\nFinal Notes\nIn simple cases, the techniques described in this gem can even provide a satisfactory\nalternative to scripting altogether. Smaller projects that do not require the full power\nof a scripting language and/or cannot afford the costs associated with it may be able to\nget by with a set of hard-coded strategy snippets, a simple GUI-based SAMMy editor,\nand a linear level-description file format containing key-value tuples for the behaviors\nattached to each entity.\n<EntityName BasilTheBunny>\n<ExportedClass Rabbit>\n<StrategyVsEntity BigBadWolf Avoid>\n<HandleCollision BigBadWolf Die>\n• i •\nThe companion CD-ROM contains several component classes and examples of\nthe techniques described in this gem. You will, however, have to make significant\nON THE co \nmodifications to them (for example, add your own 3D models to SAMMy) to turn\nthem into something useful in your own projects.\nFinally, the text file formats used to load SAMMy and other objects in the code\nare assumed to be the output of a script compiler, level editor, or other associated\ntools. As such, they have a rather inflexible structure and are not particularly human\nfriendly. If they seem like gibberish to you, gentle readers, please take a moment to\ncommiserate with the poor author who had to write and edit them by hand. ;-)\nReferences\n[Brown98] Brown, W.H., Malveau, R.C., McCormick III, H.W., Mowbray, T.J.,\nAnti Patterns: Refactoring Software, Architectures and Projects in Crisis, Wiley Com-\nputer Publishing, 1998.\n",
      "content_length": 2577,
      "extraction_method": "Direct"
    },
    {
      "page_number": 58,
      "chapter": null,
      "content": "1.8 A Game Entity Factory \n61\n[GoF94] Gamma, E., Helm, R., Johnson, R., & Vlissides, J. (1994), Design Patterns:\nElements of Reusable Object—Oriented Software, Addison-Wesley, \n1994.\n[Rising98] Rising, L. ed., The Patterns Handbook: Techniques, Strategies and Applica-\ntions, Cambridge University Press, 1998.\n",
      "content_length": 310,
      "extraction_method": "Direct"
    },
    {
      "page_number": 59,
      "chapter": null,
      "content": "1.9\nAdding Deprecation Facilities\nto C++\nNoel Llopis, Meyer/Glass Interactive\nnllopis@mgigames.com\n*\nuring the lifetime of a piece of software, function interfaces are bound to change,\nbecome outdated, or be completely replaced by new ones. This is especially true\nfor libraries and engines that are reused across multiple projects or over several years.\nWhen a function that interfaces to the rest of the project changes, the game (or tools,\nor both!) may not compile any more. On a team working on a large project, the situa-\ntion is even worse because many people could be breaking interfaces much more often.\nPossible Solutions\nThere are different ways of dealing with this situation:\n• Don't do anything about it. Every time something changes, everybody has to\nupdate the code that calls the changed functions before work can proceed. This\nmight be fine for a one-person team, but it's normally unacceptable for larger teams.\n• Don't change any interface functions. This is not usually possible, especially in\nthe game industry where things change so quickly. Maybe the hardware changed,\nmaybe the publisher wants something new, or perhaps the initial interface was\njust flawed. Trying to stick to this approach usually causes more harm than good,\nand ends up resulting in functions or classes with names completely unrelated to\nwhat they really do, and completely overloaded semantics.\n• Create new interface versions. This approach sticks to the idea that an interface\nwill never change; instead, a new interface will be created addressing all the issues.\nBoth the original and the new interface will remain in the project. This is what\nDirectX does with each new version. This approach might be fine for complete\nchanges in interface, or for infrequent updates, but it won't work well for frequent\nor minor updates. In addition, this approach usually requires maintaining the full\nimplementation of the current interface and a number of the older interfaces,\nwhich can be a nightmare.\nIn modern game development, these solutions are clearly not ideal. We need\nsomething else to deal with this problem.\n62\n",
      "content_length": 2113,
      "extraction_method": "Direct"
    },
    {
      "page_number": 60,
      "chapter": null,
      "content": "1.9 Adding Deprecation Facilities to C++ \n63\nThe Ideal Solution\nWhat we really want is to be able to write a new interface function, but keep the old\ninterface function around for a while. Then the rest of the team can start using the\nnew function right away. They may change their old code to use the new function\nwhenever they can, and, after a while, when nobody is using it anymore, the old func-\ntion can be removed.\nThe problem with this is how to let everybody know which functions have\nchanged and which functions they are supposed to use. Even if we always tell them\nthis, how are they going to remember it if everything compiles and runs correctly?\nThis is where deprecating a function comes in. We write the new function, and then\nflag the old function as deprecated. Then, every time the old function is used, the\ncompiler will generate a message explaining that a deprecated function is being called\nand mentioning which function should be used in its place.\nUsing and Assigning Deprecated Functions\nJava has a built-in way to do exactly what we want. However, most commercial games\nthese days seem to be written mostly using C++, and unfortunately C++ doesn't con-\ntain any deprecation facilities. The rest of this gem describes a solution implemented\nin C++ to flag specific functions as deprecated.\nLet's start with an example of how to use it. Say we have a function that every-\nbody is using called FunctionAQ. Unfortunately, months later, we realize that the\ninterface of FunctionAQ has to change, so we write a new function called NeivFunc-\ntionAQ. By adding just one line, we can flag FunctionAQ as deprecated.\nint FunctionA ( void )\n{\nDEPRECATE ( \"FunctionA()\", \"NewFunctionA()\" )\n// Implementation\n}\nint NewFunctionA ( void )\n{\n// Implementation\n}\nThe line DEPRECATE(\"FunctionA()\", \"NewFunctionAQ\") indicates that Func-\ntionAQ is deprecated, and that it has been replaced with NewFunctionAQ.\nThe users of FunctionAQ don't have to do anything special at all. Whenever users\nuse FunctionA() they will get the following message in the debug window when they\nexit the program:\nWARNING. You are using the following deprecated functions:\n- Function FunctionA() called from 3 different places.\nInstead use NewFunctionA().\n",
      "content_length": 2238,
      "extraction_method": "Direct"
    },
    {
      "page_number": 61,
      "chapter": null,
      "content": "64 \nSection 1 General Programming\nImplementing Deprecation in C++\nEverything is implemented in one simple singleton class [Gamma95]: Deprecation-\nMgr. The full source code for the class along with an example program is included on\n(^rs*- >^; j \nthe companion CD-ROM. In its simplest form, all DeprecationMgr does is keep a list\nonma> \nof the deprecated functions found so far. Whenever the singleton is destroyed (which\nhappens automatically when the program exits), the destructor prints out a report in\nthe debug window, listing what deprecated functions were used in that session.\nclass DeprecationMgr\n{\npublic:\nstatic DeprecationMgr * Getlnstance ( void ) ;\n-DeprecationMgr ( void );\nbool AddDeprecatedFunction (const char * OldFunctionName,\nconst char * NewFunctionName,\nunsigned int CalledFrom ) ;\n// Rest of the declaration here\nUsually, we won't have to deal with this class directly because the DEPRECATE\nmacro will do all of the work for us.\n#ifdef _DEBUG\n#define DEPRECATE ( a, b) { \\\nvoid * fptr; \n\\\n_asm { mov fptr, ebp } \n\\\nDeprecationMgr: :GetInstance()->AddDeprecatedFunction(a, b, fptr);\n\\\n}\n#else\n#define DEPRECATE(a,b)\n#endif\nIgnoring the first few lines, all the DEPRECATE macro does is get an instance to\nthe DeprecationMgr and add the function that is being executed to the list. Because\nDeprecationMgr is a singleton that won't be instantiated until the GetlmtanceQ func-\ntion is called, if there are no deprecated functions, it will never be created and it will\nnever print any reports at the end of the program execution. Internally, Deprecation-\nMgr keeps a small structure for each deprecated function, indexed by the function\nname through an STL map collection. Only the first call to a deprecated function will\ninsert a new entry in the map.\nThe DeprecationMgr class has one more little perk: it will keep track of the num-\nber of different places from which each deprecated function was called. This is useful\nso we know at a glance how many places in the code we need to change when we\ndecide to stop using the deprecated function. Unfortunately, because this trick uses\nassembly directly, it is platform specific and only works on the x86 family of CPUs.\nThe first two lines of the DEPRECATE macro get the EBP register (from which it is\nusually possible to retrieve the return address), and pass it on to AddDeprecatedFunc-\n",
      "content_length": 2356,
      "extraction_method": "Direct"
    },
    {
      "page_number": 62,
      "chapter": null,
      "content": "1.9 Adding Deprecation Facilities to C++ \n65\ntionQ. Then, if a function is called multiple times from the same place (in a loop for\nexample), it will only be reported as being called from one place.\nThere is a potential problem with this approach for obtaining the return address.\nTypically, the address [EBP-4] contains the return address for the current function.\nHowever, under some circumstances the compiler might not set the register EBP to its\nexpected value. In particular, this happens under VC++ 6.0, when compiler optimiza-\ntions are turned on, for particularly simple functions. In this case, trying to read from\n[EBP-4] will either return an incorrect value or crash the program. There will be no\nproblems in release mode, which is when optimizations are normally turned on,\nbecause the macro does no work. However, sometimes optimizations are also used in\ndebug mode, so inside the function AddDeprecatedFunctionQ we only try to read the\nreturn address if the address contained in [EBP-4] is readable by the current process.\nThis is accomplished by either using exception handling or calling the Windows-\nspecific function IsBadReadPtrQ. This will produce an incorrect count of functions\nthat deprecated functions were called from when optimizations are turned on, but at\nleast it won't cause the program to crash, and all the other functionality of the depre-\ncation manager will still work correctly.\nWhat Could Be Improved?\nOne major problem remains: the deprecation warnings are generated at runtime, not\nat compile or link time. This is necessary because the deprecated functions may exist\nin a separate library, rather than in the code that is being compiled. The main draw-\nback of only reporting the deprecated functions at runtime is that it is possible for the\nprogram to still be using a deprecated function that gets called rarely enough that it\nnever gets noticed. The use of the deprecated function might not be detected until it\nis finally removed and the compiler reports an error.\nAcknowledgments\nI would like to thank David McKibbin for reviewing this gem, and for identifying the\nproblems caused by compiler optimizations and finding a workaround.\nReferences\n[Gamma95] Gamma, Eric, et al, Design Patterns, Addison-Wesley. 1995.\n[Rose] Rose, John, \"How and When to Deprecate APIs,\" available online at\njava.sun.com/products/jdk/1.1 /docs/guide/misc/deprecation/deprecation.html.\n",
      "content_length": 2411,
      "extraction_method": "Direct"
    },
    {
      "page_number": 63,
      "chapter": null,
      "content": "1.10\nA Drop-in Debug Memory\nManager\nPeter Da/ton, Evans & Sutherland\npdalton@xmission.com\nW\nith the increasing complexity of game programming, the minimum memory\nrequirements for games have skyrocketed. Today's games must effectively deal\nwith the vast amounts of resources required to support graphics, music, video, anima-\ntions, models, networking, and artificial intelligence. As the project grows, so does the\nlikelihood of memory leaks, memory bounds violations, and allocating more memory\nthan is required. This is where a memory manager comes into play. By creating a few\nsimple memory management routines, we will be able to track all dynamically allo-\ncated memory and guide the program toward optimal memory usage.\nOur goal is to ensure a reasonable memory footprint by reporting memory leaks,\ntracking the percentage of allocated memory that is actually used, and alerting die pro-\ngrammer to bounds violations. We will also ensure that die interface to die memory\nmanager is seamless, meaning that it does not require any explicit function calls or class\ndeclarations. We should be able to take diis code and effortlessly plug it into any other\nmodule by including die header file and have everything else fall into place. The disad-\nvantages of creating a memory manager include die overhead time required for die man-\nager to allocate memory, deallocate memory, and interrogate die memory for statistical\ninformation. Thus, this is not an option that we would like to have enabled for the final\nbuild of our game. In order to avoid these pitfalls, we are going to only enable the mem-\nory manager during debug builds, or if the symbol ACTIVATE_MEMORY_MANAGER\nis defined.\nGetting Started\nThe heart of the memory manager centers on overloading the standard new and delete\noperators, as well as using #define to create a few macros that allow us to plug in our\nown routines. By overloading the memory allocation and deallocation routines, we\nwill be able to replace the standard routines with our own memory-tracking module.\nThese routines will log the file and line number on which the allocation is being\nrequested, as well as statistical information.\n66\n",
      "content_length": 2169,
      "extraction_method": "Direct"
    },
    {
      "page_number": 64,
      "chapter": null,
      "content": "1.10 A Drop-in Debug Memory Manager \n67\nThe first step is to create the overloaded new and delete operators. As mentioned\nearlier, we would like to log the file and line number requesting the memory alloca-\ntion. This information will become priceless when trying to resolve memory leaks,\nbecause we will be able to track the allocation to its roots. Here is what the actual\noverloaded operators will look like:\ninline void*\noperator new(size_t size, const char *file, int line);\ninline void*\noperator new[](size_t size, const char *file, int\nline);\ninline void operator delete( void *address );\ninline void operator delete[]( void *address );\nIt's important to note that both the standard and array versions of the new and\ndelete operators need to be overloaded to ensure proper functionality. While these dec-\nlarations don't look too complex, the problem that now lies before us is getting all of\nthe routines that will use the memory manager to seamlessly pass the new operator the\nadditional parameters. This is where the #define directive comes into play.\n#define new new( FILE , \nLINE )\ntfdefine delete setOwner(_FILE_,_LINE_) .false ? setOwner(\"\",0)\n: delete\n#define \nmalloc(sz) \nAllocateMemory(_FILE_,_LINE_,sz,MM_MALLOC)\ntfdefine calloc(num,sz)\nAllocateMemory(_FILE_1_LINE_,sz*num,MM_CALLOC)\n#define realloc(ptr,sz) AllocateMemory( \nFILE , \nLINE , sz,\nMM_REALLOC, ptr )\ntfdefine free(sz) deAllocateMemory( \nFILE , \nLINE , sz,\nMM_FREE )\nThe #define new statement will replace all new calls with our variation of new that\ntakes as parameters not only the requested size of the allocation, but also the file and\nline number for tracking purposes. Microsoft's Visual C++ compiler provides a set of\npredefined macros, which include our required __FILE_ and \nLINE__ symbols\n[MSDN]. The #define delete macro is a little different from the #define new macro. It\nis not possible to pass additional parameters to the overloaded delete operator without\ncreating syntax problems. Instead, the setOwnerQ method records the file and line\nnumber for later use. Note that it is also important to create the macro as a condi-\ntional to avoid common problems associated with multiple-line macros [DaltonOl].\nFinally, to be complete, we have also replaced the mallocQ, callocQ, reallocQ, and the\nfreeO methods with our own memory allocation and deallocation routines.\nThe implementations for these functions are located on the accompanying CD.\nt \nI \nThe AllocateMemoryO and deAllocateMemoryO routines are solely responsible for all\non m CD \nmemory allocation and deallocation. They also log information pertaining to the\ndesired allocation, and initialize or interrogate the memory, based on the desired\n",
      "content_length": 2695,
      "extraction_method": "Direct"
    },
    {
      "page_number": 65,
      "chapter": null,
      "content": "68 \nSection 1 General Programming\naction. All this information will then be available to generate the desired statistics to\nanalyze the memory requirements for any given program.\nMemory Manager Logging\nNow that we have provided the necessary framework for replacing the standard mem-\nory allocation routines with our own, we are ready to begin logging. As stated in the\nbeginning of this gem, we will concentrate on memory leaks, bounds violations, and\nthe actual memory requirements. In order to log all of the required information, we\nmust first choose a data structure to hold the information relevant to memory alloca-\ntions. For efficiency and speed, we will use a chained hash table. Each hash table entry\nwill contain the following information:\nstruct MemoryNode\n{\nsize_t \nactualSize;\nsize_t \nreportedSize;\nvoid \n*actualAddress;\nvoid \n*reportedAddress;\nchar \nsourceFile[30];\nunsigned short sourceLine;\nunsigned short \npaddingSize;\nchar \noptions;\nlong \npredefinedBody;\nALLOC_TYPE \nallocationType;\nMemoryNode \n*next, *prev;\n};\nThis structure contains the size of memory allocated not only for the user, but\nalso for the padding applied to the beginning and ending of the allocated block. We\nalso record the type of allocation to protect against allocation/deallocation mis-\nmatches. For example, if the memory was allocated using the new[] operator and deal-\nlocated using the delete operator instead of the delete[] operator, a memory leak may\noccur due to object destructors not being called. Effort has also been taken to mini-\nmize the size of this structure while maintaining maximum flexibility. After all, we\ndon't want to create a memory manager that uses more memory than the actual appli-\ncation being monitored.\nAt this point, we should have all of the information necessary to determine if\nthere are any memory leaks in the program. By creating a MemoryNode within the\nAllocateMemoryO routine and inserting it into the hash table, we will create a history\nof all the allocated memory. Then, by removing the MemoryNode within the deAllo-\ncateMemoryO routine, we will ensure that the hash table only contains a current list-\ning of allocated memory. If upon exiting the program there are any entries left within\nthe hash table, a memory leak has occurred. At this point, the MemoryNode can be\ninterrogated to report the details of the memory leak to the user. As mentioned previ-\nously, within the deAllocateMemoryO routine we will also validate that the method\n",
      "content_length": 2477,
      "extraction_method": "Direct"
    },
    {
      "page_number": 66,
      "chapter": null,
      "content": "1.10 A Drop-in Debug Memory Manager \n69\nused to allocate the memory matches the deallocation method; if not, we will note the\npotential memory leak.\nNext, let's gather information pertaining to bounds violations. Bounds violations\noccur when applications exceed the memory allocated to them. The most common\nplace where this happens is within loops that access array information. For example, if\nwe allocated an array of size 10, and we accessed array location 11, we would be exceed-\ning the array bounds and overwriting or accessing information that does not belong to\nus. In order to protect against this problem, we are going to provide padding to the front\nand back of the memory allocated. Thus, if a routine requests 5 bytes, the AllocateMem-\noryO routine will actually allocate 5 + sizeofllong)*2*paddmgSize bytes. Note that we are\nusing longs for the padding because they are defined to be 32-bit integers. Next, we must\ninitialize the padding to a predefined value, such as OxDEADCODE. Then, upon deal-\nlocation, if we examine the padding and find any value except for the predefined value,\nwe know that a bounds violation has occurred. At this point, we would interrogate die\ncorresponding MemoryNode and report die bounds violation to the user.\nThe only information remaining to be gathered is the actual memory require-\nment for the program. We would like to know how much memory was allocated, how\nmuch of the allocated memory was actually used, and perhaps peak memory alloca-\ntion information. In order to collect this information we are going to need another\ncontainer. Note that only the relevant members of the class are shown here.\nclass MemoryManager\n{\npublic:\nunsigned int m_totalMemoryAllocations;\nunsigned int m_totalMemoryAllocated; \n//In bytes\nunsigned int m_totalMemoryUsed; \n/ / I n bytes\nunsigned int m_peakMemoryAllocation;\n}|\nWithin the AllocateMemoryO routine, we will be able to update all of the Memo-\nryManager information except for the m_totalMemory Used variable. In order to deter-\nmine how much of the allocated memory is actually used, we will need to perform a\ntrick similar to the method used in determining bounds violations. By initializing the\nmemory within the AllocateMemoryO routine to a predefined value and interrogating\nthe memory upon deallocation, we should be able to get an idea of how much mem-\nory was actually utilized. In order to achieve decent results, we are going to initialize\nthe memory on 32-bit boundaries, once again, using longs. We will also use a prede-\nfined value such as OxBAADCODE for initialization. For all remaining bytes that do\nnot fit within our 32-bit boundaries, we will initialize each byte to OxE or\nstatic_cast<char>(OxBAADCODE). While this method is potentially error prone\nbecause there is no predefined value to which we could initialize the memory and\nensure uniqueness, initializing the memory on 32-bit boundaries will generate far bet-\nter results than initializing on byte boundaries.\n",
      "content_length": 2980,
      "extraction_method": "Direct"
    },
    {
      "page_number": 67,
      "chapter": null,
      "content": "70 \nSection 1 General Programming\nReporting the Information\nNow that we have all of the statistical information, let's address the issue of how\nwe should report it to the user. The implementation that is included on the CD\nrecords all information to a log file. Once the user has enabled the memory manager\nand run the program, upon termination a log file is generated containing a listing of\nall the memory leaks, bounds violations, and the final statistical report.\nThe only question remaining is: how do we know when the program is terminat-\ning so that we can dump our log information? A simple solution would be to require\nthe programmer to explicitly call the dumpLogReport() routine upon termination.\nHowever, this goes against the requirement of creating a seamless interface. In order\nto determine when the program has terminated without the use of an explicit func-\ntion call, we are going to use a static class instance. The implementation is as follows:\nclass Initialize\n{ public: Initialize() { InitializeMemoryManager(); } };\nstatic Initialize InitMemoryManager;\nbool InitializeMemoryManager() {\nstatic bool hasBeenlnitialized = false;\nif (sjnanager) \nreturn true;\nelse if (hasBeenlnitialized) return false;\nelse {\ns_manager = (MemoryManager*)malloc(sizeof(MemoryManager));\ns_manager->intialize();\natexit( releaseMemoryManager );\nhasBeenlntialized = true;\nreturn true;\n}\n}\nvoid releaseMemoryManager() {\nNumAllocations = sjnanager->m_numAllocations;\ns_manager->release(); \n// Releases the hash table and calls\nfree( sjnanager ); \n// the dumpLogReport() method\nsjnanager = NULL;\n}\nThe problem before us is to ensure that the memory manager is the first object to\nbe created and the very last object to be deallocated. This can be difficult due to the\norder in which objects that are statically defined are handled. For example, if we cre-\nated a static object that allocated dynamic memory within its constructor, before the\nmemory manager object is allocated, the memory manager will not be available for\nmemory tracking. Likewise, if we use the ::atexit() method to call a function that is\nresponsible for releasing allocated memory, the memory manager object will be\nreleased before the ::atexit() method is called, thus resulting in bogus memory leaks.\nIn order to resolve these problems, the following enhancements need to be added.\nFirst, by creating the InitMemoryManager object within the header file of the memory\nmanager, it is guaranteed to be encountered before any static objects are declared.\n",
      "content_length": 2519,
      "extraction_method": "Direct"
    },
    {
      "page_number": 68,
      "chapter": null,
      "content": "1.10 A Drop-In Debug Memory Manager \n71\nThis holds true as long as we #include that memory manager header before any static\ndefinitions. Microsoft states that static objects are allocated in the order in which they\nare encountered, and are deallocated in the reverse order [MSDN]. Second, to ensure\nthat the memory manager is always available we are going to call the InitializeMemo-\nryManager() routine every time within the AllocateMemoryO and DeallocateMemoryQ\nroutines, guaranteeing that the memory manager is active. Finally, in order to ensure\nthat the memory manager is the last object to be deallocated, we will use the ::atexit()\nmethod. The ::atexit() method works by calling the specified functions in the reverse\norder in which they are passed to the method [MSDN1]. Thus, the only restriction\nthat must be placed on the memory manager is that it is the first method to call the\n::atexit() function. Static objects can still use the ::atexit() method; they just need to\nmake sure that the memory manager is present. If, for any reason, the InitializeMem-\noryManagerQ function returns false, then this last condition has not been met and as a\nresult, the error will be reported in the log file.\nGiven the previous restriction, there are a few things to be aware of when using\nMicrosoft's Visual C++. The ::atexit() method is used extensively by internal VC++\nprocedures in order to clean up on shutdown. For example, the following code will\ncause an ::atexit() to be called, although we would have to check the disassembly to\nsee it.\nvoid Foo() { static std::string s; }\nWhile this is not a problem if the memory manager is active before the declara-\ntion of s is encountered, it is worth noting. Despite this example being completely\nVC++ specific, other compilers might differ or contain additional methods that call\n::atexit() behind the scenes. The key to the solution is to ensure that the memory\nmanager is initialized first.\nThings to Keep in Mind\nBesides the additional memory and time required to perform memory tracking, there\nare a few other details to keep in mind. The first has to deal with syntax errors that\ncan be encountered when #induding other files. In certain situations, it is possible to\ngenerate syntax errors due to other files redefining the new and delete operators. This\nis especially noticeable when using STL implementations. For example, if we #include\n\"MemoryManager.h\"a.nd then #include <map>, we will generate all types of errors. To\nresolve this issue, we are going to be using two additional header files: new_on.h and\nnew_off.h. These headers will simply #define and #undefine the new!'delete macros that\nwere created earlier. The advantage of this method includes the flexibility that we\nachieve by not forcing the user to abide by a particular #include order, and avoids the\ncomplexity when dealing with precompiled headers.\ntfinclude \"new_off.h\"\n#include <map>\n",
      "content_length": 2913,
      "extraction_method": "Direct"
    },
    {
      "page_number": 69,
      "chapter": null,
      "content": "72 \nSection 1 General Programming\n^include <string>\n#include <A11 other headers overloading the new/delete operators>\n#include \"new_on.h\"\n^include \"MemoryManager.h\" \n// Contains the Memory Manager Module\ntfinclude \"Custom header files\"\nAnother issue we need to address is how to handle libraries that redefine the new\nand delete operators on their own. For example, MFC has its own system in place for\nhandling the new and delete operators [MSDN2]. Thus, we would like to have MFC\nclasses use their own memory manager, and have non-MFC shared game code use our\nmemory manager. We can achieve this by inserting the #indude \"new_off.h\" header\nfile right after the #//2&/'created by the ClassWizard.\n#ifdef _DEBUG\n^include \"new_off.h\" \n// Turn off our memory manager\ntfdefine \nnew \nDEBUG_NEW\ntfundef THIS_FILE\nstatic char THIS_FILE[] = _FILE__;\n#endif\nThis method will allow us to keep the advantages of MFC's memory manager,\nsuch as dumping CC%>rt-derived classes on memory leaks, and still provide the rest\nof the code with a memory manager.\nFinally, keep in mind the requirements for properly implementing'the setOwnerQ\nmethod used by the delete operator. It is necessary to realize that the implementation\nis more complicated than just recording the file and line number; we must create a\nstack implementation. This is a result of the way that we implemented the delete\nmacro. Take, for example, the following:\nFile 1: line 1: class B { B() {a = new int;} ~B() {delete a;} };\nFile 2: line 1: B *objectB = new B;\nFile 2: line 2: delete objects;\nThe order of function calls is as follows:\n1. new( objects, File2, 1\n2. new( a, \nFilel, 1\n3. setOwner( File2, 2 );\n4. setOwner( Filel, 1 );\n5. delete( a );\n6. delete( objects );\nAs should be evident from the preceding listing, by the time the delete operator is\ncalled to deallocate objectB, we will no longer have the file and line number informa-\ntion unless we use a stack implementation. While the solution is straightforward, the\nproblem is not immediately obvious.\n",
      "content_length": 2016,
      "extraction_method": "Direct"
    },
    {
      "page_number": 70,
      "chapter": null,
      "content": "1.10 A Drop-in Debug Memory Manager \n73\nFurther Enhancements\n, \nc \n, \nWithin the implementation provided on the CD accompanying this book, there are\non m CD \nseveral enhancements to the implementation discussed here. For example, there is the\noption for the user to set flags to perform more comprehensive memory tests.\nOptions also exist for setting breakpoints when memory is deallocated or reallocated\nso that the programs stack can be interrogated. These are but a few of the possibilities\nthat are available. Other enhancements could easily be included, such as allowing a\nprogram to check if any given address is valid. When it comes to memory control, the\noptions are unlimited.\nReferences\n[DaltonOl] Dalton, Peter, \"Inline Functions versus Macros,\" Game Programming\nGems II, Charles River Media. 2001.\n[McConnell93] McConnell, Steve, Code Complete, Microsoft Press. 1993.\n[MSDN1] Microsoft Developer Network Library, http://msdn.microsoft .com/\nIibrary/devprods/vs6/visualc/yclang/_pluslang_initializing_static_objects.htm\n[MSDN2] \nMicrosoft \nDeveloper \nNetwork \nLibrary, \nhttp://msdn.microsoft\n.com/library/devprods/vs6/visualc/vccore/core_memory_management_with_mf\nc.3a_.overview.htm\n[Myers98] Myers, Scott, Effective C++, Second Edition, Addison-Wesley Longmont,\nInc. 1998.\n",
      "content_length": 1285,
      "extraction_method": "Direct"
    },
    {
      "page_number": 71,
      "chapter": null,
      "content": "1.11\nA Built-in Game Profiling Module\nJeffEvertt, Lithtech, Inc.\njeff@evertt.com\nT\nhis gem describes the architecture and implementation of a profiling module for\nlow-overhead, real-time analysis that supports performance counter organization\nso that many consumers can work together in harmony. It is designed from a game\nengine perspective, with many of its requirements specifically pertaining to things\ntypically found in games. At the time of this writing, the described module is in use\nby a commercially available game engine.\nProfiling the performance of a game or engine is one of those things that everyone\nagrees is important, but just as often as not guesswork or quick hacks are substituted\nfor a real game system that can gather solid data. In the long run, the time it takes to\nimplement a clean profiling system is a wise investment. And, as with everything else,\nthe earlier we plan for it, the easier it will be.\nProfiling Basics\nThe basic profiling mechanism is simple: take a timestamp at the beginning of the\ncode of interest and again at the end. Subtract the first from the second, and voila,\nthat's how long the code took to run. We need a high-resolution counter - the Win-\ndows multimedia timer and its millisecond resolution will not cut it. If the platform\nis Windows on a PC, there are two high-resolution API calls we can use: QueryPerfor-\nmanceCounter and QueryPerformanceFrequency. However, because the overhead of\nthese functions is fairly high, we will roll our own, which only requires a few lines of\ninline assembly:\nvoid CWin32PerfCounterMgr::GetPerfCounter(\nLARGE_INTEGER SdCounter) {\nDWORD dwLow.dwHigh;\nasm {\nrdtsc\nmov dwLow, eax\nmov dwHigh, edx\n}\niCounter.QuadPart = ((unsigned \nint64)dwHigh « 32)\n| (unsigned \nint64)dwLow; }\n74\n",
      "content_length": 1770,
      "extraction_method": "Direct"
    },
    {
      "page_number": 72,
      "chapter": null,
      "content": "1.11 A Built-in Game Profiling Module\nTo convert this number into seconds, we need to know the counter frequency. In\nthis case it is equal to the CPU cycles per second. We can measure it once when the\ncounters are enabled — take a time sample, sleep for at least 500ms, and then take\nanother sample. Note that similar counters are available if the target platform is a\ngame console.\nCommercially Available Tools\nPerformance tuning is definitely a case where choosing the right tool for the job can\nmake all the difference. There are many time-tested commercial tools available for the\nPC that sample an application as it runs, then offline allow profile data to be viewed\nmodule-by-module, function-by-function, and just about any other imaginable way.\nIntel® VTune™ and Metrowerks® Analysis Tools both make use of the built-in\nCPU hardware counters to generate post-processed profiles of runtime sections of a\ngame. Tuning assembly code by instruction ordering or pairing prediction is defi-\nnitely a strength of VTune™.\nThe Intel® Graphics Performance Toolkit (GPT) provides some powerful scene\nanalysis tools. It hooks in and snoops traffic at the layer between your application and\nDirect3D/OpenGL. Knowing exactly what is being drawn can at times be very help-\nful. Changing the order or the way in which the game renders can sometimes signifi-\ncantly affect performance. However, the GPT is written to a specific version of\nDirectX, so its releases usually trail that of DirectX. Also, taking any significant scene\ndata will slow down the application, so relying on the performance characteristics of\ndata taken when using the GPT can be dangerous.\nStatistics-gathering drivers for graphics cards and hardware counters can be\ninvaluable. Nvidia releases special drivers and a real-time data viewing application\nthat hooks all of the function entry points of the drivers. If the graphics driver is tak-\ning a significant percentage of CPU time, this application will allow us to look inside\nand break it down further. Intel® provides counters in its drivers and hardware for its\ni740 chip, allowing optimization for stalls all the way down to the graphics chip level.\nSome of the game consoles also provide this ability. It can be very useful, as it is the\nonly way to break down performance at this low level. It does, however, require a fair\namount of knowledge about how the drivers and chips operate, and what the counters\nreally mean.\nWhy Roll Our Own?\nReason one: frame-based analysis. Games typically have a fairly high frame-to-frame\ncoherency, but in just a matter of seconds can drastically change. Imagine a 3D\nshooter—a player starts facing a wall, runs down a long corridor, then ends it all in a\nbloody firefight with five Al-driven enemies. The game engine is running through\nmany potentially different bottlenecks that can only really be identified with a frame-\nby-frame analysis. Looking at a breakdown of an accumulated sample over the entire\n",
      "content_length": 2967,
      "extraction_method": "Direct"
    },
    {
      "page_number": 73,
      "chapter": null,
      "content": "76 \nSection 1 General Programming\ninterval gives an inaccurate view of what is really going on. Frame-based analysis\nallows focusing on one problem at a time.\nReason two: it can be done anytime and anywhere. At the end of a PC game\ndevelopment cycle, someone will probably be faced with performance problems that\nonly manifest themselves on someone's brother's machine, on odd Tuesdays. There\nare typically a significant number of these types of problems. They can cost a lot of\ntime and can very easily slip the release date. Although this type of problem is unique\nto PC games, console games still have to deal with the \"shooting a missile in the cor-\nner of level three grinds the game to a slow crawl\" types of problems. Once the prob-\nlem is understood, figuring out the solution is usually the easy part. If we could walk\nover to that test machine and pop up a few counter groups, we would quickly nail\ndown the culprit.\nReason three: customizability. Modern game engines are complicated. The ability\nto ignore all the other modules in the engine except for the one being working on is\npowerful. In addition, the only person that can organize the data exactly how they\nwant it is the engineer actually doing the work.\nProfile Module Requirements\nRequirement one: allow users to quickly and accurately profile the application.\nRequirement two: be non-obtrusive (that is, have very low overhead). When the\ncost for taking samples and displaying the results becomes a significant portion of die\nframe time, it can actually change the application's behavior within the system. In gen-\neral, slowing down the CPU will tend to hide stalls caused by graphics cards. While\neven a very small percentage can in some rare cases drastically change game perfor-\nmance, as a general rule, when the profiler is enabled, it should take less than five per-\ncent of the total CPU cycles. When disabled, it should be much less dian one percent.\nRequirement three: allow multiple users to work independently on their respec-\ntive systems without having to worry about other engine modules.\nRequirement four: when it's not needed, it should be well out of the way.\nArchitecture and Implementation\nA performance counter manager (IPerfCounterMan) keeps track of all active and inac-\ntive counters. The counters are organized into groups of similar type (for example,\nmodel render, world render, AI, physics) that are enabled and disabled together. This\nsupports the notion of multiple groups working independently in an easy to under-\nstand grouping concept. Groups are useful for two reasons: for quickly determining if\na counter needs to be sampled, and for enabling and disabling groups of counters to\nbe displayed. We will make use of four-character codes (FourCC's) for the group ID\nand full text strings for counter names.\nThe entire system is organized into a module with an interface to the rest of the\nsystem. The basic component is a counter that is identified by a group ID (its\n",
      "content_length": 2973,
      "extraction_method": "Direct"
    },
    {
      "page_number": 74,
      "chapter": null,
      "content": "1.11 A Built-in Game Profiling Module \nJ77\nFourCC) and its string name. Each counter is given an integer ID on creation that\nuniquely identifies it. In typical usage, the game code creates counters on initializa-\ntion and puts start/stop counter calls around the code to be profiled.\nThe basic functional unit interface for the module is as follows:\nclass IPerfCounterMan {\npublic:\n// Add new counter (returns the ID, 0 is failure)\nint32 \nAddCounter(uint32 CounterGroup,\nconst char* szCounterName);\n// Forget your counter's ID? (Zero is failure)\nint32 \nGetCounterID(uint32 CounterGroup,\nconst chan* szCounterName);\n// Delete the counter\nbool \nDeleteCounter(uint32 Counter-ID);\n// Start and Stop a counter.\nvoid \nStartCounter(uint32 Counter-ID);\nvoid \nStopCounter(uint32 CounterlD);\n// Draw the Counters onto the Screen (to be called once\n// per frame near the end of the scene)\nvoid \nDrawCounters();\n};\nStopCounter calculates the difference between the StartCounter and StopCounter\ncalls and keeps a running total. On DrawCounters, all the running counters are\ncleared. A maximum value is also maintained and is set at the end of the frame in\nDrawCounters. Let's assume that our engine has a debug console that accepts text\ncommands. It is a very convenient way to enable and disable counter groups and to\nallow customization of the display.\nIt is very helpful to allow as much configuration in the counter display as possi-\nble. We will most likely not want to refresh the counter display every frame (updates\nevery 30 frames should be sufficient), but depending on what is being debugged, the\nability to customize the refresh time can be very handy. In addition, displaying both\nthe current percentage and the maximum percentage since last displayed is useful.\nA bar graph is a good way to display the result. It gives the consumer a quick feel\nfor the numbers and isn't hard to code. The ability to switch from percentage to actual\ntime (in milliseconds), display the time or percentage as text values, and auto-scale the\naxes is also very useful. Be careful about switching the axis scale very often, especially\nwithout some kind of warning, because it will likely just confuse people.\n",
      "content_length": 2190,
      "extraction_method": "Direct"
    },
    {
      "page_number": 75,
      "chapter": null,
      "content": "78 \nSection 1 General Programming\nImplementation Details\nThe interface to the performance counter manager should be flexible and easy to use.\nConsumers of the profile manager will often find it easier to simply call Add-\nCounter(...) with the full string, get the ID, and start it up all at once instead of sav-\ning the counter ID at some one-time initialization point. Providing this mechanism\ncan help out when doing some quick profiling. However, it's not as efficient, and call-\ning it many times in a frame will add up quickly. Also, supplying a class that can be\nplaced at the beginning of a function that calls StartCounter in the constructor and\nStopCounter in the destructor (when it goes out of focus) can be a handy way to\ninstrument the counters.\nWhen writing the profiling manager, it's best to provide some kind of #define\nmacro that completely removes the profiler. When it comes down to getting peak per-\nformance out of a game, profiling code is often one of the first things to go. We need\nto provide macros for AddCounter, StartCounter, and StopCounter that completely\ncompile out on an #ifdefdnan%t.\nAlso, it's best to use colors for visual cues. When the counters are being displayed,\nit's easier to read if we use different colors on each line.\nData Analysis\nBe sure to profile the release build, because it can have a very different set of bottle-\nnecks from the debug version. If the target platform is the PC, it is also a good idea to\npick two or three typical system configurations (low to high end) and profile each of\nthem. Bottlenecks can vary greatly across system configurations.\nThe game should be profiled in the areas that have performance problems as well\nas during typical game play. We must break the problem down, try to focus on one\nthing at a time, and focus on the areas that will give the biggest bang for the buck. Just\nbecause a function is called the most often or takes the most CPU time doesn't mean\nit is the only place we should focus our efforts. Often, the only thing we can compare\nour cycle times with is our expectations, and realistic expectations are usually gained\nonly through experience.\nThe profiler itself should also be profiled. If the act of profiling is intrusive, it\nchanges the behavior of your game. There should be a counter around the profiler's\ndraw routines.\nImplementation Notes\nThe described module has been implemented across multiple platforms. However,\nparts of it require platform-dependent functions. The actual timestamp query and the\ndraw functions will mostly likely need to be implemented in platform-dependent\ncode, so it's best to design a level of abstraction around those functions. The described\nimplementation uses a set of debug geometry and text (which has a platform-\n",
      "content_length": 2761,
      "extraction_method": "Direct"
    },
    {
      "page_number": 76,
      "chapter": null,
      "content": "1.11 A Built-in Game Profiling Module \n_ \n79\ndependent implementation) in the draw code so that it can be platform independent.\nYou may need to write a macro to create your four character code values, as many\ncompilers do not have support for them.\nThis same system can be used to take long running profiles of a game server to\ndetect problems. All the counters go through one source, so data can easily be filtered\ndown and saved to disk.\n",
      "content_length": 440,
      "extraction_method": "Direct"
    },
    {
      "page_number": 77,
      "chapter": null,
      "content": "1.12\nLinear Programming Model for\nWindows-based Games\nJavier F. Otaegui, Sabarasa Entertainment\njJavier@sabarasa.com.ar\nI\nn the past, when DOS ruled the earth, we programmed our games in a mostly lin-\near fashion. Then it was time to port our creations from DOS to DirectX, and this\nwas a big jump because of the Windows message pump. Its architecture is simply not\nadequate for game programming. In this gem, we will cover an effective way to encap-\nsulate the message pump, provide a linear programming model and, as a very desir-\nable side effect, allow correct \"alt-tab\" application switching. We will also cover\ncorrect recovery of lost surfaces.\nIf you have previously programmed linearly, you will easily understand the\nimportance of the method introduced in this gem. If your experience in game\nprogramming started with Windows, then you might find the message pump\na natural environment for game programming, but once you try linear pro-\ngramming, you will never go back to the message pump. It is far clearer and\neasier to follow and debug than a huge finite state machine is. You can save a\nlot of design, programming, debugging time, and thinking if you start work-\ning in a more linear way.\nUpdating the World\nModern games often have some sort of UpdateWorld function, located in the heart of\nthe application in the message pump, and invoked whenever it is not receiving any\nmessages. In a first attempt, coding an UpdateWorld function can be very simple: all\nthe application variables, surfaces, and interfaces have already been initialized, and\nnow we just have to update and render them. That should be an easy task, but only if\nwe plan that our game will have only one screen, no cut-scenes, no menus, and no\noptions.\nThe problem is that UpdateWorld must eventually finish and return to the mes-\nsage pump so we can process messages from the system. This prevents us from staying\nin a continuous for loop, for example. As old DOS games didn't have to return con-\nstantly to a message pump to process system requests, we could linearly program\n80\n",
      "content_length": 2063,
      "extraction_method": "Direct"
    },
    {
      "page_number": 78,
      "chapter": null,
      "content": "1.12 Linear Programming Model for Windows-based Games \n81\nthem, and our subroutines could have all the loops they needed, or delays, or cut-\nscenes. We simply had to insert the corresponding code into the subroutine. Now,\nhowever, with the message pump, which requires constant attention, we must return\non every loop. As stated previously, the problem of returning in every single loop is\nwhen attempting to maintain several game screens.\nThe way to work around this is to make every subroutine of the application a\nfinite state machine. Each subroutine will have to keep track of its internal state, and,\naccording to this state, it must invoke several other subroutines. Each of these other\nsubroutines is also a finite state machine, and when it finishes its execution (that is, it\nhas no more states to execute), it must return a value to inform the invoking subrou-\ntine that it can proceed with its own following state. Of course, each subroutine,\nwhen it finishes, must reset its state to 0, to allow the application to invoke it again.\nNow if we imagine 30 or 40 of these subroutines, each with a couple dozen states,\nwe will be facing a very big monster. Trying to debug or even follow this code will be\ndifficult. This finite-state programming model is far more complicated that the sim-\nple model achieved by old linear DOS programs.\nThe Solution: Multithreading\nHere is a simple multithreading model that frees the game programmer from the mes-\nsage pump and its potentially undesirable finite-state programming model.\nWindows supports multithreading, which means that our application can run\nseveral threads of execution simultaneously. The idea is very simple - put the message\npump in one thread and the game into another one. The message pump will remain\nin the initial thread, so we can take out the UpdateWorld function from the message\npump and return it to its simplest form (a linear programming scheme). Now we just\nneed to add to the dolnit function the code necessary to initiate the game thread.\nHANDLE hMainThread; \n// Main Thread handle\nstatic BOOL\ndolnit( ... )\n{\n... // Initialize DirectX and everything else\nDWORD tid;\nhMainThread=CreateThread( 0,\n0,\n&MainThread,\n0,\n0,\n&tid);\nreturn TRUE;\n}\nMainThread is defined by:\n",
      "content_length": 2249,
      "extraction_method": "Direct"
    },
    {
      "page_number": 79,
      "chapter": null,
      "content": "82 \nSection 1 General Programming\nDWORD WINAPI\nMainThread( LPVOID argl )\n{\nRunGame() ;\nPostMessage(hwnd, WM_CLOSE, 0, 0);\nreturn 0;\nMain Thread will invoke our RunGame function, and when it is finished, we just\npost a WM_CLOSE message to tell the message pump thread to finish execution.\nInitialization Code\nNow we must choose whether to include initialization code (including the DirectX\ninitialization code) in the dolnit function or directly into our RunGame function. It\nmay be more elegant to include it in the dolnit function, as long as we include all ter-\nminating code in the response to WM_CLOSE in our message handler. On the odier\nhand, we could include all the initialization code in the RunGame function, which\nmeans that we will handle all of the important parts of the code directly in our new\nlinear game-programming function.\nThe \"Alt-Tab\" Problem\nMaking a game truly multitasking under Windows is perhaps one of the most hazardous\nissues in game programming. A well-behaved application must be able to correcdy switch\nto other applications. This means allowing the user to alt-tab away from the application,\nwhich some games attempt to disallow, but we will try to make things work correcdy.\nWe could try using the standard SuspendThread and ResumeThread functions, but\nit's nearly impossible to get this to work properly. Instead, we will use a multithreaded\ncommunication tool: events. Events work like flags that can be used to synchronize\ndifferent threads. Our game thread will check if it must continue, or if it must wait for\nthe event to be set.\nOn startup, we must create a manual-reset event. This event should be reset\n(cleared) when the program is deactivated, and set when the program is reactivated.\nThen, in the main loop, we just have to wait for the event to be set.\nTo create the event, we need this global:\nHANDLE \ntask_wakeup_event;\nTo create and set the event, we need to include the following code during initial-\nization:\ntask_wakeup_event =\nCreateEvent(\nNULL, \n/ / N o security attributes\nTRUE, \n// Manual Reset ON\nFALSE, \n// Initial state = Non signaled\nNULL \n// No name\n",
      "content_length": 2115,
      "extraction_method": "Direct"
    },
    {
      "page_number": 80,
      "chapter": null,
      "content": "1.12 Linear Programming Model for Windows-based Games \n83\nMost games have a function in their main loop that is called every time the game\nneeds to render a new screen; this is typically where DirectX is asked to flip the pri-\nmary and back buffers. Because this function is called constantly, this is an ideal loca-\ntion to make the thread wait for the event in an idle state, using this code:\nWaitForSingleObject( task_wakeup_event, INFINITE );\nWe must suspend the thread every time the operating system switches the active\napplication. To do this, we must have our WindowProc function, and upon receiving\nan APP_ACTIVATE message, check whether the application is active. If the applica-\ntion has gone to an inactive state, we must suspend the game execution, which\nrequires this call:\nResetEvent( task_wakeup_event );\nand to resume it:\nSetEvent( task_wakeup_event );\nWith this simple implementation, when the user hits alt-tab, the game will tem-\nporarily stop execution, freeing all the processor's time to enable die user to do other\ntasks. If the world update must continue executing even if the application loses focus,\nthen we can just suspend the rendering pipeline, and continue updating the world.\nThis event model can be used with any number of threads that the application may\nrequire, by inserting new events for each new thread.\nHandling Lost Surfaces\nIf we use video memory surfaces, we will face the problem of losing the surface infor-\nmation when the application loses focus. The problem that we now face is that with\nour new linear programming model, a program can be caught in the middle of a sub-\nroutine with all its surfaces lost.\nThere are many possible solutions to this situation, one of which is the Com-\nmand pattern [GoF94]. Unfortunately, it obscures our code, and the main goal of this\ngem is to make things more clear. We can use a global stack of pairs of callback func-\ntions and If Voids, which will be called when the surfaces need to be reloaded. When\nwe need to restore the surfaces, we would invoke callback_function( IpVoid ). The\nIf Void parameter can include pointers to all the surfaces that we need, so we can keep\nthe surfaces local to our new linear subroutines.\nLet's suppose that we have a subroutine called Splash that displays a splash screen\nin our game, which is a surface loaded from a file. If the user hits alt-tab while the\nsplash screen is displayed and then comes back, we want our application to show the\nsplash screen again (let's assume that the surface was lost while the application was\ninactive). Using our proposed method, we must do something like this:\nint LoadSplashGraphi.es ( Ipvoid Params )\n",
      "content_length": 2663,
      "extraction_method": "Direct"
    },
    {
      "page_number": 81,
      "chapter": null,
      "content": "Section 1 General Programming\nSurface *pMySurface;\npMySurface = (Surface *) Params;\n// \n(load the graphic from the file)\nreturn 1;\nint Splash()\nSurface MySurface;\n// Push the function\ngReloadSurfacesStack.Push( &LoadSplashGraphics, &MySurface );\n/ / D o not forget to load graphics for the first time\nLoadSplashGraphics( &MySurface );\n// ... the subroutine functionality.\n// Pop the function\ngReloadSurfaceStack.Pop();\n}\nWe are using a stack so that each nested subroutine can add all the surface load-\ning and generation code that it might need. The implementation could easily be\nchanged to another collection class, but this is a classic stack-oriented problem due to\nits nested functionality, and so a stack works best here.\nReferences\n[GoF94] Gamma, E., Helm, R., Johnson, R., & Vlissides, J. (1994), Design Patterns:\nElements of Reusable Object-Oriented Software. Addison-Wesley. 1994.\nOtaegui, Javier E, \"Getting Rid of the Windows Message Pump,\" available online at\nwww.gamedev.net/reference/articles/articlel249.asp.\n",
      "content_length": 1026,
      "extraction_method": "Direct"
    },
    {
      "page_number": 82,
      "chapter": null,
      "content": "1.13\nStack Winding\nBryon Hapgood, Kodiak Interactive\nbryonh57@hotmail.com\nS\ntack winding is a powerful technique for assembly programmers that allows us to\nmodify an application's stack to do weird and wonderful things that can be\nextended into C/C++ with very little work. While the days of writing every line of\ngame code in hand-optimized machine language are over, sometimes it is worth the\neffort to dip into the realm of the arcane to get that extra bit of speed and elegance in\na game.\nIn this gem, we cover one particular type of stack winding that I call the \"tempo-\nrary return.\" This is the bare minimum form that we will build upon in subsequent\nexamples until we have a thunked temporary return. The code examples have been\ntested with Microsoft's MASM and Visual C++ compiler. I have personally used stack\nwinding in a number of projects for the GameBoy Color, PC, and Xbox.\nSimple TempRet\nStack winding, as its name implies, is a technique for modifying the stack to make it\ndo unexpected things. The term stack winding comes from the idea of inserting values\nin an existing stack frame to change its normal and expected behavior.\nListing 1.13.1 The TempRet routine\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n.586\n.model flat\n.data\nbuffer dd ?\nfile_handle\nfilesize dd\n.code\n_TempRetEg:\ncall\ncall\n)\ndd ?\n?\nfnO\nfn1\n; \nbefore\nj\npop\nedx\n85\n",
      "content_length": 1346,
      "extraction_method": "Direct"
    },
    {
      "page_number": 83,
      "chapter": null,
      "content": "Section 1 General Programming\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27 end\ncall edx\n1\n; \nafter\n»\ncall fn2\ncall fn3\nret\nA: call _TempRetEg\nret\nIn Listing 1.13.1, we see the first building block of stack winding: the TempRet rou-\ntine. Let's take a function (call it MyFunc) and say it calls _TempRetEg. The latter\nthen calls two functions: fnO and fnl. It then hits the lines:\npop \nedx\ncall edx\nNow we know that the way the CPU handles the assembly CALL instruction on\nline 24 is to push the address of the next line (25) and execute a JUMP to line 8. Line\n15 pops that address off the stack and stores it in a CPU register. Now we CALL that\naddress. This pushes line 20 onto the stack and executes a JUMP to line 25. The lat-\nter does nothing but execute a CPU return, which pops an address off the stack and\njumps there.\nThe rest of _TempRetEg then continues and when it returns, we do not return to\nMyFunc but to whatever function called MyFunc in the first place. It is an interesting\nlittle trick, but why would it be important? The power comes when we consider the\nfunctions FNO through FN3.\nLet's say that FNO opens a file, FN1 allocates a buffer and reads the file into\nmemory, FN2 frees that memory, and FN3 closes the file. Thus, MyFunc no longer\nhas to worry about the release steps. It doesn't have to close the file or worry about\nfreeing up the memory associated with the file. Functionally the process of opening a\nfile, reading it into memory, freeing that memory, and closing the file is all contained\nwithin a single block of code. MyFunc only has to call _TempRetEg, use the buffer,\nand return.\nTempRet Chains\nThe TempRet example comes of age when we chain functions together. Let's take a\nclassic problem: the initialization and destruction of DirectX 7. This usually takes a\nnumber of steps, but it's incredibly important to release the components of DX in\nreverse order, which can sometimes become horribly complicated.\nSo, let's expand our first example to illustrate this:\n",
      "content_length": 1991,
      "extraction_method": "Direct"
    },
    {
      "page_number": 84,
      "chapter": null,
      "content": "1.13 Stack Winding \n87\nListing 1.13.2 Winding multiple routines onto the stack\n0 .586\n1 .model flat\n2 .code\n3\n4 TempRet macro\n5 pop \nedx\n6 call edx\n7 TempRet endm\n8\n9 createWindow:\n10 \n; open the window\n11 \nTempRet\n12 \n; close it\n13 \nnet\n14 setCooperativeLevel:\n15 \n; set to exclusive\n16 \nTempRet\n17 \n; restore\n18 \nret\n19 changeDisplayMode:\n20 ; set 640x480 16 bpp\n21 \nTempRet\n22 \n; restore\n23 \nret\n24 createSurfaces:\n25 \n; create primary surface\n26 \n; get attached back\n27 \nTempRet\n28 \n; release primary\n29 \nret\n30 _SetupDX7:\n31 \ncall \ncreateWindow\n32 \ncall \nsetCooperativeLevel\n33 \ncall \nchangeDisplayMode\n34 \ncall \ncreateSurfaces\n35 \njmp \n_SomeUserRunFunc\n36\n37\n38 \nend\nBy performing numerous TempRets in succession we effectively have wound four\nroutines onto the stack so that when _SomeUserRunFunc returns, we will bounce\nback through createSurfaces, changeDisplayMode, setCooperativeLevel, and cre-\nateWindow at the line after the TempRet in reverse order.\nSo far, we've been using assembly language, but it's not necessary to write assem-\nbly modules to use this technique. We will cover two mechanisms in Microsoft's\nVisual C++ in the final section that aid us in stack winding: inline assembly and\nnaked functions.\n",
      "content_length": 1225,
      "extraction_method": "Direct"
    },
    {
      "page_number": 85,
      "chapter": null,
      "content": "88 \nSection 1 General Programming\nThunking\nThe ideas discussed so far need to be translated into C/C++. As stated previously, Visual\nC++ has a handy mechanism for doing diis, but what about other compilers? If naked\nfunctions are not supported, then we will have to dip into assembly language because\nthe presence of a stack frame really complicates things. It is not impossible, just difficult.\nThunking is a technique popularized by Microsoft for slipping a piece of code\nbetween two others. In effect, program flow is hurtling along through our code until\nthunk!—it crashes into that layer. Thunks are a great way of implementing a stack-\nwinding paradigm in C++. Let's look at an example that performs the same task of set-\nting up DirectX as we saw earlier:\nListing 1.13.3 Visual C++ example using TempRet\n#define TempRet\\\n_ asm{pop edx}\\\n__ asm{call edx}\ntfdefine NAKED void _ declspec(naked)\ntfdefine JUMP _ asm jmp\ntfdefine RET _ asm ret\nstatic NAKED createWindow(){\n// open the window\nTempRet\n// close it\nRET\nstatic NAKED setCooperativeLevel(){\n// set to exclusive\nTempRet\n// restore\nRET\nstatic NAKED changeDisplayMode(){\n// set 640x480 16 bpp\nTempRet\n// restore\nRET\nstatic NAKED createSurfaces(){\n// create primary surface\n// get attached back\nTempRet\n// restore\nRET\n",
      "content_length": 1277,
      "extraction_method": "Direct"
    },
    {
      "page_number": 86,
      "chapter": null,
      "content": "1.13 Stack Winding \n89\nNAKED SetUpDX7(){\ncreateWindow();\nsetCooperativeLevel();\nchangeDisplayMode();\ncreateSurfaces();\nJUMP run\nRecursion\nAs a final example of the power of stack winding, we will explore a solution for a clas-\nsic problem with recursive searching: how to roll back die recursion. In regular C we\nwould simply return repeatedly, walking back through the stack until we reach the\ntop. If our recursion is over 100 calls deep, however, this might take a little time. To\nfix this, here is a pair of utility functions called SafeEnter. Incidentally, the code works\njust as well from a C++ object as a global function.\nListing 1.13.4 The SafeEnter and SafeExit functions that aid\nrecursion\n.586\n.model flat\n.code\npublic SafeEnter,SafeExit\n; struct SAFE{\n; \nvoid*_reg[8];\n; \nvoid* ret;\nI }\n; assembly for SafeEnter routine\n_SafeEnter:\npop edx ; return address\nmov eax,[esp] ; safe\nmov [eax].safe. ret,edx\nmov [eax].safe. ebx.ebx\nn)ov [eax].safe. ebp,ebp\nmov [eax].safe. esp,esp\nmov [eax].safe. esi,esi\nmov [eax].safe. edi.edi\npop \neax ; safe pointer\npop \nedx ; call function\npush eax ; safe pointer\n",
      "content_length": 1109,
      "extraction_method": "Direct"
    },
    {
      "page_number": 87,
      "chapter": null,
      "content": "90 \nSection 1 General Programming\nmov \nebp,eax\ncall \nedx\nmov \neax,ebp\njmp \nsex\n_SafeExit:\npop edx \n; \nreturn\npop eax \n; \nregs context\nmov edi,[eax].safe. edi\nmov esi,[eax].safe. esi\nmov esp,[eax].safe. esp\nmov ebp,[eax].safe. ebp\nmov ebx,[eax].safe. ebx\nmov edx,[eax].safe. ret\nmov eax,[eax].safe. eax\njmp \nedx\nend\nSafeEnter works by saving off to a SAFE structure a copy of crucial CPU regis-\nters. It then calls our recursive function. As far as the function is concerned, no extra\nwork is necessary. Now the cool part comes when we find the piece of data we're look-\ning for. We simply call SafeExit() and pass it the register context we built earlier. We\nare instantly transported back to the parent function.\nNow, if the unthinkable happened and the search routine did not meet its search\ncriteria, then the function can simply return in the normal way, all the way up the chain.\nListing 1.13.5 Recursive example using SafeEnter and SafeExit\nstatic void search(SAFE&safe,void*v){\nif(<meets_requirement>)\nSafeExit(safe);\n// do stuff\nsearch(safe,v);\nreturn;\n}\nint main(){\nSAFE safe;\nSafeEnter(\nsafe,\nsearch,\n<some_pointer>)\n",
      "content_length": 1127,
      "extraction_method": "Direct"
    },
    {
      "page_number": 88,
      "chapter": null,
      "content": "1.14\nSelf-Modifying Code\nBryon Hapgood, Kodiak Interactive\nbryonh57@hotmail.com\nS\nelf-modifying code, also known as \"RAM-code,\" is a fascinating technique that\nactually allows a program to alter its own code as it executes. It has been used in\neverything from genetic algorithms to neural networks with amazing results. In games\nit can be used as a powerful optimization technique. Recently I used this technique on\na GameBoy Color title Test Drive Cycles to decompress artwork on the fly at 60 fps,\ndecode 14 palettes of color information (instead of the standard eight), and enable\nmultiple levels of parallax scrolling. In this gem, we will cover how to write self-\nmodifying applications.\nThe Principles of RAM-Code\nRAM-code is a simple idea, but one that can take an inordinate amount of time to get\njust right. It is written for the most part in hexadecimal and can be difficult to debug.\nLet's look at a very simple case. We want to load a pointer from a 16-bit variable\nstored somewhere in RAM.\ngetjil:\nId hl,ptr_var \nLoad HL register with the address ptr_var\nId a,(hli)\nId h,(hl)\nId l,a\nLoad A register with low byte\nand increment HL\nLoad L register with high byte of ptr_var\nSave low byte into L\nret \n; Return\nThis example can be improved by writing it as:\ngetjil:\ndb $2a \n; Id hi,...\nptr_var\ndw $0000 \n; ...ptr_var\nret\nThese two routines are logically no different from each other, but can you see the\ndifference? The second example is stating the variable that stores the address to be\nloaded in HL as an immediate value! In other words, instead of physically going out\nand loading an address, we just load HL. It's quicker to load an immediate value than\n91\n",
      "content_length": 1671,
      "extraction_method": "Direct"
    },
    {
      "page_number": 89,
      "chapter": null,
      "content": "92 \nSection 1 General Programming\nto access main memory, and because there are fewer bytes to decode, the code runs\nmuch faster. We can take that idea much further when it comes to preserving regis-\nters. Instead of pushing and popping everything, which can be expensive, we simply\nwrite the value ahead into the code. For example, instead of writing:\nget_hl: \n:\nId \nhl,ptr_var\nId \na,(hli)\nId \nl,(hl)\nId \nh,a\nId \na,(hi)\npush af ; Save A register\nj\n; do something with A\nj\npop af ; Restore A register\nret\nthis code can be optimized down to:\ngetjil:\ndb \n$2a \n; Id hi,...\nptr_var\ndw \nptr_var \n; ...ptr_var\nId \na,(hi)\nId \n(var1),a\ni\n; do something with A\ndb \n$2F \n; Id a,...\nvarl db \n$00 \n; ...saved register value\nret\nThis is not a huge saving, but it illustrates the point.\nA Fast Bit Blitter\nIn many games, it is often crucial to convert from one pixel format to another, such as\nfrom 16-bit (565) RGB to 24-bit RGB. Whether this is done in some offline tool or\nwithin the game itself can be satisfied with this one routine. We can define a structure\n(call it BITMAP) that contains information about an image. From this, our blitter\ncan then use RAM-code techniques to construct an execute-buffer—a piece of code\nthat has been allocated with malloc and filled with assembly instructions.\nThe blitter works by taking a routine that knows how to read 16-bit (565) RGB\npixels and convert them to 32-bit RGBA values, and a routine that knows how to\nwrite them in another format. We can paste these two functions together, once for\nimages with odd widths, or multiple times in succession to effectively unroll our loop.\nThe example shown next takes the former approach.\nSo, let's define our bitmap structure and associated enumerated types.\n",
      "content_length": 1735,
      "extraction_method": "Direct"
    },
    {
      "page_number": 90,
      "chapter": null,
      "content": "1.14 Self-Modifying Code\n93\nenum Format{\nRGB_3x8=0 ,\nRGB_565=4,\nRGB_555=8,\nRGB_4x8=12,\nRGB_1x8=16\nstruct BITMAP{\nvoid *pixels;\nu32 w, h, depth;\nTRIPLET *pal;\nFormat pxf;\nu32 stride;\nu32 size;\n- \nBITMAP();\nBITMAP ( int , int , int , Format , int n=1 ) ;\nvoid draw( int , int , BITMAP&, int , int , int , int ) ;\noperator bool(){\nreturn v!=NULL;\nNow, it's really important that we have the same structure defined on the assem-\nbly side of things.\nBITMAP\npixels\nw\nh\ndepth\npal\npxf\nstride\nsize\nstruct\ndd ?\ndd ?\ndd ?\ndd ?\ndd ?\ndd ?\ndd ?\ndd ?\nBITMAP ends\nPF_BGR_3x8 =\nPF_BGR_565 =\nPF_BGR_555 =\nPF_BGR_4x8 =\nPF BGR 1x8 =\nOOh\n04h\n08h\nOCh\n10h\nThe next step is to define our execute buffer.\nexecute_buffer db 128 dup(?)\nFor this code to work in C++, we must use a mangled C++ name for the member\nfunction BITMAP: :draw. After that comes some initialization code:\n?draw@BITMAP@<aQAEXHHAAU1 @HHHH@Z:\npush\nlea\nebp\nebp,[esp+8]\nget arguments address\n",
      "content_length": 934,
      "extraction_method": "Direct"
    },
    {
      "page_number": 91,
      "chapter": null,
      "content": "94 \nSection 1 General Programming\npush \nebx\npush \nedi\npush \nesi\nmov edi,ecx \n;dst bitmap\nmov esi,[ebp+8] \n;src bitmap\nmov eax,[esi].bitmap.pxf\nThe first thing we must decide is whether we need to do a conversion at all.\nTherefore, we test to see if the two pixel formats of the bitmap objects are the same. If\nso, we can further ask whether they are the same size. If that is the case, we can just do\na fast string copy from one to the other. If not, but they're the same width, then we\ncan still do the string copy. If the two have different widths, then we can do string\ncopies line by line.\nmov edx,[edi].bitmap.pxf\ncmp eax,edx\njne dislike\nlike copy\nmov ecx,[esi].bitmap._size\ncmp ecx,[edi].bitmap._size\nje k3\nmov \necx,[edi].image.stride\nmov edx,[esi].image.stride\ncmp edx,ecx\njne @f\n)\n; \nsame w different h\ni\nmov edx,[edi].image.h\nmov eax,[esi].image.h\ncmp eax,edx\njl k2\nmov eax,edx\nk2: mul ecx\nmov ecx,eax\nk3: mov esi,[esi].image.Ifb\nmov edi,[edi].image.Ifb\nshr ecx,2\nrep movsd\njmp ou\n,\n; \nfind smallest h -> ebx\nj\nmov eax,[edi].image.h\nmov ebx,[esi].image.h\ncmp ebx,eax\njl @f\nmov ebx,eax\n; \ncalc strides\n",
      "content_length": 1110,
      "extraction_method": "Direct"
    },
    {
      "page_number": 92,
      "chapter": null,
      "content": "1.14 Self-Modifying Code\n95\nadd \nebp,12\nmov \neax, [ebp].rectangle.w\nmul \n[esi].image.depth; edx corrupts\nmov \nedx,[esi].image.stride\nsub \necx,eax\nsub \nedx,eax\ni\n; \ncalc offsets with intentional reg swap\npush\npush\npush\ncall\npop\npop\npop\neax\necx\nedx\ncalc_esdi\nedx\neax\necx\nou:\nshr\nmov\nrep\nlea\nlea\nmov\ndec\njne\npop\npop\npop\npop\nret\nedx=dest pad\necx, 2\nebp,ecx\nmovsd\nedi,[edi+eax]\nesi,[esi+edx]\necx,ebp\nebx\n@b\nesi\nedi\nebx\nebp\n1ch\nIf the two bitmaps have completely different pixel formats, we have no choice but\nto convert every single pixel from one format to the other. The following code shows\nthis in action. There's another way to further improve this routine by unrolling the\nloop—this would be as simple as repeating the build step four or more times.\ndislike\n:lea\nadd\npush\npush\npush\npush\npush\nmov\nmov\neax,execute_buffer\nebp,12\nou\neax\nedi\nesi\nebp\nebx,edi\nedi,eax\ndestination image\nwrite \"mov ebx,h\"\nmov \nal,OBDh\nstosb\nmov \neax,[ebp].rectangle.h\n",
      "content_length": 944,
      "extraction_method": "Direct"
    },
    {
      "page_number": 93,
      "chapter": null,
      "content": "96\nSection 1 General Programming\nstosd\n»\n; \nwrite \"mov ecx.w\"\nmov \nal,OB9h\nstosb\nmov \neax,[ebp].rectangle.w\nstosd\n; \nget read\nmov\nmov\nmov\nmov\nlodsd\nmov\nadd\nrep\n;\nmov\nmov\nlodsd\nmov\nadd\nrep\nedx\nebp\neax\nesi\necx\nedx\n,22\n,esi;\n,[ebp]\nsource\n. image. pf\n, rtbl_conv[eax]\n, eax\n,ecx\nmovsb\nput\neax\nesi\necx\nedx\nwrite\n,[ebx] . image. pf\n,wtbl_conv[eax]\n, eax\n,ecx\nmovsb\n; \nwrite tail\nmov\npush\nsub\nneg\nshl\nor\nmov\nstosd\nmov\npush\nmov\nmul\nsub\nJZ\necx\nedx\ndl,\ndl\nedx\nedx\neax\neax\neax\necx\n,[esp]\n19\n,16\n,08D007549h\n, edx\n,[ecx]\n,[ebp]\n. rectangle. w\n.image. stride\n[ebp] .image. depth\necx\n@f\nmov\n,eax\nal,OB6h\nstosb\nmov\neax, ecx\nstosd\njmp\npq\n; \nmodify outer branch\ndec\nmov\nedi\neax ,[esp+4]\nstart of exec_tail\nargs\nsource\n",
      "content_length": 702,
      "extraction_method": "Direct"
    },
    {
      "page_number": 94,
      "chapter": null,
      "content": "1.14 Self-Modifying Code\npq:\n97\npr:\nsub\nmov\npop\nmul\nmov\nsub\njz\npop\nsub\ninc\nneg\nshl\nor\neax,6\n[esp+4] ,eax\neax\n[ebx] .image. depth\necx, [ebx] .image. stride\necx, eax\n@f\nmov \nax,OBF8Dh\nstosw\nmov eax, ecx\nstosd\npop \neax\njmp \npr\neax\neax, 6\nal\nal\neax, 16\neax,OC300754Dh\nstosd\npop \nebp\npop \nesi\npop \nedi\ndest\nAnother important step in this blitter is to correctly calculate the x and y offsets\ninto the source and destination images. This routine does exactly that.\ncalc esdi:\n; \nDestination\nj\nmov \neax,[ebp-12].point.x\nmul \n[edi].image.depth\nmov \necx,eax\nmov \neax,[ebp-12].point.y\nmul \n[edi].image.stride\nmov \nedi,[edi].image.Ifb\nadd \nedi,ecx\nadd \nedi,eax\nSource\nmov \neax,[ebp].rectangle.x\nmul \n[esi].image.depth\nmov \necx,eax\nmov \neax,[ebp].rectangle.y\nmul \n[esi].image.stride\nmov \nedx,[esi].image.pal\nmov \nesi,[esi].image.Ifb\nadd \nesi,ecx\nadd \nesi,eax\nret\nget dx\nmultiply by d\nstore result\nget dy\nmultiple by stride\nget target pixels\nadd x\nadd y\nget sx\nmultiply by d\nstore result\nget sy\nmultiple by stride\npalette info\nget target pixels\nadd x\nadd y\n",
      "content_length": 1044,
      "extraction_method": "Direct"
    },
    {
      "page_number": 95,
      "chapter": null,
      "content": "98\nSection 1 General Programming\nFor this whole RAM-code idea to work, we need some initialization that gets\nplaced at the top of the RAM-code buffer. It simply loads the ECX register with the\nnumber of scan lines to copy.\nexec head\ndd\ndb\nOB9h,OOOh,OOOh,OOOh,OOOh\n(size)\nmov ecx,0\nThe next few routines are the actual read and write routines (RC and WC). The\nfirst byte tells us how many bytes make up the code in each subroutine.\nRC_BGR_1x8 \ndd \n18\ndb \n033h,OCOh\ndb \nOACh\ndb \n08Bh,OD8h\ndb \n003h,OCOh\ndb \n003h,OC3h\ndb \n003h,OC2h\ndb \n08Bh,OOOh\ndb \n025h,OFFh,OFFh,OFFh,OOOh\nRC_BGR_3x8 \ndd \n7\ndb \nOADh\ndb \n025h,OFFh,OFFh,OFFh,OOOh\ndb \n04Eh\n(size)\nxor \neax,eax\nlodsb\nmov ebx.eax\nadd eax,eax\nadd eax,ebx\nadd eax,edx\nmov eax,[eax]\nand eax,-1\n(size)\nlodsd\nand eax,-1\ndec esi\nRC BGR 4x8\nRC BGR 565:\nRC BGR 555:\ndd\ndb\n1\nOADh\ndd \n1\nlodsw\ndd \n1\nlodsw\nI \n(size)\n; lodsd\n; (size)\n; (size)\nWC_BGR_3x8 \ndd \n6\ndb \nOAAh\ndb \nOC1h,OE8h,008h\ndb \n066h,OABh\nWC_BGR_555 \ndd \n28\ndb \n033h,ODBh\ndb \nOCOh,OE8h,003h\ndb \nOCOh,OECh,003h\ndb \n08Ah,ODCh\ndb \n066h,OC1h,OE3h,005h\ndb \nOOAh,OD8h\ndb OC1h,OE8h,013h\ndb 066h,OC1h,OEOh,OOAh\ndb \n066h,OOBh,OC3h\ndb \n066h,OABh\nWC_BGR_565 \ndd \n28\ndb \n033h,ODBh\n(size)\nstosb\nshr eax,8\nstosw\n(size)\nxor ebx,ebx\nshr al,3\nah, 3\nbl.ah\nbx,5\nbl.al\neax,l3h\nax,OAh\nax,bx\nshr\nmov\nshl\nor\nshr\nshl\nor\nstosw\n(size)\nxor ebx,ebx\n",
      "content_length": 1318,
      "extraction_method": "Direct"
    },
    {
      "page_number": 96,
      "chapter": null,
      "content": "1.14 Self-Modifying Code\n99\nWC_BGR_4x8\nFinally, we have a\nBITMAP: :pf.\nrtbl_conv\nwtbl_conv\ndb\ndb\ndb\ndb\ndb\ndb\ndb\ndb\ndb\ndd\ndb\ntable\ndd\ndd\ndd\ndd\ndd\ndd\ndd\ndd\ndd\ndd\nOCOh,OE8h,003h\nOCOh,OECh,002h\n08Ah , ODCh\n066h,OC1h,OE3h,005h\nOOAh,OD8h\nOC1h,OE8h,013h\n066h,OC1h,OEOh,OOBh\n066h,OOBh,OC3h\n066h , OABh\n1\nOABh\nthat tells us which routine\nRC BGR 3x8\nRC BGR 565\nRC_BGR_555\nRC BGR 4x8\nRC_BGR_1 x8\nWC BGR 3x8\nWC BGR 565\nWC BGR 555\nWC BGR 4x8\n?\n; shr al,3\n; shr ah, 2\n; mov bl.ah\n; shl bx,5\n; or bl,al\n; \nshr \neax,13h\n; \nshl \nax.OBh\n; \nor \nax.bx\n; \nstosw\n! \n(size)\n; \nstosd\nto use for every pixel format in\n",
      "content_length": 593,
      "extraction_method": "Direct"
    },
    {
      "page_number": 97,
      "chapter": null,
      "content": "1.15\nFile Management Using\nResource Files\nBruno Sousa, Fireworks Interactive\ngems2@fireworks-interactive.com\nA\ns games increase in size (I think the grand prize goes to Phantasmagoria with\nseven CDs), there is a need for organization of the game data. Having 10 files in\nthe same directory as the executable is acceptable, but having 10,000 is not. More-\nover, there is the directory structure, sometimes going five or more levels deep, which\nis a pain to work with. Because our games will hardly resemble Windows Explorer, we\nneed to find a clean, fast way to store and organize our data. This is where resource\nfiles come into play. Resource files give us the power to encapsulate files and directo-\nries into a single file, with a useful organization. They can also take advantage of\ncompression, encryption, and any other features we might need.\nWhat Is a Resource File?\nWe already use resource files all the time in our daily work—examples of these are\nWinZip, the Windows installer, and backup programs. A resource file is nothing\nmore than a representation of data, usually from multiple files, but stored in just one\nfile (see Listing 1.15.1). Using directories, we can make a resource file work just like a\nhard drive's file system does.\nListing 1.15.1 Resource file structure.\nSignature \n= \"SEALRFGNU\" + '\\0'\nVersion \n= 1.0\nNumber of Files \n= 58\nOffset of First File = 19\n[File 1]\n[File 2]\n[File 3]\n[File .]\n[File .]\n[File .]\n[File Number Of Files - 1]\n[File Number Of Files]\n100\n",
      "content_length": 1490,
      "extraction_method": "Direct"
    },
    {
      "page_number": 98,
      "chapter": null,
      "content": "1.15 File Management Using Resource Files \n101\nEach lump (we will start calling files \"lumps\" from now on) in the resource file\nhas its own structure, followed by all of the data (see Listing 1.15.2).\nListing 1.15.2 File lump structure.\nFile Size = 14,340\nFilename = \"/bmp/Bob.bmp\" + '\\0'\nFlags = COMPRESSED\nFlagslnfo = OxF34A400B\n[Byte 1]\n[Byte 2]\n[Byte 3]\n[Byte .]\n[Byte .]\n[Byte .]\n[Byte File Size - 1]\n[Byte File Size]\nBefore we do anything else, we'll need to name our resource system. We can then use\nthe name to give each component a special naming scheme, one that will differentiate\nit from the other parts of the game. Let's call this system the \"Seal Resource File Sys-\ntem,\" abbreviated to SRFS, and use \"si\" for class prefixes.\nFirst, we need a resource file header. By looking at Listing 1.15.1, it's easy to see\nthat we are keeping our system simple. However, that doesn't mean it isn't powerful, it\nmeans that it was designed to accommodate the most-needed features and still retain\na fairly understandable syntax and structure.\nOur resource file header gives us all the relevant information about the system.\nMultiple file types are used in games, and for each type, there is usually a file header\nthat contains something unique to differentiate it from other file types. SRFS is no\ndifferent, so the first data in its header is the file signature. This is usually a 5- to 10-\ncharacter string, and is required so that we can identify the file as a valid Seal resource\nfile. The version information is pretty straightforward—it is used to keep track of the\nfile's version, which is required for a very simple reason: if we decide to upgrade our\nsystem by adding new features or sorting the lumps differently, we need a way to ver-\nify if the file being used supports these new features, and if so, use the latest code.\nOtherwise, we should go back to the older code—backward compatibility across ver-\nsions is an important design issue and should not be forgotten. The next field in the\nheader is for special flags. For our first version of the file system, we won't use this, so\nit must always be NULL (0). Possible uses for this flag are described in the For the\nFuture section. Following this is the number of lumps contained in the resource file,\nand the offset to the first lump. This offset is required to get back to the beginning of\nthe resource file if we happen to get lost, and can also be used to support future ver-\nsions of this system. Extra information could be added after this header for later ver-\nsions, and the offset will point to the first lump.\n",
      "content_length": 2586,
      "extraction_method": "Direct"
    },
    {
      "page_number": 99,
      "chapter": null,
      "content": "102 \nSection 1 \nGeneral Programming\nWe now move to our lump header, which holds the information we need to start\nretrieving our data. We start with the lump size in bytes, followed by name and direc-\ntory, stored as a fixed-length, NULL-terminated string. Following this is the flags\nmember, which specifies the type of algorithm(s) used on the lump, such as encryp-\ntion or compression. After that is information about the algorithm, which can con-\ntain a checksum for encryption or dictionary information for compression (the exact\ndetails depend on the algorithms). Finally, after all of this comes the lump informa-\ntion stored in a binary form.\nOur system has only two modules: a resource file module and a lump module. To\nbe able to use a lump, we need to load it from the resource file and possibly decrypt or\ndecompress it into a block of memory, which can be accessed normally. Some systems\nprefer to encapsulate all functionality into the resource file module, and even allow\ndirect access to lump data from within this module. This approach certainly has\nadvantages, but the biggest disadvantage is probably that we need to have the whole\nresource in memory at once, unless we use only raw data or complicated algorithms to\ndynamically uncompress or decrypt our lump data to memory. This is a difficult\nprocess and beyond the scope of this gem.\nWe need functions to open the resource file, read the header, open individual\nlumps, read information from lumps, and get data from lumps. These are covered in\nthe Implementation section.\nImplementation\nThe sample code included in the CD is written in C++, but for the text, we will use\npseudocode so it will be easy to implement in any language.\nThe sICLump Module\nOur lump module is similar to file streams in C++ or other language implementations\nof files in that we can write to it. Unfortunately, updating the resource file with a\nlump is very troublesome due to the nature of C++ streams. We can't add data to the\nmiddle of the stream—we can only replace it—and we can't modify the parent\nresource file.\nDWORD \ndwLumpSize;\nSTRING \nszLumpName;\nDWORD \ndwLumpPosition;\nBYTE [dwLumpSize] abData;\nThe variable dwLumpSize is a double word (32 bits) that specifies the size of the\nlump, szLumpName is a string describing die lump's name, dwLumpPosition keeps the\nlump's pointer position, and abData is an array of bytes with the lump information.\nHere are the sICLump module functions:\nDWORD \nGetLumpSize (void);\nSTRING GetLumpName (void);\n",
      "content_length": 2495,
      "extraction_method": "Direct"
    },
    {
      "page_number": 100,
      "chapter": null,
      "content": "1.15 File Management Using Resource Files \n103\nDWORD \nRead (BYTE [dwReadSize] abBuffer, DWORD dwReadSize);\nDWORD \nWrite (BYTE [dwReadSize] abBuffer, DWORD dwWriteSize);\nDWORD \nSeek (DWORD dwSeekPosition, \nDWORD dwSeekType);\nBOOLEAN IsValid (void);\nGetLumpSizeO retrieves the lump's size, and GetLumpName() retrieves the lump's\nname. Read() reads dwReadSize bytes into sbBuffer, and Write () does the exact\nopposite, writing dwWriteSize bytes to sbBuffer. Seek() moves the lump's pointer by\na given number from a seek position, and I sValid () verifies if the lump is valid.\nThe sICResourceFile Module\nThis module has all the functionality needed to load any lump inside the resource.\nThe module members are nearly the same as those in the resource file header.\nDWORD \ndwVersion;\nDWORD \ndwFlags;\nDWORD \ndwNumberOfLumps;\nDWORD \ndwOffset;\nSTRING szCurrentDirectory;\nFILE \nfFile;\nThe use of these members has already been described, so here is a brief definition\nof each. dwVersion is a double word that specifies the file version, dwFlags is a double\nword containing any special flags for the lump, dwNumberOfLumps is the number of\nlumps in the resource, dwOffiet gives us the position in bytes where the first lump is\nlocated, szCurrentDirectory is the directory we are in, and fFile is the actual C++\nstream.\nNow for the real meat of our system, the sICResourceFile functions—those that\nwe use to access each lump individually.\nvoid \nOpenLump (STRING szLumpName, slCLump inOutLump);\nvoid \nIsLumpValid (STRING szLumpName);\nvoid \nSetCurrentDirectory (STRING szDirectory);\nSTRING GetCurrentDirectory (void);\nEach of these functions is very simple. IsLumpValid () checks to see if a file with a\ngiven szLumpName exists in the resource. SetCurrentDirectory () sets the resource file\ndirectory to szDirectory. This directory name is prepended to each lump's name\nwhen accessing individual lumps within the resource file. GetCurrentDirectory()\nreturns the current directory.\nNow for our Open function. This function opens a lump within the resource file,\nand the logic behind the algorithm is described in pseudocode.\nCheck flags of Lump\nif \nCompressed\nOpenLumpCompressed \n(szLumpName, \ninOutLump)\nif \nEncrypted\n",
      "content_length": 2204,
      "extraction_method": "Direct"
    },
    {
      "page_number": 101,
      "chapter": null,
      "content": "104 \nSection 1 \nGeneral Programming\nOpenLumpEncrypted (szLumpName, inOutLump)\nif Compressed and Encrypted\nOpenLumpCompressedEncrypted (szLumpName, inOutLump)\nelse\nOpenLumpRaw (szLumpName, inOutLump)\nend if\nDepending on the lump type, the appropriate function to open the lump is\ncalled, thus maintaining a nice design and simple code. The source of each function is\nincluded in the CD.\nLast Words about the Implementation\nSome support functions that are used to open the file or to keep track of information\nthat can't be called directly are not represented in the preceding text. It is advisable to\n^ c^ 5? \ncheck the source code on the CD, which is well commented and easy to follow The\nON me ca \nalgorithms for compression and encryption are simple RLE compression and bit-wise\nencryption, the actual implementations of which are beyond the scope of this gem\nand must be researched separately. Information about useful public domain algo-\nrithms is at [WotsitOO], [WheelerOO], and [Gillies98].\nConclusion\nThis system can be easily upgraded or adapted to any project. Some possibilities\ninclude supporting date and time validation, copy protection algorithms, checksums,\na data pool, and better compression and encryption algorithms. There is no limit.\nReferences\n[Hargrove98] Hargrove, Chris, \"Code on the Cob 6,\" available online at\nwww.loonygames.com/content/1.11/cote/, November 2-6, 1998.\n[TownerOO] Towner, Jesse, \"Resource Files Explained,\" available online at\nwww.gamedev.net/reference/programming/features/resfiles/, January 11, 2000.\n[WheelerOO] Wheeler, David J, et al, \"TEA, The Tiny Encryption Algorithm,\" avail-\nable online at www.cl.cam.ac.uk/ftp/users/djw3/tea.ps.\n[WotsitOO] Wotsit.org, \"The Programmer's File Format Collection: Archive Files,\"\navailable online atwww.wotsit.org, 1996—2000.\n[Gillies98] Gillies, David A. G., \"The Tiny Encryption Algorithm,\" available online\nat http://vader.brad.ac.uk/tea/tea.shtml, 1995-1998.\n",
      "content_length": 1947,
      "extraction_method": "Direct"
    },
    {
      "page_number": 102,
      "chapter": null,
      "content": "1.16\nGame Input Recording and\nPlayback\nBruce Dawson, Humongous Entertainment\nbruced@humongous.com\nT\nhe eighteenth-century mathematician and physicist Marquis Laplace postulated\nthat if there was an intelligence with knowledge of the position, direction, and\nvelocity of every particle of the universe, this intelligence would be able to predict by\nmeans of a single formula every detail of the total future as well as of the total past\n[ReeseSO]. This is determinism.\nChaos theory, Heisenberg's uncertainty principle, and genuine randomness in\nquantum physics have combined to prove determinism wrong. However, in the sim-\nplified universe of a game, Laplace's determinism actually works. .\nIf you carefully record everything that can affect the direction of your game uni-\nverse, you can replay your record and recreate what happened.\nWhat Exactly Is Input Recording Useful For?\nGame input recording is useful for more things than many people realize: reproduc-\ning rare bugs, replaying interesting games, measuring optimizations, or creating game\nmovies.\nReproducing Bugs\nComputer programs are deterministic and completely predictable, yet we frequently\nhear about people encountering bugs that are difficult to reproduce, and therefore dif-\nficult to fix. If computers are deterministic, how can bugs be difficult to reproduce?\nOccasionally, the culprit is the hardware or OS. The timing of thread switching\nand the hard drive is not completely consistent, so race conditions in your code can\nlead to rare crashes. However, the rare crashes are most frequently caused by a partic-\nular combination of user input that happens to be very rare. In that case, the bug is at\nleast theoretically reproducible, if only we can reproduce the exact input sequence\nagain.\nVideotaping of testing helps track some of these bugs, but it doesn't help at all if\nthe timing is critical. Why don't we put that computer predictability to work, by hav-\ning the computer program record all input and play it back on demand?\n105\n",
      "content_length": 2010,
      "extraction_method": "Direct"
    },
    {
      "page_number": 103,
      "chapter": null,
      "content": "Section 1 General Programming\nThe crucial step here is that if we are to use input recording to track bugs, we have\nto make sure that the input is recorded even when the game crashes—especially when\nthe game crashes! On Win32, this is typically quite easy. By setting up a structured\nexception handler [Dawson99], we can arrange for our input buffer to be saved when-\never the game crashes.\nIf we add an option to our game engine to \"fast-forward\" through game input\n(only rendering a fraction of the frames), we can get to the crash more quickly. If we\nalso add an option to render frames at the exact same points in the game update loop,\nwe can easily reproduce what are likely to be the relevant portions of the crash\nscenario.\nReproducing bugs is the one time when you will want to record and playback all\nof the user input, including the interactions with menu screens. Menu code is not\nimmune to tricky bugs.\nReplaying Interesting Games\nThe most common use of game input recording is for players to record interesting\ngames. These recordings are used to demonstrate how to play the game, to make tuto-\nrials, to test the performance of new computer hardware, or to share games.\nThe most important thing about recording games for users to play back later is\nthat the recording must always be enabled. It is unrealistic to expect users to decide at\nthe beginning of the game whether they want to record the game for posterity; they\nshould be asked at the end whether they want to permanently store the recorded\ngame.\nMeasuring Optimizations\nThe most important thing to do when optimizing is to measure the actual perfor-\nmance, both before and after. Failing to do this leads to a surprisingly frequent ten-\ndency to check in \"optimizations\" that actually slow the code.\nMeasuring the performance of a game is tricky because it varies so much. Polygon\ncount, texture set, overdraw, search path complexity, and the number of objects in the\nscene all affect the frame rate. Timing any single frame is meaningless, and a quick\nrun-through is hopelessly unscientific.\nGame input playback is a great solution. If you run the same playback multiple\ntimes, recording detailed information about game performance, you can chart your\nprogress after each change to see how you're doing and where you still need work.\nRecording the average and worst-case frame rate and the consistency of the frame rate\nbecomes easier and much more meaningful.\nTesting optimizations with game input playback doesn't always work because\nyour changes might affect the behavior—your wonderful new frame rate might just\nmean the player has walked into a closet. Therefore, when using game input playback\nfor optimization testing, it is crucial that you record critical game state and check for\nchanges on playback.\n",
      "content_length": 2787,
      "extraction_method": "Direct"
    },
    {
      "page_number": 104,
      "chapter": null,
      "content": "1.16 Game Input Recording and Playback \n107\nCreating Game Movies\nTo create a demo reel, you can hook a VCR up to a video capable graphics card and\nplay the game; however, the results will not be pretty. The VCR, the video encoder,\nand the variable frame rate of the game will lead to a blurry, jerky mess.\nWith game input recording, it's trivial to record an interesting game, and then\nplay it back. With some trivial modifications to the engine you will be able to tell the\ngame engine when you are at an interesting part of the playback, at which point you\ncan switch from real-time playback to movie record playback. In this mode, the\nengine can render precisely 60 frames for each second of game play, and record each\none to disk. The frame rate may drop to an abysmal two frames per second, but it\ndoesn't matter because the canned inputs will play back perfectly.\nImplementing Multiplayer\nA number of games—X-Wing vs. TIE Fighter, and Age of Empires—have used input\nrecording and playback for their networking model [Lincroft99]. Instead of transmit-\nting player status information, they just transmit player input. This works particularly\nwell for strategy games with thousands of units.\nWhat Does ItJTake?\nGame input recording is simple in theory, and can be simple in practice as well. How-\never, there are a few subtleties that can cause problems if you're not careful.\nMaking Your Game Predictable\nFor game input recording and playback to work, your game must be predictable. In\nother words, your game must not be affected by anything unpredictable or unknow-\nable. For example, if your game can be affected by the exact timing of task switching,\nthen your game is unpredictable.\nMany games use variably interleaved update and render loops. Input is recorded\nat a set frequency. A frame is rendered and then the game update loop runs as many\ntimes as necessary to process the accumulated set of inputs.\nThis model implies that the number of times that the game update loop is run for\neach frame rendered is unpredictable; however, this needn't make the game itself\nunpredictable. If you are tracking down a bug in the Tenderer, then you may need to\nknow the exact details of how the render loop and update loop were interleaved, but\nthe rest of the time it should be irrelevant. It is worthwhile to record how many\nupdates happened for each frame, but this information can be ignored on playback\nunless you are tracking a Tenderer bug.\nHowever, if the render function does anything to change the state of the game,\nthen the variably interleaved update loop and render function do make the game\nunpredictable, and input recording will not work. One example of this is a render\nfunction that uses the same random number generator as the update loop. Another\n",
      "content_length": 2767,
      "extraction_method": "Direct"
    },
    {
      "page_number": 105,
      "chapter": null,
      "content": "Section 1 General Programming\nexample can be found in Total Annihilation. In this game, the \"fog of war\" was only\nupdated when the scene was rendered. This was a reasonable optimization because it\nreduced the frequency of this expensive operation. While it ensured that the user only\never saw accurate fog, it made the game's behavior unpredictable. The unit AI used\nthe same fog of war as the Tenderer; the timing of the render function calls would sub-\ntly affect the course of the game.\nAnother example of something that can make a game unpredictable is uninitial-\nized local variables or functions that don't always return results. Either way, your\ngame's behavior will depend on whatever happened to be on the stack. These are bugs\nin your code, so you already have a good reason to track them down.\nOne tricky problem that can lead to unpredictability is sound playback. This can\ncause problems because the sound hardware handles them asynchronously. Tiny vari-\nances in the sound hardware can make a sound effect occasionally end a bit later. Even\nif the variation is tiny, if it happens to fall on the cusp between two frames, then it can\naffect your game's behavior if it is waiting for the sound to end.\nFor many games, this is not a problem because there is no synchronization of the\ngame to the end of these sounds. If you do want this synchronization, then there is a\nfairly effective solution: approximation. When you start your sound effect, calculate\nhow long the sample will play—number of samples divided by frequency. Then,\ninstead of waiting for the sound to end, wait until the specified amount of time has\nelapsed. The results will be virtually identical and they will be perfectly consistent.\nInitial State\nYou also need to make sure that your game starts in a known state, whether starting a\nnew game or loading a saved one. That usually happens automatically. However, each\ntime you recompile or change your data you are slightly changing the initial state.\nLuckily, many changes to code and data don't affect the way the game will unfold. For\ninstance, if you change the size of a texture, then the frame rate may change, but the\nbehavior should not—as long as the game is predictable. If changing the size of that\ntexture causes all other memory blocks to be allocated at different locations, then this\nshould also have no effect—as long as your code doesn't have any memory overwrite\nbugs.\nAn example of a code or data change that could affect how your game behaves\nwould be changing the initial position of a creature or wall, or slightly adjusting the\nprobability of a certain event. Small changes might never make a difference, but they\ndestroy the guarantee of predictability.\nFloating-point calculations are one area where your results may unexpectedly\nvary. When you compile an optimized build, the compiler may generate code that\ngives slightly different results from the unoptimized build—and occasionally, these\ndifferences will matter. You can use the \"Improve Float Consistency\" optimizer set-\nting in Visual C++ to minimize these problems, but floating-point variations are an\nunavoidable problem that you just have to watch for.\n",
      "content_length": 3170,
      "extraction_method": "Direct"
    },
    {
      "page_number": 106,
      "chapter": null,
      "content": "1.16 Game Input Recording and Playback \n109\nRandom Numbers\nRandom numbers can be used in a deterministic game, but there are a few caveats.\nThe reason random numbers can be used is that rand() isn't really random. rand()\nis implemented using a simple algorithm—typically a linear congruential method—\nthat passes many of the tests for random numbers while being completely repro-\nducible. This is called a pseudo-random number generator. As long as you initialize\nrand() with a consistent seed, you will get consistent results. If having the randomness\nin your game different each time is important, then choose a seed for srandQ based on\nthe time, but record the seed so that you can reuse it if you need to reproduce the\ngame.\nOne problem with rand() is that it produces a single stream of random numbers.\nIf your rendering code and your game update code are both using rand()—and if the\nnumber of frames rendered per game update varies—then the state of the random\nnumber generator will quickly become indeterminate. Therefore, it is important that\nyour game update loop and your Tenderer get their random numbers from different\nlocations.\nAnother problem with rand() is that its behavior isn't portable. That is, the behav-\nior is not guaranteed to be identical on all platforms, and it is unlikely that it will be.\nThe third problem with rand() comes if you save a game and continue playing,\nand then want to reload the saved game and replay the future inputs. To make this\nwork predictably, you have to put the random number generator back to the state it\nwas in when you saved the game. The trouble is, there's no way to do this. The C and\nC++ standards say nothing about the relationship between the numbers coming out\nof rand() and the number you need to send to srand() to put it back to that state.\nVisual C++, for instance, maintains a 32-bit random number internally, but only\nreturns 15 of those bits through rand(), making it impossible to reseed.\nThese three problems lead to an inescapable conclusion: don't use rand(). Instead,\ncreate random number objects that are portable and restartable. You can have one for\nyour render loop, and one for your game update loop.\nWhen implementing your random number objects, please don't invent your own\nrandom number algorithm. Random number generators are very subtle and you are\nunlikely to invent a good one on your own. Look at your C runtime source code, the\nsample code on the CD, Web resources [Coddington], or read Knuth [KnuthSl].\nInputs\nOnce you have restored your game's initial state, you need to make sure that you can\nrecord and play back all of the input that will affect your game. If your game update\nloop is calling OS functions directly to get user input—such as calling the Win32\nfunction GetKeyState(VK_SHIFT) to find out when the Shift key is down—then it\nwill be very hard to do this. Instead, all input needs to go through an input system.\nThis system can record the state of all of the input devices at the beginning of each\nframe, and hand out this information as requested by the game update loop. The\n",
      "content_length": 3085,
      "extraction_method": "Direct"
    },
    {
      "page_number": 107,
      "chapter": null,
      "content": "110 \nSection 1 \nGeneral Programming\ninput system can easily record this information to disk, or read it back from disk,\nwithout the rest of the game knowing. The input system can read data from Direct-\nInput, a saved game, the network, or a WindowProc, without the update loop know-\ning the difference. As a nice bonus, isolating the game input in one place makes your\ngame code cleaner and more portable.\nProgrammers have a habit of breaking all rules that are not explicitly enforced, so\nyou need to prevent them from calling OS input functions directly. You can use the\nfollowing technique to prevent programmers from accidentally using \"off-limits\"\nfunctions.\n#define GetKeyState Please do not use this function\ntfdefine GetAsyncKeyState Please do not use this function either\nAnother important input to a multiplayer game is the network. If you want to be\nable to replay your game, dien you need to record the incoming network data\ntogether with the user's input stream. This will allow you to replay the game, even\nwithout a network connection. The network data stream is the one type of data that\ncan actually get quite large—a game running on a 56K modem could easily receive\nmany megabytes of network data per hour. While this large data stream does make\nthe recording more unwieldy, it is not big enough to be really problematic. The ben-\nefits of recording this stream are enormous, and the costs are quite small.\nThe final \"input\" that a game might use is time. You may want certain events to\nhappen at a specific time, and it is important that these times are measured in game\ntime, not in real time. Whenever your game needs to know the time—except for pro-\nfiling purposes—it should ask the game engine for the current game time. As with the\nother input functions, it is a good idea to use the preprocessor to make sure that\nnobody accidentally writes code that calls timeGetTimeO or other OS time functions.\nIt is a good idea to record inputs throughout the game. That lets you use input\nplayback to track down bugs anywhere in the game, even in the pre-game menus.\nHowever, for many purposes you will want to store the record of the input during the\ngame separately, so that you can play it back separately.\nTesting Your Input Recording\nGame input recording should work on any well-written game. Even if your game is a\nmultiplayer game, if you record every piece of input that you receive on your\nmachine, then you should be able to reproduce the same game.\nHowever, if your game playbacks are failing to give consistent results, it can be\ndifficult to determine why. A useful option in tracking down these problems is record-\ning part of the game state along with die input—perhaps the health and location of all\nof the game entities. Then, during playback, you can check for changes and detect\ndifferences before they become visible.\n",
      "content_length": 2853,
      "extraction_method": "Direct"
    },
    {
      "page_number": 108,
      "chapter": null,
      "content": "1.16 Game Input Recording and Playback \n111\nConclusion\nGame input recording and playback is a valuable part of a game engine with many\nbenefits. If it is planned from the beginning, then it is easy to add, and leads to a\nbetter-engineered and more flexible game engine. Here are some rules to follow:\n• Route all game input, including keyboard, mouse, joystick, network, and time,\nthrough a single input system, to ensure consistency and to allow recording and\nsaving of all input. This input should always be recorded. It should be stored per-\nmanently in case the game crashes or the user requests it at the end of the game.\n• Watch for floating-point optimizations or bugs in your code that can occasionally\nlead to behavior that is different or unpredictable in optimized builds.\n• The randQ function should be avoided; use random number objects instead.\n• Never change the game's state in rendering functions.\n• Store some of your game state along with the input so you can automatically\ndetect inconsistencies. This can help detect race conditions, unintended code\nchanges, or bugs.\nThe sample code on the CD includes an imput system and a random number\nclass.\nReferences\n[ReeseSO] Reese, W.L., Dictionary of Philosophy and Religion. Humanities Press, Inc.\n1980. p. 127.\n[KnuthSl] Knuth, Donald, The Art of Computer Programming, Second Edition, Vol-\nume 2, Seminumerical Algorithms.\n[Coddington] Coddington, Paul, \"Random Number Generators,\" available online at\nwww.npac.syr.edu/users/paulc/lectures/montecarlo/node98.html.\n[Dawson99] Dawson, Bruce, \"Structured Exception Handling,\" Game Developer\nmagazine (Jan 1999): pp. 52-54.\n[Lincroft99] Lincroft, Peter, \"The Internet Sucks: What I Learned Coding X-Wing\nvs. TIE Fighter,\" 1999 Game Developers Conference Proceedings, Miller Free-\nman 621-630.\n",
      "content_length": 1805,
      "extraction_method": "Direct"
    },
    {
      "page_number": 109,
      "chapter": null,
      "content": "1.17\nA Flexible Text Parsing System\nJames Boer, Lithtech, Inc.\njimb@lithtech.com\nN\nearly every modern game requires some sort of text parser. This gem, along with\nthe sample code on the CD, demonstrates a powerful but easy-to-use text pars-\ning system designed to handle any type of file format.\nText files have a number of advantages when representing data:\noNiHfco \n. They aj-e easy to reacj and efat using any standard text editor. Binary data usually\nrequires a custom-built tool that must be created, debugged, and maintained.\n• They are flexible—the same parser can be used for simple variable assignment or\na more complex script.\n• They can share constants between code and data (more on this later).\nUnfortunately, text data has a few drawbacks as well:\n• Unlike most binary formats, text must first be tokenized and interpreted, slowing\nthe loading process.\n• Stored text is not space efficient; it wastes disk space and slows file loading.\nBecause many game parameters only need to be tweaked during development, it\nmay be practical to use a text-based format during development, and then switch to a\nmore optimized binary format for use in the shipping product. This provides the best\nof both worlds: the ease of use of text files, and the loading speed of binary data. We'll\ndiscuss a method for compiling text files into a binary format later in the gem.\nThe Parsing System\nHere's what our parser will support:\n• Native support for basic data types: keywords, operators, variables, strings, inte-\ngers, floats, boots, and GUIDs\n• Unlimited user-definable keyword and operator recognition\n• Support for both C (block) and C++ (single-line) style comments\n• Compiled binary read and write ability\n• Debugging support, able to point back to a source file and line number in case of\nerror\n",
      "content_length": 1798,
      "extraction_method": "Direct"
    },
    {
      "page_number": 110,
      "chapter": null,
      "content": "1.17 A Flexible Text Parsing System \n113\n• #include file preprocessing support\n• #define support for macro substitution\nMost of the preceding items are self-explanatory, but #indude files and #define\nsupport may seem a bit out of place when discussing a text parser. We'll discuss how\nthese features can greatly simplify scripts, as well as provide an additional mechanism\nto prevent scripts and code from getting out of sync.\nMacros, Headers, and Preprocessing Magic\nPreprocessing data files in the same manner as C or C++ code can have some wonder-\nful benefits. The concept is perhaps best explained by a simple example. Let's assume\nthat we wish to create a number of unique objects using a script file, which will pro-\nvide the necessary data to properly initialize each object and create unique handles for\nuse in code. Here's what such a script might look like:\nCreateFoo(l) \n{ Data = 10 }\nCreateFoo(2) \n{ Data = 20 }\nCreateFoo(3) \n{ Data = 30 }\nCreateBar(4) \n{ Foo = 1 }\nAssuming that the CreateFooQ keyword triggers the creation of a Foo object in\ncode, we now have three Foo objects in memory, each with unique member data, cre-\nated by a script. Also, assuming that we're referencing these objects with handles, we\ncan now access these objects in code with the values of 1, 2, and 3 as unique handles.\nNote that in our example, the script can also use these numeric handles. The Bar class\nrequires a valid Foo object as a data member, and so we use a reference to the first Foo\nobject created when creating our first Bar object.\nIt could get easy to lose track of the various handle values after creating several\nhundred of them. Any time an object is added in the script, the programmer must\nchange the same values in code. There are no safeguards to prevent the programmer\nfrom accidentally referencing the wrong script object. This problem has already been\nsolved in C and C++ through the use of header files in which variables and other com-\nmon elements can be designed for many source files to share. If we think of the text\nscript as simply another source file, the advantages of a C-like preprocessor quickly\nbecome apparent. Let's look again at our example using a header file instead of magic\nnumbers.\n- Header File -\n// ObjHandles.h\n// Define all our object handles\ntfdefine \nSmallFoo \n1\ntfdefine MediumFoo 2\n#define LargeFoo 3\n#define SmallBar \n4\n#define FooTypeX \n10\n",
      "content_length": 2391,
      "extraction_method": "Direct"
    },
    {
      "page_number": 111,
      "chapter": null,
      "content": "114 \nSection 1 \nGeneral Programming\n#define FooTypeY \n20\ntfdefine FooTypeZ \n30\n- Script File -\n//\n// Directs the parser to scan the header file\n^include \"ObjHandles.h\"\nCreateFoo(SmallFoo) \n{ Data = FooTypeX }\nCreateFoo(MediumFoo) \n{ Data = FooTypeY }\nCreateFoo(LargeFoo) \n{ Data = FooTypeZ }\nCreateBar(SmallBar) \n{ Foo = SmallFoo }\nIn addition to this being much easier to read and understand without the magic\nnumbers, both the text script and source code share the same header file, so it's impos-\nsible for them to get out of sync.\nBecause we're already performing a simple preprocessing substitution with\n#define, it's just one more step to actually parse and use more complex macros. By rec-\nognizing generic argument-based macros, we can now make complex script opera-\ntions simpler by substituting arguments. Macros are also handy to use for another\nreason. Because macros are not compiled in code unless they are actually used (like a\nprimitive form of templates), we can create custom script-based macros without\nbreaking C++ compatibility in the header file.\nNote diat although we're processing macros and #defines, the parser does not rec-\nognize other commands such as #ifdef, #ifndef, and #endif.\nThe Parsing System Explained\nThere are five classes in our parsing system: Parser, Token, TokenList, TokenFile, and\nMacro. The Macro class is a helper class used internally in Parser, so we only need to\nworry about it in regard to how it's used inside Parser. TokenFile is an optional class\nused to read and write binary tokens to and from a standard token list. This leaves the\nheart of the parsing system: Parser, Token, and TokenList. Because Token is the basic\nbuilding block produced by the parser, let's examine it first.\nThe Token Class\nThe basic data type of the parsing system is the Token class. There are eight possible\ndata types represented by the class: keywords, operators, variables, strings, integers,\nreal numbers, Booleans, and GUIDs. Keywords, operators, variables, and strings are\nall represented by C-strings, and so the only real difference among them is semantic.\nIntegers, real numbers, and Booleans are represented by signed integers, doubles, and\nbooh. For most purposes, this should be sufficient for data representation. GUIDs, or\nGlobally Unique IDentifiers, are also given native data type status, because it's often\nhandy to have a data type that is guaranteed unique, such as for identifying classes to\ncreate from scripts.\n",
      "content_length": 2467,
      "extraction_method": "Direct"
    },
    {
      "page_number": 112,
      "chapter": null,
      "content": "1.17 A Flexible Text Parsing System \n115\nThe Token class is comprised of a type field and a union of several different data\ntypes. A single class represents all basic data types. Data is accessed by first checking\nwhat type of token is being dealt with, and then calling the appropriate GetQ func-\ntion. Asserts ensure that inappropriate data access is not attempted.\nEach of the data types has a role to play in the parser, and it's important to under-\nstand how they work so that script errors are avoided. In general, the type definitions\nmatch similar definitions in C++. All keywords and tokens are case sensitive.\nKeyword\nKeywords are specially defined words that are stored in the parser. Two predefined\nkeywords are include and define. User-defined keywords are used primarily to aid in\nlexicographical analysis of the tokens after the scanning phase.\nOperator\nAn operator is usually a one- or two-character symbol such as an assignment operator\nor a comma. Operators are unique in the fact that they act like white space regarding\ntheir ability to separate other data types. Because of this, operators always have the\nhighest priority in the scanning routines, meaning that the symbols used in operators\ncannot be used as part of a keyword or variable name. Thus, using any number or\ncharacter as part of an operator should be avoided. Operators in this parsing system\nalso have an additional restriction: because of the searching method used, any opera-\ntor that is larger than a single character must be composed of smaller operators. The\nlarger symbol will always take precedence over the smaller symbols when they are not\nseparated by white space or other tokens.\nVariable\nA variable is any character-based token that was not found in the keyword list.\nString\nA string must be surrounded by double quotes. This parser supports strings of lengths\nup to 1024 characters (this buffer constant is adjustable in the parser) and does not\nsupport multiple-line strings.\nIntegers\nThe parser recognizes both positive and negative numbers and stores them in a signed\ninteger value. It also recognizes hexadecimal numbers by the Ox prefix. No range\nchecking is performed.\nFloats\nFloating-point numbers are called floats and are represented by a double value. The\nparser will recognize any number with a decimal point as a float. It will not recognize\nscientific notation, and no range checking is performed on the floating-point number.\nBooleans\nBoolean values are represented as a native C++ booltype, and true and false are built-\nin keywords. As with C++, these values are case sensitive.\n",
      "content_length": 2594,
      "extraction_method": "Direct"
    },
    {
      "page_number": 113,
      "chapter": null,
      "content": "116 \nSection 1 General Programming\nQUIDs\nBy making use of the macro-expansion code, we can support GUIDs without too\nmuch extra work. Note that unless the macro is expanded with ProcessMacrosQ, the\nGUID will remain a series of separate primitive types. This function is described later.\nThe TokenLlst Class\nThe TokenList class is publicly derived from a standard STL list of Tokens. It acts\nexactly like a standard STL list of tokens, and has a couple of additional features. The\nTokenList class allows viewing of the file and line number that any given token comes\nfrom. This is exclusively an aid for debugging, and can be removed with a compile-\ntime flag.\nThe Parser Class\nThis is the heart of the parsing functionality. We first create a parser object and call\nthe CreateQ function. Note that all functions return a boot value, using true for success\nand false for failure. Next, we must reserve any additional operators or keywords\nbeyond the defaults required for the text parsing.\nAfter this comes the actual parsing. The parsing phase is done in three passes,\nhandled by three functions. Splitting the functionality up gives the user more control\nover the parsing process. Often, for simple parsing jobs, #include file processing and\nmacro substitution are not needed. The first pass reads the files and translates the text\ndirectly into a TokenList using the function ProcessSource(). The next function,\nProcessHeadersQ, looks for any header files embedded in the source, and then parses\nand substitutes the contents of those headers into the original source. The third func-\ntion, ProcessMacrosQ, performs both simple and complex C-style macro substitution.\nThis can be a very powerful feature, and is especially useful for scripting languages.\nLet's see what this whole process looks like. Note that for clarity and brevity's\nsake, we are not doing any error checking.\n/ / W e need a Parser and TokenList object to start\nTokenList toklist;\nParser parser;\n// Create the parser and reserve some more keywords and tokens\nparser.Create();\nparser.ReserveKeyword(\"special_keyword\");\nparser.ReserveOperator(\"[\");\nparser.ReserveOperator(\"]\");\n// Now parse the file, any includes, and process macros\nparser.ProcessSource(\"data\\scripts\\somescript.txt\", &toklist);\nparser.ProcessHeaders(&toklist);\nparser.ProcessMacros(&toklist);\n",
      "content_length": 2331,
      "extraction_method": "Direct"
    },
    {
      "page_number": 114,
      "chapter": null,
      "content": "1.17 A Flexible Text Parsing System \n117\nThe TokenFile Class\nBecause parsing and processing human readable text files can be a bit slow, it may be\nnecessary to use a more efficient file format in the shipping code. The TokenFile class\ncan convert processed token lists into a binary form. This avoids having to parse the\ntext file multiple times, doing #include searches, macro substitutions, and so forth.\nCharacter-based values, such as keywords, operators, and variables, are stored in a\nlookup table. All numeric values are stored in binary form, providing additional space\nand efficiency savings. In general, this binary form can be expected to load five to ten\ntimes as fast as the text-based form.\nUsing the TokenFile class is simple as well. The WriteQ function takes a TokenList\nobject as an argument, and creates the binary form using either the output stream or\nfilename that was specified. The class can also store the file in either a case-sensitive or\ncase-insensitive manner. If both the variable \"Foo\" and \"foo\" appear in the script,\nturning the case sensitivity off will merge them together in the binary format, provid-\ning further space savings. It defaults to off.\nReading the file is performed with the Read() function. Here's how it looks in\ncode:\nTokenFile tf;\n// Write a file to disk\ntf.Write(\"somefile.pcs\", &toklist);\n//Or read it\ntf.Read(\"somefile.pcs\", &toklist);\nWrapping Up\nText file processing at its simplest level is a trivial problem requiring only a few lines\nof code. For anything more complex than this, however, it's beneficial to have a com-\nprehensive text-parsing system that can be as flexible and robust as the job demands.\n",
      "content_length": 1667,
      "extraction_method": "Direct"
    },
    {
      "page_number": 115,
      "chapter": null,
      "content": "1.18\nA Generic Tweaker\nLasse Staff Jensen, Funcom\nlasse@funcom.com\n(uring game development, one of the most frequent tasks we perform is tweaking\nvariables until the game has just the right balance we need. In this gem, we\nwill cover an easy-to-use \"tweaker\" interface and the design issues behind the\nimplementation.\nRequirements Analysis\nOne of the primary goals of a generic tweaker interface is to make it as transparent\nand easy to use as possible. The user in this case is the programmer who exposes vari-\nables to be tweaked. Further requirements to emphasise are the size in memory, the\nability to tweak a variable without too much added overhead, and the speed of actu-\nally tweaking a variable (because in some cases the tweaker will be used in the release\nbuild as well).\nLet's try to break down the requirements in more detail, and see what the imple-\nmentation really needs to do:\n• It should be transparent to the coder, meaning that the variables we want to\ntweak shouldn't contain any additional data and/or functionality, and that the\nusage of these variables shouldn't need to know about the tweaker at all.\n• It should be simple to use, meaning that the user should be able to define vari-\nables to be tweaked in less than 10 lines of code, and be able to tweak and get\nvariables from a common database in typically two or three lines of code.\nImplementation\nDesign\nFigure 1.18.1 contains the UML diagram of the classes to be presented in a bottom-\nup fashion in the rest of this gem. The type information and the tweakable hierarchy\nare the essence of this design.\n118\n",
      "content_length": 1589,
      "extraction_method": "Direct"
    },
    {
      "page_number": 116,
      "chapter": null,
      "content": "\"*\"'\n1' l;l\"wfer\nTweaker_c\n^Tweakables: TweakableBase_c\n*AddTweakable()\n*TweakValue()\nTweakerlnstanceDB^c\n^Categories: Tweaker_c\n^Instances: Tweaker_c\n*AddTweaker()\nFIGURE 1.18.1 Overview of the tweaker classes.\nTweakableTypeRange_c\n: void\n: void\n^TypelD_c*: void\n*GetMax()\n*GetMin()\n*GetStoredType()\nlntTypelD_c\n*GetType()\nFloatTypelD_c\n*GetType()\nBoolTypelD_c\n*GetType()\n(O\n",
      "content_length": 376,
      "extraction_method": "Direct"
    },
    {
      "page_number": 117,
      "chapter": null,
      "content": "Section 1 General Programming\nType Information\nWe will use template specialization to provide type information that we can store in a\nuniform way. First is our base class TypelDjc that defines the interface for our type\ninformation class with a virtual function that returns a string with the type name:\nclass TypeID_c {\npublic:\nvirtual const char* GetTypeNameO const { return \"Unknown\"; }\n};\nNext, we create a template class that we can use to retrieve the correct type when\ngiven the variable. In this class, we add a member to get the pointer to our TypeID_c\ninstance that can be tested directly for the stored pointer address.\ntemplate <class T>\nclass Identifier_c {\npublic:\nstatic const TypeID_c* const GetType();\nNow that we have this class declared, we will use template specialization to define\neach unique type. Each subclass of TypeID_c will exist as a singleton, and the pointer\nto that instance serves as the identifier of the type. For simplicity, all of these will be\nplaced in the global scope through static members. We can make sure that the actual\ninstances exist, if called from other static functions, by receiving the pointer from the\nGetldentification method. The full implementation for float values follows:\nclass floatID_c : public TypeID_c {\npublic:\nvirtual const char* GetTypeNameO const { return \"float\"; }\nstatic TypeID_c* const Getldentification () ;\n} 5\ntemplate <>\nclass Identifier_c<float> {\npublic:\nstatic const TypeID_c* const GetType() {\nreturn floatID_c: :GetIdentification() ;\nTypeID_c* const floatID_c: :GetIdentification() {\nstatic floatID_c clnstance;\nreturn &clnstance;\nTo use these classes for type information, we can simply store the base pointer:\nfloat vMyFloat;\nconst TypeID_c* const pcType = TweakableBase_c: :GetTypeID( vMyFloat ) ;\n",
      "content_length": 1782,
      "extraction_method": "Direct"
    },
    {
      "page_number": 118,
      "chapter": null,
      "content": "1.18 A Generic Tweaker \n121\nHere, the TweakableBase_c (more on this class later) has a template member that\ncalls the correct Identifier^ specialization. Then we can test the address of the\npointer:\nif( Identifier_c<float>::GetType() == pcType ) {\n// We have a float!\n}\nThere are two macros for defining user types in the code on the accompanying\nCD, so all that's required for support of a new data type is to place a call to\nDECLARE_DATA_TYPE in the header and DEFINE_DATA_TYPE in the imple-\nmentation file, and then recompile. (In addition, one might want to add a call to the\nmacro DUMMY_OPERATORS () in case one doesn't want to support range checking.)\nTweakableBase_c\nWe have a clean and easy way to store type info, so let's continue by creating the base\nclass to hold the pointer to the tweakable variable. This class also contains the tem-\nplate member for getting the type info mentioned earlier. Because one of our require-\nments is to keep memory overhead to a minimum, we will use RTTI for checking\nwhich specific types of tweakables we have stored in memory. We therefore make sure\nthe class is polymorphic by adding a virtual function to get the type info stored (or\nNULL if none). Here is the implementation:\nclass TweakableBase_c {\npublic:\nTweakableBase_c( void* i_pData ) : m_pData( i_pData ) {;}\n-TweakableBase_c() { /*NOP*/;}\nvirtual const TypeID_c* const GetStoredType() const { return NULL; }\ntemplate <class T>\nstatic const TypeID_c* const GetTypeID( const T& i_cValue ) {\nreturn Identifier_c<T>::GetType();\n}\nprotected:\nvoid* m_pData;\n}; \n// TweakableBase_c\nNow that we have the base class, we can create subclasses containing additional\ndata such as type information, limits for range checking, a pointer for a call-back func-\ntion, and any other data we might need to attach to the various tweakables, while keep-\ning die memory to a minimum. Here is how one of the specific tweakable classes looks:\ntemplate <class T>\nclass TweakableType_c : public TweakableBase_c {\n",
      "content_length": 1994,
      "extraction_method": "Direct"
    },
    {
      "page_number": 119,
      "chapter": null,
      "content": "122 \nSection 1 \nGeneral Programming\npublic:\nTweakableType_c( T* i_pxData, const TypeID_c* i_pcType ) :\nTweakableBase_c( reinterpret_cast<void*>( i_pxData ) ),\nm_pcType( i_pcType ) { /*NOP*/; }\nconst TypeID_c* const GetDataType() const { return m_pcType; }\nvirtual const TypeID_c* const GetStoredType() const {\nreturn m_pcType; }\nprivate:\nconst TypeID_c* const m_pcType; \n:\n}; \n// TweakableType_c\nThe great thing about this code is that the subclasses are implemented as tem-\nplates, even though the base class was defined without them. This way, we can pass in\nthe pointer to the actual data type, hiding the casting to void horn the interface.\nTweakerje\nWe finally have all the building blocks we need to create the tweaker class itself. This\nclass will store all of our tweakables and give the user functionality for tweaking the\nstored values. We will use an STL map to hold all of the pointers to our tweakables,\nusing the name of each tweakable as the key. Simple template members provide all the\nfunctionality. An example of this is the TweakValue member:\ntemplate<class Value_x>\nTweakError_e TweakValue( const std::string& i_cID, const Value_x&\ni_xValue ) {\nTweakableBase_c* pcTweakable;\niTweakableMap_t iSearchResult = m_cTweakable_map.find( i_cID );\nif( iSearchResult == m_cTweakable_map.end() ) {\nreturn e_UNKNOWN_KEY; }\npcTweakable = (*iSearchResult).second;\n#ifdef _DEBUG\nTweakableType_c<Value_x>* pcType;\nif( pcType = dynamic_cast< TweakableType_c<Value_x>* >(\npcTweakable ) ) {\nassert( pcTweakable->GetTypeID( i_xValue ) ==\npcType-»GetDataType() );\n}\n#endif\nTweakableTypeRange_c<Value_x>* pcTypeRange;\nif ( pcTypeRange = dynamic_cast< TweakableTypeRange_c<Value_x>* >(\npcTweakable ) )\n{\nassert( pcTweakable->GetTypeID( i_xValue ) ==\npcTypeRange->GetDataType() );\nif( i_xValue < pcTypeRange->GetMin() ) { return e_MIN_EXCEEDED; }\nif( i_xValue > pcTypeRange->GetMax() ) { return e_MAX_EXCEEDED; }\n",
      "content_length": 1909,
      "extraction_method": "Direct"
    },
    {
      "page_number": 120,
      "chapter": null,
      "content": "1.18 A Generic Tweaker \n123\n*(reinterpret_cast<Value_x*>( pcTweakable->m_pData ) ) = i_xValue;\nreturn e_OK;\n} // TweakValue\nBecause the member is a template, we can cast back to the given value directly,\nthereby completely hiding the ugly void casting. Note that if users decide to not store\nthe type information, they could easily force us to do something bad, since we have\nno way of checking the origin of the reinterpret_casA\nTweakerinstanceDB_c\nIn order to support grouping of tweakables and the ability to store several instances of\na given variable, we have an instance database to hold different tweakers. The imple-\nmentation is straightforward—an STL multimap holding all of the instances of differ-\nent tweakers, and an STL map of these multimaps where the category is the key.\nLet's test our implementation against the requirements to verify that we have reached\nour goals. Defining a variable to be tweakable requires us to create a tweaker and add\nit to the tweakable instance database.\nTweaker_c* pcTweaker = TweakerInstanceDB_c::AddTweaker( \"Landscape\",\nTWEAKER_CREATE_ID( this ), \"Graphics\" );\nHere we create a tweaker for the class Landscape (inside the constructor, for exam-\nple) and put it in the Graphics category. The TWEAKER_CREATE_ID macro takes\nthe this pointer and makes sure that each instance of the class Landscape gets a unique\nID. Then, we simply add each variable to this (and other tweakers we make) by:\npcTweaker->AddTweakable( &m_vShadowmapScaleTop, \"Shadowmap scale\",\nO.OF, 68.OF );\nHere we have added a variable, constrained it to the interval [0, 68], and called it\n\"Shadowmap scale.\" It's vital to note that because of the template nature of the\nAddTweakable method, we must pass correct types to all of the arguments (for exam-\nple, use O.OF and not just 0). Defining a variable to be tweakable takes two lines of\ncode, and is totally hidden from the users of the variable in question.\nFor tweaking this variable, all we need is the name, data type, and desired\ninstance. Usually, we have the pointer to the tweaker instance itself, but in the GUI\ncode, one would typically do something like:\nTweakerInstanceDB_c::iConstCategoryMap_t iCategory =\nTweakerInstanceDB_c::GetCategory( \"Graphics\" );\nTweaker_c* pcTweaker =\nGetTweaker( iCategory->second, \"Landscape\", TWEAKER_CREATE_ID(\npcLandscape ) ) ;\n",
      "content_length": 2339,
      "extraction_method": "Direct"
    },
    {
      "page_number": 121,
      "chapter": null,
      "content": "124 \nSection 1 General Programming\nHere we first get all of the instance maps that are stored under the \"Graphics\" cat-\negory label. Then we search for the correct instance of the Landscape class (we assume\nthe pointer pcLandscape points to the instance in question). Changing the value of a\nspecific value is straightforward.\nTweaker_c::TweakError_e eError;\neError = pcTweaker->TweakValue( \"Shadowmap scale\", 20.OF );\nSo, tweaking a variable is one line of code, with additional lines for error handling\n(or simply asserting the return value). Receiving the stored value is done similarly:\nfloat vShadowmapScale;\neError = pcTweaker->GetValue( \"Shadowmap scale\", &vShadowmapScale );\nGraphical User Interface\nGUIs tend to be specific to each project, so I have left a general discussion of this\ntopic out of this gem, although I will describe an existing implementation as a source\nfor ideas. In Equinox, Funcom's next-generation 3D engine, we have implemented a\ndirectory structure, as shown in Figure 1.18.2, that can be browsed in a console at the\ntop of the screen.\nFor tweaking values, we have defined input methods that can be assigned to the\ntweakables. That way, we can create specialized input methods such as the angle\ntweaker seen in Figure 1.18.3.\nFor saving and loading, in addition to the binary snapshots, we can save all of the\ntweakables in #define statements directly into h files. Because the number of instances\nof a variable could change over the lifetime of the application, we only save the first\ninstance into the header file. This feature gives us the capability to add variables to be\ntweaked only in debug builds, and we then #indude the header file to initialize the\nTweaker: Application\n[..,.]„ \n._ \n,\n\"Fog density\"\"\"\"\" '\" \" \n\"' \n\"•' \"™\"™\" \"\"\" \n—••*•->• .-.•-.-••«\nFog end\nFog start\nLinear fog\nPhysical water\nShow Equinox logo\nShow caustics\nShow fog\nShow landscape\nShow sky\nShow water\nTable fog\nFIGURE 1.18.2 \nScreen shot from our GUI. The user can move up and down in the\ndirectories (categories in the code) and choose values to be tweaked.\n",
      "content_length": 2071,
      "extraction_method": "Direct"
    },
    {
      "page_number": 122,
      "chapter": null,
      "content": "1.18 A Generic Tweaker \n125\nTweaker: Graphics\nTweaker instance name: GraphicsTestInstance\nAngleTweak 1/2\nType: float\nUalue = 56.649902\nLimited to range <45.080000, 120.800008>\nstep = 8,758006, use +/—/spaee to modify\nFIGURE 1.18.3 \nThis specialized input gives the user the possibility to visually tweak\nangles in an intuitive way.\nvariables to the latest tweaked value in the release build. Here is a sample of how this\nworks for our ShadowmapScale variable:\nlandscape_tweakables.h:\ntfdefine \nSHADOWMAP_SCALE \n43.5\nlandscape.cpp:\ntfinclude \n\"landscape_tweakables.h\"\nm_vShadowmapScale = SHADOWMAP_SCALE;\nIt is possible to use the RTTI typeidQ to replace the type information code detailed\npreviously. There are pros and cons to using our type information code.\nPros:\n• It takes up less space for the type information, since it is only required for classes\nthat use it.\n• One can add specific information to the TypeID_c class; for example, a way to\nload and store the type or a pointer to the GUI control.\nCons:\nWe have to use macros for each unique type, while RTTI provides the type infor-\nmation automatically.\n",
      "content_length": 1114,
      "extraction_method": "Direct"
    },
    {
      "page_number": 123,
      "chapter": null,
      "content": "126 \nSection 1 General Programming\nAcknowledgment\nI would like to thank Robert Golias for invaluable help and suggestions, and for\nimplementing the Equinox tweaker GUI that was an excellent test of how simple the\ninterface actually turned out!\n",
      "content_length": 244,
      "extraction_method": "Direct"
    },
    {
      "page_number": 124,
      "chapter": null,
      "content": "1.19\nGenuine Random Number\nGeneration\nPete Isensee, Microsoft\npkisensee@msn.com\nC\nomputer games use random numbers extensively for rolling dice, shuffling cards,\nsimulating nature, generating realistic physics, and performing secure multi-\nplayer transactions. Computers are great at generating pseudo-random numbers, but\nnot so good at creating genuine random numbers. Pseudo-random numbers are num-\nbers that appear to be random, but are algorithmically computed based on the previ-\nous random number. Genuine, or real, random numbers are numbers that not only\nappear random, but are unpredictable, nonrepeating and nondeterministic. They are\ngenerated without the input of the previous random number. This gem presents a\nmethod of creating genuine random numbers in software.\nPseudo-Randomness\nPseudo-random number sequences eventually repeat themselves and can always be\nprecisely reproduced given the same seed. This leads to distinct problems in gaming\nscenarios. Consider the common case of a game that initializes its random number\ngenerator (RNG) with the current tick count - the number of ticks since the machine\nwas booted up. Now assume the player turns on their gaming console every time they\nbegin playing this game. The level of randomness in the game is gated by the choice\nof seed, and the number of bits of randomness in the seed is unacceptably small.\nNow consider the use of a pseudo-RNG to create secret keys for encrypting\nsecure multiplayer game transmissions. At the core of all public key cryptographic sys-\ntems is the generation of unpredictable random numbers. The use of pseudo-random\nnumbers leads to false security, because a pseudo-random number is fully pre-\ndictable—translate: easily hacked—if the initial state is known. It's not uncommon\nfor the weakest part of crypto systems to be the secret key generation techniques\n[Kelsey98].\nGenuine Randomness\nA genuine random number meets the following criteria: it appears random, has\nuniform distribution, is unpredictable, and is nonrepeating. The quality of\n127\n",
      "content_length": 2046,
      "extraction_method": "Direct"
    },
    {
      "page_number": 125,
      "chapter": null,
      "content": "128 \nSection 1 General Programming\nunpredictability is paramount for security purposes. Even given full knowledge of the\nalgorithm, an attacker should find it computationally infeasible to predict the output\n[Schneier96].\nThe ideal way of creating genuine random numbers is to use a physical source of\nrandomness, such as radioactive decay or thermal noise. Many such devices exist; see\n[Walker(a)] for one example. However, PCs and video game consoles do not typically\nhave access to these types of devices. In the absence of a hardware source, the tech-\nnique recommended by RFC 1750 [Eastlake94] is \"to obtain random input from a\nlarge number of uncorrelated sources and mix them with a strong mixing function.\"\nBy taking input from many unrelated sources, each with a few bits of randomness,\nand thoroughly hashing and mashing them up, we get a value with a high degree of\nentropy—a truly random number.\nRandom Input Sources\nExamples of random input available on many PCs and game consoles include:\n• System date and time\n• Time since boot at highest resolution available\n• Username or ID\n• Computer name or ID\n• State of CPU registers\n• State of system threads and processes\n• Contents of the stack\n• Mouse or joystick position\n• Timing between last N keystrokes or controller input\n• Last N keystroke or controller data\n• Memory status (bytes allocated, free, etc.)\n• Hard drive state (bytes available, used, etc.)\n• Last N system messages\n• GUI state (window positions, etc.)\n• Timing between last N network packets\n• Last N network packet data\n• Data stored at a semi-random address in main memory, video memory, etc.\n• Hardware identifiers: CPU ID, hard drive ID, BIOS ID, network card ID, video\ncard ID, and sound card ID\nSome of these sources will always be the same for a given system, like the user ID\nor hardware IDs. The reason to include these values is that they're variable across\nmachines, so they're useful in generating secret keys for transmitting network data.\nSome sources change very little from sample to sample. For instance, the hard drive\nstate and memory load may only change slightly from one read to the next. However,\neach input provides a few bits of randomness. Mixed together, they give many bits of\nrandomness.\n",
      "content_length": 2248,
      "extraction_method": "Direct"
    },
    {
      "page_number": 126,
      "chapter": null,
      "content": "1.19 Genuine Random Number Generation \n129\nThe more bits of entropy that can be obtained from input sources, the more ran-\ndom the output. It's useful to buffer sources such as mouse positions, keystrokes, and\nnetwork packets over time in a circular queue. Then the entire queue can be used as\nan input source.\nHardware Sources\nSome gaming platforms have access to physical sources of randomness. When these\nsources are available, they make excellent input sources. Examples of physical sources\ninclude:\n• Input from sound card (for example, the microphone jack) with no source\nplugged in\n• Input from a video camera\n• Disk drive seek time (hard drive, CD-ROM, DVD)\n• Intel 810 chipset hardware RNG (a thermal noise-based RNG implemented in\nsilicon) [Intel99]\nMixing Function\nIn the context of creating genuine random numbers, a strong mixing function is a\nfunction where each bit of the output is a different complex and nonlinear function of\neach and every bit of the input. A good mixing function will change approximately\nhalf of the output bits given a single bit change in the input.\nExamples of strong mixing functions include:\n• DES (and most other symmetric ciphers)\n• Diffie-Hellman (and most other public key ciphers)\n• MD5, SHA-1 (and most other cryptographic hashes)\nSecure hashing functions such as MD5 are the perfect mixers for many reasons:\nthey meet the basic requirements of a good mixing function, they've been widely ana-\nlyzed for security flaws, they're typically faster than either symmetric or asymmetric\nencryption, and they're not subject to any export restrictions. Public implementations\nare also widely available.\nLimitations\nUnlike generating pseudo-random numbers, creating genuine random numbers in\nsoftware is very slow. For the output to be truly random, many sources must be sam-\npled. Some of the sampling is slow, such as reading from the hard drive or sound card.\nFurthermore, the sampled input must be mixed using complex algorithms.\nGame consoles have a more limited selection of input sources compared to PCs,\nso they will tend to produce less random results. However, newer consoles often have\ndisk drives of some sort (CD-ROM, DVD, hard disk) that can be used as good hard-\nware sources of entropy.\n",
      "content_length": 2243,
      "extraction_method": "Direct"
    },
    {
      "page_number": 127,
      "chapter": null,
      "content": "Section 1 \nGeneral Programming\nThe randomness of the results depends solely on the level of entropy in the input\nsamples. The more input samples and the more entropy in each sample, the better the\noutput. Keep in mind that the more often this algorithm is invoked in quick succes-\nsion, the less random the output, because the smaller the change in the input bits. To\nsum up, this technique is not a replacement for pseudo-RNG. Use this technique for\nthe one-time generation of your RNG seed value or for generating network session\nkeys that can then be used for hours or days.\nImplementation\nA C++ example of a genuine random number generator is provided on the accompa-\nnying CD. Any implementation of this algorithm will naturally be platform depen-\ndent. This particular version is specific to the Win32 platform, but is designed to be\neasily extensible to other platforms. It uses hardware sources of randomness, such as\nthe Intel RNG and sound card input, when those sources are available. In the inter-\nests of efficiency and simplicity, it does not use all of the examples listed previously as\ninput, but uses enough to produce a high level of randomness.\nThe primary functionality resides in the GenRand object within the TrueRand\nnamespace. Here is an example use of GenRand to create a genuine seed value:\n#include \"GenRand. h\" // Genuine random number header\nunsigned int nSeed = TrueRand: :GenRand() .GetRandInt() ;\nHere's another example showing the generation of a session key for secure net-\nwork communication. The Buffer object is a simple wrapper around stof: :toasic__\nstring<unsigned char>, which provides the functionality we need for reserving\nspace, appending data, and tracking the size of the sample buffer:\nTrueRand: : GenRand randGen;\nTrueRand: : Buffer bufSessionKey = randGen. GetRand( );\nThe Get/tend () function is the heart of the program. It samples the random\ninputs, and then uses a strong mixing function to produce the output. This imple-\nmentation uses MD5 hashing, so the resulting buffer is the length of an MD5 hash\n(16 bytes). The mCrypto object is a wrapper around the Win32 Crypto API, which\nincludes MD5 hashing.\nBuffer GenRand: :GetRand()\n{\n// Build sample buffer\nBuffer randlnputs = GetRandomlnputsO ;\n// Mix well and serve\nreturn mCrypto.GetHash( CALG_MD5, randlnputs );\n",
      "content_length": 2320,
      "extraction_method": "Direct"
    },
    {
      "page_number": 128,
      "chapter": null,
      "content": "1.19 Genuine Random Number Generation \n131\nThe GetRandomlnputsf) function is the input sampler. It returns a buffer with\napproximately 10K of sampled data. This function can easily be modified to include\nmore or less input as desired. Because the time spent in the function varies according to\nsystem (drive, sound card) access, we can use the hardware latency as a source of random\ninput; hence, the snapshot of the current time at the beginning and end of the function.\nBuffer GenRand: :GetRandomInputs()\n{\n// For speed, preallocate input buffer\nBuffer randln;\nrandln. reserve ( GetMaxRandInputSize() );\nGetCurrTime( randln ); \n// append time to buffer\nGetStackState( randln ); \n// stack state\nGetHardwareRng( randln ); \n// hardware RNG, if avail\nGetPendingMsgs( randln ); \n// pending Win32 msgs\nGetMemoryStatus( randln ); \n// memory load\nGetCurrMousePos( randln ); \n// mouse position\n// . . . etc.\nGetCurrTime( randln ); \n// random hardware latency\nreturn randln;\n}\nFinally, here's one of the input sampling functions. It extracts the current time,\nand then appends the data to the mRandlnputs buffer object. QueryPerformance-\nCounter() is the highest resolution timer in Windows, so it provides the most bits of\nrandomness. We can ignore API failures in this case (and many others), because the\nworst that happens is that we append whatever random stack data happens to be in\nPerf Counter if the function fails.\nvoid GenRand: :GetCurrTime( Buffer& randln )\n{\nLARGE_INTEGER Perf Counter;\nQueryPerformanceCounter( &PerfCounter ); // Win32 API\nAppend( randln, PerfCounter );\nHow Random Is GenRand?\nThere are many tests for examining the quality of random numbers. One test is the\n^ c \"\"\") \npublicly available program ENT [Walker(b)], included on the accompanying CD,\nmm CD \nwhich applies a suite of tests to any data stream. Tests of GenRand () without using any\nsources of hardware input (including hard drive seek time), and generating a file of\n25,000 random integers using GetRandInt() gives the following results:\n• Entropy = 7.998199 bits per byte.\n• Optimum compression would reduce the size of this 100,000-byte file by 0 percent.\n",
      "content_length": 2140,
      "extraction_method": "Direct"
    },
    {
      "page_number": 129,
      "chapter": null,
      "content": "132 \nSection 1 General Programming\n• Chi square distribution for 100,000 samples is 250.13, and randomly would\nexceed this value 50 percent of the time.\n• Arithmetic mean value of data bytes is 127.4918 (127.5 = random).\n• Monte Carlo value for Pi is 3.157326293 (error 0.50 percent).\n• Serial correlation coefficient is 0.000272 (totally uncorrelated = 0.0).\nThese results indicate that the output has a high degree of randomness. For\ninstance, the chi square test—the most common test for randomness [Knuth98]—\nindicates that we have a very random generator.\nReferences\n[Callas96] Callas, Jon, \"Using and Creating Cryptographic-Quality Random Num-\nbers,\" available online at www.merrymeet.com/jon/usingrandom.html, June\n1996.\n[Eastlake94] Eastlake, D., Network Working Group, et al, \"Randomness Recommen-\ndations for Security,\" RFC 1750, available online at www.faqs.org/rfcs/\nrfcl750.html, December 1994. \n]\n[Kelsey98] Kelsey, J., et al, \"Cryptanalytic Attacks on Pseudorandom Number Gener-\nators,\" available online at www.counterpane.com/pseudorandom_number .html,\nMarch 1998.\n[Intel99] Intel Corporation, \"Intel Random Number Generator,\" available online at\nhttp://developer.intel.com/design/security/rng/rng.htm, 1999.\n[Knuth98] Knuth, Donald, The Art of Computer Programming, Volume 2: Seminu-\nmerical Algorithmsi Third Edition. Addison-Wesley. 1998.\n[Schneier96] Schneier, Bruce, Applied Cryptography, Second Edition. John Wiley &\nSons. 1996.\n[Walker(a)] Walker, John, \"HotBits: Genuine Random Numbers Generated by\nRadioactive Decay,\" available online at www.fourmilab.ch/hotbits/.\n[Walker(b)] Walker, John, \"ENT: A Pseudorandom Number Sequence Test Pro-\ngram,\" available online at www.fourmilab.ch/random/.\n",
      "content_length": 1716,
      "extraction_method": "Direct"
    },
    {
      "page_number": 130,
      "chapter": null,
      "content": "1.20\nUsing Bloom Filters to\nImprove Computational\nPerformance\nMark Fischer, Beach Software\nbeach@beachsoftware.com\nI\nmagine the desire to store Boolean information in a bit array—a very simple\npremise. Simply assign each element in the bit array to a specific meaning, and then\nassign it a value. In this scenario, it takes 1 bit in the array to store 1 bit of stored\ninformation. The bit array faithfully represents its relative value with 100-percent\naccuracy. This, of course, works best when the stored data is array oriented such as a\ntransient over time or space. However, what if the data is not a linear transient-\noriented data set?\nBloom's Way\nIn 1970, Burton H. Bloom published a simple and clever algorithm [Bloom70] in the\n\"Communications of the ACM.\" In his publication, Bloom suggests using a \"Hash\nCoding with Allowable Errors\" algorithm to help word processors perform capitaliza-\ntion or hyphenation on a document. This algorithm would use less space and be faster\nthan a conventional one-to-one mapping algorithm. Using this example, a majority of\nwords (90 percent, for example) could be checked using a simple rule, while the\nsmaller minority set could be solved with an exception list used to catch the instances\nwhere the algorithm would report a word as simply solvable when it was not. Bloom's\nmotivation was to reduce the time it took to look up data from a slow storage device.\nPossible Scenarios\nA Bloom Filter can reduce the time it takes to compute a relatively expensive and rou-\ntinely executed computation by storing a true Boolean value from a previously executed\ncomputation. Consider the following cases where we'd like to improve performance:\n• Determine if a polygon is probably visible from an octree node.\n• Determine if an object probably collides at a coordinate.\n• Determine if a ray cast probably intersects an object at a coordinate.\n133\n",
      "content_length": 1883,
      "extraction_method": "Direct"
    },
    {
      "page_number": 131,
      "chapter": null,
      "content": "134 \nSection 1 General Programming\nAll of these cases fit into a general scenario. Each case involves an expensive com-\nputation (CPU, network, or other resource) where the result is a Boolean (usually false)\nanswer. It is important to note that that the word probably is used in each case because\na Bloom Filter is guaranteed to be 100-percent accurate if the Bloom Filter test returns\na false (miss), but is, at best, only probably true if the Bloom Filter returns true (hit).\nA Bloom Filter can store the true result of any function. Usually, the function\nparameter is represented as a pointer to a byte array. If we wish to store the result of a\nfunction that uses multiple parameters, we can concatenate the parameters into a sin-\ngle function parameter. In cases where 100-percent accuracy is needed, we must com-\npute the original expensive function to determine the absolute result of the expensive\nfunction, if a Bloom Filter test returns true.\nHow It Works\nThere are two primary functions in a Bloom Filter: a function for storing the Boolean\ntrue value returned from an expensive function, and a function for testing for a previ-\nously stored Boolean true value. The storing function will accept input in any form\nand modify the Bloom Filter Array accordingly. The testing function will accept input\nin the same form as the storing function and return a Boolean value. If the testing\nfunction returns false, it is guaranteed that the input was never previously stored using\nthe storing function. If the function returns true, it is likely that the input was previ-\nously stored using the storing function. A false positive is a possible result from the\ntest. If 100-percent accuracy is desired, perform the original expensive function to\ndetermine the absolute value. A conventional Bloom Filter is additive, so it can only\nstore additional Boolean true results from an expensive function and cannot remove\npreviously stored values.\nDefinitions\nThe high-quality operation of a Bloom Filter requires a high-quality hash function\nthat is sometimes referred to as a message digest algorithm. Any high-quality hash\nfunction will work, but I recommend using the MD5 message digest algorithm\n[RSA01] from RSA Security, Inc., which is available in source code on the Net, and is\nalso documented in RFC 1321. The MD5 hash function takes N bytes from a byte\narray and produces a 16-byte (128-bit) return value. This return value is a hash of the\ninput, which means if any of the bits in the input change (even in the slightest),\nthe return value will be changed drastically. The return of the hash function, in\nBloom terminology, is called the Bloom Filter Key.\nBloom Filter Indexes are obtained by breaking the Bloom Filter Key into blocks\nof a designated bit size. If we choose a Bloom Filter Index bit size of 16 bits, a 128-bit\nBloom Filter Key can be broken into eight complete 16-bit segments. If there are\nremaining bits left over from breaking the Key into complete segments, they are\ndiscarded.\n",
      "content_length": 3006,
      "extraction_method": "Direct"
    },
    {
      "page_number": 132,
      "chapter": null,
      "content": "1.20 Using Bloom Filters to Improve Computational Performance \n135\nThe number of Bloom Filter Phases used in a Bloom Filter is the number of\nBloom Filter Indexes used to store the Boolean value from the expensive function. For\nexample, three phases might be used from a 128-bit key using a Bloom Filter Index\nbit size of 16 bits. The remaining five indexes will be discarded, in this example.\nA Bloom Filter Array is used to store the expensive function's Boolean value. For\nexample, if the Bloom Filter Index bit size is 16 bits, the Bloom Filter Array will be 216\nbits long, or 64K bits (8K bytes). The larger the array, the more accurate the Bloom\nFilter test.\nThe Bloom Filter Saturation of the Bloom Filter Array is the percentage of bits set\nto true in the bit array. A Bloom Filter Array is optimal when saturation is 50 percent,\nor half of the bits are set and half are not.\nExample 1\nFor an example, we will store the function parameter (\"Mikano is in the park\") using\nthree phases with an index bit size of 16 bits into an array 64k bits long (8k bytes). In\nthis instance, the expensive function was used to determine if Mikano was truly in the\npark and the result was yes (true). Although we used a string variable, in this case, any\nvariable format will work. The format of the stored expensive function parameter data\nis independent of the Bloom Filter performance, accuracy, or memory usage.\nFirst, the hash function is computed from the expensive function parameter data.\nLet's assume that the hash function returned the 128-bit value Oxl0027AB30001BF\n7877AB34D976A09667. The first three segments of 16-bit indexes will be 0x1002,\n0x7AB3, and 0x0001. The remaining segments are ignored.\nThe Bloom Filter Array starts out reset (all false bits), before we begin to populate\nthe bit array with data. Then, for each of these indexes, we will set the respective bit\nindex in the Bloom Filter Array to true regardless of its previous value. As the array\nbecomes populated, sometimes we will set a bit to true that has already been set to\ntrue. This is the origin of the possible false positive result when testing the Bloom Fil-\nter Array (Figure 1.20.1).\nWhen we wish to examine the Bloom Filter Array to determine if there was a pre-\nviously stored expensive function parameter, we proceed in almost the same steps as a\nstore, except that the bits are read from the Bloom Filter Array instead of written to\nthem. If any of the read bits are false, then the expensive function parameter was\nabsolutely never previously stored in the Bloom Filter Array. If all of the bits are true,\nthen the expensive function parameter was likely previously stored in the Array. In the\ncase of a true result, calculate the original expensive function to accurately determine\nthe Boolean value (Figure 1.20.2).\nTuning the Bloom Filter\nTuning the Bloom Filter involves determining the number of phases and the bit\nsize of the indexes. Both of these variables can be modified to change the accuracy and\ncapacity of the Bloom Filter. Generally speaking, the larger the size of the bit array\n",
      "content_length": 3082,
      "extraction_method": "Direct"
    },
    {
      "page_number": 133,
      "chapter": null,
      "content": "136\nSection 1 General Programming\nvoid store_bloom_data(\"Mikano is in the park\")\n128 Bloom Key divided\ninto 8 16-bit segments\n3 phase, 16-bit (8K Byte)\nBloom Filter\nHash\n0x1002\nOX7AB3\n0x0001\nOxBF78\nOx77AB\nOx34D9\nOx76AO\n0x9667\njwrite\nwrite\njwrite\nonly 3\nphase so\nignore the\nrest\nboolean test_bloom_data(\"Mikano is in the park\")\nread\nBit Value\nboolean test_bloom_data(\"Mikano is in the office \")\n\"Mikanq is in\nthe office\"\nHash\nOxFFFF\n0x7 AB3\nOxFFFC\n0x7063\nOx691E\nOxB269\n0x0110\nOxCOOl\nj-ead\n)\n(potential false positive) ,\n(not set so return false)\nr-J\n•w\n\\s\n•w\nIf OxFFFC was also set,\nthen a false positive would\nbe returned.\nBit Index\n0x0000\n0x0001\n0x0002\n0x0003\n0x1001\n0x1002\n0x1003\nOX7AB3\n0x7 AB4\nOxFFFC\nOxFFFD\nOxFFFE\nOxFFFF\nreturn true\nFalse Positive\nFIGURE 1.20.1 Flow of a Bloom Filter.\n",
      "content_length": 790,
      "extraction_method": "Direct"
    },
    {
      "page_number": 134,
      "chapter": null,
      "content": "1.20 Using Bloom Filters to Improve Computational Performance\n137\n// returns a pointer to 16 bytes of data that represent the hash\nvoid * compute_hash ( pData, nDataLength );\n// returns the integer value for the bits at nlndex for nBitLength long\nint get_index_value( void * pData, int nBitlndex, int nBitLength );\n// tests a bit in the Bloom Filter Array.\n// returns true if set otherwise returns false\nboolean is_bit_index_set( int nlndexValue );\n// sets a bit in the Bloom Filter Array\nvoid set_bit_index( int nlndexValue );\nvoid store_bloom_data( void * pData, int nDataLength )\n{\nvoid *pHash;\nint nPhases = 3, nPhaselndex = 0, nBitlndexLength = 16;\n// returns pointer to 16 bytes of memory\npHash = compute_hash( pData, nDataLength );\n// now set each bit\nwhile { nPhaselndex < m nPhases )\nTheoretically, a different input\nparameter could return the same\nvalue but that is unprobable.\nEither way, the algorithm will\nstill work.\nnlndexValue = get_index_value( pHash, nPhaselndex, nBitlndexLength );\n// if bit is not set, we have a miss so return false\nset_bit_index( nlndexValue ) ;\nnPhase!ndex++;\nboolean test_bloom_data( void * pData, int nDataLength )\nvoid *pHash;\nint nPhases = 3, nPhaselndex = 0, nBitlndexLength =. 16;\n// returns pointer to 16 bytes of memory\npHash = compute_hash( pData, nDataLength ); 4-\n// now test each bit\nwhile ( nPhaselndex < m nPhases )\ncompute_hash will always\nreturn the same 16 bytes of\ndata when called with the\nsame input parameters.\nnlndexValue = get_index_value( pHash, nPhaselndex, nBitlndexLength\n// if bit is not set, we have a miss so return false\nif ( !is_bit_index_set( nlndexValue ) ) return( false );\nnPhase!ndex++; \n*s.\n// all bits are set so we have a probably hit.\nreturn( true );\nReturn false as soon as we\nfind a false bit. At this point,\nthe expensive function has\ndefinitely not been previously\nstored.\nFIGURE 1.20.2 Basic use of a Bloom Filter.\n",
      "content_length": 1901,
      "extraction_method": "Direct"
    },
    {
      "page_number": 135,
      "chapter": null,
      "content": "Section 1 General Programming\n(N) and the more phases, the less likely a false positive response will occur. Bloom\nasserted that the optimum performance of this algorithm occurs when saturation of\nthe bit array is 50 percent. Statistically, the chance of a false positive can be deter-\nmined by taking the array saturation and raising it to the power of the number of\nphases. Other equations are available to tune the Bloom filter algorithm.\nThe equation to calculate the percentage of false positives is:\npercent_false_pdsitive = saturationnumb\"-°f-fhases\nor expressed as a function of percent_false_positive:\nnumber_of_j>hases \n= Logsaturation(percentjalse_fositive)\nBy assuming that the Bloom Filter Array is operating at optimum capacity of 50-\npercent saturation, Table 1 .20. 1 can be computed from the preceding formulas.\nFor example, if we want the false positive rate below half a percent (0.5 percent),\neight phases must be used, which will return a worst-case scenario of 0.39-percent\nfalse positives.\nNext, we calculate the Bloom Filter Array bit size.\narray_bit_size = ( number_of_phases * max_stored_input\nThe array_bit_size is usually rounded up to the nearest value where array_bit_size\ncan be expressed as 2 to the power of an integer.\narray _bit_size = .2*\nFinally, compute the index_bit_size from the array_bit_size.\narray <_bit_size = 2>ndex-bit-\"z*\nTable 1.20.1 Percentage of False Positives Based on Number of Phases Used\npercent_false_positive \nnumber_of_phases\n50.00%\n25.00%\n12.50%\n6.13%\n3.13%\n1.56%\n078%\n0.39%\n",
      "content_length": 1535,
      "extraction_method": "Direct"
    },
    {
      "page_number": 136,
      "chapter": null,
      "content": "1.20 Using Bloom Filters to Improve Computational Performance\n139\nExample 2\nSuppose we want to store a maximum of 9000 expensive function parameters\nwith at least 95-percent accuracy when the Bloom Filter Array test returns true. From\nTable 1.20.1, we can determine that five phases will be necessary to obtain an accu-\nracy of equal to or greater than 95 percent and a false positive of less than or equal to\n5 percent.\n5 phases * 9000 expensive function parameters / -ln(0.5) = 64,921 bits\nRounding up to the nearest 2n gives us 64K bits (8K bytes), and because 216 =\n64K, the index_bit_size will be 16 bits.\nFinal Notes\nOne way to improve performance is to use an exception list to prevent executing\nthe expensive function, as Bloom did in his algorithm. An exception list contains all\nof the false positive cases that can be returned from testing a Bloom Filter. This can be\ncomputed at parameter storage or dynamically when false positives are detected (Fig-\nure 1.20.3).\nAnother way to improve performance is to dynamically build a Bloom Filter\nArray. If the range of expensive function parameters is too great, Bloom Filters can be\ncalculated dynamically and optimized for repetitive calls to test the bit array. By\ndynamically building a Bloom Filter Array, the commonly tested expensive function\nparameters are calculated once, and untested function parameters do not waste space\nin the bit array.\nStandard Bloom Filter Test Code\nif ( test_bloom_data(c ) )\nboolean bSuccess = false;\nif ( in_exception_list ( c ) ) return ( bSuccess ) ; f*\nbSuccess = expensive_f unction (c ) ;\nif ( ibSuccess ) add_to_excepti\nreturn ( bSuccess ) ;\nelse\nif ( expensive_f unction (c ) )\nstore_bloom_data ( c ) ;\nreturn true;\nreturn false;\n/ \ni \n-.\nOptional Code\nException List Test\nDynamically computed\nException List\nDynamically computed\nBloom Filter\nFIGURE 1.20.3 \nBloom Filter configurations.\n",
      "content_length": 1886,
      "extraction_method": "Direct"
    },
    {
      "page_number": 137,
      "chapter": null,
      "content": "140 \nSection 1 General Programming\nHere are some interesting Bloom Filter characteristics:\n• Two Bloom Filter Arrays can be merged together by bitwise ORing them.\n• Bloom Filter Arrays can be shared among parallel clients.\n• Optimized Bloom Filter Arrays are not compressible.\n• Underpopulated Arrays are very compressible.\n• Memory corruption in the array can be mended by setting unknown bits to true.\nConclusion\nBloom Filters offer a method of improving performance of repeatedly called expensive\nfunctions at the expense of memory. While this method has been documented for a\nlong time, it remains a relatively unused technique, although exceptions exist, such as\nBloom Filter usage in the very popular Web-caching program Squid (www.squid-\ncache.org/) by Duane Wessels. Adding a Bloom Filter algorithm to a program can\nusually be done in less that 20K bytes of code. As with most performance-enhancing\ntricks, it is a good idea to add Bloom Filters to a project during the optimization stage,\nafter the main functionality is finished.\nReferences\n[BeachOl] \nBeach Software, \n\"Bloom Filters,\" available online at http://\nbeachsoftware.com/bloom/, May 10, 2000.\n[RSA01] RSA Security, \"What Are MD2, MD4, and MD5,\" available online at\nwww.rsasecurity.com/rsalabs/faq/3-6-6.html, March 4, 2001.\n[FlipcodeOl] Flipcode, \"Coding Bloom Filters,\" available online at \"www.flipcode\n.com/tutorials/tut_bloomfilter.shtml, September 11, 2000.\n[Bloom70] Bloom, Burton H., \"Space/Time Trade-Offs in Hash Coding with Allow-\nable Errors,\" Communications of the ACM, Vol. 13, No.7 (ACM July 1970): pp.\n422-426.\n",
      "content_length": 1597,
      "extraction_method": "Direct"
    },
    {
      "page_number": 138,
      "chapter": null,
      "content": "1.21\n3ds max Skin Exporter and\nAnimation Toolkit\nMarco Tombesi\ntombesi@infinito.it\nW\ne have seen wonderful special effects in modern films that have taken glorious\nmonsters such as dinosaurs and made them move smoothly. We know how\nthey did it (using software such as LightWave, 3ds max, Maya, etc.), but how do we\nuse the same animation technology for our games?\nThis gem is intended as an introduction to a full toolset for that purpose, starting\njust after the creation of the animated character in 3ds max (and Character Studio),\nand ending with that object smoothly animating in a game's real-time scenes. Along\nthe way, it passes through the export plug-in and is stored in a custom data format. In\nthis gem, we will go into depth only about the export aspect; the rest is well explained\nby the code on the accompanying CD.\nLet's talk about the necessary steps:\n1. The animation is done with 3ds max 3.1 (hereafter simply called MAX) and\nCharacter Studio 2.2, using Biped and/or bones and the Physique modifier. It\nshould be noted that although newer versions of these tools will become\navailable, the algorithms required for any new versions should be similar.\n2. The export plug-in creates a custom format file (.MRC), which consists of:\n• Mesh information (vertices, normals).\n• Skeletal structure (the bone tree).\n• Influence values (weighting) of each bone to vertices of the mesh (one\nvertex may be influenced by multiple bones).\n• Bone animation: For each bone, this consists of a set of translation and\nrotation keys (using quaternions), including the exact time in millisec-\nonds from the animation start to when the transformation should be\nperformed.\n3. To read the .MRC file, we have a reusable DLL available, provided with full\nsource code.\n4. The Tenderer interpolates (linearly or better) between the sample keys and\ncalculates the current transformation matrix to be applied to each bone.\n141\n",
      "content_length": 1915,
      "extraction_method": "Direct"
    },
    {
      "page_number": 139,
      "chapter": null,
      "content": "142 \nSection 1 General Programming\nThis is done using the time elapsed from the animation start, obtaining a\nsmooth and non-hardware-dependent animation.\n5. At each frame, the Tenderer recalculates the position of each vertex and its\nnormal. The calculation is based on the current transformation matrix and\ninfluence value that each bone has on a particular vertex. Most matrix oper-\nations can be done using the graphics hardware transformation and lighting\nfeatures if they exist (for example, on the GeForce and Radeon cards).\nThe process of exporting the animation data with a plug-in for MAX is not well\ndocumented. While there are many Web pages covering skinning techniques, few\nactually address the issue of exporting the data. Read and study the source code as\nwell as all Readme.txt files in the project directories for this gem on the CD. More\ninformation is also available on the authors Web page [TombesiOl], where updates\nfor MAX 4 will be available when it is released.\nThis gem is based on a hierarchical bone structure: a bone tree or a Biped, created\nusing Character Studio 2.2. Build a low polygon mesh (about 5000 triangles). The\nmesh should be a single selectable object in MAX. Deform the mesh using the\nPhysique modifier, based on the Biped previously created. The character animation\nshould be created on the Biped.\nExporting\nFirst, we need a file format specification.\nThe MRC File Format\nThis is a simple file format for the purposes of this gem. It supports normals, bones,\nvertex weights, and animation keys. See Figure 1.21.1 for a self-explanatory\nschematic, and check the code on the CD for technical clarification.\nExporting to MRC with the MAX SDK\nIf you are new to plug-in development and don't know how MAX works, be\nsure to refer to the MAX SDK documentation. In particular, study the fol-\nlowing sections before proceeding:\n• DLL, Library Functions, and Class Descriptors\n• \nFundamental Concepts of the MAX SDK\n• Must Read Sections for All Developers\n• Nodes\n• \nGeometry Pipeline System\n• Matrix Representations of 3D Transformations\n",
      "content_length": 2072,
      "extraction_method": "Direct"
    },
    {
      "page_number": 140,
      "chapter": null,
      "content": "FILE\nVSTART/\nboneOfs\nFILE\nEND\n£\nO\nCO\nCD\nI\n43\n(G\nT3\nLUzo\nCO\n}\nvertCnt\nnormCnt\nfaceCnt\nt_hd\nchildCnt\ninfluencedVertexCnt\nkeyCnt\nboneCnt\nFIGURE 1.21.1 \nMRC file format description.\n143\n",
      "content_length": 182,
      "extraction_method": "Direct"
    },
    {
      "page_number": 141,
      "chapter": null,
      "content": "144 \nSection 1 General Programming\nWorking with Nodes\nIn our export plug-in, we must derive a class from SceneExport and implement some\nvirtual methods, one of which is the main export routine.\nclass MRCexport : public SceneExport {\npublic:\n// Number of extensions supported\nint ExtCount() \n{return 1;}\n// Extension (\"MRC\")\nconst TCHAR * Ext (int n) \n{return _T(\"MRC\");}\n// Export to an MRC file\nint DoExport( const TCHAR *name,\nExplnterface *ei,\nInterface *i,\nBOOL \nsuppressPrompts=FALSE,\nDWORD options=0);\n//Constructor/Destructor\nMRCexport () ;\n-MRCexport();\nAccessing scene data requires an Interface passed by MAX to the main export rou-\ntine (the entry point of the plug-in). For every object in MAX, there is a node in the\nglobal scene graph, and each node has a parent (except RootNode) and possibly some\nchildren. We can access the root node and then traverse the hierarchy, or we can\ndirectly access a node if the user has selected it in MAX before exporting.\nINode* pNode = i->GetSelNode(0) ;\nINode* const pRoot = i->GetRootNode() ;\nTo navigate the node structure, we have these methods:\nInt count = pNode->NumberOfChildren() ;\nINode* pChNode = pNode->GetChildNode(i) ;\nA node could represent anything, so we need to discriminate among object types\nvia the node's class identifier (Class_ID or SuperClassID), and then appropriately cast\nthe object. For our purposes, we need to check if a node is a geometric object (a mesh)\nor a bone (a Biped node or a bone).\nbool IsMesh( INode *pNode)\n{\nif(pNode == NULL) return false;\nObjectState os = pNode->EvalWorldState(0) ;\nif(os.obj->SuperClassID() == GEOMOBJECT_CLASS_ID)\nreturn true;\nreturn false;\n",
      "content_length": 1654,
      "extraction_method": "Direct"
    },
    {
      "page_number": 142,
      "chapter": null,
      "content": "1.21 3ds max Skin Exporter and Animation Toolkit \n145\nbool IsBone(INode *pNode)\n{\nif(pNode == NULL)return false;\nObjectState os = pNode->EvalWorldState(0) ;\nif (los.obj) return false;\nif(os.obj->ClassID() == Class_ID(BONE_CLASS_ID, 0))\nreturn true;\nif(os.obj->ClassID() == Class_ID(DUMMY_CLASS_ID, 0))\nreturn false;\nControl *cont = pNode->GetTMController() ;\n//other Biped parts\nif( COnt->ClassID() == BIPSLAVE_CONTROL_CLASS_ID ||\n//Biped root \"Bip01\"\nCOnt->ClassID() == BIPBODY_CONTROL_CLASS_ID\n) return true;\nreturn false;\nThe previous example explains how to navigate MAX's nodes and check what\nthey represent. Once we get a mesh node, we need to acquire the desired vertex data.\nGetting Mesh Data\nFor convenience later on, we'll store all vertex data in global coordinate space. MAX\nobject coordinates are in object space, so we need a transformation matrix to be\napplied to each vertex and normal of the mesh.\nWe can grab this global transformation matrix at any time during the animation\nusing GetObjectTM(TimeValue time). This matrix is used to transform vectors from\nobject space to world space and could be used, for example, if we want to get the\nworld space coordinate of one mesh vertex. We could do this by taking the vertex\ncoordinate in object space and multiplying it (post-multiply in MAX) by the matrix\nreturned from this method. We are interested in mesh data at the animation start, so\nTimeValue is zero.\nMatrix3 tm = pNode->6etObjectTM(0)\nMAX uses row vector 1x3 and 4x3 matrices, so to transform a vector, we\nmustpremultiply it by the matrix.\nMart\nVertices and other data are not statically stored, but dynamically calculated each\ntime. To access data, we must first perform the geometry pipeline evaluation, specify-\ning the time at which we want to get the object state.\n",
      "content_length": 1795,
      "extraction_method": "Direct"
    },
    {
      "page_number": 143,
      "chapter": null,
      "content": "146 \nSection 1 General Programming\nMAX has a modifier stack system, where every object is the result of a modifica-\ntion chain. Starting from a simple parametric primitive (such as a box) that is the base\nobject, the final object is built, applying modifiers in sequence along the stack. This is\nthe object pipeline and we will work with the result. The resulting object is a Derived-\nObject and has methods to navigate the stack of modifiers.\nTo get the result at a specified animation time, we must first retrieve an Object-\nState, which is done by invoking the method EvalWorldState on the node. This makes\nMAX apply each modifier in the pipeline from beginning to end.\nObjectState os = pNode->EvalWorldState(0);\nObjectState contains a pointer to the object in the pipeline and, once we have this\nobject, we can finally get the mesh data. To do this, we must cast the generic object to\na geometric one, which has a method to build a mesh representation.\nMesh& mesh = *(((GeomObject*)os.obj)->GetRenderMesh(0, pNode, ...));\nNow it is easy to access the mesh members and finally put vertices, faces, and normals\nin memory, ready to be written to a file. These methods are available to accomplish this:\nMesh::getNumVerts(), Mesh::getNumFaces(), Mesh::getVert(i), anAMesh::getNormal(i).\nListing 1.21.1 illustrates how to export mesh data to a file.\nGetting the Bone Structure\nNow we need a way to write the skeleton's hierarchical structure to an output data file.\nStarting from the root node, we traverse depth-first through the tree, and for each\nbone, we need to get several things. First, we assign an index to any direct child and to\nthe bone's parent, and then we grab the bone orientation matrix.\ntm = pNode->GetNodeTM(0);\ntm.Invert();\nAlthough very similar, the preceding matrix isn't the object matrix, but is\nrelated to the node's pivot point, which may not be the object's origin. Check\n3^,, \nwith the SDK documentation to find a precise description. We will use this\nMOTt \n• \nr \ni \n/ \n, , \n, \n, i\nmatrix to transform every mesh vertex from world space to related bone space,\nso it can move with the bone. Since we have to multiply any vertex by the\ninverse of this matrix, we can invert it now and save rendering time.\nGetting the Bone Influences\nNow we are at the most exciting part of this gem: getting the vertex bone assignment\nand influence value (weighting). The weighting is important when two or more bones\ninfluence the same vertex and the mesh deformation depends on both (see [Wood-\nlandOO] for the theory). These assignments should be done using the Physique modi-\nfier in Character Studio 2.2. Note to the reader: Study the Phyexp.h header that comes\nwith Character Studio for modifier interface help.\n",
      "content_length": 2726,
      "extraction_method": "Direct"
    },
    {
      "page_number": 144,
      "chapter": null,
      "content": "1.21 3ds max Skin Exporter and Animation Toolkit \n147\nFirst, we must find the Physique modifier on the object's node that we wish to\nexport (this is the same node we used earlier to get the mesh vertex data). We do this\nby accessing the referenced DerivedObject and then scanning each applied modifier on\nthe stack until we find the Physique modifier (using a Class_ID check).\nModifier* GetPhysiqueMod(INode *pNode)\n{\nObject *pObj = pNode->GetObjectRef();\nif(lpObj) return NULL;\n// Is it a derived object?\nwhile(pObj->SuperClassID() == GEN_DERIVOB_CLASS_ID)\n{\n// Yes -> Cast\nIDerivedObject *pDerivedObj =\nstatic_cast<IDerivedObject*>(pObj);\n// Iterate over all entries of the modifier stack\nint ModStacklndex = 0;\nwhile(ModStacklndex < pDerivedObj->NumModifiers())\n{\n// Get current modifier\nModifier* pMod = pDerivedObj->\nGetModifier(ModStacklndex);\n//Is this Physique?\nif(pMod->ClassID() ==\nClass_ID(PHYSIQUE_CLASS_ID_A,\nPHYSIQUE_CLASS_ID_B))\nreturn pMod;\n// Next modifier stack entry\nModStackIndex++;\n}\npObj = pDerivedObj->GetObjRef();\n}\n// Not found\nreturn NULL;\n}\nNow we enter the Bone assignment phase (see Listing 1.21.2; a code overview\nfollows). Once we have the Physique modifier, we get its interface (IPhysiqueExpori)\nand then access the Physique context interface (IPhyContextExporf) for the object.\nThis owns all of the methods with which we need to work. Each vertex affected by a\nmodifier has an interface IPhyVertexExport. Grab this interface to access its methods,\ncalling GetVertexInterface(i) on the Physique context interface.\nWe must check to see if a vertex is influenced by one or more bones (RIGID_TYPE\nor RIGID_BLENDED_TYPE, respectively). In the former case, the weight value is 1 and we\nhave to find just a single bone (calling GetNode on the i-th vertex interface). In the lat-\nter case, we have to find every bone assigned to the vertex, and for each bone we must\n",
      "content_length": 1893,
      "extraction_method": "Direct"
    },
    {
      "page_number": 145,
      "chapter": null,
      "content": "Section 1 General Programming\nget its proper weight value by invoking GetWeightQ) on the i-th vertex interface,\nwhere j is the j-th bone influencing it. In addition, note that at the end, we must\nremember to release every interface.\nNow we are ready for the last phase: bone animation data acquisition.\nGetting Bone Animation Keys\nThis is a simple step. At selected time intervals (default 100 milliseconds), grab the\ntransformation matrix of each bone. In the MAX SDK, time is measured internally in\n\"ticks,\" where there are 4800 ticks per second, so we must perform a conversion.\nThen we use this method:\ntm = pNode->GetNodeTM(timeTicks);\nIt's more efficient to not store the complete matrix (16 floats), but instead only\nthe translation (3 floats) and rotation data (4 floats), so we extract a position vector\nand a unit quaternion from the matrix.\nPoints pos = tm.GetTrans();\nQuat quat(tm);\nOnce we have all the data collected in memory, we store everything to disk using\nthe MRC file format. Now it is time to see how to use it all to perform smooth ani-\nmation in our games.\nPut It to Use: The Drawing Loop\nIn our application, for each frame displayed, we should perform the following steps in\nsequence.\nGet the Exact Time\nTo make the animation very smooth and not processor dependent, getting the system\ntime is necessary. We update the skeleton structure by cycling through the bone tree\nand, for each bone, work out the current transformation matrix by linearly interpo-\nlating between two sample keys. To find out which sample keys to interpolate\nbetween, we require the current real animation time (in milliseconds) from animation\nstart.\nMoving the Skeleton\nWe determine actual bone position and rotation by linear (or better) interpolation\nand by quaternion interpolation (SLERP or better) between selected sample keys\n(sample times should enclose the current time). Then, given these data, you can build\nthe current bone animation matrix from the translation and rotation. The math\ninvolved, especially in the quaternion calculations, is explained well in the previous\nGame Programming Gems book [ShankelOO]. To take better advantage of graphics\nhardware, we perform all matrix calculations using OpenGL functions. This way we\n",
      "content_length": 2240,
      "extraction_method": "Direct"
    },
    {
      "page_number": 146,
      "chapter": null,
      "content": "1.21 3ds max Skin Exporter and Animation Toolkit \n149\ncan exploit any advanced hardware features such as transformation and lighting, and\nperformance will be much better!\nRecalculate the Skin\nOnce the skeleton is moved, it is time to deform the mesh accordingly, with respect to\nvertex weight assignments. See [WbodlandOO] for a good overview of this topic. It is\nconvenient to check the vertices in bone-major order, traversing depth-first through\nthe bone tree and doing the following passes for each bone. For each vertex influenced\nby the bone, we refer it to the bone's local coordinate system (multiplying by the bone\ninverse orientation matrk), and then transform it via the current bone animation\nmatrk. Then, we multiply the vertex coordinates by the influence value (weight) this\nbone exerts on it. We add the result to the corresponding vertex value stored in a tem-\nporary buffer. Now this buffer contains the current vertex coordinates for the skin, at\nthis point in the animation. To finish, we draw the computed mesh using vertex\narrays (or better) to gain even more performance.\nListing 1.21.1: Exporting the Mesh to a File\nbool ExportMesh (iNode* pNode, FILE *out)\n{\nMRCmesh_hdr mHdr;\nMatrixS tm = pNode->GetObjectTM(0) ;\nObjectState os = pNode->EvalWorldState(0) ;\nint needDelete;\nMesh& mesh = *(( (GeomObject*) os.obj )->GetRenderMesh (\n0, pNode, ...));\n// write the mesh vertices\nmHdr.vertCnt = mesh.getNumVerts() ;\nforfint i = 0; i < mHdr.vertCnt; i++)\n{\nPoints pnt = mesh.getVert(i) * tm; \n//premultiply in MAX\n// write vertex normals\nmesh.buildNormalsO ;\nmHdr.normCnt = mesh.getNumVerts() ;\nfor(i = 0; i < mHdr.normCnt;\nPoints norm = Normalize(mesh.getNormal(i) ) ;\n// build and write faces\nmHdr.faceCnt = mesh.getNumFaces() ;\nfor(i = 0; i < mHdr.faceCnt;\n",
      "content_length": 1779,
      "extraction_method": "Direct"
    },
    {
      "page_number": 147,
      "chapter": null,
      "content": "150 \nSection 1 General Programming\nMRCface_hdr fHdr;\nfHdr.vert[0] = mesh.faces[i].v[0];\nfHdr.vert[1] = mesh.faces[i].v[1];\nfHdr.vert[2] = mesh.faces[i].v[2];\nListing 1.21.2: Reading Bone Assignments\nbool GetPhysiqueWeights(INode *pNode, INode *pRoot,\nModifier *pMod, BoneData_t *BD)\n{\n// create a Physique Export Interface for given Physique Modifier\nIPhysiqueExport *phylnterface = (IPhysiqueExport*)\npMod->Get!nterface(I_PHYINTERFACE);\nif (phylnterface)\n{\n// create a ModContext Export Interface for the specific\n// node of the Physique Modifier\nIPhyContextExport *modContext!nt = (IPhyContextExport*)\nphyInterface->GetContext!nterface(pNode) \n;\n// needed by vertex interface (only Rigid supported by now)\nmodContext!nt->ConvertToRigid(TRUE) ;\n// more than a single bone per vertex\nmodContextInt->AllowBlending(TRUE) ;\nif (modContextlnt)\n{\nint totalVtx = modContextlnt ->GetNumberVertices() ;\nfor(int i = 0; i < totalVtx; i\nIPhyVertexExport *vtxlnterface = (IPhyVertexExport*)\nmodContext!nt->GetVertexInterface(i) ;\nif (vtxlnterface)\n{\nint vtxType = vtxInterface->GetVertexType() ;\nif(vtxType == RIGID_TYPE)\n{\nINode *boneNode = ((IPhyRigidVertex*)vtxInterface)\n-> GetNode();\nint boneldx = GetBoneIndex(pRoot, boneNode);\nInsert\n// Build vertex data\nMRCweightJidr wdata;\nwdata.vertldx = i;\nwdata. weight = 1 .Of ;\n//Insert into proper bonedata\nBD[ boneldx] . weight sVect .push_back( wdata) ;\n// update vertexWeightCnt for that bone\n",
      "content_length": 1433,
      "extraction_method": "Direct"
    },
    {
      "page_number": 148,
      "chapter": null,
      "content": "1.21 3ds max Skin Exporter and Animation Toolkit \n151\nBD[boneIdx] .Hdr.vertexCnt\n= BD[boneIdx] .weightsVect.size() ;\n}\nelse if(vtxType == RIGID_BLENDED_TYPE)\n{\nIPhyBlendedRigidVertex *vtxBlended!nt =\n(IPhyBlendedRigidVertex*)vtxInterface;\nfor(int j = 0; j < vtxBlendedInt->GetNumberNodes()\nINode *boneNode = vtxBlendedInt->GetNode(j) ;\nint boneldx = GetBoneIndex(pRoot, boneNode);\n// Build vertex data\nMRCweightJidr wdata;\nwdata.vertldx = i;\nwdata. weight = vtxBlendedInt->GetWeight(j) ;\n// check vertex existence for this bone\nbool notfound = true;\nfor (int v=0; notfound\n&& v < BD[boneIdx] .weightsVect.size() ;\n// update found vert weight data for that\n// bone\nif ( BDfboneldx] .weightsVectfv] .vertldx\n== wdata.vertldx )\n{\nBD[boneIdx] .weightsVect[v] .weight\n+= wdata. weight;\nnotfound = false;\nif (notfound)\n{\n// Add a new vertex weight data into proper\n// bonedata\nBD[boneIdx] .weightsVect.push_back(wdata) ;\n// update vertexweightCnt for that bone\nBD[boneIdx] .Hdr.vertexCnt\n= BD[boneIdx] .weightsVect.size() ;\nphyInterface->ReleaseContextInterface(modContextInt) ;\n}\npMod->Release!nterface(I_PHYINTERFACE, phylnterface) ;\n}\nreturn true;\n",
      "content_length": 1145,
      "extraction_method": "Direct"
    },
    {
      "page_number": 149,
      "chapter": null,
      "content": "152 \nSection 1 General Programming\nReferences\nSDK documentation file:\n[DiscreetOO] Max SDK Plug-in development documentation: SDK.HLP\nWeb links:\n[TombesiOl] Tombesi, Marco's Web page: http://digilander.iol.it/baggior/\nBooks:\n[WoodlandOO] Woodland, Ryan, \"Filling the Gaps—Advanced Animation Using\nStitching and Skinning,\" Game Programming Gems. Charles Raver Media 2000;\npp. 476-483.\n[ShankelOO] Shankel, Jason, \"Matrix-Quaternion Conversions\" and \"Interpolating\nQuaternions,\" Game Programming Gems. Charles River Media 2000; pp.\n200-213.\n",
      "content_length": 539,
      "extraction_method": "Direct"
    },
    {
      "page_number": 150,
      "chapter": null,
      "content": "1.22\nUsing Web Cameras in\nVideo Games\nNathan d'Qbrenan, Firetoad Software\nnathand@firetoads.com\nI\nost games nowadays have multiplayer capabilities; however, the only interaction\nthat goes on among online gamers is the occasional text message. Imagine hav-\ning the ability to see the expression on your opponent's face when you just pass them\nbefore reaching the finish line, or when they get fragged by your perfectly placed\nrocket. Web cams allow you that functionality, and with high-speed Internet slowly\nbecoming standard, it's becoming feasible to send more data to more clients.\nThis gem demonstrates a straightforward approach to implementing Web cam\nmethodologies into a game. We'll be using Video for Windows to capture the Web\ncam data, so Windows is required for the Web cam initialization function. We will\ncover numerous approaches for fast image culling, motion detection, and a couple of\nimage manipulation routines. By die end, we will have a fully functional Web cam\napplication tliat can be run and interacted widi at reasonable frame rates.\nInitializing the Web Cam Capture Window\nThe following code demonstrates how to use Video for Windows to set up a Web\nC^^l>3 \ncamera window in an application. Note to die reader: when dealing with video drivers\nONTHICD \nfrom hardware vendors: You can never have too much error checking and handling\ncode (review source code on CD for a more thorough implementation).\n// Globals\nHWND hWndCam = NULL;\nBOOL cam_driver_on = FALSE;\nint wco_cam_width = 160, wco_cam_height = 120;\nint wco_cam_updates = 400, wco_cam_threshold = 120;\n// WEBCAM_INIT\nvoid webcam_init(HWND hWnd)\n{\n// Set the window to be a pixel by a pixel large\nhWndCam = capCreateCaptureWindow(appname,\nWS_CHILD | WS_VISIBLE |\nWS_CLIPCHILDREN |\nWS_CLIPSIBLINGS,\n153\n",
      "content_length": 1784,
      "extraction_method": "Direct"
    },
    {
      "page_number": 151,
      "chapter": null,
      "content": "154 \nSection 1 General Programming\n0,0,\n1,1,\nhwnd,\n0);\nif(hwndCam)\n{\n// Connect the cam to the driver\ncam_driver_on = capDriverConnect(hWndCam, 1);\n// Get the capabilities of the capture driver\nif(cam_driver_on)\n{\ncapDriverGetCaps(hWndCam, &caps, sizeof(caps));\n// Set the video stream callback function\ncapSetCallbackOnFrame(hWndCam, webcam_callback);\n// Set the preview rate in milliseconds\ncapPreviewRate(hWndCam, wco_cam_updates);\n// Disable preview mode\ncapPreview(hWndCam, FALSE);\n// Initialize the bitmap info to the way we want\ncapwnd.bmiHeader.biSize = sizeof(BITMAPINFOHEADER);\ncapwnd.bmiHeader.biWidth \n= wco_cam_width;\ncapwnd.bmiHeader.biHeight = wco_cam_height;\ncapwnd.bmiHeader.biPlanes = 1;\ncapwnd.bmiHeader.biBitCount = 24;\ncapwnd.bmiHeader.bicompression = BI_RGB;\ncapwnd.bmiHeader.biSizelmage =wco_cam_width*wco_cam_height*3;\ncapwnd.bmiHeader.biXPelsPerMeter = 100;\ncapwnd.bmiHeader.biYPelsPerMeter =100;\nif(capSetVideoFormat(hWndCam, icapwnd,\nSizeof(BITMAPINFO)) == FALSE)\n{\ncapSetCallbackOnFrame(hwndCam, NULL);\nDestroyWindow(hWndCam);\nhWndCam = NULL;\ncam_driver_on = FALSE;\n}\nelse\n{ // Assign memory and variables\nwebcam_set_vars();\n{\nglGenTextures(1, &webcam_tex.gl_bgr);\nglBindTexture(GL_TEXTURE_2D, webcam_tex.gl_bgr);\nglTex!mage2D(GL_TEXTURE_2D, 0, 3, webcam_tex.size,\nwebcam_tex.size, 0, GL_BGR_EXT,\nGL_UNSIGNED_BYTE, webcam_tex.bgr);\nglTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_S,\nGL_REPEAT);\n",
      "content_length": 1422,
      "extraction_method": "Direct"
    },
    {
      "page_number": 152,
      "chapter": null,
      "content": "1.22 Using Web Cameras in Video Games\n155\nglTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_T,\nGL_REPEAT);\nglTexParameterf(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER,\nGLJ.INEAR);\nglTexParameterf(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER,\nGL_LINEAR);\nglGenTextures(1, &webcam_tex.gl_grey);\nglBindTexture(GL_TEXTURE_2D, webcam_tex.gl_grey);\nglTex!mage2D(GL_TEXTURE_2D, 0, 1, webcam_tex.size,\nwebcam_tex.size, 0, GLJ.UMINANCE,\nGL_UNSIGNED_BYTE, webcam_tex.greyscale);\nglTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_S,\nGL_REPEAT);\nglTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_T,\nGL_REPEAT);\nglTexParameterf(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER,\nGL_LINEAR);\nglTexParameterf(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER,\nGL_LINEAR);\nelse\n{\ncam_driver_on = FALSE;\nThe above function retrieves the handle to the Web cam window we're capturing\nfrom through the function capCreateCaptureWindow(). We then initialize it with win-\ndows properties such as its size, and whether it should be visible. In our case, we do\nwant it to be visible; however, we're only going to set the window to a 1x1 pixel, so it's\nbasically invisible. This is required because we don't actually want to display the image\nsubwindow, but we want to receive the data updates from Windows through the call-\nback function.\nWe then retrieve driver information, set the callback function (more on this\nlater), the number of times per second we want to refresh the Web cam, and then reset\nall our variables. The driver is then tested to see if it can handle returning the stan-\ndard bitmap information in which we are interested. Upon success, we initialize all\nthe memory for all our movement buffers, as well as the OpenGL texture. We pull a\nlittle trick when deciding how big to make this texture, which will come in handy\nlater on. Based on whatever height we set up our Web cam window to be, we find and\nallocate our memory to the next highest power of 2. Even though we are allocating a\nbigger buffer than the Web cam image, we save ourselves an expensive texture resize\noperation, by just doing a memcpyQ right into the larger buffer — at the cost of some\nsmall precision loss in the Web cam image.\n",
      "content_length": 2144,
      "extraction_method": "Direct"
    },
    {
      "page_number": 153,
      "chapter": null,
      "content": "156 \nSection 1 General Programming\nRetrieving Data\nOnce we have our video window initialized, we need a way to retrieve the data from\nthe Web cam every frame. To let Windows know which callback function it should\nsend the data to, we must call capSetCallbackOnFrameQ with the address of the call-\nback function. When Windows decides it's time to update the Web cam, it will pass\nus the bitmap information inside the VIDEOHDR structure.\nIn our case, we'll make the callback function process all the Web cam data to\ndecide if we want to create a texture out of it. We can pass all of that data to the web-\ncam_calc_movement () function for further processing, which will determine if enough\ndata has changed since die last frame, after which, we can update the texture.\n// WEBCAM_CALLBACK\n// Process video callbacks here\nLRESULT WINAPI webcam_callback(HWND hwnd, LPVIDEOHDR videojidr)\n{\n// Calculate movement based off of threshold\nif(webcam_calc_movement(video_hd r,\nwebcam_tex.delta_buffer,\nwco_cam_width,\nwco_cam_height,\nwebcam^tex.size,\nwco_cam_threshold))\n{\nwebcam_make_texture(videojidr, wco_cam_rendering);\n}\nreturn TRUE;\n}\nWindows defines the LPVIDEOHDR structure as:\ntypedef struct videohdr_tag\n{\nLPBYTE \nIpData; \n// pointer to locked data buffer\nDWORD \ndwBufferLength; // Length of data buffer\nDWORD \ndwBytesllsed; \n// Bytes actually used\nDWORD \ndwTimeCaptured; // Milliseconds from start of stream\nDWORD \ndwUser; \n// for client's use\nDWORD \ndwFlags; \n// assorted flags (see defines)\nDWORD \ndwReserved[4]; \n// reserved for driver\n} VIDEOHDR, NEAR *PVIDEOHDR, FAR * LPVIDEOHDR;\nWindows saves the Web cam data in the buffer called If Data. This is the primary\nvariable we are interested in, but dwTimeCaptured and some of the flags may prove\nuseful as well. Now that we've captured the data from the Web cam, let's test it to see\nif it's useful.\n",
      "content_length": 1852,
      "extraction_method": "Direct"
    },
    {
      "page_number": 154,
      "chapter": null,
      "content": "1.22 Using Web Cameras in Video Games \n157\nMotion Detection\nWe now want to weed out any unnecessary frames which have barely changed so we\ncan avoid unnecessary updates to our texture. Updating textures is a notoriously slow\noperation in a 3D API such as OpenGL.\nThe following source code compares delta buffers, and returns true or false if the\ngiven threshold has been breached. Note that returning early when the threshold has\nbeen exceeded could optimize this function further; however, that would hamper\nus from using the delta buffer later on. Ectosaver [FiretoadOO] uses these unsigned\nbytes of delta movement to calculate the amplitude of the waves it causes, and to\ndetermine when there is no one moving around.\n// GLOBALS\nunsigned char wco_cam_threshold=128; // This is a good amount (0-255)\n// WEBCAM_CALC_MOVEMENT\n// This is a simple motion detection routine that determines if\n// you've moved further than the set threshold\nBOOL webcam_calc_movement(LPVIDEOHDR video_hdr,\nunsigned char *delta_buff,\nint webcam_width, int webcam_height,\nint gl_size, unsigned char thresh)\n{\nunsigned char max_delta=0;\nint i=0, j=0;\nint length;\nunsigned char *temp_delta = (unsigned char *)malloc(\nsizeof(unsigned char)* webcam_width * webcam_height);\nlength = webcam_width * webcam_height;\nwebcam_tex.which_buffer = webcam_tex.which_buffer 7 0 : 1 ;\nif(!video_hdr->lpData)\nreturn FS_TRUE;\nfor(i=0; i<length; i++)\n{\n// Save the current frames data for comparison on the next frame\n// NOTE: Were only comparing the red channel (IpData is BGR), so\n//in theory if the user was in a solid red room, coated in red\n// paint, we wouldn't detect any movement....chances are this\n//isn't the case :) For our purposes, it this test works fine\nwebcam_tex.back_buffer[webcam_tex.which_buffer][i]\n= video_hdr->lpData[i*3];\n// Compute the delta buffer from the last frame\n// If it's the first frame, it shouldn't blow up given that we\n// cleared it to zero upon initialization\ntemp_delta[i] =\nabs(webcam_tex.back_buffer[webcam_tex.which_buffer][i] -\nwebcam_tex.back_buffer[!webcam_tex.which_buffer][i]);\n",
      "content_length": 2084,
      "extraction_method": "Direct"
    },
    {
      "page_number": 155,
      "chapter": null,
      "content": "158 \nSection 1 General Programming\n//Is the difference here greater than our threshold?\nif (temp_delta[i] > max_delta)\nmax_delta = temp_delta[i] ;\n// Fit to be inside a power of 2 texture\nfor(i=0; i<webcam_height ;\nmemcpy(&delta_buff [i*(gl_size)] ,\n&temp_delta[i*(webcam_width)] ,\nsizeof (unsigned char)*webcam_width) ;\nf ree(temp_delta) ;\nif(max_delta > thresh)\nreturn TRUE;\nelse\nreturn FALSE;\nManipulating Web Cam Data\nGet the BGR Pixels\nOnce we've performed all our testing and culling, we are ready to manipulate the data\nwe were sent from Windows. For this, we will simply copy the pixels from die\nVIDEOHDR data struct (the native format Windows returns is BGR) into a buffer\nthat we've allocated to have a power of 2. Note that this technique avoids resizing the\ntexture data's pixels, as it simply copies the pixels straight over, preserving the pixel\naspect ratio. The only drawback to this technique is that it will leave some empty\nspace in our texture, so we're left with a bar of black pixels at the top of the image. We\ncan eliminate that bar by manipulating texture coordinates (once mapped onto 3D\ngeometry) or resizing the texture.\n// WEBCAM_MAKE_BGR\nvoid webcam_make_bgr(unsigned char *bgr_tex, unsigned char *vid_data,\nint webcam_width, int webcam_height, int glsize)\n{\nint i;\nfor(i=0; i<webcam_height; i++)\n{\nmemcpy(&bgr_tex[i*(glsize*3)],\n&vid_data[i*(webcam_widtn*3)],\nsizeof(unsigned char)*webcam_width*3);\n",
      "content_length": 1430,
      "extraction_method": "Direct"
    },
    {
      "page_number": 156,
      "chapter": null,
      "content": "1.22 Using Web Cameras in Video Games \n159\nConvert to Grayscale\nOnce we've captured the BGR data, we could convert it to grayscale. This would result\nin an image that is one-third the size of our regular textures, which would be practical\nfor users who have slow Internet connections, but still want to transmit Web cam data.\nHere is a function that multiplies each RGB component in our color buffer by a\nscalar amount, effectively reducing all three color channels to one:\n// WEBCAM_MAKE_GREYSCALE\nvoid webcam_make_greyscale( unsigned char *grey,\nunsigned char *color, int dim)\n{\nint i, j;\n// Greyscale = RED * 0.3f + GREEN * 0.4f + BLUE * 0.3f\nfor(i=0, j=0; j<dim*dim; i+=3,\ngrey[j] = (unsigned char)float_to_int(0.30f * color[i] \n+\n0.40f * color [i+1] +\nO.SOf * color[i+2]);\nReal-Life Cartoons\nOnce we've successfully converted all our data to grayscale, we can manipulate the\ndata to draw the picture in a cartoon-like fashion. This method splits the image into\nfive different levels and six different colors, coloring different ranges of pixel values\nwith solid values. All we have to do is perform some simple comparisons and evaluate\neach pixel based on our heat intensity constants.\nThe final result is compared against a lookup from either the grayscale buffer or\nour delta buffer. If we want to see the image every frame (single buffer), we will need\nto compare against the grayscale. To give different results, we'll assign random color\nintensities for each pixel based on our heat intensity constants.\n// WEBCAM_INIT_CARTOON\nvoid webcam_init_cantoon(cartoon_s *cartoon_tex)\n{\nchar i;\nfor(i=0; i<3; i++)\n{\n// Pick random colors in our range\ncartoon_tex->bot_toll_col[i] = rand()%255;\ncartoon_tex->min_toll_col[i] = rand()%255;\ncartoon_tex->low_toll_col[i] \n= rand()%255;\ncartoon_tex->med_toll_col[i] = rand()%255;\ncartoon_tex->high_toll_col[i] = rand()%255;\ncartoon_tex->max_toll_col[i] = rand()%255;\ntfdefine MIN \nCAM \nHEAT \n50\n",
      "content_length": 1940,
      "extraction_method": "Direct"
    },
    {
      "page_number": 157,
      "chapter": null,
      "content": "160 \nSection 1 General Programming\ntfdefine LOW_CAM_HEAT \n75\n#define MED_CAM_HEAT 100\n#define HIGH_CAM_HEAT 125\n#define MAX_CAM_HEAT 150\n// WEBCAM_MAKE_CARTOON\nvoid webcam_itiake_cartoon( unsigned char *cartoon,\ncartoon_s cartoon_tex,\nunsigned char *data, int dim)\n{\nint i, j, n;\nfor(i=0, j=0; j<dim*dim; i+=3,\n{\nif(data[j] < MIN_CAM_HEAT)\nfor(n=0; n<3;\ncartoon[i+n] = cartoon_tex.bot_toll_col[n] ;\n}\nif(data[j] > MIN_CAM_HEAT && data[j] < LOW_CAM_HEAT)\nfor(n=0; n<3;\ncartoon [i+n] = cartoon_tex.min_toll col[n];\n}\nif(data[j] > LOW_CAM_HEAT && data[j] < MED_CAM_HEAT)\nfor(n=0; n<3;\ncartoon[i+n] = cartoon_tex.low_toll_col[n] ;\n}\nif(data[j] > MED_CAM_HEAT && data[j] < HIGH_CAM_HEAT)\nfor(n=0; n<3;\ncartoon[i+n] = cartoon_tex.med_toll_col[n] ;\n}\nif (data[ j] > HIGH_CAM_HEAT && data[j] < MAX_CAM_HEAT)\nfor(n=0; n<3;\ncartoon [i+n] = cartoon_tex.high_toll_col[n] ;\n}\nif(data[j] > MAX_CAM_HEAT)\nfor(n=0; n<3;\ncartoon[i+n] = cartoon_tex.max_toll_col[n] ;\nUploading the New Texture\nNow, all that's left is uploading the texture to OpenGL. The first step is to get the\ncolor values from Video for Windows. Once the new color values are calculated,\nwe can go on to converting it to grayscale, and then go on to our cartoon Tenderer.\nOnce all the image manipulation is finished, we call glTexSubImage2D() to get it into\nthe appropriate texture. It is then ready for use in a 3D application as a texture.\n",
      "content_length": 1394,
      "extraction_method": "Direct"
    },
    {
      "page_number": 158,
      "chapter": null,
      "content": "1.22 Using Web Cameras in Video Games \n161\n// WEBCAM_MAKE_TEXTURE\nvoid webcam_make_texture(LPVIDEOHDR video, webcam_draw_mode mode)\n{\n// Build the color first\nwebcam_make_bgr(webcam_tex.bgr,\nvideo->lpData,\nwco_cam_width,\nwco_cam_height ,\nwebcam_tex.size) ;\nif (mode == GREYSCALE || mode == CARTOON)\nwebcam_make_greyscale (webcam_tex . greyscale ,\nwebcam_tex.bgr, \nwebcam_tex.size) ;\n// Note: Could also pass in the delta buffer instead of\n// the greyscale\nif (mode == CARTOON)\nwebcam_make_cartoon (webcam_tex . bgr ,\nwebcam_tex . cartoon ,\nwebcam_tex. greyscale,\nwebcam_tex.size) ;\n// Upload the greyscale version to OpenGL\nif (mode == GREYSCALE)\n{\nglBindTexture(GL_TEXTURE_2D, webcam_tex.gl_grey) ;\nglTexSub!mage2D(GL_TEXTURE_2D, 0,0,0,\nwebcam_tex . size , webcam_tex . size ,\nGL_LUMINANCE,\nGL_UNSIGNED_BYTE, webcam_tex. greyscale) ;\n}\n// Upload the color version to OpenGL\nelse\n{\nglBindTexture(GL_TEXTURE_2D, webcam_tex.gl_bgr) ;\nglTexSub!mage2D(GL_TEXTURE_2D, 0,0,0,\nwebcam_tex . size , webcam_tex . size ,\nGL_BGR_EXT, GL_UNSIGNED_BYTE, webcam_tex.bgr) ;\nDestroy the Web Cam Window\nAfter we're done using the Web cam, we need to destroy the window and set our call-\nback function to NULL, so Windows knows to stop sending messages to it. In addi-\ntion, we must free up all the memory we previously allocated to our color, grayscale,\nand delta buffers.\n// WEBCAM_DESTROY\nvoid webcam_destroy(void)\n{\nif (cam_driver_on)\n",
      "content_length": 1420,
      "extraction_method": "Direct"
    },
    {
      "page_number": 159,
      "chapter": null,
      "content": "162 \nSection 1 General Programming\ncapSetCallbackOnFrame(hWndCam, NULL);\nDestroyWindow(hWndCam) ;\nhWndCam = NULL;\nif (webcam_tex . bgr)\nf ree(webcam_tex.bgr) ;\nif (webcam_tex . grayscale )\nfree(webcam_tex. grayscale) ;\nif (webcam_tex . delta_buf f er)\nf ree(webcam_tex.delta_buffer) ;\nif (webcam_tex.back_buffer[0] )\nf ree(webcam_tex.back_buffer[0]) ;\nif (webcam_tex.back_buffer[1 ] )\nf ree(webcam_tex.back_buffer[1 ] ) ;\nConclusion\nWeb cams have a lot of untapped potential that game developers may not realize.\nThey have the ability to be used as input devices, as in the way a mouse is used, by\ntracking color objects and translating their rotations from 2D to 3D [Wu99] . It's even\npossible to replace your standard mouse using a Web cam, by performing data\nsmoothing and color tracking algorithms on the input frames.\nReferences\nMicrosoft Developer Network Library http://msdn.microsoft.com/library/devprods/\nvs6/visualc/vcsample/vcsmpcaptest.htm.\n[FiretoadOO] Firetoad Software, Inc., Ectosaver, 2000 www.firetoads.com.\n[Wu99] Wu, Andrew, \"Computer Vision REU 99\" www.cs.ucf.edu/-vision/reu99/\nprofile-awu.html.\n",
      "content_length": 1118,
      "extraction_method": "Direct"
    },
    {
      "page_number": 160,
      "chapter": null,
      "content": "2.1\nFloating-Point Tricks:\nImproving Performance with\nIEEE Floating Point\nYossarian King, Electronic Arts Canada\nyking@ea.com\nOverview\nIntegers have fixed precision and fixed magnitude. Floating-point numbers have a\n\"floating\" decimal point and arbitrary magnitude. Historically, integers were fast and\nfloats were slow, so most game programmers used integers and avoided floats. Integer\nmath was cumbersome for general calculations, but the performance benefits were\nworth the effort. Hardware costs have come down, however, and todays PCs and\ngame consoles can do floating-point add, subtract, multiply, and divide in a few\ncycles. Game programmers can now take advantage of the ease of use of floating-point\nmath.\nAlthough basic floating-point arithmetic has become fast, complex functions are\nstill slow. Floating-point libraries may be optimized, but they are generally imple-\nmented for accuracy, not performance. For games, performance is often more impor-\ntant than accuracy.\nThis gem presents various tricks to improve floating-point performance, trading\naccuracy for execution speed. Table lookup has long been a standard trick for integer\nmath; this gem shows generalized linear and logarithmic lookup table techniques for\noptimizing arbitrary floating-point functions.\nThe following sections discuss:\n• The IEEE floating-point standard\n• Tricks for fast float/int conversions, comparisons, and clamping\n• A linear lookup table method to optimize sine and cosine\n• A logarithmic method to optimize square root\n• Generalized lookup table methods to optimize arbitrary floating-point functions\n• The importance of performance measurement\n167\n",
      "content_length": 1651,
      "extraction_method": "Direct"
    },
    {
      "page_number": 161,
      "chapter": null,
      "content": "168 \nSection 2 Mathematics\nIEEE Floating-Point Format\nThe IEEE standard for floating-point numbers dictates a binary representation and\nconventions for rounding, accuracy, and exception results (such as divide by zero).\nThe techniques outlined in this article rely on the binary representation, but are gen-\nerally not concerned with the rounding and exception handling. If a computer or\ngame console uses the standard binary representation, then these tricks apply, regard-\nless of whether the floating-point handling is fully IEEE compliant. The Pentium III\nStreaming SIMD Extensions (SSE) and PS2 vector unit both implement subsets of\nthe IEEE standard that do not support the full range of exception handling; however,\nsince the binary representation follows the standard, die tricks in this gem will work\nwith these instruction sets.\nThe IEEE standard represents floating-point numbers with a sign bit, a biased\nexponent, and a normalized mantissa, or significand. Single precision, 32-bit floating-\npoint numbers (a \"float\" in C) are stored as shown in Figure 2.1.1.\ns f i r f r ljeg fTijrnrri mm m m m |m m m m mm m m m mm m m m m\n31 30 \n\" \" \n23 22 \n~ \n\" \n\"' \n\" \n\" \n\" \n0\ns = sign\ne = biased exponent\nm = normalized mantissa\nfloating point number is s x 1 .m x 2'6-127)\nFIGURE 2.1.1 IEEE 32-bit floating-point format has a 1-bitsign, 8-bit exponent, and\n23-bit mantissa.\nThe exponent is stored as a positive number in biased form, with 127 added to\nthe actual exponent (rather than the more familiar two's complement representation\nused for integers). The mantissa is usually stored in normalized form, with an implied\n1 before the 23-bit fraction. Normalizing in this way allows maximum precision to be\nobtained from the available bits.\nA floating-point number thus consists of a normalized significand representing a\nnumber between 1 and 2, together with a biased exponent indicating the position of\nthe binary point and a sign bit. The number represented is therefore:\nn = sxl.mx2(e-127)\nFor example, the number -6.25 in binary is -110.01, or -1 X 1.1001 x 22. This\nwould be represented with s=l,e = 2+l 27= 10000001, m = [1.] 1001, as shown in\nFigure 2.1.2.\nSome additional \"magic values\" are represented using the exponent. When e =\n255, m encodes special conditions such as not-a-number (NaN), undefined result, or\npositive or negative infinity. Exponent e = 0 is used for denormalized numbers—\nnumbers so tiny that the range of the exponent overflows 8 bits.\n",
      "content_length": 2472,
      "extraction_method": "Direct"
    },
    {
      "page_number": 162,
      "chapter": null,
      "content": "2.1 Floating-Point Tricks: Improving Performance with IEEE Floating Point \n169\ns=1\n-6.25 decimal \n\"-110.01 binary \n* -1 x [1.]1001 x 22 \n+ 6 = 2 + 127 = 10000001\nm= 1001000...\nI\nFIGURE 2.1.2 The number -6.25 as stored in memory in 32-bit IEEE floating-point\nformat.\nDouble precision 64-bit floating-point numbers are stored using the same basic\nformat, but with 11 bits for the exponent and 52 for the significand. The exponent is\nbiased by 1023, rather than 127. Double precision numbers require twice the storage\nspace and may be slower to load from memory and to process. For these reasons, dou-\nble precision should generally be avoided in game code. This gem uses only single-\nprecision floats.\nFloating-Point Tricks\nBefore getting to the lookup table techniques, this section discusses some useful\nfloating-point tricks that help explain the games you can play with the bit patterns of\nfloating-point numbers.\nFloat/lnt Conversions\nThe lookup table techniques that follow convert a floating-point number to an inte-\nger to generate lookup table indices. This operation can be slow; on a Pentium II, for\nexample, casting a float to an int with \"(int)f' takes about 60 cycles. This is because\nthe ANSI C standard dictates that casting a float to an int should truncate the frac-\ntion, but by default, the FPU rounds to the nearest integer. Casting to an int becomes\na function call to a routine that changes the FPU rounding mode, does the conver-\nsion, and then changes the rounding mode back. Nasty.\nNote that the cost of casting between ints and floats is dependent on the compiler\nand processor with which you are working. As with all optimizations, benchmark this\nconversion trick against a regular typecast and disassemble the code to see what's actu-\nally happening.\nThe conversion can be performed much faster by simply adding 1 x 223 to the\nfloating-point number and then discarding the upper exponent bits of the result.\nWe'll look at the code first, and then analyze why it works.\nTo do this, it is helpful to define the following union, which lets us access a 32-bit\nnumber as either an integer or a float.\n",
      "content_length": 2123,
      "extraction_method": "Direct"
    },
    {
      "page_number": 163,
      "chapter": null,
      "content": "170 \nSection 2 Mathematics\ntypedef union\n{\nint \ni;\nfloat \nf;\n} _INTORFLOAT;\nThe INTORFLOAT type is used in code snippets throughout this gem. Note that\nit makes access to the bit pattern of numbers look very simple—in practice, the com-\npiler may be generating more code than you expect. On a Pentium II, for example,\nfloating-point and integer registers are in separate hardware, and data cannot be moved\nfrom one to the other without going through memory; for this reason, accessing the\nmembers of the INTORFLOAT union may require additional memory loads and\nstores.\nHere is how to convert a float to an int:\nINTORFLOAT \nn; \n// floating-point number to convert\nINTORFLOAT \nbias; \n// \"magic\" number\nbias.i = (23 + 127) « 23; // bias constant = 1 x 2*23\nn.f = 123.456f; \n// some floating-point number\nn.f += bias.f; \n// add as floating-point\nn.i -= bias.i; \n// subtract as integer\n// n.i is now 123 - the integer portion of the original n.f\nWhy does this work? Adding 1 x 223 as a floating-point number pushes the man-\ntissa into the lower 23 bits, setting the exponent to a known value (23 + 127). Sub-\nfloating-point\n43.25= \n1 0 1 0 1 1.0 1\n1 x 223 = \n+ 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 . 0 0\n1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 1 . 0 1\n[1 .]00000000000000000101011 01 x 223\noTv.i ojoj tTi|? |i jctl o I o I o] o I o I o I o I o I o I o I o I o I o I o [ o I o I o 111 o J11 o 11 h~|\n31 30 \n23 22 \n0\n— o I:'F'l'*ril-'i-'f' o o o o o o o o o o o o o o o o o o o o o o o\n1 0 1 0 1 1 \n=43\ninteger\nFIGURE 2.1.3 The number 43.25 is converted to an integer by manipulating the floating-point\nformat. The underlined bits in the mantissa do not fit in memory and are discarded (with rounding).\n",
      "content_length": 1713,
      "extraction_method": "Direct"
    },
    {
      "page_number": 164,
      "chapter": null,
      "content": "2.1 Floating-Point Tricks: Improving Performance with IEEE Floating Point \n171\ntracting the known exponent as an integer removes these unwanted upper bits, leav-\ning the desired integer in the low bits of the result. These steps are illustrated in Fig-\nure 2.1.3 for the number 43.25.\nOn a Pentium II (with everything in cache), this reduces the conversion time\nfrom 60 cycles to about 5. Note that it is also possible to write inline assembly code to\nget the FPU to convert from float to int without changing the rounding mode—this\nis faster than typecasting, but generally slower than the biasing trick shown here.\nThis trick works as long as the floating-point number to be converted does not\n\"overlap\" the bias constant being added. As long as the number is less than 223, the\ntrick will work.\nTo handle negative numbers correctly, use bias = ((23 + 127) « 23) + (1 «\n22)—the additional (1 « 22) makes this equivalent to adding 1.5 x 223, which causes\ncorrect rounding for negative numbers, as shown in Figure 2.1.4. The extra bit is\nrequired so that the subtract-with-borrow operation does not affect the most signifi-\ncant bit in the mantissa (bit 23). In this case, 10 upper bits will be removed instead of\n9, so the range is one bit less than for positive numbers—the number to be converted\nmust be less than 222.\nTo convert from a float to a fixed-point format with a desired number of frac-\ntional bits after the binary point, use bias = (23 - bits + 127) « 23. Again, to handle\nnegative numbers, add an additional (1 « 22) to bias. This is illustrated in Figure\n2.1.5, which shows the conversion of 192.8125 to a fixed-point number with two\nfractional bits.\nNote that you can use the \"inverse\" of this trick to convert from integer to float-\ning-point.\nfloating-point\n-43-25 = \n- 1 0 1 0 1 1.0 1\n1.5x223= \n+ 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0.0 D _\n0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 0 0.1 1\n[1 .]0111111111111111101010011 x 22\n31 30 \n23 22 \n0\n— o SJ'SWfM-¥X§;Q o o o o o o o o o o o o o o o o o o o o o o\n0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 0 0 \n=-44\ninteger\nFIGURE 2.1.4 To convert a negative float to an integer is slightly different than for positive numbers.\nHere we see the conversion of-43.25. Observe how the rounding applied when the underlined bits\nare discarded yields the correct negative integer.\n",
      "content_length": 2363,
      "extraction_method": "Direct"
    },
    {
      "page_number": 165,
      "chapter": null,
      "content": "172 \nSection 2 Mathematics\nfloating-point\n192.8125= \n1 1 0 0 0 0 0 0.1 1 0 1\n1x2 2 3~ 2 = \n+ 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0.0 0 0 0\n1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0.1 1 0 1\n[1J00000000000001100000011 01 x 223\no ] j I fi} •o|iT€f iTTil oToToToJoToJo I oj o I o [ o I o I o I o 1111 |o I o I o I o I o I o 11 h\n31 30 \n23 22 \n0\n~~ ° 33\"I\"CT1-rP£ o 0 0 0 0 0 0 0 0 0 0 0 o o o o o o o o o o o\n1 1 0 0 0 0 0 0.1 1 \n=192.75\n21.2 fixed-point\nFIGURE 2.1.5 Fractional bits can be preserved during the conversion from float to integer. Here,\n192.8125 is converted to a fixed-point number with two bits after the binary point.\nn.i = 123; \n// some integer\nn.i += bias.i; \n// add as integer\nn.f -= bias.f; \n// subtract as floating-point\n// n.f is now 123.0 - the original n.i converted to a float\nUsually, int-to-float conversions using typecasts are fast, and thus less in need of a\nperformance-optimizing trick. \n>\nSign Test\nBecause the sign bit of a floating-point number is in bit 31, the same as for integers,\nwe can use the integer unit to test for positive or negative floating-point numbers.\nGiven a floating-point number f, the following two code fragments are (almost)\nequivalent:\nif ( f < O.Of ) \n// floating-point compare\nINTORFLOAT ftmp;\nftmp.f = f;\nif (ftmp.i < 0) \n// integer compare\nAlthough they are equivalent, the integer compare may run faster due to better\npipelining of the integer instruction stream. Try it and see if it helps your code.\n(\"Almost\" equivalent because negative 0 will behave differently.)\n",
      "content_length": 1539,
      "extraction_method": "Direct"
    },
    {
      "page_number": 166,
      "chapter": null,
      "content": "2.1 Floating-Point Tricks: Improving Performance with IEEE Floating Point \n173\nComparisons\nSince the floating-point format stores sign, exponent, mantissa in that bit order, we\ncan use the integer unit to compare floating-point numbers—if the exponent of a is\ngreater than the exponent of b, then a is greater than b, no matter what the mantissas.\nThe following code fragments may be equivalent:\nif ( a < b ) \n// floating-point compare\nINTORFLOAT atmp, btmp;\natmp.f = f; btmp.f = b;\nif (atmp.i < btmp.i) \n// integer compare\nAgain, the integer comparison will usually pipeline better and run faster. Note\nthat this breaks down when a and b are both negative, because the exponent and man-\ntissa bits are not stored in the two's complement form that the integer comparison\nexpects. If your code can rely on at least one of the numbers being positive, then this\nis a faster way to do comparisons.\nClamping\nClamping a value to a specific range often comes up in games programming, and\noften we want to clamp to a [0,1] range. A floating-point value /can be clamped to 0\n(i.e., set/= 0 if/< 0) by turning the sign bit into a mask, as in the following code\nsnippet:\nINTORFLOAT ftmp;\nftmp.f = f;\nint s = ftmp.i » 31; \n// create sign bit mask\ns = -s; \n// flip bits in mask\nftmp.i &= s; \n// ftmp = ftmp & mask\nf = ftmp.f;\ns is set to the bits of/shifted right by 31—sign extension replicates the sign bit\nthroughout all 32 bits. NOT-ing this value creates a mask of 0 bits if/was negative, or\n1 bits if/was positive. AND-ing/with this value either leaves/unchanged or sets/to\n0. Net result: if/was negative, then it becomes 0; if it was positive, it is unchanged.\nThis code runs entirely in the integer unit, and has no compares or branches. In\ntest code, the floating-point compare and clamp took about 18 cycles, while the in-\nteger clamp took less than five cycles. (Note that these cycle times include loop\noverhead.)\nClamping positive numbers to 0 (set/= 0 if/> 0) is less useful but even easier,\nsince we don't need to flip the bits in the mask.\nINTORFLOAT ftmp;\nftmp.f = f;\nint s = ftmp.i » 31; // create sign bit mask\n",
      "content_length": 2117,
      "extraction_method": "Direct"
    },
    {
      "page_number": 167,
      "chapter": null,
      "content": "174 \nSection 2 Mathematics\nftmp.i &= s; \n// ftmp = ftmp & mask\nf = ftmp.f;\nClamping to 1 (set/= 1 if/> 1) can be done by subtracting 1, clamping to 0, and\nthen adding 1.\nINTORFLOAT ftmp;\nftmp.f = f - 1.0f;\nint s = ftmp.i » 31; // create sign bit mask\nftmp.i &= s; \n// ftmp = ftmp & mask\nf = ftmp.f + 1.Of;\nNote that using conditional load instructions in assembly will generally increase\nthe speed of clamping operations, as these avoid the need for branching, which kills\nthe branch prediction logic in the instruction pipeline.\nAbsolute Value\nThis one's easy: since floating-point numbers do not use two's complement, taking\nthe absolute value of a floating-point number is as simple as masking the sign bit to 0.\nINTORFLOAT ftmp;\nftmp.f = f;\nftmp.i &= Ox7fffffff;\nf = ftmp.f;\nNote that this is much faster than using a compare to determine if/is less than 0\nbefore negating it.\nLinear Lookup Tables for Sine and Cosine\nTrigonometry is often useful in games—for calculating distances and angles, stepping\nalong a circle, or animating a water mesh. The standard math library has all the nor-\nmal trig functions, but they are slow, and they work on doubles, so they use more\nmemory than needed. In a game, a low-precision calculation is often sufficient.\nTo efficiently compute sine and cosine, we can use a lookup table. A common\napproach is to use fixed-point math, with angles represented on an integer scale, say, 0\nto 1023 to cover the full circle. However, this means that the game programmer needs\nto understand the library implementation of sine and cosine, and represent his or her\nangles in the format it requires. By using floating-point tricks for efficient indexing,\nwe can create floating-point trig functions that use standard radians and do not\nrequire the programmer to know about implementation details.\nsin\nLet's implement:\nfloat fsin( float theta );\n",
      "content_length": 1870,
      "extraction_method": "Direct"
    },
    {
      "page_number": 168,
      "chapter": null,
      "content": "2.1 Floating-Point Tricks: Improving Performance with IEEE Floating Point \n175\nThis can easily be done with a lookup table. A 256-entry table, covering the range\nof angles 0 to 271, is initialized as:\nsintable[i] = (float)sin((double)i * 2.0*3.14159265/256.0)\nwhich simply converts i in the range 0-256 to floating-point radians in the range 0 to\n2n and takes the sine of the resulting angle.\nGiven this table, the jsin function could be implemented as follows:\nfloat fsin( float theta )\n{\ni = (unsigned int)(theta * 256.Of/\n(2.0f*3.14159265f));return \ntable[i];\n}\nHowever, this has two problems: first, it uses the slow float-to-int typecast, and\nsecond, if theta is outside the range [0,2Jl), then the function will index out of the\ntable.\nBoth of these problems are solved with this implementation:\n#define FTOIBIAS \n12582912.Of \n// 1.5 * 2*23\n#define PI \n3.l4l59265f\nfloat fsin( float theta )\n{\nint \ni;\nINTORFLOAT ftmp;\nftmp.f = theta * (256.Of/(2.0f*PI)) + FTOIBIAS;\ni = ftmp.i & 255;\nreturn table[i];\n}\nThis implementation uses the floating-point biasing trick described previously\nfor fast conversion from floating-point to integer. It masks the integer with 255 so\nthat the table index wraps around, always staying in the 0-255 range. Note that if/\nexceeds 222, then the float-to-integer conversion trick will fail, so it's still necessary to\nperiodically reduce/to the valid [0,27l) range.\nThis implementation of jsin takes about 10 cycles on a Pentium II (assuming all\ncode and data is in primary cache), as compared with almost 140 cycles for the stan-\ndard math library implementation of sin (even though sin uses the hardware sine\ninstruction in the FPU).\nA 256-entry floating-point table takes IK, which should easily stay within cache\nfor the duration of your inner loops. Accuracy is basically eight bits, as constrained by\n('\"c>?''\\ \nt\"ie l°°kuP table size. The worst-case error can easily be determined from analyzing\n^-—--^ \nthe lookup table (as is demonstrated in the code on the CD). Larger lookup tables\nincrease the accuracy of your results, but will hurt cache performance.\n",
      "content_length": 2098,
      "extraction_method": "Direct"
    },
    {
      "page_number": 169,
      "chapter": null,
      "content": "176 \nSection 2 Mathematics\ncos\nThe cosine function could be implemented in exactly the same way, with its own\nlookup table, but we can take advantage of the fact that cos(0) = sin(9 + n/2), and use\nthe same lookup table. To do this, we just need to add 256/4 (since adding n/2 means\nwe're adding a quarter of a circle to the angle) to the lookup table index, which we can\ndo at the same time as biasing the exponent. This yields the following implementation:\nfloat fcos( float theta )\n{\nint \ni;\nINTORFLOAT ftmp;\nftmp.f = theta * (256. Of /(2.0f*PI)) + FTOIBIAS + 64f;\ni = ftmp.i & 255;\nreturn table[i] ;\nDepending on the application, it is often useful to get both sine and cosine at the\nsame time. This can be done more efficiently than computing each separately — sim-\nply look up sin, and then add 64 to the index and mask by 255 to look up cos. If you\nneed to compute several sines or cosines at once, you can write custom code to inter-\nleave the calculations and make it faster still.\nLogarithmic Optimization of Square Root\nSquare roots are useful in games for operations such as computing distances, normal-\nizing vectors, and solving quadratic equations. Despite the presence of a square root\ninstruction built into the FPU, the sqrt function in the standard C library still\ntakes about 80 cycles on a Pentium II CPU, making it another good candidate for\noptimization.\nSquare root optimization is an interesting use of floating-point bit fiddling,\nbecause the logarithmic, multiscale nature of square root allows us to decompose the\nsquare root calculation and manipulate the mantissa and exponent separately. Con-\nsider the square root of a floating-point number:\nsqrrtf) = sqrl{\\.m x 2')\n= sqrt(l.m)x2'n\nSo, to compute the square root off, we compute the square root of the mantissa\nand divide the exponent by 2. However, the exponent is an integer, so if the exponent\nis odd, then dividing by 2 loses the low bit. This is addressed by prepending the low\nbit of the exponent to the mantissa, so we have:\nsqrtff) = sqrt(\\.m-x. 2\">) x 2 ['/2j\nwhere e0 is the low bit of the exponent.\n",
      "content_length": 2093,
      "extraction_method": "Direct"
    },
    {
      "page_number": 170,
      "chapter": null,
      "content": "2.1 \nFloating-Point Tricks: Improving Performance with IEEE Floating Point \n177\nThis is implemented with a 256-entry table for the square root of the truncated\nmantissa and some additional tweaking for the exponent calculation, as follows:\nfloat fsqrt( float f )\nINTORFLOAT \nftmp;\nunsigned int \nn, e;\nftmp.f = f;\nn = ftmp.i;\ne = (n » 1) & Ox3f800000; // divide exponent by 2\nn = (n » 16) & Oxff; \n// table index is eO+m22-m16\nftmp.i = sqrttable[n] + e; // combine results\nreturn ftmp.f;\nThe table index is simply the upper bits of the mantissa and the low bit of the\nexponent (e0). The lookup table contains the mantissa of the computed square roots.\nThe exponent of the square root is computed by shifting the exponent of /by 1\nto divide by 2. Since the exponent is biased, this divides the bias by 2 as well as the\nexponent, which is not what we want. This is compensated for by adding an addi-\ntional factor to the entries otsqrttable to re-bias the exponent.\nThis fcqrt function takes about 16 cycles on a Pentium II CPU—about five times\n^~-_i^ \nfaster than the C library implementation. Again, this is assuming that everything is in\nmma> \ncache.\nThe algorithm is explained in more detail in the code on the CD.\nOptimization of Arbitrary Functions\nConsider an arbitrary floating-point function of one variable:\nThe techniques just discussed reveal two basic methods for table-based optimiza-\ntions of general functions. For sine and cosine, the value of x was linearly quantized\nover a known range and used as a table index to look up y. For square root, the value\nof x was logarithmically quantized and used as a table index to look up a value. This\nvalue was scaled by a function of the exponent of x to get the final value of y.\nThe linear approach rescales a floating-point number and converts it to an integer\nto generate a lookup table index via linear quantization. This is a simple technique very\nsimilar to integer lookup tables, the only wrinkle being die efficient conversion of a\nfloating-point value into an integer index. The logarithmic approach uses the floating-\npoint bit pattern directly as a table index, to achieve logarithmic quantization.\nBoth of these techniques can be generalized to the case of arbitrary functions.\nDepending on the function, the linear or logarithmic approach may be more\nappropriate.\n",
      "content_length": 2333,
      "extraction_method": "Direct"
    },
    {
      "page_number": 171,
      "chapter": null,
      "content": "Section 2 Mathematics\nLinear Quantization\nThe fiin function in the previous section can be used as a template for optimiz-\ning general functions via linear quantization. Suppose we know that the function\nwill only be used over a limited range x e [A, S). We can build a lookup table\nthat uniformly covers this range, and efficiently calculate the correct index into the\ntable for values of x within the range. The optimized function f is then imple-\nmented as:\ntfdefine \nFTOIBIAS \n1258291 2. Of \n// 1.5 * 2\"23\ntfdefine \nTABLESIZE \n256\ntfdefine INDEXSCALE \n((float) TABLESIZE / ( B - A ) )\nfloat flut( float x )\n{\nint \ni;\nINTORFLOAT ftmp;\nftmp.f = x * INDEXSCALE + (FTOIBIAS - A * INDEXSCALE);\ni = ftmp.i & (TABLESIZE - 1);\nreturn ftable[i] ;\nThe lookup table is initialized with:\nftable[i] = f( (float)i / INDEXSCALE + A );\nwhere /is the full-precision floating implementation of the function. The y?«J compu-\ntation requires two floating-point operations (multiply and add), one integer bitwise\nmask, and a table lookup. It takes about 10 cycles on a Pentium II CPU.\nNote that additional accuracy can be obtained for a few more cycles by linearly\ninterpolating the two closest table entries. An API supporting this optimization for\ngeneral functions is provided on the CD, including optional linear interpolation to\nincrease accuracy.\nLogarithmic Quantization\nThe linear method treats the range [A,B) uniformly. Depending on the function, a\nlogarithmic treatment may be more appropriate, as in the square root optimization.\nThe basic idea is that the bits of the floating-point representation are used directly as\na lookup table index, rather than being manipulated into an integer range. By extract-\ning selected bits of the sign, exponent, and mantissa, we can massage the 1:8:23 IEEE\nfloating-point number into our own reduced precision format with as many bits as we\nlike for the sign, exponent, and mantissa.\nIn the square root example, we extracted 8 bits to give a logarithmically quantized\n0:1:7 representation. We used 1 bit of the exponent and 7 bits of the mantissa. The\nsign bit was discarded, since the square root of a negative number is undefined. The\n0: 1 :7 format represents an 8-bit mantissa (remember the implied 1 in the IEEE rep-\n",
      "content_length": 2253,
      "extraction_method": "Direct"
    },
    {
      "page_number": 172,
      "chapter": null,
      "content": "2.1 Floating-Point Tricks: Improving Performance with IEEE Floating Point \n179\nresentation) and a 1-bit exponent, so it can represent numbers between [1]. 0000000\nx 2° and [1] . 1 1 1 1 1 1 1 x 21, which covers the range [1 ,4).\nThe square root function was decomposed into an operation on the 0:1:7 quan-\ntized number (a table lookup) and an independent operation on the exponent (divide\nby 2). Additional trickery was employed to optimize the two independent operations\nand combine the mantissa and exponent into a 32-bit floating-point result.\nOther functions can benefit from this method of logarithmic quantization. The\nIEEE format makes it easy to extract the least significant bits of the exponent with the\nmost significant bits of the mantissa in a single shift and mask operation. To extract\nebits of the exponent and mbits of the mantissa, simply do this:\nbits = (n » (23 - mbits)) & ((1 « (ebits + mbits)) - 1)\nThis shifts the number n to the right so that the desired bits of the mantissa and\nexponent are the rightmost bits in the number, and then masks off the desired num-\nber of bits.\nThe sign bit can be handled with some extra bit fiddling, depending on the func-\ntion with which you are working. If you know that you are only dealing with positive\nnumbers (for example, square root), or that your function always returns a positive\nresult, then you can ignore the sign. If the sign of your result is the same as the sign of\nthe input number (in other words, f(-x) = -f(x)), you can simply save and restore the\nsign bit.\nFor functions with a limited range of input values, masking out selected bits of\nthe exponent and mantissa can give you a direct table index. For example, if you only\ncare about your function over the range [1,16), then you can use 2 bits of exponent\nand 4 bits of mantissa (for example). This 0:2:4 representation stores binary numbers\nbetween 1 .0000 x 2° and 1 . 1 1 1 1 x 23, or decimal 1 .0 to 1 5 . 5 . Mask out these bits and\nuse the bits directly as an index into a precomputed 64-entry table. This requires very\nfew cycles and is computationally fast. However, as you add more precision, the table\ngrows and may become prohibitively large, at which point cache performance will\nsuffer.\nAn alternative is to decompose the exponent and mantissa calculations, as was\ndone in the square root example. If your function f(x) can be decomposed as:\nthen you can, for example, approximate fl with a 256-entry lookup table, using 8 bits\nof the mantissa m, and perform the calculation of f2 directly, as an integer operation\non the exponent e. This is essentially the technique used by the square root trick.\nLogarithmic quantization is a powerful tool, but often requires function-specific\nbit fiddling to optimize a particular function. Fully general techniques are not always\npossible, but the methods described in this section should be helpful when tackling\nyour specific optimization problem.\n",
      "content_length": 2936,
      "extraction_method": "Direct"
    },
    {
      "page_number": 173,
      "chapter": null,
      "content": "180 \nSection 2 Mathematics\nPerformance Measurement\nWhen optimizing code, make sure you measure performance carefully before and\nafter making the optimization. Sometimes an optimization that looks good on paper\ncauses trouble when implemented, due to cache behavior, branch mispredictions, or\npoor handling by the compiler. Whenever you make changes, be sure that you are\nimproving your performance—never assume.\nMake sure compiler optimizations are enabled. Use inline functions where appro-\npriate. Again, test your results when using inline functions or tweaking the compiler\nsettings.\nWhen benchmarking code, take care that compiler optimization isn't getting in\nthe way of your tests. Disassemble your code and step through it to be sure it's run-\nning what you expected. When timing things, it's often helpful to run something in a\nloop—but if the body of your loop gets optimized out, then your timing won't be\nvery accurate!\nOn Pentium computers, you can use the rdtsc (read time stamp counter) instruc-\ntion to get the current CPU cycle count. Intel warns that this instruction should be\nexecuted a couple times before you start using the results. Intel also recommends\nusing an instruction such as cpuid that will flush the instruction cache, so that you get\nmore consistent timing results. To get absolute times, the cycle counts can be con-\nverted to seconds by dividing by the execution speed (MHz) of the processor.\nCycle counters are the most reliable way to measure fine-grain performance.\nOther tools such as VTune and TrueTime (on the PC) are useful for higher level pro-\nfiling. For any benchmarking, make sure that memory behavior is realistic, as mem-\nory bottlenecks are one of the most serious impediments to high performance on\nmodern processors. Be aware of how your benchmark is using the cache, and try to\nsimulate the cache behavior of your game. For a benchmark, the cache can be\n\"warmed up\" by running the algorithm a couple of times before taking the timing\nmeasurements. However, a warm cache may not emulate the behavior of your\ngame—best is to benchmark directly in the game itself. Disable interrupts for more\nreliable results, or take measurements multiple times and ignore the spikes.\nAll the cycle times reported in this gem are from an Intel Pentium II 450-MHz\nmachine. Each operation was repeated 1000 times in a loop, with the instruction and\ndata cache warmed by running the test multiple times. Cycle counts include loop\noverhead. See the code on the CD for actual benchmarks used.\nThe lookup table techniques described in this article are appropriate if the lookup\ntable remains in cache. This is probably true within the inner loop of your rendering\npipeline or physics engine, but it's probably not true if you are calling these functions\nrandomly throughout the code. If the lookup tables cannot be kept in cache, then\ntechniques that use more computation and fewer memory accesses are probably more\nappropriate—methods such as polynomial approximation (see [EdwardsOO] for a\ngood overview).\n",
      "content_length": 3038,
      "extraction_method": "Direct"
    },
    {
      "page_number": 174,
      "chapter": null,
      "content": "2.1 Floating-Point Tricks: Improving Performance with IEEE Floating Point \n181\nConclusions\nThis gem scratched the surface of floating-point optimization. Lookup tables are the\nprimary method explored, and they often produce significant speedups. However, be\naware of cache behavior, and always benchmark your results. Sometimes you can\nachieve the same result faster by using more computation but touching memory\nless—techniques such as polynomial approximation may be appropriate. The tricks\nshown here can be extended in a variety of ways, and many other tricks are possible.\nAs a popular book title suggests, there is a Zen to the art of code optimization, and a\nshort overview like this can't hope to cover all possibilities.\nReferences\n[Abrash94] Abrash, Michael, Zen of Code Optimization, Coriolis Group, 1994.\n[EdwardsOO] Edwards, Eddie, \"Polynomial Approximations txp Trigonometric Func-\ntions,\" Game Programming Gems, Charles River Media, 2000.\n[IntelOl] Intel Web page on floating-point unit and FPU data format. Good for PCs,\nbut relevant to any IEEE-compliant architecture. Available at http://developer\n.intel.com/design/intarch/techinfo/Pentium/fpu.htm.\n[Lalonde98] Lalonde, Paul, and Dawson, Robert, \"A High Speed, Low Precision\nSquare Root,\" Graphics Gems, Academic Press, 1998.\n",
      "content_length": 1295,
      "extraction_method": "Direct"
    },
    {
      "page_number": 175,
      "chapter": null,
      "content": "2.2\nVector and Plane Tricks\nJohn Olsen, Microsoft\ninfix@xmission.com\nY\nour collision detection routine is running flawlessly now, returning a surface\npoint and a normal back when you feed it a position and velocity vector. Now\nwhat? Actually, there are quite a few things you can do based on the data you have.\nIn general, you may want to have your collision routine generate the actual colli-\nsion point, but the methods in this gem show how to handle collision results that\nshow only the plane of intersection. Since a plane can be fully specified with a surface\nnormal and any point on the plane, you can work your way through the math to find\neverything you need from there.\nData that goes into your collision code would be an initial point Pt and a final\npoint Pf, and the output in the case of a collision would be a plane that is defined by\na unit vector surface normal TV and a point on the surface Ps. The point need not be\nthe actual intersection point as long as it is on the plane.\nFor optimization purposes, you will probably want to build a subset of these cal-\nculations back into your collision code. Much of the information you need will have\nalready been calculated during the collision tests. It will be much faster to reuse the\nalready known information rather than recalculate it from scratch.\nThe plane equation Ax + By + Cz + D = 0 maps onto the supplied data, where x,\ny, and z are the components of the normal vector N, and D is the dot product N* Ps.\nAltitude Relative to the Collision Plane\nOne of the most commonly used pieces of data when checking collisions is the alti-\ntude of one of your data points. If the altitude is positive, the point is above the sur-\nface and has not collided yet. If it is negative, you have collided and penetrated the\nsurface.\nTypical collision testing code will only return a hit if one of your test points is on\neach side of the test surface. This means that if you want to predict collisions, you\nneed to pass along a position with an exaggerated velocity vector. That way, the exag-\ngerated vector will intersect much earlier than your actual movement would allow.\nOnce you have tricked your collision code into returning a surface point and nor-\nmal, you can get your altitude relative to that surface by using your initial position.\nThe final position is not used for this altitude calculation.\n182\n",
      "content_length": 2365,
      "extraction_method": "Direct"
    },
    {
      "page_number": 176,
      "chapter": null,
      "content": "2.2 Vector and Plane Tricks\n183\nFIGURE 2.2.1 Determining the altitude.\nAs shown in Figure 2.2.1, we want to find the length of the vector (Ps - Pt) when\nit is projected onto the surface normal N. This gives us the distance of the shortest\nline from the point to the surface. This shortest vector is by definition perpendicular\nto the surface. This is exactly what the dot product gives us, so we are left with the\nscalar (nonvector) distance to the surface Ds as shown:\nNearest Point on the Surface\nOnce we have the distance to the surface, it takes just one more step to get the point\non the surface PH that is closest to the initial point Pf as also shown in Figure 2.2. 1 . We\nalready know the point is distance Ds from die starting point, and that distance is\nalong the surface normal TV. That means die point can be found with the following:\nPtt = P,-DsN\nThe normal vector is facing the opposite direction of the distance we want to\nmeasure, so it needs to be subtracted from the starting point.\nPinning Down the Collision Point\nWhen you have one point on each side of a test surface, your vector must at some\npoint intersect with it. Finding this intersection point Pc will tell you where your vec-\ntor pierces die surface. If your collision detection code has not already provided you\nwith the exact point, here is how you would find it.\nYou know that the collision point must lie somewhere along the line. Knowing in\nadvance that there is a collision makes it possible to take some shortcuts since we\nknow there actually is a solution to the equation. If the test ray is parallel to the sur-\nface, the ratio cannot be calculated since it results in a divide by zero. We can take\nadvantage of the calculation for Ds in finding die collision point Pc. Figure 2.2.2\nshows the information needed for this calculation.\n",
      "content_length": 1822,
      "extraction_method": "Direct"
    },
    {
      "page_number": 177,
      "chapter": null,
      "content": "184\nSection 2 Mathematics\nFIGURE 2.2.2 Finding the collision pointPc.\nSince we know the collision is between the two points, we can find it by calculat-\ning how far it is along the line from P/ to Pf. This ratio can be written as:\nR = ((Pi - P,) • N) I ((% - Pf) • N)\nOr, using our already computed Ds, it becomes:\nR = D,I ((P,. - Pf) • N)\nThe two line segments are arranged to both point in the same direction relative to\nthe surface normal, which guarantees that our ratio will be non-negative. Once we\nhave this ratio, we can use it to multiply the length of the vector from P, to Pyto tell\nhow far from P, the collision occurs. In the special case of R = 1, you can avoid the cal-\nculation since it results in the point Pf For R = 0, the point is P,-. Otherwise, the fol-\nlowing equation is used:\nPe=Pf + R(Pf - P^\nDistance to the Collision Point\nAlthough similar to Ds, this differs from the distance from the collision plane because\nthe distance is calculated along the path of travel rather than along the surface normal.\nIn the case of travelling near the surface but nearly parallel to it, your distance to col-\nlision will be very large when compared to your altitude.\nThis is the type of calculation you would want to use when calculating altitude\nfor an aircraft, since you cannot guarantee the direction of a surface normal on the\nground below. Rather than sending your actual velocity for a collision test, you would\nsend your current position and a very large down vector, long enough to guarantee\nthat it will intersect the ground. This works in the case of intersecting a small polygon\n",
      "content_length": 1603,
      "extraction_method": "Direct"
    },
    {
      "page_number": 178,
      "chapter": null,
      "content": "2.2 Vector and Plane Tricks\n185\nFIGURE 2.2.3 Calculating distance to the collision point.\nthat happens to be aligned nearly perpendicular to the test vector. In that case, the\naltitude relative to the collision plane Pn as calculated earlier would give a very small\nnumber.\nOnce you have the actual collision point, it's very easy to calculate the distance\nusing Euclid's equation to find how far it is from the starting point to the collision\npoint. Figure 2.2.3 shows the elements required. The distance to the collision point,\nDc, is the magnitude of the vector from our starting point /J to the collision point Pe\nthat was calculated earlier:\nAnother way to describe the magnitude of this vector is that it is the square root\nof the sum of the squares of the differences of each component of the vector. Most\nvector libraries include a function call to find the magnitude or length of a vector.\nVector magnitudes are never negative.\nAnother possible shortcut can be used when you know the ratio R used to find\nthe collision point as described in the previous section. The distance to the collision\npoint is the length of the full line (which you may already have lying around) multi-\nplied by the already computed ratio.\nD. = RPf-Pi\nReflecting Off the Collision Plane\nThe usual result of a collision is to bounce. The interesting part is figuring out the\ndirection and position once you have rebounded off a surface. Figure 2.2.4 shows\nthe elements used in calculating the reflected vector. The first two cases will perfectly\n",
      "content_length": 1530,
      "extraction_method": "Direct"
    },
    {
      "page_number": 179,
      "chapter": null,
      "content": "Section 2 Mathematics\n2N((Ps-Pf)-N)\nP.\nP.-Pf\nFIGURE 2.2.4 Calculating the reflected vector.\npreserve the magnitude of the velocity. In both cases, the result of the bounce will be\nthe same distance from the plane as Pf.\nOne of the simplest ways to visualize reflecting a point relative to a plane is to\nimagine a vector from the below-ground destination point back up to the surface\nalong the surface normal. The new reflected location is found by continuing that line\nan equal distance to the other side of the plane. You obtain the new location\nby adding to the final point twice the distance from the final point to the surface.\nReusing our equation to find the distance perpendicular to the plane, we come up\nwith the following. The distance is multiplied by the surface normal to turn it back\ninto a vector since you cannot add a simple scalar value such as Ds to a vector.\nThe original and reflected vectors will have the same angle relative to the plane.\nAnother way of looking at this is that if you normalize the vectors from your collision\npoint going out to both your original start point and your reflected point, then find a\ndot product of each with your surface normal; they will be equal.\nVectors are normalized by dividing the vector by its length or magnitude, so the\nstatement about reflected vectors in the previous paragraph can be written as:\np~p,\nP.-P.\np - p\n-±c \n±.N\nP.-P;\nAny point on the plane could be substituted for Pc (Ps works, for instance) in the\npreceding equation and the same result would hold since all we are saying here is that\nthe ends of the unit vectors are the same distance from the plane.\nA complication with reflections is that the newly determined end point needs to\nbe tested all over again with your collision code to see if you have been pushed\nthrough some other surface. If you repeat the collision test, but with a vector from\nyour collision point Pc to the newly reflected point Pr, you will get a possible new col-\nlision. You will need to repeat this process until no collision occurs. At each pass, your\n",
      "content_length": 2060,
      "extraction_method": "Direct"
    },
    {
      "page_number": 180,
      "chapter": null,
      "content": "2.2 Vector and Plane Tricks\n187\nvector will be smaller as it is chewed up by bouncing, as long as you do not try to\nbounce between two coincident planes.\nThere is one degenerate case you should also watch out for when chaining colli-\nsions together. Should you hit exactly at the intersection of two planes, your second\ntest will be made with an initial point on the edge of the surface. This is easy to han-\ndle if you know about this problem and allow for it in advance by assuming anything\nexactly at the surface (or on the edge) has not yet collided, and is counted as above the\nsurface for collision purposes. Collisions are reserved for penetration distances greater\nthan zero.\nOnce you have completed your final reflection, a new velocity vector can be com-\nputed by normalizing the direction from the last collision to the final reflected loca-\ntion and multiplying it by the original velocity like this:\nV = (Pr - PcPt - Pf\nP.-P.\nKickback Collision\nSometimes, rather than reflect off the collision plane, you want to kick the player\nback the way he or she came as shown in Figure 2.2.5. The calculations for this are\nsimple once you have the collision point. Since this collision also preserves velocity, it\nis also perfectly elastic.\nThe point to which you are kicked back, /^, is obtained by calculating the vector\nfrom your final point Pf back to your collision point Pe and adding it to the collision\npoint.\nWe can combine terms to get:\nPk = 2Pc - Pf\nFIGURE 2.2.5 Calculating a kickback vector.\n",
      "content_length": 1508,
      "extraction_method": "Direct"
    },
    {
      "page_number": 181,
      "chapter": null,
      "content": "188 \nSections Mathematics\nYou can run into the same problems with kickback collisions as with reflections\nwhere the destination point leads to an additional collision. However, there is an early\nway out of the loop for kickback collisions in some cases. If the collision point is more\nthan halfway from the initial point to the final point, the resulting kickback point will\noccur in an area that has already been checked for collisions, so no additional check is\nnecessary.\nCollisions with Damping\nShould you want to perform a collision with some sort of friction or damping, you\nwill need to be careful of how you handle the vectors. You will need a scalar value\nS that will be used as a multiplier to change your velocity at each impact. It will\ntypically range from zero (the object stops on impact) to one (a completely elastic\ncollision preserving velocity). Energy can be injected into the system by increasing\nthe scalar above one. A kickback collision is the same as using a scalar of negative\none.\nTo properly handle nonelastic collisions, you must scale only the portion of the\nvector from the collision point Pe to the reflected point Pr as shown in Figure 2.2.6,\nsince that is the only portion of the flight that will have been slowed due to the\nimpact. The following equation relies heavily on the earlier equations to determine\nwhat your new slowed point would be.\nIn coordination with this, you would need to multiply any separately stored\nvelocity vector by the same scalar value, or your object will resume its full speed the\nnext frame. In the case of a collision putting your point into another immediate colli-\nsion as discussed earlier, this scale factor should be applied at each pass to simulate the\ndamping effect of multiple bounces in a single frame.\nFIGURE 2.2.6 Calculating a damped reflection vector.\n",
      "content_length": 1831,
      "extraction_method": "Direct"
    },
    {
      "page_number": 182,
      "chapter": null,
      "content": "2.2 Vector and Plane Tricks \n189\nInterpolation Across a Line or Plane\nAn interesting side note about lines and planes is that a weighted average interpola-\ntion between any set of points occupies the space defined by those points. For\ninstance, starting with a line, you can assign weights to the end points where the\nweights sum to one, and all possible resulting points are on the line defined by\nthe points. Adding another point to build a plane extends the rule so the sum of the\nthree weights must equal one in order for the weighted sum to remain on the plane\ndefined by the three points. Additional points on the plane may be added, and addi-\ntional dimensions may also be added should you have need for a point on an\nn-dimensional plane.\nThis trick is related in a roundabout way to the reason we can often use Ps and Pc\ninterchangeably in several of the previous equations. Either point is sufficient to fill\nthe needs of the plane equation.\nIt's also interesting to note that the individual weights don't need to be between\nzero and one. They just need to all sum up to the value one, which allows the result-\ning point to be outside the line segment or polygon defined by the points while still\nbeing on the extended line or plane.\nSphere-to-Plane Collision\nColliding a ball with a surface is a little bit more complex than colliding a point against\nthe surface. One way to approach it is through ratios. If you draw a line from\nthe start point P± to the line-based collision point Pc of the vector against the plane, die\nball center Ph will be somewhere on that line when the ball begins to intersect the\nplane.\nWhen the ball just touches the surface, we can compare the line from Pf to Pc to\nthe line Pf to Pn to gain the information we need. If you project the first line onto the\nsecond, the ball center is off the surface by exactly the ball radius r on the line Pj to Pn.\nSince the length of that line is known to be Ds, we can get a ratio of how far the ball\nis along the line. This is similar to the way we used a ratio to find the surface collision\npoint Pc. This ratio is the same when applied to the line from P{ to Pc, which leads to\nthe equation:\n(Pe ~ Pi) \nD\nS\nThe equation can be solved for the location of the ball /^, resulting in:\np -p \nV<-Pi*\nPb-lC \n~\n",
      "content_length": 2282,
      "extraction_method": "Direct"
    },
    {
      "page_number": 183,
      "chapter": null,
      "content": "Section 2 Mathematics\nFIGURE 2.2.7 Colliding with a sphere.\nFigure 2.2.7 shows the relation graphically, indicating where the sphere is in rela-\ntion to the vectors. Care must be taken to notice that the ball does not actually reach\nPc as the ball touches the surface unless the line from Pf to Pc is perpendicular to the\nsurface. As the vector conies closer to being parallel to the plane, the ball will be far-\nther from Pc when it touches the plane.\n",
      "content_length": 453,
      "extraction_method": "Direct"
    },
    {
      "page_number": 184,
      "chapter": null,
      "content": "2.3\nFast, Robust Intersection of\n3D Line Segments\nGraham Rhodes, Applied Research Associates\ngrhodes@sed.ara.com\nT\nhe problem of determining the intersection of two line segments comes up from\ntime to time in game development. For example, the line/line intersection prob-\nlem can be beneficial in simple collision detection. Consider two objects in three-\ndimensional space that are moving in time. During a time step or animation frame,\neach object will move from one point to another along a linear path. The simplest\ncheck to see if the objects collide during the time step would be to see how close the\ntwo linear paths come to crossing, and if they are within a certain distance of each\nother (in other words, less than the sum of the radii of bounding spheres of the\nobjects), then process a collision. Other common applications for line segment inter-\nsections include navigation and motion planning (for example, when combined with\nan AI system), map overlay creation, and terrain/visibility estimation.\nThis gem describes a robust, closed form solution for computing the intersection\nbetween two infinite lines or finite-length line segments in three-dimensional space, if\nan intersection exists. When no intersection exists, the algorithm produces the point\nalong each line segment that is closest to the other line, and a vector between the two\nnearest points.\nWhat Makes This Algorithm Robust?\nThe algorithm presented here is robust for a couple of reasons. First, it does not carry\nany special requirements (for example, the line segments must be coplanar). Second,\nit has relatively few instances of tolerance checks. The basic algorithm has only two\ntolerance checks, and these are required mathematically rather than by heuristics.\nThe Problem Statement\nGiven two line segments in three-dimensional space, one that spans between the points\nj4i = [Alx Aiy Alz]r and A2 = [A^ A2y A2z\\T and one that spans between the\npoints Bl = [5lx \nBiy \nBlz\\ rand B2 = [B^ \nB2y \nB2z]T, we would like to find the true\npoint of intersection, P=[PX Py PZ]T, between the two segments, if it exists. \"When\n191\n",
      "content_length": 2106,
      "extraction_method": "Direct"
    },
    {
      "page_number": 185,
      "chapter": null,
      "content": "Section 2 Mathematics\nFIGURE 2.3.1 Two line segments in three-dimensional space. A) An intersection exists. B)\nNo intersecton.\nno intersection exists, we would like to compromise and find the point on each seg-\nment that is nearest to the other segment. Figure 2.3.1 illustrates the geometry of this\nsituation.\nThe nearest points, labeled C and D respectively, can be used to find the shortest\ndistance between the two segments. This gem focuses on finding the nearest points,\nwhich are identical to the true intersection point when an intersection exists.\nObservations\nBefore delving into how to solve the line intersection problem, it can be useful to\nmake a few observations. What are the challenges to solving the problem correctly?\nConsider an arbitrary, infinite line in space. It is likely that the line will intersect\nan arbitrary plane (if the line is not parallel to the plane, then it intersects the plane);\nhowever, it is unlikely that the line will truly intersect another line (even if two three-\ndimensional lines are not parallel, they do not necessarily intersect). From this obser-\nvation, we can see that no algorithm designed to find only true intersections will be\nrobust, capable of finding a result for an arbitrary pair of lines or line segments, since\nsuch an algorithm will fail most of the time. The need for a robust algorithm justifies\nthe use of an algorithm that finds the nearest points between two lines, within a real-\ntime 3D application such as a game.\nSince every student who has taken a basic planar geometry class has solved for the\nintersection of lines in a two-dimensional space, it is useful to consider the relationship\nbetween the three-dimensional line intersection problem and the two-dimensional\nintersection problem. In two-dimensional space, any two nonparallel lines truly inter-\nsect at one point. To visualize what happens in three-dimensional space, consider a\nplane that contains both defining points of line A, and die first defining point of line\n",
      "content_length": 2004,
      "extraction_method": "Direct"
    },
    {
      "page_number": 186,
      "chapter": null,
      "content": "2.3 Fast, Robust Intersection of 3D Line Segments \n193\nB. Line A lies within the plane, as does the first defining point of line B. Note that die\npoint of intersection of die two lines lies on die plane, since diat point is contained on\nline A. The point of intersection also lies on line B, and so two points of line B lie\nwidiin die plane. Since two points of line B lie in the plane, the entire line lies in the\nplane.\nThe important conclusion here is diat whenever there is a true intersection of\ntwo lines, those two lines do lie widiin a common plane. Thus, any time two three-\ndimensional lines have a true intersection, the problem is equivalent to a two-\ndimensional intersection problem in die plane diat contains all four of the defining\npoints.\nNaTve Solutions\nA naive, and problematic, solution to die intersection problem is to project the two\nsegments into one of the standard coordinates planes (XY, YZ, or XZ), and then solve\nthe problem in the plane. In terms of implementation, the primary difficulty widi diis\napproach is selecting an appropriate plane to project into. If neither of the line seg-\nments is parallel to any of the coordinate planes, dien the problem can be solved in\nany coordinate plane. However, an unacceptable amount of logic can be required\nwhen one or both segments are parallel to coordinate planes. A variation on diis\napproach, less naive but still problematic, is to form a plane equation from three of\nthe four points, Aly A2, Bl3 and B2, project all four points into the plane, and solve the\nproblem in the plane. In the rare case that there is a true intersection, this latter\napproach produces the correct result.\nOne key feature that is completely lacking from the basic two-dimensional pro-\njected intersection problem is the ability to give a direct indication as to whether a\nthree-dimensional intersection exists. It also doesn't provide the three-dimensional\nnearest points. It is necessary to work backwards to produce diis vital information.\nThe biggest problem with either variation on the projected solution arises when\nthe two lines pass close to one anodier, but do not actually intersect. In this case, the\nsolution obtained in any arbitrary projection plane will not necessarily be the correct\npair of nearest points. The projection will often yield completely wrong results! To\nvisualize this situation (which is difficult to illustrate on a printed page), consider the\nfollowing mind experiment. There are two line segments floating in space. Segment A\nis defined by die points (0, 0, 0) and (1, 0, 0), and segment B is defined by (1, 0, 1)\nand (1, 1, 1). When the lines are viewed from above, equivalent to projecting the lines\ninto the XY plane, the two-dimensional intersection point is (1, 0, 0), and the three-\ndimensional nearest points are (1, 0, 0) and (1, 0, 1). These are the correct nearest\npoints for the problem. However, if those two lines are viewed from different arbitrary\nangles, the two-dimensional intersection point will move to appear anywhere on the\ntwo line segments. Projecting the two-dimensional solution back onto the diree-\nC_^l^_^ \ndimensional lines yields an infinite number of \"nearest\" point pairs, which is clearly\nONTHCCO \nincorrect. The test code provided on the companion CD-ROM is a useful tool to see\n",
      "content_length": 3306,
      "extraction_method": "Direct"
    },
    {
      "page_number": 187,
      "chapter": null,
      "content": "194 \nSection 2 Mathematics\nthis problem, as it allows you to rotate the view to see two line segments from differ-\nent viewing angles, and displays the three-dimensional nearest points that you can\ncompare to the intersection point seen in the viewport.\nIn the next section, I derive a closed-form solution to the calculation of points C\nand D that does not make any assumptions about where the two line segments lie in\nspace. The solution does handle two special cases, but these cases are unavoidable\neven in the alternative approaches.\nDerivation of Closed-Form Solution Equations\nCalculating the Nearest Points on Two Infinite Lines\nThe equation of a line in three-dimensional space can be considered a vector function\nof a single scalar value, a parameter. To derive a closed-form solution to the nearest-\npoint between two 3D lines, we first write the equation for an arbitrary point,\nC = [Cx \nCy \nCJr, located on the first line segment, as Equation 2.3.1.\nC = Al+sLA, where LA = (A2 - 4) \n(2.3.1)\nNotice that Equation 2.3.1 basically says that the coordinates of any point on the\nfirst segment are equal to the coordinates of the first defining point plus an arbitrary\nscalar parameter s times a vector pointing along the line from the first defining point\nto the second defining point. If s is equal to zero, the coordinate is coincident with the\nfirst defining point, and if s is equal to 1, the coordinate is coincident with the second\ndefining point. We can write a similar equation for an arbitrary point, D = [Dx Dy\nDJT, located on the second line segment, as Equation 2.3.2:\nD = 5; + tLB, where LB = #, - B \n(2.3.2)\nHere, t is a second arbitrary scalar parameter, with the same physical meaning as s\nwith respect to the second line segment. If the parameters s and t are allowed to be\narbitrary, then we will be able to calculate points C and D as they apply to infinite\nlines rather than finite segments. For any point on a. finite line segment, the parame-\nters s and t will satisfy 0 < s,t < 1 . We'll allow s and t to float arbitrarily for now, and\ntreat the finite length segments later.\nThe two 3D line segments intersect if we can find values of s and t such that\npoints C and D are coincident. For a general problem, there will rarely be an intersec-\ntion, however, and we require a method for determining s and t that corresponds to\nthe nearest points C and D. The remainder of the derivation shows how to solve for\nthese values of; and t.\nFirst, subtract Equation 2.3.2 from Equation 2.3.1 to obtain the following equa-\ntion for the vector between points C and D:\n",
      "content_length": 2588,
      "extraction_method": "Direct"
    },
    {
      "page_number": 188,
      "chapter": null,
      "content": "2.3 Fast, Robust Intersection of 3D Line Segments\n195\nC-D = -AB + sLA - tLB = [o 0 OJr\nwhere AB = Bl - Al\n(2.3.3)\nHere, since we would like for points C and D to be coincident, we set the vector\nbetween the points to be the zero vector. The right side of Equation 2.3.3 can then be\nrepresented by the following matrk equation:\ns*\nLA. -L,\nABy\nAB.\n(2.3.4)\nThere are three rows in Equation 2.3.4, one for each coordinate direction, but\nonly two unknowns, the scalar values s and t. This is a classic over-determined or\nunder-constrained system. The only way there can be an exact solution is if the coef-\nficient matrix on the left side turns out to have rank 2, in which case the three equa-\ntions are equivalent to just two independent equations, leading to an exact solution\nfor s and t. Geometrically, when there is an exact solution, the two lines have a true\nintersection and are coplanar. Thus, two arbitrary lines in three-dimensional space\ncan only have a true intersection when the lines are coplanar.\nThe difference between the left side and right side of Equation 2.3.4 is equal to\nthe vector representing the distance between C and D. It is also the error vector of\nEquation 2.3.4 for any arbitrary values of s and t. We determine the nearest points by\nminimizing the length of this vector over all possible values of s and t.\nThe values of s and t that minimize the distance between C and D correspond to\na linear least-squares solution to Equation 2.3.4. Geometrically, the least-squares solu-\ntion produces the points C and D. When we have the case of the segments being\ncoplanar but not parallel, then the algorithm will naturally produce the true intersec-\ntion point. Equation 2.3.4 can be written in the form:\nM? = b, where 7 = I s \nt\\\n(2.3.5)\nOne method for finding the least-squares solution to an over-determined system\nis to solve the normal equations instead of the original system [Golub96]. The normal\nequations approach is suitable for this problem, but can be problematic for general\nproblems involving systems of linear equations. We generate the normal equations by\npremultiplying the left side and right side by the transpose of the coefficient matrk\nM. The normal equations for our problem are shown as Equation 2.3.6.\nMTM? = MT£ , where Mris the transpose of M.\n(2.3.6)\n",
      "content_length": 2301,
      "extraction_method": "Direct"
    },
    {
      "page_number": 189,
      "chapter": null,
      "content": "196\nSection 2 Mathematics\nEquation 2.3.6 has the desired property of reducing the system to the solution of\na system of two equations, exactly the number needed to solve algebraically for values\nof / and t. Let's carry through the development of the normal equations for Equation\n2.3.4. Expanding according to Equation 2.3.6 , the normal equations are:\nLAX \nLAy \nL^\n~~JLiD., \n~~\"-L>O,. \n-t-'D™\n~L\nBy\n-Ax\n-Ay\n-Az\nLBz\nABX\nABy\nAB.\n(2.3.7)\nCarrying through the matrix algebra:\nLA \n-LA\n\\-LA-LB\n-LS-AB_\n(2.3.8)\nOr, simplifying by defining a series of new scalar variables:\n(2.3.9)\nThis is a simple 2x2 system, and to complete this section we will solve it alge-\nbraically to form a closed-form solution for s and t. There are a number of ways to\nsolve Equation 2.3.9, including Cramer's rule [O'Neil87] and Gaussian elimination\n[Golub96]. Cramer's rule is theoretically interesting, but expensive, requiring approx-\nimately («+!)! multiply and divide operations for a general-sized problem. Gaussian\nelimination is less expensive, requiring «3/3 multiply and divide operations. There are\nother approaches to solving systems of linear equations that are significantly more\nreliable and often faster for much larger systems, including advanced direct solution\nmethods such as QR factorizations for moderate-sized systems, and iterative methods\nfor very large and sparse systems. I will derive the solution using Gaussian elimina-\ntion, which is slightly less expensive than Cramer's rule for the 2x2 system. Here, we\nperform one row elimination step to yield an upper triangular system. The row elim-\nination step is as follows. Modify row 2 of Equation 2.3.9 by taking the original row\n2 and subtracting row 1 times Ll2/Ln. to yield Equation 2.3.10.\nA,\nAa\nAi j \nAa \nAa T\nMI \nAi\nrn -\nAa\nAi\n(2.3.10)\nSimplify Equation 2.3.10 and multiply the new row 2 by Lu to yield the upper\ntriangular system shown in Equation 2.3.11.\n",
      "content_length": 1912,
      "extraction_method": "Direct"
    },
    {
      "page_number": 190,
      "chapter": null,
      "content": "2.3 Fast, Robust Intersection of 3D Line Segments \n197\ni;K \\ 1\n*• I \nI / \n*• \n/ \nr \n\\\nl/J \nL^ifB \nMl^J\nAl \n^ . 1 * 1 = 1 \n'^ \nI \n(2-3.11)\no AiA2-A2\n2\nEquation (2.3.11) immediately yields a solution for t,\nt = AI^B ~ LUTA \n(2.3.12)\n*i 1-^22 ~~ A£\nand then, for 5,\ns = TA ~ Lnt \n(2.3.13)\nAi\nIt is important to note that Equations 2.3.12 and 2.3.13 fail in certain degenerate\ncases, and it is these degenerate cases that require that we use tolerances in a limited\nway. Equation 2.3.13 will fail if line segment A has zero length, and Equation 2.3.12\nwill fail if either line segment has zero length or if the line segments are parallel. These\nsituations lead to a divide-by-zero exception. I provide more discussion later in the\nsection titled Special Cases.\nIn terms of computational expense for the 2x2 problem, the only difference\nbetween solving for s and t using Gaussian elimination and Cramer's rule, for this\ncase, is that the computation of s requires one multiply, one divide, and one subtrac-\ntion for Gaussian elimination, but four multiplies, one divide, and two subtractions\nfor Cramer's rule.\nTo summarize from the derivation, given line segment A from point Al to A2 and\nline segment B from point Bl to B2, define the following intermediate variables:\nLA = (A, - 4); ls = (B2 -B,)- ~AB = BI-AI \n(2.3.14)\nand\n•HI = ^A • LA; \nL22 = LB • LB; \nZ^ = — LA • LB\nCompute the parameters ^ and t that define the nearest points as,\nt = LU}\"B ~ ^2[A \n(2.3.16)\nAiAi ~ Ai\nand\ns =\n(2.3.17)\n",
      "content_length": 1489,
      "extraction_method": "Direct"
    },
    {
      "page_number": 191,
      "chapter": null,
      "content": "198 \nSection 2 Mathematics\nThe point where the first segment comes closest to the second segment is then\ngiven by:\nC = AL+ sLA \n(2.3.18)\nand the point where the second segment comes closest to the first segment is\ngiven by:\n£> = #!+ tLB \n(2.3.19)\nWe can consider a point located halfway between the two nearest points to be the\nsingle point in space that is \"nearest\" to both lines/segments as:\nP = (C + D)/2 \n(2.3.20)\nOf course, when the lines do intersect, point P will be the intersection point.\nSpecial Cases\nWhen we talk about the nearest points of two infinite lines in space, there are only\ntwo possible special cases. The first case occurs when one or both lines are degenerate,\ndefined by two points that are coincident in space. This occurs when point A^ is coin-\ncident with A2, or when B\\ is coincident with B2. We'll call this the degenerate line spe-\ncial case. The second case occurs when the two lines are parallel, called $\\<z parallel tine\nspecial case.\nIt is easy to relate the degenerate line special case to the equations developed pre-\nviously. Note that variable Ln, defined in Equation 2.3.15, is equal to the square of\nthe length of line segment A, and L22 is equal to the square of the length of segment\nB. If either of these terms is zero, indicating that a line is degenerate, then the deter-\nminant of the matrix in Equation 2.3.9 is zero, and we cannot find a solution for s\nand t. Note that when either Ln or L22 is zero, then L12 is also zero.\nOne standard test to check and decide if line A is degenerate is the following,\nbool line_is_degenerate = Ln < e2 ? true : false;\nHere, e is a small number such as perhaps 10\"6. It is wiser to choose a value for £\nsuch as 10\"6 rather than a much smaller number such as machine epsilon.\nWhen segments A and B are both degenerate, then point C can be selected to be\nequal to point A, and point D can be selected to be equal to point B^. When segment\nA alone is degenerate, then point Cis equal to A\\> and point D is found by computing\nthe point on segment B that is nearest to point C. This involves computing a value for\nparameter tonly, from Equation 2.3.21.\n-LBt = AB \n(2.3.21)\n",
      "content_length": 2155,
      "extraction_method": "Direct"
    },
    {
      "page_number": 192,
      "chapter": null,
      "content": "2.3 Fast, Robust Intersection of 3D Line Segments \n199\nEquation 2.3.21 is a simplification of Equation 2.3.4 for the case where segment\nA is degenerate, and again it requires that we find a least-squares solution. The least-\nsquares solution, shown here using normal equations without derivation, is:\n(2.3.22)\nPoint D can be calculated using Equation 2.3.2.\nWhen segment B alone is degenerate, then point D is set equal to B\\, and point C\nis found by computing the point on segment A that is nearest to point D. This\ninvolves computing a value for parameter s only, from Equation 2.3.23, which is anal-\nogous to Equation 2.3.21.\nLA* = AB \n(2-3.23)\nSolving for s yields:\ns = -p- \n(2.3.24)\nAi\nNote that Equation 2.3.24 is identical to Equation 2.3.13 with fset equal to zero.\nSince t equals zero at point Blt our derivation here is consistent with the derivation for\nnondegenerate lines.\nCertainly, a nice way to handle the cases where only one segment is degenerate is\nto write a single subroutine that is used both when segment A alone is degenerate and\nwhen B alone is degenerate. It is possible to do this using either Equation 2.3.22 or\nEquation 2.3.24, as long as the variables are treated properly. The implementation\n(^CBj5| \nprovided on the companion CD-ROM uses Equation 2.3.24 for both cases, with\nmm a \nparameters passed in such that the degenerate line is always treated as segment B, and\nthe nondegenerate line is always treated as segment A.\nIt is also easy to relate die parallel line special case to the equations developed pre-\nviously, although it is not quite as obvious as the degenerate case. Here, we have\nto remember that L12 is the negative dot product of the vectors LA and LB, and\nwhen the lines are parallel, the dot product is equal to the negative of the length of LA\ntimes the length of LB. The determinant of the matrix in Equation 2.3-9 is given by\nLnL22 - Lu, and this is equal to zero when L12 is equal in magnitude to the length of\nLA times the length of LB. Thus, when the line segments are parallel, Equation 2.3.9\nis singular and we cannot solve for s and t.\nIn the case of infinite parallel lines, every point on line A is equidistant from line\nB. If it is important to find the distance between lines A and B, simply choose C to be\nequal to Alt and then use Equations 2.3.22 and 2.3.2 to find D. Then, the distance\nbetween C and D is the distance between the two segments. We'll look at how to han-\ndle finite length segments in the next section.\n",
      "content_length": 2486,
      "extraction_method": "Direct"
    },
    {
      "page_number": 193,
      "chapter": null,
      "content": "200 \nSection 2 Mathematics\nCoding Efficiency\nFor coding efficiency, you should check first for degenerate lines, and then for parallel\nlines. This approach eliminates the need to calculate some of the convenience\nvariables from Equations 2.3.14 and 2.3.15 when one or both of the lines are degen-\nerate.\nDealing with Finite Line Segments\nThe previous two sections treated infinite lines. This is useful; however, there are per-\nhaps many more situations in game development when it is required to process finite\nline segments. So, how do we adjust the results shown previously to deal with finite-\nlength line segments?\nLine Segments that Are Not Parallel\nIf Equations 2.3.12 and 2.3.13 generate values of s and t that are both within the\nrange [0,1], then we don't need to do anything at all, since the finite length line seg-\nment results happen to be identical to the infinite line results. Whenever one or both\nof s and rare outside of [0,1], then we have to adjust the results. For nonparallel lines,\nthere are two possibilities: 1) s or t is outside of [0,1 ] and the other is inside [0,1]; and\n2) both s and rare outside of [0,1]. Figure 2.3.2 illustrates these two cases.\nFor the case when just one of s or t is outside of [0,1], as in Figure 2.3.2a, all we\nneed to do is:\n1. Clamp the out-of-range parameter to [0,1].\n2. Compute the point on the line for the new parameter. This is the nearest\npoint for the first segment.\n3. Find the point on the other line that is nearest to the new point on the first\nline, with the nearest point calculation performed for a finite line segment.\nThis is the nearest point for the second segment.\nIn the last step, just clamp the value from Equation 2.3.22 to [0,1] before calcu-\nlating the point on the other segment.\nFor the case when both s and t are outside of [0,1], as in Figure 2.3.2b, the situa-\ntion is slightly more complicated. The process is exactly the same except that we have\nto make a decision about which segment to use in the previous process. For example,\nif we selected line segment^ in Figure 2.3.2b, step 2 would produce point A2. Then,\nstep 3 would produce point 5ls the nearest point on segment B to point A2. The pair\nof points, A2 and BI clear jv are not the correct points to choose for Cand D. Point Bl\nis the correct choice for D, but there is a point on segment A that is much closer to\nsegment B than A2. In fact, the point generated by step 3 will always be the correct\nchoice for either C or D. It is the point from step 2 that is incorrect. We can compute\nthe other nearest point by just using the result from step 3. The process for both s and\nt outside of [0,1] then becomes:\n",
      "content_length": 2657,
      "extraction_method": "Direct"
    },
    {
      "page_number": 194,
      "chapter": null,
      "content": "2.3 Fast, Robust Intersection of 3D Line Segments \n201\nInfinite Line Result\nInfinite Line Result \n„ \n_.£__ \n,\n\"2 \n, \n1\nB7\n \nB2\nFinite Line Result\nFinite Line Result\n0 \n-I.......Q\nFIGURE 2.3.2 Finite-length line segments. A) Either sortis outside of[0,1]. B) Both s\nand t are outside of[0,1].\n1. Choose a segment and clamp its out-of-range parameter to [0,1].\n2. Compute the point on the line for the new parameter. This is not guaran-\nteed to be the nearest point for the first segment!\n3. Find the point on the other line that is nearest to the new point on the first\nline, with the nearest point calculation performed for a finite line segment.\nThis is the nearest point for the second line segment.\n4. Find the point on the first line segment that is nearest to the point that\nresulted from step 3. This is the nearest point for the first line segment.\nIf we select segment B in Figure 2.3.2b as our initial segment to correct, we would\nimmediately select point 5;, and step 3 would give the point between Al and A2. In\nthis case, step 4 is not required. The implementation provided here does not bother to\ncheck for this situation.\nLine Segments that Are Parallel\nThere are two basic possible scenarios when the two segments are parallel, both of\nwhich are illustrated in Figure 2.3.3. First, there might be a single unique pair of near-\nest points, shown in Figure 2.3.3a. This always occurs when the projection of both\nsegments into a line parallel to both do not overlap. Second, there might be a locus of\npossible nearest point pairs, shown in Figure 2.3.3b. Here, we could choose the two\n^*-^5 \nnearest points to be any pair of nearest points between the two vertical gray lines. The\nON me co \nimplementation provided on the accompanying CD-ROM selects the nearest points\nfor finite length, overlapping parallel line segments to be halfway between the gray\nlines; that is, at the midpoint of the overlapping portion of each segment.\nIt is important to note that when the two segments are parallel, or almost parallel,\nthe nearest points computed by this algorithm will often move erratically as the lines\n",
      "content_length": 2114,
      "extraction_method": "Direct"
    },
    {
      "page_number": 195,
      "chapter": null,
      "content": "Section 2 \nMathematics\nA \nB\nFIGURE 2.3.3 Parallel line segments. A) Unique nearest point pair. B) Locus of nearest\npointpairs.\nare rotated slightly. The algorithm will not fail in this case, but the results can be con-\nfusing and problematic, as the nearest points jump back and forth between the ends\nof the segments. This is illustrated in Figure 2.3.4.\nShown in Figure 2.3.4a, the nearest points will stay at the far left until the lines\nbecome exactly parallel, at which point the nearest points will jump to the middle of\nthe overlap section. Then, as the lines continue to rotate past parallel, the nearest\npoints will jump to the far right, shown in Figure 2.3.4b. This behavior may be prob-\nlematic in some game applications. It is possible to treat the behavior by using a dif-\nferent approach to selecting the nearest point when lines are parallel or near parallel.\nFor example, you could implement a rule that arbitrarily selects the point nearest A\\\nas the nearest point on segment A when the segments are parallel within, say, 5\ndegrees of each other. To avoid the erratic behavior at the 5-degree boundary, you\nwould need to blend this arbitrary nearest point with an algorithmically generated\nnearest point between, say, 5 and 10 degrees, with the arbitrary solution being 100%\nat 5 degrees and 0% at 10 degrees. This solution will increase the expense of the algo-\nrithm. There are certainly other approaches, including ones that may be simpler,\ncheaper, and more reliable. The implementation provided on the companion CD-\n*'**\"* \nROM does not attempt to manage this behavior.\nA \nB\nFIGURE 2.3.4 Erratic movement of nearest points for nearly parallel line segments. A)\nNearest points at the left. B) Nearest points at the right.\nImplementation Description\nThe implementation includes four C-language functions, contained in the files\nlineintersect_utils.h and lineintersect_utils.cpp. The primary interface is the function\nIntersectLineSegments, which takes parameters defining the two line segments, and\nreturns points C, D, and P, as well as a vector between points Cand D. The function\n",
      "content_length": 2104,
      "extraction_method": "Direct"
    },
    {
      "page_number": 196,
      "chapter": null,
      "content": "2.3 Fast, Robust Intersection of 3D Line Segments \n203\nalso takes a parameter indicating whether you want the line segments to be treated as\ninfinite lines, and a tolerance parameter to be used to check the degenerate and paral-\nlel line special cases. The vector between C and D can be used outside of the imple-\nmentation to determine a distance between the lines. It is important to note that the\nvector is not necessarily normal to either of the line segments if the lines are finite. If\nthe lines are infinite and at least one is not degenerate, the vector will be normal to the\nnondegenerate line(s). The supporting functions are as follows:\n• FindNearestPointOnLineSegment calculates the point on a line segment that is\nnearest to a given point in three-dimensional space.\n• FindNearestPointOjParallelLineSegments calculates representative (and possibly\nunique) values for Cand D for the case of parallel lines/segments.\n• AdjustNearestPoints adjusts the values of C and D from an infinite line solution to\na finite length line segment solution.\nThe code is documented with references to the text.\n,,— -,„ \nA test program is also provided, called line_intersection_demo. The demo requires\n^-ll-^ \nthat you link to the GLUT library for OpenGL. Project files are present for Microsoft\nVisual C++ 6.0 for Windows. It should not be too difficult to port this to other sys-\ntems that support OpenGL and GLUT.\nOpportunities to Optimize\nThe implementation source code was written carefully, but without any attempt to\noptimize for a particular processor or instruction set. There are a number of opportu-\nnities in every code to optimize the implementation for a given platform. In this case,\nperhaps the biggest opportunity is in the area of vectorization. There are numerous\noperations in this code that require a multiply or addition/subtraction operation on\nall three elements of a vector. These are prime opportunities to vectorize. Addition-\nally, if you have an instruction set that supports high-level operations such as dot\nproducts, take advantage when evaluating Equation (2.3.15), for example. To truly\nmaximize the performance, I strongly recommend that you use a professional code\nprofiling utility to identify bottlenecks and opportunities for your target platform(s).\nI i§£% \nThe text presented here and the implementation provided on the accompanying\nONWCD \nCD-ROM is rigorous, and treats every conceivable situation. The code is generally\nefficient, but in the case where the infinite lines intersect outside of the range of the\nfinite segments (in other words, one or both ofs and t are outside of [0,1]), the true\nnearest points are not necessarily cheap to compute. In fact, the nearest point problem\nwe've solved here is a minimization problem, and as is the case in general, the cost\nincreases when constraints are applied to minimization problems. Beyond proces-\nsor/platform-specific optimizations, it is certainly possible to remove parts of the\nimplementation that are not required for your application. For example, if you do not\nneed to treat finite length segments, remove everything that deals with finite length\n",
      "content_length": 3144,
      "extraction_method": "Direct"
    },
    {
      "page_number": 197,
      "chapter": null,
      "content": "204 \nSection 2 Mathematics\nsegments. Just have the main function return a bool that is true when the nearest\npoint is found between the finite segment endpoints, and false when the nearest point\nis found outside the finite segment endpoints.\nConclusions\nThe algorithm discussed here is rigorous and capable of handling any line intersection\nproblem without failing. Depending on your particular use of line intersections, you\nmay need to adjust the algorithm; for example, to manage the idiosyncrasies that arise\nwhen two finite segments are nearly parallel, or to remove the processing of finite seg-\nments when you only deal with infinite lines. I sincerely hope that some of you will\nbenefit from this formal discussion of line and line segment intersections, along with\nready-to-use source code.\nReferences\n[Golub96] Golub, Gene H., and Charles F. van Loan, Matrix Computations, Third\nEdition, The Johns Hopkins University Press, 1996.\n[O'Neil87] O'Neil, Peter V., Advanced Engineering Mathematics, Second Edition,\nWadsworth Publishing Company, 1987.\n",
      "content_length": 1055,
      "extraction_method": "Direct"
    },
    {
      "page_number": 198,
      "chapter": null,
      "content": "2.4\nInverse Trajectory\nDetermination\nAaron Nicholls, Microsoft\naaron feedback@hotmail.com\nA\nproblem frequently faced in the development of games is that of calculating tra-\njectories. In the most common case, we have a velocity and a direction for a pro-\njectile, and need to determine the location at a given time, and whether the projectile\nhas collided with any other entities. This is a simple iterative problem, but it is not all\nthat is required for most games. In many cases, we also need to solve the inverse of this\nproblem; namely, given a number of constants (gravity, starting position, intended\ndestination), we must calculate the proper yaw, pitch, and/or initial velocity to propel\nthe projectile between the two points. In addition, once we have a solution for this\nproblem, we can use this as a framework for solving more complex variants of the\nsame problem.\nThis gem expects that the reader is familiar with fundamental 2D/3D transfor-\nmations, basic integral calculus, and trigonometry.\nSimplifying the Problem at Hand\nThere are several ways to simplify the problem, and we can begin by reducing a three-\ndimensional problem to a two-dimensional one. Given an initial velocity and direc-\ntion for a projectile, if the only acting force is gravity (which can usually be assumed\nto be constant), the trajectory of the projectile will be parabolic and planar. Therefore,\nby transforming this planar trajectory into two dimensions (x and_y), we can simplify\nthe problem significantly. In addition, by translating the starting point to the origin,\nwe can remove the initial x and y values from most of the equations, focusing on the\ndestination coordinates. A sample trajectory, rotated into the xy plane and translated\nto the origin, is shown in Figure 2.4.1.\nIn addition, we need to determine exactly what the problem is that we wish to\nsolve. In this case, our variables are initial velocity, angle of elevation, and distance in\nx and y between the points. In the case where we know three of the four values (and\nthus have one unknown), our goal is to produce an equation that defines the value of\nthe unknown in terms of the three known values.\n205\n",
      "content_length": 2168,
      "extraction_method": "Direct"
    },
    {
      "page_number": 199,
      "chapter": null,
      "content": "206\nSection 2 Mathematics\nSource\nDestination (x, y)\nv, = Vj cos 6\nFIGURE 2.4.1 Trajectory between two points in two dimensions.\nHowever, it is very common to have to deal with multiple unknowns. In that\ncase, the best solution is typically to get rid of some of the variables by setting their\nvalues to constants. For instance, we often know the locations of the two points, but\nneed to provide an initial velocity and angle of elevation. In this case, we can elimi-\nnate initial velocity as a variable by setting it to the maximum possible velocity vmac\nBy doing so, we only have one unknown, and we simply need to determine the angle\nof elevation 6 in terms of v ,-, x, and y. This technique and guidelines for using it are\ndiscussed in further detail later in this gem, under Solving for Multiple Variables.\nDefining Position and Velocity as a Function of Time\nNow that we have reduced the problem to two dimensions, we can identify the veloc-\nity and acceleration working in each dimension. Starting with initial velocity vf, angle\nof elevation ?, and gravity g, we can express initial velocity along the x and y axes as\nfollows:\nvyi = Vf sinO\nSince the only force acting upon this system is gravity, we can assume that verti-\ncal velocity (v,) stays constant, while gravity is acting upon horizontal velocity (vy).\nThe two can be expressed as follows:\nvx = v{ cosO \n(2.4.1)\nv = v/ sin 0 — gt\n(2.4.2)\nNext, we integrate the velocity equations to determine the position at a given\ntime (assuming the origin as the starting point).\n",
      "content_length": 1534,
      "extraction_method": "Direct"
    },
    {
      "page_number": 200,
      "chapter": null,
      "content": "2.4 Inverse Trajectory Determination \n207\nx = \\vt cos 9 dt\n-> x = vf cos 9 \n(2.4.3)\ny = J (»,- sin 0- gt]dt\ny = vf sin 0 \n£t2 \n(2.4.4)\nA Special Case:\nBoth Points at the Same Elevation\nBefore tackling the general case of this problem, let's examine a simpler case, which\nwill give us insight into solving the more general problem. One of the common spe-\ncial cases is that in which both the start and end points have the same y value. An\nexample of this might be a game where the ground is flat, and a cannon on the ground\nis firing at a ground target. In this case, we know that y, the horizontal displacement\nbetween the two points, is zero. Therefore, we can simplify the horizontal position\nequation by setting y=0. This allows us to simplify Equation 2.4.4 to solve for time t,\ninitial velocity vt, or angle of elevation 9 as follows:\ny = vf sin 9 -- gf2 =0\n2v • sin 6\n-> t = — '- -\ng\nFt\n-» V; = —& -\n2 sin 0\nIn addition, this leads to a simplified formula for calculating x for this special case:\ni\nx = v\\ — '- - - cos0\nI \ng \n)\n2v sin 9 cos 9\nx = — \n'- -\ng\n",
      "content_length": 1063,
      "extraction_method": "Direct"
    },
    {
      "page_number": 201,
      "chapter": null,
      "content": "208 \nSection 2 Mathematics\nUsing the trigonometric identity sin 9 cos 0 = sin 29, we can simplify further as\nfollows:\n2v; sin 29 \n. . .\nx = —'- \n(2.4.5)\ng\nIn addition, in the previous case where a ground-based cannon is firing at ground\ntargets on flat terrain, this equation can be used to determine the maximum horizon-\ntal range of a cannon at angle of elevation 0, given maximum projectile velocity v^:\nRange =\n,2sin29\ng\n(2.4.6)\nSolving for Angle of Elevation\nNow that we have defined the equations that define the projectile's movement and\nsolved for a special case, we can continue to solve for the more general case. First, we\nwill analyze the case in which both points may not be at the same altitude, and\nwe must determine the angle of elevation or velocity required to propel a projectile\nbetween the two points. Since we have expressed x and y in terms of t, we can begin\nby removing t from the equation and defining x and^ in terms of each other.\nn \nX\nx = v-t cos 9 —» t = vf cos 9\nNext, we replace t with x I v, cos 9 in the equation for y to remove t from the\nequation.\ny = vitsm9--gt2\ni vf cos 9\n-> y = x tan 9 -- —\n2vf cos2 9\nWe then use the trigonometry identity I/cos2 9 = tan2 9 + 1 to reduce further.\n\") \nT \n'\n2v \ncos2 9\n",
      "content_length": 1241,
      "extraction_method": "Direct"
    },
    {
      "page_number": 202,
      "chapter": null,
      "content": "2.4 Inverse Trajectory Determination\n209\n. \nme2 (tan2 0 + 1)\ny = x tan 0 - &—\n2V;\nxtan0\ny = 0\n(2.4.7)\nAs odd as this final equation may look, it serves a purpose: this version of the\nequation fits into the quadratic equation as follows:\ntan0 =\nwhere\n-b ± V£2 - 4ac\n2a\nPlugging the preceding values of a, b, and c into the quadratic equation and solv-\ning for 9, we obtain the following:\n6 = tan\n,\n-x±\ns\nV-\ny\n-> 9 = tan\n-x±\nV;\n•\\\\\n(2.4.8)\n",
      "content_length": 438,
      "extraction_method": "Direct"
    },
    {
      "page_number": 203,
      "chapter": null,
      "content": "210\nSection 2 Mathematics\nThe quadratic form provides us with a way to solve for G, given a known initial\nvelocity vf, horizontal displacement x, and vertical displacement y. If (b2 - 4ac) is\npositive, we have two possible solutions, and if it is negative, there are no solutions for\nthe given parameters. In addition, if the initial velocity is zero, we know that the tra-\njectory is entirely vertical, so 6 is irrelevant.\nWhen dealing with two trajectories, it is important to remember that the flatter\ntrajectory will yield a faster route to the target, and is thereby preferable in most cases.\nIf both angles are between -7C/2 and 7t/2, the angle closer to zero will yield the flatter\ntrajectory for a given vf. A case with two valid angles of elevation to reach a given tar-\nget is shown in Figure 2.4.2. Here, Trajectory 2 is the fastest.\nTrajectory 1\nSource\nTrajectory 2\nDestination (x, y)\nFIGURE 2.4.2 Two angle of elevation solutions OC and§ for a given Vj.\nSolving for Initial Velocity\nNow that we have the problem solved for the case where 0 is unknown, we can change\nEquation 2.4.7 slightly to solve for initial velocity vt, given a known angle of elevation\n9, horizontal displacement x, and vertical displacement y as follows:\n2 \n_ 2\n2\n- tan 9 - x tan 0 + &— + 7 = 0\n2vs\n2v:\n6 + £—r = x tan 6 - y\n-> ^-(tan2 0 + 1) = xtanfl - y\n2v\nWe then multiply both sides by V; /(x tan Q -y), thereby isolating initial velocity.\n",
      "content_length": 1429,
      "extraction_method": "Direct"
    },
    {
      "page_number": 204,
      "chapter": null,
      "content": "2.4 Inverse Trajectory Determination \n211\n-(tan20\n2(x tan 9 -\nSolving for vf, we get the following:\n— y)\nAgain, we can choose to use the trigonometric identity I/cos2 6 = fan2 6 + 1 to\nsimplify the square root.\n(2A10)\nAgain, since we are dealing with a square root, there are some cases that have no\nsolution. An example would be when the slope of the initial trajectory is less than the\nslope to the target. One special case is where 6=n/2 (straight upward), since there can\nbe two solutions.\nCalculating Maximum Height for a Trajectory\nSolving for peak height of a trajectory is straightforward: vertical peak is defined as\nthe point where vertical velocity vy=0, given 9>0. Therefore, we simply solve the ver-\ntical velocity equation as follows:\nvy(t) = vi sin0 - gt = 0\nSolving for t, we get the following:\nv sin 6\ng\nNow, to determine the maximum altitude, we substitute the preceding value for t\nin the vertical position equation as follows:\n-\nv] sin2 9 \ng\\vi sin 9 |\nv] sin2 9\n— - - \n(2.4.11)\n",
      "content_length": 999,
      "extraction_method": "Direct"
    },
    {
      "page_number": 205,
      "chapter": null,
      "content": "212 \nSection 2 Mathematics\nAs mentioned previously, this depends on &>0. If the angle of elevation 6 is neg-\native (pointing downward), the vertical peak will be a.ty=0, since the projectile's initial\ndownward velocity is only increased by gravity. This is somewhat of a special case,\nsince vertical velocity is not necessarily zero at the vertical peak in this case.\nCalculating Flight Time\nIn order to determine time to destination, we can simply rewrite the horizontal posi-\ntion from Equation 2.4.3 in terms of?.\nx(t) = vf cos 6 —» t = vi cos d\nHowever, in the case where v^ = 0 or cos 6 = 0, t is undefined if expressed in terms\nof x In addition, in this case, x will always be zero, and no solutions exist in this case\nif the two points are not at the same x value. In implementation, these boundary cases\nare worth testing, since a mistake here can cause an engine to crash or behave errati-\ncally at times.\nTo solve for t when vt = 0 or cos 6 = 0, we can use the vertical position equation\nfrom Equation 2.4.4 instead.\ny(t) = vf sin 0 - - gt2\nIf Vi = 0, we can use the following equation to express t in terms of/ and g.\ny - — & -> t =\ni\nHowever, if cos 6 = 0 and v{>0, there can be one or two solutions (the latter hap-\npens only ifd>0, since vf >0 in practice). In addition, we know that if cos 6 = 0, sin 6\n= ±1. This reduces the problem further, but we still need to express this in terms of t\nas follows:\ny = vitsine--gt2\n-> - gt2 - Vft sin 6 + y = 0 \n(2.4.12)\nThis is a quadratic in terms of t, and the solution thereof is left to the reader.\nSolving for Multiple Variables\nAs mentioned near the start of this topic, it is very common that two or more values\nare unknown or need to be determined, usually 9 and vf (since both points are usually\n",
      "content_length": 1759,
      "extraction_method": "Direct"
    },
    {
      "page_number": 206,
      "chapter": null,
      "content": "2.4 Inverse Trajectory Determination \n213\nknown). In multivariate cases, the set of possible solutions expands greatly, so in order\nto solve the problem, the fastest approach is to eliminate some of the unknowns. In\nthe most common case, we are given two points and a maximum initial velocity vmax,\nand need to solve for both v-t and G.\nWhen reducing variables in order to simplify to a single-variable problem, it is\nimportant to reduce in a manner that does not overly restrict possible solutions. In the\nprevious case in which both 6 and vt are unknown, restricting 6 greatly reduces the\nnumber of solutions, and is undesirable. On the other hand, setting vf = vmax and\nvarying 6 preserves a larger set of landing points. This same logic can be extended to\nother forms of this problem, although there is not space to elaborate further within\nthe scope of this gem.\nOptimizing Implementation\nWhen implementing the previous equations in code, there are a few optimizations\nthat can make a substantial difference in performance. This is because trigonometric\nfunctions have a very high overhead on most systems.\nAvoid Oversimplification\nWhen deriving mathematical calculations, there is a tendency to reduce formulae to\ntheir simplest mathematical form, rather than the simplest or most optimal algo-\nrithm. For instance, in solving for initial velocity vf, we came across Equations 2.4.9\nand 2.4.10 as follows:\nv- = x\nx \n£\nThe tendency from a mathematical point of view would be to prefer the latter\nform, since it reduces the equation; however, in implementation, it is more efficient to\nprecalculate tan 9 and use it twice in the first equation, rather than calculating both\ntan 9 and cos 9 as is done in the latter formula. In addition, even if we choose to use\nthe second equation (and not simplify to terms of tan Q), leaving cos 9 outside of the\nsquare root bracket means that two divisions need to be done: one inside the bracket\nand one outside. To optimize, one can either place the cos 9 inside the divisor within\nthe bracket as cos2 9, or multiply x by II cos 9.\n",
      "content_length": 2075,
      "extraction_method": "Direct"
    },
    {
      "page_number": 207,
      "chapter": null,
      "content": "214 \nSection 2 Mathematics\nReduce Trigonometric Functions to\nSimpler Calculations\nRather than using the provided functions for sin, cos, and tan, it is much more effi-\ncient to use pregenerated lookup tables or take advantage of known relations between\nother variables. For instance, to calculate tan 9, you can simply divide the initial value\nof vy by t>x, since they are defined in terms of sin 6 and cos 9, respectively, and are likely\nprecomputed.\nIn addition, there is additional room for optimization—The purpose here is sim-\nply to alert the reader to the high computational cost involved with trigonometric cal-\nculation and the importance of optimization.\nSummary\nEfficient trajectory production can enhance perceived AI quality and engine perfor-\nmance. Although the derivation can be math intensive, the resulting equations are rel-\natively simple and easy to understand. In addition, once the process involved in\nderiving and simplifying the previous formulae is understood, it is easy to apply that\nknowledge to more complicated situations, such as moving targets, nonvertical accel-\neration, and other related problems.\n",
      "content_length": 1134,
      "extraction_method": "Direct"
    },
    {
      "page_number": 208,
      "chapter": null,
      "content": "2.5\nThe Parallel Transport Frame\nCarl Dougan\nCarl.dougan@gte.net\nI\nany tasks in computer games require generating a suitable orientation as an\nobject moves through space. Let's say you need to orient a camera flying along a\nlooping path. You'd probably want the camera to turn with the path and point along\nthe direction of travel. When the path loops, the orientation of the camera should\nchange appropriately, to follow the loop. You wouldn't want it to suddenly flip or\ntwist, but turn only to match the changes of the path. The parallel transport frame\nmethod can help provide this \"steady\" orientation.\nYou can also use this technique in the generation of geometry. A common opera-\ntion in 3D modeling is lofting, where a 2D shape is extruded along a path curve, and\nmultiple sections made from the shape are connected together to produce 3D geome-\ntry. If the 2D shape was a circle, the resulting 3D model would be a tube, centered on\nthe path curve. The same criteria apply in calculating the orientation of the shape as\ndid with the camera—the orientation should \"follow\" the path and shouldn't be sub-\nject to unnecessary twist.\nThe parallel transport method gets its stability by incrementally rotating a coor-\ndinate system (the frame) as it is translated along a curve. This \"memory\" of the pre-\nvious frame's orientation is what allows the elimination of unnecessary twist—only\nthe minimal amount of rotation needed to stay parallel to the curve is applied at each\nstep. Unfortunately, in order to calculate the frame at the end of a curve, you need to\niterate a frame along the path, all the way from the start, rotating it at each step. Two\nother commonly used methods of curve framing are the Frenet Frame and the Fixed\nUp method [EberlyOl], which can be calculated analytically at any point on the\npath, in one calculation. They have other caveats, however, which will be described\nlater.\nThe Technique\nA relatively simple numerical technique can be used to calculate the parallel transport\nframe [Glassner90]. You take an arbitrary initial frame, translate it along the curve,\nand at each iteration, rotate it to stay as \"parallel\" to the curve as possible.\n215\n",
      "content_length": 2180,
      "extraction_method": "Direct"
    },
    {
      "page_number": 209,
      "chapter": null,
      "content": "216 \nSection 2 Mathematics\nGiven:\na Curve C\nan existing frame Fl at t-1\na tangent Tl at t-1 (the 1st derivative or velocity of C at t-1)\na tangent T2 at t\na new frame F2 at the next time t can be calculated as follows:\nF2s position is the value of C at t.\nF2s orientation can be found by rotating Fl about an axis A with angle Ot, where\nA = Tl X T2 and\na = ArcCos((Tl •T2)/(|T1||T2|))\nIf the tangents are parallel, the rotation can be skipped (i.e., if Tl X T2 is zero)\n(Figure 2.5.1).\nA\nFIGURE 2.5.1 The frame at t-1 is rotated about A by Of to calculate the frame at t.\nThe initial frame is arbitrary. You can calculate an initial frame in which an axis\nlies along the tangent with the Fixed Up or the Frenet Frame method.\nIn some cases, you may find it desirable to use parallel transport to generate\nframes at a coarse sampling along the curve, and then achieve smooth rotation\nbetween the sample frames by using quaternion interpolation. Using quaternions is\ndesirable anyway, since there is an efficient method of generating a quaternion from a\nrotation axis and angle [EberlyOl]. You can use the angle and axis shown previously to\ngenerate a rotation quaternion, and then multiply it with the previous frame's quater-\nnion to perform the rotation.\nMoving Objects\nYou can orient a moving object with a single parallel transport rotation each time the\nobject is moved, presumably once per frame. We need three pieces of information: the\nvelocity of the object at the current and previous locations, and the orientation at the pre-\nvious location. The velocities correspond to the tangents Tl and T2 shown previously.\nFor some tasks, the parallel transport frame may be too \"stable.\" For example, an\naircraft flying an S-shaped path on the horizontal plane would never bank. To achieve\n",
      "content_length": 1790,
      "extraction_method": "Direct"
    },
    {
      "page_number": 210,
      "chapter": null,
      "content": "2.5 The Parallel Transport Frame\n217\nrealistic-looking simulation of flight, you may need to use a different solution, such as\nsimulating the physics of motion. Craig Reynolds describes a relatively simple, and\nthus fast, technique for orienting flocking \"boids\" that includes banking [Reynolds99].\nReynolds' technique is similar to parallel transport in that it also relies on \"memory\" of\nthe previous frame.\nComparison\nThe details here show how the parallel transport method we have looked at so far\ncompares with the Frenet Frame and Fixed Up methods of curve framing.\nThe Frenet Frame\nThe Frenet Frame is built from three orthogonal axes:\n• The tangent of the curve\n• The cross-product of the tangent, and the second derivative\n• Another vector generated from the cross-product of the prior two vectors\nThe Frenet Frame is problematic for the uses already discussed because it cannot\nbe calculated when the second derivative is zero. This occurs at points of inflection\nand on straight sections of the curve [Hanson95]. Clearly, not being able to calculate\na frame on a straight section is a big problem for our purposes. In addition, the frame\nmay spin, due to changes in the second derivative. In the case of an S-shaped curve,\nfor example, the second derivative points into the curves, flipping sides on the upper\nand lower halves. The resulting Frenet Frames on the S-shaped curve will flip in con-\nsequence. Figure 2.5.2 shows what this means graphically; instead of continuous\nFIGURE 2.5.2 Second derivative on an S-shaped curve, and Frenet Frame generated tube\nfrom the same curve.\n",
      "content_length": 1593,
      "extraction_method": "Direct"
    },
    {
      "page_number": 211,
      "chapter": null,
      "content": "218 \nSection 2 Mathematics\ngeometry, we have a discontinuity where the second derivative switches sides. If this\nwas a flock of birds, they would suddenly flip upside down at that point.\nThe Fixed Up Method\nIn the case of the Fixed Up method, the tangent T and an arbitrary vector V (the\nFixed Up vector) are used to generate three axes of the resulting frame, the direction\nD, up U, and right R vectors [EberlyOl].\nD = T / |T|\nR = DxV/|DxV|\nU = RxD\nA problem with the Fixed Up method occurs when the tangent and the arbitrary\nvector chosen are parallel or close to parallel. When T and V are parallel, the cross-\nproduct of D and V is zero and the frame cannot be built. Even if they are very close,\nthe twist of the resulting vector relative to the tangent will vary greatly with small\nchanges in T, twisting the resulting frame. This isn't a problem if you can constrain\nthe path—which may be possible for some tasks, like building the geometry of free-\nways, but may not be for others, like building the geometry of a roller coaster.\nFigure 2.5.3 shows a comparison of a tube generated using parallel transport with\none using the Fixed Up method. In the upper and lower sections of the curve, the\ncross-product of tangent and the Fixed Up vector is coming out of the page. In the\nmiddle section, it is going into the page. The abrupt flip causes the visible twist in the\ngenerated geometry.\nFixed Up \nParallel Transport\nFIGURE 2.5.3 Comparison of Fixed Up and parallel transport.\n",
      "content_length": 1484,
      "extraction_method": "Direct"
    },
    {
      "page_number": 212,
      "chapter": null,
      "content": "2.5 The Parallel Transport Frame \n219\nConclusion\nFor unconstrained paths—for example, flying missiles or looping tracks—parallel\ntransport is one method that you can use to keep the tracks from twisting and the\nmissiles from flipping.\nReferences\n[Glassner90] Bloomenthal, Jules, \"Calculation of Reference Frames Along a Space\nCurve,\" Graphics Gems, Academic Press, 1990: pp. 567-571.\n[EberlyOl] Eberly, David H., 3D Game Engine Design, Academic Press, 2001.\n[Hanson95] Hanson, Andrew)., and Ma, Hui, Parallel Transport Approach to Curve\nFraming, Department of Computer Science, Indiana University, 1995.\n[Reynolds99] Reynolds, Craig, \"Steering Behaviors for Autonomous Characters,\"\navailable online at www.red3d.com/cwr/steer/gdc99/index.html.\n",
      "content_length": 744,
      "extraction_method": "Direct"
    },
    {
      "page_number": 213,
      "chapter": null,
      "content": "2.6\nSmooth C2 Quaternion-based\nFlythrough Paths\nAlex Vlachos, ATI Research;\nand John Isidore\nalex@Vlachos.com and jisidoro@cs.bu.edu\nI\nn this gem, we describe a method for smoothly interpolating a camera's position and\norientation to produce a flythrough with C2 continuity. We draw on several known\nmethods and provide a C++ class that implements the methods described here.\nIntroduction\nSmoothly interpolating the positions of a flythrough path can easily be achieved by\napplying a natural cubic spline to the sample points. The orientations, on the other\nhand, require a little more attention. We describe a method for converting a quater-\nnion in S3 space (points on the unit hypersphere) into R4 space (points in 4D space)\n[Johnstone99]. Once the quaternion is in R4 space, any 4D spline can be applied to\nthe transformed data. The resulting interpolated points can then be transformed back\ninto S3 space and used as a quaternion. In addition, a technique called selective nega-\ntion is described to preprocess the quaternions in a way that produces the shortest\nrotation path between sample point orientations.\nCamera cuts (moving a camera to a new location) are achieved by introducing\nphantom points around the camera cut similar to the way an open spline is padded.\nThese additional points are needed to pad the spline to produce smooth results near\nthe cut point. The code provided describes cut points as part of a single fly path and\nsimplifies the overall code. Internally to the C++ class, the individual cut segments are\ntreated as separate splines without the overhead of creating a spline for each segment.\nPosition Interpolation\nLet's now discuss position interpolation.\nSample Points\nThere are two common ways to specify sample points. The first is to have each segment\nbetween control points represent a constant time (for example, each control point rep-\n220\n",
      "content_length": 1880,
      "extraction_method": "Direct"
    },
    {
      "page_number": 214,
      "chapter": null,
      "content": "2.6 Smooth C2 Quaternion-based Flythrough Paths \n221\nresents one second of time). The second is to use the control points only to define the\nshape of the camera path, and to have the camera move at a constant speed along this\npath. The code provided with this gem assumes a constant time between control points,\nalthough this code could easily be modified for the constant speed technique.\nNatural Cubic Spline\nA natural cubic spline is chosen due to the high degree of continuity it provides,\nnamely C2. However, it's important to note that any spline may be used in place of the\nnatural cubic spline. Code for implementing this spline is widely available, including\nNumerical Recipes In C [Press97]. The sample code provided is modeled after this.\nA natural cubic spline is an interpolating curve that is a mathematical representa-\ntion of the original drafting spline. One important characteristic of this spline is its\nlack of local control. This means that if any single control point is moved, the entire\nspline is affected. This isn't necessarily a disadvantage; in fact, this functionality may\nbe desirable. As you begin to use this spline, you'll see the advantages it has in smooth-\ning out the camera movement when you sample the spline at a higher frequency.\nIt is important to differentiate between open and closed splines. In the case of a\nclosed spline, the spline is specified such that the last point is the same as the first\npoint. This is done to treat the camera path as a closed loop. To work around any pos-\nsible discontinuities in the spline at the loop point, simply replicate the last four\npoints of the spline to the beginning of the array, and the first four sample points to\nthe end of the array. In practice, we've found that using four points was sufficient to\neliminate any visual artifacts.\nThis replication eliminates the need for modulus arithmetic and also simplifies\nour preprocessing of the camera path. This is even more important when dealing with\norientations using the selective negation method as described later (Figure 2.6.1).\n2,12\n-2,8\nFIGURE 2.6.1 Replicating points for a closed spline.\n",
      "content_length": 2135,
      "extraction_method": "Direct"
    },
    {
      "page_number": 215,
      "chapter": null,
      "content": "222\nSection 2 Mathematics\nFIGURE 2.6.2 Creating phantom points for an open spline.\nIn contrast, an open spline has a different beginning and end point. In order to\nsample the spline, you need to pad the spline with several \"phantom\" points at both\nthe beginning and end of the open spline (Figure 2.6.2). A constant velocity is\nassumed for the phantom points before and after the open spline path. At the begin-\nning of the spline in Figure 2.6.2, the vector V^Pj-Po is subtracted from P0 to get the\nresulting point P_j. Similarly, V0 is subtracted from P_j to create P_2, and so on. The\ntrailing phantom points are calculated in a similar way.\nOrientation Interpolation\nSample Points\nUnit quaternions are used as the orientation data at the sample points. Quaternions\ncan be very useful for numerous applications. The beauty of quaternions is that, for\nrotations, they take the form of a normalized 4-element vector (later referred to as a 3-\nelement vector and a scalar component). This is exactly enough information to repre-\n",
      "content_length": 1029,
      "extraction_method": "Direct"
    },
    {
      "page_number": 216,
      "chapter": null,
      "content": "2.6 Smooth C2 Quaternion-based Flythrough Paths \n223\nsent an axis of rotation and an angle of rotation around that axis [GPG1]. Quater-\nnions give us everything we need to represent a rotation and nothing more.\nFor orientation, however, there is an ambiguity in using quaternions. Orientation\ncan be thought of as a rotation from a base orientation. When using quaternions,\nthere are two possible rotations that will bring you to the same orientation. Suppose\nthere is a counterclockwise rotation 9 about an axis w that gives you the desired ori-\nentation. A rotation by 360°-0 about the axis —w also results in the same orientation.\nWhen converted into a quaternion representation, the second quaternion is simply\nthe negation of the first one.\nDirection of Rotation and Selective Negation\nWhen performing quaternion interpolation, there is one small nuance that needs to\nbe considered. When representing an orientation, either a quaternion or its negation\nwill suffice. However, when interpolating orientations (for example, performing a\nrotation), the positive and negative quaternions result in vastly different rotations and\nconsequently different camera paths. If the desired result is to perform the smallest\npossible rotation between each pair of two orientations, you can preprocess the\nquaternions to achieve this.\nTaking the dot product of two quaternions gives the cosine of half the angle of\nrotation between them. If this quantity is negative, the angle of rotation between the\ntwo quaternions is greater than 180 degrees. In this case, negating one of the orienta-\ntion quaternions makes the angle between the two quaternions less than 180 degrees.\nIn terms of interpolation, this makes the orientation spline path always perform the\nshortest rotation between the orientation key frames. We call this process selective\nnegation.\nThe technique of selectively negating orientation quaternions can be incorpo-\nrated as a preprocessing step for a camera flythrough path. For the preprocessing step,\ntraverse the flythrough path from start to end, and for each quaternion q,on the path,\nnegate it if the dot product between it and its predecessor is negative (in other words,\nif (qt- q,.j)<0). Using selective negation as a preprocessing step makes spline interpo-\nlation much more efficient by not requiring the selective negation math for every\nsample.\nTo preprocess a closed spline path, it is necessary to replicate the first four points\nof the spline path and append them to the end of the path prior to the selective nega-\ntion. Note that the replicated points may have different signs than the original points.\nWhen dealing with an open spline, you need to create phantom quaternions (corre-\nsponding to the phantom control points) to pad the spline. The concept is similar\nin that you want to linearly interpolate the difference between the two quaternions\nclosest to the beginning or end of the path. However, linearly interpolating quater-\nnions doesn't suffice. Instead, we use the spherical linear interpolation (slerp) algo-\nrithm. Given quaternions q0 and qt, we need to generate four phantom\nquaternions—q.j, q_2, and so on— to pad the beginning of an open spline. We use the\n",
      "content_length": 3201,
      "extraction_method": "Direct"
    },
    {
      "page_number": 217,
      "chapter": null,
      "content": "224 \nSection 2 Mathematics\nslerp function (spherical linear interpolation) to slerp from q, to q0 with a slerp value\nof 2.0. This effectively gives us a linear change in rotation at our phantom points.\nOnce we have preprocessed our entire list of orientation quaternions for interpo-\nlation, it is straightforward to perform smooth spline-based quaternion interpolation\ntechniques.\nSpline Interpolation for Quaternions\nAs seen for positional interpolation, splines can be used to give us much smoother\ninterpolation than linear interpolation can. However, spline interpolation for quater-\nnions is not so straightforward, and there are several techniques that can be used. One\ntechnique simply interpolates the raw quaternion values, and then renormalizes the\nresulting quaternion. However, this technique does not result in a smooth path and\nproduces bizarre changes in angular velocity. Another idea is to use techniques based\non the logarithms of quaternions. SQUAD (spherical quadrangle interpolation)\n[Shoemake91] is an example of this. A performance limitation is incurred when using\nthese techniques because they require transcendental functions (sin, cos, log, pow, and\nso on). Other techniques involve blending between great 2-spheres laying on the unit\nquaternion hypersphere [Kim95], or involve some sort of iterative numeric technique\n[Neilson92]. While many of these techniques provide decent results, most of them do\nnot provide C2 continuity or are computationally prohibitive to use, especially when\nmany flythrough paths are used (for game characters or projectiles, as an example).\nHowever, there is a technique for quaternion spline interpolation that gives very\ngood results and obeys derivative continuity requirements. This uses an invertible\nrational mapping Qohnstone99] M between the unit quaternion 4-sphere (S3) and\nanother four-dimensional space (R4). In the following equations, a, b, and c are the\ncomponents of the vector portion of the quaternion, and s is the scalar portion.\nThe transformation M-/ from S3 — >R4 is:\nx = a/sqrt(2(l-s))\ny = b/sqrt(2(l-s))\nz = c/sqrt(2(l-s))\nw=(l-s) /sqrt(2(l-s))\nThe transformation M from R4 — > S3 is:\na = 2xu> I (y? + y2 + z? + iv2)\nb = 2yw / (x2 + y2 + z2 + ui2)\nc = 2zw I (x2 + y2 + z2 + iv2)\nTo use this for quaternion spline interpolation is straightforward. First, selective\nnegation should be applied to the control quaternions to assure the shortest possible\nrotation between control points. After this, apply M ; to all the control quaternions to\nget their resulting value in R4. This can be done as a preprocessing step and can be\n",
      "content_length": 2608,
      "extraction_method": "Direct"
    },
    {
      "page_number": 218,
      "chapter": null,
      "content": "2.6 Smooth C2 Quaternion-based Flythrough Paths \n225\ndone in the flythrough-path building or loading stage of a program. This way, die\nsquare root does not have to be calculated when die flythrough path is being evaluated.\nNext, the resulting 4-vectors can be interpolated using the spline of your choice.\nBecause this is a continuous rational mapping, the continuity of the interpolated S3\nquaternion path has the same continuity as die spline used for interpolation in R4\nspace.\nIn our application, we use natural cubic splines [Hearn94] [Press97] for the inter-\npolation in R4 space.\nThis gives us C2 continuous orientation interpolation as well. The qualitative\neffect of this is that die camera path does not have any sharp changes in angular\nacceleration.\nAfter the desired point on the spline in R4 is found, it can be converted back into\na quaternion using M.\nHowever, there is one mathematical nuance in using this technique that needs to\nbe addressed.\nSingularity in the Rational Mapping\nIf your flythrough path contains orientation quaternions close or equal to (1,0,0,0), it\nwill cause numerical instability when interpolated through in R4 space, as M~;(l,0,0,0)\n= C00,00,00,00). There are a few ways to handle diis singularity. One possible option is to\nignore it, and surprisingly, this is feasible in many cases. For example, if the z-axis of the\nworld is pointing up, and you know the camera will never point straight up with the\ncamera's up-vector pointing up the y-axis, the orientation quaternion (1,0,0,0) will\nnever occur in the flythrough path, and die problem is solved.\nIf this is not the case, another option is to find a quaternion ^that is not within\n30 degrees of any of the orientation quaternions, and use gy-to rotate all of the quater-\nnions into \"safe\" orientations that are not near the singularity Qohnstone 99]. The\nbasic idea behind this is to perform the spline interpolation on a rotated version of\nyour flythrough path, and then rotate die interpolated orientations back into their\noriginal coordinate frame. All that has to be done is to multiply all your orientation\nquaternions by q^ after the selective negation step. Following, you transform the\nquaternions from S3 space into R4 space, apply the natural cubic spline, and transform\nthe resulting R4 values back into S3 space. After this, we add the additional step of\nrotating each resulting quaternion by qj1 before using it.\nAn easy way to find gy-is to randomly generate unit length quaternions, until you\nfind one that is not within 30 degrees of any of the selectively negated orientation\nquaternions.\nCamera Cuts\nA camera cut is defined as moving the camera from one point in your scene to another.\nYou can't just introduce a cut in the middle of a spline, and you can't simply step over\n",
      "content_length": 2790,
      "extraction_method": "Direct"
    },
    {
      "page_number": 219,
      "chapter": null,
      "content": "226\nSection 2 Mathematics\n14\nFIGURE 2.6.3 Creating phantom points for a path cut segment.\nCode\na segment of the spline. Instead, you segment your spline into two separate splines at\na cut point, and process these splines as separate open splines. This is done simultane-\nously for both the position- and orientation-based splines. The code we supply deals\nwith camera cuts in such a way that you don't need to explicitly create a separate path\n(see Figure 2.6.3).\nThe code accompanying this gem is a C++ class that implements most of the tech-\nniques explained in this article. It has member functions for creating and editing the\ncontrol points manually, reading and writing path files, dealing with cut points, sam-\npling the spline at a given time, and setting up vertex and index buffers for drawing\nthe spline. The class assumes there is a constant time between control points as\nopposed to a constant velocity. In addition, the code does not solve the singularity\nproblem, since we never saw the singularity in our project. Please see the source files\nfor more information.\n",
      "content_length": 1080,
      "extraction_method": "Direct"
    },
    {
      "page_number": 220,
      "chapter": null,
      "content": "2.6 Smooth C2 Quaternion-based Flythrough Paths \n227\nReferences\n[Press97] Press, William H., et al, Numerical Recipes in C, Cambridge University\nPress, 1997.\n[Hearn94] Hearn, Donald, Baker, M. Pauline, Computer Graphics Second Edition,\nPrentice Hall, Inc. 1994.\n[Johnstone99] Johnstone, J. K., Williams, J. P., \"A Rational Quaternion Spline of Arbi-\ntrary Continuity,\" Tech Report: www.cis.uab.edu/info/faculty/jj/cos.html, 1999.\n[GPG1] Edited by Mark DeLoura, Game Programming Gems, Charles River Media,\n2000.\n[Shoemake91] Shoemake, K., Quaternion Calculus for Animation, Math for SIG-\nGRAPH (ACM SIGGRAPH '91 Course Notes #2), 1991.\n[Neilson92] Neilson, G., and Heiland, R., \"Animating Rotations Using Quaternions\nand Splines on a 4D Sphere,\" English Edition, Programming and Computer Soft-\nware, Plenum Pub., New York. 1992.\n[Kim95] Kim, M.S. and Nam, K.W., Interpolating Solid Orientations with Circular\nBlending Quaternion Curves, Computer-Aided Design, Vol. 27, No. 5, pp.\n385-398,1995.\n",
      "content_length": 993,
      "extraction_method": "Direct"
    },
    {
      "page_number": 221,
      "chapter": null,
      "content": "2.7\nRecursive Dimensional\nClustering: A Fast Algorithm\nfor Collision Detection\nSteve Rabin, Nintendo of America\nsteve rabin@hotmail.com\n> asic collision detection can be a costly operation. The simplest method relies on\n'treating each object as a sphere and comparin n2 distances. Listing 2.7.1 shows\nthe code for this simple brute-force comparison algorithm. However, a new technique\ncalled Recursive Dimensional Clustering (RDC) can take the typical case from O(rf)\nto something close to O(nlog2n).\nListing 2.7.1 \nBrute-force comparison algorithm\n// Slightly optimized 0((n*2-n)/2) time complexity\nfor( i=0; i<num_objects; i++ ) {\nfor( j=i+l; j<num_objects; j++ ) {\nif( Distance(i, j) < Radius(i) + Radius(j) ) {\n//in collision\nThe practical difference between RDC and the brute-force method is shown in\nTable 2.7.1. These times were calculated on a Pentium II 400 MHz with data con-\ntaining only one collision. Note that the brute-force O(r^) algorithm was fully opti-\nmized to run at O((rf-n)/2) as in Listing 2.7.1 and compared positions using distance\nsquared in order to avoid the costly square root operation.\nWhat's interesting about Table 2.7. 1 is that RDC increases almost linearly, while\nthe brute force method increases exponentially. Although the results are remarkable,\nRDC only becomes useful if you are dealing with large numbers of objects that are\nusually not in collision.\n228\n",
      "content_length": 1398,
      "extraction_method": "Direct"
    },
    {
      "page_number": 222,
      "chapter": null,
      "content": "2.7 Recursive Dimensional Clustering\n229\nTable 2.7.1 The Difference between RDC and the Brute-Force Method\nObjects\n10\n50\n100\n200\n300\n400\n500\n1000\n2000\n5000\n10000\nRDC\n< 1 ms\n2 ms\n4ms\n7 ms\nUrns\n15 ms\n19ms\n38ms\n81 ms\n222ms\n478ms\nBrute Force\n< 1 ms\n6 ms\n18ms\n67 ms\n150ms\n263ms\n406ms\n1596ms (1.6 seconds)\n6335 ms (6.3 seconds)\n39380 ms (39.4 seconds)\n157621 ms (2 minutes, 37.6 seconds)\nOther Applications\nOne of the benefits of RDC is that it naturally finds groups of objects rather than sin-\ngle collision pairs. A group is a collection of objects that touch each other or are\nwithin a certain radius of each other. This definition also includes groups such that if\nA touches B and B touches C, then A, B, and C are all in the same group, meaning\nthat every group member is not required to touch every other group member. Thus,\nRDC can be used to find simultaneous collisions of several objects or even groups of\nenemies on a battlefield.\nOne interesting application of RDC involves identifying metaball clusters in\norder to speed up geometry generation (Marching Cubes algorithm). In this use, RDC\nfinds the clusters and then calculates the minimal axis-aligned bounding boxes\n(AABB) around those clusters. Minimal bounding boxes are critical for the Marching\nCubes algorithm. This is because the computational speed is proportional to the vol-\nume of the boxes, which equates to an algorithm with O(n?) time complexity. Color\nPlate 1 shows an example.\nThe RDC Algorithm\nIn order to understand how RDC works, the first step is to follow how it recognizes\ngroups of objects in collision along a single dimension. Figure 2.7.1 shows a one-\ndimensional example with three objects.\nAs you can see, objects B and C overlap, while object A is by itself. Thus, a clus-\ntering algorithm would find two groups: one group containing A, and a second group\ncontaining both B and C. Although it's easy to figure this out visually, we need a sys-\ntematic algorithm that achieves the same result.\nThe basic idea of this algorithm is to mark the boundaries of each object and then\nfind groups of overlapping objects using that data. This is done by looping through all\nentities and storing the beginning and ending boundaries for a given dimension in a\n",
      "content_length": 2236,
      "extraction_method": "Direct"
    },
    {
      "page_number": 223,
      "chapter": null,
      "content": "Section 2 Mathematics\nB\n-H-H-\n10 \n20 \n25\nFIGURE 2.7.1 Three objects along one dimension.\nlinked list. For example, the first object A has a left boundary of 7 and a right bound-\nary of 13. In order to make this apply to any dimension, we can think of these bound-\naries in terms of brackets and label them open and close, instead of left and right.\nFigure 2.7.2 shows the resulting linked list created from the three objects.\nA\nopen\npos 7\n-+\nA\nclose\npos 13\n-*-\nE\nopen\npos 17\n-»•\nB\nclose\npos 23\n-*•\nC\nopen\npos 22\n-*•\nC\nclose\npos 28\nFIGURE 2.7.2 The boundary list.\nWith the boundary list complete, the next step is to sort the list from lowest to\nhighest position using your favorite sorting algorithm, such as quicksort. The sorted\nlist is shown in Figure 2.7.3. In this example, only two elements were swapped.\nNow that we have the sorted list of boundaries, we can find the groups. The\nalgorithm for finding the groups is very similar to parser algorithms for matching\nbrackets. The pseudocode in Listing 2.7.2 will go through the sorted list and extract\neach \"bracketed\" group.\nA\nopen\npos 7\n— *\nA\nclose\npos 13\n— *•\nB\nopen\npos 17\n-*•\nC\nopen\npos 22\n-*\nB\nclose\npos 23\n-*•\nC\nclose\npos 28\nFIGURE 2.7.3 The list after sorting.\nListing 2.7.2 Algorithm for finding groups along one dimension\nint count = 0;\nClear( currentGroup );\nfor( element in list )\n{\nif( element is an \"open bracket\" ) {\ncount++;\nAdd entity to currentGroup;\n",
      "content_length": 1423,
      "extraction_method": "Direct"
    },
    {
      "page_number": 224,
      "chapter": null,
      "content": "2.7 Recursive Dimensional Clustering\n231\nelse { //element is a \"closed bracket\"\ncount- - ;\nif( count == 0 ) { //entire group found\nStore( currentGroup );\nClear( currentGroup );\nassert( count == 0 ) ;\nAt this point, you may have noticed that the algorithm arbitrarily groups objects\nthat share boundaries. For example, if object A has a closed boundary at position 10,\nand object B has an open boundary at position 10, then any simple sorting algorithm\nwould not distinguish between them. The result is that the algorithm in Listing 2.7.2\nwould inconsistently group these types of cases. However, there are many solutions to\nthis problem. The easiest is to use floating-point values and to make sure that objects\ndon't snap to integer locations. Another solution involves \"puffing out\" each object\nradius by a very tiny amount, thus causing identical boundaries to be offset from each\nother. You could also fix the problem in the sorting function; however, that would\nintroduce extra overhead and increase the running time.\nRDC in Higher Dimensions\nClearly, this algorithm works well for finding groups along one dimension. How-\never, it would only be useful if it worked in two or three dimensions. The trick for\nmultiple dimensions is to first find groups along one axis, and then send each newly\nformed group to the next axis to be subdivided further.\nFigure 2.7.4 shows a set of four objects in two dimensions. Again, it's easy to spot\nthe groups visually, but this example will show how the algorithm determines groups\nin multiple dimensions.\nThe ordered linked list for Figure 2.7.4 along the x-axis is shown in Figure 2.7.5.\n(6, 16,rad3)\n(14, 14,rad3)\n(19, Il,rad4)\n(22, 3,rad2)\nI I I I I II I I I I I I I ITTTT\nFIGURE 2.7.4 Two-dimensional example of four objects.\n",
      "content_length": 1772,
      "extraction_method": "Direct"
    },
    {
      "page_number": 225,
      "chapter": null,
      "content": "Section 2 Mathematics\nD\nopen\npos 3\n— *•\nD\nclose\npos 9\n-*•\nE\nopen\npos 11\nopen\npos 15\nE\nclose\npos 17\nopen\npos 20\nF\nclose\npos 23\nG\nclose\npos 24\nFIGURE 2.7.5 The sorted boundary list for Figure 2.7.4.\nThe groups in the x-axis are:\nGroupo = { D }, Groupl = { E, F, G }\nWe've now determined that there are at least two groups. The first group contains\nobject D, and the second group contains E, F, and G. With the x-axis done, each new\ngroup is sent to the y-axis to be divided further. Since object Ds group has only one\nmember, it doesn't need to be divided anymore and will simply be its own group.\nHowever, objects E, F, and G must now be analyzed along the y-axjs. Figure 2.7.6\nshows the ordered linked list for Group, along the y-axis.\nG\nopen\npos 1\n->\nG\nclose\npos 5\n->•\nF\nopen\npos 7\n-*•\nE\nopen\npos 11\n-*•\nF\nclose\npos 15\n-+\nE\nclose\npos 17\nFIGURE 2.7.6 The Groupi y-axis sorted boundary list.\nThe groups in the y-axis are:\nGroup1a = { G }, Group1b = { E, F }\nNow that we've gone through each dimension once, the final groups are:\nGroup0 = { D }, Group1a = { G }, Group1b = { E, F }\nFigures 2.7.7s. and 2.7.7b graphically show the boundaries of each object in each\ndiniension and the resulting groups. When this algorithm is expanded to three\ndimensions, the groups are simply analyzed in one more dimension; namely, the\nz-axis. Following is a summary of the steps involved in the RDC algorithm.\nRDC Steps:\n1. Start with the x-axis.\n2. Construct a linked list of object boundaries in this dimension.\n3. Sort that list by boundary position, from lowest to highest.\n4. Find groups using the open/close \"bracket matching\" algorithm in Listing\n2.7.2.\n5. For each group found in that dimension, repeat steps 2-5 in the next\ndimension.\n",
      "content_length": 1727,
      "extraction_method": "Direct"
    },
    {
      "page_number": 226,
      "chapter": null,
      "content": "2.7 Recursive Dimensional Clustering\n233\n1 1\nH\nGroup o\n1\nn'.i.\n\\ •'•*';\n•\";•\n1 1 !\n\\\n\\\n1\n4-\nit\n\"\"f\n1 1\nGroup\n1\n1\n1 1\nA\nGroup!\n•i:\nGroup\nB\nFIGURE 2.7.7 A) Groups found in thex-axis. B) Group, subdivided in they-axis.\nA Flaw in the Algorithm\nUnfortunately, the algorithm described so far has a fatal flaw. When grouping objects\nalong one axis, objects can get sucked into groups that aren't later separated by other\ndimensions. Figure 2.7.8 points out a problem configuration.\nNTT\nGroup Ob\nGroup Oa\nI I I I\nGroup 0\nA \nB \nC\nFIGURE 2.7.8 A) Flaw example. B) Groups in thex-axis. C) Group 0 subdivided in they-axis.\nFigure 2.7.8b shows the first pass along the x-axis and finds that all three objects\noverlap. Thus, they are all assigned to the same group. Then the single group is ana-\nlyzed along the y-axis, as in Figure 2.7.8c. This results in two groups being found, but\nit understandably fails to put object A and object C in separate groups.\nThe correct solution would be for each object to be in its own group. However,\nthe result of the algorithm was only partially correct. The fix is to send the new groups\nfound along the y-axis back to be analyzed again along the x-axis. When this is done,\nthe correct groups are finally found.\nThis solution can be generalized in order to permanently correct the algorithm.\nThe algorithm needs the following rule:\n",
      "content_length": 1357,
      "extraction_method": "Direct"
    },
    {
      "page_number": 227,
      "chapter": null,
      "content": "234 \nSection 2 Mathematics\nWhen a group is subdivided along one dimension,\nthe resulting subgroups must be reanalyzed along all other dimensions.\nIn the 2D case, a group that is broken up along the y-axis must be reanalyzed in\nthe x-axis, and vice versa. In 3D, a group that is broken up along the y-axis must be\nreanalyzed in both the x-axis and the z-axis. This fix finally explains the recursive ele-\nment of RDC. Following are the revised steps for RDC algorithm.\nRDC steps (revised):\n1. Start with the x-axis.\n2. Construct a linked list of object boundaries in this dimension.\n3. Sort that list by boundary position, from lowest to highest.\n4. Find groups using the open/close \"bracket matching\" algorithm in Listing\n2.7.2.\n5. For each group found in that dimension, repeat steps 2-5 in the other\ndimension(s) until the group no longer gets subdivided and all dimensions\nhave been analyzed for that unique group.\nFinding Pairs in Collision\nAs presented so far, RDC only identifies groups or clusters of objects that touch each\nother. The effect is that a group can contain members who may or may not directly\ntouch every other member in the group. While this has many great uses (simultane-\nous collisions, grouping info), general collision detection usually requires pairs that\nare in collision.\nTo find collision pairs, each final cluster group from RDC must be sent to the\nbrute-force comparison algorithm. Hopefully, the clusters have very few objects at\nthis point so that the O((n2-n)f2) algorithm runs sufficiently fast.\nOne way to find collision pairs even faster is to use the brute-force algorithm once\na collision cluster gets below a certain number; for example, less than 10 objects. At\nthis point, it would be simply faster to compare all of the objects rather than attempt-\ning to subdivide the group further with continued recursive calls.\nThe RDC Implementation\nAs described, the algorithm is basically recursive and attempts to break groups up\nuntil the minimum clusters are found. The tricky part is designing a recursive func-\ntion that chooses which dimensions to subdivide and when to end the recursion. In\n3D, the function must at least try to subdivide the group along all three dimensions.\nHowever, if any of those dimensions results in subdivision, each subdivided group\nmust then be sent recursively to the other two dimensions.\nThe easiest way to accomplish this is to let a recursive function take three argu-\nments that determine which dimensions still need to be considered. When the func-\n",
      "content_length": 2526,
      "extraction_method": "Direct"
    },
    {
      "page_number": 228,
      "chapter": null,
      "content": "2.7 Recursive Dimensional Clustering \n235\ntion first gets called, all three dimensions appear as arguments. As each dimension is\nanalyzed and not subdivided, the dimension argument list shrinks to zero and the\nrecursion halts. However, it is mandatory for a subdivided group to be called recur-\nsively with two arguments (the other two dimensions). The complete function can be\nfound in Listing 2.7.3.\nListing 2.7.3 RDC algorithm (pseudocode)\nvoid RDC( Pairs& pairs, Group& group,\nAxis axisl, Axis axis2, Axis axisS )\n{\n//\"pairs\" holds all final pairs that are in collision\n//\"group\" is the current group of objects to analyze\n//\"axisl\" is the axis to analyze within this function\n//\"axis2\", \"a3\" will be analyzed in recursive calls\nif( Size( group ) < 10 || axisl == INVALID_AXIS )\n{ //end recursion and test for collisions\nBruteForceComparisonf pairs, subGroup );\n}\nelse {\n//for this group, find the boundaries and sort them\nOpenCloseBoundaryList boundaries;\nFindOpenCloseBoundaries( axisl, group, boundaries );\nSortOpenCloseBoundaries( boundaries ); \n//O(nlogn)\nGroup subGroup;\nunsigned int count = 0;\nAxis newAxisI = axis2;\nAxis newAxis2 = axisS:\nAxis newAxis3 = INVALID_AXIS;\nbool groupSubdivided = false;\n//subdivide the group if possible and call recursively\nfor( every curBoundary in boundaries list )\n{\nif( curBoundary is \"open bracket\" )\n{ //this entity lies within a cluster group\ncount++;\nAddToGroup( subGroup, curBoundary->entity );\n}\nelse\n{\ncount-;\nif( count == 0 )\n{ //found the end of a cluster group - take subgroup\n//and call recursively on remaining axis'\nif( curBoundary != GetLastBoundary( boundaries ) )\n{ //this group is being subdivided - remember\ngroupSubdivided = true;\n",
      "content_length": 1696,
      "extraction_method": "Direct"
    },
    {
      "page_number": 229,
      "chapter": null,
      "content": "236 \nSection 2 Mathematics\nif( groupSubdivided )\n{ //reconsider all other axis'\nif ( axisl == X_AXIS ) {\nnewAxisI = Y_AXIS;\nnewAxis2 = Z_AXIS;\n}\nelse if ( axisl == Y_AXIS ) {\nnewAxisI = X_AXIS;\nnewAxis2 = Z_AXIS;\n}\nelse if( axisl == Z_AXIS ) {\nnewAxisI = X_AXIS;\nnewAxis2 = Y_AXIS;\n//recursive call\nRecursiveClustering( pairs, subGroup,\nnewAxisI, \nnewAxis2, \nINVALID_AXIS );\nClear( subGroup ); //clear the subGroup for the next group\nAs you examine the RDC function, note that it has been augmented to find col-\nlision pairs. When the recursion halts and a minimal cluster is found, it then sends\nthat cluster to the brute-force comparison function. It will also halt the recursion\nshould a cluster fall below 10 members. At this point, it immediately compares the\nmembers with the brute-force function.\nTime Complexity\nAt first glance, this algorithm looks fairly time intensive. Your gut feeling probably\ntells you that it's an O(r?) algorithm — and you'd be pretty close. However, because of\nthe physical restrictions of 3D space, certain worst-case configurations are extremely\nrare. Instead, the algorithm takes on average O(nlog2n), as long as most objects aren't\nin collision.\nRDC performs badly in two extreme cases. One is when the objects' configura-\ntion causes RDC to recurse very deeply — this is the worst case o^O(n2log2n). The\nother is when the objects are all in collision with each other, in which case RDC does\nalmost no work and the brute-force algorithm must be used with Q(t£).\nIn the worst case, recursion gets very deep. Functionally, this happens when the\nobject set is split completely asymmetrically, with one object in one group, and n-1\nobjects in the other. The larger group is then sent to the function recursively. If this\nhappens at each level of recursion, we get a total of n-1 calls to the function. (This\nanalysis applies to one dimension only. In three dimensions, we can get up to\n3 + 2(n-l) calls. In all cases, this is O(n)).\n",
      "content_length": 1967,
      "extraction_method": "Direct"
    },
    {
      "page_number": 230,
      "chapter": null,
      "content": "2.7 Recursive Dimensional Clustering\n237\nFor these calls, the average group size m is equal to n/2. The most complex part of\nthe function is the sort that we assume to be O(mlog2m) or O(nlog2n). This gives the\ntotal time complexity of the worst case as O(n) * O(nlog2n), or O(n2log2n).\nFigure 2.7.8 shows the near worst-case scenario for time complexity (a true worst-\ncase scenario might not be physically possible). Since Figure 2.7.9 is such an unlikely\nconfiguration, the worst-case time complexity of O(n2log2n) is somewhat misleading.\nInterestingly, this particular configuration results in an actual time complexity of\nO(nL78log2n). In practice you should never expect anything nearly that bad, since this\nparticular case is humorously rare and contrived.\nA more likely bad case for RDC occurs when all objects are in collision with each\nother. In this situation, each dimension would be tested, and only one group would\nbe found. This would take O(3nlog2n) time. Then the entire group would be sent to\nthe brute-force comparison algorithm in order to find the final collision pairs. This\nwould make the actual worst case be O(3nlog2n + (r£-n)f2), or simply O(rf). Given\nthat this time complexity is identical to the brute-force method and that no objects\nwill ever be in collision with all other objects, it's almost always faster to use RDC.\nT M i r i 111 11 M i M n 11 M i\nFIGURE 2.7.9 \nNear worst-case configuration for RDC (24 objects).\nConclusion\nAlthough Recursive Dimensional Clustering (RDC) isn't a complete collision detec-\ntion solution, it's an impressive first-pass filter for determining groups of objects that\nmight be in collision. It works with blazing speed, dramatically outperforming brute-\nforce methods. While partitioning of the world space is the standard solution for\nspeeding up collision detection, RDC has remarkable performance in the absence of\nsuch techniques. However, for practical purposes, RDC is best suited for analyzing\nlarge numbers of objects (25+) for collision, perhaps even after other partitioning\nalgorithms have reduced the testable set.\n",
      "content_length": 2092,
      "extraction_method": "Direct"
    },
    {
      "page_number": 231,
      "chapter": null,
      "content": "238 \nSection 2 Mathematics\nReferences\n[Blow97] Blow, Jonathan, \"Practical Collision Detection,\" Proceedings, (Computer\nGame Developers Conference 1997), also available online at http://l42.104.104\n.232/eCOW/projects/Resources/practical_collision_detection.html.\n[BobicOO] Bobic, Nick, \"Advanced Collision Detection Techniques,\" available online\nat www.gamasutra.com/features/20000330/bobic_pfV.htm, March 30, 2000.\n[Roberts95] Roberts, Dave, \"Collision Detection,\" Dr. Dobb's Sourcebook (May/June\n1995): pp. 7-11.\n",
      "content_length": 514,
      "extraction_method": "Direct"
    },
    {
      "page_number": 232,
      "chapter": null,
      "content": "Programming Fractals\nJesse Laeuchli\njesse@laeuchli.com\nT\noday, many 3D games and applications display randomized landscapes. Often,\nfractals are used to create these landscapes. Such landscapes are known for their\nquality and realism, but only recently has the computer power become available in\ngame machines to play with them in real time.\nThere are a number of reasons why you might use fractals to make a landscape. If\nyou created a completely random landscape, setting the heights of the valleys and hills\nto any height, it would look random, and unlike any real-life landscape. On the other\nhand, if you assigned the landscape heights with an orderly function—for example,\nsin—you would get a completely regular and predictable landscape, something not\npossible in real life. It is possible to use fractals to get a mix between the two: a land-\nscape where there will not be impossibly wild mountains and valleys, or evenly spaced\nhills, but more life-like scenes that match the qualities of the physical landscapes we\nsee around us.\nA good non-mathematical definition of a fractal is something regular that has\nrandomness added in a controlled way. Things modeled with fractals are not com-\npletely random, but they are not entirely orderly either. Fractals are most often used as\ntextures, or to create geometric models. Things that are complex, but do not have any\nregularity (such as people) cannot be directly modeled with fractals.\nThis gem looks at the more useful fractals, and examines how they are used. Not\nall types of fractals will be examined, as many of them are highly mathematical and\nhave little use in game programming currently. In games, fractals are usually stored as\nheight-maps: a rectangular grid with numbers in each cell representing the fractal's\nvalue at that point. In the case of a fractal landscape, the value represents the height;\nin the case of a fractal cloud, it might represent the density. The value can be inter-\npreted in many ways, some of which (no doubt) have yet to be invented, however,\nsince height is the most frequent case, I shall refer to the \"height\" of a fractal at a\npoint, rather than using the rather bland word value.\n239\n",
      "content_length": 2185,
      "extraction_method": "Direct"
    },
    {
      "page_number": 233,
      "chapter": null,
      "content": "240 \nSection 2 Mathematics\nThe Plasma Fractal\nOne of the most common fractals is the plasma fractal. This is very easy to program,\nthe sort of thing demo writers love to optimize, and you have probably seen hundreds\nof them (Figure 2.8.1).\nFIGURE 2.8.1 A small plasma fractal.\nTo create a plasma, we create an empty height-map and assign heights to the four\ncorners. Then, for each side, we linearly interpolate between each pair of corners. The\ncenter squares height is the arithmetic mean of the four corners' heights. We then\nrepeat the process for each of the four squares we have defined with these new ver-\ntices, and recurse. This interpolation scheme generates a smooth curved surface\nbetween the four corners; in fact, it can be used alone to smoothly interpolate a\nheight-map.\nTo make a fractal from this simple curved surface, we introduce a new step at\neach level of recursion. After generating the center vertex, we add or subtract a ran-\ndom amount from its height. At the next level of recursion, we do the same thing, but\nwe reduce the range of the random numbers by a number H. Note that this factor is\nthe only control available over the fractal. If H is 0, the height-map varies wildly; as H\ngets larger, die height-map gets less varied.\nThe main advantages of die plasma fractal are that it is extremely easy to understand\nand runs very fast. Unless speed is more important than results, though, this fractal\nshould be avoided for two reasons. First, very litde control is available over die fractal.\nSecond, this fractal has very bad artifacts—very pronounced ridges along the edges.\nThe Fault Fractal\nAnother common fractal is the fault fractal. This is also quite easy to program, but\nmuch slower than the plasma fractal. The fault fractal very roughly simulates the\neffect of severe earthquakes along random \"fault lines.\"\nTo create this fractal, we again create an empty height-map. Then, we apply a\nseries of \"earthquakes\" as follows: create a random line through the height-map, raise\nevery cell on one side of the line up a small amount, and move every odier cell down\na small amount. This process is repeated until the landscape looks good enough.\nThis technique can create some very good fractals, but generating them is a slow\nprocess. Generally, 1000 to 10,000 fault lines are required before you get acceptable\n",
      "content_length": 2344,
      "extraction_method": "Direct"
    },
    {
      "page_number": 234,
      "chapter": null,
      "content": "2.8 Programming Fractals \n241\nresults. Therefore, the fractal cannot be done in real time! However, for offline pro-\ncessing, this fractal is very easy to implement and does not suffer from the same alias-\ning effects as subdivision fractals such as the plasma.\nThe fault fractal is one of the few fractals that work on a sphere. The lines become\ngreat circles on the sphere that split the sphere into two hemispheres. Then, each\nhemisphere is moved slightly on their common plane.\nFault fractals have no control parameters, other than the sequence of random\nnumbers used, so it is difficult to generate them artistically.\nFractal Brownian Motion\nThe methods given so far are rather ad hoc approaches to generating fractals. Fractal\nbrownian motion (FBM) fractals have a more rigorous mathematical background and\nhave very good mathematical properties, which makes them simple to work with.\nAn FBM fractal is a combination of noise functions, but each noise function is\nspecial. The key to this technique is understanding the different types of noise.\nFirst, we have white noise, which is completely random. The static on a television\nnot picking up a signal is akin to white noise. The heights in white noise change\nwildly, and are not related to the heights nearby.\nSecond, we have pink noise, which has a limit on how much its heights change\nfrom one point to another.\nIn computer graphics, when the term noise is used it usually means pink noise\nunless otherwise specified. Ken Perlin was the first to use pink noise in computer\ngraphics, when he wrote his now-famous noise() function (known as Perlin Noise).\nHe was also the first graphics programmer to win an Academy Award—for the afore-\nmentioned function. (I look forward to winning my Oscar for best call to fopenQ!)\nWhile we usually think of noise as a ID function (e.g., sound) or a 2D function\n(e.g., a height-map), it can be generated in 3D, 4D, and even higher dimensions. This\ncan be useful when one wishes to introduce a time component to an animating tex-\nture (which can simulate fire) or to an animating 3D density function (which can\nsimulate boiling clouds).\nTo create pink noise, you take a regular grid (or higher-dimension array) and\nstore random values in each cell. The fractal is then generated at every point on the\nsurface by interpolating between these values. The defining feature of any such noise\nfunction is then the frequency, which is the inverse of distance between the grid\npoints. The higher the frequency, the closer the pink noise gets to white noise.\nOnce you have created pink noise of various frequencies, it is easy to create an\nFBM fractal by mixing the heights returned by the noise function. The simplest case\nis just adding the noise functions together, but they can be multiplied or combined in\nother ways.\nThe FBM has a few more parameters than noise alone. In addition to the fre-\nquency, there are the octave, amplitude, and //parameters. The octave variable sets how\nmany noises are added together. The amplitude is a variable that adjusts the overall\n",
      "content_length": 3057,
      "extraction_method": "Direct"
    },
    {
      "page_number": 235,
      "chapter": null,
      "content": "242 \nSection 2 Mathematics\nheight of the noise. H controls how much the amplitude changes over each octave. The\nfrequency of each slice of noise must be chosen as well. To understand the effects of fre-\nquency on an FBM, we can consider fractal landscapes. When adding noises together,\nthe lower frequency noise is responsible for hills and mountains, and the higher fre-\nquency noise creates roughness. This gives a tremendous amount of control over\nexacdy how the fractal looks. In addition, it is possible to make the amount that you\nchange the frequency differ from section to section of the noise function. This makes it\npossible to have some areas of your fractal rougher than others, so you could have a\nlandscape that is rougher in the mountains, and smoother in the deserts.\nIt is also possible to multiply the noise functions instead of adding them together.\nDoing this will create more variety in your fractal. Multiplying noises together has the\neffect of damping out the lower parts of the noise, and accentuating the higher parts.\nIf the resulting heightmap is used for a landscape, it will have planes, mountains, and\nfoothills—if you just add the noises together, the landscape will have a uniform look.\nIt is necessary to be careful when multiplying noises together, as it is easy to go to\nextremes and dampen and accentuate things too much, leaving just a flat plane with\nspikes in it!\nImplementation\nNow that we have examined the theory of creating FBMs, the next step is to imple-\nment a noise generator. To generate noise, a source of random numbers to be interpo-\nlated has to be generated. The following is the code for my random number\ngenerator:\nfloat random (int x , int y)\n{\nint \nn=x+y*57;\nn=(n«13)*n;\nfloat ret;\nret= (1 - ( (n * (n * n * 19417 + 189851) + 4967243) & 4945007) /\n3354521.0);\nreturn ret;\n}\nThis function just multiplies, adds, and subtracts prime numbers from your\nnumbers, and returns a pseudo-random value between —1 and 1. This is not the only\nway to generate random numbers, of course. Some systems use pregenerated random\nnumbers. That method gives a small performance improvement, but then you must\nstore large amounts of random numbers. With this method, all that needs to be\nremembered is the seed to regenerate the random numbers that were used.\nNext, we need a function that interpolates these random values. A simple lerping\nfunction would work, and it would be fast, but it does not provide very good results.\nWhile some use spline interpolation, this is the slowest and most complex option.\nThis article uses cosine interpolation to build our noise function. This has good qual-\n",
      "content_length": 2634,
      "extraction_method": "Direct"
    },
    {
      "page_number": 236,
      "chapter": null,
      "content": "2.8 Programming Fractals \n243\nity, it is fast, and it is easy to understand. Note that this is not the only noise function\npossible, and it differs from Perlin Noise (which is much more complex). For a more\ncomplete list, see [Ebert98].\nHere is some code for cosine interpolation:\ndouble cosineinterpolation(double number-1 .double number2,double x)\n{\ndouble ft;\ndouble f;\ndouble ret;\nft = x * 3.1415927;\nf = (1 - cos(ft)) * .5;\nret=number1*(1-f) + number2*f;\nreturn ret;\n}\nNow that there is a random number function, and an interpolation function, it is\npossible to create a noise function by creating random numbers and interpolating diem.\nfloat noise(float x, float y)\n{\nint xinteger=x;\nfloat fractionx=x-xinteger;\nint yinteger=y;\nfloat fractiony=y-yinteger;\nfloat v1,v2,v3,v4,i1,i2;\nfloat ret;\nv1= randomnumber (xinteger, yinteger);\nv2= randomnumber (xinteger + 1, yinteger);\nv3= randomnumber (xinteger, yinteger +1);\nv4= randomnumber (xinteger + 1, yinteger +1);\ni1= cosineinterpolation (v1,v2,fractionx);\ni2= cosineinterpolation (v3,v4,fractionx);\nret= cosineinterpolation (i1,i2,fractiony);\nreturn net;\n}\nThe preceding function takes two variables. Normally, the function is called for\neach point on the heightmap or grid in which you wish to store the results. Note that\nthis is two-dimensional noise.\nIn some cases, it is better to smooth the noise. Smoothing reduces the frequency\nof your noise, and makes it look less square. It is pointless to smooth ID noise, as the\nsame effect is achieved by just reducing the frequency. If you want to smooth your\nnoise, call smoothrandom instead of randomnumber in the noise function.\nfloat smoothrandom(int x,int y)\n{\nfloat corners=(randomnumber(x-1,y-1)+randomnumber(x+1,y-\n1)+randomnumber(x-1,y+1)+randomnumber(x+1,y+1))/16;\nfloat sides = (randomnumber(x-1, y)+randomnumber(x+1,\ny)+randomnumber(x, y-1)+randomnumber(x, y+1) ) / 8;\n",
      "content_length": 1884,
      "extraction_method": "Direct"
    },
    {
      "page_number": 237,
      "chapter": null,
      "content": "244\nSection 2 Mathematics\nfloat center = \nrandomnumber(x, y) / 4;\nfloat ret=corners+sides+center;\nreturn ret;\nThis is equivalent to doing integration on the nine points around the center\npoint.\nAfter a noise function has been constructed, it is quite easy to create an FBM.\nThis is how it is done:\nfloat FBM(float x, float y, float octaves, float amplitude, float\nfrequency, float h)\n{\nfloat ret=0;\nfor(int i=0;i<(octaves-1) ;i\nret +=( noise (x* frequency, y* frequency)* amplitude);\namplitude*=h;\n}\nreturn ret;\nWhile the way the values change over each octave in this noise may work fine in\nmany cases, sometimes it may be useful to change them. You can change the amount\nthe frequency and amplitude change over each octave. You can even skip octaves. This\ncontrol is another advantage to using FBMs (Figure 2.8.2).\nA slight variation on FBMs are multifractals. Multifractals are like FBMs, except\nthat instead of adding noise, noise is multiplied together. Here is how they are made:\n1\nFIGURE 2.8.2 A) An FBM of just a few octaves. B) The same FBM after several more\noctaves.\n",
      "content_length": 1078,
      "extraction_method": "Direct"
    },
    {
      "page_number": 238,
      "chapter": null,
      "content": "2.8 Programming Fractals\n245\nfloat Multi-fractal (float x, float y, float octaves, float amplitude\nfloat frequency, float h, float offset)\nfloat ret=1;\nfor(int i=0;i<(octaves-1);i++)\n{\nret *=(offset)*( noise (x* frequency, y* frequency)*\namplitude);\namplitude*=h;\n}\nreturn ret;\n}\nThe offset variable gives some control over the multiplication of the noise. You\nwill notice that the resulting fractal has dififerent kinds of hills and mountains, as well\nas planes.\nUsing FBM\nLet's learn how to make clouds with FBMs.\nClouds\nClouds are quite easy to make with FBMs. You generate an FBM, then you interpret\nall the heights over zero as white, and assign them an alpha value greater than zero. To\nall heights lower than zero, assign an alpha value of zero. Map this texture to a quad or\nsphere, colored the way the sky would be at the time of day being modeled. Figure\n2.8.3 shows some example cloud textures. See clouds.cpp for more details.\nThe example program uses OpenGL to map this texture to a quad. While it looks\nless realistic on a qua4 than on a sphere, it demonstrates the theory.\nA \nB\nFIGURE 2.8.3 (A-C) Clouds generated with FBMs of decreasing frequency.\n",
      "content_length": 1164,
      "extraction_method": "Direct"
    },
    {
      "page_number": 239,
      "chapter": null,
      "content": "246\nSection 2 Mathematics\nLandscapes\nFBMs are also useful for creating landscapes; in fact, FBMs can create excellent land-\nscapes. Just interpret the heightmap as heights for the landscape (hence, the name!).\nTo render it, create a flat plane out of triangles, and at each triangle vertex, use a\nheight from the heightmap (Figures 2.8.4 and 2.8.5). See Iandscape2.cpp for the\ncomplete listing.\nA\nB\nC\nFIGURE 2.8.4 Various fractal heightmaps: the ground texture is a height-frequency FBM colored by\nheight. A) Generated with a small frequency, small octave, and small amplitude. B) The same\nlandscape with a much higher amplitude. C) Generated with a high frequency.\nA\nB\nFIGURE 2.8.5 Two multifractal landscapes. Note how there are valleys, plains, hills, and tall\nmountains all in the same landscape.\nReferences\n[Ebert98]. David S. Ebert, et al. Texturing and Modeling. San Diego: Academic Press,\n1998.\n",
      "content_length": 903,
      "extraction_method": "Direct"
    },
    {
      "page_number": 240,
      "chapter": null,
      "content": "3.1\nStrategies for Optimizing Al\nSteve Rabin, Nintendo of America\nsteve rabin@hotmail.com\n^Sophisticated AI requires significant computational power. The problem worsens\n%^when dozens or hundreds of autonomous agents must intelligently roam the\nworld simultaneously. Yet this isn't your average optimization problem. Many\ndomains within games deal with scalability, but AI has the extra wrinkle of supporting\nimaginary parallelism. This parallelism comes from each AI agent running its own\npiece of code with the illusion of all agents thinking at the same time.\nAs it turns out, parallelism is one of AI's greatest exploitable assets. This paral-\nlelism, along with other unique attributes of AI agents, can be manipulated to opti-\nmize most AI systems. As you read through the following optiinization strategies,\nkeep in mind a mental picture of hundreds of AI agents all having unique actions and\nagendas. When you consider this magnitude, it's more obvious why certain strategies\nmake sense.\nStrategy f 1: Use Event-Driven Behavior Rather than Polling\nIdeally, autonomous agents should continuously monitor their world and react accord-\ningly. Every frame they might poll the world for events or objects to which they should\nrespond. This means everything from collision detection to noticing interesting things\nto look at. The problem with diis approach is that it promotes an enormous amount of\nredundant computation. As a rule, individual polling is usually wasteful.\nThe alternative is to employ event-driven techniques whenever possible. For\nexample, in a baseball game when the ball is initially hit, the ball could simply tell the\nfielders that it was hit. This is extremely more efficient than each fielder polling the\nsituation to detect when the batter has hit the ball. Granted, this is an obvious use of\nevent-driven behavior, but it still shows the magnitude of processing that can be saved\nby using an event-driven strategy.\nAnother example would be of an arrow flying through a battlefield. Normally, the\narrow would be checking for collisions with characters. If the arrow strikes a character,\nit would then notify the character of the collision as well as the location. The charac-\nter could then react appropriately, responding to where the arrow pierced him. While\nthis is starting to be event driven, nothing too spectacular has happened yet.\n251\n",
      "content_length": 2371,
      "extraction_method": "Direct"
    },
    {
      "page_number": 241,
      "chapter": null,
      "content": "252 \nSection 3 Artificial Intelligence\nNow consider if you wanted the character to anticipate the impact of the arrow,\nor even try to avoid the arrow. A polling solution would involve each character inter-\nmittently looking for nearby arrows. Conversely, the event-driven solution is to have\nthe arrow predict future collisions, as part of its collision detection routine, and notify\nany characters that might get hit in the future. The characters can then do whatever\nthey want with that info, including running away, ducking, or bracing for impact.\nThe result is very deep behavior without the need to poll for every contingency.\nA good example of an event-driven AI system can be found in the first Game Pro-\ngramming Gems book, in the article \"Designing a General Robust AI Engine\"\n[RabinOOa].\nStrategy #2: Reduce Redundant Calculations\nThe goal of this strategy is to reduce redundant calculations by sharing the results\nbetween several AI agents. Many times agents will individually recalculate the same\ninformation, even though they could have calculated it once and shared it. This is an\neasy optimization that can often save many cycles.\nA simple example of this strategy is apparent in collision detection. If every object\nwere to run its own simplistic collision checks, there would be O(rf-n) tests, or 9900\ncalculations for 100 objects. However, since a given pair of objects only needs to be\ntested once, an optimized collision algorithm would have only O((rf-n)/2) tests, or\n4950 calculations for 100 objects. The savings come directly from eliminating redun-\ndant work.\nAnother example of reducing redundant computation is found in pathfinding.\nWhen a player grabs a bunch of units and orders them to all move to the other side of\nthe map, each unit might expect to separately find a path. Instead, a faster and simpler\nsolution is to let one unit find a path and then let the other units roughly follow him.\nThis avoids the virtually identical path requests that would have normally taken place,\nthus saving a considerable number of cycles.\nStrategy #3: Centralize Cooperation with Managers\nAgents often need to cooperate with other agents, whether they comprise a crack\ncommando squad or a sports team. Cooperation among multiple agents can be made\nfaster and simpler by having a manager entity make the complex decisions. These\ncomplex decisions usually determine each member's role, while the agent is left to\nautonomously execute that role.\nFor example, imagine a SWAT team that is infiltrating a building. The team\nneeds to cooperate very tightly in order to secure each position and move on. If mem-\nbers had to determine their actions individually, it would be quite difficult to coordi-\nnate and would require an enormous amount of inter-member communication.\nInstead, a manager entity can plan out each step of the operation and instruct indi-\nvidual members as to their immediate goal. This simpler approach results in a more\n",
      "content_length": 2953,
      "extraction_method": "Direct"
    },
    {
      "page_number": 242,
      "chapter": null,
      "content": "3.1 Strategies for Optimizing Al \n253\nrobust and efficient design. An example of how a manager can simplify the game of\nbaseball can be found in [Rabin98].\nIt's important to remember that with this strategy, managers don't need to be rep-\nresented on-screen. Usually these managers are just fictitious entities that organize the\ncomplex cooperation among AI agents. You can even imagine transient managers that\ndynamically form around groups of monsters that have banded together. If that group\nthen divides or combines with another group, each newly formed group can be\nassigned its own manager. With these monster managers, individual monsters can\nbe coordinated so that optimal targets are chosen and everyone doesn't mob the same\nenemy.\nStrategy #4: Run the Al Less Often\nRarely do AI agents need to run through all of their decision-making routines every\nframe. Many times, agents can run portions of code every couple frames or even every\ncouple seconds. Since real creatures have reaction times, it's not unreasonable for AI\nagents to have less than lightning reflexes. This results in a handy way to cut down on\nAI processing.\nUsing an agent architecture that supports arbitrary timer callbacks is a great way\nto implement this strategy. If an agent can easily set a timer and be notified when it\nexpires, flexible systems can be built that are easily tunable. The first Game Program-\nming Gems book has a gem \"Designing a General Robust AI Engine\" [RabinOOa] that\ndiscusses a timer messaging system that is well suited for this strategy.\nOne problem with this strategy is the possibility of AI processing peaks. This\nwould occur if a majority of the agents became synchronous in their callback execu-\ntions, simultaneously executing every TV seconds or so. The simple solution is to ran-\ndomize the window of processing for each agent. For example, an agent might execute\nhis invader-detection code every 0.3 to 0.5 seconds, randomly picking a new delay\nwithin that window after each callback. This random window of execution virtually\nguarantees that agents won't become synchronous with each other, accidentally caus-\ning a processing peak.\nStrategy #5: Distribute the Processing over Several Frames\nTypically, A* pathfinding is one of the dreaded algorithms that can eat up CPU\ncycles. Since situations rarely change much over a couple frames, it's possible for an\nagent to spread a pathfinding calculation over several frames. By saving the results\nfrom each frame and resuming the next frame, a path can be found over 2-4 frames.\nThis results in a lower per-frame processing load. Any algorithm that can take an\nunspecified amount of time can be broken up in this manner.\nThis strategy can be implemented as a special case in a module, like a pathfinding\nmodule, or it can be part of an AI operating system. The next gem in this book,\n\"Micro-Threads for Game Object AI,\" by Bruce Dawson, explains how you can\n",
      "content_length": 2923,
      "extraction_method": "Direct"
    },
    {
      "page_number": 243,
      "chapter": null,
      "content": "254 \nSections Artificial Intelligence\nimplement a micro-thread strategy in order to minimize AI loads. This particular\narchitecture makes it easier for an AI agent to spread calculations over many frames\nand can help keep processing loads under control. Following Bruce's gem is \"Manag-\ning AI with Micro-Threads\" by Simon Carter, which describes how to best structure\nyour AI within a micro-thread environment.\nStrategy #6: Employ Level-of-Detail AI\nThe level-of-detail (LOD) concept is a clever optimization that has many uses outside\nof graphics. Currently, most game engines use graphical LODs in order to quickly\nrender objects that are far off in the distance. The idea is to use a low polygon count\nmodel when an object is far from the camera, and use a high polygon count model\nwhen it's close. The effect is that the rendering time is greatly sped up with little or no\nvisual loss to the game. An important realization is that the level-of-detail concept can\nalso be applied to other game programming areas, such as AI.\nPractically, the level-of-detail technique for AI comes down to three strategies. The\nfirst is to vary the processing frequency of an agent by how close it is to the camera,\nplayer, or action. The second is to vary the complexity of an agent's algorithms based\non relevance, by doing things such as eliminating precise pathfinding when an agent is\noffscreen. The third is to represent multiple agents in a single simulation algorithm as\ntheir individual importance decreases to the player. An extreme example of the third\nvariation is to simulate the outcome of a far-off military battle with a simple formula,\nwhile battles close to the player might simulate every single soldier and bullet.\nLevel-of-detail is all about trying to get away with less work without the player\nnoticing. If the player can tell something is wrong or different, then the optimization\nneeds to be scaled back, just as it would be with graphical LODs that visually \"pop.\"\nStrategy #7: Solve Only Part of the Problem\nWhen given a large problem, sometimes it suffices to only solve the part that you need\nright away. The rest of the solution can then be computed in the future when you\nactually need it. It might even be the case that the situation changes enough that the\nrest of the problem is irrelevant and never needs to be computed anyway. This strat-\negy is extremely similar to lazy evaluation.\nThe best example of this strategy in action is probably hierarchical pathfinding. In\nhierarchical pathfinding, the path is found in two phases. First, the character's high-\nlevel, room-to-room path to the goal is calculated. Once that is computed, the micro\npath to get the character to the next room, toward the goal, can be computed as each\nnew room is entered. If for some reason the character gets redirected, the remaining\npath is thrown away and never computed. This on-demand pathfinding results in a\ntremendous speed improvement that is critical for games that have large areas to navi-\ngate. See [RabinOOb] for a complete description of hierarchical pathfinding issues and\nimplementation.\n",
      "content_length": 3105,
      "extraction_method": "Direct"
    },
    {
      "page_number": 244,
      "chapter": null,
      "content": "3.1 Strategies for Optimizing Al \n255\nStrategy #8^ Do the Hard Work Offline\nSometimes, a problem is so difficult that you don't even have the CPU time to solve\nit. In the early years of game development, problems such as finding the cosine of an\nangle simply took too much time. This resulted in programmers precalculating cosine\nfor a range of values and simply indexing a look-up table to get the answer. While\ntoday that technique is no longer relevant, the basic strategy is as useful as ever. .\nCurrent incarnations of this strategy can be found in precomputed BSPs, pfe-\nanalyzed terrains, and carefully trained neural nets. Later, you'll find three gems that\nexemplify this strategy: \"Terrain Reasoning for 3D Action Games\" by William van\nder Sterren, \"Expanded Geometry for Points-of-Visibility Pathfinding\" by Thomas\nYoung, and \"Using a Neural Network in a Game: A Concrete Example\" by John\nManslow. Each gem exploits the bountiful offline time that can be used to analyze,\nrefine, and store specialized information that can then be used at a moment's notice\nduring runtime. This is surely one of the most powerful optimization strategies, since\nit can cram thousands of hours of wisdom into a few kilobytes of data and a trivial\namount of CPU cycles.\nStrategy #9: Use Emergent Behavior to Avoid Scripting\nThis strategy has the opposite problem of the last strategy. Often, you don't have\nenough offline time to create the behavior or scripts for hundreds of background AI\nentities that might populate your world. The solution is to come up with very simple\nrules that result in intelligent, emergent behavior. Later in this book, the gem \"Flock-\ning with Teeth: Predators and Prey\" by Steven Woodcock details how flocking can help\ncreate wonderfully complex behavior that is unscripted, yet interesting and lifelike.\nUnfortunately, this strategy is a double-edged sword. While it cuts down on the\namount of offline work, it has the potential for unintended consequences. In his gem,\nSteven describes a world full of creatures that feed off each other. This sometimes\nresults in the predators completely wiping out the population of prey, causing the\nentire ecosystem to collapse. By its very nature, emergent behavior is unpredictable\nand can be hard to thoroughly test. Consequently, it might be best suited for noncrit-\nical AI entities that aren't pivotal to the progress or completion of a game, such as\nbackground wildlife.\nStrategy #10: Amortize Query Costs with\nContinuous Bookkeeping\nSometimes a lot of data needs to be collected in order to make an intelligent decision.\nIf that data is gathered right when it's needed, then it might take an unacceptable\namount of time to calculate. The solution is to continuously update a data structure\nwith this data as it changes. Although more time and memory is spent keeping track of\ndata, it's amortized over many, many frames. The result is that a simple query of the\ndata no longer causes a hit to the frame rate.\n",
      "content_length": 2978,
      "extraction_method": "Direct"
    },
    {
      "page_number": 245,
      "chapter": null,
      "content": "256 \nSection 3 Artificial Intelligence\nInfluence maps are an excellent example of this strategy at work. Influence maps\nare used to analyze general strategic patterns, and in doing so, speed up AI decisions.\nAs a game progresses, the units keep their info updated within the influence map as\nthey move, evolve, or disappear. This way, when a general strategic AI wants to ana-\nlyze the world, the data is already available. This results in quick queries to the influ-\nence map without any significant speed hit. Further in this book, you'll find the gem\n\"Influence Mapping\" by Paul Tozour that explains influence maps and has some\nunique insights into making them even more powerful.\nThis strategy is also key in a later gem written by Matt Pritchard entitled \"A\nHigh-Performance Tile-Based Line-of-Sight and Search System.\" In his gem, Matt\nuses this strategy of continuous bookkeeping to maintain the line-of-sight data for\nhundreds of agents in real time, which is not a simple task. Many RTS games fail to\nachieve this frame-by-frame accuracy for their fog-of-war, mini-map, and general\nintelligence; however, Matt fully explains the techniques and strategies that give the\nAge of Empires series that extra edge.\nStrategy #11; Rethink the Problem\nMichael Abrash is well known as an optimization guru within the game development\ncommunity, as well as one of the leading figures in graphics research. On many occa-\nsions, both in presentations and in print [AbrashOO], he has stressed the importance\nof rethinking a problem in order to speed up code by orders of magnitude. His main\npremise is that optimizing specific sections of code will always result in marginal\ngains. The real way to optimize is to attack the problem from a slightly different per-\nspective, with an alternate approach or algorithm.\nThis strategy is well illustrated later in the book by Michael Zarozinski in his gem\n\"Imploding Combinatorial Explosion in Fuzzy Systems.\" In this gem, Michael\nexplains an alternate algorithm, called the Combs Method, which completely circum-\nvents the exponential nature of traditional fuzzy systems. Although the method\ndoesn't produce identical results, the output is very comparable and sufficient for\nmost purposes. In addition, it simplifies fuzzy logic implementation and planning to\nthe point where anyone can easily incorporate it into a game.\nRethinking a problem from a different perspective is probably the best advice\nanyone can give for optimization. It's the seed from which every other optimization\ngrows. Only through the process of redefining or abstracting the problem, creating an\nanalogy, or changing your perspective, can you make the leaps that will allow you to\ntruly optimize your code. While leaps don't come very often, you can learn from\nother's leaps by simply reading and learning as much as you can about how they\nsolved similar problems.\n",
      "content_length": 2878,
      "extraction_method": "Direct"
    },
    {
      "page_number": 246,
      "chapter": null,
      "content": "3.1 Strategies for Optimizing Al \n257\nConclusion\nIt takes a slightly different perspective to optimize the problems that face AI systems.\nDon't be afraid to scan the list of strategies the next time you're faced with trying to\nspeed up a seemingly unoptimizable system. With so many ways to view a problem, it\nhelps to refresh your memory and contemplate how each strategy applies to your\nunique situation. Here is a recap of all the strategies:\n1. Use event-driven behavior rather than polling.\n2. Reduce redundant calculations.\n3. Centralize cooperation with managers.\n4. Run the AI less often.\n5. Distribute the processing over several frames.\n6. Employ level-of-detail AI.\n7. Solve only part of the problem.\n8. Do the hard work offline.\n9. Use emergent behavior to avoid scripting.\n10. Amortize query costs with continuous bookkeeping.\n11. Rethink the problem.\nAs you read the gems that follow, consider how these optimization strategies have\nbeen applied and exploited within each. While there are a wide variety of strategies,\nit's quite amazing how disparate problems can often be solved with the same strategy.\nThe genius is in seeing those connections.\nReferences\n[AbrashOO] Abrash, Michael, \"It's Great to Be Back! Fast Code, Game Programming,\nand Other Thoughts from 20 (Minus Two) Years in the Trenches,\" Conference\nProceedings, (Game Developers Conference 2000). Text available online at\nwww.gamasutra.com/features/20010117/abrash_01.htm. Video also available\nonline at www.gamasutra.com/features/index_video.htm.\n[Rabin98] Rabin, Steve, \"Making the Play: Team Cooperation in Microsoft Baseball\n3D,\" Conference Proceedings, (Computer Game Developers Conference 1998).\n[RabinOOa] Rabin, Steve, \"Designing a General Robust AI Engine,\" Game Program-\nming Gems, Charles River Media, 2000: pp. 221-236.\n[RabinOOb] Rabin, Steve, \"A* Aesthetic Optimizations,\" and \"A* Speed Optimiza-\ntions,\" Game Programming Gems, Charles River Media, 2000.\n",
      "content_length": 1948,
      "extraction_method": "Direct"
    },
    {
      "page_number": 247,
      "chapter": null,
      "content": "3.2\nMicro-Threads for Game\nObject Al\nBruce Dawson, Humongous Entertainment\nbruced@humongous.com\nW\nriting good AI can be very difficult. It took many years and millions of dollars\nbefore a computer program was able to beat the world's best chess players.\nGame AI doesn't have to play championship chess, but it does have to update many\ngame objects per frame, in very little CPU time.\nAdding to the essential complexity of writing good AI is the \"accidental complex-\nity\" [Brooks95] introduced by the common methods of implementing AI for game\nobjects.\nAs an example of accidental complexity in most games' code, let's say we want to\nmake a \"Janitor\" object that wanders around our world cleaning up. This janitor's\nroutine is very simple: choose a target, move toward it, dispose of it when you get\nclose enough, and then repeat. Of course, since this is for a game we want to do it in\nsmall steps, one per update loop. Some C++ style pseudocode — without accidental\ncomplexity — might look like this:\nvoid Janitor: :Process() {\nwhile (true) {\nGameObject* target = GetNewTarget(this) ;\nwhile (Distance(this, target) > k_collisionTolerance) {\nWaitOneFrameO ;\nMoveABitTowards(this, target);\n}\nDispose(this, target);\nHowever, that doesn't work very well in a game because it doesn't share the CPU\nother entities in the world. Therefore, the traditional way to implement such a\njanitor object would be as a Janitor class with a virtual function that is called every\nframe, like this code, taken from the sample on the CD:\nJanitor: :Janitor()\n: m_target(0) , m state (k_NeedsGoal) {\n258\n",
      "content_length": 1582,
      "extraction_method": "Direct"
    },
    {
      "page_number": 248,
      "chapter": null,
      "content": "3.2 Micro-Threads for Game Object Al \n259\nvoid Janitor: :ProcessFrame(){\nswitch (m_state) {\ncase k_NeedsGoal:\nm_target = GetNewTarget(this) ;\nif (Distance(this, m_target) <= k_collisionTolerance)\nm_state = k_DisposeObject;\nProcessFrame() ; \n// Call ourselves.\nreturn;\n}\nm_state = k_MovingTowardsTarget;\n// Intentionally missing break.\ncase k_MovingTowardsTarget :\nMoveABitTowards(this, m_target);\nif (Distance(this, m_target) > k_collisionTolerance)\nbreak;\nelse\nm_state = k_DisposeObject;\n// Intentionally missing break.\ncase k_DisposeObject:\nDispose (this, m_target);\nm_state = k_NeedsGoal;\nbreak;\nWhat a mess! Our AI code has gone from simple and elegant to a huge and unread-\nable state machine. Modifying the second version of die code will clearly be much more\ncomplex, and die state machine cannot be reused widi anodier class, because it requires\nm_state and m_target. That's accidental, or nonessential complexity.\nCentral to die problem is that all of die state now has to be stored in die object.\nThis is a profound change. In the first version of the code the \"target\" variable was\ndeclared as a local variable. It was created exactly when it was needed and fell out of\nscope when its job was done. Now, the target has to be recorded in the object. We also\nadded another member variable to our Janitor class, m_state. Where did this variable\ncome from? Why wasn't it needed in our first version of this routine?\nIn the first version of Process ( ) , die state is implied by which line of code is exe-\ncuting. It's stored in the program counter. The program counter keeps track of die\ncurrent state, the stack pointer points at the current set of variables, and life is easy.\nWhen we implement AI with callbacks, we have to simulate the instruction pointer\nand stack pointer and the benefits they bring us.\nA Simpler Method\nAt this point, it should seem obvious that using callbacks for our entity code is messy.\nTherefore, how do we turn our simple version of die janitor code into something that\nactually works? To do that we need to let the rest of the game loop and die other\nobjects have some CPU time, and we need to synchronize the objects so they do\nexacdy one update per frame. To do this we need to put each game entity into a\n",
      "content_length": 2247,
      "extraction_method": "Direct"
    },
    {
      "page_number": 249,
      "chapter": null,
      "content": "260 \nSection 3 Artificial Intelligence\nseparate thread and have the WaitOneFrame () function switch to the next thread. With\nsuch a system, the pseudocode of the first example can be compiled and run perfectly!\nWe could start an OS thread for each object. This lets each thread pretend that it\nowns the CPU, while the operating system manages the magic of swapping things\naround to change the CPU state. The WaitOneFrame () function would do the neces-\nsary work to switch to the next thread—see the sample code for details.\nThis sort of strategy works well for Web servers and other multi-threaded apps,\nbut it's a poor option for games. Many games run in environments where there is no\noperating system support for threads—or no operating system at all. Even if there are\nthreads, they are frequently too expensive for game purposes. Switching threads on\nWin32 takes thousands of machine cycles, and each thread uses up a minimum of 8\nKB of memory—4 KB for the Thread Information Block and 4 KB for the smallest\npossible stack. Both allocations take 4 KB because, in order to keep threads indepen-\ndent and allow for stack growth, their allocations are put on separate memory man-\nagement pages, and this forces a 4K granularity.\nOn Win32, there is also the option of using fibers—cooperatively multitasking\nthreads. Fibers are a bit better for our purposes because the context switching is much\nfaster and more easily controlled. However, the stack still takes at least 4 KB, and\nfibers don't work at all on Win95. On Win98, each fiber stack takes a minimum of 8\nKB, making its memory footprint as bad as for regular threads.\nMicro-Threads\nLet's step back and think about precisely what we want. We want to be able to write\nAI or other object-updating code that can pretend that it owns the CPU. After exe-\ncuting the code for one time slice update, we want to be able to call WaitOneFrame()\nto give the rest of the game some CPU time. When WaitOneFrame () returns we want\nexecution to continue where it left off, one time slice later. We want this to be fast,\nand we want minimal memory overhead.\nWhat do we have to do to switch from one thread of execution to another? The\ninstruction pointer in a CPU is a register that points at the next instruction to be exe-\ncuted. If we were to write some code that changed the instruction pointer, we could\neasily jump from one thread to another. Changing the instruction pointer is easy-\nCPUs have many instructions for doing that. In a few lines of assembly language you\ncan get the current instruction pointer, store it somewhere, and then jump to a new\nlocation. This will give die desired effect of jumping back into a previously running\npiece of code—but if that's all you do, you will be terribly disappointed.\nThe instruction pointer is not the only piece of state in a CPU and it is not the\nonly thing that determines what function you are executing. Another important piece\nof the puzzle is the stack pointer. All of the local variables of a function are stored rel-\native to the stack pointer (or the stack frame pointer, but let's ignore that for now). In\nfact, the stack pointer is even more important than the instruction pointer, because\nfunction return addresses—instruction pointers—are stored on the stack.\n",
      "content_length": 3270,
      "extraction_method": "Direct"
    },
    {
      "page_number": 250,
      "chapter": null,
      "content": "3.2 Micro-Threads for Game Object Al \n261\nLet's imagine that we've written a piece of code that pushes the instruction\npointer onto the stack, then changes the stack pointer, and then pops the instruction\npointer off of the stack. Since the new instruction pointer is popped off of the new\nstack, changing the stack pointer has also changed the instruction pointer—voilfr,\nwe've changed threads. In fact, since calling a function pushes the instruction pointer,\nand returning from a function pops the instruction pointer, our thread switching\nfunction is just two instructions—move a new value into the stack pointer, then\nreturn!\nOkay, it's not quite that easy. First, CPUs have more registers than just the stack\npointer and the instruction pointer. No problem—we'll deal with them the same way.\nPush them all onto the stack at the beginning, change the stack pointer, and then pop\nthem all at the end. It just works. The exact details vary from CPU to CPU, but any\nCPU that has enough flexibility in where you point the stack pointer can implement\nthis system. Micro-threads have even been implemented on a Nintendo GameBoy!\nOn an x86 CPU, a complete thread switch can be implemented in 12 assembly lan-\nV_lli' guage instructions. In the micro-thread sample programs on the CD, that is all the\nONmca> assembly language that is used. Here is a sample SwapThreads() routine:\nSwapThreads\n// Preserve all of the registers that VC++ insists we preserve.\n// VC++ does not care if we preserve eax, ecx and edx.\npush \nebx\npush \nebp\npush \nesi\npush \nedi\n// Swap stack pointers\nitiov \neax, \nesp\nmov \nesp, s_globalStackPointer\nmov \ns_globalStackPointer, eax\n// Restore all of the registers that we previously preserved.\n// Yes, they're coming off of a different stack - they were\n// carefully placed there earlier.\npop \nedi\npop \nesi\npop \nebp\npop \nebx\nret\nIs that all there is to it? That depends. On some CPUs, you may have to preserve\nfloating-point or multimedia registers as well. On the Intel architecture, because of\nthe, umm, peculiar arrangement of the floating-point registers, it is impractical for\ncompilers to preserve them over function calls, so compilers always make sure that all\nfloating-point numbers have been written to memory before calling any function,\nincluding your WaitOneFrame() function. You also don't need to preserve all of the\ninteger registers, because compilers don't expect all of them to be preserved over func-\ntion calls—consult your compiler documentation for details.\n",
      "content_length": 2498,
      "extraction_method": "Direct"
    },
    {
      "page_number": 251,
      "chapter": null,
      "content": "262 \nSection 3 Artificial Intelligence\nStack Management\nBut what, exactly, are we assigning to our stack pointer when we change threads?\nWhen we start an OS thread we are implicitly allocating and initializing a stack—now\nwe have to do it ourselves. On Win32, the operating system allocates a 4 KB page of\nmemory for each stack. It also reserves some extra address space—1 MB by default—\nso that the stack can grow. If you declare a large array in a function, or have deeply\nrecursive function calls, the operating system automatically allocates more 4 KB pages\nof memory. If you go beyond the address space that was reserved, it stops you with a\npage fault.\nWe're trying to avoid allocating 4 KB of stack for each thread, so how much\nshould we allocate? We might decide that we want to allocate no more than 100 bytes\nof stack per object; after all, we want to have hundreds or thousands of these things.\nWe could use malloc or new to allocate 100-byte blocks and then, with a bit of care-\nful array initialization, set up this stack so that we can switch to it with\nSwapThreads(). This method will work, but it's rather dangerous. If you write any\ngame entity code that uses a bit too much stack, terrible things will happen. You will\ncorrupt whatever block of memory conies before the thread stack, and your game will\ncrash. If you decide to use this system, be sure to put some sort of marker at the far\nend of the stack, and check these markers after every thread switch to see if they have\nbeen overwritten. At least that way you will know when you have trashed memory.\nA slightly different implementation of micro-threads can avoid these strict stack\nsize limits. In this variation a large stack is allocated that all micro-threads share.\nWhen a micro-thread goes to sleep, the thread manager copies the contents of the\nstack to a resizable backup buffer. This buffer only needs to be reallocated when the\nthread's stack size increases, so the buffer allocation time is negligible. Therefore,\nthe only additional overhead of this method is copying the contents of the stack back\nand forth. Interestingly enough, this copying is virtually free, because it primes the\nCPU caches and prepares them for running the thread.\nSo far, stack copying probably doesn't seem any better than allocating a fixed\nstack for each thread. However, the advantage with stack copying is that the stack\nusage only needs to be small when you switch threads. If your AI entities need to call\na complex BSP pathfinding routine, a debug print function, or some other function\nthat uses a lot of stack, they can do this with stack copying micro-threads. The tem-\nporarily large stack usage is harmless as long as you don't call WaitOneFrame() from\ndeep within these utility functions. With fixed-stack micro-threads you can never use\nlarge amounts of stack—not even temporarily.\nThis is a huge advantage. If your AI routines are forced to use a tiny little stack\nwith not much depth, you may end up with AI that has a tiny little brain with not\nmuch depth.\n",
      "content_length": 3037,
      "extraction_method": "Direct"
    },
    {
      "page_number": 252,
      "chapter": null,
      "content": "3.2 Micro-Threads for Game Object Al \n263\nComplications\nLoading and Saving Games\nCompilers will sometimes generate stack frames for each function, which are used for\neasier addressing of local variables and parameters. These stack frames are tied\ntogether in a linked list on the stack. In other words, a typical stack contains pointers\nto itself. Therefore, the stack image cannot be used in a different location.\nStacks also contain return addresses—pointers to code. Therefore, if you save a\nstack buffer to disk you cannot load it up and expect it to work if you have recompiled\nyour code—all of the code bytes will have moved.\nEven if you deal with the problems of micro-thread stacks containing pointers to\nthemselves and to code, the stacks will contain local variables, some of which will\nbe pointers. When you have pointers in a structure you can still save and restore the\nstructure if you are careful, but with micro-thread stacks, you don't know where the\npointers are. Careful use of C++ pointer objects can manage this problem, but it is\ncomplicated.\nTherefore, loading and saving of games that use micro-thread stacks is problem-\natic. This may restrict their usage to games that don't need to load and save, or to con-\nsole machines where the exact memory layout can be restored when saving.\nStructured Exception Handling\nWin32 structured exception handling is a critical part of a debugging strategy, as it\nensures that detailed crash information is recorded. It is also used to implement C++\nexception handling. However, if you aren't careful, structured exception handlers will\nnot get called for exceptions that happen inside micro-threads. That's because the OS\nhandler that walks the linked list of exception handlers (another linked list on the\nstack) gives up if it notices an implausible pointer, such as a stack pointer outside of\nthe current OS thread's known stack range [Pietrek97].\nThis can be avoided if you locate your temporary stack somewhere in the address\nrange of your real stack, well below what you're actually using. Remember that it has\nto be in a fixed location because the linked lists on the stack won't work if it moves,\nand you have to make sure that your main thread's stack never goes down far enough\nto be overwritten by the micro-thread stacks.\nOutputDebugString\nOn Windows NT, if you call OutputDebugString () from a micro-thread when you're\nnot running under a debugger, your program may exit, due to the structured excep-\ntion handling problem mentioned earlier. This is easily fixed by placing your stack\nC^j2i5 \nappropriately or by using the OutputDebugStringW95() function on the companion\nON m a> \nCD-ROM, which detects whether you are running under a debugger and only uses\nOutputDebugString () when it is safe. It also looks for DBWin32, the freely available\ndebug output monitoring program, and talks to it directly whenever possible.\n",
      "content_length": 2895,
      "extraction_method": "Direct"
    },
    {
      "page_number": 253,
      "chapter": null,
      "content": "264 \nSection 3 Artificial Intelligence\nConclusion\nThreads are a simpler method of writing AI code for many independent entities.\nMicro-threads let us implement our game entities using threads without die high\nmemory or CPU cost of other threading methods. Micro-threads can be easily imple-\nmented on any CPU architecture, with very little assembly language [KeppelOl].\nA sample implementation of micro-threads for Win32 is on the companion CD-\nROM. Also included is a simple game that uses micro-threads, and a test application\n«,««« \n£or comparmg micro-threads to Fibers and OS threads.\nMicro-direads have also been implemented in several scripting languages used in\ngames, such as Lua [LuaOl], SCUMM (a proprietary Lucas Arts engine also used by\nHumongous Entertainment), and Python [TismerOl].\nA micro-thread janitor can clean up your game code.\nReferences\n[Brooks95] Brooks, Frederick P., Jr. The Mythical Man-Month: Essays on Software\nEngineering, Anniversary Edition, Addison-Wesley, 1995.\n[KeppelOl] Keppel, David, \"QuickThreads distribution,\" available online at http://\nwww.mit.edu/afs/sipb/project/scheme/src/guide-1.3/qt/, June5, 2001.\n[LuaOl] \"The Programming Language Lua,\" available online at www.tecgraf.puc-rio.\nbr/lua/about.html, February 22, 2001.\n[Pietrek97] Pietrek, Matt, \"A Crash Course on the Depths of Win32 Structured\nException Handling,\" Microsoft Systems Journal (Jan 1997).\n[TismerOl] Tismer, Christian, \"Stackless Python,\" available online at www.stackless.\ncom/, February 23, 2001.\n",
      "content_length": 1513,
      "extraction_method": "Direct"
    },
    {
      "page_number": 254,
      "chapter": null,
      "content": "3.3\nManaging Al with Micro-\nThreads\nSimon Carter, Big Blue Box Studios\nscarter@bigbluebox.com\nA\ns discussed in the previous gem, AI in games is generally implemented through\nsome form of state machine. State machine architecture has a number of advan-\ntages for AI. Most notably, the system can be suspended at any particular state, a facil-\nity that is critically important for any game that intends to have more than one AI\nentity. However, traditional implementations of state machines tend to be messy,\nunintuitive, pro'ne to bugs, difficult to debug, and hard to read. Micro-threads offer a\nfar more elegant way of implementing state machines and can lead to a very robust\nand extensible AI system. This gem attempts to give an idea of how to implement\nsuch a system and take full advantage of its flexibility.\nPiece by Piece\nMicro-threads allow us to code up state machines using normal, everyday program-\nming practices. Most of the \"magic\" goes on in the background, leaving us free to\ndesign our AI system as elegantly as we wish, without having to pander to background\narchitecture issues. Although this is very liberating, it can be difficult to know where\nto start when so many restrictions are lifted.\nGood artificial intelligence in games is all about organizing what can become a\nvery complex system into manageable chunks, and to make these \"modules\" as intu-\nitive and reusable as possible. An important design decision is the granularity of this\nmodularization. By way of example, classic state machines by necessity tend to make\neach individual state a module, and it is this very low-level granularity that makes the\nsystem awkward. Micro-threads allow us to choose the granularity of our modules\nourselves, and choose the level that makes the most sense conceptually.\nFrom a design standpoint, it is far better to break complex AI into units of\n\"behavior.\" In this context, \"behavior\" is the full set of tests and actions that are used\nto model an entity's responses to particular stimuli; for example, being hungry, being\nin a fight, being scared, and so forth. The more behaviors a particular entity has, the\nmore rich and varied its resulting AI will appear to be. An ideal design scenario would\nbe to have the ability to attach different suites of behaviors to different entities. In\n265\n",
      "content_length": 2313,
      "extraction_method": "Direct"
    },
    {
      "page_number": 255,
      "chapter": null,
      "content": "266 \nSection 3 Artificial Intelligence\naddition, it would be great to be able to reuse certain common behaviors between dif-\nferent types of entities, and hence minimize the amount of replicated code.\nA system based on behavioral units will allow us to construct flexible AI out of\nthese different modules, allowing us to rapidly build up different entity \"brains\" from\nreusable behaviors.\nGood Behavior\nHere's how a general interface for a behavior module might look:\nclass CAIBehavior\n{\nCAIEntity* PEntity;\npublic:\nCAIBehavior(CAIEntity* \npentity);\nvirtual bool IsRunnable(void) = 0;\nvirtual void Update(void) = 0;\nvirtual void OnActivate(void) = 0;\nvirtual void Cleanup(void) = 0;\n};\nThe IsRunnable method is responsible for stating whether the correct conditions\nare present for the behavior to run; for example, is there food nearby and is the entity\nhungry, for a \"hunger\" behavior. OnActivate is called whenever a particular behavior\nbecomes \"active.\" Cleanup is called whenever a behavior is deactivated and is respon-\nsible for making sure that the entity is put back cleanly into whatever state it was in\nbefore the behavior was activated.\nDon't worry about these too much, as they are only necessary when we want to\norganize multiple behaviors later. For the moment, the most important method\nfor our single unit of behavior is Update, as this is the method that performs the meat\nof our AI.\nIn general, a particular module of AI behavior will simply be a tree of conditional\ntests, which will resolve into different actions. For example, think about what a hun-\ngry creature might do.\nCFood* pfood = FindPFood(PEntity->GetPos());\nif(pfood!=NULL){\n//Move toward the food until we are near it\nwhile(!PositionsAdjacent(PEntity->GetPos(), \npfood->GetPos())\nPEntity->MoveOneStepTowardsPos(pfood->GetPos());\nPEntity->EatFood(pfood); //Eat the food.\n}\nHere, the creature looks for food and, if it finds it, moves toward it one step at a\ntime until it is adjacent. When it is near the food, it eats it. Unfortunately, if we ran\nthis code, the game would freeze in the while loop; this is where micro-threads come\nin to save the day. Assuming this behavior class is being run in a micro-thread, all we\nhave to do is add one magical line:\n",
      "content_length": 2241,
      "extraction_method": "Direct"
    },
    {
      "page_number": 256,
      "chapter": null,
      "content": "3.3 Managing Al with Micro-Threads \n267\nwhile ( !PositionsAdjacent(PEntity->GetPos() , pfood->GetPos()){\nPEntity->MoveOneStepTowardsPos(pfood->GetPos()) ;\nMicroThreadSleepO ; // a call to suspend the micro thread.\n}\nPEntity->EatFood(pfood) ;\nSuddenly, our simple AI process is a state machine! Now, after every step, the AI\nwill suspend its processing, returning control to the main game.\nIt's All in the Mind\nAlthough it may not seem like we've achieved much yet, we are now able to construct\na single module of AI behavior. In order to make an entity's life rich and varied, how-\never, we need some way of organizing and prioritizing multiple, conflicting behaviors\nin such a way that only one is active at a time. This is where the brain class comes in.\nclass CAIBrain\n{\nMicroThreadlnfo* \nPMicroThread;\nstd: :list<CAIBehavior> \nBehaviors;\nstd: :list<int> \nBehaviorPriorities;\nCAIBehavior* \nPActiveBehavior;\nint \nActiveBehaviorPriority;\npublic:\nvoid AddBehavior(int priority, CAIBehavior& behavior);\nvoid Update (void) ;\nEach AI entity in our game will have its own brain, and each brain has a micro-\nthread. Using the AddBehavior method, different types of entities can add different\nbehaviors to the suite of possibilities. In addition, each behavior is given a priority,\nwhich can be used to help choose the behavior to run. It is the responsibility of the\nUpdate method of the brain to keep switching control to the micro-thread, which will\nin turn keep pumping the Update method of the active behavior.\nBefore that, however, we must make sure that there is an active behavior. When\nour entity has nothing to do, we need to run through all the available behaviors and\nchoose the one with the highest priority that succeeds in the IsRunnable test. We take\nthat chosen behavior, call OnActivate on it in case it has any special initialization\ncode, and set it as our active behavior. Once that behavior has finished, we call\nCleanup on it to run any uninitialization routines it may have, and then do the whole\nthing again.\nIn this way, a brain will make sure it always keeps an appropriate active behavior\nrunning. In practice, it is usually a good idea to give all entities some type of fallback\nidling behavior that will always pass the IsRunnable test, just so that it always looks\nlike it is doing something.\nThere is a slight additional complication to this. Say our entity has decided it\nwants to go and run its Sleep behavior for a couple of minutes, because everything is\n",
      "content_length": 2485,
      "extraction_method": "Direct"
    },
    {
      "page_number": 257,
      "chapter": null,
      "content": "268 \nSections Artificial intelligence\nquiet and its Def endSelf behavior, despite having a higher priority, has found no\naggressors in the IsRunnable method. Unfortunately, while it is sleeping, the entity is\nattacked by some unscrupulous enemies. Using the system described previously, our\nsleeping AI character will be brutally murdered in his sleep, because he would only\nchoose another active behavior when his current one finished.\nWhat we need to do is periodically check our behavior list for an entry that suc-\nceeds on IsRunnable and is of a higher priority than the active behavior. If we find\none, we unplug whatever is currently running—in this case, our Sleep behavior—and\nslap in our new, higher priority system—Def endSelf. In this particular instance, it\nwould probably be the job of the Cleanup method of the Sleep behavior to ensure that\nthe entity is awake, before the new and rather more violent behavior is plugged in.\nThe code for the basics of this system is shown here:\nvoid Update()\n{\nCAIBehavior* pending = NULL;\nif(PActiveBehavior) {\npending = FindNextBehavior(ActivePriority);\n}\nif(Spending && !PActiveBehavior)\npending = FindNextBehavior(-1);\nif(pending){\nif(PActiveBehavior)\nTerminateActiveBehavior();\nPActiveBehavior = pending;\nPActiveBehavior->OnActivate();\n}\nif(PActiveBehavior)\nSwitchToMicroThread(PMicroThread);\n}\nvoid FindNextBehavior(int priority)\n{\n//Find a higher priority behavior that passes IsRunnable\n}\nstatic void MicroThreadFunction(void* pcontext)\n{\nCAIBrain* pthis = (CAIBrain*)(pcontext);\nwhile(!pthis->TerminateThread){\nif(pthis->PActiveBehavior){\npthis->ActiveBehaviorRunning = true;\npthis->PActiveBehavior->Update();\npthis->ActiveBehaviorRunning = false;\n}\nMicroThreadSleep();\n",
      "content_length": 1728,
      "extraction_method": "Direct"
    },
    {
      "page_number": 258,
      "chapter": null,
      "content": "3.3 Managing AI with Micro-Threads \n269\nComplications\nDying Considerately\nAll of this so far has been deceptively simple. Brains run micro-threads, which in turn\ncall update methods in behaviors. However, distributing processing across game turns\nhas a number of important ramifications with which we need to deal. If we return to\nthe simple hunger code we looked at earlier, there are a couple of hidden difficulties.\nFirst is the issue of tracked entity death; because the code is now spread across multi-\nple game turns, somebody else may eat the food we are tracking by the time we reach\nit. If our food had simply been deleted from the game when it had been eaten, the\ncode would crash since our pointer would be tracking invalid data.\nDepending on how we handle entity deaths in our game, there are a number of\nways to deal with this. Fundamentally, we have to make sure that any handles we have\non game entities will be valid between game turns. In addition, we should be able to\ninquire whether the entity we are tracking has died. One solution is to force our per-\nsistent handles to be identifier numbers instead of pointers, unique to every entity\nthat gets allocated in our game. That way, when an entity dies, our game code can\nsimply tell us that our handle is invalid. Unfortunately, whenever we wish to access\nany part of the entity, we have to turn our handle into a reference to the actual data,\nwhich can result in bloated, inefficient code.\nA better method is to write a special smart pointer system that deals with all of\nthese issues automatically; a good set of guidelines for writing smart pointers is given\nby Scott Meyers [Meyers96]. Classic smart pointers conceptually have a degree of\nownership over the objects they point to, through reference counting of some sort.\nWhat we want is the reverse, a pointer that passes ownership of itself to the special\ntype of object at which it is pointing. Whenever a tracking pointer is pointed at one\nof our objects, it registers itself with it. Then, when the object dies, it can inform any\ntracking pointers that refer to it about its death and set them to a null value. Once we\n- ,, \nhave this working, all we have to do in our AI code is make sure we check that the\nV_l2ss^ \npointer is non-null before we use it. Example code on how to implement this \"track-\ning pointer\" system is provided on the companion CD-ROM.\nDying Cleanly\nThere is another issue with which we have to deal. What happens if the object whose\nAI we are running dies or is interrupted? If this occurs, then the active behavior needs\nto stop, all the objects we created on the heap need to be deleted, and we have to exit\nour AI code as quickly as possible. Again, depending on your preferences, there are a\nnumber of ways to handle this.\nAn elegant method is to use the C++ exception language facility. When an excep-\ntion is thrown, behind-the-scenes C++ magic cleans up the stack and moves control\nback up the execution hierarchy, which is exactly the functionality we want. All the\n",
      "content_length": 3026,
      "extraction_method": "Direct"
    },
    {
      "page_number": 259,
      "chapter": null,
      "content": "270 \nSection 3 Artificial Intelligence\nbrain class needs to do is catch the exception and call the behaviors cleanup method.\nHowever, this is a fairly heavyweight approach, and some micro-thread implementa-\ntions don't deal too kindly with exceptions.\nA simpler approach, although rather more invasive, is to periodically check for\nwhether we have been terminated, and return if we have. This does require some care-\nful structuring of the AI code, but it is also a very lightweight solution. With some\nthought, this can even be packaged up to be only minimally invasive. In most cases, to\nbe on the safe side, the brain will keep polling the micro-thread until it receives noti-\nfication that the behavior has indeed stopped running, a technique with which you\nare familiar if you have used threads before.\nvoid CAIBrain: :TerminateActiveBehavior()\n{\nif (PActiveBehavior){\nPActiveBehavior->SetTerminateFlag() ;\nwhile ( Act iveBehaviorRunning)\nSwitchToMicroThread(PMicroThread) ;\nPActiveBehavior->Cleanup( ) ;\nPActiveBehavior->ClearTerminateFlag() ;\nActions Speak Louder\nTaking all these modifications on board, let's see how our earlier example \"hunger\"\nbehavior code might now look.\nvoid Update ()\n{\nCTrackingPointer<CFood> pfood;\npfood = FindPFood(PCreature->GetPos()) ;\nif(pfood!=NULL){\nif (ActionMoveTowardsFood( pfood )==AI_OK)\nPEntity->EatFood(pfood) ;\nEAIReturn ActionMoveTowardsFood(CSmartPointer<CFood> pfood)\n{\nwhile (pfood!=NULL && !PositionsAdjacent(PEntity, pfood-\n>GetPos()){\nif (TerminatedO)\nreturn (AI_TERMINATE) ;\nPEntity->MoveOneStepCloserToPos(pf ood->GetPos( ) ) ;\nMicroThreadSleepO ;\n}\nif(pfood!=NULL)\nreturn (AI_OK);\nreturn (AI_FAIL);\n",
      "content_length": 1658,
      "extraction_method": "Direct"
    },
    {
      "page_number": 260,
      "chapter": null,
      "content": "3.3 Managing Al with Micro-Threads \n271\nA special tracking pointer is used to track the food in case it dies. The Action-\nMoveTowardsFood method asks the brain to suspend the micro-thread after every step\nit takes toward the food. If die action finds that it has been \"terminated\" by the\nbehavior's brain, it returns a value that lets the calling AI behavior know that it should\ncleanly exit. Likewise, if the food dies, it returns a code telling the behavior as much.\nIn addition, all the code that deals with the problems of distributing the process across\ngame turns has been packaged into a separate method. Structuring our code in this\nway has a number of important advantages:\n• AI is effectively a tree of conditional tests that ultimately resolve into actual diings\nto do. These \"actions\" are the only pieces of code that need to be distributed across\ngame turns; hence, it makes sense to isolate them from die rest of the system.\n• Since only actions need to suspend processing, only they need to do any testing\nfor termination. Keeping the suspension and termination code together keeps\nthings tidy and reduces the chances of forgetting to do one or die odier.\n• Action functions can be put into the behavior base-class and reused between dif-\nferent behaviors.\nExtensions\nThe system described here has been kept purposefully loose, as I have simply\nattempted to give an idea of the elegant architecture that micro-threads can provide\nfor AI. Any number of favored AI tricks can be added, including:\n• Giving each behavior a string name, which can be displayed for debugging pur-\nposes.\n• Allowing brains to be assembled using an external data scripting language, to\nallow nonprogrammers to create and specialize entities. See Scott Bilas' excellent\ngem in this book on the topic.\n• Using the \"message\" system described in Game Programming Gems to allow AI\nentities to enquire and send information about interesting events in the world\n[RabinOO].\nConclusion\nMicro-direads allow an enormous amount of flexibility for writing AI. Using this free-\ndom properly, it is possible to create convincing, fast, lightweight, bug-free AI quickly\nand easily. Particular advantages that this system has over other methods include:\n• Behaviors are grouped intuitively into modules. They can be reused between dif-\nferent types of entities trivially by adding them to different brains.\n• There is no arbitrary jumping around spaghetti links between states, common in\nother state machine implementations. As such, when debugging, you can see the\nentire conditional tree that led to a particular problem, without having to trace\nthrough disparate states.\n",
      "content_length": 2648,
      "extraction_method": "Direct"
    },
    {
      "page_number": 261,
      "chapter": null,
      "content": "272 \nSection 3 Artificial Intelligence\n• Programmers can code using their favored programming techniques, without\nhaving to pander to a rigid architecture.\n• Data specific to an entity and its behavior can be stored naturally between game\nturns in the behavior class.\nReferences\n[Meyers96] Meyers, Scott, \"Smart Pointers,\" More Effective C++, Addison Wesley,\n1996.\n[RabinOO] Rabin, Steve, \"Designing a General Robust AI Engine,\" Game Program-\nming Gems, Charles River Media, 2000.\n",
      "content_length": 481,
      "extraction_method": "Direct"
    },
    {
      "page_number": 262,
      "chapter": null,
      "content": "3.4\nAn Architecture for RTS\nCommand Queuing\nSteve Rabin, Nintendo of America\nsteve rabin@hotmail.com\n[\neal-time strategy games have a unique method of user interaction. Using a\nmouse, the player is able to assign multiple orders to individual units or groups\nof units. This interaction has matured over the years, with each new RTS building\nand improving on previous designs. One of the most evolved designs is a technique\ncalled command queuing. This gem describes how this method of interaction works,\nand how it can be directly woven into the underlying AI architecture.\nRTS Commands\nThe basic user interface for an RTS game involves selecting units and commanding\nthem to do some task, such as attack an enemy or move to a particular spot. This is a\nfairly simple concept that doesn't require any great AI architecture to implement.\nHowever, it's important to first consider the range of simple commands that are avail-\nable in most RTS games before discussing more complex combinations. The follow-\ning is a list of common RTS commands.\n• Attack a creature or building\n• Build a structure or weapon\n• Move to a spot\n• Patrol to a spot\n• Collect a resource (food, raw material, energy)\n• Research a skill\n• Repair a unit or building\n• Reclaim a unit (recycle dead unit's material/energy)\n• Guard a unit or building (attack anyone who attacks it)\n• Hold position (attack anything in range but don't move)\n• Stop\n• Self-destruct\n273\n",
      "content_length": 1435,
      "extraction_method": "Direct"
    },
    {
      "page_number": 263,
      "chapter": null,
      "content": "274 \nSections Artificial Intelligence\nCommand Queuing\nWhile playing an RTS game, you spend much of your time telling units where to\nmove. Unfortunately, the pathfinding in most games isn't perfect and it often helps\nwhen the player assists in planning paths by setting waypoints. Waypoints are simply\nsuccessive move commands that are queued up within a unit. The player queues up\nthe move commands by holding some special button (like the Shift key) while click-\ning on the ground for each waypoint.\nWaypoint queuing was an important step that has opened the door for a more pow-\nerful interface system. If you can queue waypoints, why not let the player queue any\ncombination of commands? In effect, you could tell a unit to attack a creature, repair a\nwall, and then build a gun turret, all widiout waiting for any of the tasks to be com-\npleted. In addition, the player could decide, at a slighdy later time, to queue even more\ncommands onto the end of those. Generally, this idea is known as command queuing.\nThe trick is to think of every command as a task and to think of a unit's brain as\na queue of tasks. The unit will always process the task that's at the front of the queue.\nOnce that task is completed, it's destroyed and the next task is started. When there are\nno more tasks to process, a unit should have a default idle task. Figure 3.4.1 is an\nexample of a unit's brain queue.\nFigure 3.4.1 shows the result of queuing the commands attack, repair, and move.\nIt also shows that each task has data associated with it, such as what to attack or where\nto move. New tasks to be queued are placed at the end of the list, but before the\ndefault task. The default task must always be the last task and it never completes and\nis never destroyed.\nIf the player commands a unit to do a new task without holding the \"queuing\"\nbutton, all tasks are destroyed and the new task is put in the queue. Thus, queued\ntasks can easily be replaced by a single, new command.\nBrain Queue\n(front of queue)\nCurrent\nactive task\nenemy 24\nj-v \n-s \n.J^- \n•: i .&*&?#.&£&&* •• -\\ ' Ulill T-^\nQueued\nnon-active\ntasks\npos\n. Insert additional\nqueued tasks here\nDefault task\n—' \n9\n(never completes)\nFIGURE 3.4.1 An AItask list in the form of a brain queue.\n",
      "content_length": 2238,
      "extraction_method": "Direct"
    },
    {
      "page_number": 264,
      "chapter": null,
      "content": "3.4 An Architecture for RTS Command Queuing \n275\nWith this architecture, a common behavior is to allow the player to \"see\" the\ncommand queue by selecting the unit and holding the \"queuing\" button. The on-\nscreen result is that arrows show where the unit is planning to go and what they\nintend to do, such as build a structure. The elegant way to implement this is to let\neach task draw its contribution onto the screen. This allows the player to quickly see\nwhat's queued up in the unit and what additions might be appropriate.\nThis simple architecture is also blind to who put the commands in the queue.\nObviously, the player can put commands there, but the game can also preload com-\nmands for a NPC (Non-Player Character) that might be patrolling or guarding a spot.\nThe AI can also make high-level decisions about which units to attack by simply\nputting those commands in the queue. Even packets from over a network can be\nallowed to place commands in a unit's queue. It's a very elegant system that allows a\nlot of flexibility.\nCyclic Commands\nPatrolling is a cyclic command that presents some interesting consequences for the\nsystem described so far. When a player takes a unit and tells it to Patrol to a spot, the\nunit will remember his original spot and then walk back and forth between the two,\nindefinitely (or until an enemy is in sight). The player could also queue up several\nPatrol waypoints and the unit would similarly cycle through the waypoints forever.\nFigure 3.4.2 shows a three-point patrol that was initiated with two mouse clicks.\nOriginal Character Position \nFirst Patrol Click\nSecond Patrol Click\nFIGURE 3.4.2 Patrol path for a unit.\nQueuing the First Patrol Point\nThe first Patrol click from a player actually ends up placing two patrol commands on\nthe queue. This is because the intent of the player is for the character to move to the\nposition of the mouse click, and then move back to his original spot, repeating the\ncycle over and over again. Figure 3.4.3 shows the brain queue after just one Patrol\ncommand was issued by the player.\n",
      "content_length": 2066,
      "extraction_method": "Direct"
    },
    {
      "page_number": 265,
      "chapter": null,
      "content": "Section 3 Artificial Intelligence\npos 1\nFIGURE 3.4.3 The brain queue after a single Patrol command was issued.\nInterestingly, a Patrol command is identical to a Move command, except that it\ngets cycled to the back of the queue. Therefore, our queuing system will work per-\nfectly if a simple \"cyclic\" flag is set within a Move task in order to make it a Patrol\ntask. When the Patrol task completes, rather than being destroyed (like a Move task),\nit's put onto the back of the queue (but before the default task). Figure 3.4.4 shows\nseveral iterations of the three-point patrol sequence from Figure 3.4.2.\ntrain Queu<\nnitial pos 1\nliP\" /\nS|i| ill I\n• . - :-\"\n.«..i^a:. ;• .: ._\nisiil\nIgSflS iki;!\n-..:•-. \n'-\n:-i\nX' •\"„''>\n~.-Mc\nISEiel\n\".\".:.-;'\n:\" \n. \"v.\n1\n~;Sg«\nHillr\n-.,;i»^.\nill\nJ \nE\n) \n(P\n^pos2\ncyclic\npos 3\ncyclic\n_^pos 1\ncyclic\nlime —\ntrain Queui\nos 2 reache\n'?'.\n:',:.^\n: ^^Bffe^\nfliif|:\n||i|i|i\ns-SV.^1.\".:-.1\"1.1:?\";?;^:^.;;1\n2 \nE\nd) \n(p\n_^pos 3\ncyclic\nr-Kpos l\ncyclic\n_^pos2\ncyclic\n*•\ntrain Queue\nos 3 reache*\nK|i3v*fl\n'iiiii:i\n\"^^IHftifr^-\n., \n. . v«^>.'-^>tef. . , ; • . • ; :\npos 1\ncyclic\npos 2\ncyclic\npos 3\ncyclic\nFIGURE 3.4.4 Three iterations of a patrol path.\nQueuing Additional Commands\nSome tricky issues arise when the player wants to queue extra commands when Patrol\ntasks exist in the queue. While the following might be slightly subjective, experimen-\ntally it's very close to what most players expect.\n",
      "content_length": 1426,
      "extraction_method": "Direct"
    },
    {
      "page_number": 266,
      "chapter": null,
      "content": "3.4 An Architecture for RTS Command Queuing\n277\nThe first issue is where to put additional Patrol commands that are to be queued\nup. The player who is adding these extra Patrol points will probably expect that\nthey're put after the first set of Patrol points (regardless of where the unit currently is\nin the brain queue). This is an important point since the unit could be anywhere\nalong the patrol when the second set of Patrol commands are queued.\nThe solution is to mark the last Patrol command ever queued. This allows new\nPatrol commands to get queued after it. Once new Patrol commands are added, the\n\"last\" marker is moved. Figure 3.4.5 shows an example of three Patrol commands\nbeing queued successively.\nBrain Queue\n(first Patrol click)\nBrain Queue\n(second Patrol click)\nBrain Queue\n(third Patrol click)\npos 2\npos 1\ncyclic\npos 2\ncyclic\npos 3\n• cyclic\nlast\npos 1\ncyclic\npos 2\ncyclic\n_^_iis~l pos 1\ncyclic\nFIGURE 3.4,5 Three Patrol commands being queued in order.\nThe second issue with queued Patrol commands involves queuing additional\nnon-Patrol commands. In general, the player expects the command to be executed\nimmediately after the current Patrol waypoint is achieved. This is tricky since the new\ncommands must be placed after the current Patrol command, if there is one, and after\nany other noncyclic commands. Figure 3.4.6 shows a case of queuing several new\nnon-Patrol commands.\nAs shown, Patrol commands throw several wrenches into the command queuing\nconcept. The trick is to implement what the user expects to happen. The user will\ntypically have a model in his or her head of how the system will work. Uncovering\nthat model is not an easy task, but it will give you good insight into how to design the\ninteraction and behavior of the command queuing system.\nHowever, dealing with the users' mental model is a two-way street. It's also\nimportant to give the players immediate feedback, letting them know the result of\n",
      "content_length": 1939,
      "extraction_method": "Direct"
    },
    {
      "page_number": 267,
      "chapter": null,
      "content": "278\nSection 3 Artificial Intelligence\nBrain Queue\n(Patrol Issued)\nTV- \na \nP<>s2\n| Move \n!->• cyclic\n3 \nlast\nBrain Queue\n(Build Issued)\npos 2\nBrain Queue\n(Repair Issued)\nhouse\npos (4, 7)\nhouse\npos (4, 7)\nunit 42\nFIGURE 3.4.6 Queuing additional commands with Patrol tasks already queued.\ntheir input and how it was interpreted. That way, if the users' model is incorrect or\nflawed, they can quickly reconcile it with the correct model. A wonderful book that\ndiscusses the subject of mental models is \"The Design of Everyday Things\" by Don-\nald Norman [Norman90].\nConclusion\nCommand queuing is now a standard power feature that no RTS game can do with-\nout. By using the brain queue architecture to store tasks, many of the complexities of\na command queuing system go away. In addition, you can think of the brain queue as\na simple task list, or you can turn each task into its own neatly wrapped AI system\nthat knows how to accomplish its job. Either way, your players should be able to\nqueue up whatever they wish, and easily manage hundreds of units with this simple,\nyet powerful interface.\nReferences\n[Norman90] Norman, Donald, A., The Design of Everyday Things, Currency/Double-\nday, 1990.\n",
      "content_length": 1193,
      "extraction_method": "Direct"
    },
    {
      "page_number": 268,
      "chapter": null,
      "content": "3.5\nA High-Performance Tile-\nbased Line-of-Sight and\nSearch System\nMatt Pritchard, Ensemble Studios\nmpritchard@ensemblestudios.com\nI\nn the realm of strategy games, the concepts of Line-of-Sight (LOS) and Fog-of-War\n(FOW) for target identification and acquisition are often encountered. In tradi-\ntional turn-based strategy games, using the brute-force approach of completely rebuild-\ning a player's explored and visible maps has generally proven to be adequate. However,\nusing the same approaches in a Real-Time Strategy (RTS) game quickly reveals perfor-\nmance issues, especially as the size of the game world or number of units increases. Still,\nmany commercial RTS games, some very successful, have used this rebuild-all approach.\nUnfortunately, they have to make performance compromises such as forgoing the FOW\naltogether or not updating it every game turn, thus allowing inaccuracies to appear in\nthe display. This gem presents an efficient implementation of a player visibility system\nfor tile-based games that minimizes the performance impact, while providing support\nfor fast searching as well as other game features.\nOverview\nThe first assumption is that internal to the program, sections of the game world area\nare represented by small chunks or tiles, which correspond to a two-dimensional\narray. Most real-time strategy games have rectangular game maps, but this implemen-\ntation is easy to adapt to a hex-based world layout.\nThe goals of our player visibility system are as follows:\n• The game's explored, visible, and fogged tiles must be fully accurate at all times.\n• Units must be able to search very fast for other units or objects of interest, with\nrespect to FOW and visibility.\n• The system must support up to 16 players at a time, allowing for arbitrary infor-\nmation sharing between players.\n• The system must scale well with respect to more units, larger maps, and larger\nsearch radii.\n279\n",
      "content_length": 1915,
      "extraction_method": "Direct"
    },
    {
      "page_number": 269,
      "chapter": null,
      "content": "280^ \njSection 3 Artificial Intelligence\nDefinitions\nTile. The smallest discrete square- or hexagon-shaped portion of the game world.\nWorld. The total area in which the game takes place; internally a 2D array of tiles,\nalso called the map.\nPlayer. A human or computer entity who controls a population of units. Each\nplayer has a unique set of visibility information.\nUnit. Any game entity that is owned or controlled by a player. It does not have to be\nmovable.\nLine-of-Sight (LOS). The area around a unit that is currently visible because of its\npresence.\nLOS Radius. The range of a units LOS area, measured in tiles.\nUnexplored Tile. A tile that the player's units have never seen within their LOS.\nFogged Tile. A tile that has been explored but is not currently in the LOS of any of\nthe player's units.\nVisible Tile. A tile that is currently in the LOS of one or more of the player's units.\nFog of War (FOW). The concept that if an explored tile is not currently in the LOS\nof a player's unit, then the player can't see other players' units on that tile.\nIn an RTS, we assume that for each player, the map starts out unexplored. As tiles fall\ninto a unit's LOS, those tiles become explored for the player who owns that unit.\nWhen an explored tile is no longer in a unit's LOS, the tile becomes fogged for that\nplayer, yet will never revert to being unexplored. It's important to note that die tile\nstates of unexplored, explored, and fogged are unique for each player.\nComponent #1: Individual Player Visibility Maps\nThe first component of the player visibility system that needs to be implemented is a\nvisibility count map for each player in the game. This is a rather simple structure: a\n2D byte array with a one-to-one correspondence to the tile layout. Each array element\ncontains a count of how many of the player's units can see that tile (in other words,\nhow many units' LOS contain that tile).\nUpdating the visibility map is simple. When a unit is first created or moved into\na new tile position, all of the visibility counts are incremented by one for the tiles in\nthe unit's line of sight. When the unit is deleted, destroyed, or moves off a tile, all of\nthe visibility counts are decremented by one for the tiles in the unit's LOS. The value\nin each visibility map element is nonzero if the tile is visible to the player. However, it\nis unclear if a zero value means an unexplored tile or a fogged tile. To solve this, we\ndesignate zero to mean fogged, and -1, or 255 in byte storage, to mean unexplored.\nUnfortunately, when an unexplored tile is incremented for the very first time, the\nvalue will wrap to zero, which incorrectly means the tile is fogged. However, we can\ncatch this special case and ensure that an increment that results in zero gets incre-\nmented again. This also provides a convenient place to add code for additional one-\ntime processing on the explored tile, such as adding it to a mini-map, recording its\n",
      "content_length": 2942,
      "extraction_method": "Direct"
    },
    {
      "page_number": 270,
      "chapter": null,
      "content": "3.5 A High-Performance Tile-based Line-of-Sight and Search System \n281\ntype, or searching it for resources. Since most games do not ever revert a tile to unex-\nplored, this special case will not appear in the decrement code. It's worth noting that\nthe storage element size—in this case, a byte—sets an upper limit to the number of\nunits that can see a specific tile at one time, which in this case is 254.\nComponent #2: LOS Templates\nIn most strategy games, a unit's LOS is defined as a circular area around the unit, with\nthe radius measured in the number of tiles. The simplest way to compute this shape,\nwhich many games have done, is to take a radius-sized box of tiles around the unit's\nposition and see if the distance from each tile is less than the unit's LOS radius. How-\never, from a performance standpoint, this is horribly inefficient. Given that this oper-\nation can be called a huge number of times each turn, this function begs for major\noptimization.\nOne of the best ways to optimize this is to precompute the LOS area for each pos-\nsible LOS radius that is used in the game. This shape information can then be stored\nin a template structure with different templates used to represent different LOS radii.\nThe best implementation I have found is to store the LOS area as a series of hor-\nizontal strips, with start, stop, and vertical displacements relative to the unit's posi-\ntion, starting from the top and working down. The templates are processed\nhorizontally under the assumption that elements in that axis of the array are stored\nlinearly in memory, thus minimizing the number of cache accesses during processing.\nFor units at the edges, clipping the LOS template shape to the game map just requires\nclamping the start and stop values in the outer loop. The following code shows a\nfunction to add a unit's LOS template to the visibility count map.\n// This routine \"explores\" the game map in an area around the\n// specified unit position using a line of sight template\n// The template span data is an array of structs with 3 offset elements:\n// {vertical position, horizontal start, horizontal end}\nvoid VisibilityMap::AddLOSTemplate(int XPosition, int YPosition,\nLOSTemplate *template)\n{\nint n, x, y, xStart, xEnd;\n*\nfor (n = 0; n < template->number_of_vertical_lines; n++)\n{\ny = Yposition + template->SpanData[n].Yoffset;\nif (y >= map_y_min_coord && y <= map_y_max_coord)\n{\nxStart = max(XPosition + template->lines[n].XStartOffset,\nmap_x_min_coord);\nxEnd = min(XPosition + template->lines[n].XEndOffset,\nmap_x_max_coord);\nfor (x = xStart; x <= xEnd; x++)\n{\nif ((VisibleMap[y][x]++) == 0)\n",
      "content_length": 2612,
      "extraction_method": "Direct"
    },
    {
      "page_number": 271,
      "chapter": null,
      "content": "282\nSection 3 Artificial Intelligence\nExploreTileForFisrtTimeHandler(x, y);\nVisbleMap[y][x] = 1;\nWhen a player's unit is removed from the game world, the game decrements the\nvisibility count of its LOS area. If none of the player's other units have the tile in their\nLOS, it will be zero, indicating that the tile is no longer visible for the player, and is\nnow fogged.\nWhen a unit moves from one tile to an adjacent tile, which is normally a very\ncommon operation, it removes its LOS from the old position and adds it back in at\nthe new position. Since this pair of function calls will be often made in tandem from\nthe unit's movement code, another optimization is to combine the two operations\ninto a single function. This new function takes both the old and new positions and\nonly updates the portions of the player's visibility map where the increment and the\ndecrement do not overlap. Another situation is when a unit's LOS radius changes. In\nthat case, the remove LOS function is called with the old radius, followed by the add\nLOS function with the new radius. Properly written, the optimized update function\nshould handle this case as well.\nThere are additional advantages to using LOS templates. The first is that differ-\nent shapes can be created for different-sized objects with the same LOS radius. While\na small game unit may occupy a single tile, larger units, such as immobile structures,\nmight occupy several adjacent tiles and possibly even be nonsquare, such as rectangu-\nlar or elliptical. An LOS template that appears centered on a one-tile unit would\nappear off center when used on the larger unit. Figure 3.5.1 shows a set of LOS tem-\nplate shapes for two different-sized objects, both with a radius of three tiles.\nAnother advantage of using templates is that nonsymmetrical LOS shapes can be\nmade. Figure 3.5.2 shows an example of two rotations of a directional searchlight\nTiles occupied\nby a unit\nB:l\nVisible tiles\nFogged or un-\nexplored tiles\nFIGURE 3.5.1 LOS shapes with the same radius for units of different size.\n",
      "content_length": 2044,
      "extraction_method": "Direct"
    },
    {
      "page_number": 272,
      "chapter": null,
      "content": "3.5 A High-Performance Tile-based Line-of-Sight and Search System\n283\nTiles occupied\nby a unit\nVisible tiles\nFogged or un-\nexplored tiles\nFIGURE 3.5.2 Noncircular LOS areas with two rotations of a searchlight pattern.\nshape. With a full set of rotated LOS templates, the searchlight unit could be easily\nanimated to sweep a full circle, producing a cool game effect with very little special-\nized programming.\nComponent #3: The Combined Visibility Map\nSo far, what's been implemented is more efficient, but it doesn't help with some of the\nother goals. This next component, called the combined visibility map, will tie the other\nstructures together. This data structure will be accessed the most by the rest of the\ngame code and will provide a big boost to the searching functions.\nLike the individual player maps, the combined visibility map is a 2D array, sized\nthe same as the tile grid. The difference is that there is only one combined visibility\nmap for the entire game, and its elements are 32-bit DWORDs instead of bytes.\nGiven its usage, it could be a good idea to make this globally available to the program.\nThe purpose of the combined visibility map is to contain all of the up-to-date vis-\nibility information in a single place for all of the players in the game. This is done by\nusing just 2 bits per element for each player. One bit is to indicate that a player has\nexplored the tile, and the other bit is used to indicate if the tile is currently visible to\nthe player. This gives room for 16 players' worth of data in each DWORD.\nThe organization of the individual bits in a combined visibility map element is\nup to the user to implement. This should have no relevance on performance, as all\nupdates should consist of a single binary OR, AND, or XOR operation on the entire\n32-bit element, using mask values precomputed for each player.\nIn practice, the combined visibility map is initialized to all tiles as unexplored and\nfogged. It is then updated when any of the following events occurs for any player:\n",
      "content_length": 2024,
      "extraction_method": "Direct"
    },
    {
      "page_number": 273,
      "chapter": null,
      "content": "284 \nSections Artificial Intelligence\n• A tile is explored for the first time.\n• A tile transitions from unexplored or fogged to visible.\n• A tile transitions from visible to fogged.\nDuring the display of the game world or other structure such as a radar map, each\nplayer has a visibility mask value that contains the explored and visibility bits shifted\ninto the correct position for that player. As each tile location is traversed by the vari-\nous functions, the combined visibility map value for that location is ANDed with the\ncurrent player's visibility mask. The result gives the visibility and explored status of\nthat tile for the specified player, on which the code can then operate.\nThe first benefit of using the combined visibility map is that the player's visibility\nmasks can be combined. This allows for various game effects such as sharing lines-of-\nsight and visibility with teammates, as well as spying on other players. The effects for\neach player can be added or removed at any time by simply updating the player's visi-\nbility mask and refreshing the display.\nImproved Searching\nThe direct approach to searching involves looking at the occupants of each tile in the\nsearching unit's LOS area. As more units are added into the game, the number of\nsearches each turn increases. In addition, as the radius for each search increases, such\nas with ranged units or LOS upgrades, the number of tiles searched rises very quickly.\nFor example, a single ranged attack unit with a search radius of 10 tiles would have an\narea of about 350 tiles to be searched. Therefore, this direct approach results in a per-\nformance drop proportional to the number of tiles scanned.\nProbably the biggest benefit of using the combined visibility map comes with this\ntask of searching in a unit's LOS for enemy targets or other objects of interest. Rather\nthan search the individual tiles, it's better to keep a running list of the other player's\nunits in a given player's total combined LOS. This is where the combined visibility\nmap comes into play. Each unit in the game accesses the combined visibility map\nentry for the tile it occupies. With this data, each unit knows which players can cur-\nrently see that unit. By saving this information from the previous turn, a unit knows\nwhen it moves into and out of the LOS of every other player in the game, even if it is\nnot moving. In addition, when a change occurs, the unit can add or remove itself\nfrom a list of units visible to the other player. The update overhead is only a single\nDWORD check per unit per turn, except for when the unit has actually transitioned\nin or out of another player's combined line-of-sight.\nThe list that the units add and remove themselves from can then be broken down\nfurther depending on what the unit represents to the player (for example, teammate,\ncombat unit, infrastructure, etc.) The result is that each player will have a series of\nvery small lists, often even empty, containing pointers to other players' units that are\ncurrently in the player's total LOS.\nOnce the lists are maintained, there is no longer a need to search large numbers of\ntiles, most of which probably won't contain possible targets. Instead, searching\n",
      "content_length": 3211,
      "extraction_method": "Direct"
    },
    {
      "page_number": 274,
      "chapter": null,
      "content": "3.5 A High-Performance Tile-based Line-of-Sight and Search System \n285\nbecomes a process of scanning a far smaller list that contains only possible targets.\nThe search code can be simplified and the lists will cache better. The performance\nimprovement can be an order of magnitude better, especially in situations that involve\nmany long-range units.\nThe following code shows how a unit's update would process the changes in LOS\nvisibility. This code determines for which players its visibility status has changed, and\nsubsequently how to change them.\nvoid GameUnit: :TurnllpdateProcess( . . .)\n{\n// Game specific unit processing code...\n// Now we check to see if we've gone in or out of anyone's LOS\nDWORD CurrentlyVisibleTo =\nCombinedVisibilityMap[Yposition] [Xposition] ;\nif ( CurrentlyVisibleTo != LastVisibleToValue)\n{\n// Get only the bits that have changed\nDWORD VisibilityChanges = CurrentlyVisibleTo A\nLastVisibleToValue ;\nLastVisibleToValue = CurrentlyVisibleTo; \n// Save new value\nfor (int playerNo = 0; player-No < theGame->numOfPlayers;\nplayerNo++)\n{\nDWORD PlayerMask = 0x0001 « playerNo; // bit mask for\nplayer\n// Check to see if our visibility for this player has\nchanged\nif ((VisibilityChanges & PlayerMask) != 0)\n{\nif ((CurrentlyVisibleTo & PlayerMask) != 0)\nAddUnitToPlayersVisibleList ( playerNo , self ) ;\nelse\nRemoveUnitFromPlayersVisibleList ( playerNo , self ) ;\n// Continue with game processing\n}\nAnother benefit of this method is that the searches will respect the player's total\nvisibility and don't need to be restricted in range to the unit's LOS radius. As illus-\ntrated in Figure 3.5.3, each of the player's units at the bottom performs a target search\nwith a search radius greater than its own LOS radius and finds the enemy units visible\nto the player on the upper-left side. However, they also failed to find the two enemy\nunits in the upper right because they are on tiles that are currently fogged to the\nplayer. By respecting the combined LOS and using a search radius not tied to their\nLOS radius, more intelligent and humanlike AI decisions can be made.\n",
      "content_length": 2090,
      "extraction_method": "Direct"
    },
    {
      "page_number": 275,
      "chapter": null,
      "content": "286\nSection 3 Artificial Intelligence\nVisible tiles\nFogged or un-\nexplored tiles\nTiles occupied\nby a Player's unit\nTiles with player's\n. units searching\nfor enemies\nTiles with enemy\nunits on them\nFigure 3.5.3 Demonstration of which enemy units can be seen by the player. By\nrespecting the total LOS, the searching units will only see the enemy units on the left, even\nthough the units in the FOWare closer.\nThe same processing code can be used for large units that occupy more than one die in\nthe game world. The only difference is that the current visibility value is made by\nORing together the combined visibility map values for each tile occupied, instead of\ntaken from a single tile's value. This also makes it easy to do things like revealing the\nentire map area occupied by the unit, even if the player's LOS only falls on a corner of it.\nMirages are another game capability that the combined visibility map makes easy\nto implement. Mirages are ghost representations of units that appear visually in\nanother player's fogged area, representing what that player last saw when he or she\nexplored the area. Units that can generate mirages do so when they have transitioned\nout of another player's LOS. Also, the mirages know to remove themselves from the\ngame when they detect that they are again fully visible to the other player, by check-\ning the combined visibility map values.\nConclusion\nIt never hurts to rethink a situation, even when it appears simple and straightforward.\nThe development of this approach was the result of asking \"why\" and seeing how\nseemingly unrelated systems could lend each other a hand. The greatly improved\nsearching capability is made possible because of the presence of the combined visibil-\nity map. This only works because the individual player visibility maps are always kept\nup to date, every game tick. Therefore, while the individual systems do their specific\njobs, when joined together, more capabilities are exposed and greater optimizations\nare achievable.\n",
      "content_length": 2002,
      "extraction_method": "Direct"
    },
    {
      "page_number": 276,
      "chapter": null,
      "content": "3.6\nInfluence Mapping\nPaul Tozour\ngehn29@yahoo.com\nW\ne consider a game AI agent to be \"intelligent\" if it consistently makes decisions\nthat we consider appropriate in a given context. Thus, we can say that the core\nof intelligent game AI is decision-making.\nEveryday experience teaches that the key to effective decision-making is not\nmerely having the best data, but presenting the data in the right way. Raw data is use-\nless until converted to contextual information. An appropriate representation of the\ndata will force the relevant underlying patterns to reveal themselves.\nThis and the subsequent gem on strategic assessment present techniques for giv-\ning AI agents a well-informed tactical and strategic perspective on the character of the\ngame world and the current game state. We also discuss techniques relevant to differ-\nent game genres and virtual environments.\nInfluence Maps\nInfluence mapping is an invaluable and proven game AI technique for performing\ntactical assessment. Influence maps have been used most often in strategy games, but\nare also useful for many other types of games that require an aspect of tactical analy-\nsis. The general concepts of influence mapping are an essential part of any AI devel-\noper's toolkit.\nAn influence map is a spatial representation of an AI agent's knowledge about the\nworld. It allows a computer player to develop a tactical perspective of the current\ngame state layered on top of the underlying physical/geographical representation of\nthe game environment. An influence map indicates where a computer player's forces\nare deployed, where the enemy is located or is most likely to be found, where the\n\"frontier\" between players lies, what areas remain to be explored, where significant\nbattles have occurred, and where its enemies are most likely to attack it in the future.\nThe structure of the influence map also makes it possible to make intelligent infer-\nences about the characteristics of different locations in the environment. Influence\nmaps can pick out areas of high strategic control, pinpoint weak spots in an oppo-\nnent's defenses, identify prime \"camping\" locations or strategically vulnerable areas,\nfind choke points on the terrain, and identify other meaningful features that human\nplayers would choose through intuition or practice.\n287\n",
      "content_length": 2313,
      "extraction_method": "Direct"
    },
    {
      "page_number": 277,
      "chapter": null,
      "content": "288\nSection 3 Artificial Intelligence\nThere is no single, standard algorithm for creating influence maps, nor any single\nway to apply the technique. This gem describes several of the more popular influence\nmapping concepts, but it is only a starting point. The way you construct and employ\ninfluence maps will depend heavily on the specific strategic and tactical needs of your\nparticular game and the design of the game world that your AI agents inhabit.\nA Simple Influence Map\nAn influence map can operate in almost any type of game world topography—a\nsquare grid, a hexagonal grid, or a fully 3D environment. For the sake of simplicity,\nmost of this gem assumes a 2D grid, which is applicable to most strategy games. The\nfinal section of this gem discusses applications in more complex environments.\nWe begin with a set of square cells superimposed on our game world. All the cells\nare initialized with a value of zero. For each cell, we add a certain type of \"influence\"\nwe wish to consider. For the sake of this example, we'll compute an estimate for \"com-\nbat effectiveness.\" We'll add a positive value for each friendly unit, and a negative\nvalue for each enemy unit.\nThe specific value we add or subtract will be an estimate of the unit's combat\neffectiveness. For the moment, we'll assume that each unit has an effectiveness rating\nof 1, as shown in Figure 3.6.1.\nThe next step is to spread the influence of each cell to nearby cells. For now, let's\nassume that we propagate each cell's influence such that each time the influence is\nspread to a neighboring cell, it is diminished by 50 percent. Therefore, a value of 4\nwould add two points to each adjacent cell, one point to each cell two squares away,\nthen 1/2, and so on.\nFigure 3.6.2a shows how the influence of our two bugs spreads across the influ-\nence map. The influence of our two opponents—the sinister and nefarious agents of\n-1\n-1\nFIGURE 3.6.1 Initial influences.\n",
      "content_length": 1936,
      "extraction_method": "Direct"
    },
    {
      "page_number": 278,
      "chapter": null,
      "content": "3.6 Influence Mapping\n289\nthe dreaded Ford Motor Company—will propagate in a similar way (not shown), but\ntheir influence values will be negative because we hate them.\nWhen we combine the influences of all the cars and bugs, we end up with Figure\n3.6.2b. It should be immediately clear that this gives us an excellent sense of where\neach player wields influence. Darker cells belong to us; lighter cells belong to our\nopponent. More importantly, we can now trace a contour for the \"frontier\" between\nfriendly and hostile assets. The frontier is defined as any part of the grid where two\nadjacent cells shift between negative and non-negative values. This is shown as an out-\nlined white line in Figure 3.6.2b.\n+0.7\n+1\n+0.7\n+0.35\n+1\n+2^\n*\n+1\n+0.5\n+0.7\n+1\n+0.7\n+0.35\n+0.35\n+0.5\n+0.35\n+0.24\nFIGURE 3.6.2 A) Influence propagation. B) The final influence map.\nWe can use this frontier to determine where to place our forces for offense or\ndefense. By weighting the enemy's forces more heavily than our own (using a multi-\nplier greater than one), we can pull the frontier closer to our own forces for a more\ndefensive posture. If we weight our own forces more heavily, we push the frontier for-\nward and develop toward a more aggressive posture.\nInfluence Map Cell Data\nThe preceding example is clearly trivial. An influence map in a real game is consider-\nably more sophisticated. Rather than simply containing a number, each of the influ-\nence map's \"cells\" is a repository for some amount of data about the game world. Each\ncell is, in effect, a miniature database of relevant data for all the units and resources\nthat occupy that cell. Following are examples of some of the types of statistics that a\ncell will typically contain.\n",
      "content_length": 1729,
      "extraction_method": "Direct"
    },
    {
      "page_number": 279,
      "chapter": null,
      "content": "290 \nSection 3 Artificial Intelligence\n• Combat strength. This is the estimated combat effectiveness of the units cur-\nrently in the cell. This should take into account factors such as attack/defense\nstrength, current health or hit points, attack range, rate of fire, and so on. It may\nalso be advisable to break units into categories in a manner appropriate to the\ndesign of your particular game; for example, to account for the relative strengths\nof ranged versus melee, infantry versus cavalry, or flying versus land-based versus\naquatic units.\n• Vulnerable assets. This is an estimate of the value of a player's current assets in\nthe cell, such as a part of a village or military base in a typical strategy game.\n• Area visibility. This is a number indicating how long the area has been visible or\ninvisible to the player.\n• Body count. Indicates how many units have died in the cell in the past, and\nwhen.\n• Resources. The total resources still available for exploitation—gold, lumber, etc.\n• Passability. An estimate of the difficulty of moving through the cell, possibly\nbroken down by movement type (flying, walking, tracked, etc.) This value is\nused to more accurately propagate a cell's influence to neighboring cells, and can\nfactor into the cell's desirability for a given decision. A good variant is to sepa-\nrately store eight passability values, one for each of the directions exiting the cell.\nAn influence map will typically track these variables for each player in die game\nseparately. Think of this as maintaining multiple parallel influence maps: each player\nupdates an influence map for its own assets, plus an additional influence map to repre-\nsent its own knowledge of every other player. This is useful as it allows you to distin-\nguish the particular strengths and weaknesses of specific opponents, or to blend any set\nof friendly or enemy influences together as desired. Be warned, however, that perfor-\nmance can quickly get out of hand with more than three or four competing AI players.\nOf course, you could also just keep a single influence map for everyone, and let\nevery AI player access it. In a game with any kind of hidden map or fog-of-war\n(FOW), this constitutes \"cheating,\" and it could produce suboptimal behaviors in\nsome situations.\nComputing Desirability Values\nRather than using the basic statistics for each cell directly as a basis for decision-\nmaking, it's more useful to combine them into a \"desirability value.\" This is a com-\nputed value which estimates the cell's \"value\" with regard to a certain decision. By\ncomparing the desirability values of different cells, we can construct a ranking of\nwhich cells appear to be \"better\" for the task than others.\nThe most useful formula for desirability is often a simple weighted sum. Pick the\nvariables from each cell that you consider relevant for the decision at hand, multiply\neach by a coefficient that roughly indicates that factor's relative utility in making the\ndecision, and add the resulting values to determine desirability.\n",
      "content_length": 3030,
      "extraction_method": "Direct"
    },
    {
      "page_number": 280,
      "chapter": null,
      "content": "3.6 Influence Mapping \n291\nThe specific parameters you select to calculate different desirability values will\ndepend strongly on the particular needs of your game and the unique characteristics\nof your game design. The choice of appropriate coefficients is also subjective and is\nbest achieved through careful tweaking and tuning. Simulated annealing or competi-\ntive evolutionary approaches are feasible, but probably not desirable. Be forewarned\nthat you will also need to compensate for the different units of measurement that you\nuse for statistics such as unit health/hit points, rate of fire, attack strength, and so on.\nA short list of sample desirability values follows.\n• Attack and defense desirability. We can typically compute a single \"vulnerabil-\nity\" score to represent defense and attack capabilities for this player and his ene-\nmies, respectively. A high vulnerability score for an enemy means we can damage\nthe assets in that area easily, so we should consider attacking the enemy in that\ncell; a high vulnerability score for this AI player means that we have significant\nassets in the cell that are susceptible to attack, and we should defend them more\ncarefully.\nVulnerable areas are typically those with many assets and key resources but\nminimal opposing military units nearby. Therefore, if an enemy player has a value\nof 80 for \"assets\" in a given cell (representing its base buildings and resources) and\nan enemy offensive value of 60 (representing the enemy forces that could poten-\ntially defend it), the final \"vulnerability\" rating is 20.\n• Exploration. For strategy games that use a hidden map or FOW, a good AI\nplayer will dispatch scouts on a regular basis to refresh its view of the battlefield.\nA good heuristic for exploration is to rank the influence map cells that have gone\nunseen the longest as the most desirable for exploration. Other good factors in\nthis decision are the enemy influence in a cell and the area's estimated passability\n(so your scouts can escape if attacked).\n• Defensive asset placement. Immobile defensive assets should be placed in areas\nclose to lots of vulnerable assets. They should be in areas vulnerable enough to be\nworth defending, but not so vulnerable that they can't be constructed.\nChoke points are also good spots for defensive assets. Terrain choke points can\nbe easily identified on die influence map using precomputed passability values;\nchoke points will be high-passability influence map cells that connect other high-\npassability areas but are surrounded by low-passability cells.\n• Resource-collection asset placement. Assets that serve as resource collection\npoints (Town Centers) are typically most effective in easily defensible areas that\nare as close as possible to the largest amounts of exploitable resources.\n• Unit-producing asset placement. Unit-producing assets (such as a Barracks)\nshould typically be placed in defensible areas closest to enemy forces.\n• Vulnerable asset placement. Assets that need to be protected should be placed in\nthe most defensible areas, and the farthest from potential threats. It's also usually\na good idea to place such assets in less accessible areas to shield them from attack.\nFor flat, rectangular game worlds, it's also often a good idea to consider that map\n",
      "content_length": 3285,
      "extraction_method": "Direct"
    },
    {
      "page_number": 281,
      "chapter": null,
      "content": "292 \nSections Artificial Intelligence\ncorners have fewer avenues of approach and so are often less vulnerable, so you\ncan weight the desirability values higher at the sides and corners of the map.\nDetermining Optimal Cell Size\nThe size of the influence map cells is somewhat arbitrary. It's a trade-off between accu-\nracy and efficiency. With cells that are too large, your influence maps will have a dif-\nficult time identifying small features, such as terrain choke points or weak spots in\nenemy defenses. If the cells are too small, things will get out of hand fast; you'll end\nup doing a lot of redundant computation and possibly using a lot of memory as well.\nIn practice, it's usually best to make the cells fairly large. Avoid the temptation to\nassume that smaller cells will make the AI smarter. For a typical strategy game, I rec-\nommend (as a starting point) making each cell large enough to fit 10—20 of your\ngame's standard \"units\" side by side along the width or height of the cell, and carefully\ntune the cell size from there to obtain the best results in gameplay.\nSome readers may note that the arbitrary positioning of the cells over the map\ncould be problematic. A unit straddling two neighboring influence map cells will have\na different effect depending on which of the two cells receives its influence. This will\nusually not be an issue due to the \"influence propagation\" described in the next sec-\ntion. However, a good way to handle the problem is to modulate the (X, Y) world-\nspace offset of the entire influence map on a regular basis (perhaps each time you\nrecalculate the influence map), using either a random or periodic offset. This is akin\nto a fishing net floating on the ocean that is washed back and forth by the waves.\nInfluence Propagation\nOnce you have calculated an initial value for each cell of the influence map, the next\nstep is to propagate the value of each cell to some number of nearby cells, as in the\nearlier example. This process is also referred to as smoothing or blurring as it has a lot\nin common with standard 2D image blurring techniques (see [EvansOl]).\nInfluence propagation gives us a much more accurate picture of the current tacti-\ncal situation. We don't care only about where units are and what they're doing; we care\nabout what they might do—what areas they potentially \"influence.\" If we have a pair\nof Archers in the field flanked by large battalions of Plasma Tanks on either side, we\nwant our AI to perceive that the area the Archers occupy is really \"owned\" by the\nenemy. We need to propagate the Tanks' influence to the cell the Archers occupy.\nPropagation is just a matter of spreading the influence of each cell to neighboring\ncells using a \"falloff rule\" that determines how the influence of a given cell decreases\nwith distance as it spreads across the map. The selection of a particular falloff rule is\nsubjective and there is no single accepted technique—-as always, you will need to\ntweak and tune for optimal results. I typically find exponential falloff the most useful:\npick a falloff constant between 0 and 1 (typically 0.6 < n < 0.8), and each time you\nspread influence to a neighboring cell, use this constant as a multiplier. Given a falloff\nconstant of 0.75 (=75%), a neighboring cell will have 0.75 = 75% of the original\n",
      "content_length": 3306,
      "extraction_method": "Direct"
    },
    {
      "page_number": 282,
      "chapter": null,
      "content": "3.6 Influence Mapping \n293\nvalue. A cell two squares away will have (0.75)2 ~ 0.56 = 56% of the original value, a\ncell three squares away will have (0.75)3 ~ 0.42 = 42%, and so on. The falloff constant\nshould be proportional to the cell size: smaller influence map cells require a larger\nfalloff value to spread the influence the same distance.\nOther useful falloff rules include linear falloff (in which a cell's influence\ndecreases by a constant value each time it spreads to a neighboring cell) and Gaussian\nfilters (see [EvansOl]).\nNote that if you use floating-point numbers, your propagated influence values\nwill never actually reach zero regardless of how far you spread them. This means that\neach cell will end up spreading its influence to every other cell in the entire influence\nmap. The literature consistently refers to this phenomenon as \"a bad thing.\" The sim-\nplest solution is to terminate propagation at a certain minimum influence value (usu-\nally a value beneath which the smoothed influence would be too tiny to make a\ndifference anyway). This cutoff constant is best determined by experimentation.\nNote, however, that it's usually a good idea to spread a cell's influence a fair dis-\ntance. If your influence map consists of many small cells and the cells' influence is not\npropagated very far, you will likely end up with a lot of empty space (in other words,\na lot of zeroes) in the influence map, and it will be difficult to determine exactly where\nthe frontier lies. Use big cells, and spread their influence a good distance.\nThere is also an interesting alternative influence propagation technique based on\nquadtrees. All cells' values are passed up the quadtree to each higher layer, so higher-\nlevel quadtree cells can be used to obtain approximate \"smoothed\" values for their\nchild cells. Unfortunately, this approach spreads cells' influence in a somewhat arbi-\ntrary fashion. The distance that a cell's influence is propagated is tightly bound to the\nstructure of the quadtree, and influence might be propagated far more in some direc-\ntions than others. I find this technique less flexible and often less accurate than the\npropagation technique described earlier.\nAccounting for Terrain\nThe propagation technique described here does not necessarily paint an accurate pic-\nture in all situations. Imagine that a powerful enemy wizard has a fortress on one side\nof a mountain range. The propagation technique will spread the influence of the\nfortress over the mountains even if the wizard has no way to attack us over the moun-\ntains, and cannot navigate any of his units over or around them.\nThere are several ways to account for the impact of terrain on the influence map.\nProbably the simplest is to use a precomputed passability value for each cell and use\nthis as a multiplier for falloff values, as shown in Figure 3.6.3. Each cell contains\neither a single passability estimate or a set of four or eight passability values in the car-\ndinal directions exiting the cell. We then spread the influence from the cell in a man-\nner similar to a breadth-first search or the flood-fill algorithm. Although Figure 3.6.3\ndoes not show it, this can also handle cells where influence is merely diminished and\nnot blocked entirely.\n",
      "content_length": 3257,
      "extraction_method": "Direct"
    },
    {
      "page_number": 283,
      "chapter": null,
      "content": "294\nSection 3 Artificial Intelligence\nFIGURE 3.6.3 Spreading around terrain.\nA second technique involves precomputing all possible paths between nearby\nneighbors (Figure 3.6.4). For each cell, we perform a pathfinding step during map\npreprocessing that determines the shortest path from that cell to all neighbor cells up\nto a maximum path distance away. We can then store the computed distance to each\ntarget cell and use this as the actual \"distance\" to the neighboring cell when perform-\ning the propagation step. We consider a cell to be unavailable for influence propaga-\ntion if no path exists.\nFIGURE 3.6.4 \nPrecomputedpropagation.\n",
      "content_length": 639,
      "extraction_method": "Direct"
    },
    {
      "page_number": 284,
      "chapter": null,
      "content": "3.6 Influence Mapping \n295\nThe advantage of this technique is that it provides very accurate influence propa-\ngation. If there is an easy way to navigate around the mountain range, such as a pass\nthrough the center of the mountains, the influence map propagation will accurately\nreflect the fact that the mountains are not a significant tactical obstacle.\nUnfortunately, this technique is difficult to apply to dynamic environments. If\nyour game world allows players to build extended walls or to block off mountain\npasses, the precomputed propagation values no longer reflect reality, and it may be\nvery difficult to update your influence map in real time. This method can also poten-\ntially require a lot of preprocessing time, as it requires us to perform pathfinding from\neach cell in the influence map to potentially dozens or hundreds of other cells.\nSpecial Considerations\nTerrain will have different effects on different units. Flying units will not be stopped\nby mountains, and seafaring units will spread their influence over water but not over\nland. Therefore, it's important that each influence map cell track such different unit\ntypes separately (for example, track \"flying\" vs. \"nonflying\" assets in each cell), and\npropagate their values differently according to the terrain type.\nQuite often, certain units will have very long firing ranges, and if a unit can fire a\ncertain distance, then it can also fire that distance from any point to which it can move.\nA good way to account for this is for each influence map cell to separately track ranged-\nfire units according to the distance they can fire (possibly categorized as multiples of\nthe width of an influence map cell). After spreading the influence for these ranged dis-\ntance categories using propagation, we then spread the influence an extra TV cells from\neach influenced cell without diminishing the value. This way, we can account for a bat-\ntleship's ability to strike far into the shore, even though it can't go on land.\nYou may also find it useful to add mobile units to the map based on their pro-\njected future positions rather than their current positions. This makes the influence\nmap a bit more accurate, particularly if you don't recalculate the influence map very\noften. The simplest approach is dead reckoning—estimate each unit's position per-\nhaps 5—10 seconds from now based on its velocity vector. Since you're presumably\nwriting the AI, you might also simply look up each unit's future position if the unit is\nperforming pathfinding (although of course this may constitute cheating if an AI\nplayer looks at other players' chosen routes).\nRefreshing the Influence Map\nIf your AI needs to analyze large portions of the influence map on a regular basis, it\nmay make sense to recompute the entire influence map on a regular basis, perhaps\nevery 1-10 seconds. Considering the pace of a typical strategy game, a faster refresh\nrate will probably not produce a more effective AI. Once the influence map is com-\nputed, you can then use it to perform many calculations extremely quickly.\nA second approach is demand-based refreshing, a sort of lazy evaluation technique.\nThis is a more flexible approach, and is more efficient when you need to perform less\n",
      "content_length": 3240,
      "extraction_method": "Direct"
    },
    {
      "page_number": 285,
      "chapter": null,
      "content": "296 \nSection 3 Artificial Intelligence\nextensive influence map analysis. With this variant, you compute the values in a given\ncell only when the cell is actually queried, searching all the neighboring cells within a\ngiven maximum distance to see how their values propagate back to the original cell.\nThis technique has the added advantage that you can specify the propagation parame-\nters and desirability value coefficients at query time.\nInfluence Maps in 3D Environments\nThis gem has focused thus far on applications in 2D environments. However, influ-\nence mapping and related approaches are also broadly applicable to more complex\nenvironments such as the 3D environments of typical action games.\nUsing a 2D grid for 3D influence mapping is usually a bad idea, as it will not\naccurately reflect the topography of our game environment. Fortunately, AI pathfmd-\ning in 3D environments is usually (though, alas, not always!) based on a navigation\nmesh approach (see [SnookOO]). A navigation mesh consists of a graph of intercon-\nnected convex polygons that describe where characters can move in the game world.\nWe can use each polygon of the navigation mesh as an influence map cell. The links\nbetween polygons can describe the avenues for influence propagation. Influence\ndecreases according to the length \"traveled\" along each mesh node.\nBecause 3D game worlds are more topographically complex than 2D worlds and\nthe emphasis is usually on individual combatants, terrain assessment is typically more\nimportant than the real-time player-versus-player tactical assessment that an influence\nmap can provide. It's critical that our AI agents can pick out the tactical significance of\ndifferent areas. The following list explains some of these tactical assessment factors.\n• Vulnerability (\"cover\"). 3D action games typically involve firing powerful\nweapons over large distances, so it's critical to take into account the range of pos-\nsible fire locations to and from each cell of the influence map. AI agents often\nneed to determine the degree of \"cover\" in a given cell. A simple approach is to\ncalculate an estimate for the degree of cover for each of the six faces of a cube pro-\njected from each influence map node.\nHowever, we often want to know whether a given cell (potential destination)\ncan shoot or be shot from another cell (enemy position). A good line-of-fire rep-\nresentation would list the set of nodes that are \"attackable\" from any given\nnode—but this could quickly get out of hand for large and highly interconnected\nenvironments that approach an N2 degree of interconnectivity. A good solution is\nto package groups, of influence map nodes into \"zones,\" such that all nodes in a\ngiven zone are in the same \"room\" or \"portal,\" and use this representation to\ndetermine which zones are potentially vulnerable from other zones.\n• Visibility. This is similar to vulnerability, except that it disregards weapon dis-\ntances, takes illumination levels into account, and can pass through certain sur-\nfaces that weapons fire cannot, such as reinforced glass. This calculation becomes\ntricky when dynamic lighting is used, and lights can be turned on and off.\n",
      "content_length": 3169,
      "extraction_method": "Direct"
    },
    {
      "page_number": 286,
      "chapter": null,
      "content": "3.6 Influence Mapping \n297\n• Passability. As before, this is an estimate of the difficulty of moving through an\narea. Tight passages are usually more difficult to move through, and elevators, lad-\nders, and odier such routes cause slow movement and thus have low passability.\n• Height advantage. Locations with a high elevation relative to surrounding loca-\ntions are usually tactically superior for both offense and defense, particularly if\nthe game features hand grenades.\nThese are the basic precalculated statistics in our influence map cells. We can now\nwhip out a few coefficients and compute desirability values.\nThe best locations for offense are typically those with high passability, high cover,\nand low visibility, but which also have a good line-of-fire to many areas of high visi-\nbility (and, ideally, low passability). Good offensive locations also usually have good\ncover locations nearby in case the agent comes under fire.\nThe best defensive locations are those with the highest cover and lowest visibility,\nand for which all the potential attacking locations have high visibility.\nMore to the point, if we precalculate these desirability values for all the nodes, we\nthen can propagate these values to their neighbors using our standard influence map-\nping techniques and end up with a complete tactical assessment of the level.\nFinally, note that we can also use the influence map to make inferences about our\nopponents—we can determine their respective levels of cover, visibility, passability,\nand height advantage. We can use this to select the best opponent to attack at any\ngiven moment, or to search for a destination that has an advantage over any or all of\nour opponents.\nAnother useful extension is to estimate opponents' most likely positions in the\nnear future by finding the most desirable destinations available to them. This will\nallow us to prepare for our enemies' actions, and have the ambush already prepared.\nReferences and Additional Reading\n[comp.ai.games95] The seminal 1995 \"influence mapping\" thread on comp.ai.games\n(various authors) is reprinted at www.gameai.com/influ.thread.html.\n[EvansOl] Evans, Alex. \"Four Tricks for Fast Blurring in Software and Hardware,\"\navailable online at www.gamasutra.com/features/20010209/evans_01.htm.\n[PottingerOO] Pottinger, Dave. \"Terrain Analysis in Realtime Strategy Games,\" avail-\nable online at www.gdconf.com/archives/proceedings/2000/pottinger.doc.\n[SnookOO] Snook, Greg. \"Simplified 3D Movement and Pathfinding Using Naviga-\ntion Meshes\" from Game Programming Gems I (Ed. Mark DeLoura, Charles River\nMedia, 2000).\n[SterrenOl] van der Sterren, William. \"Terrain Reasoning for 3D Action Games.\"\n[Zobrist69] Zobrist, Albert L. \"A Model of Visual Organization for the Game of Go.\"\nThe seminal article on influence mapping. Proc. AFIPS 1969 Spring Joint Com-\nputer Conf. 34: pp. 103-112.\n",
      "content_length": 2871,
      "extraction_method": "Direct"
    },
    {
      "page_number": 287,
      "chapter": null,
      "content": "3.7\nStrategic Assessment\nTechniques\nPaul Tozour\ngehn29@yahoo.com\nT\nhis gem describes a suite of useful techniques for strategic decision-making.\nWhere the previous gem on influence mapping provided a means for tactical\nassessment on a geographical level, these data structures provide an AI agent or player\nwith a means of assessing the current game state on a strategic and functional level.\nThese techniques are most clearly applicable to games that involve some aspect of\neconomic management, resource-allocation decisions, and/or technological advance-\nment, such as strategy games, economic simulations, and \"god games.\" However,\nthere are doubtless many potential applications to other genres as well.\nThe Resource Allocation Tree\nThe resource allocation tree is a tree structure that represents the specific functional\npurpose of all the assets under a player's control. The tree breaks down all of the units\nand resources currently in play into a hierarchy of functional categories.\nThe usefulness of this representation derives from its ability to allow an AI player\nto evaluate the strategic strengths and weaknesses of all of the players in the game,\nitself included. The tree also provides an excellent basis for a wide variety of economic\nproduction and resource-allocation decisions. For example, it provides an immediate\nbasis for determining what types of new units to produce and how to reallocate exist-\ning units into different functional roles.\nAt the top of the tree is a root node that represents a player's total assets. Directly\nbeneath the root is a breakdown of the major different categories of assets available in\nthe game.\nLet's imagine we break this down into Military, Economic, and Intelligence. Each\nof these is broken down further into subcategories. Military might be broken down\ninto Offense and Defense, for example, and each of these could be broken down into\nBallistic, Ranged, and Melee to indicate different functional roles for military units.\nEconomic would likely be broken down into Resource Gathering, Unit Production,\nBase Construction, Tech Advancement, and so on down the tree. Figure 3.7.1 illus-\ntrates a small slice of the resource allocation tree.\n298\n",
      "content_length": 2205,
      "extraction_method": "Direct"
    },
    {
      "page_number": 288,
      "chapter": null,
      "content": "3.7 Strategic Assessment Techniques\n299\n(...) \n(...)\n(...)\nFIGURE 3.7.1 The resource allocation tree.\nThe leaves of the tree are the specific types of units available. For example, \"Pike-\nmen\" sits in Root/Military/Offense/Melee/Pikemen. The Pikemen node itself would\nlikely include various statistics on all the Pikemen we've dedicated to an offensive\ncapacity, such as the total quantity, total hit points, total number of Pikemen killed in\ncombat, and so on.\nJust as with an influence map, an AI player should maintain a separate instance of\nthis data structure for each player in the game, including itself. The graphs for the\n",
      "content_length": 631,
      "extraction_method": "Direct"
    },
    {
      "page_number": 289,
      "chapter": null,
      "content": "300 \nSection 3 Artificial Intelligence\nother players will represent this player's current knowledge and best estimates of the\nfunctional breakdown of each player's current strategic assets.\nA Pikeman is primarily a defensive unit, but it could also be used for attack or\nexploration. This raises the question of how to categorize a single species of unit that\ncan participate in multiple functional roles.\nAn AI player will typically dedicate a given unit to only one functional role at any\ngiven moment, so I recommend categorizing units in terms of their current functional\nemployment rather than attempting to split a single Pikeman into, say, 10% Explo-\nration, 60% Defense, and 30% Offense. The Pikeman nodes beneath Offense,\nDefense, and Exploration should represent the Pikemen that are currently allocated to\neach of those functional roles.\nIt's also important to note that at any given moment, the resource allocation tree\ncontains only those assets that I actually possess or am currently capable of producing.\nIf I have no Mage Towers and can't currently build one, there is no reason to include\nit as a node in the tree.\nCalculating Desired Allocation\nThe structure of the resource allocation tree provides us with a very simple and nat-\nural means for determining appropriate resource allocation. We can rank the intended\npriority of each node in the tree by proceeding down the graph from the root.\nBegin with a value of 1.0 at the root, indicating a desired 100% resource alloca-\ntion. At each node, we split the current value into an appropriate fraction of the\ndesired allocation for each child node. Starting from 1.0, we break this value down\ninto Military = 0.3, Intelligence = 0.1, and Economic = 0.6. Under \"Military,\" we\nbreak this 0.3 down further into 67% Defense and 33% Offense (Defense = 0.2 and\nOffense = 0.1). This process continues down the tree so that we calculate a \"desired\nallocation\" value for each tree node.\nThe algorithm for determining the numeric breakdown at each node will depend\non the design of your game. Each nonleaf node will require custom logic code to con-\ntinuously update the distribution to its child nodes in response to the evolving state of\nthe game world. This is a matter of tweaking and tuning to achieve optimal results.\nInitially it's often a good idea to simply take a few guesses and use predetermined con-\nstants until you get a good sense of what specific factors should cause the computer\nplayer to change these weights as a given game session unfolds.\nDetermining Current Allocation\n«m:::.:~: \n:::-::-:-::--::™::::'::~:^:^:::-:~;::-::Tr::\":::v::\":-::'::\":::^::-:--:':^^\nSimultaneously, we can use the tree to calculate a \"current allocation\" value for each\nnode. This gives us a breakdown of the assets we actually possess.\nThis calculation proceeds in the opposite direction, from the bottom of the tree\nup to the root. We iterate over all the Pikemen currently allocated to Defense, for\nexample, and calculate some value indicating every defensive Pikeman's estimated\n",
      "content_length": 3039,
      "extraction_method": "Direct"
    },
    {
      "page_number": 290,
      "chapter": null,
      "content": "3.7 Strategic Assessment Techniques \n301\nvalue (say, by multiplying an attack strength value for Pikemen by that specific Pike-\nman's current hit points). We then add all these Pikemen's scores together and mark\nthis as the current allocation value of the Pikeman node beneath Defense/Melee. We\nthen pass this number up to the parent node (Melee), which adds together all of\nthe numbers it receives from its children (such as all the Spearmen and Footmen we've\nallocated to Defense) and forwards this number up to its parent (in this case,\nDefense). Ultimately, the root node receives input from all of its children, and we end\nup with a fat floating-point number at the root that indicates the total current assets\nof all our possessions in the game world.\nOnce we've generated this value for \"total assets,\" we can renormalize to values\nbetween 0 and 1. Revisit each node in the tree and divide its \"current allocation\" value\nby the root node's value, so that the root node again has a value of 1.0.\nAt this point, it should be obvious that we can directly compare the current allo-\ncation value in each tree node to the desired allocation value to trivially determine how\nfar we are over or under budget in any particular capacity.\nStrategic Decision-Making\nIt should be apparent that the final allocation tree representation instantly provides us\nwith an excellent way of organically maintaining the balance of our forces. If I'm in a\nbattle and I lose all 20 of my Elephants, the Elephant node and all its parent nodes are\nnow under-allocated relative to their desired allocation.\nOf course, this won't necessarily mean that I replace all my Elephants with new\nElephants. As the parent node of Elephant receives the resources it needs to fill in new\nchild nodes, it may decide that the best course of action is to build a battalion of\nPlasma Tanks now that it's uncovered the requisite technologies.\nThe resource allocation tree is useful primarily for deciding which new units to\nconstruct and how to allocate existing units to the most appropriate roles. The first\npriority is usually to find those nodes that are most desperately in need of additional\nallocation, and then determine whether this is more appropriately addressed by real-\nlocating existing units or by creating new ones.\nThe resource allocation tree also gives us a good way to design unique player per-\nsonalities. Developing an expansionist, military-oriented \"Genghis Khan,\" an eco-\nnomically obsessive capitalist, or a research-oriented technocrat is just a matter of\ntweaking the coefficients for the appropriate parts of the tree to favor or disfavor spe-\ncific nodes. With a little tweaking at different parts of the tree, AI players can be made\nto favor individual species of units, different balances of growth versus defense, spe-\ncific strategic categories of assets, or overall play styles.\nWhere combat is concerned, it's often a good idea to keep a precomputed \"com-\nbat balancing table\" of relative unit strengths, and use this for making decisions under\nthe Military branch of the tree. This is essentially a 2D lookup table that allows you\nto determine the general effectiveness of any unit in combat against any other. By ana-\n",
      "content_length": 3218,
      "extraction_method": "Direct"
    },
    {
      "page_number": 291,
      "chapter": null,
      "content": "302 \nSections Artificial Intelligence\nlyzing the functional asset tree that represents your knowledge of a particular enemy,\nyou can determine the composition of his forces and emphasize the production of the\nassets that will be most effective against them.\nFinally, the resource allocation tree is an excellent place to store all types of addi-\ntional statistics. Several of the factors we would typically track in an influence map\ncell are also appropriate to a functional asset tree node.\nIt's also often a good idea to track which nodes in the tree have proven effective in\nthe past, and which nodes have been attacked by enemy players. In die former case, it\nwould allow me to detect that my Pikemen have served me well against another\nplayer, and to use this to direct my growth and development toward the functional\nroles that made my Pikemen victorious. In the latter case, it will allow me to detect\nthat my enemy has a proclivity for attacking my resource-gathering units (for exam-\nple), and to take additional steps to protect them in the future.\nMeasuring Value\nProbably the most significant challenge with this technique is finding an appropriate\nway to measure each unit's value in its particular branch of the tree. The numeric\nunits used in each node need to be commensurate with all other units' values in their\nrespective branches. Values under the Military branch should represent units' contri-\nbutions in combat, and should take into account attack strength, rate of fire, move-\nment speed, armor value, current hit points, and any other appropriate parameters.\nValues in the Intelligence branch should take into account factors appropriate for\neach unit's exploration ability, such as visibility range and movement speed, but prob-\nably not attack strength or hit points. Nodes in Resource Collection (under Eco-\nnomic) should take into account how quickly each resource-gatherer can collect\nresources, drop them off at the depot, and get back to the resources again. Finding an\nappropriate way to correlate these values is, like so much else in game AI, a matter of\nexperimentation to find the optimal solution for your particular game.\nAnother potential challenge is handling economic systems with multiple resources.\nIn games where different units cost different amounts of, say, gold, energy, and\ntiberium to produce, a single allocation value does not translate directly into a single\nresource. The potential solutions to this problem are beyond the scope of this gem.\nThe Dependency Graph\nThe dependency graph is a data structure that models all the dependencies between the\ndifferent types of assets in the game. The dependency graph encompasses all depen-\ndency-based relationships, such as a game's \"tech tree\" and \"building tree.\"\nThe primary dependency type is a creational dependency. This indicates some\nnumber of conditions that must exist before a given species of asset can be con-\nstructed. For example, you must possess a Barracks before you can build a Pikeman.\nYou must construct a Castle before you can reach the Imperial Age.\n",
      "content_length": 3071,
      "extraction_method": "Direct"
    },
    {
      "page_number": 292,
      "chapter": null,
      "content": "3.7 Strategic Assessment Techniques\n303\nFIGURE 3.7.2 The dependency graph.\nCreational dependencies can also include resource dependencies and other, more\nabstract dependencies. A Barracks requires gold and lumber. Gold and lumber come\nfrom the labors of peasants. Peasants get the gold from a gold mine and lumber from\nthe forest.\nFigure 3.7.2 shows a tiny sample dependency graph comprised solely of cre-\national dependencies. A peasant can create Barracks and Archery Ranges, but the\nArchery Range can only be constructed after reaching the Medieval Age.\nThe second type of dependency is a support dependency. A Mage unit might\nrequire mana, which can only be generated by a Shrine. Without a shrine, the Mage\nwill be essentially useless, as he cannot cast spells without a Shrine to feed him his pre-\ncious mana.\nAs with the previously discussed data structures, an AI player should maintain\nseveral parallel dependency graphs, one for itself and one for each of the other players.\nDependency Graph Nodes\nA given node in a dependency graph will typically contain several different types of\ndata. Useful categories include the total number of units of that type that the player\ncurrently possesses (or is believed to possess, if we are looking at another player); the\ntotal estimated value of those units; and the number of those assets currently in pro-\nduction (being created by a Barracks, for example). Given the overlap between their\n",
      "content_length": 1441,
      "extraction_method": "Direct"
    },
    {
      "page_number": 293,
      "chapter": null,
      "content": "304 \nSections Artificial Intelligence\nconcerns, it may be possible for a \"node\" in the dependency graph to be similar to a\n\"node\" in the functional asset tree, or even be the same physical data structure. The\nmain difference between the two is that the resource allocation tree tracks only the\ncurrently available assets, while the dependency graph tracks all possible assets.\nEconomic Planning\nThe first and most obvious use for a dependency graph is building toward a goal. A\ncomputer player can use the dependency graph to determine what it needs to build in\norder to be able to produce a given asset. \"I know I want to build a Wizards' Tower\neventually, so to get there, I need to build a Library, and then secure a suitable source\nof mana, and then start building a Mage Hall\nThe choice of which dependencies to fill in first is a trade-off between reacting to\nthe present and planning for the future. A purely reactive AI will use the resource allo-\ncation tree to rank all the assets it can potentially create immediately and pick the best\navailable node. A more planning-oriented AI will analyze all the nodes in the graph to\nfind a long-term goal worth pursuing, query the functional asset tree to determine\nwhich dependencies are likely to be the most valuable, and build toward the most\npromising technology, however deep in the graph it may be.\nNote that this process becomes tricky when there are several possible ways to ful-\nfill a dependency—when either A or B will allow C. This seldom happens in practice,\nas game designers wisely avoid these types of dependencies. In a situation in which\nthere are so many optional dependencies that the best route to a given node isn't obvi-\nous, any standard search algorithm should solve the problem quickly.\nFinding Vulnerable Dependencies\nA dependency graph can be used to analyze strengths and weaknesses in a player's\nforces, and to pinpoint its opponents' most vulnerable dependencies. In Red Alert 2,\nthe enemy AI will usually destroy my Barracks after taking out my War Factory. This\nis a clever and potentially devastating strategy as it forces me to spend precious time\nand money rebuilding the Barracks before I can consider rebuilding my War Factory.\nThere are three factors that generally determine whether a given node in the\ndependency graph is \"vulnerable.\"\n• Intrinsic value. Some assets are valuable of their own accord. A Nuclear Silo is\nvaluable because it can attack the enemy directly. Assets deeper in the graph (far-\nther along in the tech tree) usually have much higher intrinsic values.\n• Strong child dependencies. Some assets are worth targeting because of what\nthey can create or support. A War Factory can create tanks and other vehicles. A\nLibrary allows me to create the Mage Hall, which will eventually lead to Mages. A\nFusion Plant supplies lots of electricity to a player's base (a support dependency).\n• Weak parent dependencies. We can also eat away at parent dependencies, as\nwith the Barracks destroyed after the War Factory. Graph nodes whose parents are\n",
      "content_length": 3050,
      "extraction_method": "Direct"
    },
    {
      "page_number": 294,
      "chapter": null,
      "content": "3.7 Strategic Assessment Techniques \n305\nrelatively weak (few instances of each supporting asset) and easy to attack (poorly\ndefended) are more vulnerable to this type of attack.\nWe can use the same heuristic for both attack and defense. For attack, we often\nwant to select the most valuable opposing player dependencies, and go after the War\nFactory first and the Barracks second. In defense, we use the graph to prepare for that\nexact possibility—we increase our defense and build duplicate buildings as backup.\nStrategic Inference\nOne subtle advantage of the dependency graph is that it provides a basis for making\ninferences about other players' current assets and likely strategies based on incomplete\nobservations. For example, if I know my enemy has a Barracks, I can be confident that\nhe either has Pikemen already or is capable of creating them in the near future. Simi-\nlarly, if I see an enemy Pikeman, I can be 100-percent certain that he has a Barracks\nsomewhere about (or at least, that he did when Pikeman unit was created—there's\nalways the chance that the Barracks was destroyed after he created the Pikeman).\nInference works in two directions: forward and backward.\nWith forward inference, we know that the player in question possesses a given\nunit or resource, and we can project the likelihood that he will then fill in the child\ndependency. Each Barracks we observe makes the existence of Pikemen more likely.\nWith backward inference, we go back up the chain and assert that a given unit\nmakes its dependencies nearly certain. Seeing a Pikeman makes us very confident of a\nBarracks, even if we've never observed it directly.\nThis kind of dependency-based inference can go a long way. If I see an enemy\nGrand Mage, I can assume there's a high probability that he also has a Mages'\nArcanum building, High Magic upgrade, a Wizards' Tower, a Sages' Guild, a Library,\nand all the other dependencies leading up to the Grand Mage unit. Furthermore, I\ncan then turn around and use forward inference on each of these nodes with their new\nprobabilities. Since the Grand Mage allowed me to infer the existence of a Sages'\nGuild, I can assume that the player is probably capable of producing a Sage.\nThis process is a form of probabilistic inference and is broadly similar to a popu-\nlar inference technique known as a \"Bayes network\" [see the References for details].\nInterestingly, it's also possible to use inference to make certain nodes less probable.\nIf we set an upper bound on the maximum possible size of a player's economy at a\ngiven point during the game—either on account of the amount of time he's had avail-\nable to build up, or by reasoning based on inferences using data from the influence\nmap—then certain dependencies make others less likely. Four minutes into the game,\nI know that the best player can build a Red Dragon Roost or a Nuclear Silo, but not\nboth. Therefore, the presence of either makes the other less likely.\nOf course, this is all a lot of work, and you can just as easily cheat and look at the\nother players' assets directly. As always, I leave this decision to your conscience and\nyour opinion of how this decision would affect the entertainment value of your\ngame.\n",
      "content_length": 3211,
      "extraction_method": "Direct"
    },
    {
      "page_number": 295,
      "chapter": null,
      "content": "306 \nSections Artificial Intelligence\nPlayer Personality\nAs with the functional asset tree, we can use the dependency graph to give AI players\ndistinct personalities.\nThe vulnerability values for the various nodes in the dependency graph are a\nprime candidate for tweaking. By exaggerating or deflating the vulnerability values for\ndifferent nodes, we cause our AI players to deflate or overvalue the significance of\nthose assets. If we tweak the values on the dependency graphs we maintain for oppos-\ning players, we change the likelihood diat we will target certain enemy assets rather\nthan others. If we tweak the values on our dependency graph of our own assets, we\nchange the way our economy develops and the specific technologies we embrace.\nOne simple technique for setting initial priorities is to pick a set of ultimate\n\"goals\" for a given AI player. Look at all the rightmost (deepest) nodes in the graph,\nfind a suitable algorithm to rank these final dependencies by desirability, and come up\nwith good final desirability values. You can then propagate these desirability values\nback toward the left side of the graph, and this will give the AI player a very clear indi-\ncation of which technologies it should generally favor.\nPutting It All Together\nMost of AI is decision-making, and a good representation of the game state can make\nan AI player's decisions vastly easier to make.\nThis gem and the previous one have described data structure foundations for this\ntype of decision-making. Although not every game will be able to use all of these data\nstructures, there are endless opportunities for intercommunication between whichever\nof these data structures you use for shared strategic and tactical decision-making.\nWhen the Influence Map, die Resource Allocation Tree, and the Dependency Graph\ncommunicate and share their data, we end up with a whole diat is more than die sum\nof its parts. The Influence Map tells you where the enemy is, die Resource Allocation\nTree tells you what you need to hit him with, and the Dependency Graph tells you\nhow to build it and how to keep it full of gas once you're up and rolling.\nReferences and Additional Reading\n[Ferber99] Ferber, Jacques, Multi-Agent Systems, Addison-Wesley, London, England,\n1999. A useful perspective is to consider the cells/nodes of the data structures\ndescribed here as hierarchical \"agents\" in a multi-agent system.\n[PearlSS] Pearl, Judea, Probabilistic Reasoning in Intelligent Systems: Networks of Plau-\nsible Influence, Morgan Kaufman, San Francisco, CA, 1988. A must-read intro-\nduction to Bayes nets and probabilistic reasoning systems as they relate to AI.\n[Russell95] Russell, Stuart and Norvig, Peter, Artificial Intelligence: A Modern\nApproach, Prentice Hall, Upper Saddle River, NJ, 1995. A comprehensive intro-\nduction to AI techniques—trie \"AI bible.\"\n",
      "content_length": 2845,
      "extraction_method": "Direct"
    },
    {
      "page_number": 296,
      "chapter": null,
      "content": "3.8\nTerrain Reasoning for 3D\nAction Games\nWilliam van der Sterren, CGF-AI\nwilliam@cgf-ai.com\nft I \nocation! Location! Location!\" This decree not only holds for real estate, but\n^•i also for the virtual worlds in 3D action games. There, locations play a key role\nas sniper spots, strongholds, avenues of attack, bottlenecks, or \"red armor\" power-up\nareas. When locations are important in a game, they had better be important in the\ngame AI as well.\nThis gem presents a technique for reasoning about locations and their role in the\ngame. It shows how to translate location concepts to algorithms, so that the AI can\ncompute and grasp these concepts. This helps the AI in picking good locations for its\nactions and in understanding the positions that other actors occupy. It literally puts\nthe AI in a better position to assist or challenge the player.\nFirst, we pick a terrain representation that the AI can handle efficiently: waypoint\ngraphs. To illustrate waypoint-based reasoning, an example problem is introduced.\nThen, we identify tactical attributes and relate them to waypoint properties. We con-\nstruct formulas to compute these waypoint properties, using static data such as the\nworld geometry, and dynamic data such as actor activity. Finally, we discuss how to\nintegrate terrain reasoning in our game and we look at various other applications of\nwaypoint-based terrain reasoning.\nRepresenting Terrain to Reason About It\nReasoning about locations would be easy if there were only a few locations. However,\ntoday's game worlds feature tens of thousands of accessible polygons. In a game, mul-\ntiple AI actors take into account both visible and invisible locations. If this were done\nin terms of raw polygons, that effort would probably consume more resources than\nthe 3D graphics rendering.\nTo complicate matters further, the value of a location isn't so much determined by\nits own characteristics as it is its relationship with the surrounding locations. For exam-\nple, is it easy to access the location? Is die location observable by many odier locations?\nAre there any power-ups nearby? In addition, actual gameplay matters a lot: some loca-\ntions (for example, near an objective) are frequendy visited, whereas other areas are not.\n307\n",
      "content_length": 2248,
      "extraction_method": "Direct"
    },
    {
      "page_number": 297,
      "chapter": null,
      "content": "308 \nSection 3 Artificial Intelligence\nThus, to reason effectively and efficiently about terrain, we had better pick a rep-\nresentation that approximates the terrain using far less detail than the raw polygonal\ngeometry. That representation should express relations between locations easily, and\nsupport capturing of location-based game activity. Ideally, the representation allows\nus to use precomputed intermediate results, leaving us some CPU time for more\nadvanced AI or a faster game.\nWaypoints\nMost 3D game AIs already have a terrain representation that is easy to handle. They\nuse waypoints, or similar navigation aids such as grids, or cells (see [SnookeOO],\n[RabinOO], [ReeceOO]). These waypoints represent the most relevant part of the ter-\nrain: the terrain that is accessible to the game actors. Each waypoint is a sample, an\napproximation, of its immediate surroundings. The number of waypoints is typically\nin the order of 250 to 2500.\nReasoning in terms of waypoints is attractive because many game AIs already use\nthese waypoints to move around, to find paths, to mark the presence of special items\nand obstacles, and to receive hints from the level designer. Because the AI performs\nmany of its actions with waypoints in mind, and because it thinks of players as being\nnear waypoints, capturing gameplay data per waypoint is easy and almost free.\nBefore we start reasoning about the waypoint-based terrain representation, that\nrepresentation needs to approximate the terrain and relevant properties well enough.\nThe network of waypoints should be sufficiently dense to represent all relevant loca-\ntions as well as any cover and concealment present. Typically, that means a larger\nnumber of waypoints than required for AI navigation and pathfinding.\nTerrain reasoning often deals with other inter-waypoint relations than shortest\npath and movement. The need for these additional relations and the reasoning about\nwaypoints are best illustrated using an example.\nExample Terrain and AI Needs\nTo illustrate waypoint-based terrain reasoning, let's look at the following example: in\nthe area depicted in Figure 3.8.1, we want our AI actors to pick solid offensive and\ndefensive tactical positions, both before and during a fight.\nTo support the AI in efficiently picking and visiting strong positions, we compute\nfor each waypoint and for a number of directions, the offensive and defensive value of\nthat waypoint. This value is computed using the waypoint graph and world geometry\nand improved with captured gameplay \"experience.\" Such a \"tactical\"' understanding\nof each waypoint can be input for pathfinding, for flocking, to pick guard positions\noverlooking an objective, and so forth.\nThe example area features one objective and two entrances, and is populated by a\ndense grid of waypoints. Note that just the waypoints themselves (in Figure 3.8.1 cen-\nter) already give you a good clue of the level's architecture.\n",
      "content_length": 2934,
      "extraction_method": "Direct"
    },
    {
      "page_number": 298,
      "chapter": null,
      "content": "3.8 Terrain Reasoning for 3D Action Games\n309\ndistribution of waypoint\nw's line-of-sight relation\nx' 4;\nsectors being used to\naggregrate relations\nFIGURE 3.8.1 (left) A top view of the example terrain, featuring two entrances!exits, and\none objective o. The terrain is covered by a good number ofwaypoints, including\nwaypoint w. (center) The waypoints in the example terrain, and the valid lines of sight\nfrom waypoint w to other waypoints. (right) The distribution of lines of sight from w,\nand the proposed sectors to aggregate them.\nTactical Analysis\nIn assessing the tactical value of a location, many factors need to be considered. A\nlarge number of these factors can be translated to properties of a waypoint, which in\nturn can be computed. Let's consider the example area from both a Quake-style\ncapture-the-flag game and from a tactical simulation perspective.\nIn a fast capture-the-flag game, characterized by rapid movement, power-ups,\nnonlethal weapons, and rocket launchers, the tactical value of a location is largely\ndetermined by the following characteristics:\n• Locations that provide for fast movement and freedom to move in any direction\nare essential for attackers.\n• Locations near power-ups are valuable.\n• Locations susceptible to rocket blasts aren't that attractive.\n• Locations overlooking the path to the flag while being hard to spot when rushing\nto the flag make for good defensive positions.\nIn a tactical simulation, characterized by lethal weapons, slow movement, cover,\nstealth, and sniping, other characteristics become key.\n• Nearby cover is important for offensive and defensive actions. Even partial cover\nor reduced visibility at a location can be a serious advantage.\n",
      "content_length": 1706,
      "extraction_method": "Direct"
    },
    {
      "page_number": 299,
      "chapter": null,
      "content": "310\nSection 3 Artificial Intelligence\n• Locations where movement is slow or predictable (near the entrance, for exam-\nple) make for bad offensive spots, whereas the locations overlooking them\nbecome more attractive for defense.\n• As within the capture-the-flag game, locations that overlook the objective, and\nlocations overlooking the main paths to and from the objective are important as\nwell.\nFrom Tactical Values to Waypoint Properties\nNow that we have identified a number of tactical characteristics that largely determine\nthe offensive and defensive values of a location, we need to turn them into an evalua-\ntion function and output.\nFirst, we look at the waypoint properties that we can use to express tactical char-\nacteristics. Figure 3.8.2 illustrates the different types of waypoint properties available.\nA waypoint has properties that are local, such as the light level and the presence of\na power-up or door. Another category of properties is determined by the waypoints'\nmembership in a larger terrain representation (typically a group of waypoints). For\nexample, the waypoint may be part of a room, a street, or a roof. Note that both the\nlocal properties and the group membership properties are nondirectional.\nThe relations between waypoints, however, are directional. For example, way-\npoint w (in Figure 3.8.1) can see almost all waypoints to its east, and it will be hard to\napproach waypoint w from the east without being observed. In a 3D world, height\ndifferences often cause a waypoint to be easily accessed from one direction, and much\nharder (read: taking a longer path and more time) from other directions.\nA last, but essential, aspect is the distribution of the waypoints relations. For\nexample, if a waypoint overlooks many other locations in primarily one direction, the\nplayer or AI is able to focus on that direction and see all visible activity instandy, with-\nout having to worry about attacks from other directions. The concentration of rela-\ntions in a sector is called focus.\n0\nO © €> C\n€> C» i\nFIGURE 3.8.2 Waypoint properties: (from left to right) local properties, group membership, relations\nwith other waypoints, and focus.\n",
      "content_length": 2168,
      "extraction_method": "Direct"
    },
    {
      "page_number": 300,
      "chapter": null,
      "content": "3.8 Terrain Reasoning for 3D Action Games \n311\nComputing Way point Properties\nTo compute a useful offensive or defensive rating for a given waypoint and direction,\nwe need to implement each applicable tactical characteristic as a function of waypoint\nproperties.\nMany tactical characteristics can be decomposed into primitive functions about\nthe waypoint graph, in effect dealing with linear distance, travel time, line-of-sight,\nline-of-fire, objectives, and obstacles. For example, an important characteristic of a\ngood attack position is that it provides for rapid movement at that position. A \"water\"\nposition does not allow rapid movement locally. A waypoint with a \"water\" local\nproperty should rate low in enabling rapid movement.\nIn small rooms and tunnels, it is difficult to dodge rockets and avoid the blast\nfrom a rocket or grenade. Locations that are more spacious thus offer an advantage. If\na waypoint is part of an area (represented by a group of waypoints) that is a small\nroom or tunnel, it should rate lower in being \"open.\" Thus, the waypoint's group\nmembership can be used to compute a tactical characteristic.\nIn the following code, two tactical characteristics are computed using a local way-\npoint property and a group membership property, respectively.\nfloat GetLocalRapidMovement( waypointid wp )\n{ // result in [0 .. 1], higher values meaning higher speeds\nreturn ( GetActorMovementSpeedAtWaypoint( wp )\n/ GetMaxActorMovementSpeed( ) );\n}float GetOpenAreaMembership ( waypointid wp )\n{ // result in [0 .. 1], higher values meaning more open\nreturn 1.0 - max( IsPartOfSmallRoom( wp ),\nIsPartOfTunnel( wp ) );\n}\nIt is more complicated to compute a directional relation for a waypoint. A spe-\ncific relation for waypoint w, such as the availability of nearby cover from another\nwaypoint wu that has a line of sight on w, is computed in the following function.\n",
      "content_length": 1884,
      "extraction_method": "Direct"
    },
    {
      "page_number": 301,
      "chapter": null,
      "content": "312 \nSections Artificial Intelligence\nfloat GetCoverFromThreatsInDirection(waypointid w) {\nfloat \nproperty [kMaxDirections];\nunsigned int entry[kMaxDirections];\n// set all property and entry values to 0\n// pass one: collect and interpret relations\nfor (waypointid w_to = 0; w_to < kMaxWaypointld; w_to++ ) {\ndirection dir = GetDirectionForWaypoints( w, w_to );\n// check for line-of-fire from w_to to w\nif ( (w_to != w ) && (HasLineOfFire(w_to, w)) ) {\nentry[dir]++;\n// get value for relation (value in [0..1])\nfloat value = GetCoverFromThreatsAt( w, w_to );\nproperty [dir} += value;\n// pass two: level result into [0 .. 1] range\nfor ( direction dir = 0; dir < kMaxSectors; dir++ ) {\nif ( entry [dir] > 0 ) {\nproperty [dir] /= entry [dir];\nfloat GetCoverFromThreatsAt (waypointid w, waypointid w_at) {\nfor (waypointid w_n = 0; w_n < kMaxWaypointld; w_n++ ) {\n// check for lack of line-of-fire to neighbor of w\nif ( IsNeighborOf (w, w_n) && ( !HasLineOfFire(w_at, w_n))\nreturn 1 .0;\n}\nreturn 0; // no cover found\nIn a first iteration over all waypoints, solely those waypoints with a line of fire to\nw are considered. For each of these waypoints, the number of w's relations is incre-\nmented, and the value of the nearby cover available is accumulated.\nIn a second \"iteration, the amount of \"nearby cover\" is divided by the number of\nrelations, to return a value between 0 and 1 . Rather than using the number of rela-\ntions here, we will use the focus ( ) function to deal with the concentration of relations\nin a certain direction. This focus ( ) function is explained later.\nIn a function such as GetCoverFromThreatsAt () (the second function at bottom\nof the previous code listing), a very simple approximation is made. A more advanced\napproximation might use fuzzy logic to deal with such issues as the travel time to the\nnearest cover, the amount of cover available, and the weapon effectiveness over the\ndistance between the waypoints.\n",
      "content_length": 1941,
      "extraction_method": "Direct"
    },
    {
      "page_number": 302,
      "chapter": null,
      "content": "3.8 Terrain Reasoning for 3D Action Games \n313\nfocus() =\n3 x front\nleft + rear + right\nFIGURE 3.8.3 Simple computation of the focus values for waypoint ~w in the example\nterrain. All relations are projected on a 2D dish with four 90-degree sectors. The focus of\na sector is a weighted ratio of its relations versus the relations in other sectors.\nThe focus of a waypoint reflects the concentration of relations over the various\ndirections. Focus is particularly valuable in defense and when survival is important. In\nthese cases, it is not sufficient for a location to offer great sniping opportunities in one\ndirection. The location also needs to offer flank and rear protection; that is, have few\nline-of-sight/fire relations to the sides and to the rear.\nThe function focus ( w, d ) expresses the distribution of relations in one direction\nrelative to the distribution in other directions. The exact implementation of focus ()\ndepends on the number of different directions considered (the sectors) and the type of\nrelation for which the concentration is considered (often the line-of-sight). Figure 3.8.3\nillustrates an implementation of focus for waypoint w in our example terrain, using sim-\nply four sectors to represent die various directions possible in a 3D sphere. When deter-\nmining the focus, you should also deal widi the exceptional case of a waypoint having\nrelations solely in a single sector. Then, a default maximum should be used.\nThe focus() function assumes a more or less uniform distribution of waypoints\nacross the terrain. However, the function is largely robust against moderate deviations\nin that distribution. When we have expressed every tactical characteristic in a number\nof waypoint property computations, we can combine them as follows:\nrating( w, d ) = Z k± x local_propertyi( w )\n+ £ kj x group_membershipj( w )\n+ focus( w, d ) x I ki x relation^ w, d )\nNote that for focus () to correcdy emphasize or dampen the results from the rela-\ntionx() functions, these relation*() should all return positive values. This rating\nexpresses the AI's a-priori understanding of a location and its role in the game. This\nrating, the tactical value of a location, is based on die waypoint graph and world geom-\netry, and implicitly uses some static game constants such as actor movement speeds,\nweapon performance, and power-up locations. For the example area discussed, we are\nnow able to automatically annotate each waypoint with its offensive and defensive val-\nues in a given direction (given some time for experimentation and tuning).\n",
      "content_length": 2560,
      "extraction_method": "Direct"
    },
    {
      "page_number": 303,
      "chapter": null,
      "content": "314 \nSections Artificial Intelligence\nLearning from Gameplay Experience\nObviously, not every value will be fully correct. Our terrain sampling, by means of\nwaypoints, is an approximation, and so are the evaluation functions used to compute\nthe values.\nIn addition, we have been ignoring actual gameplay. That mistake, however, is\neasily turned into an advantage.\nBecause the AI uses waypoints for its actions, and thinks of the players as being\nnear waypoints, we can record their activity at a waypoint with little effort. We can\nuse that information in two ways. We can use it to correct the outcome of our com-\nputations, and we can use it as additional input in the computations.\nWe can improve, for example, the defensive value of a waypoint in a direction by\nadding the damage done by an actor, and subtracting the damage received by an actor\nat that waypoint. In other words, we add a little reinforcement learning to the AI's\nunderstanding of the locations. That will correct part of the error present in our\nresults. More importantly, it leads to an AI that will vary and adapt its choice of loca-\ntion based on its past successes and failures!\nThe captured gameplay data can also be input for our waypoint properties. For\nexample, the more \"hostile traffic\" waypoints that can be seen from a location, the\nmore useful that location will be for defense. Such a relation can be computed easily,\nif the required traffic data is available. When using gameplay data as input for the\ncomputations, the AI actually gains tactical understanding of the terrain.\nPutting Terrain Reasoning in the Game\nSo, our AI can analyze the example area by a series of computations, using geometry\ndata, travel time, shortest paths, line-of-sight, line-of-fire, and waypoint-related\ngameplay data. These computations have O(n 3) time complexity, because in comput-\ning some of the waypoint-to-waypoint relations, other nearby waypoints are also con-\nsidered. In practice, the computations take some tens of seconds. This kind of\nwaypoint reasoning is best done when preprocessing a level and possibly between mis-\nsions, as a background thread.\nFew resources are used by the results from the terrain reasoning algorithm. Typi-\ncally, they consist of several tables per waypoint, each table containing a small number\nof bytes. The tables can quickly be read and contain knowledge about the terrain that\nwould otherwise be almost impossible to obtain. In addition, the reinforcement learn-\ning based on gameplay data enables some varying and adaptive AI behavior at negligi-\nble costs.\nIn general, waypoint-based reasoning need not be CPU intensive. Terrain reason-\ning is quite feasible during gameplay, provided the AI considers a small set of way-\npoints, and has intermediate reasoning results available. Using small look-up tables\nfor each waypoint to store both the nearby waypoints and the visible waypoints, the\nAI can, for example, efficiently plan paths that avoid locations under fire from threats.\n",
      "content_length": 2995,
      "extraction_method": "Direct"
    },
    {
      "page_number": 304,
      "chapter": null,
      "content": "3.8 Terrain Reasoning for 3D Action Games \n315\nDynamic game terrain and entities, such as doors, vehicles, destructible terrain,\nand smoke do complicate the terrain reasoning, because these dynamics partially\ninvalidate precomputed results. Notably the line-of-sight, line-of-fire, and paths will\nbe affected by dynamic terrain. Nevertheless, it often remains attractive to use pre-\ncomputed intermediate results. It is often more intelligent and efficient to use these\nresults and try to correct for any dynamics than to use no reasoning at all.\nThe terrain reasoning discussed here is a set of heuristics. It takes a number of\nexperiments and some analysis to find the right ingredients and weights for your AI\nterrain reasoning. To effectively tune and verify your algorithm, visualization of the\n(intermediate) reasoning output is essential. The output can be interpreted easily\nwhen projected onto the terrain within the game. Alternatively, you can export the\nresults to a spreadsheet for further analysis.\nOther Applications\nWaypoint-based terrain reasoning is presented here using a simple example, precom-\nputing the offensive and defensive values of the game locations. The ideas behind the\nreasoning have a much wider use than that example. The idea of dissecting tactical\nguidelines and expressing them as evaluation functions per location is an approach\nthat will work for many games where the AI needs to reason about locations.\nJust ask yourself the question:\n\"If I were to defend this base (or whatever the AI needs to do), why would I prefer\nlocation x over location y, and what does distance, travel time, line-of-fire, the type of area,\n(or whatever terrain property or game item you can come up with) have to do with it?\"\nWaypoints, if placed in a sufficiently dense graph across the terrain, serve many\nmore purposes than just navigation. Together with a few small lookup tables for\nnearby waypoints and visible waypoints, they enable the AI to predict out-of-sight\nopponent movement, and to find a nearby location providing a new line-of-sight.\nWaypoints are a handy means to \"host\" additional costs for A* pathfinding. If\nwe tag all waypoints that are visible from the assumed threat positions with extra\ncosts, the A* pathfinder provides us a path offering cover from the threats where\navailable. If we also tag all waypoints that restrict our movement, the path returned\nwill be even more \"tactical.\" These are just two of the many examples of waypoint-\nbased reasoning. You can probably think of a few more that will put your AI in a\nstrong position.\nConclusion\nWaypoint graphs provide an easy-to-use representation of the game terrain. You can\ntranslate many of the terrain-related tactics in your game to waypoint-related proper-\nties. As an example, this gem shows how to build a per-waypoint evaluation function\nthat expresses the value of a location for general offense, general defense, or a parti-\n",
      "content_length": 2931,
      "extraction_method": "Direct"
    },
    {
      "page_number": 305,
      "chapter": null,
      "content": "316 \nSection 3 Artificial Intelligence\ncular tactic such as ambushing or sniping. This will provide your AI with a good\nunderstanding of the terrain.\nYou can extend and improve that evaluation function with captured gameplay\ndata, resulting in an AI that becomes more varied and adaptive. There are many other\nways your AI can reason about terrain using waypoints. Just try to relate the tactical\nguidelines to waypoint properties (that fit in a look-up table).\nReferences and Additional Reading\n[PottingerOO] Pottinger, Dave, \"Terrain Analysis in Realtime Strategy Games,\" Pro-\nceedings of Computer Game Developer Conference, 2000.\n[RabinOO] Rabin, Steve, \"A* Speed Optimizations,\" Game Programming Gems,\nCharles River Media, 2000: pp. 272-287.\n[ReeceOO] Reece, Doug, et al, \"Tactical Movement Planning for Individual Combat-\nants,\" Proceedings of the 9th Conference on Computer Generated Forces and\nBehavioral Representation, 2000. Also available online at www.sisostds.org/\ncgf-br/9th/.\n[SnookOO] Snook, Greg, \"Simplified 3D Movement and Pathfinding Using Naviga-\ntion Meshes,\" Game Programming Gems, Charles River Media, 2000: pp.\n288-304.\n",
      "content_length": 1144,
      "extraction_method": "Direct"
    },
    {
      "page_number": 306,
      "chapter": null,
      "content": "3.9\nExpanded Geometry for\nPoints-of-Visibility Pathfinding\nThomas Young\nthomas.young@bigfoot.com\nI\nn Game Programming Gems, Bryan Stout and Steve Rabin described \"points-of-\nvisibility\" pathfinding [StoutOO], [RabinOO]. This is essentially a way to find the\nshortest path around polygonal obstacles.\nAs Steve pointed out, there are big advantages to the method. It enables you to\ncreate a minimal representation of the search space, resulting in very fast searches. In\naddition, paths found are perfectly direct.\nIn this gem I explain how to automate construction of expanded geometry from\npolygonal obstacles, and how to use this to implement points-of-visibility pathfinding.\nBy using expanded geometry, we overcome most of the disadvantages of the technique.\n• Points of visibility can be extracted directly from the expanded geometry without\ndesigner assistance.\n• It is possible to support dynamic objects (such as characters, doors, moving\nblocks, and so on) by generating and integrating expanded geometry for those\nobjects on the fly.\n• The expansion can be parameterized to support characters of different sizes and\nformations.\nFor many games, pathfinding is fundamental to the AI. It is up to the pathfinder\nto guarantee certain aspects of character behavior. It is essential, for example, that AI\ncharacters do not get stuck against obstructions. Characters must not fail to find a\npath around obstacles when that path looks obvious to the player. When collision\nagainst obstructions is complicated, even these capabilities are difficult to guarantee.\nIf we accept some limitations on the collision model for character movement, we\ncan use exactly the same model for both collision and pathfinding. By using expanded\ngeometry we can build a pathfinding system that is exactly correct for this collision\nmodel. This system is guaranteed to understand correctly any position a character can\nreach, and returns paths that are guaranteed to be unobstructed, so characters can't get\nstuck.\nHigher-level AI built on a \"perfect\" pathfinding system is much easier to code\nbecause you don't need to catch those tricky situations, such as a character getting\n317\n",
      "content_length": 2164,
      "extraction_method": "Direct"
    },
    {
      "page_number": 307,
      "chapter": null,
      "content": "318 \nSections Artificial Intelligence\nstuck because no path can be found from its current position. By depending com-\npletely on the results of the pathfinding system, it is possible to build sophisticated\nmovement-related AI with far fewer lines of code. It is also much more fun.\nDefining a Collision Model\nA collision model precisely specifies character collision against the environment. We\nbuild our collision model around a \"collision shape\" for each character. The collision\nshape is a convex polygon chosen to best represent the shape and size of that charac-\nter. The shape translates with the characters origin when the character moves, but\ndoesn't rotate when it turns. The character is obstructed for positions where its colli-\nsion shape overlaps the environment.\nThe environment is represented polygonally and can be comprised of convex and\nnonconvex polygons that mark obstructed areas, 2D meshes to represent unob-\nstructed areas, or some combination of these representations (Figure 3.9.1).\n: -(-Obstructed\n, j .-tt'nobstructed\nFIGURE 3.9.1 Collision shapes in polygonal environments.\nPolygonal Pathfinding\nNow that we have specified a collision model, it is the job of the pathfinder to find\npaths for a character that are unobstructed for this model. For simplicity, I consider\nonly the traditional pathfinding constraint; that is, to find the shortest path from the\nstart position to a given goal position. The problem can be restated as finding the\nshortest set of unobstructed line sections connecting start to goal.\nExpand and Conquer\nThe trick is to build an expanded geometry that combines our collision shape with\nthe shape of the obstacles in the environment. This representation greatly simplifies\nthe queries we require for our pathfinding system.\n",
      "content_length": 1777,
      "extraction_method": "Direct"
    },
    {
      "page_number": 308,
      "chapter": null,
      "content": "3.9 Expanded Geometry for Points-of-Visibility Pathfinding \n319\nThe expansion we use is a Minkowski sum of planar sets. Specifically, our\nexpanded geometry will be a Minkowski sum between the environment and the\nnegated collision shape. This is sometimes called a Minkowski difference.\nThe Minkowski sum of two sets A and B is the set of values that can be generated\nby adding some member of set A to some member of set B. A polygon can be viewed\nas a planar set; that is, the set of points inside that polygon.\nOur expanded geometry represents the set of points that can be generated by sub-\ntracting some offset in our collision shape from some point inside the environment.\nThis means that for each position in our expanded geometry, some point in the colli-\nsion shape overlaps the environment. Therefore, our expanded geometry represents the\nset of points where our character will be obstructed (Figure 3.9.2).\nColl\nDoesn't Collide \\^~ \nDoesn't Collide\nFIGURE 3.9.2 Collision shape in polygonal environment, point in expanded environment.\nCollision between a collision shape and the original polygonal environment is\nidentical to collision between a point and the expanded geometry. To find out if a\ncharacter can be placed at a position, we test whether that position is inside our\nexpanded geometry. To find out if a line section is obstructed for a character, we sim-\nply test whether the line collides against our expanded geometry.\nFor points-of-visibility pathfinding, the set of convex corners in our expanded\ngeometry gives us our points of visibility. Two points can be connected if the line\nbetween the points doesn't collide against our expanded geometry.\nMinkowski Sum of Convex Polygons\nTo build our geometry, we start by looking at the simpler case of a single convex poly-\ngon obstruction. The negated collision shape is also a convex polygon, so we must\nconstruct a Minkowski sum of two convex polygons.\nFor convex polygons C and O, this sum can be visualized as the space swept out\nby dragging the center of C around the perimeter of O (Figure 3.9.3a). This space will\nbe bounded by a larger convex polygon. The sum can also be visualized as the shape\n",
      "content_length": 2174,
      "extraction_method": "Direct"
    },
    {
      "page_number": 309,
      "chapter": null,
      "content": "320\nSection 3 Artificial Intelligence\nA \nB\nFIGURE 3.9.3 A) Sum of convex polygons. B) Alternative visualization.\nenclosed by the center of the (non-negated) collision shape as it slides around touch-\ning the perimeter of O (Figure 3.9.3b).\nEdges in the expanded polygon are generated in three ways (see Figure 3.9.3B):\n1. Directly from an edge in C, when C is placed at a corner of O.\n2. By a corner of C as C moves along an edge in O.\n3. By an edge in C as C moves along a parallel edge in O.\nWhen there are no parallel edges, each edge in C and O is used exactly once, giv-\ning us a limit for edges in our expanded polygon equal to die edges in C plus the edges\nin O. This is useful for us to allocate space in advance for the expanded polygon.\nIt is fairly easy to build the expanded polygon. Vertices in C are numbered in a\nclockwise direction (Figure 3.9.4a). For each edge in O, we determine which of these\nvertices is used to expand the start and end points of that edge (Figure 3.9.4b). This\nA \nB\nFIGURE 3.9.4 A) Vertices in C. B) Stan and end points, interpolated vertices.\n",
      "content_length": 1083,
      "extraction_method": "Direct"
    },
    {
      "page_number": 310,
      "chapter": null,
      "content": "3.9 Expanded Geometry for Points-of-Visibility Pathfinding\n321\nstart=2 end=2\nend=3 \nstart=l\nend=2\nA \nB\nFIGURE 3.9.5 Ordering by edge vectors, start and end expansion for an edge.\ngives us our type (2) or type (3) edges. Type (1) edges are constructed where the end\npoint of one of these edges does not connect to the start point of the next, by inter-\npolating vertices in C, if required, and adding edges (also Figure 3.9.4B). Interpola-\ntion is just a case of counting through vertices in C until we reach the vertex that\nexpands the start of the next edge.\nSo, how do we determine the start and end expansions for each edge in the first\nplace? We can define a circular ordering on vectors, based on the directions of die edges\nin C (Figure 3.9.5). For each edge in O, position in this ordering tells us which vertices\nin C expand the start and end points of diat edge (also Figure 3.9.5). For a bit of extra\nspeed, this position can be tracked incrementally as we loop through edges in O.\nExpanding Nonconvex Geometry\nNow that we can expand a convex polygon, there is a straightforward way to extend\nthis to a nonconvex polygon. We simply split the nonconvex polygon into convex\nparts and expand each part separately (Figure 3.9.6a). However, this can result in a\nlarge number of overlapping polygons with a lot of unnecessary edges and corners.\nTo make a well-formed Minkowski sum, we should detect intersections between\nexpanded polygons and connect them together to make a single expanded shape. A\nfundamental problem with this approach is the fact that intersections may not fall\nexactly on points representable by the numbers we are using for coordinates. More-\nover, if we use approximate points at intersections, then our padifinder no longer cor-\nresponds exacdy to our collision model, although this may not matter if our collision\nengine will also be built around the same expanded representation.\nA good solution is to make a \"lazy man's Minkowski sum.\" Here we are not con-\ncerned with the set of obstructed points, but rather with transitions from unob-\nstructed areas into obstructed areas. This approach is more appropriate for external\nboundaries that can't be decomposed, as such, into convex polygons. This will also be\n",
      "content_length": 2241,
      "extraction_method": "Direct"
    },
    {
      "page_number": 311,
      "chapter": null,
      "content": "322 \nSection 3 Artificial Intelligence\nmore relevant if we need to make extensions in the fixture to support features such as\noverlapping geometry.\nTo build a \"lazy man's Minkowski sum,\" we can use virtually the same method we\nused to expand a convex polygon. The difference is that we do not interpolate points\nat a concave corner. If the end point for the edge before the corner is not same as the\nstart point for the edge after the corner, then we get an intersection and a discontinu-\nity in the expanded edge list (Figure 3.9.6b).\nThis process is a lot easier to code and a lot faster than generating a true\nMinkowski sum. For a start, we don't have to perform any triangulation or detect\nintersections. For large collision shapes, we can still end up with unnecessary edges\nand corners, but this is usually not a big problem.\nA \nB\nFIGURE 3.9.6 A) Nonconvexpolygon expanded as convex subparts. B) Lazy man's\nMinkowski sum.\nChoosing a Collision Shape\nThe fact that our collision shape doesn't rotate is a major limitation for our collision\nmodel. Because the characters in our games will almost certainly need to rotate, we\nwill want to use rotationally symmetrical collision shapes in order to get the most con-\nsistent collision behavior. A circle would be the best approximation, but we can't use a\ncircle because the resulting expanded geometry would have no corners and hence no\npoints of visibility. Instead, we must use an N-sided regular polygon to approximate a\ncircle.\nIn general, the more edges we use in our collision shape, the more edges and cor-\nners we get in the resulting expanded geometry. With more edges and corners,\npathfinding becomes more expensive (sometimes exponentially). Squares and\noctagons are obvious choices because they are relatively simple and because they can\nbe aligned with the coordinate axes.\nIn the past, it was important to use axis-aligned collision shapes for performance\nreasons. For vector comparisons against horizontal, vertical or 45-degree lines,\n",
      "content_length": 2002,
      "extraction_method": "Direct"
    },
    {
      "page_number": 312,
      "chapter": null,
      "content": "3.9 Expanded Geometry for Points-of-Visibility Pathfinding \n323\nmultiplication can often be avoided. Nowadays, branch prediction issues mean that it\nis better to simply go ahead and perform the same multiplications for all cases, so\nthere is no longer any performance reason to only use axis-aligned shapes. For some\nplatforms, avoiding multiplication may still be an important issue, however.\nConclusion\nI have shown how a pathfinding system can be constructed that is precise with respect\nto a reasonably interesting polygonal collision model. There is a trade-off to be made\nbetween sophisticated collision systems and collision systems that characters can\n\"understand.\" For games where you are able to use this model for both character col-\nlision and pathfinding, there can be a big payback in reduced debugging and simpli-\nfied AI.\nReferences\n[RabinOO] Rabin, Steve, \"A* Speed Optimizations,\" Game Programming Gems,\nCharles River Media, 2000.\n[StoutOO] Stout, Bryan, \"The Basics of A* for Path Planning,\" Game Programming\nGems, Charles River Media, 2000.\n",
      "content_length": 1061,
      "extraction_method": "Direct"
    },
    {
      "page_number": 313,
      "chapter": null,
      "content": "3.10\nOptimizing Points-of-Visibility\nPathfinding\nThomas Young\nthomas.young@bigfoot.com\nT\nhe \"points of visibility\" pathfinding method has a number of advantages (see Steve\nRabin's article in Game Programming Gems, [RabinOO]). Also, with expanded geom-\netry we can make this an exact mediod to guarantee correct paths with respect to a given\npolygonal obstruction set (see \"Expanded Geometry for Points-of-Visibility Pathfind-\ning\" in tins volume.) Complexity is independent of scale, so it is possible to efficiently\ncompute paths over long distances, and by precalculating the network of connections\nbetween points of visibility, an extremely fast pathfinder can be constructed.\nAs map complexity increases, and with it the number of points of visibility, we\nfind that the number of connections between these points can increase exponentially,\nparticularly on maps with large open areas. Memory can become an issue, especially\non console platforms. In addition, the need for interesting AI demands that pathfind-\ners must support dynamic features such as moving objects, characters, doors, and so\non. To support dynamic features such as these, we need to work with points of visi-\nbility that are generated on the fly, and obstacles that can move to invalidate connec-\ntions. If we are not careful, the overhead for calculating visibility with these dynamic\nfeatures can also increase exponentially.\nI present some optimizations that enable us to quickly discard many potential\npaths and to greatly reduce the size of our network of connections. This results in\nfaster searches and less overhead for dynamic objects. With these optimizations, our\nalgorithm will scale better to handle increasingly complicated maps.\nPoints-of-Visibility Pathfinding\nFor this gem, I assume that the pathfinding agent can be considered as a point agent\nin a polygonal environment. Section 3.9 explains how a more interesting collision\nmodel can be converted to this form.\nOur pathfinder uses an A* algorithm with a set of points of visibility as possible\nintermediate states between start and goal. The points of visibility are derived directly\nfrom the convex corners in our polygonal environment. For an explanation of the A*\nalgorithm, see Bryan Stout's article in Game Programming Gems [StoutOO].\n324\n",
      "content_length": 2287,
      "extraction_method": "Direct"
    },
    {
      "page_number": 314,
      "chapter": null,
      "content": "3.10 Optimizing Points-of-Visibility Pathfinding \n325\nStoring the Shortest Path to Each Point\nAn important first step to prevent exponential growth of our search tree is to ensure\nthat only the shortest path to any intermediate point is retained for further consider-\nation. This is not a specific optimization for points-of-visibility pathfinding as it\nshould probably be standard behavior for any A* implementation. This needs to be\nstressed, however, because it makes a big difference to scalability.\nIn Bryan Stout's article, he describes the use of an open list and a closed list. At\neach step of the A* algorithm, these lists are searched to find any other paths that also\nend at the current point under consideration.\nOne important difference between tile-based pathfinding and points-of-visibility\npathfinding is the number of potential intermediate locations we need to consider.\nSince we only consider the convex corners in our environment, this will tend to be an\norder of magnitude less than the number of tiles required to represent the same map\nfor tile-based pathfinding.\nThis means that it is feasible to use an array (with one entry per point of visibil-\nity) to keep a record of the shortest path found so far to each point. Instead of search-\ning through open and closed lists, we need only make a single lookup into this array.\nIn fact, this means that there is no longer any need for a closed list at all.\nThe array must be cleared before each use, but on most platforms, there will be a\nfast memory clear routine readily available, so the time this takes is usually irrelevant.\nIf there is a very large number of points and you expect to only use a small number of\nthese for each search, then it might be worth keeping the closed list as a record of\nwhich points must be cleared after the search is complete.\nConnecting the Corners\nEach step in the A* algorithm involves taking the best partial path found so far and\ngenerating a set of successor paths. Each successor is formed by connecting the end of\nthe partial path to another point with a line section. The point can be either a point\nof visibility or the goal point. The straightforward approach is to generate a successor\nfor every point in the world for which the line section will be unobstructed.\nBy preprocessing collision between all pairs of points of visibility and building a\n(possibly large) table, we can determine very quickly at runtime which other points of\nvisibility can be reached from some source point of visibility. The start and goal posi-\ntions will change at runtime, so line sections to and from these points cannot be pre-\nprocessed. The same is true for any points of visibility resulting from dynamic\nobstacles.\nOptimization #1: Only Consider Paths to Silhouette Points\nAs seen from some source point, each other point in the world can be classified as left\nsilhouette, right silhouette, or not a silhouette (Figure 3.10.1).\n",
      "content_length": 2931,
      "extraction_method": "Direct"
    },
    {
      "page_number": 315,
      "chapter": null,
      "content": "326 \nSections Artificial Intelligence\nilhouette \ncorner can\nPoint \nbe cut\nSource Point \nSource Point\nFIGURE 3.10.1 Silhouette points.\nThis optimization is based on the observation that we don't need to consider path\nsections that connect to nonsilhouette points. Any path section going to a nonsilhou-\nette point will result in a corner that can be cut to make a shorter path. (This is true\nunless that point coincides exactly with the goal point, or with another silhouette\npoint. In both cases, there will be an alternative mechanism to generate that path.)\nThe optimization applies when we are generating the set of successors to a partial\npath. I will refer to the point at the end of this partial path as the current point. The\npoints we consider using to extend the path are potential next points. We can simply\ndiscard any of these points that are not silhouettes as seen from the current point.\nWe discard nonsilhouette points because the resulting path can always be short-\nened by cutting a corner. To better visualize what is going on here, it is useful to\nunderstand that the shortened path will be realized as the search continues. This will\nhappen either by connection directly from the current point or by connecting to a sil-\nhouette on a blocking object.\nIf we are using a visibility graph, then this optimization can also be applied\ndirectly to the connections in our visibility graph. Any connection can be removed\nfrom the graph where the destination point is not a silhouette from the source point.\nOptimization #2: Only Consider Paths that Go\nAround the Corner\nThis optimization is also applied when generating successors to a partial path.\nFor this optimization, we are interested in the line section at the end of our par-\ntial path. When generating successors for the first time, from the start position, the\npartial path is empty so this optimization does not apply. I will refer to the point at\nthe start of this line section as the previous point. The point at the end of the partial\npath is our current point. As a result of our first optimization, the current point will\nalways be a silhouette point as seen from the previous point.\nThe reasoning behind this optimization is similar to die reasoning behind die first\noptimization. Any path diat does not go around the silhouette point will result in a cor-\nner that can be cut to make a shorter path. Figure 3.10.2 shows a silhouette point, a set\n",
      "content_length": 2427,
      "extraction_method": "Direct"
    },
    {
      "page_number": 316,
      "chapter": null,
      "content": "3.10 Optimizing Points-of-VisibilityPathfinding \n327\nof path sections that go around that point, and one example of a path that can be dis-\ncarded. Again, the shortened path will be realized either by a direct connection from the\nprevious point, or via another silhouette point if the direct connection is obstructed.\nTo implement this optimization, we use the vector from the previous point to the\ncurrent point and the vector from the current point to the potential next point under\nconsideration. At a left silhouette, the next vector must be on the right of the previous\nvector and to the left of the obstacle. At a right silhouette, the next vector must be on\nthe left of the previous vector and to the right of the obstacle (Figure 3.10.2).\nGoal\nStart\nFIGURE 3.10.2 The path must go around each corner.\nSilhouette Zones\nFor implementation, it is useful to define two zones relating to each point of visibility\n(Figure 3.10.3). Each point of visibility is positioned at a convex obstruction corner.\nThe zones are formed by extension of the obstruction edges before and after that cor-\nner. The zones classify this point of visibility as seen from some arbitrary point. If that\npoint is in the left silhouette zone, then our point of visibility is classified as left sil-\nhouette, and vice versa.\nTo go \"around\" the silhouette point, the next point must be in the opposite zone\nto the previous point, but it must also be inside the set of valid destinations bounded\nby the extension of the axis from the previous connection.\nWe can apply the second optimization to the connections in our visibility graph.\nEach connection in our graph has a source point and a destination point. When gen-\nerating successors, these correspond to the current and next points, but there is no\ninformation in a simple visibility graph about the position of the previous point. This\nmeans that when we apply this optimization to the visibility graph, we must allow for\n",
      "content_length": 1952,
      "extraction_method": "Direct"
    },
    {
      "page_number": 317,
      "chapter": null,
      "content": "328\nSection 3 Artificial Intelligence\nI 1 4\nI\" ~'f\" Right Silhouette\nLeft\nFIGURE 3.10.3 Silhouette zones at a corner.\nall possible positions for the previous point. This just means that our set of valid des-\ntinations becomes the set of points in either of our silhouette zones.\nSo, to apply this optimization to our visibility graph, we also discard connections\nwhere the destination point is not in one of the source point's silhouette zones. When\nwe retrieve a connection from the visibility graph, we know the position of the previ-\nous point so we can make a more specific test to possibly discard that connection.\nEnvironment 1\nEnvironment 2\nPoints \nConnections before\n21 \n231\n96 \n1638\nConnections after\n98\n568\nFigure 3.10.4 shows two examples of obstruction environments. The table above\nshows the number of connections in our visibility graph before and after using sil-\nhouette optimizations to discard connections.\nFIGURE 3.10.4 Environment 1, Environment 2.\n",
      "content_length": 969,
      "extraction_method": "Direct"
    },
    {
      "page_number": 318,
      "chapter": null,
      "content": "3.10 Optimizing Points-of-Visibility Pathfinding \n329\nUsing Silhouette Zones with Spatial Partitioning\nThe optimizations I have described enable us to reduce the number of connections in\nour visibility graph, and to reduce the size of our search tree. For dynamic points, we\nstill need to test for connection to and from every other point in the world. We can\nquickly discard many of these connections, but connections that cannot be discarded\nneed to be tested for collision.\nThe next step is to build a representation to quickly determine a minimal set of\npoints that can potentially connect to or from a given dynamic point. Silhouette\nzones are a good starting point for building this representation. The zones for a given\npoint of visibility give us an area within which dynamic points can potentially con-\nnect to that point of visibility. The exact nature of this representation should vary for\ndifferent types of obstruction environments.\nIn maps with low visibility, built from rooms connected by portals, silhouette\nzones can be projected through portals to determine which rooms can potentially see\nthe corresponding point of visibility.\nFor a more general system, silhouette zones can be clipped against the polygonal\nenvironment to determine the area in which a given point is visible. The resulting shapes\ncan then be entered into some general spatial partitioning system. If the shape for one of\nthese areas is represented exacdy, then there is no need for any collision checking once it\nis known diat a dynamic point is inside that shape. (Note that exact representation of the\nclipped area may depend on using an exact representation for line intersections.)\nConclusion\nThere are many more details involved in building an efficient points-of-visibility\npathfinding system. I have described some techniques for quickly discarding many\nconnections and therefore reducing the total number of paths that must be consid-\nered. This is a good first step.\nI have briefly mentioned how silhouette zones can be used with spatial partition-\ning to handle dynamic points efficiently. To support the addition of dynamic obsta-\ncles efficiently, a good spatial partitioning system is essential.\nA final detail is the problem of testing for connection from one dynamic point to\nanother. For the case with no dynamic obstacles, this only needs to be done once, for\nthe potential connection from start point to goal point. With dynamic obstacles, this\ntest may need to be performed a large number of times, so an efficient implementa-\ntion becomes important.\nReferences\n[RabinOO] Rabin, Steve, \"A* Speed Optimizations,\" Game Programming Gems,\nCharles River Media, 2000.\n[StoutOO] Stout, Bryan, \"The Basics of A* for Path Planning,\" Game Programming\nGems, Charles River Media, 2000.\n",
      "content_length": 2783,
      "extraction_method": "Direct"
    },
    {
      "page_number": 319,
      "chapter": null,
      "content": "3.11\nFlocking with Teeth: Predators\nand Prey\nSteven Woodcock\nferretman@gameai.com\nF\nlocking (sometimes called swarming or herding) is a technique first put forth by\nCraig Reynolds in a 1987 paper he did for SIGGRAPH entitled \"Flocks, Herds,\nand Schools: A Distributed Behavioral Model\" [Reynolds87]. In this paper, Reynolds\ndefined the three basic rules (or steering behaviors) for flocking and explained how\nthey interacted to give lifelike group behavior to creatures he called boids. In Game\nProgramming Gems, I wrote a short gem introducing the subject [WbodcockOO] and\nadded another steering behavior to make what I called the \"Four Rules of Flocking.\"\n• Separation: Steer to avoid crowding local flockmates.\n• Alignment: Steer toward the average heading of local flockmates.\n• Cohesion: Steer to move toward the average position of local flockmates.\n• Avoidance: Steer to avoid running into local obstacles or enemies.\nWhat's interesting about these four simple behavioral rules is how lifelike the\nresulting behavior of the boids can seem. Watching the original demo from the first\nbook (also provided on the companion CD-ROM files for this chapter), one can see\ngroups of boids coalesce and move in ripples around their world. When they\nON THE CD approach boids belonging to another flock, they flee, breaking apart into smaller\nflocks, if necessary, to avoid contact with anybody not belonging to their flock. If\nsplit from their original flocks, individual boids eventually find fellows and form a\nnew flock, which in turn would eventually find other flocks to join.\nAnother interesting aspect of flocking is that the movement algorithm itself is\nstateless—no information is maintained from movement update to movement\nupdate. Each boid reevaluates its environment at every update cycle. Not only does\nthis reduce memory requirements that might otherwise be needed to provide a simi-\nlar behavior using approaches besides flocking, it also allows the flock to react in real\ntime to changing environmental conditions. As a result, flocks exhibit elements of\nemergent behavior—no one member of the flock knows anything about where the\nflock is going, but the flock moves as one mass, avoids obstacles and enemies, and\nkeeps pace with one another in a fluid, dynamic fashion.\n330\n",
      "content_length": 2287,
      "extraction_method": "Direct"
    },
    {
      "page_number": 320,
      "chapter": null,
      "content": "3.11 Flocking with Teeth: Predators and Prey \n331\nThis technique has proven to be a valuable one for video games, having uses in\neverything from unit formations in an RTS, to realistic behavior of crowds in RPGs.\nThis gem builds on the original article in a number ways, borrowing from some\nof the suggested enhancements outlined there, together with one or two suggestions\nreceived by readers. I'll expand on the original demo, adding some features that\nsomewhat individualize the boids, giving each boid a new feature—hunger. The\nworld itself will be made a bit more difficult to navigate through the introduction of\nobstacles. I'll then introduce a new discriminator that gives our boids a reason to flee\neach other—some will be predators that actually feed on the others! Boids will now\ncome in three flavors: hawks, sparrows, and flies. To this end, we'll be adding a \"Fifth\nRule\":\n• Survival: Steer to eat as needed, or to avoid being eaten if a predator is seen.\nA Whole New World\nThe original cube-shaped world of the first demo is a boring, empty place; nothing\nexists in that realm but the boids themselves. Left to itself (and assuming it didn't run\ninto a boid from another flock), a given boid would pretty much fly around forever,\nwandering aimlessly. The only flocking-related code that might otherwise have influ-\nenced a boid's motion was a minor function I added to the flocking algorithm (in\nCBoid:: Cruising ()), and even that didn't contribute much. The world wrap code\n(which teleported boids flying off one side of the world to the other side) could screw\nup flocks a bit, but they always eventually found each other again.\nMore variety is needed if we're to make the lives of our creations more interesting\nand to provide an environment closer to one that might be found in an actual game.\nTo help give our boids more to think about this time around, we've got to give them\nsomething new to deal with—obstacles.\nObstacles\nAn obstacle is pretty much what it sounds like—something that's in the way. A new\nclass of object called CObstacle has been added to create these. A CObstacle object\nforms an impenetrable cone-shaped barrier that all boids will try to avoid during their\ntravels.\nThis class gives us a simple way to make the world a bit more interesting and pro-\nvides them with some interesting navigational challenges. Obstacles can be created\nanywhere within the world with any arbitrary orientation, using either specified val-\nues or randomly determined ones. The CObstacle: :GetPosition () method has been\nadded to help us with collision detection and in determining if an obstacle is in the\nline of sight of a given boid, while Cobstacle: :GetRelativeDiameter() will return the\nrelative size of the obstacle at the boid's cruising altitude.\n",
      "content_length": 2777,
      "extraction_method": "Direct"
    },
    {
      "page_number": 321,
      "chapter": null,
      "content": "332 \nSection 3 Artificial Intelligence\nCritters of All Kinds\nFigure 3.11.1 shows how boids now come in three flavors, arbitrarily named hawks,\nsparrows, and flies, as they are all flying creatures. Each serves an important role in the\necology of our gem by hunting and feeding on each other.\n- Moves quick \n- Moves average \n- Moves slow\n- Sees further \n- Sees average \n- Can't see far\n- Hunts Sparrows \n- Hunts Flies \n- Hunts nothing\n- Randomly reproduces\nFIGURE 3.11.1 Types of boids.\nEvery Boid Is a Bit Different\nThe original Simple Flocking demo initialized all boids with various parameters—range\nof sight, maximum speed of flight, etc.—which were identical for all boids anywhere in\nthe world. There were no particular discriminators to distinguish one boid from\nanother, beyond the flock to which it belonged. Boids belonging to other flocks were\nautomatically enemies and avoided like the plague (if that switch was turned on).\nThe Predators and Prey flocking demo individualizes each boid a bit by allowing a\nrandomized component upon boid creation. A boid thus created (via a new construc-\ntor added to the CBoid class) will now have some \"personality,\" making each one a\nlittle bit different from its fellows. Some won't see well, while others will see farther\nthan their brothers. Still others will want to maintain more distance from their fellows\nthan the norm. Some will be hungrier than others, and so on.\nWhy do this? There are a couple of reasons, both of which add to the lifelike\nbehavior of the creatures in our little world. First, providing each boid with slightly\ndifferent capabilities is simply more realistic than an endless army of clones. Second,\nthe differences will combine to provide some novel forms of emergent behavior as our\nboids interact, again providing what in the end is a more realistic representation of a\ngroup of creatures moving en masse. The tug and pull of two boids in the same flock,\none of which wants to maintain a cohesion much tighter than its fellow, will make for\nsome interesting group dynamics, as will a boid that can see an oncoming predator\njust a bit farther than any of his flockmates.\nAdditionally, the new demo adds some finer control over what types of boids\nare considered \"enemies\" and what types aren't. A new parameter has been added to\nthe CBoid constructor that allows specification of that boid's type. This allows for sim-\nple tests to be added to the CBoid:: SeeEnemies () and CBoid:: FindFood () methods to\ncompare types and determine if a given boid is a predator to be avoided or prey to be\nhunted.\n",
      "content_length": 2577,
      "extraction_method": "Direct"
    },
    {
      "page_number": 322,
      "chapter": null,
      "content": "3.11 Flocking with Teeth: Predators and Prey \n333\nDoes this all add some overhead? Yes, though it's not much. The needs of die par-\nticular implementation, of course, will drive any such design decisions. For example,\nin an RTS game, every unit of archers might well be fairly generic, while in an FPS\ngame, every squad-mate is an individual with unique characteristics.\nFeeding the Flock\nIt follows that if we're going to have classes of boids that feed on one another, we're\ngoing to need something to control that hunger. Nothing outside of the Jaws movies\nhas an insatiable appetite, and our boids are no exception.\nTo represent this, both hawks and sparrows have a hunger rating that decrements\na little each update cycle. \"When it reaches zero, our boid will become hungry and will\nbegin to actively seek out prey to satisfy that hunger. In our demo, hawks hunt for\nsparrows, of course, while sparrow boids will seek out flies. Flies are at the bottom of\nthe food chain and don't eat anything, but they will reproduce if there are enough of\nthem in one flock. Each time a hawk or a sparrow eats, a random test will determine\nif it's still hungry by comparing its current hunger rating to its starting hunger rating.\nFor example, if a hawk starts out with 10 hunger points and has eaten four sparrows,\nthere's a 40-percent chance it will be satisfied and stop eating.\nSince it isn't my desire to build a complicated feeding simulator, both hawks and\nsparrows \"eat\" when they successfully collide with their favorite food. A hawk will\nattempt to close with any sparrow boid it sees, while a sparrow boid will deliberately\nsteer to intercept the nearest fly. Anything eaten is, of course, removed from the\nworld.\nThere's Always Another Fly\nSince hawks feed on sparrows and sparrows feed on flies, flies are both at the low end\nof the food chain and arguably the most important members of it. If they die off,\nevery other boid will too, sooner or later. To prevent this, flies have one feature that\nno other type of boid has—they can reproduce. To do this, I've added a Reproduction\nparameter to the CBoid class that controls the creation of new flies. When enough flies\ncongregate in a flock, they can reproduce, creating a new fly boid every few seconds.\nDinner on the Go\nAs mentioned previously, feeding is a pretty straightforward affair. When a hawk or\nsparrow is hungry (in other words, its Hunger rating has decremented down to zero),\nit will look for the nearest food it sees and try to collide with it. Any hawk that suc-\ncessfully intercepts a sparrow will gain one hunger point and then check to determine\nif it's eaten enough. The sparrow, on the other hand, is immediately removed from the\nworld. Sparrows hunt flies in a similar fashion.\nSince hawks are normally faster than sparrows, and sparrows are normally faster\nthan flies, about the only thing that will prevent a given sparrow or fly from being\neaten is a failure on the part of the predator to catch its prey. Each boid will, of course,\n",
      "content_length": 3012,
      "extraction_method": "Direct"
    },
    {
      "page_number": 323,
      "chapter": null,
      "content": "334^ \n_ \nSection 3 Artificial Intelligence\nautomatically try to avoid any and all predators it sees, and so that natural motion\nwill help somewhat. Interestingly, the biggest single frustrating factor for predators are\nthe obstacles we'll be scattering about the world. Avoiding collision with them will\noften slow down a predator enough for an individual target to get away—for a while,\nanyway.\nFlocking with Teeth\nThe results of all this effort can be seen in the Flocking with Teeth demo on the CD.\nThe demo maintains the same control features of the original, with the user being\nON me a> \nabje to pan jmj zoorn as desired, turn on bounding bubbles to better visualize boid\nsight, avoidance, and cohesion distances, and so forth.\nA few hawks (the larger delta-shaped objects) prowl in a world filled with obsta-\ncles of all sizes. Groups of sparrows (the medium-sized delta-shaped objects) flit\nbetween masses of flies (the masses of pixel-sized objects), eating them nearly as fast as\nthey can reproduce. Every so often, a hawk becomes hungry and swoops towards the\nnearest flock of sparrows, causing them to scatter in all directions to avoid being\neaten. Often an obstacle will frustrate either predator or prey, preventing capture or\nescape. Scattered flocks of sparrows and flies will seek the safety of others and form\nnew flocks, and the whole cycle starts over again.\nDepending on how the demo is set up, and to some degree blind luck, most\ndemos end in one of two ways. The most likely outcome is what amounts to ecologi-\ncal disaster—the sparrows eat all the flies or the hawks eat all the sparrows. If all the\nflies die off, the sparrows also eventually die too from lack of food, and the hawks (left\nfoodless) will follow soon after. If the sparrows all die because the hawks are just a bit\ntoo good at what they do, the hawks will eventually die as well, leaving a world filled\nwith nothing but flies and obstacles. This seemed to happen quite a bit in most of\nmy tests.\nAnother possibility is a sort of stasis between the sparrows and flies. The hawks\nmight all die off dirough bad luck and not finding any sparrows to eat. If this hap-\npens, the sparrows will live on, feeding on the flies for an indefinite period. They\nmight eventually kill off flies, which puts us back into the first scenario described ear-\nlier, but a balance is also possible, with the flies reproducing just fast enough to keep\nall the sparrows fed and happy.\nIf sparrows and hawks are allowed to reproduce (not the demo default, but\nan easy exercise for the reader), just about any outcome is possible. This is the most\nrealistic way to configure the simulation, but it's also the most difficult to balance\nproperly.\nLimitations and Potential Improvements\nAlthough overall I'm fairly happy with the performance of the demo for the purposes\nof this gem, there are several improvements and enhancements that suggest them-\n",
      "content_length": 2914,
      "extraction_method": "Direct"
    },
    {
      "page_number": 324,
      "chapter": null,
      "content": "3.11 Flocking with Teeth: Predators and Prey \n335\nselves, particularly if one were to try to adopt this code for a game. Although only flies\ncan reproduce in the demo, it's a simple matter to allow both sparrows and hawks to\ndo so. Another potential improvement that could help \"close the loop\" ecology-wise\nmight be to give the flies something to feed on as well, perhaps hawk feathers.\nVision is still handled very basically, with all boids having perfect 360-degree\nvision that enables them to see infinitely in any direction. In reality, most predators\nhave rather keen and far-sighted forward vision, while most prey animals are fairly\nnear-sighted with vision to the sides (compare the wolf to the sheep, for example). It\nwouldn't be too difficult to make vision in the demo more realistic and force hawks to\nactually search for sparrows rather than simply stumbling across them, although the\nadditional overhead associated with limiting vision (line-of-sight tests, angle-of-vision\ntests, etc.) can add a lot of math overhead.\nAcknowledgments and Other Resources\nAgain, I'd like to thank Christopher Kline (Mitre Corporation) for his excellent\nmethod for computing roll/pitch/yaw (liberally adapted here), originally published in\nhis C+ + Boids implementation (available on his Web site [Kline96]). Another must-\nsee site is the one maintained by the \"father of flocking,\" Craig Reynolds\n[ReynoldsOO], where there are nearly a hundred pointers to uses of flocking in gaming\nand film, along with a huge resource of research on the topic. The author's Web site\n[WoodcockOl] also maintains a number of pointers to flocking articles and pages.\nOne reader of the original Game Programming Gems built a great litde flocking\napp that allows you to vary the influence of each steering behavior in real time\n[GrubOl]. This is a great way to study how these behaviors affect the flock on an indi-\nvidual basis, and how their combination causes the emergent behavior that makes\nflocking so interesting.\nFinally, an excellent book that addresses the topic of artificial life in general, in\naddition to discussing both flocking and boids, is Steven Levy's Artificial Life\n[Levy93].\nReferences\n[GrubOl] Grub, Tom, \"Flocking Demo,\" www.riversoftavg.com/flocking.htm,\nMarch 6, 2001.\n[Kline96] Kline, Christopher, maintains one of several excellent pages on flocking,\ntogether with many demos and sample code, at www.media.mit.edu/-ckline/\ncornellwww/boid/boids.html, August 14, 1996.\n[Levy93] Levy, Steven, Artificial Life: A Report from the Frontier Where Computers\nMeet Biology, Vintage Books, 1993.\n[Reynolds87] Reynolds, C. W. (1987) Flocks, Herds, and Schools: A Distributed Behav-\nioral Model, in Computer Graphics, 21(4) (SIGGRAPH '87 Conference Pro-\nceedings) pp. 25-34.\n[ReynoldsOO] Reynolds, Craig, maintains an extensive reference on flocking and\nsteering behavior at www.red3d.com/cwr/boids/ and has presented a wide variety\n",
      "content_length": 2928,
      "extraction_method": "Direct"
    },
    {
      "page_number": 325,
      "chapter": null,
      "content": "336 \nSection 3 Artificial Intelligence\nof papers at various conferences discussing the progress he's made in exploring\nand perfecting uses of this technology, December 6, 2000.\n[WoodcockOO] Woodcock, Steven, \"Flocking a Simple Technique for Simulating\nGroup Behavior,\" Game Programming Gems, Charles River Media, 2000.\n[WoodcockOl] Woodcock, Steven, maintains a page dedicated to game AI at\nwww.gameai.com, 2001.\n",
      "content_length": 413,
      "extraction_method": "Direct"
    },
    {
      "page_number": 326,
      "chapter": null,
      "content": "3.12\nA Generic Fuzzy State\nMachine in C++\nEric Dybsand\nedybs@ix.netcom.com\nF\nuzzy logic was ably presented in the original Game Programming Gems article\ntitled \"Fuzzy Logic for Video Games\" by Mason McCuskey [McCuskeyOO]. Like-\nwise, a generic Finite State Machine was introduced in that same book, in the article\n\"A Finite-State Machine Class\" written by me [DybsandOO]. This gem will serve to\nmarry these two concepts into a generic Fuzzy State Machine (FuSM) C++ class that\nyou can use in your games, and to provide you with an additional overview of fuzzy\nlogic, as well as some ideas on how to use fuzzy logic in your games.\nFirst, let's briefly review the FAQ definition of fuzzy logic:\n\"Fuzzy logic is a superset of conventional (Boolean) logic that has been\nextended to handle the concept of partial truth—truth values between\n\"completely true\" and \"completely false\" [FAQ97].\"\nThus, instead of the states of ON and OFF, or TRUE and FALSE, a fuzzy state\nmachine can be in a state of almost ON or just about OFF, or partially TRUE or sort\nof FALSE. Or even both ON and OFF or TRUE and FALSE, but to various degrees.\nWhat does this mean to a game developer? It means that a Non-Player Character\n(NPC), for instance, does not have to be just AMD at a player, but that the NPC can\nbe almost MAD, or partly MAD, or really MAD, or raging MAD at a player. In other\nwords, by using a FuSM (implementing fuzzy logic), a game developer can have mul-\ntiple degrees of state assigned to a character (or a concept within the game—more on\nthis later). This could also mean that states in a game do not have to be specific and\ndiscrete (often referred to in the fuzzy logic world as crisp), but can be, well, fuzzy (less\ndetermined). The real advantage to this is discussed in the next section.\nStatus in a FuSM is typically represented internally using the range of real num-\nbers from 0.0 to 1.0; however, that is not the only way we can represent a fuzzy value.\nWe can choose literally any set of numbers, and consider them fuzzy values. Continu-\ning the NPC attitude example [DybsandOO], let us consider how to maintain the \"dis-\nlike portion\" of the attitude of an NPC toward a player within a FuSM. We could use\nthe range of integers from 1 to 25 to indicate that an NPC has a variable feeling of\n337\n",
      "content_length": 2300,
      "extraction_method": "Direct"
    },
    {
      "page_number": 327,
      "chapter": null,
      "content": "338 \nSections Artificial Intelligence\n99\nThese values could even overlap\ni \nV\n1 \nAnnoyed > 30\nFIGURE 3.12.1 A) Fuzzy values for dislike attitudes toward player. B) Fuzzy values that\noverlap.\nANNOYANCE toward a player, and the range of integers from 26 to 50 may reflect an\nNPC's variable feeling of MAD toward a player, while the range of integers from 51 to\n99 may indicate the NPC's variable feeling of RAGE. Thus, within each type of atti-\ntude toward a player, the NPC may possess various degrees of dislike such as\nANNOYANCE, MAD or RAGE (Figure 3.12.1).\nBefore we leave this brief introduction to FuSMs, let's clear up one common mis-\nconception often associated with fuzzy logic: there is no specific relationship between\nfuzzy values and probability. Fuzzy logic is not some new way to represent probability,\nbut instead represents a degree of membership in a set. In probability, the values must\nadd up to 1.0 in order to be effective. Fuzzy logic values have no such requirement (note\nthe overlap example just presented). This does not mean that fuzzy logic values can't\nhappen to add up to 1.0, it just means that they don't have to for a FuSM to be effective.\nWhy Use a FuSM In a Game?\nIn this author's opinion, the number-one reason to use FuSMs in a computer game is\nthat it is an easy way to implement fuzzy logic, which can broaden the depth of rep-\nresentation of the abstract concepts used to represent the game world and the rela-\ntionships between objects in the game.\nIn essence, to increase gameplay!\nHow do FuSMs increase gameplay, you ask? FuSMs increase gameplay by provid-\ning for more interesting responses by NPCs, by enabling less predictable NPC behav-\nior, and by expanding the options for choices to be made by the human player.\nThus, a player does not encounter an NPC that is just MAD or not MAD about\nbeing attacked by the player. Instead, the player must deal with an NPC that can be\n",
      "content_length": 1920,
      "extraction_method": "Direct"
    },
    {
      "page_number": 328,
      "chapter": null,
      "content": "3.12 A Generic Fuzzy State Machine in C++ \n339\nvarious degrees of being MAD. This broader array of considerations increases game-\nplay by adding to the level of responses that can be developed for the NPC, and seen\nby the human player.\nAnother effect of adding FuSMs to computer games is to increase the replayabil-\nity of the game. By broadening the range of responses and conditions that the player\nmay encounter in given situations during the game, the player will be more likely to\nexperience different outcomes in similar situations.\nHow To Use FuSMs in a Game\nActually, various forms of FuSMs have been used a lot in computer games!\nOne example of where a FuSM has been used in computer games is for the health\nor hit points of an NPC or agent. Instead of the agent simply being healthy or dead\n(finite states), using a range of hits points can reflect the agent being anything from\ncompletely healthy to partially healthy to almost dead to totally dead (fuzzy states).\nAnother example of using a FuSM in a computer game can be found in the control\nprocess for accelerating or braking an Al-controlled car in a racing game. Using a\nFuSM in this case would provide various degrees of acceleration or braking to be cal-\nculated in lieu of the finite states of THROTTLE-UP or THROTTLE-DOWN and\nBRAKE-ON or BRAKE-OFF actions. And as our ongoing example of representing an\nattitude shows, a FuSM is perfect for representing NPC emotional status and attitude\ntoward the player or other NPCs.\nApplying fuzzy logic to states in a computer game is relatively straightforward, as\nnoted in the previous examples. Those decision processes that can be viewed as having\nmore than two discrete outcomes are perfect candidates for the application of fuzzy\nlogic, and there are many of those processes to be found.\nNow let's consider putting fuzzy logic into a generic C++ class, a FuSM.\nReview of Game Programming Gems' Generic\nFinite State Machine in C++\nThe original Generic FSM in C++ [DybsandOO] consisted of two classes: FSMclass\nand FSMstate. The FSMclass class object encapsulated the actual finite state machine\nprocess, maintained the current state of the FSM, supported the container for the var-\nious FSMstate class objects, and provided control for the state transition process.\nThe FSMstate class object encapsulated a specific state and maintained the arrays\nof input and output states for which a transition could be performed for the state of\nthe object.\nInputs to the FSM were presented to FSMclass: :StateTransition(), which\ndetermined the appropriate FSMstate object that was to handle the input (based on\nthe current state), and then the input was passed to FSMstate:: GetOutput () to obtain\nthe new output state.\n",
      "content_length": 2724,
      "extraction_method": "Direct"
    },
    {
      "page_number": 329,
      "chapter": null,
      "content": "340 \nSections Artificial Intelligence\nThe new output state was returned to the FSM user process by FSMclass::State -\nTransition () and was also made the new current state of the FSMclass object. Thus,\nthe generic FSM provided a crisp and discrete state transition in response to an input.\nAdapting the Generic FSM in C++ to FuSM in C++\nThere are only a few changes needed to transform the Generic FSM into a FuSM. The\nfirst is to add support to the FSMclass class object for multiple current states. The next\nchange is to modify the FSMstate class to support degrees of being in a state. Finally, we\nneed to modify the state transition process within both class objects to support a tran-\nsition to multiple states and a degree of being in the new state. During this refinement\nprocess, we will morph FSMclass into FuSMclass and the FSMstate class into the\nFuSMstate class.\nThe reader is invited to review the Fuzzy/Finite State Machine project found on\n,-ke companion CD-ROM, and to follow along in that project code as the various\nclasses are referenced.\nThe adaptation process begins with the FuSMclass class that, while similar to\nFSMclass, is now capable of supporting multiple current states (the new FuSMclass\nand FuSMstate class members are shown in bold.) This capability is provided by the\nFuzzyState_List m_list member, which is an STL list object that contains pointers\nto FuSMstate objects. A pointer to any active fuzzy state (based on the current input\nvalue) object is saved in this list. This way, multiple current states can be supported.\nAs in FSMclass before, FuSMclass also maintains an STL map object (the Fuzzy -\nState_Map m_map member) for containing pointers to all possible FuSMstate objects\nthat could be considered by FuSMclass.\nWe continue the adaptation process by developing an access member function\n(called GetNextFuzzyStateMember()) that will provide an accessing service to the\nFuSMclass object. The GetNextFuzzyStateMember() member function maintains a\npointer to the next FuSMstate pointer in the FuzzyStateJ-ist m_list, so that all\nactive current states can be accessed by processes outside of FuSMclass. Thus, this ser-\nvice is how you can get access to the active current states by your program. By contin-\nuing to call GetNextFuzzyStateMember() until you receive a NULL pointer, your\nprogram can determine all the active fuzzy states.\nThe next step in the adaptation process is to modify the FuSMstate class to sup-\nport various degrees of membership. This support is provided by adding the new\nmember variables of int m_iLowRange and int m_iHighRange. For simplicity, this\ndesign views the fuzzy membership range as whole positive numbers, and could be\neasily adapted to view membership as a set of real numbers. For convenience, this\nadaptation also maintains two additional attributes of the FuSMstate object: the value\nof membership in the set for this FuSMstate object (int m_iValueOf Membership), and\nthe degree of membership in the set (int m_iDegreeOfMembership).\nNotice that the biggest difference between the finite state object (FSMstate) and\nour new fuzzy state object (FuSMstate) is that a state transition array is no longer\n",
      "content_length": 3180,
      "extraction_method": "Direct"
    },
    {
      "page_number": 330,
      "chapter": null,
      "content": "3.12 A Generic Fuzzy State Machine in C++ \n341\nneeded. This is because in fuzzy logic, it is possible to be in one or more states at the\nsame time; while in finite logic, it is possible only to be in one state at a time.\nConcluding the adaptation process involves modifying the state transition\nprocess in both the FuSMclass and FuSMstate objects to support the possibility of\nmultiple current states and to support various degrees of membership within a given\nstate. For FuSMclass, this means modifying StateTransition() to process the Fuzzy-\nState_Map m_map member containing all possible states, giving each FuSMstate object\nan opportunity to effect a transition based on the accumulated input value (the int\nm_iCurrentInput member found in the FuSMclass). Those FuSMstate objects that do\ntransition have their pointers saved off in the FuzzyState_List m_list member, thus\nindicating that the FuSMstate object is an active current state.\nFor the FuSMstate class object, the adaptation process involves replacing FSM-\nstate: :GetOutput () (from the FSM) with a new transition function. The new FuSM-\nstate: :DoTransition() member function accepts the input value maintained by\nFuSMclass and considers the degree of membership this input value represents. If\nmembership within the fuzzy state exists, the member function returns a TRUE and\nmaintains the status of membership for any future access.\nThis completes the adaptation process. For more details and the code listings, see\ntne FuSM project on the companion CD-ROM.\nNow Fuzzy Up Your Games!\nUsing the FuSMclass and FuSMstate classes as a guide, you are now ready to start mak-\ning your games more fuzzy! Doing so will enrich the gameplay experience of your\nplayers and broaden your own understanding of how to deploy one of the more flexi-\nble forms of artificial intelligence tools available to game developers.\nReferences\n[DybsandOO] Dybsand, Eric, \"A Generic Finite State Machine in C++,\" Game Pro-\ngramming Gems, Charles River Media, 2000.\n[FAQ97] \"What is fuzzy logic?\" FAQ: Fuzzy Logic and Fuzzy Expert Systems 1/1\nMonthly Posting, www.faqs.org/faqs/fuzzy-logic/partl/, 1997.\n[McCuskeyOO] McCuskey, Mason, \"Fuzzy Logic for Video Games,\" Game Program-\nming Gems, Charles River Media, 2000.\n",
      "content_length": 2253,
      "extraction_method": "Direct"
    },
    {
      "page_number": 331,
      "chapter": null,
      "content": "3.13\nImploding Combinatorial\nExplosion in a Fuzzy System\nMichael Zarozinski, Louder Than\nA Bomb! Software\nmichaelz@LouderThanABomb.com\nF\nuzzy logic, when you come right down to it, is just a bunch of \"if-then\" state-\nments. One of the biggest problems in using fuzzy logic is that the number of \"if-\nthen\" statements grows exponentially as you increase the number of fuzzy sets you\n\"if\" together. This is called combinatorial explosion, and can make fuzzy systems slow,\nconfusing, and difficult to maintain. In games, speed is essential, and combinatorial\nexplosion can make the use of fuzzy logic impractical.\nFor an introduction to fuzzy logic see \"Fuzzy Logic for Video Games\" by Mason\nMcCuskey in the first Game Programming Gems [McCuskeyOO]. For this gem, we'll\nprovide some definitions, as there is little agreement on fuzzy logic terminology.\n• Variable. A fuzzy variable is a concept such as \"temperature,\" \"distance,\" or\n\"health.\"\n• Set. In traditional logic, sets are \"crisp\"; either you belong 100 percent to a set or\nyou do not. A set of tall people may consist of all people over six feet tall, anyone\nless than six feet is \"short\" (or more appropriately, \"not tall\"). Fuzzy logic allows\nsets to be \"fuzzy\" so anyone over six feet tall may have 100-percent membership\nin the \"tall\" set, but may also have 20-percent membership in the \"medium\nheight\" set.\nThe Problem\nTable 3.13.1 shows the effects of combinatorial explosion as more variables and/or\nsets are added to the system.\nThis exponential growth in the number of rules can bring any system to its knees\nif every possible rule must be checked on each pass.\n342\n",
      "content_length": 1631,
      "extraction_method": "Direct"
    },
    {
      "page_number": 332,
      "chapter": null,
      "content": "3.13 Imploding Combinatorial Explosion in a Fuzzy System \n343\nTable 3.13.1 The Effects of Combinatorial Explosion\nNumber of Variables \nSets Per Variable \nNumber of Rules\n2\n3\n4\n5\n6\n7\n8\n9\n10\n5\n5\n5\n5\n5\n5\n5\n5\n5\n52 =\n53 =\n54 =\n55 =\n56 =\n57 =\n58 =\n59 =\n5\n10 =\n25\n125\n625\n3,125\n15,625\n78,125\n390,625\n1,953,125\n= 9,765,625\nThe Solution\nWilliam E. Combs, an engineer at Boeing, developed a method for turning the expo-\nnential growth shown above into linear growth known, appropriately enough, as the\n\"Combs Method.\" This results in a system with 10 variables and 5 sets per variable\nhaving only 50 rules, as opposed to 9,765,625 rules.\nIt is important to note that the Combs Method is not an algorithm for convert-\ning existing \"if-then\" rules to a linear system. You should start from the bottom up,\ncreating rules that fit in with the Combs Method.\nIf you're interested in the theory behind the Combs Method, see the proof at the\nend of this gem.\nThe Real World\nTo bring this theory into the real world, we'll look at a trivial system for calculating\nthe aggressiveness of a unit in a game. For now, we'll consider a one-on-one battle with\nthree variables, ignoring any surrounding units (friend or foe):\n• Our health\n• Enemy health\n• Distance between us and the enemy\nThe health variables have three sets: Near death, Good, and Excellent.\nThe distance variable has three sets: Close, Medium, and Far.\nFinally, our output (aggressiveness) has three sets: Run away, Fight defensively,\nand All-out attack!.\nTraditional Fuzzy Logic Rules\nIf we were using a traditional fuzzy logic system, we'd start creating rules in a spread-\nsheet format as shown in Table 3.13.2.\n",
      "content_length": 1658,
      "extraction_method": "Direct"
    },
    {
      "page_number": 333,
      "chapter": null,
      "content": "Section 3 Artificial Intelligence\nTable 3.13.2 Some Traditional Fuzzy Logic Rules\nOur Health\nExcellent\nExcellent\nExcellent\nExcellent\nExcellent\nExcellent\nExcellent\nExcellent\nExcellent\nEnemy Health\nExcellent\nExcellent\nExcellent\nGood\nGood\nGood\nNear death\nNear death\nNear death\nDistance\nClose\nMedium\nFar\nClose\nMedium\nFar\nClose\nMedium\nFar\nAggressiveness\nFight defensively\nFight defensively\nAll-out attack!\nFight defensively\nAll-out attack!\nAll-out attack!\nAll-out attack!\nAll-out attack!\nAll-out attack'\nGood\nGood\nClose\nFight defensively\nGood\nNear death\nClose\nFight defensively\nNear death\nNear death\nNear death\nExcellent\nExcellent\nExcellent\nClose\nMedium\nFar\nRun away\nRun away\nFight defensively\nNote that Table 3.13.2 only shows 14 of the 27 possible rules. While a trivial\nexample such as this is fairly manageable, combinatorial explosion quickly conies into\nplay. In a game, we may need to take into account more variables such as the relative\nhealth of our forces and the enemy forces that may join in the battle. If we were to\nrepresent these two additional variables (bringing the total number of variables to\nfive), the table would grow from 27 rules to 243 rules. This can quickly get out of\nhand. Fortunately, the Combs Method only needs 15 rules to deal with the same five\nvariables.\nCombs Method of Fuzzy Logic Rules\nBuilding rules in the traditional system, we look at how the combination of input sets\nrelates to the output. To build rules using the Combs Method, we look at each indi-\nvidual set's relationship to the output and build the rules one variable at a time (Table\n3.13.3).\nIn a Combs Method system, it is recommended that all variables have the same\nnumber of sets as the output variable. This is not an absolute rule, but it gives each\noutput set the chance to be paired with an input set for each variable.\n",
      "content_length": 1828,
      "extraction_method": "Direct"
    },
    {
      "page_number": 334,
      "chapter": null,
      "content": "3.13 Imploding Combinatorial Explosion in a Fuzzy System\n345\nTable 3.13.3 Each Individual Set's\nRelationship to the Output\nOur health\nExcellent\nAggressiveness\nAll-out attack!\nGood\nFight defensively\nNear death\nRun away\nEnemy health\nExcellent\nAggressiveness\nRun away\nGood\nFight defensively\nNear death\nAll-out attack!\nDistance\nClose\nAggressiveness\nFight defensively\nMedium\nFight defensively\nFar\nAll-out attack!\nConcrete Example\nTo test the system, we'll use the following values:\n• Our health: 76.88\n• Enemy health: 20.1\n• Distance: 8.54\nFigures 3.13.1 through 3.13.3 show the \"Degree of Membership,\" or DOM, for\nthe input values in the system (note that the DOMs for a variable do not have to sum\nto 100 percent).\nr.O;\nFIGURE 3.13.1 Our Health>r a value of 76.88. Near death:\nExcellent: 53%.\n",
      "content_length": 790,
      "extraction_method": "Direct"
    },
    {
      "page_number": 335,
      "chapter": null,
      "content": "346\nSection 3 Artificial Intelligence\nfear, death\n1:0\nFIGURE 3.13.2 Enemy Healthy»rd value of 20.1. Near death: 60%, Good: 17%,\nExcellent: 0%.\nFigures 3.13.1 through 3.13.4 were taken from the Spark! fuzzy logic editor,\nwhich allows you to visually create a fuzzy logic system, integrate it into your game,\nand change the AI in real time without having to recompile.\nFIGURE 3.13.3 Distance fir a value of 8.54. Close: 83%, Medium: 0%, Far:\nConcrete Example with the Traditional System\nUsing the rules we created earlier, the rules listed in Table 3.13.4 are activated in the\ntraditional system.\nThe DOM of the input sets are ANDed together to get the output set's DOM. The\nANDing is logically equivalent to taking the MINIMUM of the three input values.\nThe denazification method we're using—center of mass—takes the MAXIMUM\nvalue for the output set then finds the center of mass for the output sets (Figure\n3.13.4).\n",
      "content_length": 916,
      "extraction_method": "Direct"
    },
    {
      "page_number": 336,
      "chapter": null,
      "content": "3.13 Imploding Combinatorial Explosion in a Fuzzy System\n347\nTable 3.13.4 These Rules Are Activated in the Traditional System\nOur Health\nEnemy Health\nDistance\nAggressiveness\nExcellent (53%)\nExcellent (53%)\nGood (18%)\nGood (18%)\nGood (17%)\nNear death (60%)\nGood (17%)\nNear death (60%)\nClose (83%)\nClose (83%)\nClose (83%)\nClose (83%)\nFight defensively (17%)\nAll-out attack! (53%)\nFight defensively (17%)\nFight defensively (18%)\n:.AI.oyl\n.23\no;6o\nSO\nm I\nFIGURE 3.13.4 Traditional system output. Fight defensively: 18%; All-out attack: 53%;\nAggressiveness: 68.66.\nConcrete Example Using the Combs Method\nUsing the same input values, the Combs Method rules are listed in Table 3.13.5.\nThe Combs Method result of 60.39 is not exactly the same as the traditional\nmethod (68.66), but we wouldn't expect it to be as we're using a different inference\nmethod. The Combs Method is ORing the values together, which is the same as\ntaking the MAXIMUM (Figure 3.13.5). Traditional fuzzy logic ANDs values\ntogether, which takes the MINIMUM; hence, the difference in the fight defensively\noutput sets.\nNote that (in this case) if we took the MINIMUM of the output sets (and there\nis no rule saying we can't) we would get the exact same result as the traditional fuzzy\nlogic method. This is a result of the rules we selected for the Combs Method. Since\nthere is not an algorithm to convert traditional fuzzy logic rules to the Combs\nMethod, we cannot say that by simply taking the MINIMUM you will always get the\nsame results as in the traditional method.\nThe Proof\nIt is not essential that you understand why the Combs Method works in order to use\nit. Formal logic can be confusing, so this proof is provided for the reader who wishes\nto have a deeper understanding of the theory behind the Combs Method. The Combs\n",
      "content_length": 1797,
      "extraction_method": "Direct"
    },
    {
      "page_number": 337,
      "chapter": null,
      "content": "348\nSection 3 Artificial Intelligence\nTable 3.13.5 Combs Method system output. Fight defensively: 83%;\nAll out attack: 53%; Aggressiveness: 60.39.\nOur Health\nExcellent (53%)\nGood (18%)\nEnemy Health\nGood (17%)\nNear death (60%)\nDistance\nClose (83%)\nAggressiveness\nAll-out attack! (53%)\nFight defensively (18%)\nAggressiveness\nFight defensively (17%)\nFight defensively (60%)\nAggressiveness\nFight defensively (83%)\niJilli.iiisl'-spgs'^?!\n\"\"H *\nft 00\nFIGURE 3.13.5 Combs Method system output. Fight defensively: 83%, All out attack:\n53%. Aggressiveness: 60.39.\nMethod is based on the fact that the logical proposition (p and q) then r is equivalent\nto (p then r) or (q then r).\nSince fuzzy logic is a superset of formal logic, we can ignore \"fuzziness\" and just\nprove the equivalence of the Combs Method to the traditional method. In Table\n3.13.6, p and q are antecedents and r is the consequence. The antecedents are state-\nments such as \"if Jim is tall\" or \"if Jim is healthy.\" The consequence is a potential\nresult such as \"Jim can play basketball\".\nThis proof is straightforward, except for the x thenjy type clauses. These are stan-\ndard formal logic propositions, but their truth table is confusing—especially when x\nand y are false but the proposition is true. See [aiGuruOl] for some examples that will\nhelp clarify this proposition's truth table.\n",
      "content_length": 1350,
      "extraction_method": "Direct"
    },
    {
      "page_number": 338,
      "chapter": null,
      "content": "3.13 \nImploding Combinatorial Explosion in a Fuzzy System\nTable 3.13\nP..__J7 _.,.\nT \nT\nT \nT\nT \nF\nT \nF\nF \nT\nF \nT\nF \nF\nF \nF\n349\n.6 Antecedents and Consequences\npandq\nT\nT\nF\nF\nF\nF\nF\nF\nT \nIp and q) then r\nT \nT\nF\nT\nF\nT\nF\nT\nF\nF\nT\nT\nT\nT\nT\nT\np then r\nT\nF\nT\nF\nT\nT\nT\nT\nq then r \n(p then r) or (Q then r)\nT \nT\nF\nT\nT\nT\nF\nT\nT\nF\nT\nT\nT\nT\nT\nT\nIf you need visual proof, the Venn diagrams are shown in Figures 3.13.6 and\n3.13.7. Since Venn diagrams can only show AND, OR, and NOT relationships, the\nfollowing conversions are made by material implication:\n• Traditional Logic: (p and q) then r is equivalent to (not (p and q)) or r\n• Combs Method: (p then r) or (q then r) is equivalent to ((not/>) or r) or ((not q)\nor r)\np and q \nnot (p and q) \n(not (p and q)) or r\nFIGURE 3.13.6 Venn diagram for Traditional Logic.\n(not p) or r \n(not q) or r \n((not p) or r) or ((not q) or r)\nFIGURE 3.13.7 Venn diagram for Combs Method.\n",
      "content_length": 904,
      "extraction_method": "Direct"
    },
    {
      "page_number": 339,
      "chapter": null,
      "content": "350 \nSections Artificial Intelligence\nConclusion\nIf forced to make a choice between fast and intelligent game AI, fast will win almost\nevery time (ignoring turn-based games). The Combs Method allows you to create AI\nthat is not only fast, but also complex enough to result in rich, lifelike behavior, thus\nproviding a more engaging experience for the player.\nNext time you're faced with creating a complex behavior system, give the Combs\nMethod a try. You may be surprised by the depth of the behavior you can get with\nsuch a small number of rules.\nReferences\n[aiGuruOl] \nZarozinski, \nMichael, \n\"if p \nthen \nq?\" \navailable \nonline at\nwww.aiGuru.com/logic/if_p_then_q.htm, March 5, 2001.\n[Andrews97] Andrews, James E., \"Taming Complexity in Large-Scale Fuzzy Sys-\ntems,\" PC AI (May/June 1997): pp.39-42.\n[Combs99] Combs, William E., The Fuzzy Systems Handbook 2nd Ed, Academic\nPress, 1999.\n[McCuskeyOO] McCuskey, Mason, \"Fuzzy Logic for Video Games,\" Game Program-\nming Gems, Charles River Media, 2000.\n",
      "content_length": 1002,
      "extraction_method": "Direct"
    },
    {
      "page_number": 340,
      "chapter": null,
      "content": "3.14\nUsing a Neural Network in a\nGame: A Concrete Example\nJohn Manslow, Neural\nTechnologies Limited\njfm96r@ecs.soton.ac.uk\nT\nhe original Game Programming Gems book included a contribution that gave a\nbroad and comprehensive overview of the field of neural networks [LaMotheOO].\nThis gem complements that by providing a concrete illustration of the application of\none of the most useful and widely applied neural networks, the multiplayer percep-\ntron (MLP). In so doing, it describes how to identify problems that can be solved by\nthe MLP, and highlights the steps required to produce a solution.\nThe Game \n_._\nTo provide a concrete illustration of the application of the MLP for this gem, it was\nnecessary to construct an application that was sufficiently simple that the role of the\nneural network was clear, but not so trivial as to have any obvious alternative solution.\nThe application that was settled upon was a simple tank game where two tanks are\nplaced on a randomly generated side-view landscape, with the leftmost tank con-\ntrolled by the player, and the rightmost tank by the computer.\nThe tanks take turns firing at each other, and the first one to score a hit is\ndeclared the winner. Each tank aims by adjusting the inclination of its barrel—a task\nmade especially difficult because the tank's shell decelerates as it travels (due to drag)\nand is affected by wind (which, for simplicity, maintains a constant speed and direc-\ntion for the duration of the shell's flight). The main challenge for the AI is thus how\nto set the inclination of its tank's barrel to hit the enemy tank. This gem will show\nhow an MLP can be taught, by example, to solve this problem.\nThe Multilayer Perceptron\nThe MLP is a type of neural network that became popular in the mid-1980s as a\nresult of the discovery of a particularly efficient way of teaching it. Since then, the\ntechnique has grown rapidly in popularity and is currently one of the most widely\n351\n",
      "content_length": 1954,
      "extraction_method": "Direct"
    },
    {
      "page_number": 341,
      "chapter": null,
      "content": "352\nSection 3 Artificial Intelligence\napplied neural network architectures in industry, and has even been used in a number\nof games (such as Codemasters' Colin McRae Rally 2.0).\nAlthough more advanced techniques are now common in academia, the MLP\nremains popular because it is one of the easiest to understand, easiest to code, easiest\nto apply, and offers robust performance even in the hands of relatively inexperienced\nusers. The MLP is thus a good starting point for people new to the field of neural net-\nworks and a powerful tool for more experienced users.\nA neural network such as an MLP is really just a complex nonlinear function with\na number of adjustable parameters that can be changed to control its shape. The\nprocess of teaching the network (or training it, as it is more commonly called) is sim-\nply one of adjusting its parameters so that the function it represents takes on a desired\nshape. Although polynomials and splines can be used to address similar problems to\nthe MLP, the structure of the MLP makes it particularly robust.\nThe shape of the function to be learned is indicated by pairs of input-output sam-\nples and thus neural network training consists of nothing more than curve fitting-—\nadjusting the parameters in the network so that it fits roughly tJirough the samples.\nThis process will be familiar to many readers from science class, where it was often\nnecessary to draw smooth curves through data collected from experiments.\nSince neural networks often represent quite complex equations, they are fre-\nquently visualized in terms of directed graphs. For example, Equation 3.14.1 is the\nformula for the output j/ of an MLP with one linear output, N inputs, Xj to x//, and M\nhidden neurons, and Figure 3.14.1 is its graphical representation. Although the MLP\nis represented by a directed graph, arrows are usually omitted from the network dia-\ngram since information flow is always in the direction of input to output.\nInput neurons\nHidden neurons\nMN\nM\nOutput neuron\nFIGURE 3.14.1 The graphical representation of the MLP in Equation 3.14.1. The\nellipses indicate that the number of inputs and hidden neurons can vary.\n",
      "content_length": 2153,
      "extraction_method": "Direct"
    },
    {
      "page_number": 342,
      "chapter": null,
      "content": "3.14 Using a Neural Network in a Game: A Concrete Example \n353\ny-\n(3.14.1)\nThe adjustable parameters of the network are the w's (weights) and b's (biases),\nthe distinction being that weights connect neurons together, whereas the biases excite\nor inhibit individual neurons even in the absence of other activity in the network. The\nbiases are not shown in Figure 3.14.1 since each can be considered to be part of the\ninternal make-up of an individual neuron. A detailed examination of the structure of\nneural networks is given in [LaMotheOO] and [Haykin94] and will not be repeated\nhere.\nFor the purposes of diis gem, it is sufficient to understand that an MLP represents\nthe function given in Equation 3.14.1, and that that function will be used to calculate\ndie inclination of die AI tank's barrel that is required to hit die player's tank. The w's\nand b's in Equation 3.14.1 are adjustable parameters that we can use to fit the MLP to\na set of samples diat illustrate how the inclination of the barrel should be set, and that\nthose parameters are found using some curve-fitting procedure, otherwise known as\ntraining.\nSo, in order to train the MLP, we need a set of samples that consists of input-\noutput pairings that are examples of how the AI tank's barrel should be set to hit the\nplayer's tank. Clearly, from the problem we're trying to solve, we want the network's\noutput to be the inclination of die AI tank's barrel, but what should die inputs be?\nThis often complex question is considered in the next section.\nInput Selection\nBefore the input-output samples that are required to train the network can be col-\nlected, it is necessary to decide what inputs the MLP is going to need. Clearly, the\ninputs must contain the information necessary for die MLP to calculate the correct\noutput; in diis case, die inclination of the tank's barrel that is required to hit the\nplayer's tank.\nThe selection of inputs is often difficult in practice, since a wide range of informa-\ntion can usually be extracted from the game world, and the problem being solved is\noften too complex or poorly understood to specify exactly what information is useful.\nIn this case, much time can be spent training many different networks with different\ncombinations of input variables to see which perform best. To minimize the effort\nrequired to find good combinations, the following guidelines should be followed:\n• Use prior knowledge about the problem you're trying to solve. Make educated\nguesses about what information in die game world is likely to be relevant. If you\n",
      "content_length": 2554,
      "extraction_method": "Direct"
    },
    {
      "page_number": 343,
      "chapter": null,
      "content": "354 \nSection 3 Artificial Intelligence\nthink the network output should depend on a particular function of variables,\nadd that function into the set of network inputs.\n• Abstract variables derived as a function of much simpler ones often provide more\nprecise information than any of their constituent parts. For example, in a strategy\ngame, a single indicator of enemy strength may be more useful than lots of indi-\nvidual indicators relating to different aspects of it.\n• Use variables that provide as different information about the game world as pos-\nsible, because this lets you convey the same amount of information with fewer\ninputs. For example, no benefit would be gained in giving the relative positions of\nthe players tank and the AI tank in both polar and Cartesian coordinates since\nthey contain no unique information.\n• Try using combinatorial search algorithms to look for good combinations of\ninputs. For example, forward selection takes a large set of candidate inputs and\nrepeatedly adds single inputs to the network, at each stage adding the one that\nimproves performance the most. Such techniques require minimal human inter-\nvention, but are slow and may fail to find the best combination.\nAlthough it is tempting to avoid the laborious process of input selection by pro-\nviding the network with access to all variables that may be of relevance, this is likely to\nresult in a network that performs poorly and in unpredictable ways. Input selection is\nthe most labor-intensive part of developing a neural network application, and finding\na small set of inputs that is rich in relevant information is crucial to success.\nFortunately, our prior knowledge is sufficient to say exactly what information is\nrequired to work out the inclination of the AI tank's barrel—the displacement\nbetween the tanks (expressed, say, as two inputs, x-displacement and^-displacement),\nand the wind speed and direction (expressed as a single signed input). The drag on the\nshell is fixed, and hence the network does not need to be told the strength of drag, but\nwill learn its effect during training. Now that it has been decided what inputs to use,\nit is possible to collect the samples that will be used during training.\nCollecting Data\nThe simplest and most obvious way to generate samples that show how to set the\ninclination of the AI tank's barrel is for a player to control the AI tank, and to record\nthe selected input variables (relative positions of the tanks and wind speed) and the\ninclination of the AI tank's barrel every time the player controlling the AI tank scores\na hit. This process is repeated until a sufficiently large set of samples is available for\ntraining. Since a human player typically hits the enemy tank only in around one in\nfive shots, the many hundreds or thousands of samples required for training can take\na long time to collect.\nTo generate the samples used in this gem, the data collection process was auto-\nmated by performing simple random searches for the correct inclination. This was\ndone by setting the AI tank's barrel to random inclinations until, by chance, it scored\n",
      "content_length": 3112,
      "extraction_method": "Direct"
    },
    {
      "page_number": 344,
      "chapter": null,
      "content": "3.14 Using a Neural Network in a Game: A Concrete Example \n355\na hit. At this point, the relative positions of the tanks, the wind speed, and the incli-\nnation that achieved the hit were recorded, and the process repeated for new, ran-\ndomly placed tanks and a random wind speed.\nAlthough this was highly inefficient, it required no human intervention and was\nleft running until a sufficiently large data set had been generated. In addition, the\nsimulation of the game world need not be run at normal speed and may be acceler-\nated by, for example, disabling rendering, provided that this does not change its\nbehavior. Overnight, this process achieved around 1200 hits and hence created a data\nset of roughly 1200 samples.\nOne important question that needs to be asked when collecting data is, \"How\nmuch data should I collect?\" Unfortunately, there is no simple answer to this, because\nit depends on the complexity of the problem you're trying to solve. In practice, pro-\nvided that the number of hidden neurons is kept small (the 10 used in this gem would\nnormally be considered quite a large number), good performance can be achieved\nwith as few as 107 training samples for a network with 7 inputs.\nOne important hazard in developing neural network solutions is that the last-\nminute tweaking of a game engine that is often done to fine-tune game play can, if it\nchanges the behavior of the game world, cause the neural network to perform poorly.\nThis can be overcome by repeating the data collection and training processes to pro-\nduce a new set of parameters for the network. Provided that the changes in the behav-\nior of the game weren't too drastic, the difficult problem of input selection will not\nnormally have to be repeated. Now that we've decided what the network is going to\ncontrol and the inputs it needs, and we've collected some training data to show it\nwhat to do, we're ready to train it.\nTraining the MLP\nAs has already been described, the MLP is a nonlinear function that is fit to a series of\nsamples by adjusting its parameters. This training process is achieved by using an\noptimization algorithm to search for the parameters that minimize a measure of the\nerror with which the MLP reproduces each output sample given their associated\ninput. The mean squared error is the most commonly used error measure and is cal-\nculated from the sum of the squares of the differences between the MLP s outputs and\nthe corresponding outputs in the samples, divided by the number of samples.\nAlthough the gradient descent optimization algorithm is usually used to fit an\nMLP to the training samples, this article uses a rarely applied technique called the\nperturbation search because it is easier to code, easier to understand, and easier to\napply (for example, it is guaranteed to be stable). In addition, the perturbation search\ndoes not require gradient information,\n• Making it easy to experiment with a wide range of network structures, nonlinear-\nities, and error functions.\n• Eliminating common bugs that result from the incorrect calculation of gradient\ninformation or propagation of that information through the network structure.\n",
      "content_length": 3151,
      "extraction_method": "Direct"
    },
    {
      "page_number": 345,
      "chapter": null,
      "content": "356 \nSection 3 Artificial Intelligence\n• Allowing integer versions of networks (aimed at low-end platforms) to be opti-\nmized directly, avoiding some spurious behaviors that can result from the conver-\nsion of floating-point networks to integer form.\n• Permitting the inclusion of discontinuous functions in the network.\nThe basic perturbation search can be summarized as follows: Measure die perfor-\nmance of the MLR Perturb the MLP's parameters by adding a small amount of\nrandom noise to each one, and remeasure its performance. If its performance deterio-\nrated, restore the parameters to dieir original values. Repeat this process until some\nstopping criterion is met.\nSince all of the techniques that can be used to train an MLP will indefinitely\nimprove its performance (if only incrementally), some decision must be made as to\nwhen to stop training. To this end, the MLP's performance should periodically be\nevaluated in the game, and training should stop either when the measured perfor-\nmance is adequate, or when further training fails to improve performance.\nWhen evaluating the performance of the MLP in the game, great care must be\ntaken to exercise the game in a way that is representative of how the game will actually\nbe played. This ensures that the environment that the MLP is presented with during\nthis testing phase is similar to the one that it will encounter once the game has\nshipped, and hence guarantees that the measured performance is a useful guide to the\nhow the MLP will perform in the final product. If the MLP's performance in the\ngame fails to reach a useful level, consider the following causes:\n• The optimization algorithm has hit a plateau or a local minimum [Bishop95].\nTry restarting training from a random set of parameters.\n• The input samples contain insufficient information about their associated out-\nputs for the network to reproduce them. Repeat the input selection process to\nfind new inputs that contain more relevant information.\n• The network is too simple to learn the relationship between the inputs and out-\nputs in die sample data. Consider transformations of the inputs that might sim-\nplify the relationship, or increase the number of hidden neurons in the network\n(but keep them to an absolute minimum).\n• The samples are not representative of the environment that the network encoun-\nters in game. The behavior of the game world must not change after the training\nsamples have been collected, and the samples must contain everything that the\nnetwork will encounter in-game in the right proportions.\nComputational Issues\nSince game AI operates in an environment in which CPU time is at a premium, it is\nimportant to consider the computational cost associated with neural networks.\nUnfortunately, training an MLP is processor intensive, making the MLP poorly\nsuited to in-game learning and, in most cases, much simpler learning mechanisms can\nalmost always be employed. In contrast, computing the output of a trained MLP\n",
      "content_length": 2979,
      "extraction_method": "Direct"
    },
    {
      "page_number": 346,
      "chapter": null,
      "content": "3.14 Using a Neural Network in a Game: A Concrete Example \n357\nrequires very little processor time, particularly since all internal quantities can be\nmodeled using integers and nonlinear functions replaced by look-up tables. Such\noptimizations have allowed the MLP to be used in several real-time titles on the PC\nand Playstation.\nResults\nFollowing the steps outlined in the preceding sections, an MLP was created that had\nthree inputs, two consisting of a Cartesian representation of the relative positions of\nthe player's tank and the AI tank, and one representing wind speed. We collected\n1207 examples of successful shots, and the MLP was trained for around two-and-a-\nhalf hours on a PC with a 500MHz Intel Celeron processor. At this time, training was\nstopped because the MLP's performance was as good as was required, achieving a 98-\npercent hit rate in the game.\nConclusion\nThis gem described the steps taken to produce the neural network AI that is used in\nC e>% \nthe simple tank game that is included on the CD. The interested reader is strongly\non me CD \nencouraged to pursue important issues such as input selection and overfitting in refer-\nences such as [Haykin94] and [Bishop95], which are able to provide both a broader\nintroduction and greater detail than is possible here. Finally, there is no substitute for\npractical experience—experiment with the MLP class that accompanies this article\nand apply it to your own problems. Follow the development process that was out-\nlined, and you'll discover neural networks to be a flexible and powerful tool.\nReferences\n[Bishop95] Bishop C. M., Neural Networks for Pattern Recognition, Oxford University\nPress Inc., 1995.\n[Haykin94] Haykin S., Neural Networks: A Comprehensive Foundation, Macmillan\nCollege Publishing Company, 1994.\n[LaMotheOO], LaMothe, A., Game Programming Gems, Edited by DeLoura, M.,\nCharles River Media, Inc, 2000.\n[SarleOl] Sarle, W. S., \"Neural Network FAQ\" available online at www.ci.tuwien\n.ac.at/docs/services/nnfaq/FAQ.html, February 15, 2001.\n",
      "content_length": 2030,
      "extraction_method": "Direct"
    },
    {
      "page_number": 347,
      "chapter": null,
      "content": "4.1\nComparison of VIPM Methods\nTom Forsyth, Mucky Foot Productions\ntomf@muckyfoot.com\nV\niew-Independent Progressive Meshing (VIPM) has moved from the status of an\ninteresting research project, to promising new technology, to sensible addition to\nall the best engines, and now into the Direct3D graphics API itself. It is now becom-\ning almost required for any engine, and its inclusion in the Direct3DX library means\nthat one form of VIPM is relatively easy to add.\nHowever, in an effort to push the performance of VIPM, and in particular to\ndrive the hardware as efficiently as possible, several new forms have been developed,\neach with their own tradeoffs and characteristics. This gem is intended as a guide to\nsome of the more promising versions, and should help people decide which of the\nmany variants to use in particular situations.\nThis gem does assume a basic familiarity with VIPM, and there is no space for a\nthorough introduction here. However, there are several good guides both in print and\nonline. The two best known are Jan Svarovsky's gem in Game Programming Gems\n[SvarovskyOO] and Charles Bloom's Web site [BloomOl], both of which have excellent\nstep-by-step guides to implementations of the \"vanilla\" VIPM method. All of the\nmethods discussed here use the same basic collapse/split algorithm, but implement it\nin different ways.\nConsiderations\nThere are a few main points on which the various methods need to be judged. Differ-\nent situations demand different choices, and the different ways each object type in a\ngame is used may mean that different methods of VIPM are used. Things to consider\ninclude:\n• Global memory cost. How much memory is taken up just by the mesh repre-\nsentation of the model? This memory is shared between all onscreen instances.\n• Instance memory cost. How much memory is used for each instance of the\nobject drawn onscreen? This memory is duplicated for each instance and cannot\nbe shared.\n• Streaming or referenced memory cost. This is the amount of data actually ref-\nerenced on each frame. There may be a large amount of existing data for an\n363\n",
      "content_length": 2098,
      "extraction_method": "Direct"
    },
    {
      "page_number": 348,
      "chapter": null,
      "content": "Section 4 \nGeometry Management\nobject that is mainly left on CD or swapped out to a hard drive by virtual mem-\nory. However, on each frame the actual amount of data referenced may be small,\nallowing the data to be streamed and/or handled efficiently by the virtual mem-\nory system. This is especially important for consoles that typically have limited\nmemory.\n• CPU cost. How many clock cycles does the algorithm take, in terms of user code?\nThis includes both single-frame rendering costs and the cost of changing the level\nof detail from frame to frame.\n• API interface efficiency. How many CPU cycles are used in driver and API\ninterfaces getting data down to the graphics card?\n• Bus bandwidth. How much data must be sent to the graphics card? On a PC,\nthis means the AGP bus bandwidth.\n• Vertex—cache coherency. Modern graphics cards try to fetch, transform, and\nlight each vertex only once, even though the vertex will be used by multiple tri-\nangles. To do this, they have a vertex cache that holds the most recently used ver-\ntices, and applications need to try to use vertices in this cache as often as possible\nto get maximum performance. An algorithm that uses more triangles than\nanother may still be faster because it has a higher vertex cache hit rate.\nVertex cache coherency will be quoted in terms of the number of vertices loaded\nor processed per triangle drawn, or \"vertices per triangle.\" Current triangle reordering\nalgorithms for static (i.e., non-VIPM) meshes using modern vertex caches of around\n16 entries can get numbers down to around 0.65. For an example, see [Hoppe99].\nThis gives suitable benchmark figures to compare efficiencies when the mesh is con-\nverted to a VIPM one. Also note that when calculating the vertices per triangle using\ntriangle strips, only drawn triangles should be counted, not degenerate ones. The\ndegenerate triangles are a necessary evil—they add nothing to the scene.\nAlgorithms that are good at streaming allow the application to draw huge worlds\nthat are mostly stored on disk, and to degrade image quality gracefully if the stream-\ning of data hits a limit somewhere along the way, such as available disk bandwidth or\navailable memory on the machine.\nThis also helps systems with virtual memory; if the data is accessed linearly, the\nvirtual memory manager can swap out data that has yet to be accessed, or has not\nbeen accessed for a long time. Static data can be optimized even further and made\ninto a read-only memory-mapped file. This also ensures that irritating \"loading level\"\nmessages are no more tedious than absolutely necessary. The object data does not all\nneed to be loaded at the beginning; the player can start playing the level with low-\nresolution data and as the detailed models are needed, they will be loaded.\nAll the methods discussed here are based around implementations of the same\nfundamental algorithm. Single operations are done that collapse a single vertex onto\nanother vertex along one of its triangle edges. No new \"average\" vertex is generated,\nand no collapses between vertices that do not share an edge are allowed. These are\nworth looking into; however, the current consensus is that they involve a higher run-\n",
      "content_length": 3204,
      "extraction_method": "Direct"
    },
    {
      "page_number": 349,
      "chapter": null,
      "content": "4.1 Comparison of VIPM Methods \n365\ntime cost for equivalent error levels on most current hardware. Of course, things\nchange, and new algorithms are always being invented.\nA note on the terminology used: The resolution of a mesh is proportional to the\nnumber of triangles in it. Thus, a high-resolution mesh undergoes edge collapses and\nbecomes a lower-resolution mesh. The opposite of an edge collapse is an edge split,\nwhere a single vertex splits into two separate vertices. For a given edge collapse, there\nis a kept vertex and a binned vertex. The binned vertex is not used in any lower-\nresolution meshes, whereas the kept vertex is. For a given edge collapse, there are two\ntypes of triangles. Those that use the edge being collapsed will not be in any lower-\nresolution mesh and are binned. For a typical collapse, there are two binned trian-\ngles, although there may be more or less for complex mesh topologies. Those that\nare not binned but use the binned vertex are \"changed\" triangles, and changed so\nthat they use the kept vertex instead of the binned vertex. When performing an\nedge split, the previously binned vertex and triangles are \"new,\" although they are\noften still called binned because there are typically no split data structures, just col-\nlapse data structures that are done in reverse. Most of the perspective is in the col-\nlapsing direction, so words like first, next, before, and after are used assuming\ncollapses from a high-triangle mesh to a low-triangle mesh. Again, splits are done by\nundoing collapses.\nThis gem will be talking in a very PC and DirectX-centric way about CPUs, AGP\nbuses, graphics cards (\"the card\"), system/video/AGP memory, index, and vertex\nbuffers. This is generally just a convenience—most consoles have equivalent units and\nconcepts. Where there is a significant difference, it will be highlighted. The one term\nthat may be unfamiliar to the reader is the AGP bus; this is the bus between the main\nsystem memory (and the CPU) and the graphics card with its memory. There are var-\nious speeds, but this bus is typically capable of around 500Mbytes/sec, which makes\nit considerably smaller than the buses between system memory and the CPU, and\nbetween the graphics chip and its video memory. Some consoles have a similar bottle-\nneck; others use a unified memory scheme that avoids it. In many cases, this is the\nlimiting factor in PC graphics.\nVanilla VIPM\nThis is the best-known version of VIPM, and the version used by the Direct3DX8\nlibrary. It has a global list of static vertices, arranged in order from last binned to first\nbinned. Each time a collapse is done, the vertex being binned by the collapse is the\none at the end of the list, and the number of vertices used is decremented by one. This\nensures that the used vertices are always in a single continuous block at the start of the\nvertex buffer, which means that linear software T&L pipelines always process only\nthe vertices in use.\nThe triangles are also ordered from last binned to first binned. Each edge collapse\ngenerally removes two triangles, although they may actually remove anywhere from\nzero upward for meshes with complex topologies.\n",
      "content_length": 3168,
      "extraction_method": "Direct"
    },
    {
      "page_number": 350,
      "chapter": null,
      "content": "Section 4 Geometry Management\nTriangles that are not binned but are changed during a collapse simply have the\nindex to the binned vertex changed to that of the kept vertex. Since the index list\nchanges as the level of detail changes, the triangle index buffer is stored as per-instance\ndata. The index buffer is comprised of indexed triangle lists (each triangle defined by\nthree separate indices), rather than indexed triangle strips.\nEach record of collapse data has the following format:\nstruct VanillaCollapseRecord\n{\n// The offset of the vertex that doesn't vanish/appear.\nunsigned short wKeptVert;\n// Number of tris removed/added.\nunsigned char bNumTris;\n// How many entries in wlndex0ffset[] .\nunsigned char bNumChanges;\n// How many entries in wlndex0ffset[] in the previous action.\nunsigned char bPrevNumChanges;\n// Packing to get correct short alignment.\nunsigned char bPadding[1];\n// The offsets of the indices to change.\n// This will be of actual length bNumChanges,\n// then immediately after in memory will be the next record.\nunsigned short wlndex0ffset[] ;\nThis structure is not a fixed length — wlndexOf f set [ ] grows to the number of ver-\ntices that need changing. This complicates the access functions slightly, but ensures\nthat when performing collapses or splits, all the collapse data is in sequential memory\naddresses, which allows cache lines and cache prefetching algorithms to work .effi-\nciently. It also allows the application to stream or demand-load the collapse data off a\ndisk very easily. Because it is static and global, it can also be made into a read-only\nmemory-mapped file, which under many operating systems is extremely efficient.\nAlthough at first glance bPrevNumChanges doesn't seem to be needed for collapses,\nit is needed when doing splits and going back up the list — the number of wlndexOff -\nset[] entries in the previous structure is needed so they can be skipped over.\nAlthough this makes for convoluted-looking C, the assembly code produced is actu-\nally very simple.\nTo perform a collapse, the number of vertices used is decremented since the\nbinned vertex is always the one on the end. The number of triangles is reduced by\nbNumTris; again, the binned triangles are always the ones on the end of the list.\nThe changed triangles all need to be redirected to use the kept vertex instead of\nthe binned one. The offsets of the indices that refer to the binned point are held in\nwlndexOff set[]. Each one references an index that needs to be changed from the\nbinned vertex's index (which will always be the last one) to the kept vertex's index —\nwKeptVert.\n",
      "content_length": 2604,
      "extraction_method": "Direct"
    },
    {
      "page_number": 351,
      "chapter": null,
      "content": "4.1 Comparison of VIPM Methods\n367\nVanillaCollapseRecord *pVCRCur = the current collapse;\niCurNumVerts-;\niCurNumTris -= pVCRCur->bNumTris;\nunsigned short *pwlndices;\n// Get the pointer to the instance index buffer.\np!ndexBuffer->Lock ( &pwlndices );\nfor ( int i = 0; i < pVCRCur->bNumChanges; i++ )\n{\nASSERT \n( \npwIndices[pVCRCur->w!ndexOffset[i]] \n==\n(unsigned shortJiCurNumVerts );\npwIndices[pVCRCur->w!ndexOffset[i]] = pVCRCur->wKeptVert;\n}\n// Give the index buffer back to the hardware.\np!ndexBuffer->Unlock();\n// Remember, it's not a simple ++\n// (though the operator could be overloaded).\npVCRCur = pVCRCur->Next();\nNote that reading from hardware index buffers can be a bad idea on some archi-\ntectures, so be careful of exactly what that ASSERT () is doing—it is mainly for illustra-\ntion purposes (Figure 4.1.1).\nIndex list\nVanillaCollapseRecord\nwKeptVert = 4\nbNumTris = 2\nbNumChanges = 3\nbPrevNumChanges = -1\nwlndexOffset [3] = {\n1,\n5,\n12}\nIndex list\n148\n846\nFIGURE 4.1.1 An edge collapse with before and after index lists and the VanillaCollapseRecord.\n",
      "content_length": 1064,
      "extraction_method": "Direct"
    },
    {
      "page_number": 352,
      "chapter": null,
      "content": "368 \nSection 4 Geometry Management\nDoing a split is simply a matter of reversing the process.\nVanillaCollapseRecord *pVCRCur = the current collapse;\npVCRCur = pVCRCur->Prev();\nunsigned short *pwlndices;\np!ndexBuffer->Lock ( &pwlndices );\nfor ( int i = 0; i < pVCRCur->bNumChanges; i++ )\n{\nASSERT ( pwIndices[pVCRCur->w!ndexOffset[i]] ==\npVCRCur->wKeptVert );\npwIndices[pVCRCur->w!ndexOffset[i]] =\n(unsigned shortJiCurNumVerts;\n}\niCurNumTris += pVCRCur->bNumTris;\niCurNumVerts++;\nplndexBuffer->Unlock();\nNote that in practice, and for arbitrary historical reasons, in the sample code the\nVertexCollapseRecords are stored last first, so the Prev() and Next () calls are swapped.\nVanilla VIPM is simple, easy to code, and has decent speed. It should probably be\nthe first version used for any evaluation of VIPM, because it is so simple, and even\nthis will give good scalability, streaming, and so on.\nThe good thing about vanilla VIPM is that it streams very well. Collapse infor-\nmation and index buffer data is completely linear in memory and ordered by collapse,\nso implementing a streaming system with fallbacks for when data is not immediately\navailable is extremely easy.\nHowever, there are many bad things about vanilla VIPM. Vertex cache coherency\nis poor. Because triangle order is strictly determined by collapse order, there is no\nway to reorder triangles for better vertex caching.\nAnother problem is the relatively large per-instance memory use. The whole\nindex data chunk needs to be replicated for each instance. This can be reduced by\nonly allocating as many indices as are actually currently being used, and growing or\nshrinking as needed (along with a bit of hysteresis to prevent calling malice () and\nf ree() all the time), but it is still large if there are lots of objects onscreen.\nFinally, vanilla VIPM only works with indexed triangle lists, which can be a poor\nchoice for hardware that prefers strips.\nSkip Strips\nSkip strips is a slightly overloaded name. It was borrowed from a paper on View-\nDependent Progressive Meshing (VDPM) [El-Sana99]. VDPM is significantly more\ncomplex and requires some fairly extensive data structures to achieve good efficiency,\nand a skip list is one of those data structures. However, the section that inspired this\nVIPM method was the bit that noted that to bin a triangle, it does not have to fall off\nthe end of the index list, as in vanilla. There is not much wrong with simply making\nit degenerate by moving one of its vertices (usually the binned vertex) to another one\n",
      "content_length": 2532,
      "extraction_method": "Direct"
    },
    {
      "page_number": 353,
      "chapter": null,
      "content": "4.1 Comparison of VIPM Methods \n369\n(usually the kept vertex), and leaving it in the list of drawn triangles. Hardware is very\ngood at spotting degenerate triangles, and throws them away very quickly without\ntrying to draw any pixels.\nThis means that the order of triangles is no longer determined by collapse order;\nthey can be ordered using some other criteria. The cunning thing that the original\nskip strips paper pointed out is that triangles can now be ordered into strip order, and\nindeed converted into strips. This is great for hardware that prefers its data in strip\norder. Since this VIPM method was inspired by the paper, it inherited the name,\ndespite it being somewhat inaccurate.\nThe ability to reorder triangles increases vertex cache coherency. Strips are natu-\nrally good at this—they have an implicit 1.0 vertices per triangle efficiency (for long\nstrips with no degenerates), and with the right ordering and a decent-sized vertex\ncache, they can get much lower values.\nOne cunning thing about the implementation is that the collapse/split routines\nand data structures are virtually identical to vanilla VIPM. The only change is that the\nnumber of drawn triangles does not change with collapses and splits. Triangles simply\nbecome degenerate; they do not fall off the end of the list.\nHowever, this shows a big problem with skip strips. After many collapses, there\nare many degenerate triangles in the list. Although they are rejected by the hardware\nquickly, they still take some time to reject, and their index data still has to be sent to\nthe card. This eats into the bus bandwidth, and lowers the visible triangle throughput\nin triangles/second.\nAfter many collapses, the vertex cache efficiency also drops. The nice neat strips\nwill have been bent and broken by the collapses, which disrupts the cache efficiency.\nMoreover, as triangles become degenerate, the number of indices referring to one of\nthe remaining vertices increases. A collapse that bins that vertex must change all the\nindices that refer to it, including the degenerate triangles. Therefore, the more col-\nlapses that are done, the more expensive each collapse becomes, because the size of\nwlndexOffsett ] grows. This does not scale with the number of triangles drawn,\nwhich is no good since that is the whole point of VIPM—things at lower detail\nshould take less time to render.\nMultilevel Skip Strips\nFortunately, there is a solution to most of skip strip's woes. After a certain number of\ncollapses, simply stop, take the current geometry with all of its collapses done, throw\naway the degenerate triangles, and start making a completely new skip strip from\nscratch. Continue collapses with this new skip strip until it too becomes inefficient,\nand so on.\nWhen creating each new skip strip level, all of the degenerate triangles are thrown\naway, which reduces the number of triangles (both visible and degenerate) that are\nsent to the card. The triangles are also reordered to make lists that are again vertex-\ncache optimal. New collapses don't need to change lots of degenerate triangle indices\n",
      "content_length": 3090,
      "extraction_method": "Direct"
    },
    {
      "page_number": 354,
      "chapter": null,
      "content": "Section 4 Geometry Management\neach time, each instance only needs to copy the skip strip level that it actually uses,\nand they become shorter with decreasing detail.\nThe different index lists can be stored globally since when switching to a new list,\na new copy is taken and then refined with collapses to exactly the number of triangles\nwanted. Therefore, the fact that there are now multiple index lists is not too bad—its\nglobal data. This also restores some of the nice streaming friendliness that the vanilla\nmethod has. The granularity is a bit coarser; the whole of an index list must be\ngrabbed before anything can be rendered using that level, but at least it's no longer an\nall-or-nothing thing, and the lower-resolution index lists are actually very small.\nFor a bit more efficiency, two versions of the index lists can be stored in global\nspace: fully collapsed (before switching to a lower-resolution list, that is) and fully\nuncollapsed. This means that a single-collapse oscillation across the boundary\nbetween two index lists is still fairly efficient. If only the uncollapsed versions are held,\neach time the level of detail increases, the higher-resolution index list must be copied,\nand then all of its collapses need to be performed to draw the next frame. Having the\ncollapsed versions stored as well means that a change in the level of detail of n col-\nlapses only actually requires n collapses (and sometimes fewer).\nThe actual collapse/split code and structures are the same as for standard skip\nstrips, except that there is a global array of structures holding the premade index lists,\nthe collapse lists for each one, and the number of collapses in each. Before doing any\ncollapses or splits, the code checks to see if it needs to change levels, and if so, copies\nthe new level's index list and starts doing collapses/splits until it reaches the right level\nof detail within that level.\nSo, this has fixed all the bad things about skip strips when compared to vanilla in\nexchange for an increase in global (but easily streamed or swapped) memory.\nSkip strips also have an equivalent using triangle lists instead of triangle strips.\nThe principle is exactly the same, but use a different primitive. Some algorithms\nrequire lists rather than strips, and some vertex cache routines can obtain slightly\nhigher caching rates with lists than strips. No separate implementation was done in\nthe sample code, because they are so similar.\nMixed-Mode VIPM\nOne of the problems with the types of VIPM mentioned so far is that the whole index\nlist needs to be copied for each instance of the object. This can be quite a burden in\nsome cases, especially on machines with limited memory, notably consoles, where\neverything has to be shoehorned into memory that is usually half the size that the pro-\ngrammers would like, even before VIPM is mentioned. It would be excellent if some\nof this index list could be moved to global (i.e., static and shared between instances)\nmemory instead of having to be copied for each instance.\nOn a multilevel skip strip, many of the triangles are not affected, even when that\nlevel is fully collapsed. Therefore, there is no need to copy those triangles per instance;\n",
      "content_length": 3212,
      "extraction_method": "Direct"
    },
    {
      "page_number": 355,
      "chapter": null,
      "content": "4.1 Comparison of VIPM Methods \n371\nthey can be global and shared between instances. In fact, for this algorithm, indexed\nlists are used—the indexed strip case will be discussed later as a variant. At each level,\nthe triangles are split into four lists:\n• The triangles that are not affected by any collapses.\n• The triangles that are binned by collapses, but not modified by any before they\nare binned.\n• The triangles that are modified by collapses, but not binned.\n• The triangles that are first modified by one or more collapses and then binned.\nLists 2 and 4 are each sorted by bin order, just as for vanilla VIPM. Lists 1 and 3\nare sorted into whatever order gives the highest vertex cache efficiency. Then list 2 is\nappended to list 1, and the combined list is put into a global index buffer that is sta-\ntic and shared by all instances. List 4 is appended to list 3, and the combined dynamic\nlist is copied into instances when they use that level. This list is then modified at run-\ntime using exactly the same modification algorithm as vanilla VIPM.\nTo draw the mesh, the required collapses and splits are done to the dynamic per-\ninstance list, and the list is drawn. Then the associated level's static list is drawn, with\nthe only modification being that the number of triangles drawn will change as static\ntriangles are collapsed.\nThe code and structures needed are based on the multilevel skip list, except that\nfor each level there are two lists: the copied dynamic one and the shared static one.\nThe other change is that there are two triangle counts, one for each list, and a collapse\nmay alter either or both of these numbers. Therefore, the bNumTris member is\nreplaced by bNumStaticTris and bNumDynamicTris, and the appropriate increments\nand decrements are added.\nThis means that a large proportion of each mesh is being drawn from a static\nindex buffer that is tuned for vertex cache coherency (list 1). It is not quite as good as\nit could be, since the triangles in this list only make up part of the object. There will\nbe \"holes\" in the mesh where triangles have been moved to the other three lists, and\nthis decreases both the maximum and the actual vertex per-triangle numbers that are\nobtained. Some of the dynamic buffer is also ordered for optimal vertex cache behav-\nior (list 3), although collapses can interfere with this efficiency, and the mesh for list 3\nis usually far from usefully connected, so there is a limit to what any reordering\ncan do.\nLike all multilevel methods, it is streaming friendly; although in this case, since\nthe lists are ordered by collapse order, the granularity is even finer at the triangle level,\nnot just the list level. Whether this is terribly exciting is a different question—the\nfiner control is probably not going to make much of a difference in performance.\nThis does require two DrawIndexedPrimitive() calls to Direct3D (or equivalent\nAPI), although on most platforms, this is not a bottleneck and does not affect render-\ning speed. It may be important for very low-triangle meshes, and for these, switching\nto another method may be appropriate.\n",
      "content_length": 3114,
      "extraction_method": "Direct"
    },
    {
      "page_number": 356,
      "chapter": null,
      "content": "372 \nSection 4 Geometry Management\nMixed-Mode Skip Strips\nMixed-mode skip strips are identical to mixed-mode lists, except that strips are used,\nand instead of the dynamic list being done with vanilla VIPM, it is done using the\nskip strips algorithm. As with skip strips, using strips means that ordering by collapse\norder is too inefficient, and diis means that list 2 triangles now have to be binned by\nbeing made degenerate. This forces them to become dynamic instead of static, and\nthey join lists 3 and 4. The triangles from these three lists are merged and treated as a\nskip strips —reordered for optimal vertex cache efficiency, copied for each instance,\nand modified by collapse information.\nThe disadvantages with this method are that there is now more data being copied\nfor each instance, and because the triangles are ordered by strip order and not collapse\norder, triangles cannot be binned entirely by simply dropping them off the end of the\nindex list. However, both these factors are only mildly worse than the list version, and\nif the hardware needs to be fed strips, this is still an excellent method.\nSliding Window\nSliding window VIPM introduces the idea of fully static and global index buffers,\nwith no editing of indices, and therefore a tiny amount of per-instance memory.\nSliding window notes that when a collapse happens, there are two classes of trian-\ngles: binned triangles and modified triangles. However, there is no real need for the\nmodified triangles to actually be at the same physical position in the index buffer\nbefore and after the collapse. The old version of the triangles could simply drop off\nthe end of the index buffer along with the binned triangles, and the new versions\nadded on at the other end.\nTherefore, instead of an example collapse binning two triangles and editing three\nothers, it actually bins five triangles and adds three new ones. Both operations are per-\nformed by just changing the first and last indices used for rendering—sliding a \"ren-\ndering window\" along the index buffer (Figure 4.1.2).\nThe index buffer is split into three sections. At the beginning are triangles added\nas a result of changes, in reverse collapse order. In the middle are triangles not affected\nby collapses, in any (vertex cache-optimal) order. At the end are triangles binned or\nchanged by collapses, again ordered in reverse collapse order—first collapse at the\nend. Note that a triangle modified as the result of a collapse cannot then be involved\n(either binned or changed) in another collapse. To be modified by a second collapse\nwould mean that triangle would have to fall off the end of the index buffer. It has\nalready been added to the beginning so it cannot then also fall off the end—the\nchance of the ordering being just right to allow this are incredibly slim.\nOnce a triangle has been modified by a collapse, the only way it can be involved\nin another collapse is if a new index buffer is started that has all the same triangles as\nthe previous (collapsed) one. The ordering of this new one is not constrained by the\nprevious collapses, and so can be sorted by new collapses. Again, the multilevel con-\n",
      "content_length": 3155,
      "extraction_method": "Direct"
    },
    {
      "page_number": 357,
      "chapter": null,
      "content": "4.1 Comparison of VIPM Methods\n373\nIndex List \nSlidingWindowRecord\ndwFirstlndexOf fset = 0,\nwNumTris = 7,\nwNum Verts = 8\ndwFkstlndexOffset =9,\nwNumTris = 9,\nwNum Verts = 9\nFIGURE 4.1.2 A collapse showing the index list and the two windows.\ncept is used, but in this case because further collapses cannot happen without it, not\nsimply for efficiency.\nThe problem with this at face value is that algorithms such as QEM give an\nordering for collapses. If this ordering is strictly followed, the QEM frequently wants\nto do a new collapse that involves a triangle that has already been modified by a pre-\nvious collapse. This forces a new level to be made, and the index buffer needs to be\ncopied. Since only a few collapses have been done, this copy is almost as big as the\noriginal. If only a few collapses are done before having to make a copy, the memory\nused for all the index buffers is going to be huge.\nHowever, there is actually no need to strictly follow the order of collapses that\nQEM decides. Progressive meshing is not an exact science, since it ignores everything\nbut the distance of the camera from the object, and the whole point is to simply be\n\"good enough\" to fool the eye. Therefore, diere is no real need to precisely follow the\ncollapse order that QEM decides—it can be manipulated a bit.\nThe way to do this is to follow the QEM collapse order until it decides to do a\ncollapse that involves triangles that have already been modified. Doing this collapse\nwould force a new level, and so this is put off for as long as possible. For the moment\n",
      "content_length": 1561,
      "extraction_method": "Direct"
    },
    {
      "page_number": 358,
      "chapter": null,
      "content": "374 \nSection 4 Geometry Management\nthis collapse is ignored, and the best one that can be done without creating a new level\nis found. The errors of the two collapses are compared, and if they are within a certain\ntolerance, then doing them out of strict order is not going to affect visual quality all\nthat much, and the collapse that will not force a new level is done.\nOnce the difference in error levels is too great, then doing the wrong collapse first\nis going to affect image quality significantly, and the algorithm bites the bullet and\ncreates a new level. There have now been a decent number of collapses done before\nthis copy happens, the triangle count has been significantly reduced, and thus far,\nfewer levels are needed before they collapse down to the minimum level of detail.\nThe sample code uses a fairly small tolerance level of 10 percent of the average\ncollapse error, and even this small tolerance reduces the number of levels dramatically.\nUsing a larger error tolerance can reduce the memory use even more, although only to\na point. After a while, the algorithm simply runs out of triangles that have not already\nbeen involved in a collapse. Most meshes can only lose around 20 percent of their tri-\nangles before this happens, but this still keeps memory use at sensible levels.\nSince no runtime modification is made to the index or vertex lists, all the data can\nbe made global, and there is almost zero per-instance memory use. There is also\nalmost zero CPU time used to change level of detail—each time, a simple table look-\nup is made to decide the index list to use, the start and end index to draw from that\nindex list, and how many vertices are used. In practice, the index lists are concate-\nnated together, so that the first index also implies the index list to use. The table is\ncomposed of this structure:\nstruct SlidingWindowRecord\n{\nunsigned int \ndwFirstlndexOffset;\nunsigned short wNumTris;\nunsigned short wNumVerts;\n};\nAlthough the number of triangles and vertices is known to be less than 64k (this\nis a limit in all currently known hardware), because the index list is a concatenation of\nmany lists, it may easily be greater than 64k indices in length, so 32 bits are required\nfor it. This does mean that the structure is nicely padded to 8-byte alignment,\nthough. The rendering code is amazingly simple:\nSlidingWindowRecord &pswr = swrRecords[iLoD];\nd3ddevice->DrawIndexedPrimitive (\nD3DPT_TRIANGLELIST, // Primitive type\n0, \n// First used vertex\npswr->wNumVerts, \n// Number of used vertices\npswr->dwFirst!ndexOffset,// First index\npswr->wNumTris ); \n// Number of triangles\nThere is no code to do splits or collapses as with all the other methods—the cur-\nrent level of detail is just looked up in die SlidingWindowRecord table each time the\n",
      "content_length": 2784,
      "extraction_method": "Direct"
    },
    {
      "page_number": 359,
      "chapter": null,
      "content": "4.1 Comparison of VIPM Methods \n375\nobject is rendered. This also means that with hardware transform and lighting cards,\nthe CPU time required to render objects is fixed and constant per object, whatever\ntheir level of detail. The phrase \"constant time\" is always a good one to find lurking in\nany algorithm.\nThe major problem with sliding window VIPM is that it forces the ordering of\nthe triangles at the beginning and end of each level's index lists. This has two effects:\nit makes strips hard to use—only triangle lists really handle fixed ordering well—and\nvertex cache efficiency is affected.\nFortunately, it is not as bad as it first seems. When an edge collapse is performed,\nall of the triangles that use the binned vertex are removed, so they all go on the end of\nthe triangle list. This is typically from five to seven triangles, and they form a triangle\nfan around the binned vertex. Then the new versions of the triangles are added. These\nneed to go together at the beginning of the index list, there are typically three to five of\nthem, and they form a triangle fan around the kept vertex. These fans can be ordered\nwithin themselves to get the best cache coherency. The middle of the index list that is\nnot affected, and thus has no set order, can be reordered for the vertex cache. This gets\nmuch better cache coherency than vanilla. Although it is still quite a bit short of the\ntheoretical ideal, it is not unreasonably poor.\nVertex cache coherency can be raised by having a larger middle index list section\nin each level—by having fewer collapses per level. This takes more memory, but the\nextra performance may be worth it, especially as it is global memory.\nHardware that requires strips rather than lists can still use this method, although\nit does require many degenerate triangles to join the different parts. In practice, this\ndoes not increase the number of indices required, it actually reduces it—strips have\none index per triangle, compared to a list's three. The vertex cache efficiency per\ndrawn triangle is exactly the same. The raw triangle throughput is increased a lot\n(roughly doubled), but since all of these extra triangles are just degenerate, most hard-\nware will reject them very quickly. If there is a choice, which of the two primitives\nused depends on whether the hardware is limited by index bandwidth (in which case,\nstrips are optimal) or triangle throughput (in which case, lists are optimal).\nSummary\nVIPM seems to be coming of age. It is now mainstream, it has been incorporated into\na major API, and for discrete objects it has beaten off VDPM and static level of detail\nmethods for the most visual bang for the CPU buck (although it is worth noting that\nVDPM methods are still challengers for large landscapes, especially regular-height-\nfield ones). In addition, it now has a plethora of methods from which to choose, each\nwith its own advantages and disadvantages. Innovation certainly won't stop there—\nthere are already some interesting paths for future investigation, but this roundup\nshould give a fairly good guide to some of the issues and options when choosing\nwhich VIPM method to implement.\n",
      "content_length": 3154,
      "extraction_method": "Direct"
    },
    {
      "page_number": 360,
      "chapter": null,
      "content": "376 \nSection 4 Geometry Management\nTable 4.1.1 Summary of Strengths and Weaknesses of Each VIPM Method\nVertex cache use\nGlobal memory use\nInstance memory use\nLoD-change CPU cost\nAPI efficiency\nList efficiency\nVanilla\nPoor\nLow\nHigh\nMedium\nGood\nPoor\nSkip Strips\nExcellent\nMedium\nHigh\nMedium\nGood\nExcellent\nMixed-Mode\nGood\nMedium\nMedium\nMedium\nGood\nGood\nSliding Window\nGood\nHigh\nLow\nTiny\nExcellent\nGood\nTable 4.1.1 shows the results of each method with their relative strengths and\nweaknesses. Note that \"skip strips\" refers to multilevel skip strips—the single-level\nversion is not actually a sensible method in practice, for the reasons given.\nReferences\n[SvarovskyOO] Svarovsky, Jan, \"View-Independent Progressive Meshing,\" Game Pro-\ngramming Gems, Charles River Media, 2000, pp. 454-464.\n[BloomOl] Bloom, Charles, VIPM tutorial, and various VIPM thoughts gathered\nfrom many sources, www.cbloom.com/3d/index.html.\n[Hoppe99] Hoppe, Hugues, \"Optimization of Mesh Locality for Transparent Vertex\nCaching,\" Computer Graphics (SIGGRAPH 1999 proceedings) pp. 269-276.\nSee also www.research.microsoft.com/-hoppe/.\n[El-Sana99] J. El-Sana, F. Evans, A. Varshney, S. Skiena, E. Azanli, \"Efficiently Com-\nputing and Updating Triangle Strips for View-Dependent Rendering,\" The Jour-\nnal of Computer Aided Design, vol. 32, no. 13, pp. 753-772. See also\nwww.cs.bgu.ac.il/-el-sana/publication.html.\n",
      "content_length": 1384,
      "extraction_method": "Direct"
    },
    {
      "page_number": 361,
      "chapter": null,
      "content": "Simplified Terrain Using\nInterlocking Tiles\nGreg Snook\ngregsnook@home.com\nW\nith recent advancements in 3D rendering hardware, it seems that everyone is\nbringing his or her game to the great outdoors. Far horizons and mountainous\nlandscapes, once hidden by fog and far clipping planes, are now an obtainable reality.\nGame programmers once consumed with the BSP tree and span-based rendering\nmethods are now trading in tired old buzzwords for shiny new acronyms like ROAM\nand VDPM.\nROAM (Real-time Optimally Adapting Meshes) [Duchaineau] and VDPM (View\nDependent Progressive Meshes) [Hoppe98] are outlined elsewhere in great detail (see\nthe References), so I'll just give them a quick overview here. Both of these methods do\nan amicable job of reducing the polygon count (and therefore the rendering load) on\nthose parts of the terrain that do not require a great deal of geometry, such as reason-\nably flat plains or areas far off in the distance. In turn, they allow more detailed terrain\nto exist closer to the camera, or on very rough surfaces, where additional polygons are\nneeded. Essentially, they are two rather complex ways to achieve the same simple goal:\nmore polygons where you need them, less where you don't.\nThe trouble for some applications is that methods such as ROAM and VDPM\ntend to rely on procedurally generated geometry to achieve a smooth transition from\nlow- to high-detail areas. ROAM uses a binary tree of triangle intersections to con-\nstruct the actual terrain geometry from a given height field. VDPM achieves a similar\neffect by using a coarse mesh to represent the low-detail terrain and applying a set of\nsuccessive vertex splits to further divide the terrain polygons where necessary. In most\ncases, these continuous triangulations disrupt the speed advantage of hardware trans-\nform and lighting, which relies on static geometry for optimum speed.\nThe main reason for this is that diese methods work almost too well. They have the\npower to analyze die terrain down to the poly level, hand-picking tliose that stay and\nthose that get collapsed. This can result in many minute changes to the terrain geome-\ntry over time, and requires reprocessing of the entire method should the terrain change.\nBy sacrificing that finite level of control over the geometry, we can remain hardware\nfriendly by working over larger areas of static geometry and remain flexible to changes in\nthe terrain over time.\n377\n",
      "content_length": 2431,
      "extraction_method": "Direct"
    },
    {
      "page_number": 362,
      "chapter": null,
      "content": "378 \nSection 4 Geometry Management\nWhat this gem proposes is a far simpler method that most applications can\ntake advantage of with a minimal amount of coding. It is not intended to wrestle with\nthe visual quality that ROAM or VDPM methods can produce; instead, it serves to\ncreate a simple terrain with the benefits of dynamically adapting detail levels and ani-\nmation flexibility. It does this while maintaining a data system that is perfectly suited\nfor hardware transform and lighting.\nTiles Revisited\nMany moons ago, game programmers used 2D tiles to represent the playfield. This\nwas done for one simple reason: less artwork was easier to create and manage. Early\ngames simply did not have the memory to afford a large amount of pixel data, so\nsmaller pictures were tiled to create the illusion of a larger area. These small tiles were\nalso easier to draw and push around, so smooth-scrolling 2D games could easily be\ncreated out of little 32x32 pixel tiles.\nThe terrain method presented here works on the same basic principle by dividing\nthe terrain into smaller, reusable tiles. The same advantages apply: smaller bits of data\nare easy to push around, drawing can be optimized, and memory is used more effi-\nciently. The obvious difference is that we are no longer dealing with pixel data within\nthe tiles. The terrain tiles are represented as index buffers that link together the ver-\ntices of the terrain.\nThink of the 3D tiles as a grid being projected down on the landscape from\nabove. Each grid square represents a single tile in the terrain system. On the surface, it\nmay not appear as if the terrain tiles ever repeat, given that terrain is a pretty random\nset of geometry. The truth is the terrain may never repeat on the surface, but behind\nthe scenes, there is ample data to tile and reuse.\nConsider each terrain tile in the form of a vertex and index buffer. While each tile\nmay contain a unique set of vertex data, the index buffers used to draw the tiles can be\nmade to repeat rather frequently. In fact, by careful planning of the vertex data, we can\ncreate a finite set of index buffer \"tiles\" to use throughout the entire terrain.\nWe do this by taking advantage of a few refinements in the geometry of our tiles.\nFirst, each tile must contain an identical number of vertices, sharing the edge vertices\nwith its neighbors. These vertices represent the highest level of detail possible for the\ntile. Second, the vertices of the tile are arranged in a regular grid on the x-y plane,\nusing z to represent the vertices' height above sea level. Last, we store the vertices of\neach tile in an identical order so our index buffers can be used on any tile. Have a look\nat the sample tile shown in Figure 4.2.1. Here we have a 17x17 vertex tile showing\nthe grid-aligned positioning of each vertex, each of which has a unique height value\nsampled from the terrain bitmap.\nThe reason for this vertex organization is simple. Since the vertex data always\nappears in a regular grid and in an identical order, a fixed set of index buffers can be\ncreated for the entire terrain. Using the proper index buffer, a given tile can be ren-\ndered at any level, ranging from full detail down to a simple pair of triangles. Index\n",
      "content_length": 3230,
      "extraction_method": "Direct"
    },
    {
      "page_number": 363,
      "chapter": null,
      "content": "4.2 Simplified Terrain Using Interlocking Tiles\n379\n£\n-:.^^\"^'-^.x-' ?f'iXm$K'm f *- -«-•*. --' ~ g-wii-z-z?,\n,\ngli|M*MW^\nills\nC*; KrKifp^ r- TM^'^fe'ip' |Ssff\nliKf^;Sf|;^-;'SlP^4\nFIGURE 4.2.1 A sample terrain tile of 17x17 vertices.\nbuffers that use more of the available vertices create a higher detailed representation of\nthe tile. Similarly, index buffers using less vertices render tiles with reduced triangle\ncounts. Figure 4.2.2 illustrates this by showing a sample tile rendered at different\ndetail levels.\nFIGURE 4.2.2 Using index buffers to create two separate detail levels from the same set of\nvertices.\nMap Making\nIn order to create the landscape tiles, we need a set of source data from which to pull.\nA common method is to read elevation data from a height map. This map is simply a\ngrayscale bitmap of the terrain, where the luminance of the pixel is used to represent\nthe elevation at a given position. The height map has the added advantage that it is\n",
      "content_length": 970,
      "extraction_method": "Direct"
    },
    {
      "page_number": 364,
      "chapter": null,
      "content": "380 \nSection 4 Geometry Management\nalready arranged in a regular grid, so it can be easily translated into terrain vertex data.\nIt can also serve as an animation resource, adjusting the pixel values to afTect the ter-\nrain height at different locations.\nCreating the tile vertices is simple. Since each tile vertex has a known 2D position\non the x-y grid, all that remains is to sample the corresponding height pixel from the\nterrain bitmap and translate it to a z value for the terrain vertex. For each terrain tile, a\ncorresponding block of pixels in the height map can be sampled to create a unique\nvertex buffer for the tile. In the case of an animating height map, this process must be\nrepeated periodically to update the terrain vertices.\nTile Templates\nThe index buffer can be thought of as a drawing template cast over the tile vertices. As\nwe saw in Figure 4.2.2, the index buffer defines how we pull triangles out of the tile,\ncontrolling how detailed a version of it we draw. Following our key rules, each tile's\nvertex buffer has been laid out in an identical order so the index buffers can be used\ninterchangeably. For an example 9x9 vertex tile, we can create a global set of index\nbuffers to draw all possible detail levels for any 9x9 set of vertices, skipping vertices in\nthe grid to create the level geometry. The top-level index buffer uses all 81 vertices to\ndraw 128 triangles, while the lowest level uses only the four corner vertices to draw a\ntwo-triangle quad. In addition, there are two additional detail levels representing 32\nand 8 triangles, respectively.\nThe next requirement is a method to determine which of our four detail levels\neach tile needs to use when being drawn. This determination can range from a simple\nfunction of the distance between the tile and the camera, to a full heuristic taking into\naccount die viewing angle and perceived roughness of the tile. The best method to use\ndepends on die game terrain and camera movement. Hugues Hoppe's paper on the\nVDPM mediod [Hoppe] sheds more light on heuristic ideas that can be used to select\ndetail levels for each terrain location. The sample application on the companion CD-\nROM, SimpleTerrain, uses the distance from the tile to die camera for simplicity. Once\nthe detail level is known, drawing is a simple matter of sending die tile's vertex buffer\nalong widi die desired index buffer into your chosen rendering API for drawing.\nUgly, Ugl* Ugly\nWe have the basic terrain system in place, but it is by no means a smooth terrain.\nWhat we have now is a terrain that changes abruptly as tiles of different detail levels\nare drawn side by side. In addition to that, seams can appear in the gaps created by\ntwo tiles of different detail levels. In short, we have made a mess, but there is still\nhope.\nThe key to this method is having tiles that interlock. That is, creating tiles that\nmesh together perfectly, regardless of the differences in detail levels between neigh-\nboring tiles. To do this, a different set of index buffers is required to merge tiles of dif-\nferent levels together without gaps and seams. These index buffers can be broken into\n",
      "content_length": 3142,
      "extraction_method": "Direct"
    },
    {
      "page_number": 365,
      "chapter": null,
      "content": "4.2 Simplified Terrain Using Interlocking Tiles\n381\nFIGURE 4.2.3 The 16 basic tile bodies. Unshaded areas show where linking pieces must\nbe placed.\ntwo groups: bodies and links. Bodies represent a major portion of a tile at a given\ndetail level, with areas removed to provide space for linking pieces. Links, as the name\nsuggests, link the bodies of different detail levels together seamlessly.\nFigure 4.2.3 shows the 16 possible body types for a tile of any given detail level.\nTo keep things under control, we specify that tiles only link downward, meaning that\ntiles at higher detail levels must use link pieces to fit together with lower-detail neigh-\nbors. Looking at Figure 4.2.3, the unshaded areas of each body type then represent\nspaces where links are required to connect to a neighbor tile at a lower detail level.\nLinking pieces are smaller index buffers that fit into the spaces left vacant by the\nbody tiles. These index buffers arrange triangles to step down from a tile using a\nhigher number of vertices to an adjacent one using less. Figure 4.2.4 shows an exam-\nple link tile used to connect two body tiles. Since we only link downward in detail lev-\nels, each detail level needs enough link pieces to connect to the details levels below it.\nFor the example 9x9 vertex tile, we would need three linking pieces for each side of\nour highest-detail level, since it must be able to link to three lower-detail levels. Our\nlowest-detail level, the simple quad tile, needs no linking pieces, since all higher-detail\nlevels must do the work to link down to it.\nFIGURE 4.2.4 An example link piece used to join two tiles of different detail levels.\n",
      "content_length": 1656,
      "extraction_method": "Direct"
    },
    {
      "page_number": 366,
      "chapter": null,
      "content": "382 \nSection 4 Geometry Management\nTable 4.2.1 All Index Buffers Required for Our Sample of Four Detail Levels\nDetail Level \nBody Pieces Required \n+ \nLinking Pieces Required \n= \nTotal\n4 \n16\n3 \n16\n2 \n15\n1 \n1 '\n3 for each side \n28\n2 for each side \n24\n1 per side \n19\n0 \n1\nGrand Total: \n72\nGiven our example of a 9x9 vertex tile with four detail levels, we can calculate\nthat the total number of index buffers required amounts to a grand total of 48 \"body\"\npieces and 24 \"linking\" pieces. Table 4.2.1 shows the full table of index buffers\nrequired to smooth out our terrain. As can be seen, increasing the number of detail\nlevels increases the index buffer count, but since these are relatively small in size and\ncan be used throughout the entire terrain, they still remain rather efficient.\nBetter, Faster, Stronger\nUsing the new body and linking pieces means we need to change our rendering\nmethod. For each tile, we now need to examine the tile's neighbors. We choose a body\ntile that contains a notched side for each neighbor that is at a lower detail level than\nthe current tile. Then, we select the necessary linking pieces that fill the notches and\nconnect us with the adjacent tiles. Each of these index buffers is then sent to the ren-\ndering API along with the tile's vertex buffer for drawing. In the worst case, we send\nfive index buffers per tile (one body, four linking), but in the best case, we still send\nonly one (the full body tile).\nOrganizing the index buffers into triangle strips and fans can further optimize the\nmethod. For larger tiles (33x33 vertices and up), this will greatly reduce rendering\ntime. In addition, the order of the vertices in the tile can be adjusted for better cache\nperformance when rendering. The exact order will depend on which index buffers the\ntile will be rendered with most often.\nConclusion\nFigure 4.2.5 shows the final output of the rendering method. The sample program\nSimpleTerrain demonstrates the method using DirectX 8.0. Full source code for the\n^-•~ij:'-s%, \nsample program is available on the companion CD-ROM. In this image, the wire-\nframe of the terrain is exposed to show the various body tiles and linking tiles in use.\nONJHCCP \nI I \nJ\nf\nJ \nU-l-\nGround textures have been removed tor readability.\nThe intent of this gem was to provide an alternative to the popular procedural\nmethods for rendering dynamic terrain while fully enabling hardware transform and\nlighting. By using this method, a dynamic terrain system can be up and running\nquickly without severely impacting the application's frame rate. While the final ter-\nrain may not rival that of a well-written ROAM or VDPM system, it does provide the\n",
      "content_length": 2670,
      "extraction_method": "Direct"
    },
    {
      "page_number": 367,
      "chapter": null,
      "content": "4.2 Simplified Terrain Using Interlocking Tiles\n383\nFIGURE 4.2.5 Sample output of the SimpleTerrain^rograzwz showing tiles and linking\npieces in use.\nsame basic advantages of those methods with the potential of greater rendering speed\nin hardware.\nReferences\n[Duchaineau] Duchaineau, M., Wolinski, M., Sigeti, D., Miller, M., Aldrich, C., and\nMineev-Weinstein, M., \"ROAMing Terrain: Real-time Optimally Adapting\nMeshes\" (www.llnl.gov/graphics/ROAM).\n[Hoppe98] Hoppe, H. \"Smooth View-Dependent Level-of-Detail Control and Its\nApplication to Terrain Rendering\" IEEE Visualization 1998, October 1998, pp.\n35-42. (www.research.microsoft.com/'-hoppe).\n",
      "content_length": 647,
      "extraction_method": "Direct"
    },
    {
      "page_number": 368,
      "chapter": null,
      "content": "4.3\nSphere Ttees for Fast Visibility\nCulling, Ray Tracing, and\nRange Searching\nJohn W. Ratcliff, Sony Online Entertainment\njratcliff@verant.com\n\\JLJfcile there are many data structures for storing static 3D objects, including\nWlf quadtrees, octrees, and BSP trees, they are not always ideal for large numbers of\ndynamic objects. This gem presents an algorithm and demonstration application that\nmanages thousands of objects in motion that are continuously maintained as a collec-\ntion of hierarchical bounding spheres in a SphereTree.\nThe design goal for this algorithm has been to make the 99-percentile case spend\nalmost no CPU time updating an object in motion within the tree structure. Queries\nagainst the SphereTree perform more tests than other data structures, but this is mit-\nigated by the fact that the tree can be maintained using very little CPU time. This\ndata structure is ideally suited for gross culling of massive numbers of moving objects\nin a large world space. It doesn't matter if the objects are moving at widely disparate\nspeeds, or even if many of them are not in motion at all. It also has a very low cost\nwhen objects are inserted and removed from the tree with great frequency.\nBounding Spheres\nThere are certain limitations when using a bounding sphere as a culling primitive. A\nbounding sphere does not necessarily fit very tightly around an object, especially if it\nis tall and thin. On the other hand, this over-described bounding sphere can be seen\nas a feature, not necessarily a limitation. A bounding sphere must encompass the\ncomplete extent of an object in all orientations. This includes taking into considera-\ntion all possible animation poses that might be applied. Additionally, this bounding\nsphere is presumed to encompass all child objects that are attached to the parent. This\nallows for the assumption that whatever the visibility state of the parent is also con-\nsidered true for its children. Another advantage of an over-described bounding sphere\nis that it can be used to cull animations, shadows, and other associated effects. This\nextra slop around an object can be an effective tool to determine when to treat an\n384\n",
      "content_length": 2171,
      "extraction_method": "Direct"
    },
    {
      "page_number": 369,
      "chapter": null,
      "content": "4.3 Sphere Trees for Fast Visibility Culling, Ray Tracing, and Range Searching \n385\nobject, its children, and its associated effects as active or inactive. Culling shadows,\nanimations, and special effects are just as critical as culling geometry alone.\nUsing Sphere Trees\nEvery object in the simulation, whether it is in motion or not, uses the class\nSpherePack to maintain itself inside a valid SphereTree. When an object changes posi-\ntion using the method NewPos(), SpherePack simply computes the squared distance\nbetween the new position and the center of the parent node. If it is still contained\nwithin the radius of the parent sphere, which is designed to be true almost all of the\ntime, the routine immediately returns. This method is implemented inline for maxi-\nmum performance. This is the only calculation performed for the vast majority of all\nobjects in motion, even if there are thousands of them. For static objects, nothing is\ndone beyond their initial insertion into the tree.\nWhen a new position would cause an object to pierce the skin of its parent\nsphere, then that child is removed from the parent and inserted into the root node of\nthe tree. This involves only a couple of pointer swaps to instantly maintain a com-\npletely valid tree. When a child node is detached from its parent, it is placed into the\nreintegration FIFO queue. The parent is added to the recomputation FIFO queue to\nmaintain an optimally balanced tree. At each frame, the simulation performs the\nprocess method on the SpherePackFactory so that the reintegration and recomputa-\ntion FIFO queues can be flushed.\nOne problem with a quadtree or an octree is that it is possible for a single leaf\nnode to be contained in multiple nodes of the tree. If an object crosses a quadtree\nboundary, it needs to be represented in both nodes. The SphereTree does not have\nthis property. No leaf node can ever be contained in more than one SuperSphere.\nWhat is true for the SuperSphere is automatically true for all children. If a Super-\nSphere is outside the view frustum, then all of its children are outside the view frus-\ntum as well. The same is true for range tests and ray trace tests.\nThis makes the sphere tree an ideal data structure for these kinds of queries.\nWhen performing visibility culling with a sphere tree, each node keeps track of the\nstate it was in on the previous frame. Callbacks occur only when a node undergoes a\nstate change, which allows the simulation to efficiently maintain a list of only those\nobjects in the view frustum.\nDemonstration Application\nThis algorithm is demonstrated in the Windows application SphereTest.exe.\nSphereTest.exe will create a SphereTree containing 1000 spheres in motion. Even\nthough this demonstration application is in 2D, the SphereTree is a completely 3D\ndata structure. The rather large SphereTree displayed runs at a low frame rate since\nrendering all of this data is fairly slow under Windows. The SphereTest application\n",
      "content_length": 2965,
      "extraction_method": "Direct"
    },
    {
      "page_number": 370,
      "chapter": null,
      "content": "386\nSection 4 Geometry Management\napt\n<~3**\nON THE CO\ndemonstrates building a SphereTree and performing a variety of high-speed queries\nagainst it while running a simulation that models the type of situations seen in\ngames.\nThe number of spheres created by the simulation can be passed as a command-\nline argument. With fewer spheres, it will be much easier to visualize the SphereTree\nthat is built. If a SphereTree of 5000 to 10,000 items is created, queries will still be\nseen taking place very quickly, with most of the CPU time burned just calling Win-\ndows graphics routines to render the results. If the application is begun with a very\nlarge number of items, there will be a pause while the initial tree is built and balanced,\nafter which it will run fairly quickly.\nThe example simulation models the type of situations one would see in an actual\ngame. In this simulation, 25 percent of the objects are in stasis, and the other 75 per-\ncent are always attempting to clump toward one of 16 different attraction points. In\nan actual game, objects are not usually evenly distributed across the address space.\nThe example simulation demonstrating the use of the SpherePackFactory class is con-\ntained in the files Circle.cpp and Circle.h on the companion CD-ROM.\nFigure 4.3.1 shows the class diagram for the SpherePack system.\nTo use the SpherePack system in a simulation, we simply instantiate a\nSpherePackFactory class with the maximum number of spheres, the size of the root\nnode, the size of the leaf node, and the amount of gravy around each SuperSphere.\nThe gravy factor acts as a bit of slop in our coordinate space to prevent objects from\ndetaching from their parent SuperSphere too frequently. For each object in the simu-\nlation, we call the AddSphere () method to create a SpherePack instance. Whenever an\nobject changes position, we invoke the NewPos () method. If the object changes both\nposition and radius, we invoke the NewPosRadiusO method. When an object in the\nSpherePack System\n•'•'•-•';: ^Interface./ :,i£jf!\nSpherefacKallback\nFIGURE 4.3.1 \nThe SpherePack system class diagram.\n",
      "content_length": 2103,
      "extraction_method": "Direct"
    },
    {
      "page_number": 371,
      "chapter": null,
      "content": "4.3 Sphere Trees for Fast Visibility Culling, Ray Tracing, and Range Searching \n387\nsimulation is destroyed, we invoke the RemoveQ method on the SpherePackFactory\nclass.\nThe SpherePackFactory class maintains the complete SphereTree hierarchy and\ncontains the two integration FIFO queues. When performing queries, an interface\ncalled SpherePackCallback is used to extract information from the SphereTree. The\nleaf node SpherePack inherits the properties of a Sphere class.\n",
      "content_length": 472,
      "extraction_method": "Direct"
    },
    {
      "page_number": 372,
      "chapter": null,
      "content": "Compressed Axis-Aligned\nBounding Box Trees\nMiguel Gomez, Lithtech\nmiguel@lithtech.com\nT\nhe axis-aligned bounding box (AABB) tree structure has proven to be very useful\nfor accelerating intersection queries on sets of geometry. The data structure is\neasy to implement, the built structure is numerically well conditioned, and like all\nbinary trees, they have O(log n) search time [Sedgewick90]. This gem explains several\ntechniques that can be used to lower the overall memory footprint of an AABB tree to\n11 bytes per triangle.\nA Brief Survey of Hierarchical Sorting Methods\nThis section covers quadtrees, k-d trees, BSP trees, bounding volume trees, and\naxis-aligned bounding boxes, data structures for sorting three-dimensional sets of\ntriangles.\nQuadtrees, k-d Trees, and BSP Trees\nSome of the most popular data structures for sorting three-dimensional sets of trian-\ngles are the octree, k-d tree, and BSP tree. While the octree is probably the simplest to\nimplement, the more sophisticated k-d and binary space partitioning (BSP) trees\nadapt better to specific sets of geometry. All of these structures use planes to separate\nspace into convex regions, which leads to some serious side effects. First, any triangle\nthat straddles a separating plane must either be split into two pieces, which increases\nthe set of data and can create problematic \"slivers,\" or included in multiple nodes,\nwhich removes any upper bound on the size of the node structure. Second, octrees\nand k-d trees do not separate geometry adaptively, so they may need arbitrary thresh-\nolds to terminate a recursive build algorithm. For example, if many triangles share the\nsame vertex, the octree recursion may never achieve one triangle per node and will\nhave to be terminated based on tree depth. This can lead to unnecessarily deep trees.\nBSP trees that adaptively use the planes of individual triangles for separation do not\nhave this problem, but they still can have problems introduced by splitting.\n388\n",
      "content_length": 1985,
      "extraction_method": "Direct"
    },
    {
      "page_number": 373,
      "chapter": null,
      "content": "4.4 Compressed Axis-Aligned Bounding Box Trees\n389\nBounding Volume Trees\nBounding volume trees approach the problem differently. Instead of dividing space,\nbounding volume trees recursively divide a set of triangles into two subsets and find\na bounding volume that encloses each subset. This approach avoids having to split tri-\nangles or include them in multiple nodes, and building a tree simply stops when a\nsubset has only one remaining triangle. For more information on bounding volume\ntrees, see [vandenBergen99].\nAxis-Aligned Bounding Boxes\nAn axis-aligned bounding box has a position (its center) and extents. As its name\nimplies, the sides of an AABB are parallel to the x-,y-, and z-axes. Figure 4.4.1 shows\nhow an AABB fits a single triangle.\nFIGURE 4.4.1 The sides of an AABB are parallel to the coordinate axes.\nAABB Trees\nThe bounding boxes in an AABB can and often do overlap. Figure 4.4.2 shows a shal-\nlow tree for a set of two connected triangles, L and R. Notice that die left and right\nAABBs overlap.\n",
      "content_length": 1021,
      "extraction_method": "Direct"
    },
    {
      "page_number": 374,
      "chapter": null,
      "content": "390\nSection 4 Geometry Management\n(a)\n(b)\nFIGURE 4.4.2 A) The AABBs for two connected triangles will always intersect. B) The\nAABB tree structure for this particular geometry.\nBuilding AABB Trees\nAn AABB tree is built to by successively dividing a set of triangles into two subsets\nuntil each subset contains only one triangle. The basic algorithm for building an\nAABB tree is:\n• Find the AABB that encloses the entire set.\n• Divide the set into two subsets. This can be done by classifying the centroid of\neach triangle along the major (longest) axis of this AABB. If one subset is empty,\narbitrarily create two subsets of approximately equal size.\n• If a subset contains only one triangle, create a leaf.\n• Otherwise, repeat the same process on each subset.\nCompressing AABB Trees\nIn most applications, 4-byte floats have sufficient precision (seven digits) for specify-\ning box extents, requiring 6 X 4 = 24 bytes at each node. Any binary tree requires\nexactly 2n - 1 nodes to sort n elements, allowing an array of nodes to be allocated\nbefore building the tree. If the data set is large, it might be necessary to specify the\nindices of the child nodes with 4-byte unsigned integers. To avoid having to store yet\nanother 4-byte integer for a triangle index at each node, we can exploit the fact that\nthe 0th node (the root) is never referenced by another node. Therefore, if one of the\nchild node indices is zero, we can consider the node a leaf, and the other integer must\nindex a triangle. This trick gives us a grand total of 32 bytes per node, or about 64\nbytes per triangle as n becomes large. If we are willing to limit our triangle count to\n215 (giving a node count of 216 - 1), unsigned 2-byte integers can be used for child\nnode indices. This reduces the footprint to 28 bytes per node, or about 56 bytes per\ntriangle. Since most applications can divide triangle sets into chunks of 215, 56 bytes\nper triangle will be used as a reference value.\nThere are two important properties of AABB trees that can be exploited to mini-\nmize storage. First, child AABB nodes are fully contained by their parent. This allows\nus to store child extent values as unsigned 8-bit integer offsets relative to their parent's\n",
      "content_length": 2217,
      "extraction_method": "Direct"
    },
    {
      "page_number": 375,
      "chapter": null,
      "content": "4.4 Compressed Axis-Aligned Bounding Box Trees\n391\nextents. Second, at most, six extent values of the child nodes are not identical to those\nof the parent node. This means diat we only need to store six values to fully describe\nthe two children.\nApproximating Extents\nIn order to use unsigned bytes as relative extent values for nodes, we must keep track\nof the floating-point extent values of the parent as the tree is built. By scaling the child\nextents relative to the parent AABB and then truncating to an integer value, we get a\nconservative estimate for the child AABB extents (Figure 4.4.3).\nexact max\ntruncated max\ntruncated min\nexact min\nFIGURE 4.4.3 When approximating extents with unsigned 8-bit integers, min values are\nmeasured from the left, while max values are measured from the right.\nThe error of any extent value relative to its parent is never more than 1/255 ~\n4 X 10~3. To put this in perspective, if the extents of the parent node are one meter on\neach side, we get a resolution of about four millimeters for the child extents. Keep in\nmind that these numbers scale as the nodes become smaller. The equations for calcu-\nlating relative offset values are:\n= trunc 255-\nMid - mm parent\n255-\nW^e \n[0,255].\nUsing 1 byte instead of 4 bytes to store an extent value immediately brings the\nmemory consumption down to 10 bytes per node, or 20 bytes per triangle.\n",
      "content_length": 1378,
      "extraction_method": "Direct"
    },
    {
      "page_number": 376,
      "chapter": null,
      "content": "392\nSection 4 Geometry Management\nExploiting Redundancy\nIn order to store only six extent values for both children, we must take a bold step and\nstore both the left and the right child information within one node structure. In this\nstructure, a bit field is used to indicate which extent belongs to which child. A true bit\nmeans that the unique extent value belongs to the left child (so the parent's extent\nvalue belongs to the right child), and a. false bit indicates the opposite situation. This\nrequires only 6 bits, so the other 2 bits are used to indicate which nodes are leaves.\nWhen information for both children is stored at a single node, the node only con-\nsumes 11 bytes (Figure 4.4.4).\nflags (1 byte)\nextents (6 bytes)\nleft node/triangle\nindex\n(2 bytes)\nright node/triangle\nindex\n(2 bytes)\nFIGURE 4.4.4 The compressed AABB node structure consumes only 11 bytes per node.\nIn addition, only n nodes (including the root) are required to sort n triangles, so\nthe tree now needs only 11 bytes of storage per triangle. (Some architectures may\nrequire a 12-byte structure for alignment.) This is almost 50 percent less than if rela-\ntive values were used alone, and about one-fifth the storage of our reference value. As\nan added bonus, we can now keep track of twice as many triangles (216 - 1 instead of\n215) (Figure 4.4.5).\nIn practice, the root node is a separate data type that specifies the floating-point\nextents of the entire triangle set and is not part of the actual node array, which con-\ntains « - 1 nodes.\nFIGURE 4.4.5 For a set of four triangles, the uncompressed tree requires seven nodes,\nwhereas the tree on the right requires only four.\n",
      "content_length": 1661,
      "extraction_method": "Direct"
    },
    {
      "page_number": 377,
      "chapter": null,
      "content": "4.4 Compressed Axis-Aligned Bounding Box Trees \n393\nRuntime Efficiency\nThe runtime cost of converting the 8-bit values back to floating-point values is mini-\nmal. An experiment in which a line segment was tested for possible intersection with\n16K randomly distributed triangles showed that the compressed structure was about\n10 percent slower than the full floating-point representation. It seems that the ability\nof the significantly smaller data set to fit in the cache nearly compensates for the over-\nhead of converting integers to floating point values.\nFuture Work\nThe compressibility of AABB trees gives them a clear advantage over other structures;\nhowever, it may be possible to apply the same techniques to compress other bounding\nvolume tree structures, such as OBB trees. The fact that child AABB nodes are fully\ncontained by their parent volume allows us to easily scale and share extent values. This\nsame property does not hold for OBB trees [Gottschalk96]. The lack of this property\nmay make it impossible to share redundant extent values; however, it may still be pos-\nsible to store scaled 8-bit extent values and 8-bit orientation values for OBB trees by\npropagating the expanded dimensions back up the tree to the root node.\nReferences\n[Gottschalk96] Gottschalk, S., Lin, M. C., and Manocha, D., \"OBBTree: A Hierar-\nchical Structure for Rapid Interference Detection,\" SIGGRAPH Proceedings,\n1996, pp. 171-180.\n[Sedgewick90] Sedgewick, Robert, Algorithms in C, Addison-Wesley, 1990.\n[vandenBergen99] van den Bergen, G., Collision Detection in Interactive 3D Computer\nAnimation, Ph.D. Thesis, Eindhoven University of Technology, 1999.\n",
      "content_length": 1651,
      "extraction_method": "Direct"
    },
    {
      "page_number": 378,
      "chapter": null,
      "content": "4.5\nDirect Access Quadtree\nLookup\nMatt Pritchard, Ensemble Studios\nmpritchard@ensemblestudios.com\nQ\nuadtrees are versatile and well-known constructs for spatially managing large\namounts of two-dimensional data. In games programming, they are a favorite\nfor managing object locations in a game world, offering good search performance and\nflexible implementation possibilities. In cases where the game data is static, quadtrees\ncan be precalculated, and from a performance standpoint, they are quite efficient.\nBut what about a highly dynamic case, such as in a real-time strategy (RTS) game\nwhen large numbers of objects are constantly in motion and coming into and out of\nexistence in the game world (quadtree)? During the implementation and subsequent\nprofiling of such a scenario, I found that my quadtree update routines were showing\nup surprisingly high on the list of CPU-consuming code. This behavior for a con-\nstantly updating data set led me to ask where the time was actually going, and to look\nfor more efficient ways to get the same job done. The result is the technique that I\npresent here.\nThis technique is a general-purpose optimization for quadtree access that\nimproves performance in three ways over the traditional implementations: 1) by elim-\ninating node traversal and the unnecessary cache-misses it causes, 2) by requiring\nfewer instructions and CPU cycles overall vs. a best case traditional approach, and 3)\nby doing so in a compact amount of time and with minimal memory accesses regard-\nless of what depth in the tree the target node resides in. Because it is general purpose\nin nature, many ways can be found to tweak and adapt this technique to suit the par-\nticular uses that may arise.\nWhere the Performance Goes\nExamining my original quadtree traversal routines (similar to those in Listing 4.5.1)\nshowed almost no fat in the code itself after the compiler optimizations. The search rou-\ntine was just a few lines of code that checked die bounding box of each child node and\ncalled itself recursively if necessary. Generating a CPU cycle count estimate of the num-\nber of calls assuming the worst case where it would recurse to the bottom level of die\nquadtree every time, didn't even begin to add up to die time that the profiles indicated.\n394\n",
      "content_length": 2278,
      "extraction_method": "Direct"
    },
    {
      "page_number": 379,
      "chapter": null,
      "content": "4.5 Direct Access Quadtree Lookup \n395\nIt turns out that the performance drag was much the result of modern computer\narchitecture. The code was constandy touching data through pointers, and then mov-\ning on to other data that wasn't adjacent in memory. The result of this was an\nextremely high cache miss rate. If all of the quadtree updates were queued up sequen-\ntially, most of the upper nodes toward the root node of the quadtree would eventually\nbe in the CPU cache. When the updates weren't queued together, much of the previ-\nously cached quadtree node data would be flushed between calls.\nTo further degrade performance, the code in Listing 4.5.1 is comprised almost\nentirely of comparison functions which, when compiled, result in a large number of\nbranch, jump, and call instructions, and a large number of possible data paths for\neach iteration. On modern CPUs, this stalls the instruction pipeline every time a\nbranch or jump is mispredicted. Due to the nature of the data, this happens more\noften than one might think because, unlike most loops, the branch chosen in a previ-\nous iteration has no relevance to the likelihood of it being taken again.\nEliminating the Middlemen\nBasically, the compact C++ code in Listing 4.5.1 was spending more time waiting on\ndata and instructions than actually executing. Upon further reflection, the vast major-\nity of the data actually being looked at was not needed other than to be eliminated\nfrom consideration. Therefore, the question became: how to get the resultant\nquadtree node without actually examining the quadtree nodes themselves?\nIt is the asking of, or more specifically the answering of, this question that would\neliminate most of the performance hit on the quadtree access routines. Of course, the\nimplementation counts too, and what is presented here is an interesting and very effi-\ncient way to calculate the answer, but it is by no means the only possible solution.\nConditions and Requirements\nThere are two limitations to this technique. First, the quadtree has to be regular;\nthat is, each node is split exactly in the middle on each axis, making all nodes at a\nparticular depth in the tree represent the same size area. Fortunately, most quadtrees\nare implemented this way. Second, the program has to select in advance the maxi-\nmum depth (number of subdivisions) of the quadtree. Again, this is not unusual.\nConsidering these limitations, one might conclude that the area represented by the\nquadtree then needs to be perfectly square, but that's not the case as will be explained\nlater.\nThe only requirement is that the program needs to have array ordered access to\nthe nodes at each level in the tree. This means that either all of the quadtree node\npointers are placed in a linear array ordered by their spatial position, or if the quadtree\nnode elements themselves are a fixed size, then they are stored in an array. Put another\nway, given the x and y node coordinates on a specific level, the address of the quadtree\ndata can be obtained without having to traverse through other nodes.\n",
      "content_length": 3064,
      "extraction_method": "Direct"
    },
    {
      "page_number": 380,
      "chapter": null,
      "content": "396\nSection 4 Geometry Management\nDetermining the Tree Level\nThe first step in directly finding the target quadtree node is determining at what level\nin the tree the target resides. Once that is known, the coordinates of the search object\nwill provide the row and column at which to directly look up the target node. For the\nrest of this gem, when we talk about objects, we are usually referring to their bound-\ning volumes.\nConsider that an object will reside in the root node of a quadtree if its volume\ncrosses the nodes midline for either axis. If it doesn't touch the midlines, it can there-\nfore be wholly contained in one of the node's children (Figure 4.5.1). It is assumed\nthat it already passed the root volume area contain test. The process is repeated until\neither it gets to the bottom level of the quadtree, or it finds a node where the object\ncrosses the midlines. The area check never has to worry about the outer edges, because\nthey were the previous level's midlines and other edges.\nConsider just one axis of the area represented by the quadtree if the total length was\nan exact power of 2, say 256.0 for example, and had nine levels where the lowest leaf\nnodes represented an area 1.0 by 1.0. The midline of the root node would be at 128.0,\nthe midlines of the next level nodes would be at 64.0 and 192.0. Level 3 midlines would\nbe 32.0, 96.0, 160.0, and 224.0. See a pattern here? The transition point for each level\nis at a different power of 2 that direcdy corresponds to the level depth on the tree.\nNow take the same axis of the search object's bounding area, which gives a line\nsegment (x1; x2). What we want to know is the largest power of 2 that it spans,\nbecause that indicates the lowest level of the quadtree in which it can be wholly con-\ntained. Now, \"spanning\" a power of 2 simply means that the range from xl to x2 tran-\nsitions from below the power of 2 value to greater than (or equal to) the value. Since\nour storage requirement is that the object be fully contained inside a quadtree node,\nthe quadtree level to store the object is actually one level higher than the level where\nthe node area size is the specific power of 2 that is crossed.\nA \nB\nFIGURE 4.5.1 A) Objects that cross the node's midlines cannot be stored in child nodes. B)\nObjects that don't cross the midlines are stored in child nodes.\n",
      "content_length": 2342,
      "extraction_method": "Direct"
    },
    {
      "page_number": 381,
      "chapter": null,
      "content": "4.5 Direct Access Quadtree Lookup\n397\nSince the spanning of the value can be represented as a binary transition from 0 to\n1, the program quickly can determine where the spanning occurs by taking the integral\nportions of our range (#1; x2) and XORing them together. Each bit in the result indi-\ncates that the range crosses a point at the corresponding power of 2, returning 1 if there\nwas a transition at that position. The lower the position of the first \"1\" bit of the result,\nthe lower (deeper) in the quadtree the span can be stored. If a zero result occurs (i.e., no\n\"1\" bits in the result), then the range can be stored at the very lowest level in the\nquadtree. Therefore, the bit position of the highest \"1\" bit indicates how many levels\nabove the bottom of the quadtree the range (xl} x2) can first be properly placed.\nHere are some examples using a nine-level, 256.0-length axis that illustrate this\npower of 2 property. Figure 4.5.2 shows a 2D representation of each example, using\nthe x-axis.\n128.0 \n160.0 \n192.0\n1^1J\n_\nI\nr\nj\n1\nExample #1\n(127.8 to 128.3)\nExample #2\n(128.3 to 128.8)\nExample #3\n(155.4 to 166.1)\nFIGURE 4.5.2 Illustration of the examples. Example boxes not to scale for illustrative\npurposes.\nExample #1\nObject bounding line (127.8, 128.3). This object is sitting in the middle of the root\nnode and only fits at the top level. Integer values for (x1; x2) are (127, 128).\nX1 =\nX2=\n127 = 0 1 1 1 1 1 1 1\n128 = 10000000\nXOR result 255 = 11111111\nThe first \"1\" in the result is bit 7 (27) or the 8th position. 9-8 (number of tree\nlevel minus position) gives us 1, or the first level (root level) in the quadtree.\n",
      "content_length": 1636,
      "extraction_method": "Direct"
    },
    {
      "page_number": 382,
      "chapter": null,
      "content": "398 \nSection 4 Geometry Management\nExample #2\nObject bounding line (128.3, 128.8). The object in Example #1 has been nudged just\noff the centerline and should fall all the way down to a leaf node (level 9). Integer val-\nues for (#1, x2) are (128, 128).\nX1= \n128 = 10000000\nX2= \n128 = 10000000\nXOR result \n0 = 00000000\nThere is no \"1\" bit in the result, so we get 0 for the position. 9-0 = 9* level in\nthe quadtree.\nExample #3\nObject bounding line (155.4, 166.1). This is a very big object centered at about 60\npercent of the range. Because of its size compared to the smallest node, it will be at\nleast four levels above the bottom nodes (level 9). Integer values for (#j, x2) are (155,\n166).\nX1= \n155 = 10011011\nX2= \n166 = 10100110\nXOR result 61 = 00111101\nThe first \"1\" is at bit position 6. 9 - 6 = 3rd level in the quadtree.\nMapping to the Situation\nNow that we know how to determine the level for a one-dimensional tree, moving the\nprocess to two dimensions is as simple as repeating the process for each axis and\nchoosing the highest level (in the quadtree) result.\nWhile the preceding examples work because they assume the storage range is a\npower of 2, in most situations the area represented by a quadtree is not going to be an\neven power of 2, and the smallest nodes are not going to just happen to represent an\narea 1.0 by 1.0 in size. Fortunately, the solution is as simple as transforming coordi-\nnate values from the game or applications measuring system to a scale that represents\nthe quadtree's dimensions. This can be accomplished by computing a scale factor for\neach axis during initialization, and multiplying the coordinates by the scale before\nconverting them to integers. For the quadtree scale, 1.0 represents the size of the leaf\nnodes on each axis. (Note that each axis can be independently scaled, allowing rectan-\ngular areas to map to a square node). Thus, the scaled coordinates for an n level\nquadtree will be in the range 0 to 2\"~1 for each axis.\nAfter scaling and converting the coordinates to integers, we XOR together the\nstart and end positions of each axis. There are several ways to determine which bit\n",
      "content_length": 2140,
      "extraction_method": "Direct"
    },
    {
      "page_number": 383,
      "chapter": null,
      "content": "4.5 Direct Access Quadtree Lookup \n399\nposition contains the highest\" 1\" bit. The simplest and most portable is a shift loop to\ncount the bits, but a look-up table may work better for quadtrees with six or fewer\nlevels. Even better, there are platform-specific solutions such as the Pentium's BSR\ninstruction and the PowerPC's cntlzw instruction that bit-scan a value, removing\nlooping and branching in the process. See Listing 4.5.2 for an example of code that\ndetermines the quadtree level using this method and a while loop.\nDetermining the Location\nOnce the level in the quadtree has been determined, the only step remaining is to take\nthe scaled coordinates and extract the row and column positions of the target node. If\nthe target node is on the bottom level, no scaling will be necessary. For each level\nup the tree, the target coordinates have to be scaled down by 2 to reflect the smaller\nnumber of nodes on that level. This scaling can be done simply by right-shifting the\ninteger coordinates by the number of levels the target is from die bottom level. This\ngives the row and column positions to plug into the array lookup for nodes on that level\nof the quadtree. Listing 4.5.3 shows an example function that puts all of this together.\nTraversing the Quadtree\nIf, after locating the search node, there still is a need to traverse the quadtree, all that\nis required is to save the tree level and array row and column positions. By shifting the\nposition values right or left, a program can go up and down the tree levels, and by\nincrementing and decrementing die array positions, it can move adjacently on die\ncurrent tree level.\nTuning the Quadtree\nHere are a couple of quick tips for getting the most out of a quadtree that apply to any\nquadtree access implementation.\nThe first is to make sure that items are being positioned as far down in die tree as\npossible. Improper edge boundary conditions can cause items to be placed much\nhigher than they should be. In the example used of a 256 by 256 tree, an object that\nspanned position 128.0 would be placed in a root node. However, what about objects\nthat only touch, but don't actually span, such as 1.0 sized \"tiles\" that sit at 127.0 to\n128.0? In this case, switching \">=\" or \"<=\" for \">\" or \"<\" or tweaking the object coor-\ndinates with a tiny value can make the difference between root node placement and\nleaf node placement.\nThe next tip is to make sure that the program picks the correct number of levels\nfor the quadtree. If it picks too few, the nodes will be overloaded with items to be\nsearched, when the whole idea is to reduce the size of the search set in the first place.\nToo many tree levels can be just as bad. Many nodes may go empty, wasting space,\nand too much node traversal may be taking place during various operations. It's a\n",
      "content_length": 2811,
      "extraction_method": "Direct"
    },
    {
      "page_number": 384,
      "chapter": null,
      "content": "400 \nSection 4 Geometry Management\ngood idea to add performance counters and statistics to the nonrelease versions of a\nquadtree implementation, and analyze the results using real data, as the optimal set-\ntings will be dependent on the actual data that is encountered.\nFinally, I don't see any reasons why this technique couldn't be adapted to octrees.\nPerhaps someone out there will try this and let me know how well it works.\nListing 4.5.1 Simple implementation of quadtree search\n// Two C++ classes, one to represent the QuadTree and one to\n// Represent each individual node.\n// all variables are class members unless defined\nQuadNode* QuadTree: :GetNodeContaining(const rect &ObjBounds)\n{\nif (RootNode->Contains(ObjBounds) )\nreturn(RootNode->GetNodeContaining(ObjBounds) ) ;\nelse\nreturn(NULL);\n}\nQuadNode* QuadNode: : Get NodeContaining( const rect &0bj Bounds)\n{\nif (lisLeafNode)\n{\nif (ULNode->Contains(ObjBounds)\nreturn(ULNode->GetNodeContaining(ObjBound)) ;\nif (URNode->Contains(ObjBounds)\nreturn(URNode->GetNodeContaining(ObjBound) ) ;\nif (LLNode->Contains(ObjBounds)\nreturn(LLNode->GetNodeContaining(ObjBound) ) ;\nif (LRNode->Contains(ObjBounds)\nreturn(LRNode->GetNodeContaining(ObjBound) ) ;\n}\nreturn(this);\nbool QuadNode: : Contains (const rect &0bj Bounds)\n{\nreturn (Obj Bounds. top \n>= y1 && ObjBounds.left >= x1 &&\nOb j Bounds. bottom <= y2 && Obj Bounds. right <= x2);\n",
      "content_length": 1385,
      "extraction_method": "Direct"
    },
    {
      "page_number": 385,
      "chapter": null,
      "content": "4.5 Direct Access Quadtree Lookup \n401\nListing 4.5.2 Code to determine the level of the target quadnode\nint Quadtree::GetNodeLevelContaining(const rect &ObjBounds)\nint \nxResult = ((int) (ObjBounds.left * QuadXScale)) A\n((int) (ObjBounds.right * QuadXScale));\nint \nyResult = ((int) (ObjBounds.top * QuadYScale)) *\n((int) (ObjBounds.bottom * QuadYScale));\nint \nNodeLevel = NumberOfTreeLevels;\nwhile (xResult + yResult != 0 ) \n//Count highest bit position\nxResult »= 1;\nyResult »= 1;\nNodeLevel--;\nreturn (NodeLevel);\n}\nListing 4.5.3 Code to determine the level of the target quadnode\nQuadNode* QuadTree::GetNodelContaining(const rect &0bjBounds)\nint \nx1 = (int) (ObjBounds.left * QuadXScale);\nint \ny1 = (int) (ObjBounds.top * QuadYScale);\nint \nxResult = x1 \" ((int) (ObjBounds.right * QuadXScale));\nint \nyResult = y1 A ((int) (ObjBounds.bottom * QuadYScale));\nint \nNodeLevel = NumberOfTreeLevels;\nint \nshiftCount = 0;\nwhile (xResult + yResult != 0 ) \n//Count highest bit position\nxResult »= 1;\nyResult »= 1;\nNodeLevel--;\nShiftCount++;\n// Now lookup the node pointer in a 2D array stored linearly\nx1 »= shiftCount; \n// Scale coordinates for\ny1 »= shiftCount; \n// quadtree level\nQuadNode** nodes = NodeLevelPointerArray[NodeLevel];\nreturn (nodes[y1«(NodeLevel-1 )+x1 ]);\n",
      "content_length": 1266,
      "extraction_method": "Direct"
    },
    {
      "page_number": 386,
      "chapter": null,
      "content": "4.6\nApproximating Fish Tank\nRefractions\nAlex Vlachos, ATI Research\nalex@vlachos.com\nT\nhis gem briefly explains a method for approximating the refraction effect seen\nwhen looking through the side of a fish tank. The majority of this gem explains\nhow to construct the transformation matrix that will be applied to the geometry\ninside the tank to simulate the refraction effect.\nFish Tank Observations\nHave you ever had a long wait at a seafood restaurant and spent any time staring at\nthe fish tanks by the lobby? If so, you probably noticed the unique way in which the\ninternal shape of the tank seems to change. Through observation, you'll notice that as\nyou walk by the tank from one side to the other, the back wall of the tank seems to\nshear in the left and right directions. Simultaneously, the tank seems to flatten almost\nto a 2D image when you're at the far left or far right of the tank. Further observations\n(and common sense) show that the height of your head also affects the appearance of\nthe internal shape of the tank in a similar way. An obvious way to simulate diis move-\nment is to concatenate a shear and scale matrix to simulate these observations.\nAlthough there are surely more mathematically savvy methods using Snell's Law\nfor computing refraction rays and so on, this gem focuses on approximating this\nvisual effect based solely on empirical observation. It is important to note that this\ngem refers to fish tanks instead of shark tanks, the difference being the size of the tank\nrelative to the viewer. This algorithm assumes that the viewer is, for the most part, not\nstanding extremely close to the front of the glass. The phrase \"extremely close\" is obvi-\nously a relative one. If you imagine a fish tank that is approximately 3 feet by 2 feet, a\nperson walking by that tank is the scale at which this gem is aimed. If you picture that\nsame person walking in front of a shark tank measuring 30 feet by 10 feet, you'll real-\nize that the person is spending most of his or her time directly in front of the tank rel-\natively close to the glass. Although this algorithm doesn't break down, the visual\neffects are best noticed when the viewer is moving relative to the glass as opposed to\nstanding directly in front of it. Environment mapping makes a similar assumption, so\nthis is nothing new to real-time graphics.\n402\n",
      "content_length": 2345,
      "extraction_method": "Direct"
    },
    {
      "page_number": 387,
      "chapter": null,
      "content": "4.6 Approximating Fish Tank Refractions\n403\nPreeomputations\nGiven a fish tank whose front face has dimensions width and height, the transforma-\ntion matrix that places the center of the front face of the tank at the origin in a certain\norientation can be precomputed (e.g., back of the tank extends down the positive z-\naxis with the positive j/-axis as the up vector). The reason the center of the front face\nis placed at the origin is to facilitate the scale and shear transformations. Once the\ntransformation matrix has been generated, the position of the camera can be trans-\nformed into the space of the fish tank with a simple matrix multiply. This will allow\nall of the computations to happen in that common space (tank space). It's important\nto note that this method is based solely on the position of the camera relative to the\ntank. The view direction of the camera does not affect the visual results.\nScale Factor\nThe scale factor for the tank needs to be computed per frame, which can be visualized\nby bringing the far face of the tank toward the near face (the face through which the\nviewer is looking). When the viewer is standing directly in front of the glass, no scal-\ning should take place. When the viewer is standing off to the side of the tank looking\nacross the face of the glass, the tank is scaled in quite a bit. The effect of this left to\nright motion is shown in Figure 4.6.1.\nGiven the viewer s position in tank space and the center of the glass, the angle to\nthe surface of the tank is computed while taking into account the ratio of the width\nFIGURE 4.6.1 Three shearing and scaling examples based on the viewer's position. The\nuser clip planes are created based on the viewer's position and the edges of the tank glass.\n",
      "content_length": 1751,
      "extraction_method": "Direct"
    },
    {
      "page_number": 388,
      "chapter": null,
      "content": "404\nSection 4 \nGeometry Management\nand height of the tank's glass. If the glass dimensions aren't taken into account, the\nresults across different shapes of glass will be inconsistent.\nThe scale factor is computed using the following method:\n1. Transform the viewer's position into fish tank space. This puts the center of\nthe tank's glass at the origin.\n2. Calculate the vector from the center of the glass (the origin) to the camera,\nbut do not normalize it.\n3. Divide the x- and y-coordinates of the vector by the width and height of the\nglass, respectively.\n4. Divide the z-coordinate of the vector by the depth of the tank (distance\nfrom near to far glass).\n5. Normalize the vector.\n6. Compute the dot product of this vector and the face normal of the glass in\ntank space (0, 0, -1). This scalar value clamped 0.0 to 1.0 will serve as the\nscale factor.\nAssuming the tank was transformed to the origin as explained previously, the\nscale would take place along the .zr-axis.\nShear Factor\nThe shear factor must also be computed per frame. Two separate shear values need to\nbe generated: one for the x-axis and one for the y-axis. For the shear along the x-axis,\nwe create a 2D vector composed of the x- and z-coordinates of the vector computed\nfor the scale factor and normalize it. The x-component of the normalized 2D vector is\nused for the shearing along the x-axis. Similarly, we create a 2D vector composed of\nthe y- and z-coordinates, normalize it, and use the x-component of the normalized\n2D vector for the shearing along the y-axis. Experimentation has shown that limiting\nthe shear values in x to 0.75 and in y to 0.25 helps reduce unwanted effects.\nComposing the Matrix\nThe scale and shear factors can be placed into a single matrix:\n1 \n0 \nshearx \n0\n0 \n1 \nsheary \n0\n0 \n0 \nscale \n0\n0 0 0 \n1\nUser Clip Planes and the Stencil Buffer\nWhen visualizing what happens to the geometry after the shear and scale transforma-\ntions are applied, it becomes apparent that the geometry ends up touching pixels that\n",
      "content_length": 2013,
      "extraction_method": "Direct"
    },
    {
      "page_number": 389,
      "chapter": null,
      "content": "4.6 Approximating Fish Tank Refractions \n405\nwere never intended to be modified. To solve this problem, if the fish tank glass is rec-\ntangular in shape, enabling four user clip planes from the position of the viewer to the\nfour borders of the glass will solve the problem (Figure 4.6.1). This will clip all of\nthe sheared geometry that could otherwise be seen from the outside of the tank. If the\nglass is circular or some other nonrectangular shape, the stencil buffer will need to be\nused in place of user clip planes to stencil out the pixels that don't belong to the fish\ntank glass.\nImproving the Reality\nSo far, this method describes how to make the geometry on the inside of the tank look\nas if it's filled with water. There is still much room for improvement. The first\nimprovement that can be done is to apply caustic textures. In short, caustics are the\npatterns of light that appear on the bottom of a water-filled volume. These patterns\nare caused by light refracting as it passes from outside the tank through the surface of\nthe water at the top. While it is nice to have caustic effects that correspond roughly to\nthe simulation of the water surface, acceptable caustics can be created by simply\nscrolling two caustic textures across all of the geometry in the tank using projective\ntextures.\nThe next obvious visual cue that is missing is making the outside of the glass\nreflective. A simple way to get nice reflections on glass is to render the reflected geom-\netry of the glass into a renderable texture and then texture from that to give the illu-\nsion of a transparent reflective surface.\nTo give the viewer the ability to see through the water at the top of the tank, we\ncould use another renderable texture to render what could be seen if there were no\nwater in the tank. We could then apply environment-mapped bump mapping (or any\nother applicable pixel shader that uses dependent texture reads) to that renderable tex-\nture to give the illusion of animated water.\nObviously, this algorithm can be applied to each separate face of the fish tank. In\naddition, higher order culling can be performed if the vertices defining each side of\nthe glass are outside the current view frustum. This method for culling large groups of\npolygons can be applied to each individual pane of glass.\nConclusion\nSimulating refractions through a planar surface can be very simple to fake. When\ncombined with other real-time rendering techniques, it is possible to create a very\nconvincing approximation to the real world.\n",
      "content_length": 2524,
      "extraction_method": "Direct"
    },
    {
      "page_number": 390,
      "chapter": null,
      "content": "4.7\nRendering Print Resolution\nScreenshots\nAlex Vlachos and Evan Hart,\nATI Research\nalex@vlachos.com and ehart@ati.com\nW\nith the recent advances in real-time graphics technology, games have become\nfantastically rich in visual quality. While these images are great for display on a\ncomputer monitor that is typically 72 dots per inch (dpi), they are somewhat less\nappealing when displayed in print. Print resolution is typically a minimum of four\ntimes finer than monitor resolution in each dimension. Thus, a one-to-one mapping\nof the screen pixels to the dots on the printed page results in postage-stamp-sized\nscreenshots. One solution to this problem is to enlarge the source image in the page\nlayout software, but this results in blocky images that sell the original content short.\nThe simple solution to this problem is to take the screen shots at a higher frame\nbuffer resolution. Naturally, the larger buffer can be an offscreen surface, so that it is\nnot tied to the monitor's supported resolutions. This still poses problems, as most\naccelerators are only designed to render to the maximum resolution of monitors, leav-\ning the programmer with at best a 2048 by 2048 screenshot. Although this resolution\nmay sound sufficient, it won't cover a full magazine page at 300 dpi. This approach\nalso takes up 32MB of graphics memory for a single color buffer and a depth buffer.\nThe solution proposed here is to break the task into the rendering of several\nsmaller subimages. These subimages can then be pasted together to form a screen shot\nof arbitrary resolution. This gem focuses on the projection matrix tricks required to\ndo this seamlessly.\nBasic Algorithm\nSince current graphics hardware cannot render the resolutions required for print, the\ndesired final image must be divided into a grid of subimages and pasted together. In\nthe example code later in this gem, the dimensions for each of the subimages are\nassumed to be equal to the frame buffer dimensions. Although the subimages must\nbe a supported rendering resolution by the graphics hardware, setting the viewport\n406\n",
      "content_length": 2085,
      "extraction_method": "Direct"
    },
    {
      "page_number": 391,
      "chapter": null,
      "content": "4.7 \nRendering Print Resolution Screenshots\n407\nsize to anything smaller than the frame buffer will allow this method to handle arbi-\ntrary dimensions.\nFigure 4.7.1 shows how an image can be segmented into a grid of subimages. Six\nfrustum planes define a projection matrix: near, far, left, right, top, and bottom. For\neach subimage, new left, right, top, and bottom planes are computed that will define\na unique projection matrix for rendering that subimage.\nTaking the screen shot involves three steps:\n1. Calculate the frustum planes.\n2. Determine the intermediate planes.\n3. Render each subimage using its own frustum composed of the intermediate\nplanes.\nFirst, the frustum planes for the projection matrix are computed as six scalars.\nThe near and far values are simply the distance from the eye to the near and far\nplanes, while the left, right, top, and bottom values are defined by the points at which\nplanes intersect the near plane. Section 3.5 of Real-Time Rendering has an excellent\ndescription of the meaning of these values [Moller99].\nNext, the intermediate plane values Hn and Vn are computed by linearly interpolat-\ning the top and bottom values and the left and right values, respectively.\nFinally, the frustum for each subimage is composed of the bordering Hn and Vn\nvalues for the left, right, top, and bottom. The projection matrix can be generated by\nh\n3072 Pixels\nFIGURE 4.7.1 Segmentation of the image.\nH\nPaneO\n1\nffi\n00\n1024 Pixels\ntop\n2*top/\nH2\ntop/3 +\nH3\nV0 \nV, \nV2 \nV3 bottom\neft \n2*left/3 + right/3 left/3 + 2*right/3 right\n",
      "content_length": 1552,
      "extraction_method": "Direct"
    },
    {
      "page_number": 392,
      "chapter": null,
      "content": "408 \nSection 4 Geometry Management\ncalling either glFrustum() or D3DXMatrixPerspectiveOffCenter(). When rendering\ninto each of the subimages, the entire scene is rendered normally.\nFollowing is a simple code example for manually building the projection matrix\nfor both OpenGL and Direct3D for a 3x3 grid of subimages.\nconst float GPG_PI = 3.14159265f;\ninline float GpgDegToRad(float D) { return ((D) * (GPG_PI/180.0f)); }\nvoid GpgPerspective (double fovy, double aspect, double Near, double\nFar, int subrect)\n{\ndouble fov2, left, right, bottom, top;\nfov2 = GpgDegToRad(fovy) * 0.5;\ntop = Near/(cos(fov2)/sin(fov2));\nbottom = -top;\nright = top*aspect;\nleft = -right;\nif (subrect == -1) \n//Regular full screen\nGpgFrustum (left, right, bottom, top, Near, Far);\nelse if (subrect == 0) //UL\nGpgFrustum(left, left/3.0, top/3.0, top, Near, Far);\nelse if (subrect == 1) //UC\nGpgFrustum(left/3.0, right/3.0, top/3.0, top, Near, Far);\nelse if (subrect == 2) //UR\nGpgFrustum(right/3.0, right, top/3.0, top, Near, Far);\nelse if (subrect == 3) //ML\nGpgFrustum(left, left/3.0, bottom/3.0, top/3.0, Near, Far);\nelse if (subrect == 4) //MC\nGpgFrustum(left/3.0, right/3.0, bottom/3.0, top/3.0, Near, Far);\nelse if (subrect == 5) //MR\nGpgFrustum(right/3.0, right, bottom/3.0, top/3.0, Near, Far);\nelse if (subrect == 6) //BL\nGpgFrustum(left, left/3.0, bottom, bottom/3.0, Near, Far);\nelse if (subrect == 7) //BC\nGpgFrustum(left/3.0, right/3.0, bottom, bottom/3.0, Near, Far);\nelse if (subrect == 8) //BR\nGpgFrustum(right/3.0, right, bottom, bottom/3.0, Near, Far);\n}\nvoid GpgFrustum (double left, double right, double bottom, double\ntop, double zNear, double zFar)\n{\nfloat matrix[16] = { 1.0f, O.Of, O.Of, O.Of,\n0.Of, 1.Of, 0.Of, 0. Of,\nO.Of, O.Of, 1.0f, O.Of,\n0. Of, 0. Of, 0. Of, 1 . Of } ;\n#ifdef GPG_OPENGL_API\nmatrix[0] = (float)(2.0*zNear/(right-left));\nmatrix[5] = (float)(2.0*zNear/(top-bottom));\nmatrix[8] \n= (float)((right+left)/(right-left));\n",
      "content_length": 1936,
      "extraction_method": "Direct"
    },
    {
      "page_number": 393,
      "chapter": null,
      "content": "4.7 Rendering Print Resolution Screenshots \n409\nmatrix[9] \n= (float) ((top+bottom)/ (top-bottom) );\nmatrix[ 10] = (float) (-(zFar+zNear)/(zFar-zNear) );\nmatrix[11] = (float) (-1 .0) ;\nmatrix[14] = (float) (-(2.0*zFar*zNear)/(zFar-zNear) ) ;\n#else //DirectSD\nmatrix[0] \n= (float) (2. 0*zNear/ (right-left j) ;\nmatrix[5] \n= (float) (2. 0*zNear/ (top-bottom) );\nmatrix[8] = (float) ((right+left)/(right-left)) ;\nmatrix[9] \n= (float) ((top+bottom) /(top-bottom) );\nmatrix[10] = (float) (-(zFar)/(zFar-zNear)) ;\nmatrix[11] = (float) (-1 .0) ;\nmatrix[14] = (float32) (-(zFar*zNear)/(zFar-zNear)) ;\n#endif\n//Now set this matrix as the current projection matrix\nCaveats and Concerns\nAs with any rendering algorithm, the programmer must pay attention to how this\ntechnique interacts with any special tricks performed by the graphics engine. The pro-\ngrammer should be aware that the utilization of multiple images to create the screen\nshot could affect Gouraud shading in the case of very large polygons in the scene. Due\nto the multiple projections, large polygons can possibly be clipped at all the subimage\nboundaries, resulting in lighting artifacts. Additionally, the programmer should\ntake care to handle any special effects that require rendering into textures. The resolu-\ntion for these images may also need to be increased for optimal results. Of course, if\nanything in the scene is animated, one should make sure that the same exact time is\nused in the animation when each of the subimages is rendered.\nWhile we have referred to the Direct3D and OpenGL graphics APIs directly and\nimplied the use of PC hardware, this technique would work equally well on game\nconsoles where the screen shot problem is the worst. On these devices especially, gam-\ning magazines are forced to jump through all sorts of hoops to get terrible screen grabs\nfrom NTSC signals.\nIs this technique cheating? No. This method is equivalent to running your game\nat a higher resolution. You're not misrepresenting your work by providing large print-\nresolution screenshots to a gaming magazine. We have used this technique for color\nplates in Real-Time Rendering and Game Programming Gems and have been very\npleased with the results.\nConclusion\nWe have presented a technique for rendering print-resolution screenshots using\ngraphics hardware. Since it is not possible to directly render the high-resolution\nimages required for print, we have shown how to divide the desired final image into a\n",
      "content_length": 2465,
      "extraction_method": "Direct"
    },
    {
      "page_number": 394,
      "chapter": null,
      "content": "410 \nSection 4 Geometry Management\ngrid of subimages that are rendered separately. This allows content developers to show\ntheir games in the best light in print media.\nReferences\n[Moller99] Moller, Tomas, and Eric Haines, Real-Time Rendering, AK Peters, 1999.\n",
      "content_length": 260,
      "extraction_method": "Direct"
    },
    {
      "page_number": 395,
      "chapter": null,
      "content": "4.8\nApplying Decals to Arbitrary\nSurfaces\nEric Lengyel, C4 Engine\nIengyel@c4engine.com\nI\nany games need to render special effects such as scorch marks on a wall or foot-\nprints on the ground that are not an original part of a scene, but are created dur-\ning gameplay. These effects are commonly implemented by creating a new object,\nwhich we will call a decal, which coincides with an existing surface, and rendering it\nusing some type of depth offset technique (for example, see [LengyelOO]). Applying a\ndecal to the interior of a planar surface is simple, but difficulties arise when applying\ndecals to the more complex surfaces used in today's games to represent curved objects\nand terrain patches. This gem presents a general method for applying a decal to an\narbitrarily shaped surface and concurrently clipping the decal to the surface s boundary.\nThe Algorithm\nWe begin with a point P that lies on an existing surface and a unit normal direction N\nthat is perpendicular to the surface at diat point. The point P represents die center of\nthe decal and may be the point at which a projectile has impacted the surface or the\npoint where a character s foot has stepped on the ground. A unit tangent direction T\nmust also be chosen in order to determine die orientation of the decal. This configu-\nration is illustrated in Figure 4.8.1.\nFIGURE 4.8.1 Configuration of a decal.\n411\n",
      "content_length": 1382,
      "extraction_method": "Direct"
    },
    {
      "page_number": 396,
      "chapter": null,
      "content": "412 \nSection 4 Geometry Management\nGiven the point P and the directions N and T, we have an oriented plane that is tan-\ngent to the surface geometry at P. We can carve a rectangle out of this plane that rep-\nresents the area of our decal by constructing four boundary planes that are parallel to\nthe normal direction N. Let w and h be the width and height of the decal. Then the\n4D vectors corresponding to the four border planes are given by\nw \nI\nright = -T, — + T • P\nbottom = B, \nB • P\ntop = [-B, - + B • P | \n(4.8.1)\nwhere B = N X T. We will generate a triangle mesh for the decal object by clipping\nnearby surfaces to the four boundary planes. We also want to clip to front and back\nplanes to avoid bleeding through to parts of the same surface mesh that may be inside\nthe boundary planes, but far in front of or behind the point P. The 4D vectors corre-\nsponding to the front and back planes are given by\nfront = (-N, d + N • P)\nback = (N, d - N • P) \n(4.8.2)\nwhere d is the maximum distance that any vertex in the decal may be from the tan-\ngent plane passing through the point P.\nThe algorithm proceeds as follows. First, we identify which surfaces in the world\nmay potentially be affected by the decal. This may be determined by locating any sur-\nfaces whose bounding volume reaches within a certain distance of the point P. For\neach potentially affected surface, we individually examine each triangle in the surface's\nmesh. Let M denote the unit normal direction corresponding to the plane of a trian-\ngle in the mesh. We throw out any triangles for which N • M < £ for some fixed posi-\ntive value E, since these triangles are facing away from the decal s normal direction N.\nRemaining triangles are clipped to the planes given by Equations 4.8.1 and 4.8.2 and\nstored in a new triangle mesh.\nWhen a triangle overlaps any of the planes and needs to be clipped, we interpo-\nlate the normal vectors as well as the vertex positions so that we can later apply color-\ning to the clipped vertices that reflects the angle between each vertex's normal and the\ndeed's normal direction. This has the effect of smoothly fading the decal texture in\n",
      "content_length": 2146,
      "extraction_method": "Direct"
    },
    {
      "page_number": 397,
      "chapter": null,
      "content": "4.8 Applying Decals to Arbitrary Surfaces \n413\nrelation to each triangle's orientation relative to the plane of the decal. We assign an\nalpha value to each vertex using the equation\nN ' R - e\nR\nalpha = \n(4.8.3)\nwhere R is the (possibly unnormalized due to interpolation) normal corresponding to\nthe vertex. This maps the dot product range [e,l] to the alpha value range [0,1].\nTexture mapping coordinates are applied to the resulting triangle mesh by mea-\nsuring the distance from the planes passing through the point P and having normal\ndirections T and B. Let Q be the position of a vertex in the decal's triangle mesh.\nThen the texture coordinates s and t are given by\nw \n2\nB • (Q - P) !\nt = — \n- + -\nh \n2 \n(4.8.4)\nTriangle Clipping\nEach triangle belonging to a surface that is potentially affected by the decal is treated\nas a convex polygon and is clipped to each of the six boundary planes one at a time.\nClipping a convex polygon having n vertices to a plane results in a new convex poly-\ngon having at most n + 1 vertices. Thus, polygons that have been clipped against all\nsix planes may possess as many as nine vertices. Once the clipping process is complete,\neach polygon is treated as a triangle fan and added to the decal's triangle mesh.\nTo clip a convex polygon against an arbitrary plane, we first classify all of the ver-\ntices belonging to the polygon into two categories: those that lie on the negative side\nof the plane, and those that lie on the positive side of the plane or on the plane itself.\nIf all of the polygon's vertices lie on the negative side of the plane, the polygon is dis-\ncarded. Otherwise, we visit every pair of neighboring vertices in the polygon looking\nfor edges that intersect the clipping plane. As shown in Figure 4.8.2, new vertices are\nadded to the polygon where such intersections occur, and vertices lying on the nega-\ntive side of the plane are removed.\nSuppose that the vertex V, lies on the positive side of the clipping plane C, and\nthat the vertex V2 lies on the negative side of C. A point V3 lying on the line segment\nconnecting Vj and V2 can be expressed as\nV3 = V1 + t(V2-V1) \n(4.8.5)\n",
      "content_length": 2143,
      "extraction_method": "Direct"
    },
    {
      "page_number": 398,
      "chapter": null,
      "content": "Section 4 Geometry Management\nFIGURE 4.8.2 Clipping a polygon against a plane.\nwhere the parameter t satisfies 0 < t < 1. We would like to know for what value of t the\npoint v3 lies on the plane C. If we treat the V, as a homogeneous vectors having w-\ncoordinates of one, then we simply need to find the value of t for which the 4D dot\nproduct C • V3 is zero. Plugging in the right side of Equation 4.8.5 for V3 and solving\nfor t gives us\nt =\nO V,\no(v,-v2)\n(4.8.6)\n(Note that the difference V\\ — V2 has a zf-coordinate of zero.) Substituting this\nvalue of t back into Equation 4.8.5 gives us our new vertex.\nImplementation\nThe source code on the companion CD-ROM demonstrates the algorithm presented\nin this article through the implementation of a C++ class called Decal. The construc-\ntor of this class takes the decal center P, the normal direction N, and the tangent direc-\ntion T as parameters, as well as the width, height, and depth of the decal. After\ncalculating the boundary planes using Equations 4.8.1 and 4.8.2, the constructor\nclips all potentially affected surfaces to these planes and stores the resulting mesh in a\nnew triangle array. Vertex colors and texture mapping coordinates are then assigned\nusing Equations 4.8.3 and 4.8.4. The source code generated the scorch marking decal\nshown in Figure 4.8.3.\n",
      "content_length": 1322,
      "extraction_method": "Direct"
    },
    {
      "page_number": 399,
      "chapter": null,
      "content": "4.8 Applying Decals to Arbitrary Surfaces\n415\nI*»s»«3iS(g3t8««»*8K\nFIGURE 4.8.3 A scorch mark decal applied to a curved surface.\nReferences\n[LengyelOO] Lengyel, Eric, \"Tweaking a Vertex's Projected Depth Value,\" Game\nProgramming Gems, Charles River Media, 2000, pp. 361-365.\n",
      "content_length": 275,
      "extraction_method": "Direct"
    },
    {
      "page_number": 400,
      "chapter": null,
      "content": "4.9\nRendering Distant Scenery\nwith Skyboxes\nJason Shankel, Maxls\nshankel@pobox.com\nC\nonsider a game that takes place on a Tibetan mountaintop. In the distance, we\ncan see the ridge of the Himalayas, clouds in the sky, and a village down in the\nvalley. Or, consider a game in deep space, with the Eagle and Orion nebulae shining\nfrom light-years away. Such imagery can heighten the beauty and sense of immersion\nof a 3D game.\nRendering distant scenery in 3D can be accomplished with skyboxes. This gem\nexplains the principle of skyboxing and describes alternative means for rendering a\nskyboxed scene.\nBasic Technique\nThe idea behind a skybox is very simple. Distant scenery is rendered onto six textures,\neach of which is applied to one side of a cube. The camera is placed at the center of\nthe cube. The camera can rotate freely within, but never move from the center of this\ncube. When the scene is rendered, the images projected on the walls of the skybox\ngive the impression of distant scenery much in the same way images projected onto\nthe ceiling of a planetarium give the impression of the night sky (Figure 4.9.1).\nSkybox Resolution\nIdeally, one texel in die skybox object should map to one pixel on the screen. The fol-\nlowing formula can be used to determine the ideal skybox resolution for a given\nscreen resolution\nscreenRes\nskyboxRes =\ntan.(fov/z)\nwhere skyboxRes is the resolution of one side of the skybox in texels, screenRes is the\nwidth of the screen in pixels, andyof is the angle of the horizontal field of view. For\nexample, a scene with a 90-degree field of view running at 640x480 would have an\nideal skybox resolution of 640 texels.\n416\n",
      "content_length": 1661,
      "extraction_method": "Direct"
    },
    {
      "page_number": 401,
      "chapter": null,
      "content": "4.9 Rendering Distant Scenery with Skyboxes\n417\nFIGURE 4.9.1 Skybox as seen from above: distant terrain is rendered on the sides of the\nbox, and the camera is placed at the center.\nSome 3D systems limit texture resolution to 256x256 texels. This means that the\nskybox textures may be stretched noticeably when rendered to the screen. For some\napplications, this stretching may be acceptable. Others may wish to subdivide each\nskybox face to increase texture resolution (Figure 4.9.2).\nFIGURE 4.9.2 Subdividing the skybox's faces will improve image quality at the cost of\nincreased texture memory and polygon count. Upper left) One texture per side. Upper\nright) Four textures per side. Lower left) Sixteen textures per side.\n",
      "content_length": 725,
      "extraction_method": "Direct"
    },
    {
      "page_number": 402,
      "chapter": null,
      "content": "418 \nSection 4 Geometry Management\nSkybox Size\nBecause the camera is always at the center, it does not matter how big we make the\nskybox as long as it falls within the viewing frustum. As the size of the skybox\nincreases, its walls become proportionally more distant, keeping the same portion in\nframe.\nThe skybox dimensions should be chosen so that the farthest points, the corners,\nare closer to the camera than the far clipping plane. The following formula can be\nused to calculate the maximum skybox size:\nskyboxWidth <\nwhere skyboxWidth is the length of one edge of the skybox in world units, and zf aP. is\nthe distance to the far clipping plane in world units.\nRendering the Scene\nThe simplest technique for drawing a skybox is to render an ordinary textured cube,\naligned to the world axes and centered on the camera's world position. The skybox\nshould be the first thing rendered. There is no need to clear the color buffer first, as\nthe skybox will always fill the entire screen.\nWhen rendering a skybox, both depth testing and depth writing should be dis-\nabled, as the skybox geometry will not intersect properly with the other geometry in\nthe scene. Lighting, fogging, and any other similar effects should also be disabled.\nThe skybox images should be rendered without any atmospheric modification.\nAs noted earlier, a simple one-texture-per-face cube may produce significant tex-\nture stretching. Texture filtering can be used to reduce the effect of this stretching.\nTexture filtering reduces the jagginess of stretched images by sampling neighboring\ntexels and blending them together.\nTexture filtering may cause seams to appear along the edges of the skybox, where\ntwo textures meet. These seams are caused by improper texture wrapping. Texture\nwrapping determines how the texture filter decides which texels \"neighbor\" the texels\nat the edge of a texture. If texture wrapping is set to repeat (GL_REPEAT in OpenGL),\ntexels on one edge will be combined with texels on the opposite edge, causing seams\nbetween textures to stand out.\nIn OpenGL, texture wrapping should be set to GL_CLAMP_TO_EDGE_EXT, if possi-\nble. This will clamp filtering to the edge the texture, eliminating interference from\nborder texels. GL_EXT_texture_edge_clamp is an OpenGL extension, so it might\nnot be available on all systems. If the GL_CLAMP_TO_EDGE_EXT mode is not available,\ntexture filtering should be set to GL_CLAMP, which combines edge texels with the tex-\nture's constant border color.\n",
      "content_length": 2488,
      "extraction_method": "Direct"
    },
    {
      "page_number": 403,
      "chapter": null,
      "content": "4.9 Rendering Distant Scenery with Skyboxes\n419\nCube Environment Mapping\nCube environment mapping is an alternative to traditional skybox rendering. Cube\nenvironment mapping combines all six sides of a skybox into a single texture.\nTraditionally, texture coordinates are specified as offsets into a two-dimensional\ntexture map, with (0,0) being one corner of the texture, and (1,1) being the opposite\ncorner. In cube environment mapping, six textures are combined to form a cube, and\ntexture coordinates are specified as three-dimensional vectors, pointing outward from\nthe center of the cube to a point on its surface (Figure 4.9.3).\nCube environment mapping can be used to render distant scenery, and to cast\nreflections of the skybox on nearby shiny objects.\nCube environment mapping limits skyboxes to one 2D texture per face, so subdi-\nviding faces to increase resolution is not possible. Fortunately, most cube environ-\nment mapping systems support texture resolutions above 256x256.\nFIGURE 4.9.3 Texture coordinates for cube environment maps are specified as vectors\npointing to the surface of a cube centered on the origin.\nGenerating Skybox Textures\nSome software packages provide direct support for generating skyboxes. For those\nthat don't, manually generating skybox images is simple.\nThe size of the output image should be set to texture resolution (e.g., 256x256)\nand the camera's field of view set to 90 degrees. Six renderings are generated, with the\ncamera looking up and down each of the three cardinal axes (left, right, up, down, for-\nward, and back).\n",
      "content_length": 1572,
      "extraction_method": "Direct"
    },
    {
      "page_number": 404,
      "chapter": null,
      "content": "420 \nSection 4 Geometry Management\nConclusion\nA sense of place is critical to most 3D games. Rendering distant scenery not only\nincreases visual beauty, it also provides players with a means of orienting themselves in\nthe virtual environment. Skyboxes provide an economical and effective way to render\ndistant scenery.\nSource Code\nSample source code is provided using OpenGL and GLUT. The sample program\ndemonstrates both 2D and cube environment map rendering.\nCube environment mapping is supported in OpenGL via the GL_ARB_texture_\ncube_map extension. The sample code checks for the presence of this extension at\nstartup. In cube environment map mode, a shiny object is placed in the camera's view,\ndemonstrating reflectance.\nSkybox textures were generated with Terragen (Copyright © 1997—2000 Planet-\nside Software).\n",
      "content_length": 819,
      "extraction_method": "Direct"
    },
    {
      "page_number": 405,
      "chapter": null,
      "content": "4.10\nSelf-Shadowing Characters\nAlex Vlachos, David Gosselin, and\nJason L. Mitchell; ATI Research\nalex@vlachos.com, gosselin@ati.com,\njasonm@ati.com\nR\nendering self-shadowing characters is an important visual cue missing from most\nreal-time games. This gem presents a projective texture approach, which enables\nself-shadowing of convex subsections of characters in real time. After breaking the\ncharacter into convex subsections, the subsections are rendered into a texture with\nvarying alpha values from the point of view of the light source. When the character is\nrendered from the viewer's point-of-view, this texture is projected back onto the con-\nvex subsegments of the character, simulating the occlusion of each subsegment with\nrespect to the light source. Being map based rather than stencil-volume based, this\ntechnique requires no additional work to be compatible with higher-order surface tes-\nsellation techniques.\nPrevious Work\nProjective techniques for shadowing started with [Williams78] and have been refined\nin many papers. This gem breaks with the depth-based shadow mapping and uses a\ntechnique similar to the priority buffers of [Hourcade85]. [LengyelOO] also uses a\nsimilar segmented technique.\nSegmenting Character Geometry\nThe first step in this algorithm is grouping the character geometry. The artist tags\nbones to form groups of geometry that will shadow the other groups of geometry.\nThese groups should be selected to reduce the segmenting of the model but retain the\nshadowing relationships. During preprocessing, the dominant bone for each polygon\nwill be determined by finding the bone that has the largest blending weight. The tag\nwill then be extracted from this bone and the polygon will be placed in the appropri-\nate group. See Figure 4.10.1 for an example of a segmented model.\n421\n",
      "content_length": 1819,
      "extraction_method": "Direct"
    },
    {
      "page_number": 406,
      "chapter": null,
      "content": "422\nSection 4 Geometry Management\nFIGURE 4.10.1 Segmented model.\nRendering the Texture\nOnce the character has been logically divided into convex subsegments, these groups\nare sorted from front to back with respect to the light source. Since there are usually a\nrelatively small number of groups in a given character, this sorting is an insignificant\ncomputational burden. The character in Figure 4.10.2, for example, has only six\ngroups to sort. Then a view matrix is computed from the light's point of view such\nthat is centered on the center of the bounding box surrounding the object. A perspec-\ntive projection matrix is also generated to have the character fill as much of the ren-\nderable texture as possible.\nThe basic steps are:\n1. Compute light matrix.\n2. Clear renderable texture with (255, 255, 255, 255).\n3. Draw each of the subsegments into the alpha texture from front to back\n(from the light's point of view) with increasing alpha values: 0, 1, 2, 3,4,...\n254. (255 is reserved as the alpha clear color.)\nNote that the rate of increasing the alpha values can be spread out to cover the\nentire range of alpha values available based on the number of groups being rendered.\nThis will help to remove rendering artifacts, which is explained in the next section.\n",
      "content_length": 1272,
      "extraction_method": "Direct"
    },
    {
      "page_number": 407,
      "chapter": null,
      "content": "4.10 Self-Shadowing Characters \n423\nRendering the Character\nOnce the shadow map is created, the next step is to render the character into the\nframe buffer using the shadow map. In a brute-force approach, this is accomplished in\nthree passes. The first pass renders a fully lit character into the frame buffer. The sec-\nond pass renders each of the subsegments of the character with an alpha test of less\nthan the alpha value that was used to draw the subsegment into the shadow buffer.\nThis is done for two reasons/The first reason is to use only those parts of the shadow\nbuffer that would be shadowing the character. Since the shadow buffer was segmented\nusing the alpha values, setting the alpha test of less than retrieves the shadows of all\nthe previous groups (the ones closer to the light). The second reason for using the\nalpha test is to effectively shrink the shadows by half a pixel in order to avoid pulling\nunwanted alpha values in from bilinear texture fetching. The texture matrix is set to\ntake the world space position of the object and transform it by the light's view and\nprojection matrix tliat was calculated when rendering to the texture. The pixels\nthat pass the alpha test are drawn in black, effectively masking out the lighting in the\nfirst pass. The final pass draws the character with its base color modulated by a small\nambient term to brighten the areas in shadow by an ambient term. Figure 4.10.2\nshows the results of this rendering over several frames of animation. This is obviously\na brute-force approach and can be optimized using pixel shaders.\nFIGURE 4.10.2 Character rendered, with shadows from three different angles.\nConclusion\nWe presented a way to render animated characters with self-shadowing using a pro-\njective texture technique. By segmenting the character into convex subsegments, we\navoided the aliasing found in purely depth-based approaches. The approach is also\ngeneral enough to be used by any graphics hardware that supports rendering to tex-\ntures and projective texture mapping.\n",
      "content_length": 2036,
      "extraction_method": "Direct"
    },
    {
      "page_number": 408,
      "chapter": null,
      "content": "424 \nSection 4 Geometry Management\nReferences\n[Hourcade85] Hourcade, J. C., and Nicolas, A., \"Algorithms for Antialiased Cast\nShadows,\" Computers and Graphics, vol. 9, no. 3, pp. 259-264.\n[LengyelOO] Lengyel, Jerome E., \"Splatting for Soft-Edged Shadows,\" Microsoft\nTechnical Report, 2000.\n[Williams78] Williams, Lance, \"Casting Curved Shadows on Curved Surfaces,\"\nComputer Graphics (SIGGRAPH 78 Proceedings), vol. 12, no. 3, 1978, pp.\n270-274.\n",
      "content_length": 445,
      "extraction_method": "Direct"
    },
    {
      "page_number": 409,
      "chapter": null,
      "content": "4.11\nClassic Super Mario 64\nThird-Person Control and Animation\nSteve Rabin, Nintendo of America\nsteve rabin@hotmail.com\nT\nhe classic Super Mario 64 control scheme has easily become one of the most intu-\nitive ways to control a 3D character from a third-person perspective. While the\ngame Super Mario 64 didn't invent the technique, it did manage to polish it and pop-\nularize it with millions of gamers. It's routinely used as the measuring stick of an\nextremely playable control scheme. However, the real beauty is that it makes sense to\neven a first-time player, which is no small accomplishment.\nThis gem will deal with the basic issues of controlling and animating a character\nfrom a third-person perspective. While it seems straightforward enough (just copy\nSuper Mario 64), it's not as trivial as it first appears. There are many small nuggets of\nwisdom that can often take weeks of trial and error to discover.\nThe Setup\nThe classic Super Mario 64 control incorporates a free-floating camera that follows the\ncharacter around wherever he may go. Imagine the camera hovering behind him\nattached by a bungee cord to his body. As the character moves from a stand to a run,\nthe camera smoothly accelerates toward the character trying to maintain a fixed dis-\ntance from him. As the character turns, the camera gently circles around trying to stay\nbehind him.\nThe key to this control scheme is that the character will go whichever way we tell\nhim, as if we were sitting inside the camera. Therefore, if we press up on the con-\ntroller, the character will move away from the camera. If we press right, the character\nmoves rightward from the camera's perspective. The tricky part is that the camera is\nalways moving and that this camera-oriented control needs to be mapped onto the\nworld's coordinate system, where the character actually moves around.\nConverting the Controller Input\nThe basic programming problem involves converting the player's input (up, down,\nright, left) from the camera's perspective to the world orientation. In order to do this,\n425\n",
      "content_length": 2058,
      "extraction_method": "Direct"
    },
    {
      "page_number": 410,
      "chapter": null,
      "content": "426 \nSection 4 Geometry Management\nwe need a vector that corresponds to the camera's forward direction, and a vector that\ncorresponds to the cameras rightward direction.\nThese vectors become useful because any up/down controller movements get\ndirectly mapped into translations along the camera's forward vector. Similarly, any\nright/left controller movements get mapped into translations along the camera's right\nvector. However, since the character basically moves on a flat plane, these camera vec-\ntors shouldn't contain any height information (traditionally represented by the/-axis).\nFigure 4.11.1 shows how we can think of the controller input in relation to the cam-\nera and the character.\nTop Down View\nDown\n1 T\nRight\nFIGURE 4.11.1 Controller relationship to character with respect to the camera.\nThe forward vector of the camera is easy to find since it's simply the direction the\ncamera is facing. Once we have it, we zero out the vertical axis and renormalize it.\nNow we can get the camera's right vector with the following relationship:\nright.x = forward.z\nright.z = -fonward.x\nnight.y = 0 . 0\nSince controller input traditionally comes in the form of numbers, a brief expla-\nnation is necessary. We can expect that the user input on an analog stick will basically\nvary from -1.0 to 1.0 along each axis. In reality, most input schemes use integers\nand vary from -128 to 127 or -32768 to 32767, but for our purposes, we'll need to\nconvert those to a floating-point number within the -1.0 to 1.0 range. However, its\nimportant to realize that Up and Right are both positive. The layout of a controller is\nshown in Figure 4.11.2.\n(Up)\n+1.0\n(Left)-1.0 •*—{ \n)—*+1.0 (Right)\n-1.0\n(Down)\nFIGURE 4.11.2 Values from an analog controller.\n",
      "content_length": 1741,
      "extraction_method": "Direct"
    },
    {
      "page_number": 411,
      "chapter": null,
      "content": "4.11 Classic Super Mario 64 Third-Person Control and Animation \n427\nArmed with the camera's forward and right vectors, we can now remap the input\nfrom the controller to get the final world vector. The following relationship gives the\ndirection the character should move, in world coordinates.\nfinal.x = (inputLtRt * right.x) + (inputUpDn * forward.x)\nfinal.z = (inputLtRt * right.z) + (inputUpDn * forward.z)\nfinal.y = 0\nOnce this final vector is normalized, it can be applied to the character so that he\nmoves in the proper direction. It's important to remember that for every frame, a new\nforward and right vector must be calculated, since the camera can move at any time.\nRotating the Character\nThe user input at any instant gives a desired direction. By sampling the magnitude of\nthe directions over time, the speed of the character can be determined. A simple\nmodel for moving the character is to maintain both a direction and a speed separately.\nIt helps to keep them separate, instead of representing both as a single vector, so that\na speed of zero still retains a direction. Obviously, bad things would happen if we try\nto orient the character using a zero vector.\nAs the input is sampled over time, the character's direction should converge on\nthe user's desired direction. For example, if the character is facing north and the player\nturns him east, the character should turn toward the east using some kind of damp-\nening. A very pleasing dampening effect comes from simply adding a proportion of\nthe desired direction to the current direction, based on frame rate. In Figure 4.11.3,\nnotice how the character initially rotates quickly and then slowly dampens toward the\nfinal desired direction over a short period of time.\nThe soft dampening shown in Figure 4.11.3 results in a smooth, responsive feel\nwhen controlling the character. The rate at which it converges on the desired direc-\ntion can be carefully tuned to get the desired feel. The dampening function in Figure\n4.11.3 can be represented by the following formula:\nnew_dir = (old_dir * 0.5) + (desired_dir * 0.5)\nNormalize( new_dir )\nBy taking into account frame rate, the dampening function can be made to be\nfairly resilient to frame rate fluctuations. Unfortunately, wild frame rate fluctuations\nAngle: 90° \n45° \n22.5° \n12.3° \n6.1° \n3.0° \n1.5°~* 0°\nTime: \n0\n1\n2\n3\n4\n5\n6\n7\nFIGURE 4.11.3 Character rotation over time with exponential dampening.\n",
      "content_length": 2418,
      "extraction_method": "Direct"
    },
    {
      "page_number": 412,
      "chapter": null,
      "content": "428 \nSection 4 Geometry Management\nof 100 percent or so are not dealt with properly. The following is a dampening for-\nmula that is semi-resilient to frame rate changes (within a certain window).\nnew_ratio = 0.9 / FPS\nold_ratio = 1.0 - new_ratio\nnew_dir = (old_dir * old_ratio) + (desired_dir * new_ratio)\nNormalize( new_dir )\nThis new dampening formula will now rotate the character 90 percent toward the\ndesired direction after one second, regardless of frame rate. The percentages need to\nbe tuned, but whatever frame rate it's tuned to becomes the center of our frame rate\nwindow. However, as the frame rate wanders too far from that center, the \"feel\" will\nslowly distort and become either too sensitive or too sluggish. If the frame rate varies\ntoo much, we can consider decoupling this calculation with the graphics update in\norder to maintain a steady rate.\nWhen a character is told to move 180 degrees from the current direction, smooth\nrotation is not always the best solution. Since there is such a large angle to cover, it\nresults in an extended rotation that can feel clunky and unnatural. Instead, it's better\nto use a transition animation to make large changes in direction. In Super Mario 64,\nthis occurs when Mario is at a full run and told to go in the opposite direction. This\nresults in a skidding stop followed by a seamless 180-degree in-place turn. However,\nduring this process, there's a speed penalty that stalls him for a split second before he\ncan move again.\nThe method of rotation described up to this point is fairly touchy feely and is\nultimately susceptible to frame rate issues, even though they have been reduced. For\nexample, if you record a player's input and feed it back to the game at a slightly dif-\nferent frame rate, the result will be slightly different. This has grave consequences if\nyou record a game, using input alone, and plan to replay it back from a different cam-\nera angle (perhaps causing the frame rate to vary). The solution is either to lock the\nsimulation rate or use a highly controlled method of rotation, such as clamping to a\nparticular angular velocity. However, this would give up some of the smooth accelera-\ntion effects in return for higher predictability.\nTranslating the Character\n•lim,f.-............ ...,„.,.... ..,.,........„.._„„....... \n....-*....,.... ................,~...................... -::~p~.~~:™wr™~:~^~ -;-•;•::-/ -.\".>s;i^-\"-..\"&^;::-~ —;;:••:-• :•--• ^.\\.^..:':\"-:^::*\nWith the character smoothly turning, we now need to actually move the character.\nThis is done by taking the character's current direction and translating him forward\nby the current speed. The smooth rotation of the character basically points the hips in\nthe proper direction, and the current speed moves him forward.\nWe'll want some type of dampening function, just like with the rotation, to con-\ntrol the speed. However, the speed needs to be clamped to a top speed, unlike the\nrotation. We'll also want to penalize the current speed for 180-degree turns and turns\nin general. The dampening function should quickly converge (faster than I/10th of a\nsecond) to the desired speed in order to make the control feel responsive.\n",
      "content_length": 3182,
      "extraction_method": "Direct"
    },
    {
      "page_number": 413,
      "chapter": null,
      "content": "4.11 Classic Super Mario 64 Third-Person Control and Animation\n429\nResponsiveness is a funny thing. Ideally, a character should respond instanta-\nneously to a player's input. However, this is both unrealistic and abrupt. By adding an\nexponential dampening, the edge is taken off transitions while maintaining respon-\nsiveness. Note that this implies that there are no physics taking place. Characters have\ntremendous control over their movement and actually don't accelerate and decelerate\nlike a car or rocket ship. Figure 4.11.4 shows the speed of a character under controller\ninput. Notice how responsiveness equates to quickly advancing to the desired speed\nand then smoothly converging on it.\nControl Stick\n0.0\n•1.0\nMagnitude\nFIGURE 4.11.4 Character speed based on controller input with exponential dampening.\nAnimating the Character\nThe simplest animation scheme is to have two different animation loops: standing\nand running. When the character's speed is zero, play the stand animation. When the\ncharacter's speed is above zero, play the running animation. Obviously, most charac-\nters should have more elaborate animations, but this is a good starting place.\nHere are some tricks to making the animation look reasonable:\n1. Match the speed of the animation (the movement of the feet) with the top\nspeed of the character. When moving, the character will spend most of the\ntime at the top speed, so the loop should look the best at this speed. At this\nspeed, the feet should meet the ground and appear to stick until they're\nlifted back up.\n2. The speed of the animation can be changed to match the speed of the char-\nacter, but most animations only look reasonable at a tiny range of speeds.\nThere is a little room to vary the speed, but not the full range from 0 to 8\nm/s for a decent run. A run can usually be varied from 5 to 8 m/s, a trot can\nbe varied from 3 to 5 m/s, and a walk can vary from 1 to 3 m/s. Actual\nranges can only be found experimentally with the actual animation data\nand are extremely subjective.\n3. When the character is turning sharply at high speeds, die character should\nalgoridimically lean into the turn. This helps emphasize speed and looks more\n",
      "content_length": 2183,
      "extraction_method": "Direct"
    },
    {
      "page_number": 414,
      "chapter": null,
      "content": "430\nSection 4 Geometry Management\nnatural. Another turning enhancement is to have the character algorithmically\nrotate his head slighdy in the direction of the turn. This further adds to the\nrealism, since characters generally anticipate and look toward future positions.\n4. Transition animations (stand to run, walk to run) are tricky to implement.\nUsually they tend to get in die way of responsiveness. A simple, clean solu-\ntion is to algorithmically construct a single in-between frame when transi-\ntioning. This takes the edge off transitions without getting in the way of the\nlook or feel. Calculating in-between frames is a well-known problem that\ncan be referenced in many animation programming books.\n5- The transition from a stand to a walk or run can be virtually seamless by\ndesigning the walk or run loop correctly. Figure 4.11.5 shows what the first\nframe of the loop should look like. Notice how the left foot is on the\nground while the right foot is barely being lifted into the air. This particular\nkeyframe minimizes the jar when changing animations from a stand to the\nwalk or run. However, since a moving character can potentially stop at any\ntime, this doesn't help smooth the transition to a stand. Transitioning to a\nstand can be dealt with by quickly interpolating die character to the stand\nposition, paying careful attention not to let the feet pierce the ground.\n6. A more elaborate transition system can be devised where there are actual\ntransition animations, such as a stand-to-run and a run-to-stand. When the\nplayer commands the character to start moving, the stand-to-run animation\nis played and then followed by the run loop. When the player tells the char-\nacter to stop, the character must somehow transition smoodily to the run-\nto-stop animation regardless of the current frame of the run loop. A simple\nway to solve this is to have two different run-to-stand animations, each\nbeginning with a different foot in front. This way, the run loop at most\n1R\nStand \nWalk \nRun\nFIGURE 4.11.5 First frame for smooth transitions.\n",
      "content_length": 2058,
      "extraction_method": "Direct"
    },
    {
      "page_number": 415,
      "chapter": null,
      "content": "4.11 Classic Super Mario 64 Third-Person Control and Animation\n431\nneeds to play out half the run cycle before it can seamlessly transition into\nthe run-to-stand animation. Unfortunately, some responsiveness is sacri-\nficed if animations are forced to play out longer than necessary in order to\nline up transitions. Also, transition animations need to be lightning quick\nor else responsiveness is compromised even further. Depending on the\ndesired look and feel of the game, it will take experimentation with both\ncanned and algorithmic transitions in order to find the proper mix.\nSuper Mario 64 Animation Analyzed\nThe following tables list the animation behavior that can be found in Super Mario 64.\nThis info was created by observing the game without any knowledge of actual imple-\nmentation. Certainly, any game can be analyzed in this way in order to deconstruct\nthe control and animation techniques.\nSpeed\nStand\nMedium\nFast\nVery Fast\nTransitions\nAnimation\nSeveral idle animations\nTrot\nRun with forward lean\nRun with pronounced forward lean\nAnimation\nStand to Tip-toe\nStand to Trot\nStand to Run\nTip-toe to Stand\nTrot to Stand\nRun to Stand\nTip-toe to Trot\nTrot to Run\nTrot to Tip-toe\nRun to Tip-toe\nRun to Trot\nAction\nAny turn during Stand\n180° turn during Tip-toe\n180° turn during Trot\n180° turn during Run\n< 180° turn during Tip-toe\n< 180° turn during Trot\n< 180° turn during Run\nTurning during Run\nSingle Walk cycle followed by Tip-toe\nPop into Trot\nPop into Run with puff of smoke\nPop into Stand\nPop into Stand\nPop into skidding stop, then seamlessly into Idle\nPop into Trot\nPop into Run (matching the foot cycle) with puff of smoke\nPop into Tip-toe\nPop into Tip-toe\nPop into Trot (matching the foot cycle)\nResulting Behavior\nPop into direction\nSmooth tight u-turn\nSmooth tight u-turn\nSkid to stop with smooth about-face\nSmooth rotation\nSmooth rotation\nSmooth rotation\nLean into turn\n",
      "content_length": 1892,
      "extraction_method": "Direct"
    },
    {
      "page_number": 416,
      "chapter": null,
      "content": "432 \nSection 4 Geometry Management\nConclusion\nUndoubtedly, many great games have implemented the classic Super Mario 64 third-\nperson control, even before Super Mario 64 ever existed. However, before trying to\ncode something, find an example to model and become intimately familiar with it.\nTry to notice every nuance of what happens under different controller inputs. Notice\nthe transitions, the acceleration/deceleration of the motion/rotation, the different\nspeeds of walks/trots/runs, the shallow and sharp turns, and the decay after com-\npletely letting go of the controller. Having a good example to model is important so\nthat you have a stable target to copy and ultimately improve upon.\nReferences\n[Maestri99] Maestri, George, Digital Character Animation 2: Essential Techniques,\nNew Riders Publishing, July 1999.\n",
      "content_length": 822,
      "extraction_method": "Direct"
    },
    {
      "page_number": 417,
      "chapter": null,
      "content": "5.1\nInker\nCartoon Rendering: Real-time\nSilhouette Edge Detection and\nRendering\nCarl S. Marshall, Intel Architecture Labs\ncarl.s.marshall@intel.com\nS\nilhouette detection and rendering is a key component for adding a stylized look\nto 3D cartoon rendering. The basic concept of silhouette edge detection is to find\nthe important edges that depict the outline of a model. Many cartoon animators illus-\ntrate these silhouettes by tracing a black outline around the borders of a model. This\ncartoon rendering gem describes several silhouette edge detection techniques: an\nedge-based detection method, a programmable vertex shader technique, and an\nadvanced texturing technique. The advantages and disadvantages of each technique\nare highlighted.\nThe terms inking and painting come from the artist's traditional cartoon eel creation\nprocess. Inking a eel is the process of drawing the outlines of the characters and\nobjects in the scene, while painting is the process of coloring or filling in the interior\nof the outlines. This gem focuses on the inking process of cartoon rendering. Adam\nLake's gem on \"Cartoon Rendering Using Texture Mapping and Programmable Ver-\ntex Shaders\" covers the painting process. Together, these two techniques form a com-\nplete cartoon rendering engine. Figure 5.1.1 demonstrates the inking and painting\nprocess on a 3D duck model.\nThe general inking process is comprised of two parts. The first part is the detec-\ntion of the silhouettes, and the second is the rendering of the silhouettes. This gem\ndescribes this inking process using several techniques that can all be performed in real\ntime on both manifold and nonmanifold meshes.\n",
      "content_length": 1659,
      "extraction_method": "Direct"
    },
    {
      "page_number": 418,
      "chapter": null,
      "content": "5.1 Cartoon Rendering: Real-time Silhouette Edge Detection and Rendering\n437\nFIGURE 5.1.1 A gouraud-shaded duck (left), inked duck with faces colored as\nbackground (center), and a flat-shaded duck using the painter (right).\nImportant Edges\nSilhouette edge detection (SED) is the main component of the inker. Along with the\ndetection and rendering of silhouettes, there are other important edges of the model\nthat artists tend to highlight: the crease and boundary edges. As described in the intro-\nduction, silhouette edges are the edges that form the outline of a model, but can also\ncontain some internal edges, as shown in Figure 5.1.2. One aspect that is very impor-\ntant to silhouette edge detection is that silhouettes are view dependent. This means\nthat the silhouettes have to be re-detected and rendered with each change in the\nmovement of the camera or model. Crease angle edges are those edges whose angle\nBack-facing polygon\n\\\nFront-facing polygon\nCamera's View Vector \nSilhouettes from Camera View\nFIGURE 5.1.2 Shows the silhouettes detected from a camera facing the first step (left).\n(Right) shows the silhouettes from the camera's view of the stairs.\n",
      "content_length": 1167,
      "extraction_method": "Direct"
    },
    {
      "page_number": 419,
      "chapter": null,
      "content": "438 \nSection 5 Graphics Display\nbetween its two neighboring faces is within a given threshold. This is called the dihe-\ndral angle. A user-defined threshold is used to detect crease angles. The boundary\nedges are edges that border a discontinuity in the mesh. A discontinuity in the mesh\noccurs where two faces that border an edge contain the same vertices for that edge but\nhave one of the following differences: texture coordinates, materials, or normals.\nSilhouette Edge Detection Techniques\nWhy are there so many different silhouette edge techniques? For starters, there are\nseveral rendering APIs that have certain advantages and disadvantages as far as render-\ning performance, features, and functionality on various video cards. This gem\ndescribes a summary of experiments on many of the inking methods. Texture map-\nping features, line segment rendering, and polygon offsetting are just a few of the fea-\ntures that vary dramatically across hardware and APIs.\nEdge-based Inking\nThe term edge-based is used to describe a technique that analyzes the edges of the\npolygons of the model to detect and render its important edges. The full silhouette of\nthe model along with accurate silhouettes and crease edges are guaranteed with this\nmethod. Other inking techniques imply silhouette and crease edges through an esti-\nmation of surface curvature. The edge-based technique consists of two parts: a pre-\nprocess part and a run-time part.\nPreprocess\nThe first step in the preprocess is to allocate and find a unique edge list for the model.\nThe three edges of each face of the model are examined individually and inserted into\na hash table if they have not previously been stored. Once the hash table is complete,\na compacted array can be stored with only the unique edges. An edge entry includes\ntwo vertex indices, two face indices, and a flag entry. The flag entry describes the edge\nas a silhouette, crease angle, boundary, and/or an unimportant edge.\nTo detect silhouettes accurately, face normals have to be computed. If the model\nis static (nonanimating), then these normals can be precomputed along with the\ncrease angle edges. For nonprogressive meshes, the boundary edges can be processed\nat authoring or load time. The trade-off for accurate silhouettes at runtime for ani-\nmating objects is the recomputation of the face normals every frame.\nRuntime\nRuntime consists of detecting and rendering the important edges of the model. V\nrefers to the viewing vector, and Nj and N2 are the face normals of the triangles that\nshare the edge in consideration.\n",
      "content_length": 2564,
      "extraction_method": "Direct"
    },
    {
      "page_number": 420,
      "chapter": null,
      "content": "5.1 Cartoon Rendering: Real-time Silhouette Edge Detection and Rendering \n439\nRuntime Inking\n1. If animating geometry, recalculate face normals.\n2. For each edge in the unique edge list,\n• Compute V by subtracting the viewing vector position from one of the\nedge vertex positions.\n• Set boundary flag if edge has one neighboring face or two neighboring\nfaces with discontinuities.\n• If animating geometry, set crease flag if the dihedral angle between the\ntwo neighboring faces exceeds a given threshold.\n• Detect silhouette using (A/i • V) X (N2 • V) < 0 and set silhouette flag.\n3. Iterate over edge list and render edges whose edge flag is set. Creating sepa-\nrate silhouette, crease, and boundary edge lists can optimize the rendering\nof the edges since each edge list can be rendered in a single API call. If the\nAPI you are using supports polygon offsetting and line thickness, they both\ngive added visual appeal to the final rendering.\nStep 2 is the core to the silhouette detection algorithm. By calculating the dot\nproducts between the face normal and the view vector for each of the edge's neigh-\nboring faces, highly accurate silhouettes are detected. Vertex normals could be used as\nan optimization, but this technique would miss silhouettes much like many of the\nvertex and pixel shader-based approaches. See Listing 5-1.1 for a code example.\nAdvantages\n• Cross-platform solution.\n• Completely accurate silhouette edge detection.\n• Artists can choose threshold for crease angle edges.\n• Visibility of edges is solved via the z-buffer.\nDisadvantages\n.• Line thickness is only available under certain APIs.\n• Must compute face normals for silhouette edge detection.\n• An offset needs to be applied to the lines to avoid the model occluding the line.\nListing 5.1.1 Edge-based silhouette edge detection\n// Detect silhouettes\nEdge *pEdge;\n// Iterate over all edges\nfor(unsigned int i=0; i < numEdges; i++){\npEdge = &m_pEdgel_ist[i];\n//Calculate vector from eye\npEdgeVertexPosition =\npMesh->GetVertexPosition(pEdge->GetVertexIndex(0));\n",
      "content_length": 2043,
      "extraction_method": "Direct"
    },
    {
      "page_number": 421,
      "chapter": null,
      "content": "440 \nSection 5 Graphics Display\n// Subtract eyeposition from a vertex position on the edge\nviewVector = pEyePosition - pEdgeVertexPosition;\nview/Vector. normalize () ;\n// Calculate the dot products from the face normal and\n// the view vector\nuDotProductl = DotProduct(viewVectpr, *pFaceNormalA);\nuDotProduct2 = DotProduct(viewVector, *pFaceNormalB);\nif((uDotProductl * uDotProduct2) <= 0.0f){\n// The edge is a silhouette edge\nAddEdgeToRenderEdges(pEdge, uNumfienderedVertices);\nProgrammable Vertex Shader Inking\nA programmable vertex shader is an extremely flexible graphics API for modern\ngraphics architectures. Why is a programmable vertex shader able to help with inking?\nSince we have shown that inking relies on the dot product of a normal with the view\nvector, we can pass the view vector and normals to the graphics hardware to find\nsilhouettes.\nProgrammable Vertex Shader Inking Runtime\n1. Set up texture pipeline via the graphics API. This requires the creation\nor loading of a one-dimensional texture. It works fine to load a two-\ndimensional texture, but only the first row will be used. In setting up the\ntexture, the color may be varied when moving across the texture from the\nsilhouette color, usually black, to any color desired. A 1x32 or 1x64 texture\nwith only a few black pixels near u=0 progressing to the surface material\ncolor for the rest of the texels is recommended.\n2. Load the registers of the programmable vertex shader. What you need to\nload may depend on your specific application and where you are doing your\ntransformations, but normally you need to send the world to eye and projec-\ntion matrix. Next, the vertex position and vertex normal should be sent and\ntransformed. Then, the eye position is sent and used to compute texture\ncoordinates. Since new texture coordinates are computed, they do not need\nto be passed to the card. However, remember to make sure that the graphics\nunit expects texture coordinates to be generated for the model.\n3. Perform the transformation of the vertex position from model to homoge-\nnous clip space.\n4. For each vertex, create a view vector by subtracting the vertex position in\nworld space from the eye vector. Compute the dot product between the ver-\ntex normal and the view vector, N* V, shown in Listing 5.1.2. Make sure\nthe normal and view vector are in the same coordinate frame or the results\n",
      "content_length": 2369,
      "extraction_method": "Direct"
    },
    {
      "page_number": 422,
      "chapter": null,
      "content": "5.1 Cartoon Rendering: Real-time Silhouette Edge Detection and Rendering \n441\nwill be incorrect. This can be done on the graphics unit or the CPU before\nbeing loaded into the constant registers of the vertex shader.\n5. Store the result of step 4 as the texture coordinate for the u texture\ncoordinate.\nAnother silhouette programmable vertex shading technique is a two-pass tech-\nnique that first extrudes the vertex along its normal. Then the depth buffer is disabled\nand the model is rendering in the desired silhouette color. Next, the depth buffer is\nreenabled and die model is rendered in its normal state.\nAdvantages\n• Fast. All silhouette detection processing is placed on graphics card.\n• Varying line thickness.\nDisadvantages:\n• Less accurate. Relies on vertex normals that depend on the object's shape.\n• Does not detect crease or boundary edges without special variables.\n• \nRequires programmable vertex shader API support.\nListing 5.1.2 Silhouette shader for DirectX 8.0\nvertex programmable shading\nt \n.. \n... \n._ \n_ \n... \n.. \n... \n.. \n... \n...\n; Constants specified by the application\n; \nc8-c11 = world-view matrix\n; \nc12-c15 = view matrix\n; \nc32 \n= eye vector in world space\ni\n; Vertex components (as specified in the vertex DECL)\n; \nvO \n= Position\n; \nv3 \n= Normal\n; Vertex transformation\nt \n. \n_ \n_ \n....-.....-.-. \n--..-.\n; Transform to view space (world matrix is identity)\n; m4x4 is a 4x4 matrix multiply\nm4x4 r9, vO, c8\n; Transform to projection space\nm4x4 n10, r9, c12\n; Store output position\nmov oPos, r10\n; Viewing calculation eye dot n\nt \n- \n. \n--. \n_ \n_ \n__. \n- \n. \n.\n;first, make a vector from the vertex to the camera\n;value in r9 is in world space (see vertex xform above)\n",
      "content_length": 1699,
      "extraction_method": "Direct"
    },
    {
      "page_number": 423,
      "chapter": null,
      "content": "442 \nSections Graphics Display\nsub r2, c32, r9 \n;make vector from vertex to camera\n; now normalize the vector\n; dp3 is a dotproduct operation\nmov r3, r2 \n;make a temp\ndp3 r2.x, r2, r2 \n;r2A2\nrsq r2.x, r2.x \n;1/sqrt(r2A2)\nmul r3, r2.x, r3 \n;(1/sqrt(r2A2))*r3 = r3\n•',. dp3 oTO.x, r3, v3 \n; (eye2surface vector) dot surface normal\nInking with Advanced Texture Features\nAn innovative technique that can be performed fully on the graphics processor is\ndescribed in detail in [DietrichOO]. This method uses a per-pixel Ndot Vto calculate\nand obtain the silhouette. An alpha test is used to clamp the values to a black outline,\nand a per-primitive alpha reference value is used to vary the line thickness. The basic\nsteps are listed next, but for more details, see the reference.\nBasic Steps\n1. Create a normalizing cube map texture. Effectively, this creates a single tex-\nture that contains the six square faces. Each face contains a per-pixel RGB\nnormal that represents the direction of that point on the unit cube from the\norigin.\n2. Use view space normal texture coordinates as a lookup into the cube map\ntexture. This outputs a RGB-encoded vector representing A^.\n3. Use view space position texture coordinates as a lookup into the cube map\ntexture. This outputs a RGB-encoded vector representing V.\n4. Set the Alpha compare mode to LESS_EQUAL.\n5. Set the Alpha reference value to 0 for thin lines, higher for thicker lines.\n6. Perform the dot product on the color values from steps 2 and 3, performing\nNdotV.\n7. Perform one pass with the alpha test LESS_EQUAL for the silhouettes, and\nthen another pass with alpha test set to GREATER for the shaded object.\nAdvantages\n• Very fast with appropriate hardware.\n• Allows line thickness to vary.\nDisadvantages\n• Less accurate. Relies on vertex normals that depend on the object's shape.\n• Requires specific thresholds for detecting crease angles, and specific alpha refer-\nence values for boundary edges.\n• Requires specific hardware for speed.\n",
      "content_length": 1990,
      "extraction_method": "Direct"
    },
    {
      "page_number": 424,
      "chapter": null,
      "content": "5.1 Cartoon Rendering: Real-time Silhouette Edge Detection and Rendering \n443\nConclusion\nThe inking and painting techniques used to cartoon render a scene are just a couple of\ntechniques in a larger domain called nonphotorealistic rendering (NPR). There are\nmany other stylized rendering techniques in the NPR field with which to experiment.\nA few of these techniques are pencil sketching, water coloring, black-and-white illus-\ntrations, painterly rendering, and technical illustrations. Inking is a fundamental tool\nand is a great place to start building your NPR library. This library will help you dis-\ntinguish your game from others by giving you the flexibility of alternate rendering\nstyles that will potentially broaden the appeal of your game.\nReferences\n[DietrichOO] Dietrich, Sim. \"Cartoon Rendering and Advanced Texture Features of\nthe GeForce 256 Texture Matrix, Projective Textures, Cube Maps, Texture Coor-\ndinate Generation and DOTPRODUCT3 Texture Blending.' Available online\nat: www.nvidia.com/Marketing/Developer/DevRel.nsf/WhitepapersFrame. 2000.\n[GoochOl] Gooch, Bruce, and Amy Gooch. Non-Photorealistic Rendering, A.K.\nPeters, Ltd., 2001.\n[IntelOO] Intel's Graphics and 3D Technologies Web page. Available online at:\nhttp://developer.intel.com/ial/3dsoftware. 2000.\n[LakeOO] Lake, Adam, Carl Marshall, Mark Harris, and Mark Blackstein. \"Stylized\nRendering Techniques of Real-Time 3D Animation.\" Non-Photorealistic Anima-\ntion and Rendering Symposium, pp. 13-20. 2000. ftp://download.intel.com/\nial/3dsoftware/toon.pdf.\n[Markosian97] Markosian, Lee, Michael Kowalski, et al. \"Real-Time Nonphotorealis-\ntic Rendering.\" In Proceedings of ACM SIGGRAPH 97, pp. 113-122. 1997.\n",
      "content_length": 1692,
      "extraction_method": "Direct"
    },
    {
      "page_number": 425,
      "chapter": null,
      "content": "5.2\nCartoon Rendering Using\nTexture Mapping and\nProgrammable Vertex Shaders\nAdam Lake, Intel Architecture Labs\nadam.t.lake@intel.com\nC\nartoon rendering is a stylistic rendering technique that can give a 3D scene the\nlook and feel of a cartoon environment. The techniques described in this gem\ntake advantage of modern real-time graphics capabilities, including texture mapping\nand programmable vertex shading. The basic idea is to simulate a limited color palette\nusing textures. To do this, we modify the standard diffuse shading equation to create\na highlight and shadow color, and use these colors to create a small texture map for\neach material to be used as a lookup table at runtime. Additionally, these techniques\nrequire no additional markup information from the artist—this gem describes the\ncreation of the texture maps and texture coordinates for each material.\nCartoon Shading\nCartoon shading is achieved by mimicking the process of fainting And inking eels used\nfor animation. This gem covers the painting algorithm. Carl Marshall has a gem, \"Car-\ntoon Rendering: Real-time Silhouette Edge Detection and Rendering,\" that covers the\ninking of the eel used for animation. Inking creates the outlines, or silhouettes, of the\nmodels that are \"filled\" by the painting pass of the Tenderer. It does diis by detecting\nthe silhouettes, creases, and material boundaries of the surface. For more details on the\ninking technique, see Carl Marshall's gem. The painter examines the material proper-\nties of the object along with the lighting, and calculates a texture map to be used for\nrendering of each mesh. The painter also calculates texture coordinates for the surface.\nEach gem can be used alone to achieve its own effect, or they can be used in combina-\ntion to simulate the complete painting and inking method used by animators.\nPainting\nThe painting process can be broken down into two phases, the preprocess and the run-\ntime. In the preprocess, each material is assigned a texture map that is created based\n",
      "content_length": 2019,
      "extraction_method": "Direct"
    },
    {
      "page_number": 426,
      "chapter": null,
      "content": "5.2 Cartoon Rendering Using Texture Mapping and Programmable Vertex Shaders \n445\non lighting and material properties. In the runtime phase, this texture map is set as\nthe active texture, and the texture coordinates are generated based on the result of the\nangle between the vertex normal and the light vector. For positional lights, the surface-\nto-light vector needs to be computed per vertex; therefore, an expensive normalize per\nvertex is computed since the surface to light vector is different for each vertex. For\ndirectional lights, the light comes from the same direction at all points in the scene;\ntherefore, the direction is the same and the surface-to-light vector doesn't require\nrecomputation for each vertex. When performance is an issue, use directional light-\ning. In most cases in cartoon shading, the additional realism provided by positional\nlights is of little benefit.\nPreprocess\nThe preprocess consists of three steps for each material. First, calculate the illumi-\nnated diffuse color. Next, calculate the shadowed diffuse color. Finally, create a texture\nfor each material based on these colors. In this example, only a one-dimensional tex-\nture is needed, but using a two-dimensional texture works just as well and probably is\nbetter suited to the fast path with most graphics hardware and graphics APIs.\nIn the following process, C,- refers to the illuminated diffuse color, Cs refers to the\nshadowed diffuse color, Aff refers to the global ambient light, and Am and Af refer to\nthe ambient color for materials and lights, respectively.\nPreprocess Cartoon Shade:\n1 . Calculate the illuminated diffuse color.\n+ D;X Dm\n2. Calculate the shadowed diffuse color.\nCs = AgxAm+Al xAm\n3. For each material, create and store a one-dimensional texture map with two\ntexels containing the results of steps 1 and 2. Assuming the texture uses the\ntexture coordinate u, store C;at the u=l end of the texture and Cs at u=0.\nRuntime\nRuntime consists of setting up the texture pipeline with the preprocess texture, com-\nputing a dot product per vertex, and using this value to determine texture coordinates\nfor each vertex. L refers to the light vector and n refers to the vertex normal in the\nsteps that follow.\nRuntime Cartoon Shades\n1. Set up texture pipeline to make the texture computed in the preprocess\nthe active texture. Set the texture coordinate mode to clamp the texture\n",
      "content_length": 2391,
      "extraction_method": "Direct"
    },
    {
      "page_number": 427,
      "chapter": null,
      "content": "446 \nSection 5 Graphics Display\ncoordinates generated. In general, we are not interested in multitexturing in\nthis step, so we set the texture combining function to replace.\n2. For each vertex, compute the dot product between the vertex normal and\nthe light direction vector, L • n. We also want to clamp the value so we do\nnot allow negatives, so the resultant equation is max/Z • n, 0}. See Listing\n5.2.1 and Figure 5.2.1.\n3. Disable lighting.\n4. Enable texture mapping.\n5. Render model.\nListing 5.2.1 Function for computing Toon texture coordinates\nSetTextureCoordinates(Mesh *pMesh, Light *pLight)\n//grab the light.\n//If there are multiple light source in the scene return the\n//greatest contributor\npLight->GetLightToWorldMatrix(&lightToWorldMat);\n//convert light direction in light space to light direction in\n//world space\nvector4 \nlightDir!nLightSpace.set(0,0,-1,0);\nvector4 lightDirlnWorldSpace;\nlightDirlnWorldSpace = lightToWorldMatrix * lightDirlnLightSpace;\n//convert light direction in world space to light direction in\n//model space\nmatrix4x4 *meshToWorldMatrix = pMesh->GetMeshToWorldMatrix();\nvector4 lightDirlnModelSpace;\nlightDirlnModelSpace = meshToWorldMatrix->inverse() *\nlightDirlnWorldSpace;\nlightDirlnModelSpace.normalize();\nint iNumVerts = pMesh->GetNumVerts();\n//for demonstration, we assume directional lights, point lights\n//would need a vector pointed from eye to vertex for each\n//dotproduct.\nfor(int iVert=0;iVert>iNumVerts;iVert++)\nvectors vert = mesh->GetVert(iVert);\nvectors normal = mesh->GetNormal(iVert);\nfloat fTexU.fTexV;\n//only negate if the light points from light to object\nfTexU = -normal->dotproduct(lightDir!nModelSpace);\n//max(L.n,0)\nif(texU < 0) texU = 0.0;\nfTexV = 0.0;\n",
      "content_length": 1719,
      "extraction_method": "Direct"
    },
    {
      "page_number": 428,
      "chapter": null,
      "content": "5.2 Cartoon Rendering Using Texture Mapping and Programmable Vertex Shaders \n447\nN:\nu=0 \nu=l\nFIGURE 5.2.1 In this figure Nj, N2, #WN3 are the normal vectors at the surface. L\nrepresents the directional light vector. Note that when N; • L=0, where i= 1, we are at\nu=0 in the texture; when N; • L=.5, i=2, the transition point or hard boundary in the\ntexture occurs. This is when the transition occurs between the highlight and shadow\ncolor. Finally, when N; • L=l, n=3 and the texture coordinate \\i=\\is reached.\nmesh ->SetTextu reCoord(iVe rt,fTexU,fTexV);\nAlternatives\nThe preceding description details the typical cartoon shading style of two colors, one\nin highlight and one for shadow. Many alternatives can be used to achieve a variety of\neffects. For example, one can create a texture map with any number of colors to sim-\nulate the available color palette. As an extreme case it is even possible to approximate\nGouraud shading by using several colors in the texture, which we call gradient shad-\ning. Also, the texture can be filled with only black and white texels for a black-and-\nwhite shading style. Furthermore, you can adjust C, and Cs using a weighting factor to\nbrighten or darken the texture color for even more effects.\nUsing multitexturing it is possible to increase the flexibility of the algorithm\ndescribed previously. Multitexturing allows us to apply other textures with the base\ncartoon shading texture. For example, one may be creating an anime-style game with\ncartoon shading, but the characters are wearing camouflage pants. With multitextur-\ning, you can set up one texture to be the cartoon shading and the other texture to be\nthe camouflage texture for the character (Figure 5.2.2).\n",
      "content_length": 1712,
      "extraction_method": "Direct"
    },
    {
      "page_number": 429,
      "chapter": null,
      "content": "448\nSection 5 Graphics Display\nFIGURE 5.2.2 In this figure, the duck model has been shaded with the technique\ndescribed previously and given in Listing 5.2.1.\nProgrammable Vertex Shaders\nModern graphics hardware and graphics APIs are evolving at an amazing pace. With\nthis new power comes performance that can be utilized effectively in implementing a\ncartoon shader. Programmable vertex shading provides two important benefits. One,\nit allows us to replace the lighting equation. In legacy graphics pipelines, the vertex-\nbased lighting equation was hard-wired into the API. This allowed hardware to be\noptimized for the specific lighting equation. Modern graphics architectures are being\ndeveloped that allow programming of the vertex shader. This allows us to replace the\ntraditional lighting equations with any lighting calculation we like. Obviously, there\nare hardware restrictions that will depend on the card for the size of the instruction\ncache, number and type of registers, instruction sets, and so forth. Hopefully, stan-\ndards will exist to provide consistency among hardware vendors. Software implemen-\ntations of vertex shaders are optimized to take advantage of SSE and SSE2\ninstructions on Intel CPUs.\nGiven that we have programmable vertex shaders, how does this help us with car-\ntoon shading? If the hardware exists, we are able to effectively move the runtime tex-\nture coordinate calculation off to the graphics unit. The preprocessing steps are the\nsame as before. We modify the runtime piece to load the registers on the graphics unit\nwith the normal and light information, and perform the dot product calculation on\nthe card. Finally, we load the texture coordinates computed into the appropriate tex-\nture register.\n",
      "content_length": 1743,
      "extraction_method": "Direct"
    },
    {
      "page_number": 430,
      "chapter": null,
      "content": "5.2 Cartoon Rendering Using Texture Mapping and Programmable Vertex Shaders 449\nProgrammable Vertex Shader Runtime:\n1. Set up texture pipeline to make the texture computed in the preprocess the\nactive texture. Since we are using the programmable vertex shader, we do not\nneed to be concerned about setting up the texture coordinate generation\nmodes—we will do this on the graphics unit.\n2. Load the registers of the programmable vertex shader. What you need to\nload may depend on your specific application and where you are doing\nyour transformations, but normally you need to send the world to eye and\nprojection matrix. You also need to send down the vertex position to be\ntranslated as well as the vertex normal. Also, you need to send down the\nlight position to be used to compute texture coordinates. Since we are com-\nputing new texture coordinates, they do not need to be passed to the card.\nHowever, remember to make sure that the graphics unit expects texture\ncoordinates to be generated for the model. This can be mistakenly over-\nlooked when dealing with models that previously did not have texture\ncoordinates.\n3. Perform the transformation of the vertex position from world to screen\nspace.\n4. For each vertex, compute the dot product between the vertex normal and\nthe light direction vector, Z,- • N. Make sure the normal and light vector are\nin the same coordinate frames or the results will be incorrect. The simplest\nway to do this is to transform the light vector from light space to model\nspace. This can be done on the graphics unit or the CPU before being\nloaded into the constant registers of the vertex shader.\n5. Store the result of step 4 as the texture coordinate for the u texture coordinate.\nListing 5.2.2 DirectX 8.0 cartoon programmable vertex shader\nmm \n'-••••••••••^-\"•\"••••\"-•~—\"-' -.-- \n<••< \n•• \n-\"i\"™:-;;: :;• •*:: —.•:.-.:. \n::•:-'--—•-•-• •l~:~l::l\"\"^-:::i«::•- ;• \n..•...,„.„.., \n:™ \n.,„...,,.,,...,.,,.....,.,.... \n,„..,„. \n•••»••_•_••_ \n••••'••'.:\"--•.\"-. :••:- \n\";•••••••••;— \n;•••;;•; \n-.-.,...,... \n......,,.,...:s\nvs.1.0\nConstants specified by the app-must be loaded using\ndxSDevice->SetVertexShaderConstant(reg,&vector,nVectors)\ncO \n= ( 0, 0, 0, 0 )\nc8-c11 = world-view matrix\nc12-c15 = view matrix\nc20 \n= light direction (in model space)\nVertex components (as specified in the vertex DECL)\nvO \n= Position\nv3 \n= Normal\nInstructions\nm4x4 = 4x4 matrix translation, same as 4 dp3s\nmov \n= moves values from right to left operator\ndp3 \n= dot product\n",
      "content_length": 2491,
      "extraction_method": "Direct"
    },
    {
      "page_number": 431,
      "chapter": null,
      "content": "450 \nSection 5 Graphics Display\n; Vertex transformation\nj--..-.---.., \n- _ \n__ \n. \n- \n_ _ _ _\n; Transform to view space (world matrix is identity)\nm4x4 r9, vO, p8\n; Transform to projection space\nm4x4 r10, r9, c12\n; Store output position\nmov oPos, r10\ns \n.. \n_ \n- \n- \n- _ - \n- - . _ _ - .\n; Lighting calculation - calculate texture coordinate\nt..-.. \n-_- \n_ \n, \n. - _ _ - . _ - _ \n_ _ _ .\n; light vector dot vertex normal\n; no max? Texturing mode set to CLAMP which clamps for us.\ndp3 oTO.x, c20, v3;\nConclusion\nTwo methods have been presented for cartoon shading, as well as the core techniques\nin the underlying algorithms. These techniques, combined with the \"Inker\" gem, can\nbe used to create cartoon environments for a unique look and feel in your game or\nimmersive experience. A variety of other effects can be achieved using different tex-\nturing techniques, including digital engraving, wood carving, limestone, marble,\nnewsprint, and more. Many can be made to run in real time by using the fundamen-\ntal approaches presented in this gem; namely, texture mapping and programmable\nshaders. With new hardware and APIs empowering us in new ways, computer graphi-\ncists will no doubt have fun in the coming years of PC evolution. If you are interested\nin exploring other rendering methods, see the References. [DietrichOO] discusses tech-\nniques using DirectX, [LakeOO] has a more elaborate list of academic references,\n[Gooch98] discusses a technique for technical illustration, and [Mark97] discusses a\nstatistical approach to inking. Good luck!\nReferences\n[DietrichOO] Dietrich, Sim, \"Cartoon Rendering and Advanced Texture Features of\nthe GeForce256 Texture Matrix, Projective Textures, Cube Maps, Texture Coor-\ndinate Generation and DOTPRODUCT3 Texture Blending,\" available online at\nwww.nvidia.com/Marketing/Developer/DevRel.nsf/WhitePapersFramePOpen-\nPage, 2000.\n[Gooch98] Gooch, Amy, Bruce Gooch, Peter Shirley, and Elizabeth Cohen. \"A Non-\nPhotorealistic Lighting Model for Automatic Technical Illustration.\" In Proceed-\nings ofACMSIGGRAPH98, pp. 447-452, 1998.\n[GoocnOl] Gooch, Bruce, and Amy Gooch. Non-Photorealistic Rendering, A.K.\nPeters, Ltd., 2001.\n[IntelOO] www.intel.com/ial/3dsoftware/doc.htm. Contains presentations, papers,\nand other references to Cartoon Shading, Multi-Resolution Meshes, Subdivision,\nand Character Animation. There is also an application that demonstrates cartoon\nshading, pencil sketching, and other NPR techniques, all running on animated\nmultiresolution meshes.\n",
      "content_length": 2508,
      "extraction_method": "Direct"
    },
    {
      "page_number": 432,
      "chapter": null,
      "content": "5.2 Cartoon Rendering Using Texture Mapping and Programmable Vertex Shaders \n451\n[LakeOO] Lake, Adam, Carl Marshall, Mark Harris, Marc Blackstein, \"Stylized Ren-\ndering Techniques for Scalable Real-Time 3D ACM Animation,\" In Symposium\nof Non-Photorealistic Animation and Rendering (NPAR) 2000, pp. 13-20, 2000.\n[Mark97] Markosian, Lee, Michael Kowalski, Samuel Trychi, Lubomir Bourdev,\nDaniel Goldstein, and John Hughes. Real-Time Nonphotorealistic Rendering. In\nProceedings of ACM SIGGRAPH 97, pp. 113-122, 1997.\n",
      "content_length": 514,
      "extraction_method": "Direct"
    },
    {
      "page_number": 433,
      "chapter": null,
      "content": "5.3\nDynamic Per-Pixel Lighting\nTechniques\nDan Ginsburg and Dave Gosselin,\nATI Research\nginsburg@alum.wpi.edu and gosselin@ati.com\nA\ncommon method of performing dynamic lighting effects in games is to use\nvertex-based lighting techniques. A significant shortcoming of vertex-based\nlighting is that the geometry must be highly tessellated in order to even approach the\nquality of per-pixel lighting. This article presents several techniques that can be used\nto perform dynamic lighting effects on a per-pixel basis. These methods have the\nadvantage that they don't require highly tessellated geometry, and can often be per-\nformed at little performance cost on multitexturing graphics hardware.\n3D Textures for Dynamic Lightmapping\nThe first method of dynamic lighting we will examine is using a 3D texture for\ndynamic lightmapping. 3D textures can best be explained through their relation to\n2D textures. In traditional 2D texturing, two texture coordinates are present in each\nvertex and are interpolated across the face. Each of the two texture coordinates (s, t)\nrefers to the distance along one of the texture map dimensions (width and height). 3D\ntextures expand upon 2D textures by adding a third texture coordinate (r) that refers\nto the depth of the texture. A 3D texture can be thought of as depth number of slices\nof 2D textures (see Figure 5.3.1). The texture coordinate r is used to select which\nw\nA \nB\nFIGURE 5.3.1 A) 2D texture. B) 3D texture.\n452\n",
      "content_length": 1461,
      "extraction_method": "Direct"
    },
    {
      "page_number": 434,
      "chapter": null,
      "content": "5.3 Dynamic Per-Pixel Lighting Techniques \n453\nFIGURE 5.3.2 Cross-section of the 3D lightmap. This actual lightmap is monochrome;\nthis picture rises color-coding to clearly show the mapfalloff. Red is highest intensity and\nblue is least. See color version in insert.\nof the 2D maps to access, and then coordinates (s, t) are used as normally in a 2D\ntexture.\nA natural use for 3D textures is in dynamic lightmapping. A typical application\nof dynamic lightmapping in games is having a moving light source that illuminates\nthe geometry in the scene. For example, a rocket fired from the player would dynam-\nically light the static game world geometry. A light of any shape can be created in a\n3D texture. A simple case would be a sphere light with linear falloff from the center.\nIn our example, a sphere light with quadratic falloff (Figure $.3.2) is used.\nThe 3D lightmap was generated with the following code:\nListing 5.3.1 Code to generate 3D lightmap with quadratic falloff\nfor(r = 0; r < MAP_SIZE; r++)\nfor(t = 0; t < MAP_SIZE; t++)\nfor(s = 0; s < MAP_SIZE; s++)\n{\nfloat DistSq = s * s + t * t + r * r ;\nif(DiStSq < RADIUS_SQ)\n{\nfloat FallOff = (RADIUS_SQ - DistSq) /\nRADIUS_SQ;\nFallOff *= FallOff;\nLightMapfr * MAP_SIZE * MAP_SIZE + t *\nMAP_SIZE + S] =\n255.Of * FallOff;\n",
      "content_length": 1276,
      "extraction_method": "Direct"
    },
    {
      "page_number": 435,
      "chapter": null,
      "content": "Section 5 Graphics Display\nelse\nLightMap[r * MAP_SIZE * MAP_SI2E + t\nMAP_SIZE + s] = 0;\nThe 3D lightmap itself can be specified in OpenGL using the EXT_texture3D\nextension (part of OpenGL 1.2.1). The 3D texture is sent to OpenGL using glTexIm-\nage3D(), which behaves much like giTexImage2D(). The only difference is that the\ndepth of the image is specified, and the texel array contains width X height 'X depth texels.\nThe geometry in our example will be textured with a basemap (b) and will be\nmodulated with a moving light source (/) represented by the 3D lightmap texture.\nThe texture blending we wish to achieve is:\nResult = b * 1\nThe texture environment can be configured to perform this operation through\nOpenGL using ARB_multitexture as follows:\n// 3D texture lightmap on stage 0\nglActiveTextureARB(GL_TEXTUREO ARB) ;\nglTexEnvi(GL_TEXTURE_ENV, GL_TEXTURE_ENV_MODE, GL_REPLACE) ;\n// Basemap to be modulated by 3D texture\nglActiveTextureARB(GL_TEXTURE1_ARB);\nglTexEnvi(GL_TEXTURE_ENV, GL_TEXTURE_ENV_MODE , GL_MODULATE) ;\nGiven the light position (/) and radius (Ir), the texture coordinate at each vertex\n(v) to look up into the 3D lightmap can be calculated as follows:\ns = (v.x - 1.x) / Ir\nt = (v.y - l.y) / Ir\nr = (v.z - l.z) / Ir\nFortunately, this texture coordinate equation can be easily calculated in\nOpenGL using the texture matrix. First, the texture coordinate for each vertex is\nspecified to be the same as its position (s = v.x, t = v.y, r = v.z). Next, each texture\ncoordinate must be put into the space of the light by subtracting the light position.\nThe texture matrix can be used to perform this operation by adding a translation to\nthe texture matrix of minus the light position (— /). The texture coordinate now\nneeds to be divided by the radius of the light. The texture matrix can be used to per-\nform this operation by scaling the texture matrix by the reciprocal of the light radius\n(1/lr) in s, t, and r. The following block of code configures the texture matrix as\ndescribed using a uniform scale.\nglMatrixMode(GL_TEXTURE) ;\nglLoadldentityO ;\n",
      "content_length": 2073,
      "extraction_method": "Direct"
    },
    {
      "page_number": 436,
      "chapter": null,
      "content": "5.3 Dynamic Per-Pixel Lighting Techniques\n455\nglScalef(1 / lr, 1 / lr, 1 / lr);\nglTranslatef(-1.x, -l.y, -l.z);\nNote that by using a nonuniform radius, the shape of the light could be modified\nto produce shapes other than a sphere without needing to modify the texture. For\nexample, making the scale in x larger than in y and z, the light would be shaped as an\nellipsoid.\nGiven this setup, each polygon is rendered with its basemap modulated by the\n3D lightmap. Figure 5.3.3 shows the effect achieved by this 3D lightmapping\ntechnique. \n' \n\"\nNote that while 3D textures are a natural method for performing dynamic per-\npixel point lights, 3D textures are not the most memory-efficient technique. In Game\nProgramming G^-—\"Attenuation Maps,\" Dietrich presents a method for performing\nper-pixel point lights using only 2D and ID textures.\nFIGURE 5.3.3 Basemap modulated by the 3D lightmap. See color version in insert.\n",
      "content_length": 916,
      "extraction_method": "Direct"
    },
    {
      "page_number": 437,
      "chapter": null,
      "content": "456 \nSection 5 Graphics Display\nDot3 Bump Mapping\nThe effect presented in the previous section using a 3D texture as a dynamic lightmap\nwill now be improved by adding per-pixel light perturbations to the surface. Several\navailable graphics cards provide this functionality through Dot3 bump mapping. In\nOpenGL, Dot3 bump mapping is exposed through the EXT_texture_env__dot3\nextension. This extension simply adds a new blend equation to the blend modes sup-\nported by EXT_texture_env_combine (GL_MODULATE, GLJNTERPOLATE,\netc.). The GL_DOT3_RGB equation performs the following computation:\nDest.r = Dest.g = Dest.b =4 * ((AO.r - 0.5) * (A1.r - 0.5) +\n(AO.g - 0.5) * (A1.g - 0.5) +\n(AO.b - 0.5) * (A1.b - 0.5))\nThis blend equation performs a dot product between the (r, g, b) vectors of any\ntwo color sources.\nIn order to allow for color values to represent vector components in the range\n[-1, 1], the color values are made signed by subtracting .5 from each component.\nHowever, by performing this subtraction and multiplying each component, the out-\ngoing color value is not scaled properly. In order to place the result of the dot product\nin the proper scale, it is multiplied by 4.\nUsing this equation, the normal vector (N) at each texel can be encoded into the\n(r, g, b) values of a texture. The light vector (L) in texture space can be encoded into\nthe (r, g, b) values of another source. The resultant dot product performed at blend\ntime yields the equation TV * L at each texel. This is the fundamental calculation that\nis needed for per-pixel bump mapping.\nThe texture map used for bump mapping will contain normals that will perturb\nthe light vector over the surface. In order to generate the bump map, a grayscale image\nrepresenting a heightfield of the original base map is authored. From this heightfield,\nthe bump map can be generated by calculating the change in texel height in each\ndirection.\nThe height differences can be calculated using a Sobel filter. The Sobel filter pro-\nvides two image filters that detect vertical and horizontal change.\ndx = I 0 0 0 I dy r 1 o ii\nI -2 0 2 I\n|_ 1 ° \n1J\nThe normal at each texel is then equal to (-dx, -dy, 1). This vector is normalized\nand placed into the color components at the texel in the bump map. Figure 5.3.4\nshows the bump map generated in the example.\nAt each vertex, the light vector will be stored in the primary color component.\nWith smooth shading on, this vector will be linearly interpolated across the face. The\ninterpolated vector will be used in each per-pixel dot product. This vector must be\n",
      "content_length": 2568,
      "extraction_method": "Direct"
    },
    {
      "page_number": 438,
      "chapter": null,
      "content": "5.3 Dynamic Per-Pixel Lighting Techniques\n457\nFIGURE 5.3.4 Dot3 bump map texture generated from the beightfield using the Sobel\nfilter. See color version in insert.\ntransformed into the space of the bump map texture on each polygon before it can\nbe used in the dot product. For point lights, the world space light vector at each ver-\ntex is calculated by subtracting each vertex position from the center position of the\n3D light. In our case, anytime the 3D lightmap or the geometry moves, the tangent\nspace light vector must be recalculated. Note that to use Dot3 bump mapping with a\nstatic directional light, the tangent space light vector can be precalculated because the\nper-vertex light vector doesn't change.\nIn order to rotate the light vector into the space of the texture (known as tangent\nspace), a local coordinate system at each vertex is constructed. Three vectors define\nthis coordinate system: the vertex normal (N), a tangent to the surface (T), and the\nbinormal (B). The vertex normal is determined by taking the average of all the nor-\nmals to the faces that contain the vertex. The tangent vector is calculated by deter-\nmining the direction of increasing s or t texture coordinates along the face in the\nobject's coordinate system. The binormal is then calculated by taking the cross\n",
      "content_length": 1304,
      "extraction_method": "Direct"
    },
    {
      "page_number": 439,
      "chapter": null,
      "content": "458 \nSection 5 Graphics Display\nproduct of the vertex normal and tangent vector. Given this coordinate basis, the light\nvector can be rotated into the space of the bump map using the following rotation\nmatrix:\n[\nT.x T.y T.z (Tl\nB.X B.y B.z 0 I\nN.X N.y N.Z 0 I\n0 0 \n0 \n1 J\nFinally, this tangent space light vector is stored in the primary color component\nof the vertex.\nGiven the Dot3 texture map (dotmap), the tangent space light vector (tl), the\nbasemap (b), and the 3D lightmap (/), we wish to perform the following texture\nblending:\nResult = (dotmap DOT3 tl) * b * 1\nAssuming hardware that has three orthogonal texture units, this can be achieved\nby configuring the texture environment as follows (in practice, this may need to be\ndone on multiple passes on many graphics cards):\n// dotmap DOTS tl on stage 0\nglActiveTextureARB(GL_TEXTUREO_ARB);\ng!TexEnvi(GL_TEXTURE_ENV, GL_TEXTURE ENV_MODE, GL_COMBINE_EXT);\nglTexEnvi(GL_TEXTURE_ENV, GL_COMBINEJ1GB_EXT, GL_DOT3_RGB_EXT) ;\nglTexEnvi(GL_TEXTURE_ENV, GL_SOURCEO_RGB_EXT,\nGL_PRIMARY_COLOR_EXT);\nglTexEnvi(GL_TEXTURE_ENV, GL_OPERANDO_RGB_EXT, GL_SRC_COLOR);\nglTexEnvi(GL_TEXTURE_ENV, GL_SOURCE1_RGB_EXT, GL_TEXTURE);\nglTexEnvi(GL_TEXTURE_ENV, GL_OPERAND1_RGB_EXT, GL_SRC_COLOR);\n// previous * basemap on stage 1\nglActiveTextureARB(GL_TEXTURE1_ARB);\nglTexEnvi(GL_TEXTURE_ENV, GL_TEXTURE_ENV_MODE, GL_COMBINE_EXT);\nglTexEnvi(GL_TEXTURE_ENV, GL_COMBINE_RGB_EXT, GL_MODULATE);\ng!TexEnvi(GL_TEXTURE_ENV, GL_SOURCEO_RGB_EXT, GL_PREVIOUS_EXT);\nglTexEnvi(GL_TEXTURE_ENV, GL_OPERANDO_RGB_EXT, GL_SRC_COLOR);\nglTexEnvi(GL_TEXTURE_ENV, GL_SOURCE1_RGB_EXT, GL_TEXTURE);\nglTexEnvi(GL_TEXTURE_ENV, GL_OPERAND1_RGB_EXT, GL_SRC_COLOR);\n// previous * lightmap on stage 2\nglActiveTextureARB(GL_TEXTURE2_ARB);\nglTexEnvi(GL_TEXTURE_ENV, GL_TEXTURE_ENV_MODE, GL_COMBINE_EXT);\nglTexEnvi(GL_TEXTURE_ENV, GL_COMBINE_RGB_EXT, GL_MODULATE);\ng!TexEnvi(GL_TEXTURE_ENV, GL_SOURCEO_RGB_EXT, GL_PREVIOUS_EXT);\nglTexEnvi(GL_TEXTURE_ENV, GL_OPERANDO_RGB_EXT, GL_SRC_COLOR);\nglTexEnvi(GL_TEXTURE_ENV, GL_SOURCE1_RGB_EXT, GL_TEXTURE);\nglTexEnvi(GL_TEXTURE_ENV, GL_OPERAND1_RGB_EXT, GL_SRC_COLOR);\nFigure 5.3.5 shows the results of this technique.\n",
      "content_length": 2163,
      "extraction_method": "Direct"
    },
    {
      "page_number": 440,
      "chapter": null,
      "content": "5.3 Dynamic Per-Pixel Lighting Techniques\n459\nFIGURE 5.3.5 Base map modulated by 3D lightmap with Dot3 bump mapping.\nSee color version in insert.\nCubemap Normalizer\nWe now have a bump-mapped object dynamically lit on a per-pixel basis. However,\nthere is one major shortcoming with the method presented. The tangent space light\nvector calculated at each vertex used in the Dot3 blend stage was stored in the pri-\nmary color component. By storing the light vector in the color component with\nsmooth shading enabled, the vector is linearly interpolated across the face. Unfortu-\nnately, the linearly interpolated vector will often fail to maintain its length of 1 across\nthe face. Figure 5.3.6 shows an example of two linearly interpolated 2D vectors. VI\nand V2 both have a length of 1, but when linearly interpolated, the resultant vector\nhas a length less than 1. This failure to maintain normalization results in decreased\nvisual quality, particularly when the geometry is not highly tessellated.\nIn order to correct this problem, a cubic environment map will be used to keep\nthe light vector normalized. The contents of the cube map at each texel will be the\nsame as the normalized texture coordinate used to look up into it. Instead of storing\nthe tangent space light vector in the primary color component, it will be stored as a\ntexture coordinate that will be used to look up into the cubemap. Since each texel in\n",
      "content_length": 1418,
      "extraction_method": "Direct"
    },
    {
      "page_number": 441,
      "chapter": null,
      "content": "460 \nSection 5 Graphics Display\nFIGURE 5.3.6 The linear interpolation of two normalized vectors resulting in a vector\nwhose length is less than 1.\nthe map contains the normalized vector of the texture coordinate, the light vector will\nstay normalized when interpolated across the face.\nThe Dot3 operation using the cubemap can be done using two texture units by\nconfiguring the texture environment as follows:\n// Cubmap normalizer on stage 0, just pass it through\nglActiveTextureARB(GL_TEXTUREO_ARB);\ng!TexEnvi(GL_TEXTURE_ENV, GL_TEXTURE_ENV_MODE,\nGL_COMBINE_EXT);\nglTexEnvi(GL_TEXTURE_ENV, GL_COMBINE_RGB_EXT, GL_REPLACE);\nglTexEnvi(GL_TEXTURE_ENV, GL~SOURCEO_RGB_EXT, GL_TEXTURE);\nglTexEnvi(GL_TEXTURE_ENV, GL_OPERANDO_RGB_EXT, GL_SRC_COLOR);\n// dotmap DOT3 cubemap on stage 1\nglActiveTextureARB(GL_TEXTURE1_ARB);\nglTexEnvi(GL_TEXTURE_ENV, GL_TEXTURE_ENV_MODE,\nGL_COMBINE_EXT);\nglTexEnvi(GL_TEXTURE_ENV, GL_COMBINE_RGB_EXT,\nGL_DOT3_RGB_EXT);\nglTexEnvi(GL_TEXTURE_ENV, GL_SOURCEO_RGB_EXT,\nGL_PREVIOUS_EXT);\nglTexEnvi(GL_TEXTURE_ENV, GL_OPERANDO_RGB_EXT, GL_SRC_COLOR);\nglTexEnvi(GL_TEXTURE_ENV, GL_SOURCE1_RGB_EXT, GL_TEXTURE);\nglTexEnvi(GL_TEXTURE_ENV, GL_OPERAND1_RGB_EXT, GL_SRC_COLOR) ;\nFigure 5.3.7 shows the improved results by using the cubemap normalizer.\nPer-Pixel Spotlights\nIn addition to per-pixel point lights as we have implemented using a 3D lightmap,\nanother useful dynamic lighting technique is per-pixel spotlights. Instead of using a\n3D lightmap, we will use 2D texture to represent the light and project it onto each\nface. The contents of the 2D texture will be a cross-section of the spotlight cone con-\ntaining the attenuation falloff from the center. As with point lights, a tangent space\nlight vector from the spotlight will be placed in the color component of the vertex. A\nfalloff factor based on the distance from the tip of the cone to the vertex is placed in\nthe alpha channel. The tangent space light vector will be Dot3'd with the vectors in\n",
      "content_length": 1974,
      "extraction_method": "Direct"
    },
    {
      "page_number": 442,
      "chapter": null,
      "content": "5.3 Dynamic Per-Pixel Lighting Techniques\n461\nFIGURE 5.3.7 Base map modulated by 3D lightmap with Dot3 bump mapping and\ncubemap normalizes See color version in insert.\nthe normal map. The interpolated alpha in the vertex color is modulated with the\ncolor to perform the distance attenuation.\nThe result of this Dot3 calculation now need to be modulated by the projected\nspotlight texture. The spotlight can be projected onto the face by configuring the tex-\nture matrix to perform the projection. The texture matrix is first set to represent the\nview from the spotlight by calculating the \"look-at\" matrix based on its position,\ndirection, and any vector perpendicular to the direction. The \"look-at\" texture matrk\nmust finally be multiplied by a matrix that represents the frustum created by the spot-\nlight. The texture coordinates for the spotlight texture will then simply be the world\ncoordinates of the vertex. The result of this texture look-up is modulated with the\nDOT3 calculation to get the final lighting.\nReferences\n[Blythe98] Blythe, David, \"Advanced Graphics Programming Techniques Using\nOpenGL\" available online at www.sgi.com/software/opengl/advanced98/notes/\nnotes.html\n",
      "content_length": 1188,
      "extraction_method": "Direct"
    },
    {
      "page_number": 443,
      "chapter": null,
      "content": "462 \nSection 5 Graphics Display\n[DeLouraOO] DeLoura, Mark, Game Programming Gems, Charles River Media, 2000.\nDietrich, Sim, \"Attenuation Maps,\" pp. 543-548.\nDietrich, Sim, \"Hardware Bump Mapping,\" pp. 555-561.\n[Mitchell] Mitchell, Jason, \"Radeon Bump Mapping Tutorial,\" available online at\nwww.ati.com/na/pages/resource_centre/dev_rel/sdk/RadeonSDK/Html/Tutori-\nals/RadeonBumpMap.html\nARB_multitexture, EXT_texture_env_combine, and EXT_texture_env_dot3 spec\navailable online at http://oss.sgi.com/projects/ogl-sample/registry/\n",
      "content_length": 527,
      "extraction_method": "Direct"
    },
    {
      "page_number": 444,
      "chapter": null,
      "content": "5.4\nGenerating Procedural Clouds\nUsing 3D Hardware\nKim Pallister, Intel\nkim.pallister@intel.com\nA\ngreat number of the games we play take place in outdoor environments, and\nmost of those take place in environments that attempt to look much like the\nworld around us. Because of this, the realistic rendering of terrain has become some-\nthing of a holy grail for many game developers. Unfortunately, the modeling of the\nsky, and the clouds therein, does not get nearly as much attention, and is often added\nas an afterthought. Clouds usually end up being modeled with one or more layers of\nstatic scrolling textures. At first glance, these look OK, but they quickly give away\ntheir repetitive nature when looked at for an extended period.\nIn this gem, we'll set out to procedurally generate cloud textures that possess\nsome of the properties that real clouds exhibit. In addition, because textures typically\nreside in graphics subsystem memory, we'll aim to generate the procedural clouds\nalmost entirely using the graphics hardware. Finally, we'll address some ways to scale\nthe technique's quality and performance requirements in order to accommodate a\nrange of target machines.\nProperties of Clouds\nBy taking note of the characteristics of real clouds, it's possible to come up with a pri-\noritized feature list for the simulation. As with all real-time techniques, we may need\nto forsake some of these features in the interest of speed, but we'll worry about that\nlater.\nHere are a few things that we notice at first glance:\n• Clouds are animated. They both move across the sky as the wind pushes them\nalong, and change shape or \"evolve\" with time (as can be seen in any time-lapse\nfootage of clouds). Additionally, the amount of cloud in the sky changes with\ntime. This gives us a hint that there are three variables we'll need: the simulation\nrate, the wind speed, and something describing how overcast it is.\n• As the clouds change shape over time, small details change frequently, while\nlarger details take longer to change.\n• Clouds exhibit a great deal of self-similarity in their structure.\n463\n",
      "content_length": 2103,
      "extraction_method": "Direct"
    },
    {
      "page_number": 445,
      "chapter": null,
      "content": "464 \nSection 5 Graphics Display\n• The level of cloud cover can also vary from a completely overcast sky to a clear\nblue sky with only a few isolated clouds (or none at all). As the level of cloud\ncover changes, so does the appearance of the clouds. In overcast conditions,\nclouds become gray and dark; in clear skies, clouds tend to be bright white\nagainst the blue backdrop of the clear sky.\n• Clouds are three-dimensional entities. They are lit by the sun on one side and fall\nin shadow on the other. On a smaller scale, its much more complex than that,\nwith clouds self shadowing and scattering light in all directions.\n• Clouds are lit much differently at sunrise and sunset, as the light of the sun tends\nto illuminate them from an orthogonal angle, or even from underneath.\n• Clouds tend to float at a common altitude, forming a cloud layer. Sometimes\nthere are multiple layers. Since each of these layers is a constant altitude above the\nearths curved surface, we'll likely use some kind of curved geometry for the layers\nof clouds.\n. . . and this is just some of what we see from the ground. In an application such as a\nflight simulator, where we could fly up and into the clouds, a whole new set of diffi-\nculties comes up. For this gem, we'll stick to the view from the ground.\nRandom Number Generation\nAs with almost any procedural texture, a good place to start is with the generation of\nsome noise. Noise is a term used to describe a primitive that is random in nature. The\nnoise primitive is a function that for a given input series (e.g., 1, 2, 3...), produces a\nseemingly random series of results (e.g., 0.52,—0.13,—0.38...). I say seemingly random\nbecause it must always produce the same result for a given input. This makes it\npseudo-random, allowing us to recreate the same result for a given input seed value.\nAdditionally, noise is often referred to as having a certain dimensionality (e.g., 2D\nnoise, 3D noise, etc). This just refers to the number of inputs that are used to map\ninto the random number function, much as one does a lookup into a multidimen-\nsional array. One of the dimensions is scaled by some factor (usually a prime number)\nlarge enough to keep repetitive patterns of results from showing up in an obvious\nfashion.\nThe generation of random numbers (or pseudo-random numbers) is a subject of\nmuch study. All approaches contain trade-offs between the complexity of the function\nand the quality of the result. A random number generator of high quality generates a\ngood distribution of the random values, and does not repeat for a very long time.\nLuckily, for the purposes of this gem, the results of a very simple random number\ngenerator will suffice. When we cover the specifics of the technique later, we'll be call-\ning the random number generator multiple times per pixel with different input \"seed\"\nvalues. The cumulative result of this will mask any obvious repetition that occurs.\nThe pseudo-random number generator (PRNG) we'll start with is shown in List-\ning 5.4.1. It works by using the input parameter x as the variable in a polynomial,\n",
      "content_length": 3087,
      "extraction_method": "Direct"
    },
    {
      "page_number": 446,
      "chapter": null,
      "content": "5.4 \nGenerating Procedural Clouds Using 3D Hardware \n465\nwhere each term of the polynomial is multiplied by large prime number. By scaling\neach term of the polynomial differently, we get a long series before it repeats. The sign\nbit is then masked off, and the number is divided down to the 0—2 range, and is sub-\ntracted from 1, to give us a range of—1 to 1.\nListing 5.4.1 A simple pseudo-random number generator\nfloat PRNG( int x)\n{\nx = (x«13)*x;\nint Primel = 15731;\nint Prime2 = 789221;\nint Primes = 1376312589;\nreturn (1.0f - ((x * (x*x*Prime1 + Prime2) + Primes)\n& 7fffffff ) / 1073741824.0)\n}\nIn cases where multiple octaves are being used, you can increase the \"random-\nness\" of the PRNG by constructing an array of prime numbers and using different\nones for Primel and Primel, depending on the octave. For the purposes of this gem,\nusing the single set of primes in Listing 5.4.1 is sufficient\nSince we want to implement this in graphics hardware, and graphics hardware\ndoesn't allow us to do all of the code shown in Listing 5.4.1, we'll create a lookup table\nof the function in a 512x512 texture map. Using a 512x512 texture map gives us\n-260 thousand entries before the function repeats. We'll use this texture as a random\nnumber generator by copying part of this texture into a target texture, using a software-\ngenerated random number to offset the texture coordinates. This is illustrated in Fig-\nure 5.4.1. The copying is done using the graphics hardware to render our random\nnumber series texture to a quad in the target texture.\nStartlndex(x,y)\nFIGURE 5.4.1 A) The random number lookup table texture. B) The generated 32x32\nnoise texture.\n",
      "content_length": 1656,
      "extraction_method": "Direct"
    },
    {
      "page_number": 447,
      "chapter": null,
      "content": "466 \nSection 5 Graphics Display\nBand-Limited Noise\nKen Perlin pioneered the technique of using band-limited noise as a rendering primi-\ntive. Band-limited means that the noise is limited to a certain frequency range, which\ncan be thought of as its maximum rate of change between samples. For our purposes,\nthis means that we want to be able to produce a series of random values spaced out\naccording to the frequency range, with intermediate points interpolating between\nthese random samples. We do this simply by indexing into our random number\nlookup table and upsampling by the desired amount, using the graphics hardware's\nbilinear filtering to do the interpolation for us. Getting rid of the high frequency\ncomponents will make for a procedural primitive with smoother, more natural-looking\ntransitions. This is illustrated in Figure 5.4.2.\n(a) \n(b)\nFIGURE 5.4.2 A) Sampling the random number lookup table texture to create an array of\nnoise. B, C) Using upsampling and filtering to create band-limited noise at the target\nresolution (the target frequency range).\nIt's worth noting here than in some cases when using noise to create procedural\ncontent, bilinear interpolation is insufficient, and a higher order filtering is needed to\nproduce adequate results. Luckily, this is one case where the lower quality bilinear fil-\ntering produces sufficient results.\nAn array of noise created in this fashion gives us a single noise primitive of a given\nfrequency. We'll refer to this as an octave of noise, since we will later combine multi-\nple octaves (multiples of the same frequency) together. First, though, we need to be\nable to animate our array of noise.\nAnimating an Octave of Noise\nfs?r: ::•:•;;;;:\":•\"\"::•:.-v::1:\":1::1;-.'\"'\":'\"'::;.:::::1::1\"\":':.:\" r.r\":\\'™™'.r:~\"~r:r\"'::-'\"~r.r:..—•;:.l™r\":;:;:l:r::1^-\"': .::™.r. ~:^~\"~:; ..::.•\". \".'.'>*../.::\"' r^~.:'.~:~:\"~ ~\" :'\"~:r:\":\"'r -\"•.•-—--..: ,™:v: :™:-\"-.\"\"'::'-'-$\nIf we want to animate an octave of noise, we can look at time as a third dimension\nthat we can use to index into our random number generator. The way we'll imple-\nment this using the graphics hardware is to periodically save off our noise texture,\ncreate a new one, and then interpolate between the two from one update to the\nnext. The rate at which we update the texture determines the frequency in this third\ndimension.\nThe interpolation is illustrated in Figure 5.4.3. This is one case where using lin-\near interpolation results in some artifacts, as the noise becomes more \"focused\" at the\n",
      "content_length": 2524,
      "extraction_method": "Direct"
    },
    {
      "page_number": 448,
      "chapter": null,
      "content": "5.4 Generating Procedural Clouds Using 3D Hardware \n467\nJ\nFIGURE 5.4.3. Interpolating between noise updates to animate an octave of noise. Result =\nPreviousUpdate * (1-(T1-TO)/(T2-TO)) + NewUpdate * (Tl-TO)/(T2-TO). TO is the previous\nupdate time, T2 is the new update time, and Tl is the current time between updates.\nactual sample points. Again, this artifact is not apparent after the noise is incorporated\ninto the final effect, as we'll see. Still, it's worth keeping in mind. If we were willing to\nsacrifice enough fill rate, we could maintain octaves for multiple points in time and\nuse a higher order interpolation scheme to achieve a better result.\nSumming Octaves into Turbulent Noise\nA commonly used technique in procedural texture generation is to use a fractal sum,\nwhich is a summation of scaled harmonics of the basic noise function. This is referred\nto as fractional Brownian motion, or fBm, and is used in all types of procedural ren-\ndering techniques, such as fractal terrain, many types of procedural textures, and so\nforth. The fractal sum is shown in Equation 5.4.1. In it, a determines how we step\nacross the frequency spectrum (a is most commonly 2, giving us f, 2f, 4f, ...), and b\ndetermines the amplitude of the contribution of each component in the series.\nJV-1\nFortunately, a value of 2 for a is both commonly used in the generation of proce-\ndural textures, and is well suited to our hardware implementation, as we can simply\nimplement the octaves of noise as a series of texture maps whose sizes are a series of\npowers of 2.\nUsing a value of 2 for b is also both commonly used and makes our implementa-\ntion easier. The composition of the octaves of noise can be done by performing mul-\ntiple render passes using a simple blend, as shown in the pseudocode in Listing 5.4.2.\nListing 5.4.2 Noise octave composition\n//note that ScaleFactor is needed to keep results in the\n// 0-1 range, it changes {1 + 1/2 + 1/4 + ...} to {1/2 + 1/4 + ...}\n",
      "content_length": 1969,
      "extraction_method": "Direct"
    },
    {
      "page_number": 449,
      "chapter": null,
      "content": "468\nSection 5 Graphics Display\nfloat ScaleFactor =0.5\nfloat FractalSum = 0.0\nfor i = 1 to NumOctaves\n{\nFractalSum = FractalSum*0.5 + ScaleFactor *\nNoiseOctave(NumOctaves-i)\nFigure 5.4.4 illustrates the process of animating the different octaves between\nupdates, and building the composited turbulent noise texture.\nPrevious Updates\nAnimated Octaves\nCurrent Updates\nOctave 0\nOctave 1\nOctave 2\nOctave 3\n1/2 Octave 0 + 1/4 Octave 1 +\n1/8 Octave 2 + 1/16 Octave 4 =\nFIGURE 5.4.4 Composition of several octaves of animated noise.\n",
      "content_length": 525,
      "extraction_method": "Direct"
    },
    {
      "page_number": 450,
      "chapter": null,
      "content": "5.4 Generating Procedural Clouds Using 3D Hardware \n469\nMaking Clouds from \"Vapor\"\nNow that we have a texture map of animated, turbulent-looking noise, we need to do\na few steps to turn it into clouds. Ideally, we'd like to use the noise as input to some\nsort of exponential function, giving us a sharp \"condensation level\" above which\nclouds would be visible, below which they would not. However, since this is an oper-\nation not available to us in a graphics chip, we'll have to use another method. There\nare several ways to tackle this.\nThe simplest way is to do a subtraction. Subtracting a fixed value from the texture\nclamps the texture at 0 where the noise was below that fixed value, isolating some\nclouds. This is illustrated in Figure 5-4.5.\nFIGURE 5.4.5 Subtracting a fixed value to get isolated clouds.\nUnfortunately, we lose some of the dynamic range in the remaining clouds. We\ncan compensate for this, however, by oversaturating and modulating with vertex col-\nors and varying this. This is the method we use in the accompanying sample code.\nAnother way would be to have all the layers of texture that we have talked about so\nfar have an alpha channel. This would let you do the subtraction and the clamping as\nin the previous test, but only on the alpha, and then do an alpha test to mask off the\nregion without clouds without losing any dynamic range in die clouds themselves. A\ndifferent problem occurs here, however. Since the alpha test is done before any filter-\ning, rough jagged edges occur unless we use a really high-resolution destination texture.\nAnother way that may be better still would be to use some sort of dependent tex-\nture lookup, where one texture's color value affects the location from which a texel is\nfetched in a subsequent stage. One example of a texture- dependent lookup is the\nBumpEnvMap render state supported by some hardware under DirectX. In the\nfuture, as more hardware supports this type of operation, it may become feasible to\nencode an exponential function in a texture map and simply look up the result.\nMapping It to the Sky Geometry\nHaving prepared the cloud texture in Figure 5.4.5, we can map it to the sky geometry.\nYour choice of geometry depends on your application. The sample application uses\nsomething we've called a \"skyplane,\" which is simply a rectangular grid of triangles,\nwith the vertices pulled down over die radius of a sphere. You can imagine this as\ndropping a piece of cloth over the surface of a beach ball. It's not perfect, but makes\nmapping the texture easy. The skyplane is illustrated in Figure 5.4.6.\n",
      "content_length": 2586,
      "extraction_method": "Direct"
    },
    {
      "page_number": 451,
      "chapter": null,
      "content": "470\nSection 5 Graphics Display\nFIGURE 5.4.6 Terrain geometry and the skyplane used for the cloud texture.\nFeature Creep\nAt this point, we can do many things to the clouds, depending on how much applica-\ntion time and graphics hardware fill-rate we want to consume. Some of these are\nimplemented in the sample code; others are listed to provide you with ideas for your\nown implementation. Some of the things that can be added include:\n• Noise-driven wind direction, cloud cover. Some dramatic results can be achieved\nby using other noise functions to modify some of our other variables over time, so\nthat, for example, the wind can change direction and the level of cloud can\nincrease or decrease over hours or days.\n• Embossing the clouds to give them a 3D appearance. This will require an extra\npass, and will require some modification of the vertex UV values. The vertices are\ngiven a second set of texture coordinates and are offset/scaled according to the\ndirection of the sun. The clouds are darkened on the side away from the sun, and\nbrightened on the side toward the sun.\n• The clouds can cast shadows on the ground simply by using the end result texture\nwith a subtractive blend. Your terrain will need to have another set of texture\ncoordinates, or will have to use texture projection in order to do this.\n• Modify lighting and/or lens flare intensity. Since we know how the texture is\nmapped to the geometry, and we know the angle of our sun, we can calculate the\n",
      "content_length": 1475,
      "extraction_method": "Direct"
    },
    {
      "page_number": 452,
      "chapter": null,
      "content": "5.4 \nGenerating Procedural Clouds Using 3D Hardware \n471\nexact texel or group of texels corresponding to where the sun is in our line of\nsight. We can use this to vary the level of lighting on our terrain, or to fade out a\nlens flare temporarily. Note that when modifying lighting, increased cloud cover\nshould decrease the intensity of the directional light of your \"sun\" in the scene,\nbut should increase the ambient level, since in reality the clouds will scatter the\nsunlight in all directions.\nHardware Limitations\nAllowing the graphics hardware to do much of the grunt work in this technique\nallows us to achieve better performance than we'd be able to achieve if we had to man-\nually lock and modify the texture at every frame. Unfortunately, it comes with some\ndrawbacks as well. The drawbacks fall in four areas:\n• Render-to-texture support. The technique spelled out in this gem uses this\ncapability extensively. However, support for rendering to texture surfaces is far\nfrom ubiquitous. Detecting support for the capability has become easier with\nmore recent API releases, but can still be tricky. In cases where rendering to tex-\nture surfaces is not supported, a workaround of copying from frame buffer to tex-\nture can be used, but performance may suffer.\n• Limited precision. Current hardware stores texture and render target values as\nintegers, usually in 32 or 16 bits per pixel. Because we are essentially working in\n\"monochrome,\" generating a texture in shades of gray, we are limited to 8 bits per\npixel, and in the worst case, 4! The latter gives noticeable artifacts. Note that this\nmeans that the high-frequency octaves are only contributing a few bits of color\ndata to the final result due to this problem.\n• Limited dynamic range. Because the integer values represent data in the 0-1\nrange, we are forced to scale and offset values to fit in this range. Since our noise\nfunction originally returned values in the -1 to 1 range, we had to compress these\nto fit them into our available range. This requires extra work, and also amplifies\nthe artifacts from the limited precision\n• Limited hardware instruction set and capabilities. The limited instruction set\nof the graphics hardware limits us in terms of what we are able to do. It would\nhave been nice to feed the turbulent noise texture into a power function, perhaps\nas the exponent, to generate some interesting results, but we are instead limited to\nsimple arithmetic operations. As well, we make much use of render-to-texture,\nwhich isn't available on all hardware. In the future, as hardware capabilities\nincrease, this will be less of an issue.\nMaking It Scale\nIf we want to use this technique in a commercial game project, and are targeting a\nplatform such as the PC, where performance can vary from one machine to the next,\nthen we need to worry about scalability of the technique. Even if targeting a fixed\n",
      "content_length": 2893,
      "extraction_method": "Direct"
    },
    {
      "page_number": 453,
      "chapter": null,
      "content": "472\nSection 5 Graphics Display\nplatform, the game may have a varying load, and we may want to scale back the qual-\nity and performance requirements of the technique in heavy load situations.\nThere are several ways in which the technique can be scaled:\n• Texture resolution. The resolution of the textures used at the various intermedi-\nary stages could be reduced, saving memory and fill-rate consumption. Note that\nscaling color depth is most likely not an option here, since the artifacts show up\npretty quickly when using 16bpp textures.\n• Texture update rate. Not every texture need be updated per frame. Particularly if\nthe simulation rate is slow, the interpolating textures do not need to be updated\nat every frame as we did in the sample code.\n• Number of octaves used. The sample code uses four octaves of noise, but using\nthree might provide an acceptable result. Similarly, five octaves might give slightly\nbetter quality on systems that have the horsepower.\nConclusion\nmm \n; \n:-: \n:r\"::-;:::::; \nr: \n;\"\":;• \n--7:::. \n—-'-•::\" ~\" \n:;-:;;: •—-•••:::•—-•\"••--:•-••:;•::,: -™:r:~:::: ::•: -•-'•r:;-::^--\":-vi::::'::\"::\"r\"-:;-.v;;:::-1\"-»\nFigure 5.4.7 displays the final result of the procedural cloud example program.\n*a^p^ta»%s«\n\"*\"\"'\"*\"\nFIGURE 5.4.7 Final result of procedural cloud example program.\n",
      "content_length": 1310,
      "extraction_method": "Direct"
    },
    {
      "page_number": 454,
      "chapter": null,
      "content": "5.4 Generating Procedural Clouds Using 3D Hardware \n473\nWe hope this technique has provided you with some insight into procedural\ntexture generation, using clouds as an example, and how to get graphics hardware\nto do much of the per-pixel work needed in generating dynamic procedural textures.\nAs hardware grows more capable, so will the techniques in which we can generate\nthese textures in real time. We encourage you to try your own experiments and share\nthem with the development community.\nReferences\n[Ebert et al, 98] Ebert, David S., et al, Texturing and Modeling: A Procedural Approach,\nAP Professional Inc., 1999. ISBN: 0-12-228730-4.\n[Elias99] Elias, Hugo, \"Cloud Cover,\" available online at http://freespace.virgin.net/\nhugo.elias/models/m_clouds.htm, offers a software-only technique similar to this\none.\n[Pallister99] Pallister, Kim, \"Rendering to Texture Surfaces Using DirectX 7\", avail-\nable online at www.gamasutra.com/features/19991112/pallister_01.htm\n",
      "content_length": 971,
      "extraction_method": "Direct"
    },
    {
      "page_number": 455,
      "chapter": null,
      "content": "5.5\nTexture Masking for Faster\nLens Flare\nChris Maughan, NVIDIA Corporation\ncmaughan@nvidia.com\nT\nhis gem introduces a novel way in which to generate texture information from\npixels already rendered to the frame buffer. The technique can be used in several\ndifferent ways, but is presented here as a solution to the common problem of\noccluded lens flare. Many games attempt to read back pixels generated in the frame\nbuffer in order to determine exactly what was visible in the final scene. I will present\na technique that works without CPU assistance, and does not require reading\ndata from the graphics card. I will also outline the reasons why reading back infor-\nmation from the graphics card can be a costly operation and should be avoided if\npossible.\nLens Flare Occlusion\nMany modern games add lens flare to the scene to increase realism. The lens flare is\nusually applied as the last item in the scene, using a 2D texture map rendered as a bill-\nboard over the frame. A complication with this technique is that objects in the scene\ncan occlude the sun image, and in this case, the correct visual result is a lessening of\nthe lens flare intensity. A good way to visualize this is to imagine yourself driving\nalong a road lined with trees on a sunny day; if the sun is below the tree line, you will\nexperience a flickering as your viewpoint through the trees changes and the amount of\nlight reaching your eyes varies.\nThe usual approach to detecting the occlusion of the sun is to first render the\nobjects in the scene, including the sun itself. Then we read back the frame buffer\ndata around where the sun pixels would be and deduce the amount of sun visible in\nthe scene. We can do this in two ways: we can read back the color buffer and look\nfor values that match our sun color, or we can read back the Z-buffer and look for Z\nvalues that are as far away as the sun. The ratio of visible to occluded sun pixels\ngives us a handy approximation of the intensity of the lens flare. We are now ready to\ndraw our lens flare by blending it onto the final scene using an alpha value to set its\nintensity.\n474\n",
      "content_length": 2110,
      "extraction_method": "Direct"
    },
    {
      "page_number": 456,
      "chapter": null,
      "content": "5.5 Texture Masking for Faster Lens Flare \n475\nHardware Issues\nThe preceding approach is generally taken when rendering lens flare in games. While\nit can work well, it causes unnecessary stalls in the graphics pipeline that can seriously\nimpair performance.\nModern graphics pipelines are very deep. Polygon data is not only queued inside\nthe graphic chip pipeline, but it is also queued in a large \"staging\" buffer. Typically,\nmany thousands of polygons will be queued in the staging buffer by the game, and the\ngraphics chip will drain the buffer as it draws polygons into the frame buffer. In a\ngood parallel system, the game can be doing useful work on the CPU, such as physics,\nAI, and so forth, while the graphics chip (GPU) is draining the staging buffers.\nIndeed, this is to be encouraged if the maximum performance of the system is to be\nachieved. Figure 5.5.1 illustrates a system with optimal parallelism.\nM \n- \nCPU \nPreparing \nScene \n3\nSubmit Scene 2\nDo Network\nDoAl\nDo Physics\nCPU Activity \nSubmit Scene 2 \nDo Network \nDoAl \nDo Physics \nI \nSubmit Scene 3\nDraw Scene 1 \nPage Flip\nDraw Scene 2\n^_ \nGPUDrawing \n__M \nGPUDrawing Scene 2 \n-\nocsne l\nFIGURE 5.5.1 Parallelism of the GPU I CPU in an ideal game engine.\nNow consider the situation that occurs when the game has submitted all the\npolygons for the current scene to the graphics chip. Much of the scene may still be\nqueued in staging buffers and will not be drawn for some time. The next thing our\ngame wants to do is to read back the contents of the scene to determine the sun vis-\nibility for the lens flare calculation. Here lies the first part of our problem. In order\nto read the completed scene from the frame buffer, we must wait for the rendering to\ncomplete, and in order for this to happen, the whole pipeline must be flushed. While\nwaiting for this to occur, the CPU is effectively unused, as it is simply idle inside the\ngraphics card driver waiting for the rendering to complete. Ideally, we want the GPU\nand the CPU to be concurrently active at all times. One potential solution to this\nproblem is to insert our physics/AI code after the scene render, but before the lens\nflare calculation. In this way, the CPU will be busy while the GPU is rendering the\npolygons.\nIn this case, if our CPU work is more than the GPU work, then we do not have a\nproblem—although arguably the system is unbalanced because the GPU is waiting\nfor the CPU to finish its work, when it could be doing more rendering (Figure 5.5.2).\n",
      "content_length": 2488,
      "extraction_method": "Direct"
    },
    {
      "page_number": 457,
      "chapter": null,
      "content": "476\nSection 5 Graphics Display\nCPU Submitting\nScene 2\nCPU Activity\nSubmit Scene 2\n-H-\nCPU Waiting forGPUto Finish Scene 2\nLock / Read Frame Buffer\nSubmit Flare\nGPU Activity\nDraw Scene 1\n^ \nGPUDrs\nScene 1\nPage Flip\nDraw Scene 2\nDraw Flare\nFIGURE 5.5.2 Pipeline stall caused by flush at end of rendering.\nIf our CPU work is less than the GPU work, we will again stall when we try to\nread back the lens flare data. This is undesirable because ideally we would like to be\npreparing the next frame of the game on the CPU while the last one completes on the\nGPU (Figure 5.5.3). Parallelism is the key here, and inserting any stalls can hurt it\nconsiderably.\nThe story does not, however, end here. After losing our concurrency, there is\nanother problem. Reading back data from a current generation graphics card is a slow\noperation, and in some cases cannot be done at all.\nWhile most graphics cards run at AGP 2x/4x speeds when written to, reading\nback from them is still limited to PCI speeds—this is inherent in the nature of the\nAGP bus design as it stands today. The result is that for a 32-bit frame buffer, we can\nonly read pixels at a maximum rate of 66Mhz, with no caching or bursting behavior.\nTherefore, reading an area of 256 * 256 from the graphics card will take\n1 / (66,000,000 / (256 x 256)) = -1 millisecond.\nThis assumes a 256-square pixel area of the sun projected onto the screen. If we\nare standing nearer to the light source—for example, a street-lamp—then the pro-\njected area can vary quite considerably until the read back becomes very significant.\nEven if we are willing to take this hit in performance, there is no guarantee that the\nCPU Submitting\nScene 2\nCPU Preparing\nScene 3\nCPU Activity\nGPUActivity\n(CPU Load\nheavier than I\nLoad)\nSubmit Scene 2\nNetwork/ Physics /Al\nLock/Read\nFrame\nBuffer\nDraw Scene 1\nPage Flip\nDraw Scene 2\nGPU Idle \n|\nGPUDrawing\nScene 1\nGPUDrawing\nScene 2\nGPUWaiting for CPU to finish\nFIGURE 5.5.3 Pipeline stall caused by flush before end of frame, after CPU work.\nSubmit Flare\nDraw Flare\n",
      "content_length": 2034,
      "extraction_method": "Direct"
    },
    {
      "page_number": 458,
      "chapter": null,
      "content": "5.5 Texture Masking for Faster Lens Flare \n477\ngraphics card will allow us to read back the data at all; in fact, many do not. Most will\nnot allow reading of the Z-Buffer, many do not allow reading of the frame buffer, and\nnone will allow reading of an antialiased buffer.\nTexture Masking\nHow can we alleviate the stalls caused by reading the frame buffer? We arrive at the\nsolution through a bit of lateral thinking. We know that we cannot pass a value down\nfrom the CPU to modulate the lens flare brightness, for the reasons outlined previ-\nously. This leaves only one possibility: that we modulate the lens flare value with data\nalready generated in the graphics memory on the card. Such a value must be in the\nform of a texel in a texture map, and this texel needs to contain either a luminance\ncolor value or an alpha value. We know that we can render to a texture map in\nDirect3D or OpenGL. The remaining problem is how we actually generate this texel\nbased on a set of source pixels. The solution lies in the alpha blending capabilities of\nthe GPU. The alpha blending unit is basically an adder, which adds a value in the\nGPU to one on the frame buffer, and can be used to accumulate color information.\nAdd to that the realization that objects in our scene are rendered in a color of our\nchoosing, and a suitable solution presents itself. The following steps show how to\nachieve the result we need.\nStep 1\nCreate a texture map of 16x16 texels. Call this the sun map. We will be rendering the\nsun itself and the occluding geometry onto this map. The surface format should have\nat least 8 bits per color component. On typical graphics hardware, this equates to a\n32-bit ARGB surface. The sun map is chosen to be 16x16 because it contains 256 tex-\nels. As we will see later, we are not limited to a 16x16 size, and can play tricks with fil-\ntering to reduce it if necessary.\nStep 2\nCreate a 1x1 texture map. This is the intensity map. This is the final destination of our\nintensity data. We only need a single texel of information, but of course, this texture\ncan be as big as needed to satisfy particular hardware requirements. Again, the format\nof this surface should be at least 8 bits per color component.\nStep 3\nRender the portion of the scene containing the sun into the sun map. There are many\nways to do this, but we choose a simple approach. We orient the viewer to look directly\nat the center of the sun. We also set the projection matrix so that the sun fills the view-\nport. The front plane is just beyond the eye; the back plane is just behind the sun. The\nsun map is cleared to black. We render one of two colors to the sun map. The image of\nthe sun itself is rendered in white. The occluding geometry is rendered in black, thus\n",
      "content_length": 2747,
      "extraction_method": "Direct"
    },
    {
      "page_number": 459,
      "chapter": null,
      "content": "478 \nSection 5 Graphics Display\ncovering any of the sun values already rendered. If the sun is rendered first, Z-BufFering\nis not required, as we are just interested in the occlusion, not the depth ordering. The\nsun map now contains 256 values, some of which are white, some of which are black.\nIn 32-bit color, this means that the frame buffer contains OxFFFFFFFF or\n0x00000000. Note that for consistency, I set up the alpha channel in the same way as\nthe color channels, enabling the option of alpha blending or color blending.\nStep 4\nRender 256 pixels to the 1x1 intensity map. Draw them using point-lists or point-\nsprites if the API/hardware supports them, as they require less transform work than\nfull triangles or quads. Set texture coordinates so that each sun map texel is referenced\nonce. Set the alpha blend unit to add the color information of each of the source sun\nmap texels to the destination intensity map. We also want to sample only one texel at\na time from the sun map, so we set texture sampling to point sampling mode. Note\nthat we are writing to a single destination pixel multiple times, with different source\ntexels. One further step is that we blend each sun map texel with a constant value of\n0x01010101. This is actually 1/255 in each of the color channels. The result is that\nthe modulated sun map values will either be 0x01010101 if the source sun map texel\nis white, or 0 if the source sun map texel is black. I choose white and black as values\nin the sun map because these are generally easy to achieve during rendering, and can\nbe displayed for diagnostic purposes in the demo.\nThe trick here is that we are adding 256 values from the sun map, to form a pos-\nsible range of 256 values in the intensity map. The brighter the pixel in the intensity\nmap, the more visible sun pixels there are in the sun map, and hence the scene itself.\nWe have \"masked\" out the texture results of a previous rendering and added them\ntogether. As we will see later, this texture masking approach can be very useful for var-\nious applications.\nThe whole process has used the GPU to generate lens flare intensity from infor-\nmation in the frame buffer. Because the GPU pipeline is serialized, we know that the\nintensity information will be written before we generate our lens flare, and that the\npipeline does not require a flush during the operations discussed earlier. Further,\nbecause we have decoupled lens flare intensity generation from scene rendering, we\ncan perform these steps at any point, and potentially use the resulting value during\nrendering of the actual scene rather than at the end. We could perhaps use this value\nto modify the ambient intensity of the scene to simulate the viewer's pupils' reaction\nto the light—an option that is not open to us with the lock method unless we want to\nrender the entire scene twice.\nPerformance Considerations\nThe presented algorithm may seem like a lengthy procedure, but is in fact a relatively\ninexpensive operation when compared to reading the frame buffer and flushing the\npipeline. Consider that we are adding a little GPU work at the end of the frame,\n",
      "content_length": 3124,
      "extraction_method": "Direct"
    },
    {
      "page_number": 460,
      "chapter": null,
      "content": "5.5 Texture Masking for Faster Lens Flare \n479\nwhich can continue to run in parallel with the rest of our engine. The caveat is that\nthe rendering of the sun map must be quick. We can ensure that this is the case by\nconsidering that the sun is usually above ground, and that the field of view to the sun\nis actually very small. This considerably reduces the number of objects we have to\nconsider, and allows quick rejection of those that we do via frustum culling. We can\ndo early-out rejection if we determine that any of our objects completely occlude the\nsun, and hence we do not draw the lens flare at all. A further option would be to ren-\nder the potential occluders with less geometric detail.\nAnother performance concern may be the rendering of the 256 blended polygons\nwe use to find the intensity result, but this isn't a problem because a modern GPU can\nrender about 40 million points per second—a fraction of the time it will take to read\nback a potentially large amount of data from the frame buffer, issues of concurrency\naside. In addition, reading back data from the frame buffer involves the CPU, which\nwe are trying to free up for nongraphics tasks.\nImprovements\nThe preceding scheme works well, and it gives a good approximate result. One obvious\ncriticism of the technique is that the sun is typically a circular object and the sun map we\nare using is a square texture. In fact, this is not a problem, as we can sample any texels we\nlike from the source sun map, including a circular sampling pattern. Of course, we need\nto make the sun map larger in order for it to cover the required number of samples.\nIf we wish, we can only sample a selection of the sun map texels. To do this, we\nsimply sample the required number of texels in the sun map, and change the modu-\nlate operation we use when writing to the intensity map to scale up our results.\nNote that we are solving the lens flare problem as an example, but many of the\ntechniques are reusable in other situations. Perhaps the intensity value could be used\nto darken the scene to mimic overexposure effects, or to add silhouettes or halos to\ncharacters. In fact, once we realize that the GPU has great flexibility as a mathemati-\ncal solver, we can modify our algorithm in a number of ways, using the GPU as a gen-\neral parallel mathematics engine. For example, we can use texture filtering to sample\nfour texels at a time, giving an average result for four samples. In our previous exam-\nple, we only need to draw 64 points to get our intensity map results if we rely on\nbilinear filtering to get the average intensity of the four samples. We can also do sev-\neral mathematical operations by varying the blending operation, such as using modu-\nlation to scale values. This is useful if we wish to accumulate more samples in the\nintensity map, because we can use the modulation to add scaling to our intensity map\nresults at the expense of dynamic range.\nSample Code\nif •;.«& \"*§ \nThe sample demo on the companion CD-ROM gives a good idea of the performance\nON me co \ndifference between the locking and texture masking techniques, and shows how to\n",
      "content_length": 3125,
      "extraction_method": "Direct"
    },
    {
      "page_number": 461,
      "chapter": null,
      "content": "480 \nSection 5 Graphics Display\nimplement the algorithm as described. Options are also available on the menu to\nenable the display of the sun map and the intensity map.\nWhen running the demo on my target system, I take about a 50-percent frame-\nrate hit for using the lock method versus the texture masking method. The perfor-\nmance delta also increases the larger the frame buffer becomes. Typical numbers for\nthe opening scene are as follows:\nTexture Masking (600x500x32bits) = 53.5 fps\nFrame Buffer Locking (600x500x32bits) = 27.8fps\nThe source is heavily commented and should be easy to follow. I used Direct3D\nversion 8 to write the demo, but the concepts are identical for OpenGL. See the\ns~~z- B^ \nREADME included with the application on the CD for more information on how to\n£,'•:\" *JC •*\"' : '•-%\n5<-ffii^ \nrun ,-he demo and analyze the results. Detail is also included on how to use the\n\"Increase CPU Work\" option in the demo to study the hit to system parallelism from\nusing the lock call versus the texture masking technique.\nAlternative Approaches\nThere are two alternative approaches to lens flare that should be mentioned for\ncompleteness:\n• Sometimes, a geometry-based approach is taken to determine the visibility of the\nflare. The approach is to scan the geometry and do ray intersection tests to deter-\nmine visibility of a grid of sun pixels. While this works, it can be costly in terms\nof CPU compute time, and is not a useful approach when using billboards, as the\nsource textures have to be scanned for \"holes.\"\n• Some graphics cards have the ability to do asynchronous readback of the frame\nbuffer data. In this case, the light source area is uploaded in parallel with the ren-\ndering of the rest of the scene. This can be useful assuming that there is a suitable\npoint in the scene after occlusion objects are drawn in which to start the read-\nback, but before the rest of the scenery or lighting work is done. This method\ndoes of course rely on the support from the API to read back the data asynchro-\nnously, and support from the hardware to upload the data. At the time of writing,\nthis support is not available in Direct3D or OpenGL, although extensions to\nboth APIs have been proposed.\nReferences\n[KingOO] Yossarian King, \"2D Lens Flare,\" Game Programming Gems, Charles River\nMedia Inc. 2000: pp. 515-518.\n",
      "content_length": 2336,
      "extraction_method": "Direct"
    },
    {
      "page_number": 462,
      "chapter": null,
      "content": "Practical Priority Buffer\nShadows\nD. Sim Dietrich Jr., Nvidia Corporation\nsdietrich@nvidia.com\nA\ns game graphics become more sophisticated in certain areas, others begin to look\nprimitive by comparison, thus breaking the consistency so essential to an immer-\nsive experience. One example of this phenomenon is the advent of detailed per-pixel\nlighting, which can be applied to the entire scene in real time (see the \"Dynamic Per-\nPixel Lighting\" gem). Unfortunately, the visual complexity of the lighting outshines\nthe shadow techniques employed by many games. This gem presents a set of tech-\nniques to improve the utility of priority buffers, first introduced in [Hourcade85].\nAlong the way, we will explore other shadow techniques, and close by discussing how\nto create useful hybrid techniques.\nShadows are very tricky in real-time graphics, because they are truly a scene-graph\nlevel problem, perhaps most naturally solved on the CPU. However, to achieve\nthe detailed results and performance we seek, we must leverage graphics hardware to\nsolve the shadow test on a per-pixel basis. Some graphics hardware currently has\nnative shadow support, including priority buffers and shadow depth buffers. However,\nsince none of these are available through a single standard interface, we will concen-\ntrate on generic techniques that should work with modern PC graphics hardware\nthrough either Direct3D or OpenGL.\nSome of the shadow techniques employed by modern games are shadow volumes,\ndepth buffer shadows, and. priority buffer shadows. Each has various advantages and dis-\nadvantages, briefly outlined in Table 5.6.1.\nShadow depth buffers [Williams78] work by using the Z-buffer or a texture that\nrepresents per-pixel depth from the light. We will focus on techniques that work with\ntexturing, to maximize the utility of the techniques across graphics hardware. Shadow\ndepth buffers work like so:\nBuffer Creation Phase:\nFor each Light\nClear Depth Buffer Texture to Oxff\nFor each Object in Light's Viewing Frustum\n481\n",
      "content_length": 2018,
      "extraction_method": "Direct"
    },
    {
      "page_number": 463,
      "chapter": null,
      "content": "482\nSection 5 Graphics Display\nTable 5.6.1 Comparison of Real-Time Shadow Techniques\nPriority Buffers\nDepth Buffers\nOnly convex pieces can\nself-shadow properly\nShadow Volumes\nCPU Work\nRender To Texture\nRequired\nFill Requirements\nSelf Shadowing\nVery Low\nPer-Light Setup\nObject Sorting\nYes\nMedium\nDepends on size of\nshadow map\nPartial\nVery Low\nPer-Light Setup\nYes\nMedium\nDepends on size of\nshadow map\nYes\nHigh\nPer-Light Setup\nPer-Object Shadow\nVolume Creation\nNo\nHigh\nDepends on complexity\nof shadow volume and\ncamera position\nYes\nPrecision\nAliasing Artifacts\nGPU Complexity\nTypically 8-24 bits of\nID\nRange independent\n8-24 bits of ID\nTypically spread across\nlights' range\nYes\nBetween Adjacent\nObjects\n0 ( N * M * R * P )\nN = Vertices of caster\nR = Vertices of receiver\nP = Number of receivers\nM = Size of shadow map\nYes\nDepending on Depth\nPrecision & Light Range\n0 ( N * M * R * P )\nN = Vertices of caster\nR = Vertices of receiver\nP = Number of receivers\nM = Size of shadow map\nNo limit to accuracy\nDirectional Lights\nSpot Lights\nPoint Lights\nYes\nYes\nYes\nYes\nYes\nYes\nWith less precision\nYes\nYes\nYes\nNo\n0 ( N * R * P * E )\nN = Vertices of caster\nR = Vertices of receiver\nP = Number of receivers\nE = Depth complexity\nof shadow volume\nCompute Per-Pixel Depth from Light from 0x0 to Oxff\nRender Object into Texture, using Depth as the color\nShadow Testing Phase:\nFor each light\nCreate texture matrix to move vertices from view space to\nLight's view space\nFor each Object in Player's Viewing Frustum\nCompute Per-Pixel Depth exactly as above\nSelect Depth Buffer as a Texture\nFor each vertex\nProject vertices to the Depth Buffer Texture\nFor each pixel of Object\nCompare Computed Depth to Closest Projected Depth\n",
      "content_length": 1704,
      "extraction_method": "Direct"
    },
    {
      "page_number": 464,
      "chapter": null,
      "content": "5.6 Practical Priority Buffer Shadows \n483\nIf Computed Depth > Closest Projected Depth\nPixel is in Shadow\nElse\nPixel is Lit\nPriority buffers work by first assigning each \"Object\" a unique ID from 0x0 to\nOxFE. An object is defined as something that can't shadow itself. Examples of objects\nwith perfect shadowing through this technique are convex objects and individual tri-\nangles. Priority buffer shadows work like so:\nBuffer Creation Phase:\nFor each Light\nSet Priority Buffer Texture as the Render Target\nClear Priority Buffer Texture to Oxff\nFor each Object in Light's Viewing Frustum\nAssign ID from nearest to Light = 0x0 to farthest from Light\n<=OxFE\nRender Object into Texture, using ID as the color\nShadow Testing Phase:\nFor each light\nCreate texture matrix to move vertices from view space to\nLight's view space\nFor each Object in Player's Viewing Frustum\nSelect ID as a constant color\nSelect Priority Buffer as a Texture\nFor each vertex\nProject vertices to the Priority Buffer Texture\nFor each pixel of Object\nCompare constant ID to Closest Projected ID\nIf Constant ID > Closest Projected ID\nPixel is in Shadow\nElse\nPixel is Lit\nComparing Priority Buffers to Depth Buffers\nPriority buffers and depth buffers are very similar techniques—we could even use the\nsame pixel shader program or texture stage setup to perform either method.\nDepth buffers have the advantage that each pixel is treated individually by having\nits own depth value measured from the light. This allows this technique to perform\nself-shadowing.\nOne downside of depth buffer shadows is that the depth from the light is typi-\ncally computed over the light's entire range of influence. If we use an 8-bit color or\nalpha channel to represent depth from the light as in our previous example, only 8\nbits are available for the entire light's range. This is not adequate precision for many\nscenes to support both proper inter-object shadows as well as intra-object self-\nshadowing (Figure 5.6.1).\n",
      "content_length": 1969,
      "extraction_method": "Direct"
    },
    {
      "page_number": 465,
      "chapter": null,
      "content": "Section 5 Graphics Display\nAt Light |—^—— \n——^^1 ^ Light's Maximum Range\nFIGURE 5.6.1 Depth from light.\nPriority buffers overcome this difficulty by assigning each object its own ID,\nbased on its sort order in terms of distance from the light. This way, the precision is\neffectively infinite over the entire range. Any range can be equally accommodated, at\nthe cost of losing self-shadowing. Because each object has its own ID, individual sec-\ntions of the object can't shadow each other.\nFigure 5.6.2 is an example where two chairs are rendered with different IDs from\nthe point of view of the light. The background is normally white, but is cleared to\nblack to make the chairs show up better.\nFIGURE 5.6.2 Priority buffer from light's view point.\nThere are several ways to overcome the self-shadowing problem without special-\nized hardware. One way is to break up the model into convex pieces, perhaps each\nhierarchy level of an animated model or even down to the individual triangle level.\nOne natural approach for static geometry is to break up the world into convex pieces\nusing OctTree or BSP nodes, and assign an ID to each node. Unfortunately, this\napproach exacerbates a serious problem—aliasing.\nResolving Aliasing Problems\nAliasing artifacts most obviously occur when two nonoverlapping objects with differ-\nent object IDs shadow each other. This occurs due to the simple fact that the back\nbuffer and priority buffer texture are at different resolutions and different orienta-\ntions. This causes a point sample of the priority buffer to fall somewhere within one\ntexel of the desired sampling location. Sometimes the sample selects the desired texel,\nsometimes one of its neighbors (Figure 5.6.3).\n",
      "content_length": 1710,
      "extraction_method": "Direct"
    },
    {
      "page_number": 466,
      "chapter": null,
      "content": "5.6 Practical Priority Buffer Shadows\n485\nFIGURE 5.6.3 The dashed line shows the texture sample positions lined up with the\npriority buffer. This mismatch of size and orientation causes aliasing.\nBilinear filtering is used for texture mapping in order to reduce this type of alias-\ning by performing a weighted average of a 2x2 footprint of texels. Unfortunately, aver-\naging object IDs makes no sense. If we have texels with object ID 100 and 200, and\nwe average them, we get object ID 150. This object ID may represent a completely\ndifferent object, so we see that straight bilinear filtering won't do the trick.\nOne way to solve the aliasing problem is to offset the texture by half a texel so that\nthe sample falls exactly in between a 2x2 area of texels. Then, perform the shadow test\nfour times, and only allow a shadow when all four samples agree that the pixel should\nbe in shadow. This solves the aliasing problem, but costs four texture fetches, and\nmultiple passes on dual-texture hardware.\nAn improvement to this technique is to \"pre-jitter\" the priority buffer. After cre-\nating the priority buffer as we did earlier, by putting the object ID in the alpha chan-\nnel of the priority buffer, we perform another render-to-texture pass into a texture the\nsame size as the original priority buffer. With this pass, we perform the \"pre-jitter\" by\ntaking the four texels that neighbor the original sample location in the priority buffer,\nand replicating them into R, G, B, and A of the destination color.\nThis way, during the shadow testing phase, a single texture fetch of the \"pre-\njittered priority buffer\" gives all four neighboring samples. With a bit of per-pixel\nmath, all four shadow tests can be computed at once, their results combined, and the\naliasing eliminated, by only shadowing the pixel if all four tests agree it should be in\nshadow (Figure 5.6.4).\nThis pre-jitter technique is useful because there is only one jitter step per frame,\nbut many shadow testing operations, so it exploits coherency for faster rendering.\nFigure 5.6.5 is a pre-jittered version of Figure 5.6.4. Note how the chairs have a\ncolored outline, which indicates that the R, G, and B channels represent different IDs\nafter jittering.\n",
      "content_length": 2228,
      "extraction_method": "Direct"
    },
    {
      "page_number": 467,
      "chapter": null,
      "content": "486\nSection 5 Graphics Display\nFIGURE 5.6.4 The dashed line shows the\ntexture sample positions lined up with the four\nnearest neighbors of the priority buffer.\nFIGURE 5.6.5 Pre-jittered priority buffer from\nthe light's view point.\nHybrid Approaches\nPerhaps the best use of priority buffer shadows is to use them for inter-object shadows\nbetween objects that don't come close to intersecting, and thus won't alias, and use\nanother technique altogether to handle self-shadowing. So, if two objects are far\nenough apart such their bounding spheres don't intersect, the priority buffer method\nis used to shadow the further one with the closer one. In the case where the bounding\nspheres do intersect, there is a chance that the objects may alias with each other, so\nthey use the same object ID, and they must be shadowed with the self-shadow test.\nOne approach that combines priority buffers for inter-object shadows and depth\nbuffers for self-shadowing is to encode the 8-bit object ID into the red channel of a\ntexture in a vertical ramp, and an 8-bit depth in the green channel in a horizontal\nramp. The idea here is that the 8-bit depth buffer is only used for self-shadowing\nwithin a single object, so the 8 bits can be spread across a single object's range. This\ngets around a major problem with standard depth buffer shadows: limited precision\nacross the light's range (Figure 5.6.6).\nObject 2\nDepth Range 1 \nDepth Range 2\nFIGURE 5.6.6 Depth measured across each object.\n",
      "content_length": 1474,
      "extraction_method": "Direct"
    },
    {
      "page_number": 468,
      "chapter": null,
      "content": "5.6 Practical Priority Buffer Shadows \n487\nThe technique to perform this dual shadow test is a subtraction and a dot prod-\nuct, replicated into the alpha channel. Alpha testing can be used to determine\nwhether a pixel is in shadow, thus allowing this technique to work on any hardware\nwith dual texturing and a dot product operation.\nAnother hybrid approach is to use stencil shadow volumes only for self-shadowing.\nAfter computing the shadow volume edges, we can extrude them only to the edge of\nthe object's bounding box, instead of extending them to the limit of the light's range.\nThis reduces the impact of the major drawback to stencil shadow volumes—the fill\nrate cost when the shadow volume extends across the camera's view plane. By restrict-\ning them to self-shadowing only, we also have the benefit that we can completely skip\nthe self-shadowing test for objects outside the viewing frustum.\nYet another way to achieve self-shadowing with priority buffers is to perform ray\ncasts of each vertex to the light source on the CPU, and check for the ray intersecting\nthe object. If the ray intersects a solid portion of the object, set the alpha channel of\nthe vertex diffuse color to zero. During the lighting process, modulate this alpha value\nwith the lighting contribution of the light. As shown previously, this could be per-\nformed only on objects in the viewing frustum, and even dropped altogether for dis-\ntant objects. A variant on this approach is to perform the test only on chunks of the\nmodel—say, one for each model hierarchy level—like the shoulder or forearm. This\nmakes a nice level-of-detail option for distant and/or unimportant models.\nSummary\nPriority buffers are a great way to get inter-object shadows that bypasses the issue of\nlimited precision across a light's range. Although standard priority buffers are not\nideal for handling self-shadowing, other techniques can be paired with them to\nachieve a complete shadowing solution for real-time games.\nReferences\n[DietrichOO] Dietrich, D. Sim, \"GDC 2001 Presentation—Shadow Techniques,\"\nwww.nvidia.com/marketing/developer/devrel.nsf/bookmark/04l9FBACDE043\nABF88256A1800664C06.\n[Hourcade85] Hourcade, J.C., and A. Nicolas, \"Algorithms for Antialiased Cast\nShadows,\" Computers and Graphics, vol. 9, no. 3, pp. 259-265, 1985.\n[Williams78] Williams, Lance, 'Casting Curved Shadows on Curved Surfaces,\"\nComputer Graphics (SIGGRAPH 78 Proceedings), vol. 12, no.3, pp. 270-274,\nAugust 1978.\n",
      "content_length": 2464,
      "extraction_method": "Direct"
    },
    {
      "page_number": 469,
      "chapter": null,
      "content": "5.7\nImpostors: Adding Clutter\nTom Forsyth, Mucky Foot Productions\ntomf@muckyfoot.com\nf mpostoring is a term that is probably not familiar to many reading this. However,\nthe concept may be—it has surfaced in various forms many times in the history of\n3D graphics. Simply put, it is about using sprites in a 3D scene, but instead of an\nartist drawing or rendering the sprites beforehand, they are updated on the fly. (In\nfact, the academic version of impostoring started when rendering things such as\ncityscapes for VR fly-throughs, and was not updated dynamically—that came in later\nversions. However, the dynamic update version is far more interesting to games, since\nby their nature they deal with scenes that change.)\nInstead of rendering a high-triangle object every frame, the high-triangle object is\noccasionally rendered to a texture—usually on the order of once every 5 to 50 frames.\nEvery frame this texture is mapped onto a much lower-triangle object which is drawn\nin place of the complex object.\nThe main target for impostors is scenes with lots of small static objects in them—\nclutter. Each of these objects will use an impostor, and most will be redrawn at a\nmuch lower rate than the main scene's frame rate. By doing this, the perceived trian-\ngle density is far higher than the actual density, and the visual quality allowed by all\nthese incidental objects considerably increases the realism of the scene. The main dif-\nference between an office or house in a computer game and the real thing is the\namount of clutter present.\nAlthough newer cards have huge triangle throughput, using impostors is still of\ngreat benefit. The bus bandwidth (in the case of the PC, this is the AGP bus) is usu-\nally a bottleneck, and reducing this for some objects allows greater triangle detail to be\nused on others. An impostor is a single texture, whereas rendering the object normally\nmay require multiple textures and multiple texture layers—changing texture flushes\nthe hardware's texture cache and may require extra texture management from the dri-\nver, the API, or the application. Drawing the object each frame requires that it be lit\neach frame, even if the lighting has not changed, and as lighting techniques become\nmore sophisticated, lighting becomes more expensive. Finally, there is usually plenty\nof application overhead associated with drawing an object, even before a single API\ncall is made—using impostors can avoid much of that work.\n488\n",
      "content_length": 2458,
      "extraction_method": "Direct"
    },
    {
      "page_number": 470,
      "chapter": null,
      "content": "5.7 Impostors: Adding Clutter \n489\nThe Whole Process\nImpostoring involves a few key parts, which will be addressed separately:\n• Rendering the impostor texture on the screen each frame. I call this \"rendering\"\nthe impostor.\n• Rendering the impostor's mesh at low speeds to the texture. I call this \"updating\"\nthe impostor.\n• Deciding when to update the impostor, and when to leave it.\n• Driving the hardware efficiently.\nRendering the Impostor:\nONE:INVSRCALPHA\nAn impostor is essentially a color picture with an alpha channel that defines that pic-\nture's opacity in some way. Given that, there are basically two choices for this sort of\nblending: premultiplied alpha and \"normal\" blended alpha.\nNormal alpha is the standard SRCALPHA:INVSRCALPHA style. The other\nstyle is premultiplied alpha— the ONE:INVSRCALPHA style.\nWhich one to use depends on which produces the correct result when rendering\nan alpha-blended object into an impostor, and then rendering the impostor to the\nscreen. A pixel P is rendered to an impostor texture (which is cleared to black) to pro-\nduce an impostor pixel I, and then that is rendered on top of the existing framebuffer\npixel F, to produce result pixel R.\nIf using non-premultiplied alpha, the desired result is:\nThe render to the impostor produces the result:\nAnd rendering this to the framebuffer produces:\n= P x Pa x Pa x Pa + F x ( 1 - Pa x />„)\nThis is pretty useless, and very little like the desired result. With premultiplied alpha,\nthe desired result is:\nR = P+Fx(l-Pa)\nThe render to the impostor produces this result:\n7=P+Ox(l- JP a)\n",
      "content_length": 1578,
      "extraction_method": "Direct"
    },
    {
      "page_number": 471,
      "chapter": null,
      "content": "490 \nSection 5 Graphics Display\nRendering to the framebuffer produces this:\n= P+Fx(l-Pa)\nwhich is perfect. Premultiplied alpha is not used by many apps, but it is fairly simple\nto adapt an existing engine to use it.\nOne thing to note is that it is now important to be precise about the alpha-\nchannel result even when rendering opaque triangles, since the result will be written\nto the impostor, and will influence the result when die impostor is rendered to the\nscreen. Non-alpha-blended (i.e., opaque) rendering to the impostor must ensure that\nthe alpha result is 1 , or the background will show through. Fortunately, this is fairly\neasy to do, but it does require more care with the alpha-channel result than is nor-\nmally taken.\nOne problem with impostoring is that alpha-blend effects rendered into an\nimpostor must be capable of expressing their effect within the premultiplied alpha\nscheme. This means that effects such as multiplicative color blends (basically, any-\nthing with a COLOR argument in the alpha-blend) will not work as intended,\nbecause the impostor has only a single alpha channel to express the amount of back-\nground to allow through. Fortunately, these sorts of effects are rarely used on objects\nthat are suitable for impostoring. Note that this only applies to actual translucent\neffects — opaque multipass rendering that uses alpha blending to combine the passes\n(e.g., light maps, detail maps, etc.) will be fine, as long as the final alpha-channel value\nis carefully controlled.\nBillboard Quad\nThe most obvious way to render the impostor is to simply render a quad representing\nthe impostored object. This gives a perfect result as long as the neither the object or\nthe camera move.\nUnfortunately, pixels are not all the app has to worry about in a 3D scene; there\nis also depth to consider. A quad can only represent a single plane of depth, but the\nobject it represents will cover multiple depths.\nSo, for the quad, the app needs to decide at what depth to draw. Unfortunately,\nfor some of the most common applications, there is no single depth that is appropri-\nate. As can be seen in Figure 5.7.1, our impostored hero is standing between two\nwalls. Unfortunately, his feet are sticking through the near wall, and his head has van-\nished through the far wall. Quads are no good if an impostored object is going to be\nclose to other objects. They may be quite good for flying objects that don't usually get\ntoo close to things, though, such as aircraft in a flight simulation.\nCuboid\nThe next approximation is a bounding box. Instead of a quad, the object-space\nbounding box of the object is drawn, with the impostor texture projected on it.\n",
      "content_length": 2675,
      "extraction_method": "Direct"
    },
    {
      "page_number": 472,
      "chapter": null,
      "content": "5.7 Impostors: Adding Clutter\n491\nFIGURE 5.7.1 Side view and rendered view of a billboard impostor showing Z-buffer\nproblems.\nBecause the bounding box is a real 3D object, its Z-buffer properties can be con-\ntrolled far better than those of a screen-aligned quad. In particular, its Z-buffer prop-\nerties are now independent of the camera position—they only depend on the object\nposition and orientatipn, which is one less thing the app has to worry about.\nBounding boxes actually work quite well. Most things in everyday life fill their\nbounding boxes nicely, and artifacts from intersections between bounding boxes are\nrare. Note that only the front or back of the bounding box is drawn. Either can be\nused, but I recommend the front, because many objects fill their bounding boxes, so\nusing the front side gives a parallax shift that is similar to the real object when the\ncamera moves.\nAlthough a bounding box is more complex than a quad, it's not much more com-\nplex—12 tris is not going to break the triangle budget now that typical scenes have\nhundreds of thousands of triangles. The increase in Z-buffering stability compared to\na single quad is definitely worth the effort.\nBounding Object\nThere are plenty of objects for which a bounding box is not a good enough approxi-\nmation, and using one leads to unnecessary Z-buffer clashes. Another factor to con-\nsider in choosing the shape of the impostor is parallax error. Most 3D scenes have a\nlarge number of elements that are stationary, but the camera will still be moving\nthrough that scene. A box painted with a picture of something on it is not going to\nlook like that something for long when the camera starts moving. Although increasing\n",
      "content_length": 1702,
      "extraction_method": "Direct"
    },
    {
      "page_number": 473,
      "chapter": null,
      "content": "492 \nSection 5 Graphics Display\nthe rate at which the impostor is updated can help, this just burns pixel and triangle\nrates far faster for not all that much benefit—the eye very quickly notices the lack of\nparallax as it moves.\nUsing an impostor object that is closer to the real shape of the object, although\nstill with a very low triangle count, can give a good improvement over a bounding\nbox. The main restriction on the shape is that it needs to fully enclose the object; oth-\nerwise, the impostor image may be bigger onscreen than the impostor object being\nused, and the edge of the image will not get drawn. The other restriction is that the\nobject must usually be convex to prevent self-sorting problems, because the impostor\ntexture is drawn with alpha blending.\nImage Warping\nOne of the problems with the impostor object is that it must be both convex and\nlarger than the thing it represents. The former is required to prevent pixels being ren-\ndered twice, and the latter to prevent some pixels not being rendered at all. However,\nthis inevitably means that the parallax as the object rotates (or the camera moves) is\nnot going to be correct, because the impostor object is bound to be larger than the\nimage it represents. Using a higher-tri impostor object can help reduce this in the case\nof entirely convex source objects. However, for nonconvex source objects, this does\nnot noticeably improve matters—the impostor object must remain convex, and no\namount of tris will allow it to match a concave object.\nAnother way to deal with this is to move the texture coordinates at each vertex\neach frame. The tri counts involved are fairly low, so a bit more work at each vertex is\nunlikely to hurt performance much. The principle is fairly simple—figure out where\non the real object (and thus the impostor texture image) each impostor objects vertex\nlies when viewed from a certain angle. As this viewing angle changes, the texel that the\nvertex lies over will change. Therefore, for a new viewing angle, trace the line from the\nviewer through the impostor object vertex to the original object. Then work out\nwhich texel this part of the object was originally drawn to, and set the UV coordinates\nof this vertex accordingly.\nNice Theory, What Can We Get Away With?\nThis is expensive and fiddly to implement. It also has loads of problem cases, such as\nthe vertex raytrace falling down a visually insignificant \"chasm\" in the object and,\nbecause of the low density of vertices in the impostor object, producing large warps\nover the image. Another problem is what to do with vertices at the edge of the impos-\ntor object that do not map to any part of the real object at all—what happens to\nthem? Some type of interpolation seems to be needed from the visible edges of the\nobject out to these vertices. This is the type of work that an app does not want to be\ndoing at runtime, however few vertices it involves.\nIn practice, what I have found to be far simpler, and works just fine, is to give each\nvertex a \"parallax factor\"—the number of image texels to move per degree of viewer\n",
      "content_length": 3089,
      "extraction_method": "Direct"
    },
    {
      "page_number": 474,
      "chapter": null,
      "content": "5.7 Impostors: Adding Clutter \n493\nmovement. This is a factor usually tweaked by hand, and easily determines the vertex's\ntexel coordinates at runtime. This factor is only done once for each impostor object\nvertex, and hand-tweaking around 8 to 10 vertices per object does not take long.\nAlternatively, to generate these parallax values automatically for most real-world\nobjects, find the nearest real-object vertex to each bounding object vertex. This dis-\ntance is then proportional to the parallax factor required. The actual value depends on\nexactly how the factor is applied to the UV values, which depends on how the texture\nis mapped to the impostor object. For more complex objects, such as highly irregular,\nspiky, holed, or multilayered objects, it may still be better to hand-tweak the factors.\nThis method finds the nearest vertex, but for these objects, it may be more appropri-\nate to use some sort of average instead.\nEven this simple method may not be possible because the objects are generated\ndynamically; for example, through animation. In this case, using a bounding cuboid\nand assuming an ellipsoid object inside works remarkably well for such a primitive\napproximation. It certainly works better than having no texture coordinate\nchanges at all.\nUpdate Heuristics\nOn each frame, for each impostor, the decision needs to be made whether to update it\nthat frame. A number of factors contribute to this decision. In all these cases, some\nsort of screen-space error estimate is made for each factor, and the factors summed. If\nthis sum is over a global factor (which may be static, object-specific in some way, or\ndynamic to try to maintain a certain frame rate), the impostor is updated.\nAnimation\nAnimation changes the appearance of the object, and at some point the error is going\nto grow too great. This can be quantified by a delta between the animation frame the\nimpostor was rendered with, and the animation frame that would have been used if\nthe object were not impostored. Doing this precisely requires the object to be ani-\nmated each frame, even if an update is not needed. This can be quite a large part of\nthe expense of rendering an object, and it is a good idea to try to avoid a complete ani-\nmation step. The easiest way I have found is to do a preprocessing step on each ani-\nmation and find the largest distance that any vertex moves during the animation.\nDivide by the length (in time) of the animation, and thus find a \"maximum error per\nsecond\" measure for the animation. This is easy to do in a brute-force way, and since\nit is a preprocessing step, this is perfectly reasonable.\nNote that the human eye is absolutely superb at extracting humanoid movement\nfrom images just a few pixels high. Impostoring this motion, effectively reducing its\neffective frame rate, can be surprisingly noticeable, even at very slight levels. It is a\ngood idea to have an extra bias on these animations that can place even more empha-\nsis on them than simple mathematical screen-space error. This effectively rules out\nimpostoring for anything but slight animations on distant objects.\n",
      "content_length": 3109,
      "extraction_method": "Direct"
    },
    {
      "page_number": 475,
      "chapter": null,
      "content": "494 \nSection 5 Graphics Display\nLighting\nIf the lighting changes significantly on the object, it will need to be updated. Since\nlighting systems are extremely varied between 3D engines, this requires fairly engine-\nspecific routines to decide what the equivalent screen-space error is. Lighting a point\nat the center of the object using the six cardinal normals and comparing RGB differ-\nences between the current conditions and those when the impostor was created gives\na fairly good idea of how the lighting has changed. Multiplying this by object size and\ndividing by the distance from the camera then gives a rough screen-space error.\nViewing Angle\nChanging the viewing angle is probably the most obvious factor that decides an\nimpostor update. Note that what is important is the vector from the camera to the\nobject in object space. This will change when the object rotates, and also when the\ncamera moves, both of which are important. The camera's direction of view is unim-\nportant—unless an enormous field of view is used, the object does not change appear-\nance much when the camera rotates, only when it moves.\nCamera Distance\nAs well as the direction from the object to the camera, the distance between the two is\nalso important. Although it does not change the actual appearance of the object, as\nthe camera moves directly toward the object, the impostor texture gradually enlarges.\nAfter a while, it becomes obvious that this is just an image that is being enlarged by\nbilinear filtering, and not a real polygonal object, and so needs updating. This update\nwill render to a larger texture, and so give more detail.\nGame-Specific Heuristics\nMany games also have specific heuristics that can be used to tweak these update rates.\nA common one for FPS games is that objects near the center of the view are usually\nthe ones the player is looking at. These should get a slight boost to their update rates\nby dropping the acceptable screen error.\nFor mouse-driven games such as god games and RTS games, a similar tweak can\nbe made to objects underneath the mouse cursor, for exactly the same reasons.\nA distinction can also be made between \"scenery\" and \"important\" objects. Items\nthat are purely in the scene to create an ambience, but are not usually involved in the\ngameplay, can be assigned a relatively large screen error. The player will not be exam-\nining them terribly closely—his or her attention is likely to be elsewhere. Therefore,\nthese objects can be \"more wrong\" before the player notices the error.\nEfficiency\nThe main efficiency hit on most cards is changing the render target. This causes flush-\ning of many internal caches and states, and on some cards causes a flush of the entire\n",
      "content_length": 2707,
      "extraction_method": "Direct"
    },
    {
      "page_number": 476,
      "chapter": null,
      "content": "5.7 Impostors: Adding Clutter \n495\nrendering pipeline. The main efficiency aim is to minimize these changes. The best\nway to do this is to wait until the end of the current scene, batching up the required\nupdates to the impostor textures, rather than doing them as they are needed. Use large\nrender targets, and at the end of the scene, pick the emptiest render target and render\nmultiple impostor images to subregions of that texture.\nPrediction\nWhen updating an impostor, the current state of the object is rendered to the texture.\nThis is then faded in over a few frames, and then preserved for a few frames more,\nbefore in turn being replaced by a newer render. This does mean that what is visible\nonscreen is always out of date.\nThis can be improved by doing some forward prediction of impostor state. The\nidea is to predict what the impostor is going to look like halfway through its lifetime.\nIf an object is currently being updated every sixth frame, when updating the impos-\ntor, the state of the impostor (orientation, position, lighting, animation, etc.) should\nbe forward-predicted by three frames.\nWith games such as first-person-shooters, objects in the world are basically split\ninto two distinct categories: those that almost never move (walls, furniture, clutter),\nand those that move erratically (players). The movement of the players is notoriously\nhard to predict, and it is probably a waste of time trying to impostor players.\nOn the other hand, impostoring the scenery and furniture is a far more viable\nproposition. Prediction for them is trivial—they almost never move. And when they\ndo move, they usually move under control of a player; in other words, erratically. The\neasiest thing is to simply disable impostoring for the duration of the movement.\nFor god games and Real-Time Strategy (RTS) games, the problems are similar, but\nthe movement of the camera is very different. It is usually a bird's-eye view, and most of\nthe time it is either static (while issuing orders to units), or moving at constant speed\nover the map to get to a different area. Small, erratic movements are rare, which is for-\ntunate since these are extremely hard to predict. Prediction of moving objects can also\nbe very useful in these games, since most of them are Al-controlled. Much of the time,\nthe objects are either stationary or walking in straight lines to a destination, both of\nwhich are easy to predict. However, both camera movement and object movement can\nchange abruptly, and when they do, the best thing is to flag the impostor for an update\nvery soon, or even to temporarily disable impostoring altogether.\nSummary\nImpostoring is useful when trying to draw scenes with lots of fairly static objects in\nthem. The raw triangle count will overwhelm any bus and graphics device that tries to\nrender them at top detail, and progressive mesh methods can only do a certain\namount to reduce the workload—texture changes and animation are extremely diffi-\ncult to reduce in this way.\n",
      "content_length": 2994,
      "extraction_method": "Direct"
    },
    {
      "page_number": 477,
      "chapter": null,
      "content": "Section 5 Graphics Display\nImpostoring is most effective on static objects some distance from the camera.\nIntroducing this sort of clutter into games increases the visual quality substantially,\nespecially since each object is still a real independent 3D object that players can inter-\nact with if they wish. It also allows key objects to be \"hidden in plain sight\" amongst\na lot of other objects—something that has been extremely difficult to do with existing\ntechniques and the limited number of objects available in a scene.\nEven an implementation using a bounding box and some simple math produces\ngood results for the incidental objects that are currently missing from games, but pro-\nduce far more realistic scenes.\n",
      "content_length": 721,
      "extraction_method": "Direct"
    },
    {
      "page_number": 478,
      "chapter": null,
      "content": "5.8\nOperations for Hardware-\nAccelerated Procedural\nTexture Animation\nGreg James, NVIDIA Corporation\ngjames@nvidia.com\nC\nonsumer-level 3D accelerators have come a long way in recent years. Today's\nmost advanced chips sample four textures per pass and offer powerful texture\naddressing and pixel processing operations. Among these are dependent texture reads,\nwhere the color value sampled from one texture is used to perturb the coordinates of\na subsequent texture read. Dependent texture reads combined with the ability to ren-\nder to a color buffer and use that buffer as a source texture in later rendering make it\npossible to generate interesting textures and texture animations entirely on the graph-\nics processor. With texel sampling rates close to one billion per second, these proce-\ndural texture effects run very fast and are practical for real-time 3D-accelerated scenes.\nTechniques for procedural texture generation have been with us from the early\ndays of computer graphics. There are various algorithms for mimicking natural phe-\nnomena and generating complex emergent patterns [Ebert98]. Procedural texture\nanimation is excellent for a wide range of effects while using a tiny fraction of the\nmemory and storage that a prerendered or \"canned\" animation would require. Mem-\nory to hold two or three full frames is often all that is required to generate an endless\nnon-repeating animation. User input can be applied to these animations on the fly,\nand this interactivity enables richer and more engaging virtual scenes.\nThis gem covers a few fundamental operations for generating procedural anima-\ntions, and puts these to use in specific examples that simulate fire, smoke, water,\nor perform image processing. With today's consumer hardware, we can even run com-\nplex cellular automata programs entirely within the rendering of a 3D accelerator and\nput the resulting animations to use in various effects.\nHardware Operations\nWe will focus on two rendering operations that give rise to interesting procedural tex-\nture effects. The first is four-sample texture sampling from adjacent texels of an\nimage, and the second is 2D dependent green-blue texture addressing. These opera-\ntions are supported in the two most common APIs: OpenGL and Microsoft's\n497\n",
      "content_length": 2269,
      "extraction_method": "Direct"
    },
    {
      "page_number": 479,
      "chapter": null,
      "content": "Section 5 Graphics Display\nDirectXS. For the four-way multisampling, we will use a vertex program that is\nloaded into the graphics processor and operates on the incoming vertex position and\ntexture coordinates. These vertex programs are DirectXS's \"Vertex Shaders\" [DXS'OO]\nand what is currently the NVIDIA NV_vertex_program extension to OpenGL\n[NVExt2001]. For our examples, this vertex program establishes the appropriate\ncoordinates for neighbor texel sampling in each of the four texture stages that feed the\npixel engine. This pixel engine will combine the samples for various effects, and can\nalso further manipulate the samples with the dependent texture addressing opera-\ntions. The pixel engine is also programmable as exposed through DirectX 8's \"Pixel\nShader\" programs and NVIDIA's NV_texture_shader extension. First, we examine the\nvertex processing operations.\nNeighbor Sampling for Blur, Convolution, and Physics\nMany procedural texture algorithms rely on sampling a texel's neighbors and filtering\nor blurring these samples to create a new color value. We can accomplish this neigh-\nbor sampling for all the texels of a source texture by rendering it into a color buffer of\nthe same resolution as the texture while using four-texture multisampling. The source\ntexture is selected into all texturing units, and a vertex program generates four sets of\nindependent texture coordinates, each offset by the distance to one of the texels\nneighbors. By rendering a single quad with texture coordinates from 0.0 to 1.0, which\nexactly covers the render target, and setting each texture coordinate offset to zero,\neach texel of the destination would sample from its single source texel four times. We\nwould end up with an exact copy of the source texture. By offsetting each texture\ncoordinate by a vector to a neighboring texel, each pixel of the destination samples\nfrom four of its neighbors in the source. We can convolve the samples (combine them\nwith various scale factors) in the pixel engine however we like.\nIf we use point sampling, four-sample multitexturing hardware gives us up to\nfour neighbor samples per pass. If we enable bilinear filtering, each offset sample\ndraws upon four texels, so we could potentially sample 16 neighbors per pass. The\nweighting of texels within each 2x2 bilinear sample is determined by the precise tex-\nture coordinate placement. For example, we could grab and average all eight of a\ntexels nearest neighbors by placing four bilinear samples exactly between pairs of\nneighboring texels. Figure 5.8.1b shows this, and Listing 5.8.1 presents code for\nneighbor sampling on four-sample multitexturing hardware. The 'X' of Figure 5.8.1\ndenotes the texel being rendered to the destination, and the dots indicate the sample\nlocations from the source texture used to render it. We can select between various sets\nof sample locations (A or B in this case) by using the vertex shader indexing variable\naO. x. The value of the indexing variable is loaded from a shader constant value that is\nset before rendering.\n",
      "content_length": 3051,
      "extraction_method": "Direct"
    },
    {
      "page_number": 480,
      "chapter": null,
      "content": "5.8 Operations for Hardware-Accelerated Procedural Texture Animation\n499\nOffsets A\nOffsets B\nFIGURE 5.8.1 Texel sampling for the code of Listing 5.8.1, showing the sample pattern\nwhen the texel marked by the X is being rendered. The vertex program's texture\ncoordinates as iterated in each texture unit T[0-3] are marked with dots. The hollow\ncircle marks where a sample of texture coordinate offiet (0.0, 0.0) would fall, illustrating\nthe need for the s_of f and t_of f half-texel offiets. Each texel is of dimension (si, tl)\naccording to Listing 5.8.1.\nListing 5.8.1. Code and vertex program for sampling each texel's\nneighbors\nRenderFullCoverageQuadO renders a single quad with input texture coordinates\nfrom 0.0 to 1.0 in each axis, which exactly covers the render target. These coordinates\nare offset four ways into the four output oT[0-3] texture coordinates so that as each\npixel is rendered, it draws upon neighboring texels for its result. All-caps variables are\n#defines to appropriate indices into vertex shader constant memory.\nfloat s1 = 1.0f / texture_resolution_x; // one texel width\nfloat t1 = 1.0f / texture_resolution_y; // one texel height\nfloat s_off = s1 / 2.Of; \n/ / t o sample texel center\nfloat t_off = t1 / 2.Of;\n// s,t,r,q offsets for 4 nearest neighbors (bilinear or point)\nfloat offset_al[4] = { -si + s_off, O.Of + t_off, O.Of,\nO.Of};\nfloat offset_a2[4] = { s1 + s_off, O.Of + t off, O.Of,\nO.Of};\nfloat offset_a3[4] = { O.Of + s_off, t1 \n+ t off, O.Of,\nO.Of};\nfloat offset_a4[4] = { O.Of + s_off, -t1 \n+ t_off, O.Of,\nO.Of};\n// s,t,r,q offsets for 8 surrounding neighbors (use bilinear)\nfloat offset_bl[4] = { s1/2.0f + s_off, tl \n+ t_off, O.Of,\nO.Of};\nfloat offset_b2[4] = { -s1 \n+ s_off, t1/2.0f + t_off, O.Of,\nO.Of};\nfloat offset_b3[4] = { -s1/2.0f + s_off, -t1 \n+ t_off, O.Of,\nO.Of};\n",
      "content_length": 1816,
      "extraction_method": "Direct"
    },
    {
      "page_number": 481,
      "chapter": null,
      "content": "500 \nSection 5 Graphics Display\nfloat offset_b4[4] = { s1 \n+ s_off, -tl/2.0f + t_off, O.Of,\nO.Of};\nSetVShaderConstants((TO_BASE .. T3_BASE) + SET_A, offset_a1 ..\noffset_a4);\nSetVShaderConstants((TO_BASE .. T3_BASE) + SET_B, offset_b1 ..\noffset_b4);\nSetVShaderConstants( OFFSET_TO_USE, use_a ? SET_A : SET_B );\nRenderFullCoverageQuad();\nVertex Program\n; vO = vertex position\n; v1 = vertex texture coordinate\n; Transform vertex position to clip space. \n4-vec * 4x4-matrix\ndp4 OPOS.X, vO, C[ WORLDVIEWPROJJ) ]\ndp4 oPos.y, vO, C[ WORLDVIEWPROJ_1 j\ndp4 OPos.z, VO, C[ WORLDVIEWPROJ_2 ]\ndp4 OPOS.W, vO, C[ WORLDVIEWPROJ_3 ]\n; Read which set of offsets to use - set A or B\nmov aO.x, c[OFFSET_TO_USE ].x\n; Write S,T,R,Q coordinates to all four texture stages, offsetting\n; \neach by either offset_a(1-4) or offset_b(1-4)\nadd oTO, v1, c[ aO.x + TO_BASE ]\nadd oT1, v1, c[ aO.x + T1_BASE ]\nadd oT2, vl, c[ aO.x + T2_BASE ]\nadd oT3, v1, c[ aO.x + T3_BASE ]\nIt is important to note that for this case of rendering a full coverage quad to a\nbuffer with the same resolution as the source texture, a texture coordinate offset of\n(0,0) would sample from the upper left (lowest coordinate point) of each texel. To\nsample from the exact texel center, we must either add half a texel width and height to\nthe offset or move the quad by half a pixel in each axis. Listing 5.8.1 chooses to add\nhalf a texel width and height. It is essential to understand these half-texel offsets when\nusing bilinear filtering. Without this, the bilinear sample will grab potentially unde-\nsired neighbors and produce very different results. It is essential to test and know\nexactly where texture samples are placed for procedural texture algorithms to work as\nexpected. Conway's \"Game of Life\" described later in this gem makes a good test case.\nThe four resulting texture samples can be combined in the programmable pixel\nengine for various effects. By using the resulting image as a new source texture and\napplying the neighbor sampling again and again to create subsequent frames, a wide\nvariety of interesting texture animations is possible. If the four samples are averaged,\nthe result is a blurring of the source image. By introducing an additional (s,t) scrolling\namount to the offsets presented previously, we can blur and scroll a source image over\nsuccessive frames. As we blur and scroll, we can jitter the scrolling vector used in each\nframe and multiply each sample color by various RGBA values to fade or alter the\ncolor. If we supply a steady input to the blur and upward scroll by first rendering\n",
      "content_length": 2573,
      "extraction_method": "Direct"
    },
    {
      "page_number": 482,
      "chapter": null,
      "content": "5.8 \nOperations for Hardware-Accelerated Procedural Texture Animation\n501\nA.\nTexture 1\nSource \"Embers\"\nblur + scroll \nblur + scroll\nTexture 2\nB.\nFIGURE 5.8.2 Fire and smoke animation using Listing 5.8.1 s offiets A with a scroll offset. The bright\n\"embers\" at the bottom are rendered to the texture each frame before blurring and scrolling upward.\nB) shows the progression of rendering operations.\nbright source pixels or \"embers\" in the bottom of the texture for each frame, the result\nis the fire and smoke effect of Figure 5.8.2. Using just two 128x128 32-bit textures,\nthis effect runs endlessly without repetition at over 500 frames per second on a mod-\nern graphics card. Because we cannot simultaneously render to a texture and use it as\na source, we must use two textures and ping-pong back and forth between them. One\nis used as the previous frame source, and the other as the current frame destination.\nRather than averaging neighbor samples to blur, we can compute the differences\nbetween samples and raise this to a power for high contrast. Using Listing 5.8.1's off-\nsets A and reducing the magnitude of the offsets to partially sample the center texel,\nwe can perform edge detection in a hardware pixel shader program, as implemented\nby Matthias Wloka [Wloka2000] and shown in Figure 5.8.3. Another curious\n\"frosted glass\" effect is produced by blurring the source and differencing this blur\nfrom the original image. Figure 5.8.3d shows the result of ( src DIFF ( src DIFF(\nBLUR(src))), where DIFF is the absolute value of the difference in RGB color.\nNeighbor sampling and differencing can also be used to implement the physics of\nheight-field-based water in successive render-to-texture operations. An algorithm for\nheight-field water with vertex geometry on the CPU is presented in Game Program-\nming Gems [GomezOO]. We can develop this into a series of rendering operations that\nuse textures to represent the water height, velocity, and force. Each texel takes the\nplace of a vertex in Gomez's implementation. Instead of sampling neighboring ver-\ntices on the CPU, we sample neighboring texels on the graphics processor. Our imple-\nmentation involves six textures. Two textures represent the height of the water as\n",
      "content_length": 2233,
      "extraction_method": "Direct"
    },
    {
      "page_number": 483,
      "chapter": null,
      "content": "502\nSection 5 Graphics Display\na.\nc.\nFIGURE 5.8.3 Edge detection and image processing. A) is the original image. B) is the\nresult of an edge detection in programmable pixel hardware. C) shows a 50-percent blend\nof a and b. D) is the original minus the difference between the original and a blur of the\noriginal.\ngrayscale color values (height maps), with one texture for the heights at the current\ntime step and one for the heights at the previous time step. Similarly, two textures rep-\nresent the velocity of the water, and two are used to accumulate the nearest-neighbor\nforces acting on each texel. Figure 5.8.4 shows four frames in the progression of an\nanimation using this technique, and despite the use of six 256x256 32-bit textures\nand four rendering passes per time step, the animation maintains a rate of over 450\nFIGURE 5.8.4 Initial condition and three frames of height-based water animation in the pixel\nprocessing of a 3D accelerator. Six textures are used in generating subsequent time steps, although only\nthe output height texture is shown here.\n",
      "content_length": 1065,
      "extraction_method": "Direct"
    },
    {
      "page_number": 484,
      "chapter": null,
      "content": "5.8 Operations for Hardware-Accelerated Procedural Texture Animation\n503\nFIGURE 5.8.5 Six state textures used for height-based water animation. Hm is height for the most\nrecent time step. Fl and F2 are used to accumulate the force that will act on each texel height. The\nresulting F2 is applied to the previous time step's velocity V^.;, and the resulting velocity Vm is\napplied to the height to create the height field at the next time step //w+/. Scale factors for \"mass\" and\n\"time\" that are multiplied into the texel values are not shown.\ntime steps per second. Figure 5.8.5 shows the progression of textures used in generat-\ning one time step.\nThe hardware used for this example operates internally on 9-bit per component\nsigned color values, and this gives rise to inaccuracy. Low bit values are easily lost, pro-\nducing rounding errors in the physics that cause the system to decay to zero or grow\nto saturation. The nearest-neighbor sampling can also produce high-frequency oscil-\nlation between texel values that appears as noise. These problems are lessened by\ndamping the system with blurring and adding a restoring force that pulls all heights\ngently to a midrange value. The blurring is accomplished by using bilinear filtering\nwith neighbor offsets slightly greater than one texel width or height. The system can\nbe driven by occasionally rendering seed droplets to the texture at random locations.\nBy experimenting with the scale factors at which blurring, force, and velocity are\napplied, a stable endless animation is not difficult to achieve.\nAnimated grayscale height maps are useful, but we can go a step farther and use\nnearest-neighbor sampling to create an RGB normal map from the grayscale map.\nThis normal map can then be used for realistic dot product bump mapping\n[Moller99]. The normal map can be created in a single render-to-texture pass on the\ngraphics processor, and this avoids costly CPU work, texture memory copies, and\ngraphics pipeline stalls. Creating normal maps in hardware this way is an elegant\nmeans of updating and animating the surface detail they represent. Grayscale height\nfeatures such as bullet holes, cracks, and so forth can be rendered into the height map\n",
      "content_length": 2208,
      "extraction_method": "Direct"
    },
    {
      "page_number": 485,
      "chapter": null,
      "content": "504 \nSection 5 Graphics Display\nas the game is running, and this is then converted to a normal map on the fly. The\nconversion is comparable in speed to the fire and smoke effect discussed earlier. List-\ning 5.8.2 shows a pixel program for creating an RGB normal map from a grayscale\nheight map in a single pass on four-sample multitexture hardware. It uses an approxi-\nmation in normalizing the resulting RGB texels, and the result works very well for\nlighting and reflection calculations. Two passes and a dependent texture read opera-\ntion could be used to produce exactly normalized RGB vectors.\nUse texel offsets A from Listing 1.\nListing 5.8.2 Code for RGB normal map creation in hardware from a\ngrayscale height texture. The grayscale image is\nselected into all four texture stages, and offsets A from\nListing 5.8.1 are used.\nPixel Program;\n// Creates an RGB normal map from an input grayscale height map\n// Pairing of RGB and Alpha instructions is not used\n// \nNormal map parameterization is [0,1] so 0.5 = zero component\n// \nalong that axis (value of 127 stored in the texture).\n// \nRed \n= positive S axis\n// \nGreen = positive T axis\n// \nBlue = positive R axis (up out of page)\n// Declare pixel shader version\nps.1.1\ndef c5, 1.0, 0.0, 0.0, 1.0 \n// red mask for s axis component\ndef c6, 0.0, 1.0, 0.0, 1.0 \n// green mask for t axis component\ndef c4, 0.0, 0.0, 1.0, 1.0 \n// blue mask for r axis component\n// (blue = up out of texture)\ndef c2, 0.5, 0.5, 0.0, 0.0 \n// 0.5 bias for red & green\ndef c1, 1.0, 1.0, 0.0, 0.0 \n// color mask for red & green\nget colors from all 4 texture stages\nto = -s, 0\nt1 = +s, 0\nt2 = 0, +t\nt3 = 0, -t\n// Select source grayscale texture into all 4 texture stages\n// Sample all 4 texture stages\ntex to \n// to = RGBA texel at coordinate offset by\n// \n(-s, 0)\ntex t1 \n// t1 = (+s, 0)\ntex t2 \n// t2 = ( 0,+t)\ntex t3 \n// t3 = ( 0,-t)\n",
      "content_length": 1863,
      "extraction_method": "Direct"
    },
    {
      "page_number": 486,
      "chapter": null,
      "content": "5.8 Operations for Hardware-Accelerated Procedural Texture Animation \n505\nsub_x4 rO, to, t1 \n// rO = (tO-t1)*4 = s axis height slope\n// Use _x4 to increase low contrast grayscale\n// input\nmul \nto, rO, c5 \n// to = rO * red mask = red component only\n// Use to as temp storage\nsub_x4 M, t3, t2 \n// r-1 = (t3-t2)*4 = t axis height slope\nmad \nrO, r-1, c6, to \n// rO = M.green + to = s and t result in\nred,green\nmul \nt1, rO, rO \n// t1 = square s and t components\n// Use t1 as temporary storage\ndp3_d2 n, 1-tl, c1 \n// rl.rgb = (1 - s\"2 + 1 - tA2 )/2\n// (1-s\"2) is approx sqrt(1-s*2) for small s\nadd rO, rO, c2 \n// rO = rO + 0.5 red + 0 . 5 green\n// shifts signed values to [0,1]\nmad rO, M, c4, rO \n// RGB = (r+0, g+0, 0+blue )\n// output = rO\nDependent Texture Addressing\nWe have seen that a simple multisample operation can go a long way to produce var-\nious effects. There are other more sophisticated and powerful texture operations at\nour disposal. Dependent texture address operations enable us to fetch texture samples\nfrom one texture based on the colors of another texture, or to fetch based on the dot\nproducts of iterated texture coordinates and texture colors. This gem covers only\none of the more simple dependent texture operations: the dependent green-blue\ntexture addressing operation expressed as DXS's texreg2gb instruction, or the\nGL_DEPENDENT_GB_TEXTURE_2D_NV extension to OpenGL.\nDependent green-blue addressing is a straightforward process. For the pixel being\nrendered, the hardware fetches the source texture's color at that pixel. The green com-\nponent of this color is used as the S (horizontal) coordinate of a fetch into another\ntexture. The blue component is used as the T (vertical) coordinate. Figure 5.8.6 illus-\ntrates this with a 3x3 source texture.\nTexture 2 can have any size relative to Texture 1; however, if Texture 1 holds 8-bit\ngreen and blue values, then any resolution of Texture 2 greater than 256 is pointless,\nas the fine resolution cannot be accessed by the coarse 8-bit values. Texture 2 provides\nan arbitrary lookup table for the Texture 1 input, and this can be used with render-to-\ntexture operations to run some very sophisticated programs entirely within in the\npixel hardware. We'll refer to Texture 1 as the \"input\" texture, and Texture 2 as the\n\"rules\" texture, because Texture 2 determines how an input color maps to a result.\nWith render-to-texture operations, we can use one or several texture maps to\nstore intermediate logic results. We can also generate the input and rules maps on the\nfly based on previous results or user input. As you can imagine, there's quite a lot of\nflexibility here, and we haven't even considered dependent alpha-red lookups or the\ndot product address operations! Since the green-blue addressing operation relies on\n",
      "content_length": 2795,
      "extraction_method": "Direct"
    },
    {
      "page_number": 487,
      "chapter": null,
      "content": "506\nSection 5 Graphics Display\nG-B Addressing\nTexture 1 \nTexture 2 \nResult\nFIGURE 5.8.6 Dependent green-blue texture addressing. The Texture 1 source is sampled\nat the points indicated. Each texel of Texture 1 determines the coordinate at which to\nsample from Texture 2, the \"rules\" texture. The resulting color from Texture 2 is output as\nthe result.\nspecific texture colors that are probably not the best colors for displaying in a scene, it\nis a good idea (and trivial) to add a second dependent lookup into a color table. This\nsecond operation maps the results of the procedural texture to any RGBA values for\ndisplay in the scene. It creates a final output texture, so the user never sees the under-\nlying green-blue textures driving the calculations. Our final example involves com-\nbining neighbor sampling and dependent lookups to run Conway's \"Game of Life\"\non a graphics processor.\nConway's \"Game of Life\" in Hardware\nJohn Conway's \"Game of Life\" [Gardner70] is a popular cellular automata program.\nThough it does not at first seem relevant or of much use to the average computer\ngame, it is familiar territory in which to work, and the basic operations of running the\ngame on a graphics chip are applicable to other procedural techniques. The game can\nproduce interesting patterns of correlated noise that are useful in driving other effects;\nfor example, the embers in the fire and smoke effect shown previously. Implementing\nthis game on your own platform is a good way to verify that the hardware is doing\nexactly what you expect. The game has easily recognizable cyclical patterns and\ndepends sensitively on proper texel sample placement, making it easy to determine\nwhen you have your sampling correct.\nIn Conway's \"Game of Life,\" each cell begins as either \"on\" or \"off,\" which we\nrepresent by a texture map of white or black texels, respectively. The rules for creating\nthe next generation are, for every cell on the map:\n",
      "content_length": 1940,
      "extraction_method": "Direct"
    },
    {
      "page_number": 488,
      "chapter": null,
      "content": "5.8 Operations for Hardware-Accelerated Procedural Texture Animation\n507\n1. If a cell is on and has two or three neighbors on, the cell remains on in the\nnext generation.\n2. If a cell is on and has fewer than two or greater than three neighbors on, the\ncell is turned off in the next generation.\n3. If a cell is off and has three neighbors on, the cell is turned on in the next\ngeneration.\nThe game requires that we sample eight neighbors and the center cell, and apply\nlogic to the result of the sampling. The OpenGL \"Red Book\" [Neider93] outlines a\ntechnique for running the game using a hardware stencil buffer, but we can imple-\nment it in a more flexible manner using fewer passes with hardware capable of depen-\ndent texture addressing.\nOur approach is to create a render target color buffer of the same resolution as the\nfield of cells. Beginning with black at each texel of this buffer, we render colors addi-\ntively from the source cell field for each of the eight neighbor texels and the center\ntexel. Each neighbor texel of the source is multiplied by 1/8 green and added to the\ndestination, and the center texel is multiplied by full blue and added in. In practice,\nwe use bilinear sampling and the B offsets of Listing 5.8.1 to sample two neighbors at\nonce, and multiply the sample by 1/4 green. A second pass samples, the center texel\nmultiplied by blue. The result is a color that encodes the condition of each source\ntexel in relation to the rules of the game. Each cell's neighbor count ranges from 0 to\nGreen channel\nneighbor count\nDependent green-blue\naddress operation\n(1,1)\nd. Rules map \ne\nFIGURE 5.8.7 Steps in the production of the next generation of cells in Conways \"Game of Life. \"A) is\nthe initial cell field. B) is the green component of the condition texture that is each 'cell's number of\nactive neighbors. C) is the blue component of the condition that reflects whether the cell is on or off.\nD) is an 8x2 pixel texture that encodes the rules of the game. E) is the resulting generation of cells\nthat will be used again as the new input a.\n",
      "content_length": 2071,
      "extraction_method": "Direct"
    },
    {
      "page_number": 489,
      "chapter": null,
      "content": "508 \nSections Graphics Display\n1.0 in green, and the cell's \"on\" or \"off\" state is 0 or 1 in blue. Each green-blue texel is\nthen used as the input for a dependent green-blue address operation. The operation\nreads from an 8x2 pixel rules texture that determines the color (white or black) of the\ntexel in the next generation. This rules texture is black at all texels except those at\n(2,1), (3,1), and (3,0), which are white. These white pixels are those that the rules of\nthe game determine to be \"on\" in the next generation. Figure 5.8.7 shows an initial\ngeneration source texture, the green-blue condition rendered from it, the rules tex-\nture, and the subsequent generation produced.\nThis simulation depends on the source texels being white and the intermediate\nbeing green-blue. We could easily perform an additional dependent texture read from\nthe source or intermediate into an arbitrary color ramp to create a separate texture for\nuse in rendering the scene. Also, there is no need to limit the rules texture to 8x2 pix-\nels. Any size texture could be loaded, and this texture could encode highly complex\nrules, or rules that spawn pixels of any RGB value. See the online examples and source\ncode mentioned below for a glimpse of the possibilities.\nFuture Work\nAs graphics processors draw more texture samples per rendering pass, the 8-bit color\ncomponents and internal pixel processing operations of today's hardware are squeezed\nfor precision. It is all too easy to end up with color banding or other rendering arti-\nfacts. Future generations of hardware will almost certainly need higher precision for-\nmats, and with 16 or 32 bits per color component, there are great opportunities for\nhardware-accelerated procedural texture effects.\nProblems of limited precision were mentioned earlier in the water simulation. 16-\nbit floating point values would virtually eliminate these. Higher precision floating-\npoint values in textures and pixel calculations could enable fluid flow simulations and\nlattice grid-based Navier-Stokes algorithms to run in graphics hardware [Witting99].\nCPU implementations of these algorithms are already close to real time in special\neffects houses and graphics research. Increased precision of render target buffers will\nalso enable hardware-accelerated advanced lighting calculations that involve simple\nFresnel integrals, wave propagation, and diffraction effects [Feynman85][Stam99].\nCellular automata programs give rise to a wealth of interesting animations and\nrjatterns with various degrees of correlation. Cellular automata programs do have the\ndisadvantage of being difficult to control and engineer to a specific pattern or effect,\nbut collections of discovered programs and convenient browsing programs exist on\nthe Internet. Work on lattice gas automata (generally 2D surface simulations) may\nalso provide useful animated patterns.\nThe future of real-time procedural texturing and animation is filled with promise.\nThere is a vast landscape of techniques and effects to explore, and these certainly have\nthe power to bring added realism and variety to interactive 3D games.\n",
      "content_length": 3121,
      "extraction_method": "Direct"
    },
    {
      "page_number": 490,
      "chapter": null,
      "content": "5.8 Operations for Hardware-Accelerated Procedural Texture Animation \n509\nAcknowledgments\nSpecial thanks to Matthias Wloka for his work on multisampling and hardware image\nconvolution, and to my co-workers at Nvidia for inspiring and enabling such amazing\ngraphics hardware.\nCode Samples\nDirectX 8 code for the preceding examples is posted on Nvidia's public Developer\nWeb site (www.nvidia.com/Developer/DX8) for you to download and experiment\nwith. The samples can be run in the DX8 SDK's reference rasterizer or on hardware\nthat supports DX8 Vertex Shaders vl.l and Pixel Shaders vl.l.\nReferences \n_\n[Ebert98] Ebert, David S., et al, Texturing and Modeling: A Procedural Approach, Aca-\ndemic Press, 1998 [ISBN 0-12-228739-4].\n[DXS'OO] Microsoft Corporation, DirectXS SDK, available online at http://msdn\n.microsoft.com/directx/, November, 2000.\n[NVExt2001] Nvidia Corporation, \"Nvidia OpenGL Extensions Specifications\"\n(nvOpenGLSpecs.pdf). available online at www.nvidia.com/opengl/OpenGLSpecs,\nMarch 2001.\n[Wloka2000] Wloka, Matthias, \"Filter Blitting,\" available online at www.nvidia.com\\\nDeveloper/DX8, November 2000.\n[Gomez2000] Gomez, Miguel, \"Interactive Simulation of Water Surfaces,\" Game\nProgramming Gems, Charles River Media Inc., 2000: pp. 187-194.\n[Moller99] Moller, Tomas, and Haines, Eric, Real-Time Rendering, A K Peters, Ltd.,\n1999.\n[Gardner70] Gardner, Martin, \"Mathematical Games,\" Scientific American, vol. 223,\nno. 4, October 1970, pp. 120-123.\n[Neider93] Neider, Jackie, et al, OpenGL Programming Guide, Addison-Wesley Pub-\nlishing Co., 1993: pp. 407^409.\n[Witting99] Witting, Patrick, \"Computational Fluid Dynamics in a Traditional Ani-\nmation Environment,\" Computer Graphics Proceedings (SIGGRAPH 1999) pp.\n129-136.\n[Feynman85] Feynamn, Richard P., QED: The Strange Theory of Light and Matter,\nPrinceton University Press, 1985, pp. 37-76. Although he does not label it a\n\"Fresnel integral,\" this is the name for the calculation he explains in Chapter 2.\nThis powerful mathematics accounts for all phenomena in the propagation of\nlight by a large sum of a few simple terms.\n[Stam99] Stam, Joe, \"Diffraction Shaders,\" Computer Graphics Proceedings (SIG-\nGRAPH 1999) pp. 101-110.\nGomez, Miguel, \"Implicit Euler Integration for Numerical Stability,\" Game Program-\nming Gems, Charles River Media Inc., 2000: pp. 117-181.\n",
      "content_length": 2341,
      "extraction_method": "Direct"
    },
    {
      "page_number": 491,
      "chapter": null,
      "content": "6.1\nBridge\nGame Audio Design Patterns\nScott Patterson\nscottp@tonebyte.com\nD\nesign pattern concepts have achieved great popularity in recent years. Really,\ndesign patterns have been in use for a long time, and recently we have been get-\nting better at categorizing and identifying them. Object-oriented programming lan-\nguages are commonly associated with design pattern implementations, but even\nprogramming languages that are not identified as object oriented can provide effective\nobject pattern implementations. Design patterns can also serve as an inspiration when\nbuilding a code system. In this gem, we will use them as an inspiration for an audio\ninterface design. This discussion assumes that we are audio interface designers and\nour clients are game programmers. We want to supply an audio interface to our\nclients that is convenient, flexible, and powerful. We will present brief summaries of\nsome design patterns and how we can relate them to audio interface design.\n\"Decouple an abstraction from its implementation so that the two can vary\nindependently.\"\nSound Identifiers\nAn effective way of decoupling an abstraction from its implementation is to pass iden-\ntifiers rather than things such as class pointers or references. Identifiers can be defined\nas numbers or strings. Since we are talking about audio, we are talking about an iden-\ntifier for each particular sound. We can start and stop a sound by passing its identifier.\nHow the audio system actually does the work to start and stop the sound is com-\npletely decoupled from the client of our API.\nvoid StartSound( int nSoundld );\nvoid StopSound( int nSoundld );\nAlso hidden is the way in which sounds are loaded and accessed. We can provide\nsimilar calls to load and unload a particular sound.\nvoid LoadSound( int nSoundld );\nvoid UnloadSound( int nSoundld );\n514\n",
      "content_length": 1836,
      "extraction_method": "Direct"
    },
    {
      "page_number": 492,
      "chapter": null,
      "content": "6.1 Game Audio Design Patterns \n515\nPerhaps more useful is yet another identifier system for collections of sounds.\nNow we can load and unload many sounds at a time.\nvoid LoadSoundCollectionf int nSoundCollectionld );\nvoid UnloadSoundCollection( int nSoundCollectionld );\nIt may be useful to know if a sound is currently loaded,\nbool IsSoundLoaded( int nSoundld );\nIf we try to start a sound that is not loaded, the response could be to play no\nsound or play an error sound.\nFacade\n\"Provide a unified interface to a set of interfaces in a subsystem. Facade defines a\nhigher-level interface that makes the subsystem easier to use.\"\nSubsystem Control\nWhen writing an audio API for game programmers to use, the goal is to hide any\ntedious complexity of the audio system and cover the needs of all parts of the game.\nWriting an API with this type of goal is much like designing a class with the Facade\ndesign pattern. The complexity of the audio system is hidden from the complexity of\nthe game code, and the connection between the two systems is our API.\nWe may have more than one method available to produce sounds, but having the\nsame interface to control these sounds makes the audio subsystem easier to use. Calls\nto set and get master volume may look simple enough, but actually may update more\nthan one audio subsystem internally.\nfloat SetMasterVolume( float fVolume );\nfloat GetMasterVolumeO;\nAudio subsystems related to hardware synthesis, software synthesis, and stream-\ning code may all be updated from calls such as these, but this complexity is hidden.\nSimilar complexity may be hidden in a call that stops all sounds currently playing.\nvoid StopAllSounds();\nComposite\n\"Compose objects into tree structures to represent part-whole hierarchies. Composite\nlets clients treat individual objects and compositions of objects uniformly.\"\nEngine Control\nSomething like a car engine may actually be composed of many different sounds.\nThere may be rumbles, whines, clanks, and sputters all happening in concert. The\n",
      "content_length": 2017,
      "extraction_method": "Direct"
    },
    {
      "page_number": 493,
      "chapter": null,
      "content": "516 \nSections Audio Programming\nvolume and pitch and other parameters of these sounds may be mapped to various\ngame parameters such as engine type, throttle level, power level, current speed, and\nmany others. In this case, we may want to hide this complexity and provide functions\nspecific to the type of engine we are controlling.\nvoid StartEngine( Carlnstance_t *pObject );\nvoid UpdateEngine( Carlnstance_t *pObject );\nvoid StopEnginef Carlnstance_t *pObject );\nNow the internal audio code can interpret the states and parameters available in\nthe given Carlnstance_t object and translate them into the control of one or more\nsounds. Our client is able to treat engine control the same way, whether we are con-\ntrolling an individual sound object or compositions of sound objects.\nAmbience Control\nControl of ambient sounds can also be a situation that exhibits composite behavior. If\nwe want to simulate an environment such as a jungle, we may be randomly playing\nmany animal sounds. In this case, we may not have a structure in the game called\nJungle_t, but we may know our distance from the jungle area and how excited the ani-\nmals are.\nvoid Start Jungle ( float f Distance, float f Activity );\nvoid UpdateJungle( float f Distance, float f Activity );\nvoid StopJungle() ;\n\"Provide a surrogate or placeholder for another object to control access to it.\"\nHandles\nHandles provide just such a placeholder for another object to control access through.\nWhen we start a particular instance of a sound, we may want to continue to control\nthat instance over time. Our control parameters may be anything from 3D position\ninformation to direct control over things such as volume, pitch, pan, or effects. Our\nstart function returns a handle, and our update and stop functions use this handle to\naccess the sound instance.\nHandle_t StartHandledSound( int nSoundld, const ControlParamsjt &cp) ;\nvoid UpdateHandledSound( Handle_t hSound, const ControlParams_t &cp) ;\nvoid StopHandledSound( Handle_t hSound );\nA discussion on handles can be found in [BilasOO] .\n",
      "content_length": 2051,
      "extraction_method": "Direct"
    },
    {
      "page_number": 494,
      "chapter": null,
      "content": "6.1 Game Audio Design Patterns \n517\nDecorator\n\"Attach additional responsibilities to an object dynamically. Decorators provide a flex-\nible alternative to subclassing for extending functionality.\"\nUser Data\nOne way to allow dynamic responsibilities and associations to be given to an object is\nto provide user data access. If we provide a user data field that clients can set per\ninstance of a sound, we can help clients link other responsibilities with sound\ninstances. We can add user data access functions to our handled sound interface.\nvoid SetHandledSoundUserData( Handle_t hSound, UserData_t User-Data );\nUserData_t GetHandledSoundUserData( Handle_t hSound );\nCallbacks\nWe can also provide a callback field that clients can set per instance of a sound. This\ncallback could be defined to be triggered when a sound loops or has played for a cer-\ntain amount of time.\nvoid SetHandledSoundCallback( Handle_t hSound, CallbackFuncPtr_t pCB );\nvoid ClearHandledSoundCallback( Handle_t hSound );\nCommand\n\"Encapsulate a request as an object, thereby letting you parameterize clients with dif-\nferent requests, queue or log requests, and support undoable operations.\"\nCommand Queues\nWe can put some or all calls to our audio API in a command queue that is processed\nonce per game frame. We could look through this queue to determine if the same\nsound is being called more than once per frame, or whether a sound has been started\nand stopped before it had a chance to play. Viewing this queue can provide an impor-\ntant aid during debugging.\nSpeech Systems\nA speech system benefits from command queuing. Since more than one character\nmay want to talk at one time, we can look through the queue of requests to determine\nwho should speak next. There may also be times when we want to stop any further\nspeaking so we clear the queue.\nvoid PostSpeechRequest( int nSpeakerld, int nPhrase );\nvoid ClearSpeechQueue();\n",
      "content_length": 1907,
      "extraction_method": "Direct"
    },
    {
      "page_number": 495,
      "chapter": null,
      "content": "518 \nSections Audio Programming\nMemento\n\"Without violating encapsulation, capture and externalize an object's internal state so\nthat the object can be restored to this state later.\"\nPause and Restart\nWhen we want to pause all sounds, we could return a handle to a state that can be\nused to restart those sounds later.\nStateHandle_t PauseAllSounds();\nvoid RestartAllSounds( StateHandle_t hState );\nObserver\n\"Define a one-to-many dependency between objects so that when one object changes\nstate, all its dependents are notified and updated automatically.\"\nDynamic Types\nIf we can pass a type number to a sound that we are starting, we could later reference\nthat sound and any others that have been given the same type. For example, if we start\nall the sounds for a particular character with the same type number, then we can later\nturn off those sounds with one call.\nvoid StartSoundWithTypef int nSoundld, int nTypeld );\nvoid StopAllSoundsWithType( int nTypeld );\nWe can also update all sounds of a particular type,\nvoid UpdateSoundsWithType( int nTypeld, const ControlParams_t &cp);\nWe can also associate behaviors such as default priority and default volume with\ntypes.\nvoid SetDefaultPriorityForType( int nTypeld, int nDefaultPriority );\nvoid SetDefaultVolumeForType( int nTypeld, float fDefaultVolume );\nIt is assumed here that a priority system is in place to determine which sounds\nshould play if limited buffers are available.\nBig Ball Of Mud \n(also known as Spaghetti Code)\nThe last design pattern I want to mention is the Big Ball of Mud. The paper with this\ntitle, written by Brian Foote and Joseph Yoder, is a witty and insightful categorization\nof patterns that can creep into a project quite naturally. In a way, the Big Ball of Mud\nis the pattern we all want to avoid, but conversely it is a pattern that may be impossi-\nble to avoid. Therefore, the wisdom here is that whether you know design patterns or\n",
      "content_length": 1919,
      "extraction_method": "Direct"
    },
    {
      "page_number": 496,
      "chapter": null,
      "content": "6.1 \nGame Audio Design Patterns \n519\nnot, you may be implementing the patterns that can lead to a Big Bull of Mud any-\nway, namely: Throwaway Code, Piecemeal Growth, Keep It Working, Shearing Lay-\ners, and Sweeping It Under the Rug.\nSo, how does the Big Ball of Mud pattern relate to audio and game program-\nming? Our first goal might be to keep our audio system's internal code from being a\nBig Ball of Mud. Our second goal might be to keep the rest of the game code from\nbeing a Big Ball of Mud. We have some influence over the code organization by pro-\nviding useful features in our audio API. We can also provide API features to help\ndebug audio problems. Therefore, even if Mud prevails, our audio API can provide\nfeatures for swamp navigation.\nStatus Functions\nProviding status functions can help us find common problems. We can return specific\nvalues in response to specific requests such as the number of voices playing. We can\nalso return a string ready for display in response to more general requests such as\nsound status.\nint \nGetNumberOfSoundsPlayingO;\nbool IsSoundPlaying( int nSoundld );\nstring GetAudioStatusO;\nvoid GetDescriptionsOfSoundsPlaying( list<string> &Stringl_ist );\nLogging Functions\nWe can provide a logging system that records audio system activity. The logging\nrecords could be directed to different types of output such as stdout or a file or a dis-\nplay. We can also provide a detail-level control to determine how much information is\nrecorded. One detail level might just record all audio API calls and parameters passed.\nAnother detail level might include internal sound buffer allocation information and\nother internal state information.\nvoid EnableLogging();\nvoid DisableLogging();\nvoid SetLoggingDetailLevel( int nDetailLevel );\nvoid SetLoggingOutputType( int nOutputType );\nSystem Disable\nSometimes the easiest way to determine if the audio system is causing problems with\nthe game is to disable the audio system completely. When the audio system is dis-\nabled, all calls to audio API functions simply do no work. If problems still persist after\ndisabling the audio system, then we can eliminate it as a cause. Disabling a system\nsuch as this can also make some game debugging situations less complicated.\nvoid AudioSystemEnable();\nvoid AudioSystemDisable();\n",
      "content_length": 2297,
      "extraction_method": "Direct"
    },
    {
      "page_number": 497,
      "chapter": null,
      "content": "520 \nSection 6 Audio Programming\nConclusion\nUsing design patterns as an inspiration, we have outlined useful features for a game\naudio API. Whether we are revving engines, on a jungle safari, or just navigating the\nswamps, we want to make our clients happy.\nReferences\n[Gamma94] Gamma, et al., Design Patterns, Addison-Wesley Longman, Inc., 1994.\n[Foote99] Foote, Brian, and Yoder, Joseph, Big Ball of Mud, www.Taputan.org/mud/\n[BilasOO] Bilas, Scott, \"A Generic Handle-Based Resource Manager,\" Game Program-\nming Gems, Charles River Media, 2000: pp. 68-79.\n",
      "content_length": 558,
      "extraction_method": "Direct"
    },
    {
      "page_number": 498,
      "chapter": null,
      "content": "6.2\nA Technique to Instantaneously\nReuse Voices in a\nSample-based Synthesizer\nThomas Engel, Factor 5\ntengel@factor5.com\nS\nynthesizers typically offer a limited number of voices that can be active at any\ngiven time, so complex allocation schemes are used to make the best use of the\nvoices that are available. Allocating a voice at any given time is easy as long as free\nvoices are available, but becomes quite tricky when this is not the case, requiring voices\nto be reused. The difficulty results from the amplitude difference between the current\nactive sample and the next sample to be played, resulting in a sharp pop or click sound\n(see Figure 6.2.1). This gem presents a technique to accomplish this without any\nmajor calculation time or memory overhead.\nFIGURE 6.2.1 The amplitude difference between samples can create a distracting click.\nThe Problem\nTo reuse an active voice for playback of another sample, you might try slowly lower-\ning the volume of the current sample and immediately starting the playback of the\nnew sample. This would nicely avoid any clicks or pops caused by abruptly stopping\nthe old sample, and would start the new sample prompdy.\n521\n",
      "content_length": 1168,
      "extraction_method": "Direct"
    },
    {
      "page_number": 499,
      "chapter": null,
      "content": "522\nSection 6 Audio Programming\nThis is unfortunately not very practical since two voices are needed to handle this\nproperly—and all this at a time when voices are no longer available. A possible solu-\ntion to this problem would be to reserve a number of voices for just this case. Unfor-\ntunately, this also has major drawbacks. First, hardware resources are lost since you\nhave to guarantee the availability of some extra voices at all times. Second, the num-\nber of voices that could be reallocated at once would be limited by the number of\nextra voices reserved for this purpose, making this a rather impractical solution.\nYou can remove the need for two voices by serializing the method: first fade out\nthe old sample, and then start the new sample on the same voice. This delays the start\nof the new voice and lowers the volume of the old voice quite a bit earlier than one\nwould like. It also can be very problematic when playing back a musical composition\nbecause the delay is very noticeable. The effect of the delay can be minimized by\ndelaying all voice starts, no matter if reusing voices or not. This nevertheless intro-\nduces an extra global delay to the audio pipeline, and makes it more difficult to\nhandle the voices due to added complexity.\nA more elegant solution is needed.\nAn Idea for a Solution\nThe basic idea for the solution is found within a simple question, or rather, the answer\nto it: What is sound? Answer: sound is a change in air pressure and, therefore, a\nchange in the amplitude of the output signal. A constant output signal, no matter\nwhat the amplitude, will not be audible. Reallocating a voice results in a sudden,\nunwanted change in amplitude that generates a sharp pop sound. This sound would\nalso be audible if one were to switch off the old sample even without starting a second\nsample.\nThe idea now is not only to stop any change or oscillation of the old sample, but\nalso to keep its last amplitude active in the output sum. A single sample being stopped\nwould look something like Figure 6.2.2.\nThis output would not generate any click or pop since there is no sudden ampli-\ntude change.\nFIGURE 6.2.2 Holding the last amplitude from a sample prevents an undesiredpop\nsound.\n",
      "content_length": 2218,
      "extraction_method": "Direct"
    },
    {
      "page_number": 500,
      "chapter": null,
      "content": "6.2 A Technique to Instantaneously Reuse Voices In a Sample-based Synthesizer \n523\nThe Solution\nThe effect outlined previously can be put to good use to solve our problem. Halting\nthe oscillation of a voice but not dropping its last amplitude simplifies things quite a\nbit, since all logic concerned with fetching new samples or handling the pitch for the\nold voice can be dropped as soon as the new sample is started.\nThe output would look something like Figure 6.2.3.\nFIGURE 6.2.3 Starting the second sample at the final amplitude of the first.\nThis has an obvious drawback: by simply halting the old voice we introduce a\npotentially high DC offset to the output signal, which, due to the limited maximum\namplitude of the output sample, may cause the output quality to drop significantly\nbecause of clipping artifacts.\nTwo simple approaches can limit, and, in most cases, completely remove such\nartifacts. First, one should use a mix buffer of more than 16 bits to generate the final\noutput signal. This extends the maximum amplitude, which can be internally han-\ndled. Since the DC offset will be handled together with other voices that again can\nlower the amplitude, this actually reduces artifacts quite dramatically. The most\nimportant step nevertheless is to lower the DC offset quickly to zero. One basically\nhas to fade out the halted old sample (Figure 6.2.4).\nAll this would still require separate logic to handle the halted old sample for each\nvoice to avoid limiting the number of voices that can be reused at once. But is this\nreally true? In fact, one could handle all DC offsets introduced by voices being reused\nin one very simple handler.\nFIGURE 6.2.4 Fading the initial sample to zero.\n",
      "content_length": 1705,
      "extraction_method": "Direct"
    },
    {
      "page_number": 501,
      "chapter": null,
      "content": "524\nSection 6 \nAudio Programming\nThe logic is as follows: each time a voice is reused, the last value mixed into the\nsum by the old sample on this particular voice will be added to a global DC offset\nvalue. This value in turn will be added to the output signal once all voices are\nprocessed.\nTo get rid of this DC offset, which as outlined previously is necessary but\nunwanted, one lowers the DC offset sum on a per-sample basis over a certain time.\nThis can be very efficiently done and does not introduce any further artifacts if not\nperformed too rapidly. A period of about five milliseconds is usually slow enough to\nlower even a full amplitude DC offset to zero (Figure 6.2.5).\nFIGURE 6.2.5 Fading the initial sample to zero while playing the second sample.\nConclusion\nIn practice, the theoretical negative side effects caused by the DC offset are close to\ninaudible. One would have to reuse extreme numbers of voices at high amplitudes to\nachieve some audible effect when using at least a 24-bit mix buffer.\nAt the same time, the benefits of this method are huge. One can reuse a voice on\na moment's notice with no delay and with no audible artifacts in the output signal.\nThe overhead needed to implement this method is minimal. The method can, widi\nsome extra work, be used in systems that feature multichannel hardware playback of\nsamples. Just one voice has to be set aside to contain the DC offset values to be added\nin the form of a sample data stream generated by the CPU following the algorithm\noutlined in this gem.\n",
      "content_length": 1531,
      "extraction_method": "Direct"
    },
    {
      "page_number": 502,
      "chapter": null,
      "content": "6.3\nSoftware-based DSP Effects\nfan Lewis, Acclaim Studios\nilewis@acclaim.com\nT\nhis gem introduces basic DSP concepts and techniques that can be cheaply\nimplemented on today's PCs and next-generation consoles, including filtering,\nconvolution, delay, and interpolation.\nDSP Technique\nFiltering\nPurpose\nOcclusion and 3D sound effects\nPhysical modeling effects such as strain on engines\nConvolution\nDelay\nInterpolation\nHead-Related Transfer Functions (HRTFs)\nAccurately simulating real acoustic spaces\nEchoes from walls or terrain\nPitch shifting\nSample rate conversion\nFiltering\nFiltering is actually a special case of convolution, but merits its own section because it\nis far simpler to implement quickly than general convolution.\nTo filter an audio signal is to emphasize or deemphasize certain frequency com-\nponents, much like the \"bass\" and \"treble\" knobs on your stereo. The effect of this is\nextremely difficult to see on a graph of the waveform, but is immediately recognizable\nto the ear. For instance, applying a low-pass filter tends to make the wave sound muf-\nfled, and applying a high-pass filter tends to make the wave sound thin.\nThe general form of a filter is a loop where a set of values (filter coefficients) are\nmultiplied with the incoming samples, and then added together. The first filter coef-\nficient is multiplied with the current sample, the second with the previous sample,\nand so forth, so the code looks something like this:\nfor (k = 0; k < nCoefficients; k++)\n{\noutput+=coefficient[k] * (*(input-k));\n525\n",
      "content_length": 1534,
      "extraction_method": "Direct"
    },
    {
      "page_number": 503,
      "chapter": null,
      "content": "526 \nSection 6 Audio Programming\nThis type of filter is called an FIR, or Finite Impulse Response filter, because its\noutput will always decay to zero in a predictable amount of time after the input decays\nto zero. A slightly less acoustically \"stable,\" but more powerful filter is the IIR, or Infi-\nnite Impulse Response filter. This design feeds the filter outputs back into the input\nin a form something like this:\nfor (k = 0; k < nCoefficients; k++)\n{\noutput+=coefficient[k] * input[n-k] +\nfeedback_coefficient[k] * previousOutput[n-k];\n}\nAfter each sample is computed, of course, the contents of the previous Output[]\narray are shifted up by one, and the current output is placed into the bottom position.\nThis looks more complex, but the upside is that the number of coefficients can be\nmuch smaller than the equivalent FIR implementation.\nAlthough there are hundreds of filters available, most have musical purposes and\ntend to be more complex than what you need for games. The sample code uses a vari-\nant of the music-DSP source code archive's simple Chamberlin filter [DeJongOl],\nwhich in its full form provides a high pass, low pass, notch, and bandpass filter that is\nextremely cheap and easy to implement.\nFilters work really well with SIMD hardware and even vector hardware, because\nthey're nothing but strings of multiply-accumulates.\nConvolution\nConvolution is the process of taking two signals and multiplying them together so\nthat the first signal takes on the characteristics of the second. For instance, say you\nhad a level set in an old cathedral. You could literally make a recording of an\n\"impulse\" (a very short sound spike, like a balloon popping) in any handy Gothic\ncathedral, convolve that impulse with your game sounds, and presto!—your game\nsounds like it's inside that very cathedral. Unfortunately, convolution is extremely\nexpensive—mostly because each output sample is the sum of one input sample multi-\nplied by ALL of the impulse samples. To understand the code, think of each sample in\nthe impulse file as being a coefficient in the FIR filter described earlier. This only\nreally works for very short impulses.\nA good collection of short impulses is the set of Head Related Transfer Functions\n(HRTFs) available at the MIT media lab [Gardner94]. Convolving with the appro-\npriate HRTF gives the illusion of placing the sound in three-dimensional space.\nA faster method of convolution involves translating both signals into the fre-\nquency domain (where each sample represents a frequency like on a spectroscope,\nrather than an amplitude like on an oscilloscope) using the Fast Fourier transform\n[Press92]. This can be useful if you're already storing samples in the frequency\ndomain. Some methods of compression do use the FFT or one of its variants; for\n",
      "content_length": 2791,
      "extraction_method": "Direct"
    },
    {
      "page_number": 504,
      "chapter": null,
      "content": "6.3 Software-based DSP Effects \n527\ninstance, MP3 compression uses a variant called the Discrete Cosine Transform\n(DCT).\nA digital delay is probably the easiest DSP effect to generate. It takes very little CPU,\nbut it does require some RAM. The algorithm is simple: for each sample, push a copy\nof the sample onto a queue or circular buffer. Then read the oldest sample out of the\nbuffer and mix it with the output.\nDelayBuffer.push(input);\nOutput=input + DelayBuffer.pop() * delayGain;\nThe length of the buffer determines the length of the delay. Usually you'll want to\nscale the delay volume by some factor (delayGain in the preceding example). A simple\ndelay can add an echo to a big outdoor scene, for instance.\nMore interesting delays are regenerative. In a regenerative delay, the scaled delay\noutput samples are fed back into the delay buffer, producing a multiple echo effect\nthat more accurately simulates natural spaces. Since the gain of each sample is reduced\nevery time it gets recycled, eventually the echoes die away into nothing. The time it\ntakes for the delay to die away is determined by the amount of attenuation you apply\nto each sample. Apply a lot, and you get a \"slap-back\" effect with very little presence,\nlike you would at the edge of a canyon or near the wall of a very large building. Apply\nless attenuation, and you get a dense stream of echoes more like what you'd hear\ninside a cathedral or an echoing cavern.\nAn even more sophisticated reverb effect is the multi-tap reverb. In the multi-tap\nalgorithm, a copy of the input sample is not only pushed onto the tail of the delay\nbuffer, but inserted into other locations (\"taps\") in the buffer as well. This allows for\nmuch denser echoes and more realistic effects. For instance, a sound made in a large\nrectangular room might be pushed into the delay buffer four times, one for each wall\nthe sound bounced off. The exact position of each tap in the buffer could be dynam-\nically determined based on how far the source of the sound is from each wall.\nThe ultimate in spatial realism comes from DSP reverberation algorithms, which\nare an even more complex variation on the basic delay theme. Reverberation algo-\nrithms are generally too expensive to implement in software. With a growing trend to\nimplement hardware reverb processors on PC soundcards (for example, Creative's\nEAX extensions) and next-generation game consoles, this article will not try to\ndescribe reverb algorithms in depth.\nInterpolation\nInterpolation is the art of determining values for nonexistent samples, based on the\nvalues for known samples. That might seem a little esoteric, but the principle is one\nyou use all the time in many areas of game programming. For instance, bilinear\n",
      "content_length": 2736,
      "extraction_method": "Direct"
    },
    {
      "page_number": 505,
      "chapter": null,
      "content": "528 \nSection 6 Audio Programming\ntexture filtering is a form of interpolation, where you might use as few as 4 or 5 texels\nto cover 10 or 20 onscreen pixels. Resampling is the primary use of interpolation in\naudio. One of the most effective ways to compress audio is to reduce its sample rate,\nespecially if the audio contains very few high-frequency components.\nSample-rate conversion (and pitch shifting, which is by and large the same thing)\ncan use one of several algorithms. They are listed here from least to most expensive:\n• Sample doubling, used when the ratio between the target sample rate and the\nsource sample rate is a multiple of two.\n• Sample averaging, where the target sample is computed to be the average of the\nvalues of the two closest points.\n• Linear interpolation, similar to sample averaging except that the average is\nweighted—more weight is given to the value of the closer point.\n• \nCubic interpolation, where the nearest 3-7 points (reportedly 5 points gives the\nbest results [DeJongOl]) are approximated using a spline function, and the value\nof the target point is the value of the spline at that point.\nCubic interpolation does give a decidedly better result than the other forms of\nresampling, although surprisingly, all of the other forms sound about the same. In a\ncase where the resample ratio is not a power of 2, simple sample averaging is the best\nchoice if CPU cycles are at a premium. This gives a reasonable result for pitch shifting\nwhere the ratio between the source and target sample rates is between .75 and 1.5.\nCubic sampling can get you higher ratios without sounding terrible, but no simple\nresampling algorithm will ever avoid the dreaded \"Mickey Mouse\" effect. To get rid of\n\"Mickey Mouse,\" you've got to do formant-corrected pitch shifting, which involves\nsome extremely complicated calculations that are far beyond the scope of this gem.\nReferences\n[BoresOl] \"Bores Signal Processing. Introduction to DSP,\" www.bores.com/courses/\nintro/ (4 March 2001)\n[DeJongOl] Dejong, Bram, \"The Music-DSP Source Code Archive,\" www.\nsmartelectronix.com/musicdsp/ (4 March 2001)\n[Gardner94] Gardner, Bill, and Martin, Keith (1994). \"HRTF Measurements of a\nKEMAR Dummy-Head Microphone.\" MIT Media Lab, http://sound.media\n.mit.edu/KEMAR.html (4 March 2001).\n[Iowegian99] lowegian International Corp. (1999), DSPGuru, www.dspguru.com/\n(4 March 2001).\n[Kosbar98] Kosbar, Kurt L. (1998), \"Introduction to Digital Signal Processing\n(DSP),\" www.siglab.ece.umr.edu/ee301/dsp/intro/index.html (4 March 2001).\n[Press92] Press, William H., et al, Numerical Recipes In C, Cambridge University\nPress, 1992, www.ulib.org/webRoot/Books/Numerical_Recipes/ (4 March 2001).\n[SprengerOl] Sprenger, Stephan M, \"The DSP Dimension,\" www.dspdimension\n.com/(4 March 2001).\n",
      "content_length": 2788,
      "extraction_method": "Direct"
    },
    {
      "page_number": 506,
      "chapter": null,
      "content": "6.4\nInteractive Processing\nPipeline for Digital Audio\nKeith Weiner, DiamondWare Ltd.\nkeith@dw.com\nIntroduction\nAlgorithms for Digital Signal Processing (DSP) have been readily available for a long\ntime. Games haven't used them much, probably because of the high CPU cost. Today,\nhowever, gigahertz processors are cheap and are getting cheaper. They allow room for\na certain amount of audio processing, even after the graphics engine, AI engine, and\nphysics engine all get their share.\nGames (and other applications) have a need for an audio processing pipeline. The\ngoal is to allow a set of DSP functions with corresponding parameters to be specified\nfor a sound. Other sounds may pass through a different set of DSP functions and/or\nuse a different set of parameters.\nA block diagram of an audio system is shown in Figure 6.4.1. A full architecture\nwould stream sounds from any source, decrypt if necessary, decompress if necessary,\nprocess, mix, and then output. This gem describes the block labeled \"Processing.\"\nThis gem presents a lightweight, but general-purpose architecture. \"General pur-\npose\" is meant in two respects here. First, it allows any type of processing, even a\nspeed changer. Speed changers are tricky because they necessitate a buffer length\nchange. It gets even trickier if you want to allow parameter changes on the fly. Second,\nit's completely OS independent, and could be used on Linux as easily as Windows.\nThe architecture demonstrated in this article has been used in device drivers, a\ngeneral-purpose audio API/engine, and a telephony media control component.\nConstraints\nIn thinking about, and designing a system, a good way to get focused is to define the\nproblem and all of the constraints for the solution. We've already begun, but I'd like\nto spell out all of the requirements in one list, and then discuss each item.\n• Supports A^ sounds.\n• Each sound can pass through A^DSP functions.\n529\n",
      "content_length": 1927,
      "extraction_method": "Direct"
    },
    {
      "page_number": 507,
      "chapter": null,
      "content": "Sound 1\nSource (file, http,CD,\nmemory buffer, etc.)\n~~TT~^\nDecryption\n_xH\nDecompression\n4^\nProcessing\nr^. ...\nSound 2\nSource (file, http,CD,\nmemory buffer, etc.)\nzm:\nDecryption\nL^^\nDecompression\nZLTZ\nProcessing\nSound 3\nSource (file, http.CD,\nmemory buffer, etc.)\n~^±\nDecryption\n~^-£~\nDecompression\n~^r~\nProcessing\n^ \n1\nFIGURE 6.4.1 An audio processing system.\n530\n",
      "content_length": 364,
      "extraction_method": "Direct"
    },
    {
      "page_number": 508,
      "chapter": null,
      "content": "Interactive Processing Pipeline for Digital Audio \n531\n• Any parameter for any DSP function may be changed at any time.\n• Any function may impose a length change.\n• Efficient, this is for games on PCs, not scientific research on supercomputers.\n• Makes it easier to write DSP functions.\nLet's drill down into each item. First, we said N sounds. Monophonic sound\nengines have been obsolete since around 1994. If we store all DSP function and para-\nmeter information in the instance data of each sound, this will allow us to handle an\nunlimited number of sounds without having extra complexity.\nNext is the requirement to support N DSP functions per sound. This is the\nessence of the gem. If we wanted to pass a sound through only a single DSP function,\nwe wouldn't need a pipeline!\nParameters may be changed at any time. This is the heart of interactivity. In a\ngame, the sound designer doesn't know what will happen, or when it will happen. At\nany time, the user could enter the concrete pipe, and then certain sounds would have\nto have a reverb.\nPerhaps it's not that often that you want to slow down or speed up a sound you're\nplaying, but sometimes you do. As long as we're building a general-purpose engine,\nwe may as well support this operation. A speed-changing DSP function, in the con-\ntext of our pipeline, is any function that outputs a different number of samples than\nit uses for input. The classic example of a DSP function which slows down music is\nonly one type of speed changer. A reverb function may be categorized as a speed\nchanger (though it is actually more of a length changer) if it can generate output past\nthe end of its input; in other words, it allows the last reverberations to fade to silence\nbefore stopping.\nThe audio system should be efficient. Hopefully the pipeline itself doesn't con-\nsume a lot of CPU cycles, but we can be careful not to cause any unnecessary copying\nof memory; for example, if a DSP function returns \"I have no work to do,\" no mem-\nory copying should be performed.\nThe goal of any general-purpose API is to save work, not create work. An audio\nengine is built only once. There are many types of DSP functions. We should handle\nas much ancillary work as possible, so that each DSP function implements an algo-\nrithm and not much else.\nDiscussion\nThroughout this section, I will discuss what happens for one sound. Multiple sound\nsupport does not become a relevant factor until the mix stage.\nLooking again at Figure 6.4.1, we see that the audio input to our little world\ncomes from the decompressor (if present, or else from the input stream manager). The\noutput goes to the mixing engine (which may be DirectSound or another system).\nThis is asymmetrical. While the input side is relatively flexible (it should be able\nto supply us with as many samples of audio as we request, within reason), the output\n",
      "content_length": 2859,
      "extraction_method": "Direct"
    },
    {
      "page_number": 509,
      "chapter": null,
      "content": "532 \nSection 6 Audio Programming\nside is inflexible. The mixing engine needs a certain number of samples from our\nstream; it cannot handle anything more, and if we try to pass it anything less it will\ncontinue mixing—without our sound, which will have a gap in it.\nThis is so important a rule that it should be stated again: the output of the audio\nprocessing pipeline must be determined by the needs of the mix engine. That's what\ndetermines how many samples we are to output.\nThere is only one type of inflexibility imposed by the input stream: EOF. When\nthe stream reaches the end, the processing engine needs to know.\nSo, let's say the mix is done in a fixed buffer of 16,384 samples. This means that\nit waits until it needs that many samples, and then triggers the audio processing.\nTherefore, the audio processing pipeline must output 16,384 samples.\nHow many samples does the pipeline need for input? We don't know that yet. So\nfar, we know only that the last function in the chain must output 16,384 samples.\nHow many samples does this function need for input?\nWe don't know that either, but we can find out. We can ask it! The mixer wants\n16,384 samples. The last function in the chain, with its current parameter set, says it\nwants 24,576 samples of input to produce 16,384 of output. To determine how many\nsamples of input to obtain from the stream, we continue traversing the chain of DSP\nfunctions backward. We go backward because we know the number of samples out-\nput at the end, but not the number of samples input at the beginning.\nOnce we're done with this phase, we can obtain the requested number of samples\nfrom the input stream, and pass them to the first function in the chain. We can take\nits output and pass it to the second function, and so forth. At the end, theoretically,\nwe have the right number of samples to send to the mix engine.\nWhat if that assumption is broken? What if a DSP function produces fewer sam-\nples than it was supposed to? The next DSP function in the chain must be given the\nnew, smaller buffer. It must produce output as well as it can. At the end, there may be\na shortfall. We treat this shortfall as the desired output for a second iteration, query\nbackward up the chain, and then process data a second time. We do this until we\neither run out of input samples, or fill the output buffer. For the sake of efficiency,\nDSP functions should be implemented in a manner such that they don't frivolously\nmisreport their expected input requirements. This is a feature that should only be\nused if computing the exact number of input samples required would require sub-\nstantial processing (for example, if the DSP function would have to actually process\nthe audio to know exactly how many samples it would need).\nWhat if a DSP function \"eats\" fewer samples than requested? This is a trickier\ncase to program. The pipeline must provide a buffer between each pair of DSP func-\ntions in the chain. The buffer between function #2 and function #3 holds underflow\ndata from function #3.\nWhat if a DSP function produces too many output samples? Well, it shouldn't do\nthat! Seriously, the obvious way to handle this case is to buffer it, but that is not\ndemonstrated in the code for this gem.\n",
      "content_length": 3230,
      "extraction_method": "Direct"
    },
    {
      "page_number": 510,
      "chapter": null,
      "content": "6.4 Interactive Processing Pipeline for Digital Audio \n533\nThis raises a point: DSP functions are not commutative. Order matters. This is\nnot merely a limitation of the buffering system I just proposed, but also of the nature\nof processing. If one changes the pitch of a sound and then imposes a reverb, the result\nwill sound different than if one applies a reverb and then changes the pitch. Therefore,\nwe're not worried that our proposed architecture imposes this requirement as well.\nDetails\nWe're envisioning an audio processing pipeline that's called whenever the mixing\nengine needs more data for a sound channel. It may be implemented as a callback, if\nthe mix engine is driven by interrupts, or as a regular function if the status of the mix\nbuffer is polled.\nThe processing engine must call the input stream manager to request raw data for\nthe sound channel. It may return a full buffer, or less if the sound has reached the end.\nThe processing engine can call each DSP function with several messages. So far,\nwe've discussed a query to determine how many input samples are needed to produce\nthe required output, and of course the output call itself.\nWe ought to add two more: firstcall and lastcall. Firstcall is the first message sent to\na DSP function, to let it allocate instance data, and lastcall allows it to free that data.\nTo implement a DSP function to plug into diis architecture, the programmer\nmust provide a single entry point that's capable of properly handing firstcall (initial-\nization), lastcall (shutdown), query, and output messages. This entry point is given a\nsingle struct that contains the command number, input and output buffers and\nlengths, and two other items. One of these is a pointer to DSP-specific parameters,\nwhich is passed down from the application (presumably controlling all of this). Exam-\nples of DSP-specific parameters would be room size for a reverb, ratio for a speed\nchanger, and so forth. The other item is private instance data allocated and main-\ntained by the DSP function itself.\nImplementing the engine is somewhat more complex, but this was our intent.\nMake this one piece intelligent so that the many DSP pieces are quick and easy to\nimplement.\nThe processing engine uses three buffers: a source, a destination, and an accumu-\nlation buffer. During processing, the buffers swap roles, so the engine uses buf [0],\nbuf [1 ], and buf [2]. The reason is that the destination (output) of DSP function #1\nbecomes the source (input) of DSP function #2.\nSimilarly, if the last DSP function in the chain outputs less than the amount\nrequired by the mixing engine, its destination buffer becomes the accumulation\nbuffer. After the next iteration of the chain, the accumulation buffer is prepended to\nthe new destination buffer.\nThe Code\nLet's look at the source code to the main entry point.\n",
      "content_length": 2845,
      "extraction_method": "Direct"
    },
    {
      "page_number": 511,
      "chapter": null,
      "content": "534\nSection 6 \nAudio Programming\nvoid dsp_ProcessAudio(dsp_AUDIO *audio)\naudio->src = 0;\naudio->dst = 1;\naudio->acc = 2;\nbfbuf_WIPE(audio->buf[audio->src]);\nbfbuf_WIPE(audio->buf[audio->dst]);\nbfbuf_WIPE(audio->buf[audio->acc]);\naudio->samps = 0;\nwhile ((audio->samps < audio->sampsneeded) && (!audio->done))\nSWAP(audio->acc, audio->dst);\nQueryDSPIn(audio);\nstream_GetData(audio);\nDoDSP(audio);\nbfbuf_MoveAll(audio->buf[audio->dst], \naudio->buf[audio->acc]);\nON me a\nON me CD\nOne last explanation is necessary before this code makes sense. A bfbufis a data\nstructure of my own invention. A backfill buffer is a memory buffer designed to make\nit easy to prepend data. The contents are always aligned flush with the end, so that\nprepending is done with a simple memcpy (). The source code to BFBUF.C is included\non the companion CD-ROM.\nIt turns out that the prepend operation is the one we need to handle the under-\nflow buffers in the DSP chain itself. Therefore, I've implemented the outer loop to\nuse a prepend to take the partial buffer from the previous iteration and add it to the\ncurrent partial buffer. This could just as easily have been implemented to append the\ncurrent partial buffer to the previous partial buffer. When you make yourself a new\nhammer, and you feel clever about it, you have a tendency to see everything as a nail.\nLet's walk through the function. Its sole parameter is a pointer to a struct defined\nin the code on the CD. There are three backfill buffers, which we initialize to empty,\nand assign their initial semantics.\nWe have a loop that iterates until we run out of source data, or until the output\nbuffer is full. For the first iteration, the swap is meaningless and does nothing.\nThe rest is simple. First, we determine how many input samples are needed, get\nthem, and process. Then, we prepend the accumulated samples from previous itera-\ntions (if any) to the current destination.\nstream_GetData() is the call to the input stream manager (external to DSP.C). It's\nimportant to understand that this function must put the samples in the destination\nbuffer. As we'll see, DoDSP () swaps the source and destination buffers at the beginning.\nNow let's look at the query function.\n",
      "content_length": 2213,
      "extraction_method": "Direct"
    },
    {
      "page_number": 512,
      "chapter": null,
      "content": "6.4 Interactive Processing Pipeline for Digital Audio \n535\nstatic void QueryDSPIn(dsp_AUDIO *audio)\n{\ndsp_PARAMS params;\ndsp_DSP *dsp;\nDWORD underlen;\nDWORD x;\nparams.cmd \n= dsp_QUERYACTIN;\nparams. actualin = audio->sampsneeded - audio->samps;\nfor (x=0;x<audio->numdsps;x++)\n{\ndsp = &(audio->dsp[audio->numdsps - x - 1]);\nparams. dstlen = params. actualin;\n(*dsp->callback) (&params) ;\nunderlen = bfbuf_GETDATALEN(dsp->underbuf ) ;\ndsp->inreq = (underlen < params. actualin) ?\nparams. actualin - underlen : 0;\ndsp->outreq = params. dstlen;\nNotice how the function begins by knowing how many samples remain (audio ->\nsampsneeded — audio->samps). It sets this up where the code in the loop expects to\nfind it from a previous iteration. Alternatively, I could have coded this with a goto to\nenter the loop in the middle, but that seemed a less elegant solution.\nThe loop itself traverses all the DSP filters used by the sound in reverse order. For\neach, it sets up a parameter to specify the desired number of output samples, and\nmakes the call. Then it subtracts the number of samples stored in the underflow\nbuffer from a previous iteration of processing. The result may be zero, if the previous\niteration had sufficient samples left over. In this case, the filter needs no more input;\nall the input it requested is already waiting for it in our underflow buffer!\nEach DSP stores how many input samples it needs, and the expected output (the\nnumber of samples requested by the next item in the chain).\nThe meat of the Gem is the DoDSP( ) function.\nstatic void DoDSP(dsp_AUDIO *audio)\n{\nbfbuf_BUFFER *srcbuf;\nbfbuf_BUFFER *dstbuf;\ndsp_PARAMS params;\ndsp_DSP *dsp;\nDWORD x;\nparams.cmd = dsp_OUTPUT;\nfor (x=0;x<audio->numdsps;x++)\n",
      "content_length": 1727,
      "extraction_method": "Direct"
    },
    {
      "page_number": 513,
      "chapter": null,
      "content": "536 \nSection 6 Audio Programming\ndsp = &(audio->dsp[x]);\nSWAP(audio->src, audio ->dst);\nsrcbuf = audio->buf[audio->src];\ndstbuf = audio->buf[audio->dst];\nbfbuf_MoveAll(srcbuf, dsp->underbuf);\nbfbuf_SetDataLen(dstbuf, dsp->outreq);\nbfbuf_GetBufStart(srcbuf, &(params.lsrc), &(params.rsrc));\nbfbuf_GetBufStart(dstbuf, &(params.ldst), &(params.rdst));\nparams.srclen \n= bfbuf_GETDATALEN(srcbuf);\nparams.dstlen \n= bfbuf J3ETDATALEN(dstbuf);\nparams.dspspecific = dsp->dspspecific;\nparams.privdata \n= dsp->privdata;\n(*dsp->callback)(&params);\nif (params.nowork)\n{\nbfbuf_WIPE(dstbuf);\nSWAP(audio->src, audio->dst);\nparams.actualout = params.srclen;\n}\nelse\n{\nif (params.actualout < bfbuf_GETDATALEN(dstbuf))\n{\nbfbuf_ChokeUp(dstbuf, params.actualout);\n}\nif (params.actualin < bfbuf_GETDATALEN(srcbuf))\n{\nbfbuf_Eat(srcbuf, params.actualin);\nbfbuf_MoveAll(dsp->underbuf, srcbuf);\n}\nelse\n{\nbfbuf_WIPE(srcbuf);\n}\n}\n}\naudio->samps += params.actualout;\n}\nAt first, the initial swap of source and destination looks funny. Each DSP func-\ntion is given the previous function's output (destination) for its own input (source).\nThis also makes it easy to handle the case when a DSP reports that it has done no\nwork.\nThere's some variable setup, and then four calls to this mysterious backfill buffer\nmanager. First, we fetch all underflow samples from the previous iteration. Note: this\n",
      "content_length": 1366,
      "extraction_method": "Direct"
    },
    {
      "page_number": 514,
      "chapter": null,
      "content": "6.4 Interactive Processing Pipeline for Digital Audio \n537\nis stored on a per-DSP basis. The underflow for DSP function #1 is different from the\nunderflow for DSP function #2, and must be kept separate.\nNext, we set up the expected size of the destination backfill buffer. If this turns\nout to be wrong, we'll fix it later. Finally, we obtain pointers to the current beginnings\nof the buffers. Notice that left and right are stored separately. This makes DSP pro-\ncessing easier, as well as the eventual move to multichannel audio (for example, 5.1).\nWe do some straightforward parameter setup. Notice how we provide the DSP\nwith both a pointer to function-specific parameters, and its own instance data for this\nsound.\nAfter the call, if the function did no work, we set the destination buffer to empty,\nand swap destination with source (so the destination is now the one with samples in\nit) to prepare for the next iteration, which will swap again.\nOtherwise, something was done by the function, so we check to see if the DSP\ngenerated less than a full buffer. The choke up is the only BFBUF operation that must\ndo a memory move.\nThen we check to see if the function consumed less than all of the input data sup-\nplied to it. If so, we buffer it as underflow. Otherwise, we just mark the source buffer\nas empty.\nExtra Commentary\nThis isn't the easiest code to read, but it's nice and efficient, which is what counts! No\ncycles are wasted unless a DSP generates too little data, and there's not much to do\nabout that except iterate the whole chain again hoping we'll get enough data.\nNotice how each time dsp_ProcessAudio() is called, the parameters for all of the\nDSP functions could have changed. This code forms the core of an audio processing\nengine that meets all of the criteria we enumerated earlier.\nBuilding it was not only possible, but it wasn't as hard as it seemed it would be.\nTwo functions have been omitted from the text (they're on the CD). dsp_New-\n^r'^Hs, \nSound () must be called when a new sound is added to the system, and dsp_Delete-\nONWCD \nSound () must be called when a sound is removed from the system. This is important\nbecause it's not obvious from the code presented thus far. There is a call to the stream\nmanager, and that call sets audio->done if the stream reaches the end.\nWhatever code calls dsp_ProcessAudio() must check this bit, and then call\ndsp_DeleteSound() if appropriate. The tricky part is to wait until the sound is done\n(in other words, audio->samps is 0). DSP functions (such as echo) may retain their\nown internal buffers. Regardless of how they determine when to eat input samples\nand produce nothing (when given a request for output and when provided with less\ninput than requested) they must output whatever they can. This way, the DSP engine\nknows that when a stream reaches the end, and the DSP function chain produces no\noutput, the last reverberations or echoes of the sound are done, and the sound may\nsafely be deleted without causing an audible truncation.\n",
      "content_length": 3016,
      "extraction_method": "Direct"
    },
    {
      "page_number": 515,
      "chapter": null,
      "content": "538 \nSection 6 Audio Programming\nFrom an architectural standpoint, this is admittedly somewhat weak. It is possible\nto design a more elegant, self-contained solution to this problem inside DSP.C. A\nrelated limitation is that the dsp_AUDIO struct and its dsp_DSP array are allocated\noutside as well. There is entirely too much management of DSP-related memory\nstructures, parameters, and so forth, outside the DSP engine. This is done primarily\nto keep the code clean and easy to understand.\nThere are two functional limitations (the previous are considered to be structural\nor architectural) to discuss. First, the code doesn't handle the case of when a DSP\nfunction overflows. The quick excuse is that no function should ever output more\ndata than is requested of it. It could also be argued that those few functions that\nwould want to, can simply maintain an internal buffer. This isn't satisfactory because\nwe've gone to great lengths to make sure that DSP functions are small, lightweight,\nand easy. The real answer is that this would add considerably to code size and com-\nplexity (including in BFBUF.C), and provide a (comparatively) marginal value. This\ncode is not really a robust commercial implementation, and adding something like\noverflow protection (including the algorithms to determine how big is big enough,\netc.) just wouldn't make sense before putting in DEBUG error-checking, for example.\nThe other missing feature is that there is no way to add or remove DSP functions\nafter a sound is created. This can be worked around as long as all DSP functions have\na parameter to indicate \"passthru.\" Then, just make sure each sound is created with all\nof the DSP functions that you'll possibly want to use on it at any point during its life-\ntime. It's not inefficient, and it works (although it is a bit clunky).\nIt would be a bad kludge, but you could actually add new DSP functions to the\nend of the list (as long as you provided a way to do firstcall processing for them).\nConclusion\nThe essence of this gem demonstrates how to build a basic DSP pipeline that supports\npassing a sound channel through a chain of DSP filters, each of which can do any-\nthing to the stream that it wants.\nIn order to support DSPs that may wish to change the size of the buffer as they\nprocess, we need a query call to ask the DSP \"if we want N samples of output, how\nmany samples of input do you estimate you'll need?\" We do this query in reverse\norder.\nIn addition, we added support for two underflow conditions: generating too little\ndata, and eating too little input. These weren't too hard to support with the help of an\ninnovative data structure: the backfill buffer. The concept is the most difficult thing\nONTHCCD \n-with this. As you'll see on the CD, the code is straightforward, if not trivial.\nWith this engine, and some glue logic, it's possible to do any type of audio pro-\ncessing that a game will need. Indeed, it could support a whole professional audio stu-\ndio for music production and performance.\n",
      "content_length": 3012,
      "extraction_method": "Direct"
    },
    {
      "page_number": 516,
      "chapter": null,
      "content": "6.5\nA Basic Music Sequencer\nfor Games\nScott Patterson\nscottp@tonebyte.com\nT\nhis gem describes how to make a basic music sequencer. First, we will start with a\ncomparison of music streaming and music sequencing. Then, we will review\nsome important concepts from the MIDI music language, outline a basic computer\nmusic language implementation, and then discuss the coding issues that relate to tim-\ning and synthesis control.\nStreaming vs. Sequencing\nMusic in games is generally played back in one of two ways: either as a stream of sam-\nple data or as a sequence of instructions to an audio synthesis system. It is also possi-\nble that music playback may involve a combination of both methods. Individually,\nthe methods have some pros and cons that depend on the hardware systems available.\nTo be combined, synchronization issues must be addressed as well.\nStreaming Method Pros\n• Audio hardware requirements are minimal.\n• Music development and integration with the game is easy.\n• Music quality is only limited by the sample rate and number of channels of the\nstream data.\nStreaming Method Cons\n• Music data plays the same way each time.\n• There can be latency in the start and stop of the stream.\n• There may be latency problems when looping a stream or switching streams.\n• There may be large memory buffer requirements.\n• Certain resources may be tied up during playback such as DMA hardware and\nstorage device hardware.\n• If the stream data is not compressed, it will take significant storage space.\n• If the stream data is compressed, it will require hardware or software decompres-\nsion resources.\n539\n",
      "content_length": 1609,
      "extraction_method": "Direct"
    },
    {
      "page_number": 517,
      "chapter": null,
      "content": "540 \nSection 6 Audio Programming\n• It may not be possible to cross-fade two different streams depending on hardware\nlimitations, so the only choice available may be fading to or from silence.\nSequencing Method Pros\n• No latency problems when starting or stopping the music.\n• No latency problems when looping or switching music.\n• If audio memory is available, sample data memory will not compete with game\ndata memory.\n• Resources such as DMA hardware and storage device hardware may not be\nrequired for music playback and will be free for die game to use at any time.\n• A great deal of music styles and variations can be produced from a relatively small\nsample data set.\n• Music data can be dynamically altered at runtime to create unique game and\nmusic interactions.\nSequencing Method Cons\n• Voices for music may compete with voices needed for other game audio.\n• Music development and integration with the game is more complex.\n• Music quality may be limited by synthesis capabilities.\n• Music quality may be limited by available sample memory.\nCore Computer Music Concepts\nLet's now review core computer music concepts, and build our music command\nlanguage.\nEvent Blocks\nMusic can be described as events or commands occurring over time. Therefore, we\ncan build our music command language with \"event blocks\" composed of three ele-\nments: time, event type, and event details. We will store the time relative to previous\nevents and call it a delta-time. The event type will be identified with a number, and\nthe event details will be zero or more parameters diat are defined by the event type\n(Figure 6.5.1).\nBy using a sequence of event blocks we can describe any combination of events\nand time intervals. Therefore, building our computer music language is now a task of\nDelta Time / Event Type / Event Parameters\nFIGURE 6.5.1 Event block.\n",
      "content_length": 1843,
      "extraction_method": "Direct"
    },
    {
      "page_number": 518,
      "chapter": null,
      "content": "6.5 A Basic Music Sequencer for Games \n541\nchoosing how to store the delta time, choosing the event types to support, and choos-\ning the parameters supplied for each event type.\nMIDI (Musical Instrument Digital Interface) Music\nThe MIDI specification has been around for a long time. Most music composition\nand sequencing software provides compatibility with MIDI input and output ports\nfor recording and playback. These software products also provide options to save and\nload MIDI files. Since we are creating our own computer music language, a good\nplace to start will be learning the MIDI specification and its file format. We can then\nconvert MIDI file data to our own custom data.\nThe word interface in MIDI refers to the fact that it is a specification for commu-\nnication between musical devices. In making a music sequencer for games, we aren't as\ninterested in musical device communication as we are in music playback on a partic-\nular machine. Therefore, my introduction to MIDI will include only the parts that\nrelate directly to making our music sequencer for games.\nMIDI Event Types\nThe MIDI specification defines several events called the channel voice messages.\nMIDI originated as a virtual piano keyboard communication language, so terms such\nas attack velocity, release velocity, pitch wheel, and key pressure all refer to actions\napplied to a virtual piano keyboard (Table 6.5.1).\nThe channel voice messages are the core musical control events defined by MIDI.\nThe Program Change event defines what instrument definition to use. The Note On\nand Note Off events do as they suggest, and the remaining events update various\naudio playback parameters to new values. Since the Control Change event specifies a\nTable 6.5.1 MIDI Channel Voice Messages\nEvent Type\nNote Off\nNote On\nPitch Wheel\nControl Change\nProgram Change\nPoly Key Pressure\nChannel Pressure\nEvent Parameters\nNote Number\nRelease Velocity\nNote Number\nAttack Velocity\nPitch Bend LSB\nPitch Bend MSB\nController ID\nController Value\nProgram Number\nNote Number\nPressure Value\nPressure Value\n",
      "content_length": 2060,
      "extraction_method": "Direct"
    },
    {
      "page_number": 519,
      "chapter": null,
      "content": "Section 6 Audio Programming\nController ID parameter, it can be used for many different types of audio control.\nTwo of die most commonly used Controller IDs are 7 for Volume and 10 for Pan.\nThere are also meta-events defined in die MIDI file format 1.0 specification.\nTable 6.5.2 lists a selection that will be important to us.\nThe End of Track meta-event defines the end of a series of event blocks, and the\nSet Tempo meta-event defines how fast to step through die delta time values of event\nblocks. The Time Signature and Key Signature meta-events do not change the way\nthat MIDI music plays, but are commonly used for organizing die visual display of\nmusic data. We can use these meta-events as special markers for our own organization\nor synchronization purposes. The remaining meta-events I have listed store string\ndata. We can store custom information in these strings to be used in our conversion\nfrom die MIDI format to a custom format.\nMIDI Channels and Tracks\nThe \"channel\" in MIDI channel voice messages refers to the fact that each MIDI\nevent block also contains a channel number from 1 to 16 (0 to 15). The channel con-\ncept makes it possible to send MIDI commands to more than one target over a serial\nconnection. It would also be possible for us to store our music data as a single serial\nstream and assign channels to each message. An advantage of this method is that pro-\nTable 6.5.2 Selected MIDI Meta-Event Types\nMeta-Event Type \nMeta-Event Parameters\nEnd of Track\nSet Tempo \nTempo Number\nTime Signature \nNumerator\nDenominator\nMIDI clocks per metronome click\n32nd-notes in a MIDI quarter-note\nKey Signature \nSharps/Flats Indicator\nMajor or Minor Indicator\nText Event \nString Length\n__ \nString Data\nSequence/Track Name \nString Length\nString Data\nInstrument Name \nString Length\nString Data\nLyric \nString Length\nString Data\nMarker \nString Length\nString Data\nCue Point \nString Length\nString Data\n",
      "content_length": 1912,
      "extraction_method": "Direct"
    },
    {
      "page_number": 520,
      "chapter": null,
      "content": "6.5 A Basic Music Sequencer for Games \n543\ncessing a single stream of data would work well for CPU caching. A disadvantage of\nthis method is that track data organization would not be flexible and independent.\nIt so happens that the MIDI file format 1.0 specification defines \"format 0\" files\nthat have all information combined in one track, and \"format 1\" files that have any\nnumber of tracks.\nThe basic music sequencer that we will present processes any number of tracks\nindependently and does not have a channel concept.\nComputer Music Sequencer Implementation\nNow we are at the point where we can determine our own custom computer music\nlanguage. For the purposes of this gem we will choose to implement event types that\nare very similar to MIDI event types. You can create your own additional event types\nfor your own needs.\nSequences, Tracks, Events, Instruments, and\nVoices\nLet's quickly cover the terminology used in the rest of this paper. A sequence is a col-\nlection of tracks that run simultaneously. Each track is a series of event blocks that we\ndefined earlier. There is always a single current instrument on each track. Every Note\nOn event in a track will start a voice of the current instrument. The corresponding\nNote Off event will turn this voice off. Many types of events in a track will modify the\nstate of the track's voices.\nThe sequencer data structures described later show an implementation of these\nrelationships.\nSequencer Event Types\nAs a first step in creating our basic music sequencer we will come up with a list of\nevent types that we want to support. These are displayed in Table 6.5.3.\nTable 6.5.3. Event Type Ideas\nEvent Types \nNotes\nNote Control \nThese work like the traditional MIDI events\nNote Off \nKey\nRelease velocity (optional)\nNote On \nKey\nAttack velocity\n(continues)\n",
      "content_length": 1811,
      "extraction_method": "Direct"
    },
    {
      "page_number": 521,
      "chapter": null,
      "content": "544\nSection 6 Audio Programming\nTable 6.5.3. (Continued)\nEvent Types\nImmediate Modifications\nSetVolume\nSetPitchBend\nNotes\nThese work like the traditional MIDI events\nValue\nValue\nSetPan\nValue\nSetEffect\nAny effect type\nValue\nSetlnstrument\nProgram change\nSetTempo\nValue\nTarget Modifications\nSetTarget\nTarget an event value rather than setting it\nTime format and duration to target value\nBasic modification type and data\nArrangement\nTrack End\nTrack Marker\nJump to Track\nGosub to Track\nEnds track playback\nAdditional entry points, sync points.\nJump to new track data\nJump to new track data, returns when done\nCallback\nCallback\nCalls game code, could change test values\nNote Control\nIt is pretty hard to make music without notes. Following the MIDI tradition, we asso-\nciate a key number and velocity with notes. The MIDI Note Off message includes a\nrelease velocity, but it is our option to include this for our sequencer.\nImmediate Modifications\nThese event types are quite similar to certain MIDI messages. This will make conver-\nsion from MIDI files for these events easy. These events also represent immediate\nupdates of synth hardware. Values may be absolute or relative depending on the event\ntype.\nTarget Modifications\nThese event types interpolate from current value to destination value over a given\ntime rather than changing settings immediately. Target modifications have the advan-\ntage of being able to describe a curve of parameter values with a single command\nrather than the many immediate modification commands needed to achieve the same\neffect.\nArrangement\nThese event types switch us to different sections of music data.\n",
      "content_length": 1635,
      "extraction_method": "Direct"
    },
    {
      "page_number": 522,
      "chapter": null,
      "content": "6.5 \nA Basic Music Sequencer for Games \n545\nCallback\nThese event types generate callbacks to functions that have been registered with the\nmusic sequencer.\nSequencer Data Structures\nThe abbreviated data structures that we could use for our music sequencer are listed\nin Listing 6.5.1.\nListing 6.5.1 Music sequencer data structures\ntypedef list< Sequence_t * > SequencePtrList_t;\ntypedef list< Track_t * > \nTrackPtrListjt;\ntypedef list< Voice_t * > \nVoicePtrList_t;\nclass MusicSequencer_t {\nMusicSequencerState_t State;\nSequencePtrList_t \nActiveSequencePtrList;\nSequencePtrList_t \nFreeSequencePtrList;\nTrackPtrList_t \nActiveTrackPtrList;\nTrackPtrList_t \nFreeTrackPtrList;\nVoicePtrList_t \nActiveVoicePtrList;\nVoicePtrList_t \nFreeVoicePtrList;\n};\nclass SequenceState_t {\nTempo_t Tempo;\nVolume_t Volume;\n};\nclass Sequence_t {\nSequenceState_t State;\nTimeUnit_t \nTimeElapsed;\nTimeUnit_t \nTimeStep;\nTrackPtrList_t TrackPtrList;\n};\nclass TrackState_t {\nVolume_t \nVolume;\nPitchBend_t PitchBend;\nPan_t \nPan;\nEffect_t \nEffect;\n};\nclass Track_t {\nTrackState_t \nState;\nSequence_t \n*pOwner;\nchar \n*pEvent;\nInstrument_t *plnstrument;\nVoicePtrList_t VoicePtrList;\n};\nclass VoiceState_t {\n",
      "content_length": 1171,
      "extraction_method": "Direct"
    },
    {
      "page_number": 523,
      "chapter": null,
      "content": "546 \nSection 6 Audio Programming\nSynthVolume_t Volume;\nSynthPitch_t \nPitch;\nSynthPan_t \nPan;\nSynthEffectjt Effect;\n};\nclass Voice_t {\nVoiceState_t \nState;\nTrack_t \n*pOwner;\nint \nnKey;\n};\nHere we show the MusicSequencer_t class that holds the lists of active and free\nsequences, tracks, and voices. We also see that sequences, tracks, and voices each have\na notion of state and some example parameters of those states are shown. A\nSequence_t has a TmckPtrList that holds the tracks owned by the sequence. A Track_t\nhas a VoicePtrList that holds the voices owned by the track. A Voice_t has zpOwner\nthat points to the track that owns the voice. A Track_t has apOwner that points to the\nsequence that owns the track. These parent and child data structures help us query\nand update information up and down our hierarchy, whether we are operating on\nsequences, tracks, or voices.\nEvent Data Structures\nTo implement the event type commands, we can have the event type command num-\nbers correspond to an array lookup that holds the relevant function pointer and the\nbyte length of the event type and parameters. Listing 6.5.2 shows this code. The func-\ntion pointers give us a quick way to get to the code associated with each event type.\nThe byte lengths give us a quick way to step to the next event block.\nListing 6.5.2 Event type data structures\n// Example Note Off Event Block\ntypedef struct {\nchar nEventType;\nchar nKey;\n//no release velocity\n} NoteOff_EventBlock_t;\nvoid NoteOff_Function( Track_t *pTrack )\n{\n// the pEvent is pointing at our event block\nNoteOff_EventBlock_t *pNoteOffEB =\n(NoteOff_EventBlock_t *)pEvent;\n// walk through this track's voices and turn off\n// any that have pVoice->nKey == pNoteOffEB->nKey\n}\n// Example Note On Event Block\n",
      "content_length": 1753,
      "extraction_method": "Direct"
    },
    {
      "page_number": 524,
      "chapter": null,
      "content": "6.5 A Basic Music Sequencer for Games \n547\ntypedef struct {\nchar nEventType;\nchar nKey;\nchar nVelocity;\n} NoteOn_EventBlock_t;\nvoid NoteOn_Function( Track_t *pTrack )\n{\n// the pEvent is pointing at our event block\nNoteOn_EventBlock_t *pNoteOnEB = (NoteOn_EventBlock_t *)pEvent;\n// try to get a voice from the free list or\n// try to get a voice from the active list if possible\n// if we have a voice, turn it on with the pNoteOnEB->nKey\n// and pNoteOnEB->nVelocity and other state information\nenum enumEventType\n{\nEVENT_TYPE_NOTEOFF ,\nEVENT_TYPE_NOTEON,\nEVENT_TYPE_COUNT\ntypedef void (*EventFuncPtr_t) (Track_t *);\ntypedef struct {\nEventFuncPtr_t pFunc; \n// pointer to command function\nint \nnLength; // byte length of command\n} EventTypes_t;\nstatic EventTypes_t aET[EVENT_TYPE_COUNT] = {\n{ NoteOff_Function, sizeof (NoteOff_EventBlock_t) },\n{ NoteOn_Function, sizeof (NoteOn_EventBlock_t) },\nHere we show that we can give each event type a number that can be used to call\nup an EventType$_t structure from an array. The EventTypes_t structure contains the\nfunction pointer to call for the given event type and the length of the command ID\nand parameters. Being able to define our own command numbers and have them cor-\nrespond to array entries like this provides an alternative to switch statements.\nThe Audio Frame and Update Interval\nDifferent computer systems have different ways of providing timing callbacks or\nthreads that wake up at specific intervals. I will simply assume that we can have a\nfunction called at a specific interval referred to as the audio callback. We can think of\n",
      "content_length": 1589,
      "extraction_method": "Direct"
    },
    {
      "page_number": 525,
      "chapter": null,
      "content": "548 \nSection 6 Audio Programming\nthe time between these callbacks as the audio frame. During each callback, we need to\nupdate our notion of how much time will pass during the next audio frame, and we\nneed to send out all of the commands that are due to occur over diis time.\nIndependent of the audio callback rate we will also have an update interval. The\nupdate interval determines the amount of time we will step when sending out low-\nlevel commands. For example, we could have an audio callback that occurs once every\nsecond with the update interval at 120 times a second, which would require stepping\nthrough 120 time intervals per callback. Another possibility is that we could have an\naudio callback that occurs 60 times a second with the update interval at 120 times a\nsecond, which would require stepping through two time intervals per callback.\nListing 6.5.3 is an outline of the audio callback code.\nListing 6.5.3 The audio frame\n// This function is called by the timer callback\nstatic void OSys_AudioCallback(void)\n{\n// protect against callback reentrance\n// determine the number of update intervals required\n//to deliver during this callback\n// begin critical section\nOSys_BeginAudioCriticalSection();\n// for the number of update intervals required on this frame\n// {\n// \niterate over sequences\n// \nperform per sequence operations\niterate over tracks\nperform per track operations\n//\n// \nsend low-level commands for this time step\n// \nmove to next time step\n// }\n// end critical section\nOSys_EndAudioCriticalSection();\n}\nSince our callback may happen while other code is executing, this means it might\nhappen when we are changing data structures for the music sequencer. We protect\nagainst this by using the critical section method specific to our operating system.\nTiming Calculations\nIn order to play our music data at different rates, we need to work out how to step\nthrough our music data based on three parameters: the music tempo, the update\ninterval, and the resolution of our music time format.\n",
      "content_length": 2014,
      "extraction_method": "Direct"
    },
    {
      "page_number": 526,
      "chapter": null,
      "content": "6.5 A Basic Music Sequencer for Games \n549\n• Music tempo is described in beats per minute (BPM).\n• The update interval is described in updates per second (UPS).\n• Music time resolution is described in parts per quarter note (PPQ).\nWe are looking for the amount of music time to increment for each audio call-\nback. We can call this parts per update (PPU).\nIf we consider beats per minute (BPM) to be the same as quarter notes per minute\n(QPM), then the equation is:\nPPU = QPM * PPQ* (I/UPS) * (lMinute/60Seconds)\nIf we store this PPU number as a 16.16 fixed point number, the final code is\n(Listing 6.5.4):\nListing 6.5.4 Time step calculation\nunsigned long CalcTimeStep( unsigned short qpm,\nunsigned short ppq,\nunsigned short ups)\n{\nunsigned long ppu;\nunsigned long temp;\ntemp = (unsigned long)qpm * (unsigned long)ppq;\nif( temp < 0x10000 )\n{\nppu = ((temp * 0x10000) / 60)\n/ (unsigned long)ups;\n} else {\nppu = ((temp / 60) * 0x10000)\n/ (unsigned long)ups;\n}\nreturn(ppu);\n}\nOur calculation here does a little range checking during the calculation to make\nsure that we obtain as accurate a 16.16 result as possible given that the input numbers\ncan range in value.\nWe recalculate the parts-per-update value any time that a sequence's tempo\nchanges. This parts-per-update value is placed in our TimeStep variable in our sequence\nstructure. Since these time parameters are in the sequence structure, we can only change\nthe tempo for the entire sequence. If we wanted to change tempo for each track indi-\nvidually, we could put these parameters and die tempo setting in the track structure.\nAudio Synthesis Control\nConnecting Synth to Sequencer\nAn important issue for our music sequencer implementation is how music event para-\nmeters are mapped to audio synthesis parameters. This is where music sequencer code\n",
      "content_length": 1806,
      "extraction_method": "Direct"
    },
    {
      "page_number": 527,
      "chapter": null,
      "content": "550 \nSection 6 Audio Programming\ncan get very platform specific. In order to keep the code as cross-platform as possible,\nI will call a software synthesizer interface from our sequencer code.\nOne important part of connecting our audio synthesis to our music sequencer is\nthe Setlnstrument event type. The Program Change parameters of Setlnstrument\nCommand is used as an index into a table of instrument definitions. The address of\nthis table entry is used to set the ^Instrument field of our Track data structure. When\na Note On command occurs, the parameters from the plnstrument are transferred to\nthe voice to be started. You can view these details in the accompanying source code.\nThe capabilities of the audio synthesis system that we are using will determine\ninstrument definition and even definition details. As a result, there will be certain\ntypes of control we will have available and music will have to be written with these\ncontrol issues in mind.\nThe Code\nThe example code on the CD-ROM shows how to play music using our custom\nmusic sequencer language. This includes how to step through the music data of each\ntrack of each sequence, and how to code the event types for a particular synth inter-\nface. Of the event type ideas presented, the code implements the NoteOn, NoteOff,\nSetPan, Setlnstrument, and TrackEnd commands.\n^|' c> 4 \nThe example code uses a cross-platform audio engine called CSyn. The CSyn\nON me CD \nlibrary provided on the CD-ROM is for demonstration purposes only.\nConclusions\nWe covered the details of a basic music sequencer. Important MIDI concepts have\nbeen presented, as well as our custom music language. Implementation details of data\nstructures, event types, and timing were presented. Finally, the code is there to play\nwith and customize for your own needs. Enjoy!\nReferences\nCSyn audio engine, www.softsynth.com/csyn.\n",
      "content_length": 1863,
      "extraction_method": "Direct"
    },
    {
      "page_number": 528,
      "chapter": null,
      "content": "6.6\nAn Interactive Music\nSequencer for Games\nScott Patterson\nscottp@tonebyte.com\nG\names are interactive. This means that a player has control over the game in some\nway, and the game asks the player to use his or her control to interact in some\nway. This control and interaction is the foundation of gameplay that is immersive and\nentertaining.\nIt is natural to want to mix the immersiveness of control and interaction in com-\nputer games with the immersiveness of music. How do we control music? How can\nwe create musical interaction? \"What kind of musical meanings can we generate? This\nis the motivation for this gem.\nBuilding on the concepts and code from the basic music sequencer, we now will\ndiscuss features that provide interactive control. Specifically, we will discuss the ability\nto modify parameters on the sequence level and track level.\nMaking interactive music can be viewed as controlling a puppet. We need to pull\nthe right strings to make it seem alive. And if we pull the right strings to control the\nway the music plays, we may even pull the emotional strings of our game player. In\norder to discuss what types of emotional strings might be available, we've generated a\nlist of associations and meanings that music can convey. We then cover transitions,\ntransition types, control granularity, and target control. Finally, we present a few\ndesign examples.\nMusical Associations\nMusic is its own form of entertainment. We listen for styles, attitudes, technology,\nimprovisation, composition, and skilled performances and interpretations. Our mem-\nories associate music with past situations, friends, and places. While some associations\nmay be personal and specific, others are quite common and generally accepted. We\nmay associate a particular song with a particular person. We may associate a particular\nstyle of music with a particular geographical location. We may associate the \"mood\"\nof some music widi love, hate, contentment, or anger (Table 6.6.1).\n551\n",
      "content_length": 1979,
      "extraction_method": "Direct"
    },
    {
      "page_number": 529,
      "chapter": null,
      "content": "552\nSection 6 Audio Programming\nTable 6.6.1 Music Associations\nCategory / Type\nAge Groups\nActivities\nCultures\nTime Periods\nLocations\nMood\nTension\nStrength\nReward\nDefeat\nDescription\nChildren, teenage, college, mature\nSports, chase, battle, puzzles\nThemes, styles, anthems\nHistorical, futuristic\nGeographical, magical, space exploration\nHumor, serious\nRelaxed, tense\nPowerful or weak\nPride, confident and energetic\nRidicule, goofy and taunting\nMusical Meaning\nIf we want our music to be interactive, we should know the different meanings that\nwe wish to convey with the music. Some of the meanings that we might want to\nattach to the control of music are categorized in Table 6.6.2.\nTable 6.6.2 Musical Meanings\nCategory / Type\nDescription\nSelf\nHealth\nPower\nSkill\nMood\nFamiliar\nOthers\nFriends\nEnemies\nLove\nHate\nFamiliar\nLocation\nSecrets\nHints\nSafety\nDanger\nMagic\nFamiliar\nWhat state is the player in?\nConfidence in the music.\nStrength in the music.\nSharpness and agility in the music.\nHeaviness or lightness in the music.\nMusic that is familiar to certain player states in the game.\nWhat state are nonplayer characters in?\nPleasing attitude in the music.\nHarsh attitude in the music.\nSweetness in the music.\nViolence in the music.\nMusic that is familiar to certain nonplayer character states in the game.\nWhat is our current location like?\nOccasional secret melodies or instruments play.\nSudden burst when looking the right way.\nEven, predictable music.\nIrregular, ominous music.\nChimes, and echoes, and sprinkles in the music.\nMusic that is familiar to a common location in the game.\n",
      "content_length": 1583,
      "extraction_method": "Direct"
    },
    {
      "page_number": 530,
      "chapter": null,
      "content": "6.6 An Interactive Music Sequencer for Games \n, \n553\nTable 6.6.2 (Continued)\nCategory / Type\nSituation\nSafety\nDanger\nMagic\nPreparation for Bartle\nTension\nAdrenaline\nTime is Running Out\nChallenge Level\nReward\nFailure\nFamiliar\nDescription\nWhat kind of situation are we in?\nEven, predictable music.\nIrregular, ominous music.\nChimes, and echoes, and sprinkles in the music.\nDrums of war. Mechanized beats.\nSharp tones and dynamic changes.\nTempo is up. Mechanized beats.\nTempo is up. Chaotic passages.\nComplicated layering, added effects.\nTriumphant music.\nWhimpering or taunting music.\nMusic that is familiar to a common situation in the game.\nTransitions\nTransitions can be defined as one or more changes occurring over a time interval. A\ntransition might mean an interpolation of some type of state data done over a specific\ntime interval. In addition, a transition might mean a new track section, musical\ncadence, key change, or other compositional technique. A transition could be a com-\nbination of these things.\nTransitions may be triggered by a combination of game logic and music language\nlogic. It is useful to provide API functions for game code to directly set target states.\nThese types of implicit and explicit controls over transitions are another key element\nof the interactive control of music.\nTransition Types\nSome of the many transition types are mentioned in Table 6.6.3.\nThe simplest way to use music interactively is to simply switch music. If we have\none composition that is considered traveling music, and one composition that is con-\nsidered battle music, then when we stop traveling in the game to have a battle, the\nmusic switches at the same time. This type of musical interactivity is very common\nand very useful. We could even use a basic music sequencer to simply stop one tune\nand start another. If we want our transitions between tunes to be more musical or sub-\ntle, then we need more sophisticated functionality from our music sequencer. We\nmight want to overlap the two tunes so that one is heard to be fading off as the other\nfades in. We might want to have the tunes synchronized in some way as they go\nthrough this transition.\nTo use music interactively is not the same as making interactive music. This would\nmean that we actually change the character of a music composition through various\ncontrol methods. What if we want to gradually switch the timbres of instruments in\n",
      "content_length": 2410,
      "extraction_method": "Direct"
    },
    {
      "page_number": 531,
      "chapter": null,
      "content": "Section 6 Audio Programming\nTable 6.6.3 Music Transition Types\nTransition Type\nDescription\nQuick\nSlow\nFading\nIntensity\nEffects\nKey\nChord\nHarmony\nMelody\nAccompaniment\nPercussion\nTransposing\nLayering\nFills\nRhythmic\nRandomness\nInstrument\nTiming\nMusic that stomps on previous music\nSubtle alterations and state changes\nFading whole sequences or just some tracks\nInstrument dynamics\nAny synthesis parameter changing\nCompositional changes\nCompositional changes\nCompositional changes\nCompositional changes\nCompositional changes\nCompositional changes\nCompositional changes\nCompositional changes\nEnter from any beat position, push music decoration events in to a queue\nLagging, ahead, modified swing\nControlled randomness of varying parameters\nSwitching instruments\nSwitching tempo\nthe music to make it seem more dangerous? What if we also want to gradually change\nthe mix of the music to emphasize our new instrument timbres and bring up the per-\ncussion? Now we are talking about interactive music. If we can design manageable\nways to control this complexity, we will have something pretty impressive.\nControl Granularity\nThe many ways to define and control volume are a great example of the levels of gran-\nularity available for music parameters. These volume control types are listed in Table\n6.6.4.\nWe can see that there can be many levels of control for certain audio parameters.\nWe might even want to group controls. It is useful to define the set of track volumes\nin a sequence as a mix. We can then command a sequence to switch to a given mix\ndefinition either immediately or gradually. We might want to externally control\nsomething like a sequence volume to turn it down while a character is talking. In\naddition, we might want to set up internal relationships such as ducking one\nsequence's volume when another sequence is playing.\n",
      "content_length": 1834,
      "extraction_method": "Direct"
    },
    {
      "page_number": 532,
      "chapter": null,
      "content": "6.6 An Interactive Music Sequencer for Games \n555\nTable 6.6.4 Volume Types\nVolume Controls\nMaster\nMusic\nSequence\nTrack\nInstrument\nNote\nVoice\nDescription\nControls all audio.\nThe music volume controls all musical sequences.\nA sequence volume can be used to do fade in or fade out or ducking.\nEach track of a sequence has a volume. It is useful when creating music to be able\nto define the balance between tracks and to control crescendo and decrescendo.\nInstrument definitions may include volume. When defining instruments, we may\nwant a volume control so that the instrument can be programmed to have similar\nvolume range characteristics as other instruments.\nThe velocity parameter of a note. It is useful when creating music to have this\nbuilt-in volume control per note.\nThe value we pass to a particular synthesis voice. This value is determined from a\ncombination of the other volume types.\nTarget Control\nWhen we switch any parameter, we may want to do so immediately or gradually. To\nchoose the gradual behavior, we set a target volume and timeframe for the transition.\nInternally, the parameter is interpolated from its original level to its target level over\nthe given timeframe.\nWhen audio synthesis is involved, even if you are setting immediate parameter\nvalues, the internal synthesis behavior might actually result in a quick interpolated\ntransition from the original value to the \"immediate\" value over a short period of\ntime. In addition, some synthesis parameters might only allow modification before a\nvoice has been turned on and not while it is playing.\nThe abbreviated data structures for our music sequencer with new target controls\nare shown in Listing 6.6.1\nListing 6.6.1 Sequencer data structures with target control\ntypedef list< Sequence_t * > SequencePtrListjt;\ntypedef list< Track_t * > \nTrackPtrList_t;\ntypedef list< Voice_t * > \nVoicePtrList_t;\nclass MusicSequencer_t {\nMusicSequencerState_t State;\nSequencePtrList_t \nActiveSequencePtrList;\nSequencePtrList_t \nFreeSequencePtrList ;\nTrackPtrList_t \nActiveTrackPtrList ;\nTrackPtrl_ist_t \nFreeTrackPtrList;\nVoicePtrList_t \nActiveVoicePtrList ;\nVoicePtrList_t \nFreeVoicePtrList;\nclass SequenceState_t {\n",
      "content_length": 2179,
      "extraction_method": "Direct"
    },
    {
      "page_number": 533,
      "chapter": null,
      "content": "556 \nSection 6 Audio Programming\nTempo_t \nTempo;\nVolume_t Volume;\n};\nclass Sequence_t {\nSequenceState_t \nState;\nSequenceState_t \nTargetState; \n// Interactive feature\nSequencelnterpolator_t Interpolator; \n// Interactive feature\nTimeUnit_t \nTimeElapsed;\nTimeUnit_t \nTimeStep;\nTrackPtrList_t \nTrackPtrList;\n};\nclass TrackState_t {\nVolume_t \nVolume;\nPitchBend_t PitchBend;\nPan_t \nPan;\nEffect_t \nEffect;\n};\nclass Track_t {\nTrackState_t \nState;\nTrackState_t \nTargetState; \n// Interactive feature\nTracklnterpolator_t Interpolator; \n// Interactive feature\nSequence_t \n*pOwner;\nchar \n*pEvent;\nInstrument_t \n*plnstrument;\nVoicePtrl_ist_t \nVoicePtrList;\n};\nHere we show new additions to our sequence and track data structures that allow\nus to interpolate from our current states to new target states. The TargetState and Inter-\npolator members define what the target values are and how fast to step toward them.\nDesign Examples\nThere are four important factors in the discussion of interactive music: game design,\ngame programming, music design, and music programming. Music programming is\ninfluenced by the other factors in the following ways:\n• Game design will influence music design.\n• Music design will influence music programming.\n• Game design will influence game programming.\n• Game programming will influence music programming.\nTo point out these influences, I will describe some interactive music design examples.\nDesign Example #1\nGame design: Through player skill, a character can achieve a powered-up state. This\nstate can last a very long time and a sound effect might get monotonous. We\nwant to hear his energy in the music.\n",
      "content_length": 1629,
      "extraction_method": "Direct"
    },
    {
      "page_number": 534,
      "chapter": null,
      "content": "6.6 An Interactive Musfc Sequencer for Games \n557\nMusic design: Transition the melody and percussion track instruments to add DSP\neffects that add color and depth to the instruments.\nProgramming design: Two sequence states are created, and the game can choose\nwhen to set each target state.\nSummary: The music responds to the player's attributes. This way, the music tells\nthe player how he or she is doing.\nDesign Example #2\nGame design: When our player goes near a dangerous location in a level, we may\nwant to hint at that approaching danger, using the music to do so.\nMusic design: Fade down the main melody track and fade up die danger melody track.\nProgramming design: Based on distance from the location, set the track target\nstates for volume.\nSummary: The music responds to the player's location. This way, the music tells the\nplayer that there are new things to expect from this place.\nDesign Example #3\nGame design: Let's say we have a game design where we change from day to night.\nAssuming that the player's role is more offensive in the day and more defensive\nat night, we'll want energy music during the day, and tense and scary music at\nnight.\nMusic design: To keep it simple, we will describe three tracks of the music: melody,\naccompaniment, and percussion. We will define \"energy,\" \"mellow,\" and\n\"creepy\" versions of each of the three tracks. Again, keeping it simple, we will\ndefine \"energy,\" \"mellow,\" and \"creepy\" versions of each of the instruments for\neach track.\nWe could describe our transition table like Table 6.6.5.\nStop at each column in the table and you can see a different stage of the music.\nWe can consider each column a keyframe for our music control parameters. We can\nuse the control value shown to interpolate between the keyframes.\nTable 6.6.5 Day-to-Night Transitions\nGame Time\nControl Value\nMelody Track\nMelody Instrument\nAccompaniment Track\nAccompaniment Instrument\nPercussion Track\nPercussion Instrument\n12noon\n0.0\nEnergy\nEnergy\nEnergy\nEnergy\nEnergy\nEnergy\n3pm\n0.25\nEnergy\nMellow\nMellow\nEnergy\nEnergy\nEnergy\n6pm\n0.50\nCreepy\nMellow\nMellow\nMellow\nEnergy\nEnergy\n9pm\n0.75\nCreepy\nCreepy\nMellow\nCreepy\nMellow\nMellow\n1 2midnight\n1.0\nCreepy\nCreepy\nCreepy\nCreepy\nCreepy\nCreepy\n",
      "content_length": 2212,
      "extraction_method": "Direct"
    },
    {
      "page_number": 535,
      "chapter": null,
      "content": "558 \nSection 6 Audio Programming\nProgramming design: We generate our control value based on the game time. This\ncontrol value is used to interpolate between instrument states and track states.\nTherefore, when our game time reaches 3 P.M., the melody instrument has fully\ntransitioned to the \"mellow\" state. When our game time reaches 6 P.M., the\n\"energy\" melody track has faded down and the \"creepy\" melody track has faded\nup.\nSummary: The music responds to the game state. This way, die music tells the\nplayer something about how to play die game, or how the game is progressing,\nor what to expect next.\nThe Code\nBuilding on die code presented in the basic music sequencer gem, die example code\nshows how to play music that can be interactively modified to new target states.\nThe example code uses a cross-platform audio engine called CSyn. The CSyn\nlibrary provided on the CD-ROM is for demonstration purposes only.\nConclusion\nThe reasons for developing your own interactive music sequencer code are the same as\nthe reasons for any code development. You may want standard features across many\nplatforms. There may not be systems available that meet your needs. You may want\nan implementation that you can optimize for delivering the particular features you\nneed. You may want control over your own code to provide improvements, enhance-\nments, and reliability in line with internal scheduling requirements.\nIn this discussion, we covered many motivations and implementation ideas for\ninteractive music. We presented some core programming concepts that can give us the\nflexibility and control we need. We pointed out the design influences, meanings, and\ntransition types. The next thing to do with all of these ideas is to implement your own\ninteractive music sequencer and make sure interactive music is part of your game's\ndesign.\nReferences\nCSyn audio engine, www.softsynth.com/csyn.\n",
      "content_length": 1888,
      "extraction_method": "Direct"
    },
    {
      "page_number": 536,
      "chapter": null,
      "content": "6.7\nA Low-Level Sound API\nIan Lewis, Acclaim Studios\nilewis@acclaim.com\nT\nhis gem describes a platform-independent, low-level sound API suitable for\ngames. This API could be a wrapper for DirectSound, OpenAL, or console-\nspecific APIs. A DirectSound reference implementation is provided on the CD.\nThe goal of the API is to provide a platform-independent, extensible API in C++.\nThe basic functionality must support:\n• Hardware-accelerated mixing\n• Software mixing and processing\n• One-shot and looping sounds\n• Wave caching\nIn addition, each feature must be extensible to support new platforms and features.\nCore Classes\nCWave \nWraps a wave audio source. Waves are always accessed indirectly\nby the output stage, so they can be cached and reused.\nCWavePtr \nIterator class for indirectly accessing a CWave. CWavePtr's main\nfunction is to fill a user-supplied buffer with bytes from the wave\nto which it points. CWavePtr maintains a current position and a\nloop flag to make sure the bytes come from the correct place in\nthe wave.\nThe base class is fully functional, but it can be extended if\nextra processing is needed. For instance, you might extend\nCWavePtr to convert a 16-bit PCM input source into floating-\npoint data, or to convert an ADPCM-encoded source into\nstandard PCM. CWavePtr can also be extended to provide\nplatform-specific memory functions. For instance, some console\nplatforms contain both areas of memory that are directly CPU-\naccessible, and memory areas that cannot be directly accessed by\nthe CPU. A CWavePtr-derived class might automatically move\nmemory from non-CPU-accessible to CPU-accessible RAM.\n559\n",
      "content_length": 1628,
      "extraction_method": "Direct"
    },
    {
      "page_number": 537,
      "chapter": null,
      "content": "560\nSection 6 Audio Programming\nCMixer \nEncapsulates channel allocation and updating. Has a virtual\ntick() routine that should be called once per frame. (This is\nperhaps less elegant than running the mixer on a separate thread,\nas DirectSound does, but threads are hardly cross-platform...\nand since most threading OSs have a thread timeslice that is\ngreater than the length of a 60-Hz frame, threading can often\ncause more problems than it solves.)\nThe mixer can be extended to handle various hardware\narchitectures. The base class mixer does not allocate any memory\nfor channels, since derived class mixers may want to use their\nown channel implementations.\nCMixer: :channel \nThe base channel class is tightly coupled with CMixer, so it's\nimplemented as an inner class. Channels are responsible for\nmanaging a CWavePtr, which is the input to that channel. The\nchannel class extracts data from the CWavePtr on demand, keeps\ntrack of whether the CWavePtr is still playing or has (in the case\nof one-shot sounds) finished, and deletes the CWavePtr when it\nis done\nThe channel class can also be extended to meet varying\nneeds. The sample source for this article contains\nimplementations for a DirectSound accelerated channel and a\nsoftware-based mixer channel.\nCMixer-channel also contains a virtual tick() function,\nwhich is called from the base CMixer: :tick(). This allows\nplatform-specific channel implementations to perform hardware\nhousekeeping. For instance, the\nCDirectSoundAcceleratedChannel implementation uses tick() to\napply the channel's gain and pan parameters to the hardware\nbuffer\nCAudioBufTer \nEncapsulates a pointer to audio data and a length. Used to pass\ndata around the system.\nCWaveDesc \nEncapsulates a platform-independent wave description. It\nstrongly resembles Microsoft's WAVEFORMATEX, but contains\nsome extra fields for platform independence.\non me co\nThe sample source on the CD contains implementation classes for various\nDirectSound-based classes, showing how hardware acceleration, software mixing, and\nDSP-style processing can be worked into the base classes. This implementation is, of\ncourse, not optimized and is written more for readability than for performance.\n",
      "content_length": 2198,
      "extraction_method": "Direct"
    },
    {
      "page_number": 538,
      "chapter": null,
      "content": "APPENDIX\nAbout the CD-ROM\nThe CD-ROM that accompanies this book contains a wide variety of useful informa-\ntion designed to make your life easier as a game developer. Here are some of the things\nthat are included on the disc:\n• All of the gem source code listed in the book\n• Demos of many of the techniques described in the book\n• The DirectX SDK\n• The glSetup Monolithic version\n• The OpenGL Utility Toolkit (GLUT)\n• High-resolution versions of the color plates\n• Links to useful and interesting game development sites\nComplete installation and usage instructions are included on the CD-ROM in\nthe AboutThisCD.htm file. Please read this first.\nAlso, be sure to visit the Web site www.GameProgrammingGems.com, for more\ninformation about the series and about game programming!\n561\n",
      "content_length": 781,
      "extraction_method": "Direct"
    },
    {
      "page_number": 539,
      "chapter": null,
      "content": "Index\nA* algorithm, 250\npathfinding and, 315, 325\nwaypoints and, 315\nAbstract interfaces\ndescribed and defined, 20-22\ndisadvantages of, 26-27\nfactories, 22-23\nas traits, 23-26\nvirtual destructors, 23\nAccidental complexity, 258-259\nAlgorithms\nA* algorithm, 250, 315, 325\nBloom Filter algorithm, 133\ncollision detection, 228-238\ncombinatorial search algorithms, 354\nline / line intersection, 191\nMarching Cubes algorithm, 229\nrandom number generator algorithm, 130\nRecursive Dimensional Clustering (RDC), 228-238\nAliasing\nbilinear filtering and, 485\n\"pre-jitter\" technique, 485—486\nshadows and aliasing problems, 484-486\nAlignment, flocking rule, 330\nAllocateMemoryO routine on CD, 67\n\"Alt-Tab\" problem, 82-83\nAnimation\nbone animation keys, 148\nclouds, procedural texture generation, 463-473\nmesh deformation and skin calculation, 149\nprojective self-shadowing techniques for characters,\n421-424\nsimple animation scheme, 429-431\nSuper Mario 64 controls, 431\nsystem time and smooth animation, 148\nthird-person control schemes for, 425-432\n3ds max skin exporter and animation toolkit,\n141-152\nSee also Bones\nAPI functions, explicit DLL loading and, 36\nArtificial Intelligence (AI)\naccidental complexity, 258-259\narchitecture, 251-272\nbehavioral module, 266\ndecision making and intelligent agents, 287\ndistributed processing, 253\nemergent behavior to avoid scripting, 255\nevent-driven behaviors, 251-252\nflocking, 330-336\nfuzzy logic, 343-350, 347\nfuzzy state machines (FuSM), 337-341\ngame programming vs. academic research,\n249-250\ninfluence mapping, 287-297\ninnovations in, 256\nLevel-of-DetailAI,254\nmanager entities and centralized cooperation,\n252-253\nneural networks, MLPs, 351-357\npathfinding, 152, 252, 274-275\npersonalities and, 306, 332-333\npolling, 251-252\nprecomputing and preprocessing, 255\nproblem solving shortcuts, 254\nprocessing issues, 253-254\nprocessing peaks, avoiding, 253\nreal-time strategy issues, 272-306\nredundant calculations, reducing, 252\ntactical decisions, 287-316\nterrain reasoning, 307-316\nupdating data, 255-256\nSee also Micro-threads, AI architecture\nArtificial Life by Steven Levy, 335\nAudio design patterns\nBig Ball of Mud (spaghetti code) audio design\npattern, 518-519\nbridge audio design pattern, 514-515\ncommand audio design pattern, 517\ncomposite audio design pattern, 515-516\ndecorator audio design pattern, 517\nfacade audio design pattern, 515\nmomento audio design pattern, 518\nobserver audio design pattern, 518\nproxy audio design pattern, 516\nAudio processing pipelines, interactive, 529-538\nbackfill buffers in, 534-537\n563\n",
      "content_length": 2563,
      "extraction_method": "Direct"
    },
    {
      "page_number": 540,
      "chapter": null,
      "content": "564\nIndex\nAudio programming\naudio design patterns, 514-520\nDigital Signal Processing (DSP) techniques,\n525-528\ninteractive processing pipeline for digital audio,\n529-538\nlow-level sound API, 559-560\nmusic sequencers, 539-558\nsample-based synthesizer for voices, 521-524\nAudio systems\ndescribed, 529-531\nschematic illustration of, 530\nAuthors, bios and contact information for, xix-xxxfi\nAvoidance, flocking rule, 330\nAxis-aligned bounding box (AABB) tree structures\nbuilding AABB trees, 390\ncompressing AABB trees, 390-391\ndescribed, 388\nextent value approximation, 391\nredundancy in, 392\nresources required, runtime costs, 393\nAxis-aligned bounding boxes, 389\nBackfill buffers for underflow data, 534-537\nBand-limited noise, 466\nBehavioral classes, 53\nhierarchy for, 54-55\nBehaviors\nactive behaviors and brain classes, 267\nAI design and, 265-268\nbehavioral module example, 266\nCombs method and fuzzy logic for, 342-350\nemergent behaviors, 255, 332-333\nevent-driven behaviors for AI optimization, 251-252\nflocking, 330-336\nTemplate Method pattern for assigning, 55\nBinary space partitioning (BSP) trees, 388\nBit maps and bit mapping, fast bit blitter for, 92-99\nBlitters, 92-99\nBloom, Burton H., 133\nBloom Filters, 133-140\ndefinitions related to, 134-135\ndescribed, 134\nexceptions lists and, 139-140\nflow chart illustrated, 136\ntuning, 135-138\nuse fundamentals, 137\nBlurring\nSee under Influence maps\nBones\nbone animation keys, 148\nbone assignments, 150-151\nposition and rotation of, 148-149\nsegmenting character geometry and, 421—422\nweighting, 146-148\nBoolean values, text parsers, 115\nBottlenecks, profiling module for identifying, 74-79\nBounding volume trees, 389\nBounds violations, defined and described, 69\nBrains\nbrain classes, 267-269\nbrain queues and cyclic commands, 274-278\nBridge audio design pattern, 514-515\nBSP (binary space partitioning) trees, 388\nBuffers\nbackfill buffers for underflow data, 534-537\nindex buffers, 372-375, 378-379\npriority buffers vs. depth buffers, 483\npriority buffers described, 483\npriority buffers used for shadows, 481-487\nBugs and debugging\nabstract interfaces and, 26\ncode bloat and, 11\ndeprecated functions and, 63\ndrop-in debug memory manager, 66-73\nOutputDebugString (), Windows NT, 263\nreproducing bugs, 105-106\nstructured exception handling and micro-threads,\n263\nC++\ndeprecation facilities for, 62-65\nexporting classes from DLLs, 28-32\nimplicit linking support in, 33-34\noptimization techniques, 5-15\nproperty class for generic member access, 46-50\nrecursive searching, 89-90\nstack winding and, 88-90\nCache misses, 18\nCallbacks, 545, 547-549\nCamera cuts, 220, 225-226\nCameras\ncamera cuts, 220, 225-226\nflythrough paths for, 220-227\nfree-floating cameras, 425\nimpostoring and camera distance, 494\nlens-flare effects, 474-480\norientation interpolation, 222-223\nposition interpolation, 220-222\nweb cameras, 153-162\nCartoon rendering\nprogrammable vertex shaders and, 444-451\nsilhouette edge detection and, 436-443\ntexture mapping and, 444-451\nCaustics, simulating water in a fish tank, 402-405\nCellular automata, 506-508\n",
      "content_length": 3066,
      "extraction_method": "Direct"
    },
    {
      "page_number": 541,
      "chapter": null,
      "content": "Index\n565\nChild classes, data 43-44\nCiphers as mixing functions, 129\nClasses\nexporting from DLLs, 28-30\nSee also Specific classes\nClass member functions, exporting from DLLs, 30-31\nClosed-form equations, used to calculate nearest points\non lines, 194-198\nClouds\nadditional features for procedural clouds, 470-471\ncharacteristics of, 463-464\nFBM fractals used to create, 245\nmapping to skyplane, 469-470\nprocedural cloud generation, 463-473\nrandom number generation and, 464-465\nscalability of procedural generation techniques,\n471-472\n\"vapor\" creation, 469\nClutter. See Impostors\nCode bloat, 11-12\naccidental complexity in AI, 258-259\ninline functions and, 18\nCohesion, flocking rule, 330\nCollision detection\naltitude relative to collision plane, 182-183\nbrute-force comparison algorithm for, 228\ndistance to collision point, 184-185\nfinding pairs with RDC, 234-235\nkickback collisions, 187-188\nline / line intersections, 191-204\nlocation of collision point, 183-184\nRecursive Dimensional Clustering (RDC), 228-238\nreflected vectors (bounces), 185-187\nvector / plane intersections, 182-190\nSee also Collisions\nCollisions\nwith damping, 188-190\npathfinding and, 317-323\nsphere-to-plane collisions, 189-190\nSee also Collision detection\nCollision shapes, selecting, 318-321\nCombs, William, 343\nCombs Method for managing exponential growth,\n343-349\nproof for, 348-349\nCOM interface search, alternatives to, 46-50\nCommand audio design pattern, 517\nCommand queues, audio design and, 517\nComposite audio design pattern, 515-516\nComputation, history and development of, 165-166\nConstructors\nexplicit vs. implicit, 8\noptimization and, 7-8\nControl schemes\ncamera-oriented controls, 425\ncharacter rotation and input, 427—428\nconverting player's input for third-person control\nsystems, 425-427\ndampening formula for smooth character control,\n427-428\nsimple animation scheme, 429-431\nthird-person control of animated characters,\n425-432\nConvolution, 526-527\nConway, John, 506\nCore editor modules, generic, 46—50\nCosine functions, lookup tables for, 174-175\nCramer's rule, 196-197\nCreational dependencies, 302-304\nCryptographic hashes as mixing functions, 129\nCube environment mapping, 419\nCubemap normalization, 459-460\nCubic interpolation, DSP techniques, 528\nCulling, sphere trees for, 384-387\nCycle counters, 180\nDampening formula for smooth character control,\n427-^28\nDatabases\ngame save databases and persistent type information,\n44\ntweakable instance database, 123-124\nData files, preprocessing, 113-114\nDeAllocateMemoryO routine on CD, 67\nDebugging. See Bugs and debugging\nDecals\nalgorithm for, 41 I^il3\non complex surfaces, 411-415\ndefined, 411\ntriangle clipping and, 413-414\nDecorator audio design pattern, 517\nDependency\ncreational dependencies, 302-304\nand resource allocation trees, 302-304\nvulnerable dependencies, 304-305\nDEPRECATE macro, 64-65\nDeprecation\nadding facilities to C++, 62-65\nimplementation of, 64-65\nDesirability values, 290-292\nDestructors, virtual destructors in abstract interfaces,\n23\nDeterminism\ndefined, 105\nrandom numbers and, 109\nSee also Predictability\n",
      "content_length": 3076,
      "extraction_method": "Direct"
    },
    {
      "page_number": 542,
      "chapter": null,
      "content": "566\nIndex\nDigital Signal Processing (DSP)\nconvolution, 526-527\ncubic interpolation, DSP techniques, 528\ndelays, 527\nfiltering technique, 525-526\ninteractive audio processing pipeline, 529-538\ninterpolation, 528\nlinear interpolation, DSP techniques, 528\nreverberation effects, 527\nsample averaging, DSP interpolation, 528\nsample doubling, DSP interpolation, 528\nDigital Signal Processing (DSP) techniques, 525-528\nDirectX, DLLs and required components, 34—36\nDLLs. See Dynamic Link Libraries (DLLs)\nDot3 Bump mapping, 456—459\nDrop-in debug memory manager\nlogging, 68-70\nmemory allocation and deallocation routines, 67-68\nreports from, 70-71\nDynamic_cast operator, 42\nDynamic Link Libraries (DLLs)\nAPI functions, 36\nclass member functions, exporting, 30-31\nDirect X components and, 34-36\nexplicit vs. implicit linking and, 33-34\nexporting C++ classes from, 28-32\nFreeLibrary, 34\nGetProcAddress, 34-36, 37\nLoadLibrary, 34, 37\nmemory-tracking programs and, 29\nOS specific features, 36-37\nvirtual class member functions, exporting, 31-32\nDynamic type information (DTI) class\ndescribed, 38-39\nexposing and querying, 39-40\ngeneric objects and, 41-43\ninheritance and IsA function, 40-41\nEconomic systems, resource allocation trees and, 302,\n304\nEdge collapse, binned vertices, 365\nEdge detection, 502\nsilhouette edge detection and rendering, 436—443\nEdge split, defined, 365\nEfficiency. See Optimization\nEmergent behaviors, 255, 332-333\nEncryption, 104\nEntities\ndeath of entities, AI management strategies, 269-270\nEntity class and subclass, 54-55\nentity managers and cooperation among AI agents,\n252-253\nruntime strategies for, 58-60\nException lists, 139-140\nExponential growth, Combs Method to manage,\n343-349\nExported classes, 50, 56-57\nFacade audio design pattern, 515\nFactories\ndefined and described, 57-58\nEntity factories, 57\ngame entity factory, 51-61\nFactories, abstract interfaces and, 22-23\nFBM (fractal brownian motion) fractals. See Fractal\nbrownian motion (FBM) fractals\nFibers, cooperatively multi-tasking threads, 260\nFile lump structure, 101\nFiles, management using resource files, 100-104\nFilters and filtering\nbilinear filtering and aliasing, 485\nBloom Filters, 133-140\nFinite Impulse Response (FIR) filters, 525-526\ntexture filtering, 418, 479\nFinite Impulse Response (FIR) filters, 525-526\nFish tanks, simulating refraction effects in, 402-405\nclip planes and stencil buffer, 404-405\nprecomputations, 403\nscale factor for tank, 403—404\nshear factor for tank, 404\nFixed Up method vs. parallel transport frames, 218\nFloating-point numbers\nabsolute values, 174\narbitrary functions, 177-179\nclamping values to a specific range, 173—174\ndefined, 167\nfloat/int conversions, 169-172\nIEEE floating-point format, 168-169\ninitial state variations and, 108\ninteger comparisons, 173\nIntel architecture and, 261\nlinear quantization, 178\nlogarithmic quantization, 178-179\nperformance measurement after optimization, 180\npropagated influence values and, 293\nsign test for, 172\nsquare root optimization and, 176-177\ntext parsers, 115\nFloats. See Floating-point numbers\nFlocking, 330-336\nboids, varieties of, 332-333\nrules of, 330-331\nFlocking with Teeth demo, 334\nFlythrough paths\nnatural cubic splines and, 221-222\nquaternion-based flythrough paths, 220-227\n",
      "content_length": 3256,
      "extraction_method": "Direct"
    },
    {
      "page_number": 543,
      "chapter": null,
      "content": "Index\n567\nFlyweight classes, 53\nFlyweight objects\ndescribed, 52\nState And Media Manager (SAMMy), 52-54\nFog-of-War (FOW)\ndefined, 280\nvisibility and, 279\nFormats\nfast bit blitter for conversion of, 92-99\nMRC file format for exporting, 142-143\nFractal brownian motion (FBM) fractals\nclouds created with, 245\ndescribed, 241-242\nlandscapes created with, 245\nnoise generator implementation, 242-245\nturbulent noise function, 467\nFractals\ndefined, 239\nfault fractals, 240-241\nmultifractals, 244-245\nplasma fractals, 240\nprogramming, 239-246\nterrain creation, 239, 246\nSee also Fractal brownian motion (FBM) fractals\nFreeQ, 9\nFreeLibrary, 34\nFree lists, memory management and, 9\nFrenet Frames vs. parallel transport frames, 217-218\nFunction pointers, used within C++ classes, 59—60\nFunctions\nchaining and TempRet routine, 86-87\ndeprecated functions, 62-65\nexporting from DLLs, 28\nFuzzy logic\ncombinatorial explosions and, 342-350\nCombs Method and, 343, 348-349\nCombs Method rules for, 344-348\ndefined, 337\nsets in, 342\ntraditional rules for, 343-344\nvariables in, 342\nFuzzy state machines (FuSM), 337-341\nadapting generic FSMs, 339-341\nincreasing gameplay with, 338-339\nuses in games, 339\nGame engines\ndata-driven development, 51-61\nGPU / CPU parallelism, 475\ninput recording and, 105-111\n\"Game of Life,\" 506-508\nGaussian elimination, 196-197\nGenRandQ, 131-132\nGeometry management of 3D models\naxis-aligned bounding box (AABB) trees and,\n388-393\ncube environment mapping, 419\ndecals on complex surface, 411-415\nprojective self-shadowing techniques, 421-424\nquadtree lookup, direct access, 394—401\nsegmenting character geometry, 421-422\nskyboxes and distant scenery, 416-420\nsphere trees and, 384-387\nterrain creation with interlocking tiles, 377-383\nVIPM methods, comparison of, 363-376\nGetProcAddress function, 34\nGraphical User Interfaces (GUIs), tweaker interface\nGUI, 124-125\nGraphics display\nhardware accelerated procedural texture animation\nand, 497-509\nhardware limitations and, 508\nimpostoring, 488^496\nlens flare using texture masking, 474-480\nper-pixel lighting techniques, 452—462\npipeline stalls, 475-477\nprint-resolution of screenshots, 406-410\nsilhouette edge detection and rendering, 436-443\ntexture mapping and programmable vertex shaders,\n444-451\n/GR switch, 42\nGUIDs, text parsers, 116\nHandles, used in proxy audio design, 516\nHardware\ncloud generation with, 463-473\ndisadvantages when used for procedural textures, 471\nprocedural rexture animation and, 497-509\nrendering print-resolution screenshots with, 406-410\nas source for random numbers, 129\nHashing functions, 129, 134\nHash Table template, 48\nHeader files, 101-102, 113-114\nHeight advantage, as tactical assessment factor, 296\nHerding. See Flocking\nHierarchies\nBehavior class hierarchy, 54-55\nof C++ classes, method for describing, 51-61\nIEEE floating-point format, 168-169\nImpostors\nbillboard quad rendering, 490\nbounding object rendering, 491-492\ncamera distance and updates, 494\ncuboid rendering, 490-491\ndescribed, 488\n",
      "content_length": 2992,
      "extraction_method": "Direct"
    },
    {
      "page_number": 544,
      "chapter": null,
      "content": "568\nIndex\nImpostors (cont.)\ngame-specific updates, 494\nimage warping and, 492\nlighting and updates, 494\nprediction of impostor states, 495\nrendering, 489-493\nupdate heuristics, 493-494\nuses of, 495-496\nviewing angles and updates, 494\nIncrement functions, optimization and, 7\nIndex buffers\nin sliding window VIPM, 372-375\nas tile templates, 378-379, 380\nInfluence maps\nAI optimizations, 256\ncell data types, 289-290\ncell size, determining optimal, 292\ndescribed, 287-289\ndesirability values, 290-292\nfalloff rules, 292-293\ninfluence propagation (smoothing or blurring),\n292-293\nrefreshing influence maps, 295-296\nterrain and impacts on, 293-297\nin 3D environments, 296\nInheritance\nabstract interfaces as traits and, 23-26\nIsA function and dynamic type information (DTI)\nclass, 40-41\nmultiple inheritance, 45\nInitializer lists, 6-7\nInking for nonphotorealistic rendering\nadvanced texture features and inking, 442\nedge-based inking, 438-440\ninking described, 436-437\nprogrammable vertex shader inking, 440-442\nInline functions, 11-12\nadvantages of, 16-18\ncode bloat and, 18\nvs. macros, 16-19\nparameter types and, 18\nInline keywords, Microsoft specific keywords, 19\nInlining. See Inline functions\nInput recording\nbug reproduction with, 105-106\ngame movie creation, 107\nmeasuring optimization with, 107\nmultiplayer uses of, 107, 110\npredictability and, 107-108\nreplaying interesting games, 106\ntesting techniques for, 110\nuses of, 105-107\nInputs\nconverting player's input for third-person control\nsystems, 425-427\nrandom number generators and, 128-129\nInstruction pointers, 260-261\nIntegers\ninteger / float conversions, 169-172\ntext parsers, 115\nInteraction\ninteractive audio processing pipeline, 529-538\ninteractive music sequencer, 551-558\nweb-cams for multiplayer games, 153\nInterface functions, deprecation facilities and, 62-65\nInterpolation\ncubemap normalizer to correct problems, 459-460\ndefined, 527\nDSP and linear interpolation, 528\nspline interpolation technique, 224-225\nvectors across line or plane, 189\nIntersections, techniques for calculating, 191-204\nIsA function, dynamic type information (DTI) class\nand inheritance, 40—41\nK-d trees, 388\nKeywords, text parsers, 115\nLandscapes. See Terrain\nLazy evaluation, 254\nLens flares\nasynchronous readback of buffer data, 480\ngeometry-based approaches, 480\nhardware issues, 475-477\nocclusion, 474\ntexture masking demo, 479—480\ntexture masking for, 474, 477-478\nLevel-of-Detail (LOD)\nAI optimization, 254\ntile landscapes and determination of detail, 380\nLevy, Steven, author of Artificial Life, 335\nLights and lighting\ncode for 3D lightmap with quadratic falloff,\n453-455\nDot3 Bump mapping, 456—459\nimpostoring and, 494\nlight maps, 452-459\nper-pixel spotlights, 460-461\nper-pixel techniques, 452—462\nSee also Shadows\nLinear programming\n\"Alt-Tab\" problem in multitasking, 82-83\nmultithreading, 81-84\nsurfaces, video memory and loss of information,\n83-84\nfor Windows-based games, 80-84\n",
      "content_length": 2935,
      "extraction_method": "Direct"
    },
    {
      "page_number": 545,
      "chapter": null,
      "content": "Index\n569\nLinear quantization and floating-point numbers, 178\nLine-of-Sight (LOS)\ndefined, 280\nLOS radius defined, 280\nLOS search systems, 279-286\ntemplates, 281-283\nLines and line segments\ndegenerate lines, 198-199\nfinite line segments, 200-203\nintersection calculation, 191-204\nnearest points calculated with closed-form solution\nequations, 194-200\nnearest points on finite segments, 200-202\nparallel lines, 199, 201-202\nLinking, explicit vs. implicit, 33-34\nLoadLibrary function, 34\nLocations\ntactical analysis of, 309-310, 315\nterrain reasoning for 3D games, 307-316\nLogarithmic quantization and floating-point numbers,\n178\nLogs and logging\naudio system activity and, 519\nmemory manager logging, 68-70\nLookup tables, for trig functions, 174-176\nLoops, object construction and, 6\nLOS. See Line-of-Sight (LOS)\nMacros\nDEPRECA TE macro, 64-65\nvs. inline functions, 16-19\nstate machines created with, 19\nMallocQ, 9, 67-68\nMaps\ncombined visibility maps, 283-286\ncubemap normalizer to correct interpolation\nproblems, 459-460\nDot3 Bump mapping, 456-459\nheight maps, 503-504\ninterlocking landscape tiles and height maps,\n379-380\nlightmapping, 3D textures, 452—459\nplayer visibility maps, 281-282\nshadow maps, 422\nMAX. See 3ds max skin exporter and animation toolkit\nMemcpyO, 13\nMemory\nAABB tree optimizations, 388-393\nbounds violations, 69\ncode bloat and, 11-12\ndrop-in debug memory manager, 66-73\nfragmentation and Standard Template Library\n(STL), 13-14\nfreeO, 9, 67-68\ninline functions and, 18\nleaks, 70-71\nmanaging for optimization, 9\nmemcpyO, 13\nmemory tracking, 29, 66-73\nMFC's memory manager, 72\nprocedural textures to spare, 497\nStandard Template Library and, 12—14\nVIPM memory costs, 363-364\nSee also Memory allocation\nMemory allocation\nallocating for stacks, 262\nalternatives to mallocQ, callocQ, reallocQ, andfrecQ,\n67-68\nmallocO, 9, 67-68\nweb camera allocation, 155-156\nMemory managers, drop-in debug memory manager,\n66-73\nMeshes\ndeformation and skin calculations, 149\nexporting to file, 149-150\nReal-Time Optimally Adapting Meshes (ROAM),\n377-378\nresolution defined, 365\nView Dependent Progressive Meshes (VDPM),\n377-378\nView-Independent Progressive Meshing (VIPM),\n363-376\nMessage pumps, alternatives to, 80-84\nMetaball clusters, RDC algorithm and Marching Cubes\nalgorithm, 229\nMFC, new and delete operators in, 72\nMicro-threads, AI architecture\n\"brains\" to run, 267-268\nloading and saving, 263\nstack management, 262\nstate machine coding and, 265-266\nstructured exception handling, 263\nswitching between threads, 260-262\ntroubleshooting, complications, 263\nMIDI (Musical Instrument Digital Interface),\n541-543\nMinkowski sums, 319-322\n\"lazy man's Minkowski sum,\" 321-322\nMirages, 286\nMixing functions and randomness, 129\nMLPs. See Multiplayer perceptrons (MLPs)\nModules\nfile management using resources files, 102-104\ngame profiling, 74-79\nmemory-tracking module, 66-73\nMomento audio design pattern, 518\n",
      "content_length": 2910,
      "extraction_method": "Direct"
    },
    {
      "page_number": 546,
      "chapter": null,
      "content": "570\nIndex\nMotion\nforward motion and animation, 428—429\nparallel transport frames for orienting moving\nobjects, 216-217\nMotion detection, web cameras and, 157-158\nMovies, input recording to create game movies, 107\nMRC file format, 142-143\nMultiplayer games\ninput recording and, 107, 110\nweb-cam interaction for, 153\nMultiplayer perceptrons (MLPs)\ncollecting data for, 354-355\ndescribed, 351-353\ninput selection and training, 353-354\nperturbation searches and, 355-356\nresources required for, 356-357\ntraining, 353-354, 355-356\nMultitasking in games, 82-83\nMultithreading, 81-84\nMusic\nassociations with, 551-552\nbasic music sequencer, 539-550\ncallbacks, 545, 547-549\ncontrol granularity, 554-555\nevent blocks, 540-541\nevent data structures, 546-547\nmeanings of, 552-553\nMIDI (Musical Instrument Digital Interface),\n541-543\nmodifications, 544\nnote control, 544\nsequencer data structures, 545-546\nsequencer implementation, 543-549\nsequencing methods, 539-540\nstreaming method, 539-540\nsynthesizer / sequencer connection, 549-550\ntiming calculations, 548-549\ntransitions in, 553-554\nvolume control, 554-555\nMusical Instrument Digital Interface (MIDI), 541-543\nMusic design, factors for interactive music, 556-558\nNearest-point calculation, closed-form equations for,\n194-198\nNeural networks, multiplayer perceptrons (MLPs),\n351-357\nNodes, export routines and, 144-145\nNoise\nanimating an octave of noise, 466-468\nband-limited noise, 466\nfractals and pink noise, 241-242\nPerlin noise, 466\nturbulent noise creation, 467—468\nNonphotorealistic rendering (NPR)\ninking for cartoon rendering, 436-443\npainting for cartoon rendering, 444—451\nNvidia's Developer Web site, 509\nObjects\nconstruction and destruction of, 5-8\ngeneric member access, 46-50\ngeneric objects, 41-43\norientation of moving objects, 215-219\npreallocation and caching of, 8\nRDC algorithm to find groups, 229\nObserver audio design pattern, 518\nObstacles, defined, 331\nOctrees, 388\nvs. sphere trees, 385\nOpenGL, texture wrapping settings for skyboxes, 418\nOperators\noptimization and return by value, 7\ntext parsers, 115\nOptimization\nArtificial Intelligence strategies, 251—257\nfor C++ games, 5-15\ncode size and, 11-12\nconstructors and, 7-8\nevent-driven behaviors vs. polling, 251-252\nimpostoring and render targets, 494-495\nincrement functions and, 7\ninitializer lists, 6-7\nLOS templates for player visibility systems, 281-283\nmanager entities to centralize cooperation, 252-253\nmeasuring with input recording, 106\nmemory management techniques for, 9\nmemory usage, 66-73\nobject construction and destruction, 5-8\nobject preallocation and caching, 8\noperators, 7\nof points-of-visibility pathfinding, 324—329\nprofiling for, 5\nquadtree access routines, 394-401\nredundant calculations, 252\nStandard Template Library and, 12-14\ntemplates and, 14\ntrigonometric functions and, 213-214\nvirtual functions and, 9—11\nOS threads, 260\nPage faults, 18\nPainting for nonphotorealistic rendering\ncomputing Toon texture coordinates, 438—440,\n446-448\npainting described, 444-445\nprogrammable vertex shaders, 448-450\n",
      "content_length": 3049,
      "extraction_method": "Direct"
    },
    {
      "page_number": 547,
      "chapter": null,
      "content": "Index\n571\nParallax values, 492-493\nParallel transport frames\ncalculation of, 215-216\nvs. Fixed Up method, 218\nvs. Frenet Frames, 217-218\nused to orient objects, 215-219\nParameter types, inline functions and, 18\nParser class of parsing system, 114-116\nPassability, as tactical assessment factor, 296\nPathfinding\nAI pathfinding, 152, 274-275\ncollisions and, 317-323\ndistributed processing for optimization, 253-254\nhierarchical on-demand pathfinding, 254—255\nprecomputing propagated influence values, 294—295\nredundant computations and, 252\ntile-based pathfinding, 325\nwaypoint queuing and, 274-275\nSee also Points-of-visibility pathfinding\nPaths\nquaternion-based flythrough paths, 220-227\nSee also Trajectories\nPatrolling, command queuing in RTS, 275-278\nPauses, in audio design, 518\nPerformance\nBloom Filter to improve, 133-140\ncommercially available tools for tuning, 75\ncycle counters, 180\nfloating-point numbers and, 167-181\nmeasuring, 180\nprofiling module, 74-79\nsearching systems for tile-based games, 279\ntuning with commercially available tools, 75\nSee also Optimization\nPer-pixel spotlights, 460-461\nPersistent type information, 43-44\nPersonality, creating in AI, 306, 332-333\nPerturbation searches, 355-356\nPlayers\ndefined, 280\npersonalities for AI players, 306\nPlayer visibility systems, 279-286\ncombined visibility maps, 283-286\nLOS templates, 281-283\nmaps, 281-286\nmirages, 286\nplayer visibility maps, 281-282\nPointers\nfunction pointers used within C++ classes, 59-60\ninstruction pointers, 260-261\nsmart pointer systems, 269\nstack pointers, 260-261\ntracking pointers, 271\nPoints-of-visibility pathfinding\ncollision models for, 318\ncollision shape selection, 322-323\nexpanded geometry for, 317-323\nMinkowski sums of polygons, 319-322\noptimization of, 324-329\nsilhouette points and, 325-326\nsilhouette zones and, 327-329\nspatial partitioning, 329\nvs. tile-based pathfinding, 325\nPolygonal pathfinding. See Points-of-visibility\npathfinding\nPostincrement functions, 7\nPrecalculating. See Preprocessing\nPrecomputing. See Preprocessing\nPredators and Prey flocking demo, 330-336\nPredictability, 105\ngenuine randomness and, 127—128\ninitial state predictability, 108\ninputs and, 109-110\nprotecting game predictability, 107-108\npseudo-random numbers and, 127\nrandom numbers, 109\nPreincrement functions, 7\nPreprocessing\nAI optimization and, 255\nof data files, 113-114\ninfluence maps, 293—297\npropagated influence values, 294-295\nsegmenting character geometry, 421-422\nPrint resolution of screen shots, 406-410\nalgorithm for, 406-409\nProbability, strategic inference using dependency\ngraphs, 305\nProcedural textures\ncloud generation, 463-473\ndependent texture addressing, 505-506\nhardware accelerated animations, 497-509\nheight-field water as, 501-503\nneighbor sampling and, 498-504\nsampling methods, 485-504\nscalability of, 471-472\nProfiling modules\narchitecture, 76-77\nbasic mechanisms for, 74-75\nbuilt-in game profiling module, 74-79\ndata analysis, 78\nimplementation, 78-79\nperformance counter manager (IPerfCounterMan),\n76\nProjective shadowing techniques, 421—424\nProperties, alternatives to Borland's proprietary, 46-50\nProxy audio design pattern, 516\n",
      "content_length": 3157,
      "extraction_method": "Direct"
    },
    {
      "page_number": 548,
      "chapter": null,
      "content": "572\nIndex\nPseudo-random numbers\ncloud generation and, 464-465\npseudorandomness described, 127\npseudo-random number generators, 109, 465\nsimple pseudo-random number generator code, 465\nQuadtrees\naccess routine optimization, 394-401\nvs. sphere trees, 385\nQuadtrees, direct access lookup\nconditions and requirements, 395-396\nlevel determination, 396-398, 401\nlocation of target node, 399\ntraversing, 399\ntuning, 399-400\nQuaternions\nflythrough paths and, 220-227\nas orientation data, 222-223\nselective negation to preprocess, 220, 223-224\nsingularity in rational mapping, 225\nspline interpolation technique, 224-225\nRAM-code. See Self-modifying code\nRand() function, alternatives to, 109\nRandom number generation\nimplementation of, 130-131\nnoise generation using, 242-244\nprocedural cloud generation and, 464-465\nspeed limitations of process, 129-130\nRandom numbers and randomness, 109\nhardware as source, 129\nmixing functions and, 129\nrandom number generators, 127-132\nRay tracing , sphere trees for, 384-387\nReal-Time Optimally Adapting Meshes (ROAM),\n377-378\nReal-time strategy (RTS) games\ncommand queuing for, 273-278\ncommands for, 273\ncyclic commands (patrolling example), 275-278\nLine-of-Sight searching systems for, 279-286\nwaypoint queuing and pathfinding, 274-275\nRecursive Dimensional Clustering (RDC), 228-238\npseudocode for RDC algorithm, 235-236\nrecursion and time complexity, 236-237\nsteps for, 232, 234\nReflections, 405\nRefraction, simulating refraction effects, 402—405\nReplays, input recording to replay interesting games,\n106\nResource allocation trees, 298-300\ncurrent resource allocation, determining, 300-301\ndependency graphs, 302-304\ndesired resource allocation, calculating, 300\nmeasuring values in branches of, 302\npersonality creation and, 306\nstrategic decision making, 301-302\nResource files\ndefined and described, 100\nimplementation of modules, 102-104\nresource system design, 101-102\nused for file management, 100-104\nRTS. See Real-time strategy games (RTS)\nRTTI. See Runtime type information (RTTI)\nRuntime type identification (RTTI)\nComponent Object Model (COM) as alternative to,\n24\nRuntime type information (RTTI)\ncode bloat and, 12\noptimization, 14\nRTTI typeidO, 125-126\nScreen shots, print resolution, 406-410\nScripting\nalternatives to, 51-60\nemergent behaviors as alternative to, 255\nmicro-threads and scripting languages, 264\nSearches\nCOM interface searches, alternatives to, 46—50\nperturbation searches, 355-356\nquadtree search implementation code, 400\nrecursive searching and C++, 89-90\nsphere trees for range searching, 384-387\ntile-based game search systems, 279-286\nSelf-modifying code\ndefined and described, 91-92\nfast bit blitter example, 92-99\nSelf-shadowing\naliasing problems and, 484-486\nhybrid approaches, 486-487\nwith projective textures, 421-424\nSeparation, flocking rule, 330\nSequencers, music\nbasic music sequencer, 539-550\ninteractive sequencer, 551-558\ntarget controls, 555-556\nShadow maps, 421-424\nShadows\naliasing problems, 484-486\nbrute-force rendering, 423\ncast by procedural clouds, 470\nhybrid approaches for, 486—487\ninter-object shadows, 486-487\npriority buffer shadows, 481^487\nreal-time techniques compared, 481-482\nself-shadowing, 421-424, 484-487\n",
      "content_length": 3208,
      "extraction_method": "Direct"
    },
    {
      "page_number": 549,
      "chapter": null,
      "content": "Index\n573\nshadow maps, 421-424\nSICLump module, 102-103\nSICResourceFile module, 103-104\nSign test (positive / negative) for floating-point\nnumbers, 172\nSilhouette edge detection (SED)\nadvanced texture features and inking, 442\nboundary edges, 437-438\ncrease edges, 437-438\nedge-based inking, 438-440\ninking described, 436-437\nprogrammable vertex shader inking, 440—442\nSilhouette points and zones, pathfinding, 325-329\nSine functions, lookup tables for, 174—175\nSkeletal representations. See Bones\nSkip strips VIPM method described, 368-370\nmixed-mode skip strips, 372\nmultilevel skip strips, 369-370\nSkyboxes\nalternatives to, 419\ndescribed, 416\nrendering, 418\nrendering distant scenery with, 416-420\nresolution, 416-417\nsize, calculating maximum, 418\ntextures for, 419\nSkyplanes, mapping procedural clouds to, 469-470\nSmoothing.\nSee under Influence maps\nSorting methods, hierarchical, 388-389\nSound\nabstract interface to create sound system, 20-22\nambient sound, 516\ndefined, 522\nechoes, 527\nlow-level sound API, 559-560\npredictability and playback, 108\nreverberation effects, 527\nsample-based synthesizer to reuse voices, 521-524\nspeech systems and command queuing, 517\ntroubleshooting, 519\nvolume controls, 554-555\nSee also Audio design patterns; Audio programming;\nMusic\nSpatial partitioning, used with silhouette zones, 329\nSpeech systems and command queuing, 517\nSpeed. See Optimization\nSphere trees, 384-387\nbounding spheres, 384—385\ndemo and algorithm, 385-387\nuses of, 385\nSplines\nnatural cubic splines and flythrough paths, 221-222\nopen vs. closed, 221-222\nSpotlights, per-pixel, 460-461\nSprites. See Impostors\nSquare roots, logarithmic optimization of, 176-177\nSrandQ, 109\nStack pointers, 260-261\nStacks\ncopying, 262\nstack management and micro-threads, 262\nstack winding, 85-90\nStack winding, 85-90\nrecursion and, 89-90\ntemporary return routine, 85-86\nthunking and, 88-89\nStandard Template Library (STL)\nmemory fragmentation, 13-14\noptimization and, 12-14\nState And Media Manager (SAMMy), 52-54\nState machines\ncreating with macros, 19\nSee also Micro-threads, AI architecture\nStatus functions in audio design, 519\nStrategic assessment techniques, 298-306\nresource allocation trees, 298-300\nStrategic decision making\nand resource allocation trees, 301-302\nstrategic inference, 305\nStrategy games\nLine-of-Sight searching systems for, 279-286\nstrategic assessment techniques, 298-306\nStreaming vs. sequencing method for music, 539-540\nStrings, text parsers, 115\nStructured exception handling (Win 32), 263\nSuper Mario 64, third-person control scheme, 425-432\nanimation analyzed, 431\nSurfaces, loss of surface information, 83-84\nSurvival, flocking rule, 331\nSwapThreads () routine, 261\nSwarming. See Flocking\nSyntax errors, memory tracking and, 71\nTactical analysis and assessment\nheight advantage, 296\nof locations, 309-310\ntactical analysis of locations, 309-310\ntactical values, converting to waypoint properties,\n310\nvisibility, 296-297\nTarget identification, Line-of-Sight systems, 279-286\nTemplate Method pattern, 55\nTemplates, optimization and, 14\nTemplate specialization, type information provided\nusing, 120-121\n",
      "content_length": 3125,
      "extraction_method": "Direct"
    },
    {
      "page_number": 550,
      "chapter": null,
      "content": "574\nIndex\nTerrain\nfractals to create realistic landscapes, 239, 246\ninfluence maps and, 293—297\ninterlocking tiles method, 377- 383\nreasoning for 3D games, 307-316\nskyboxes for rendering distant scenery, 416—420\nSee also Terrain reasoning\nTerrain reasoning\ncomputing waypoint properties, 310-313\nresources required for algorithm, 314—315\nwaypoints, 308-309\nText files\nadvantages and disadvantages, 112\nparsing systems, 112-117\nText parsers, 112-117\nBoolean values, 115\nfloating-point numbers, 115\nGUIDs, 116\nintegers, 115\nkeywords, 115\noperators, 115\nParser class, 116\nstrings, 115\nToken class, 114-115\nTokenFile class, 116\nTokenList class, 116\nvariables, 115\nTexture filtering, 479\nto reduce stretching, 418\nTextures\ndependent texture reads, 497\nfiltering to reduce stretching, 418\nfour-sample texture sampling, 497-498\ngreen-blue texture addressing, 497—498, 505-506\nself-shadowing with projective textures, 421—424\nfor skyboxes, 419\n3D textures for light mapping, 452-459\nuploading web-cam data, 160-161\nSee also Procedural textures\nThreads\nfibers (multi-tasking threads), 260\nOS threads, 160\nSee also Micro-threads, AI architecture\n3ds max skin exporter and animation toolkit\nbone animation keys, 148\nbone structure and hierarchy, 146\nbone weighting (influence values), 146—148\nmesh data and, 145-146\nMRC file format for exporting, 142-143\nnodes and, 144-145\nsteps to use, 148-149\nThunks and thunking, defined and described, 88\nTile-based games, Line-of-Sight searching systems for,\n279-286\nTiles\ndefined, 280\nsearching systems for tile-based games, 279\ntile-based pathfinding, 325\nSee also Tiles, interlocking landscape\nTiles, interlocking landscape\ndetail levels for, 380-382\nand height maps, 379-380\nlinking pieces explained, 381-382\nrendering method for, 382\nTime\nposition and velocity as function of, 206-207\nsmooth animation and, 148\ntime complexity and RDC, 236-237\nTimers, for AI agents, 253\nToken class of parsing system, 114-116\nTokenFiles class of parsing system, 117\nTokenList class of parsing system, 116\nTools, 3-4\nobject creation tools, 51-61\nperformance tuning, commercially available, 75\nprofiling module, 74-79\nTracks, audio, defined, 543\nTrajectories\nangles of elevation and, 207-210\nflight time calculations, 212\ngravity's influence, 205-206\ninitial velocity, 210-211\ninverse trajectory determination, 205-214\nmaximum height calculations, 211—212\nmultiple variables and, 212-213\ntime, position and velocity as function of, 206-207\nTransparency, exported classes and, 56-57\nTrigonometric functions\nlookup tables for, 174-176\noptimizations and, 213-214\nTroubleshooting\naudio design, 519\nmemory tracking programs, 29\nvoices in synthesizers, 521-524\nTweakableBase_c class, 121-122\nTuieaker_c class, 122-123\nTweakerInstanceDB_c class, 123\nTweaker interface, 118-126\nclasses, schematic illustrating, 119\ndesign, 118\ntype information for, 120-121\nType information code of tweaker interface, 125\nTypes\ndefined and described, 38\ndynamic type information (DTI) class, 38-43\n",
      "content_length": 2988,
      "extraction_method": "Direct"
    },
    {
      "page_number": 551,
      "chapter": null,
      "content": "Index\n575\ndynamic types in audio design, 518\npersistent type information, 43-44\nUpdates\nArtificial Intelligence (AI) data updates, 255-256\naudio frame and intervals, 547\nmotion detection to avoid unnecessary, 157-158\ntweaking update rates, 494\nupdate heuristics for impostors, 493-494\nUpdateWoM function, \n80-81\nValues\nabsolute values, 174\nclamping to a specific range, 173-174\nfloating-point number tricks, 173-174\ntactical values, converting to waypoint properties,\n310\nVariables\nabstract variables as MLP inputs, 354\nfuzzy variables, 342\ninfluence maps to track, 289-290\ntext parsers, 115\ntweaking, 118-126\nVectors\ndamped reflection vectors, 188-190\ninterpolating across line or plane, 189\nin MAX, 145\nreflected off collision planes, 185-188\nStandard Template Library vectors, 12-13\nVertex-cache coherency, 364, 375\nVertices, binned vertices, 365\nView Dependent Progressive Meshes (VDPM),\n377-378\nView-Independent Progressive Meshing (VIPM)\ncomparison of methods, 376\nmixed-mode method described, 365-368\nresources required for, 363-364\nskip strips method described, 368-370\nsliding window method described, 372-375\nvanilla method described, 365-368\nVirtual class member functions, exporting from DLLs,\n31-32\nVirtual functions, 9-11\nVisibility\nas tactical assessment factor, 296-297\nSee also Player visibility systems\nVoices, defined, 543\nVoices, sample-based synthesizers to reuse, 521-524\nVulnerability, as tactical assessment factor, 296\nWater\nheight-field water as procedural texture, 501-503\nsimulating refraction in a fish tank, 402—4:05\nWaypoints, 308\nA* pathfinding and, 315\nuses of waypoint-based reasoning, 315\nwaypoint properties, 310-313\nWeb addresses\nartificial intelligence sites, 336\nfor authors, xix—xxxii\nCSyn audio engine, 558\nflocking and steering behaviors, 335\nNvidia's Developer site, 509\nSquid web-caching program, 140\nWeb cameras\nBGR pixels, 158\ncapture window initialization, 153—158\ncartoon-like images, 159-160\ndata manipulation, 158-162\ndata retrieval, 156\ndestroying windows, 161-162\ngrayscale conversion, 159\nmemory allocation for, 155-156\nmotion detection, 157-158\nin multi-player games, 153\ntextures, uploading, 160-161\nWeighting\nbones, 146-148\nmesh deformation and, 149\nWorld, defined for tile-based games, 280\n",
      "content_length": 2247,
      "extraction_method": "Direct"
    }
  ],
  "enrichment": {
    "version": "1.0.0",
    "generated_by": "generate_chapter_metadata.py",
    "contains": [
      "keywords",
      "concepts",
      "summary"
    ]
  }
}