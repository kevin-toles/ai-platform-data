{
  "metadata": {
    "title": "Game Programming Gems 3",
    "author": "Unknown Author",
    "publisher": "Unknown Publisher",
    "edition": "1st Edition",
    "isbn": "",
    "total_pages": 618,
    "conversion_date": "2025-11-27T15:19:12.290952",
    "conversion_method": "PyMuPDF + OCR fallback",
    "source_pdf": "Game Programming Gems 3.pdf"
  },
  "chapters": [
    {
      "number": 1,
      "title": "Segment 1 (pages 1-15)",
      "start_page": 1,
      "end_page": 15,
      "detection_method": "topic_boundary",
      "content": "Contents\n\nForeword... cc ccc cee eee eee ees xi\nPreface... ccc cece een eee ee ee ee ae xv\nAcknowledgments. ....0cc0cuscuneeneeneeeeueee en eeeneeeee xix\nAbout the Cover Image ........000c0unues vem eee eee eee xxi\nContributor Bios .......... ee ee ee ee xxiii\n\nSECTION 1 GENERAL PROGRAMMING .......0.ccen eens nenenaee f\n\n1.1\n\n1.2\n\n1.3\n\n1.4\n\n1.5\n\n1.6\n\n1.7\n\n1.8\n\nIntroduction 2... cee eee eee eee eee eee\n\nKim Pallister\n\nScheduling Game Events ........000 cence eee eee e eee eee 5\nMichael Harvey and Carl Marshall\n\nAn Object-Composition Game Framework .........:0ceccuauaen 15\nScott Patterson\n\nFinding Redeeming Value in C-Style Macros ..... ween eee e eee 26\nSteve Rabin\n\nPlatform-Independent, Function-Binding Code Generator ........ 38\nAllen Pouratian\n\nHandle-Based Smart Pointers .......000ccceeasneuewereneneee 44\nBrian Hawkins\n\nCustom STL Allocators ......0cccceecnauen Cane e ce eeeneee ». 49\nPete Isensee\n\nSave Me Now! ........000: eee w eee tenes vuwnuas seueneeat ss SO\nMartin Brownlow\n\nAutolists Design Pattern...... wee eee eee 64\nBen Board\n\n1.9\n\nContents\n\nFloating-Point Exception Handling ........00000e0ncnunen ents s 69\nSoren Hannibal\n\nProgramming a Game Design-Compliant Engine Using UML .......73\n\nThomas Demachy\n\nUsing Lex and Yacc To Parse Custom Data Files ....... 2.0005 122283\nPaul Kelly\n\nDeveloping Games for a World Market ........0.0.0:: eee neeneas 92\nAaron Nicholls\n\nReal-Time Input and Ulin 3D Games .......00000esneneneuuen 109\nGreg Seegert\n\nNatural Seiection: The Evolution of Pie Menus .....-..00e00005 117\nDon Hopkins\n\nLightweight, Policy-Based Logging ........00::020008 saeeneans 129\nBrian Hawkins\n\nJournaling Services .......00s0een0neee re ee e212 136\nEric Robert\n\nReal-Time Hierarchical Profiling ........0000eceneeuneuaue ents 146\n\nGreg Hyjelstrom and Byon Garrabrant\n\nSECTION 2 MATHEMATICS ..... ccc eee cee eee ees 1G\n\n2.1\n\n2.2\n\n2.3\n\n2.4\n\n2.5\n\nIntroduction ........ seen eee eee eee wean a2. 155\nJohn Byrd\n\nFast Base-2 Functions for Logarithms and\n\nRandom Number Generation ...... seen eee eee eee ... 157\nJames McNeill\n\nUsing Vector Fractions for Exact Geometry ........ seen een aaee 160\nThomas Young\n\nMore Approximations to Trigonometric Functions ..... aunenenaentZO\nRobin Green\n\nQuaternion Compression ......000sn0ecnennaens ee seeen tees 187\nMark Zarb-Adami\n\nConstrained Inverse Kinematics ......000neccenerenncncenaee 192\nJason Weber\n\n2.6\n\n2.7\n\nCellular Automata for Physical Modeling ............000n00008 200\nTom Forsyth\n\nCoping with Friction in Dynamic Simulations ........... nese 215\nMiguel Gomez\n\nSECTION 3 ARTIFICIAL INTELLIGENCE .......0ccnennewe nen eel\n\n3.1\n\n3.2\n\n3.3\n\n3.4\n\n3.5\n\n3.6\n\n3.7\n\n3.8\n\nIntroduction .......:. cane eee Se ee sna 229\nSteven Woodcock\n\nOptimized Machine Learming with GoCap .......e000seeaneuun 231\nThor Alexander\n\nArea Navigation: Expanding the Path-Finding Paradigm ......... 240\nBen Board and Mike Ducker\n\nFunction Pointer-Based, Embedded Finite-State Machines ....... 256\nCharles Farris\n\nTerrain Analysis in an RTS—The Hidden Giant ........ ee ean anes 268\nDaniel Higgins\n\nAn Extensible Trigger System for Al Agents,\n\nObjects, and Quests .......0.0008 vanes Cee eee ee 22 285\nSteve Rabin\n\nTactical Path-Finding with A* ........0..0055 wenaeae eeu eenees 294\n\nWilliam van der Sterren\n\nA Fast Approach to Navigation Meshes .........::5 wesnenas »..307\nStephen White and Christopher Christensen\n\nChoosing a Relationship Between Path-Finding and Collision ..... 321\nThomas Young\n\n4.1\n\n4.2\n\nIntroduction ....ccc cen n eee ee eneesens rr 2. 335\nJeff Lander\n\nT-Junction Elimination and Retriangulation ......... ee eanaas .. 338\nEric Lengyel\n\nFast Heightfield Normal Caiculation ........0.0000ncevunnunae 344\n\nJason Shankel\n\nviii\n\n4.4\n\n4.5\n\n4.6\n\n4.7\n\n4.8\n\n4.9\n\n4.12\n\n4.13\n\n4.14\n\n4.15\n\nContents\n\nFast Patch Normals ......00ccn en enee nnn e eens 349\nMartin Brownlow\n\nFast and Simple Occlusion Culling ..... 2.002000 eseeseeeraeras Bod\nWagner T.: Corréa, James T. Klosowski, and Claudio T. Silva\n\nTriangle Strip Creation, Optimizations, and Rendering .......... 359\nCarl S. Marshall\n\nComputing Optimized Shadow Volumes for Complex Data Sets ...367\n\nAlex Vlachos and Drew Card\n\nSubdivision Surfaces for Character Animation ........000000008 372\nWilliam Leeson\n\nImproved Deformation of Bones ......0ccceerseennenenanesees OOF\nJason Weber\n\nA Framework for Realistic Character Locomotion ........: veae s 394\n\nThomas Young\n\nA Programmable Vertex Shader Compiler .......ccn0ecunaunae 404\nAdam Lake\n\nBillboard Beams ........0000000:8 Pr ee 413\nBrian Hawkins\n\n3D Tricks for Isometric Engines .......000c0nnnennennneennes 417\nGreg Snook\n\nCurvature Simulation Using Normal Maps .......:2022202202022 424\nOscar Blasco\n\nMethods for Dynamic, Photorealistic Terrain Lighting ........... 433\nNaty Hoffman and Kenny Mitchell\n\nCube Map Lighting Techniques .........0ccnneucennnnananen 444\nKenneth L. Hurley\n\nProcedural Texturing ..... eee eee eee eenee seve censneneeas 452\nMike Milliger\n\nUnique Textures .....00000008 er re 459\nTom Forsyth\n\nTextures as Lookup Tables for Per-Pixel Lighting Computations . . . 467\nAlex Vlachos, John Isidoro, and Chris Oat\n\nRendering with Handcrafted Shading Models .........:..: want 477\nJan Kautz\n\nSECTION 5 NETWORK AND MULTIPLAYER .....nc scene nnn nnnee 485\n\n5.1\n\n5.2\n\n5.3\n\n5.4\n\n5.5\n\n5.6\n\n5.7\n\n5.8\n\n5.9\n\nIntroduction ........; eneneenee eee wen eee e nee s 487\nAndrew Kirmse\n\nMinimizing Latency in Real-Time Strategy Games ...... ee neneee 488\nJim Greer and Zachary Booth Simpson\n\nReal-Time Strategy Network Protocol ....... ee eee eee eee 496\nJan Svarovsky\n\nA Flexible Simulation Architecture for\n\nMassively Multiplayer Games .........05e0005 ene e eens 506\nThor Alexander\n\nScaling Multiplayer Servers ...... enna ene e tees eae s O20\nJustin Randall\n\nTemplate-Based Object Serialization ..... enneae een ewer eee 534\nJason Beardsley\n\nSecure SocketS ..... 2c cece eee eee eee eee 546\nPete Isensee\n\nA Network Monitoring and Simulation Tool ..... ene enee 2... 557\nAndrew Kirmse\n\nCreating Multiplayer Games with DirectPlay 8.1 .........+:++.:561\nGabriel Rohweder\n\nWireless Gaming Using the Java Micro Edition .......2:0.000008 573\nDavid Fox\n\nSECTION 6 AUDIO eee weet DOS\n\n6.1\n\n6.2\n\n6.3\n\nIntroduction .......00.05 se neeene ee »... 585\nScott Patterson\n\nAudio Compression with Ogg Vorbis .......... ee ee 587\nJack Moffitt\n\nCreating a Compelling 3D Audio Environment ..........:5 enna 595\nGarin Hiebert\n\nObstruction Using Axis-Aligned Bounding Boxes ....... see eeae es 600\n\nCarlo Vogelsang\n\n6.4\n\n6.5\n\n6.6\n\n6.7\n\nContents\n\nUsing the Biquad Resonant Filter ........ weneas ween e eee 606\nPhil Burk\n\nLinear Predictive Coding for Voice Compression and Effects ..... 613\nEddie Edwards\n\nThe Stochastic Synthesis of Complex Sounds .......0200000085 622\nPhil Burk\n\nReal-Time Modular Audio Processing for Games .......0.:00008: 630\nFrank Luchs\n\nAppendix: About the CD-ROM ........c00ceeeennewnuueewenee 639\n\nON THE CD\n\nScheduling Game Events\n\nMichael Harvey and Carl S. Marshall,\n\nIntel Labs\n\nmichael.harvey@intel.com,\ncarl.s.marshall@intel.com\n\nMets events in a game—animation updates, object collisions, and so forth—\ncan be a daunting task if there is no clear understanding of how the events are\norganized and executed. This gem will explain how a scheduler can provide both\norganization and flexibility to your game framework.\n\nWe will begin by describing what a scheduler is and why it is useful, and end with\nadvanced topics on scheduler development. A simple scheduler is provided as source\ncode on the CD-ROM.\n\nWith the growing sophistication of computer games, real-time events and simu-\nlations are virtually a standard in today’s game architectures. What is needed is a way\nto manage and execute multiple events per frame, or many times within a frame's\ntimestep. A scheduler can manage game events in a very flexible fashion, as well as\nfacilitate a modular approach for extensibility.\n\nA few examples of game technologies that can effectively utilize a scheduler are\nphysics simulations, character animation, collision detection, game AI, and render-\ning. A key aspect in all of these technologies is time. Many of these simulation tech-\nnologies can become enormously complex, with hundreds of independent objects and\nprocesses being updated at various time intervals. For instance, a physics simulation\nwill break down time into small, discrete intervals for each object in order to update\nthe object’s motion [Bourg01]. By providing a finer resolution of time, the simulation\nwill have a much higher degree of accuracy. In this case, many objects and time inter-\nvals are managed by the same scheduling code, so efficiency is a vital concern in pre-\nventing scheduling bottlenecks.\n\nAnother important aspect of the scheduler is its ability to add and remove objects\non the fly. This allows for new entities to come into a game and participate in the sim-\nulations along with the rest of the game’s entities without missing a beat, and then be\nremoved from scheduling when they are no longer needed.\n\nScheduler Concepts\n\ntime = 10\n\nSection 1 General Programming\n\nThe basic components of the scheduler are a task manager, an event manager, and a\nclock (see Figure 1.1.1). With these components, the scheduler can generate time- or\nframe-based events and execute event handlers. Throughout this gem, we will refer to\n\nevent handlers as tasks.\n1) Event Manager ( Task Manager q\n\nFIGURE 1.1.1. Basic scheduler architecture.\n\nTask Manager\n\nThe task manager handles the registration and organization of tasks. Each task has a\nstandardized interface that contains a callback function for the manger to execute. The\ntask manager maintains a list of tasks, along with scheduling information about each\none—such as start time, execution frequency, duration, priority, and other required\nproperties. It might also contain a user-data pointer or performance statistics.\n\nEvent Manager\n\nThe event manager is the heart of the scheduler. Each task in the task manager defines\none or more events that it handles. An event is a moment in time when a task is to be\nexecuted. For example, in Figure 1.1.2, Task1 defines events at times 10 and 15. The\nevent manager generates events as needed to trigger the execution of tasks.\n\nReal-Time Versus Virtual Time\n\nA real-time scheduler is fairly simple in concept—the event manager sits in a loop.\nwatches a real-time clock, and as soon as a target time is reached, it fires an event. In\na real-time system, latency is critical. If a task takes too long, then it might interfere\n\nwee newer est wwwene\n\nTask1\nnext_time = 10\nperiod = 5\n\nGet Next Task = Task1\n\n@ Task1 next_time = 10\npdate Clock\n\n@ clock time = task time = 10\nExecute Task\n\nUpdate Task next time\n\n@ new_time = 15\n\nExecute(t = 10)\n\nTask2\nnext_time = 12\n\nperiod = 20\n\neee ee ee ens\n\nFIGURE 1.1.2 Event processing.\n\nwith the start of the next task. Since each task occurs exactly at its scheduled time, the\ntime between tasks is essentially wasted from the scheduler’s frame of reference.\n\nFrom the task’s point of view, time is only a number. Times can be compared, and\nelapsed time can be computed, based on this comparison number. The scheduler can\nsimulate a given time or the passage of time by manipulating this number, indepen-\ndent of real-time—hours can pass in the blink of an eye, or time can be halted. This\nis the basis of virtual time.\n\nVirtual time is extremely useful because it allows the scheduler to execute tasks\nwhen it is most convenient to do so, instead of when real-time dictates. It allows a\nsequence of events to be run quickly forward, stopped, recorded, and replayed. It also\nmakes it possible to debug a ‘real-time’ application by stepping one interval at a time.\n\nA virtual time scheduler divides time into frames. Tasks are executed in batches\nbetween frames, running in ‘virtual time,’ and then are synchronized with real-time\nwhen each frame is rendered. If the frame rate is high enough, the illusion of real-time\nis achieved. However, a few dozen milliseconds between frames is a lot of time for the\ncomputer, especially if it is managed efficiently. By batching all tasks together into a\nsingle block, the remaining time can be used for something else (see Scalability).\nLatency issues can be almost eliminated.\n\nWe'll refer to virtual time as simulation time in this gem, since all objects within\nthe simulation use it as a reference. If simulation time is stopped, then simulation\npauses as well. When it resumes, objects in the simulation do not detect any break in\ncontinuity. Simulation time starts at zero at the beginning of the simulation.\n\nTasks are executed sequentially while simulation time is updated between tasks.\nAs an example, assume each frame has a length of 20 ms (see Figure 1.1.3). If we have\nevents that occur at 51 ms and 54 ms, then they will be processed during Frame 2.\nThe event manager does not know how long Frame 2 is until it has ended; so at the\nbeginning of Frame 3, it looks at real-time and sees 60 ms. It can now process the\ntasks scheduled for Frame 2. Task] is the first, at 51 ms; but the simulation clock is\nstill at the beginning of Frame 2. The clock is advanced to 51 ms and Task] is exe-\n\nFrame 2 - Real-Time Frame 3 - Real-Time\n\n40ms 51ms 54ms 60ms\n\nStart Frame End Frame Start Frame\n\n<Task’ ‘<Task2> kRender> een eee ee eee\n\n40ms 51ms 54ms 60ms\n\nFrame 2 - Simulation Time Frame 3 - Simulation Time\nFIGURE 1.1.3 The difference between real-time and simulation time in Frame 2.\n\nSection 1 General Programming\n\ncuted. Once Task1 is done, the clock is advanced to the next event at 54 ms and Task2\nis executed. No more events are scheduled for this frame, so the clock is set to the end\nof the frame (60 ms) and the frame is rendered. (If you are using an offscreen buffer,\nthe frame was probably already rendered, and this is merely copying the image to the\ndisplay.) Any unused time can be used for additional processing (see Scalability on\nhow to use those extra processing cycles).\n\nIn this model, task execution and frame rendering always lag slightly behind real-\ntime. But this is not perceptible to the viewer, and it allows us to work with a variable\nframe rate. If the frame rate slows down, the scheduler can compensate so that the\nsimulation appears to run at a constant rate. If the frame rate is fixed, the scheduler\ncan predict the start and end times, and perform event processing in advance. How-\never, if the machine becomes significantly overloaded, the scheduler cannot compen-\nsate, and the game will become slower.\n\nEvent Types\n\nFrame events are the simplest types of events and occur once per NV frames, or every\nframe (N = 1). They can also occur before or after the render event. Time events, on\nthe other hand, occur in simulation time and are not specifically synchronized with\nframes. For example, a time event can occur every 10 ms, regardless of the rendering\nframe rate. It is also possible to combine time events and frame events. For example,\nan event could be scheduled to occur 10 ms after the start of every frame, or it could\nexecute five times per frame, evenly distributed in simulation time.\n\nClock\n\nThe clock component of the scheduler keeps track of real-time, the current simulation\ntime, and the frame count. The accuracy of the clock will determine the accuracy of\nthe simulation—a 1-ns resolution clock will be much more accurate than a 1-ms res-\nolution clock. For most purposes, 1-ms resolution is adequate. If greater resolution is\nrequired, one could use the 1-ms hardware clock and subdivide the real-time ticks as\nneeded to increase the resolution. A floating-point clock could be used as well.\nalthough careful attention would have to be paid to dealing with rounding errors.\n\nSequencing\n\nThe event manager handles the sequencing and generation of events. Since tasks are\ntriggered by events, proper ordering occurs naturally. For example, let’s define two\n\ntasks:\n\nTaskI: | Run every 5 ms from 5 to 15, normal priority.\n\nTask2: Run every 4 ms from 11 to 19, high priority (see Table 1.1.1).In some\ncases, tasks might be set to execute at the same time. In the example,\nboth Task1 and Task2 execute at time 15. Since Task2 has higher\npriority than Task], it is executed first. If priorities are equal, or no\n\n1.1 Scheduling Game Events 9\n\nTable 1.1.1 Task Execution Order\n\nTime Task\n\n5 ms Task1\n10 ms Task1\n11 ms Task2\n15 ms Task2\n15 ms Task1\n19 ms Task2\n\npriority system is implemented, they are handled round-robin. Priority is also\nuseful for ordering frame-based tasks.\n\nTask Manager Details\n\nWith hundreds of potential tasks, the task manager must manage things intelligently.\nA brute-force search for the next task is clearly not very efficient. While many meth-\nods are possible, the example programs on the CD-ROM make use of an ordered list.\nThe tasks are stored in a list according to their next execution time—the head of the\nlist is always the next task to be executed. The event manager only needs to look at the\nfirst task to determine when the next event should occur. When an event occurs, the\nforemost task is ‘popped’ off the list and executed, its next time is updated, and it is\nre-inserted into the list according to its updated execution time.\n\nBesides avoiding lengthy searches, this approach also has the advantage that fre-\nquent tasks stay close to the front of the list (almost like a cache). Infrequent tasks stay\nout of the way and ‘bubble up’ automatically at the proper time.\n\nIt is often the case that a registered task must be modified on the fly, which might\ninvolve adjusting its priority, period, duration, or even deleting it before it is finished.\nIn order to update a task, there must be some external means to locate it. A unique\nregistration ID can be assigned to locate the task in the list.\n\nwill demonstrate how a simple scheduler can be built and utilized. Code for the exam-\nples provided can be found on the CD-ROM. The provided sample scheduler\n(Scheduler, Clock, and ITask) can also be used as a library. Two sample clients are pro-\n\nvided (sample.exe and win.exe).\n\nThe scheduler’s design hinges on two components—the scheduler engine itself and\nthe ITask plug-in interface (see Figure 1.1.4).\n\n10 Section 1 General Programming\n\nClock\n\nEvent Manager\n\nFIGURE 1.1.4 Relationship between scheduler components and client application.\n\nIn order for the scheduler to run, someone needs to call it. In a non-GUI pro-\ngram, this is as simple as coding a loop and executing:\n\nwhile (running)\nscheduler.ExecuteFrame();\n\nThere are two ways to integrate a scheduler into a message-pump GUI, such as\nWindows. The first is by modifying the message loop to process messages and then\nexecute the scheduler. This is the most obvious approach, but it suffers from sched-\nuler ‘freezes’ while a window is being resized.\n\nThe second approach is to create a Windows timer, and use that to call the sched-\nuler. Since timers are not interrupted by window dragging, the scheduler runs contin-\n\n_ uously in the background. A sample application (Win) has been provided on the\n© 5 CD-ROM that shows how to use a scheduler in a Windows application. Let’s look at\nonmie co this application more closely.\n\nThe core Windows code is quite simple. The scheduler is run off a WM_TIMER mes-\nsage and has two types of scheduled events. One updates the position of each ball\nevery 15 ms, while the render event writes all the balls to an offscreen buffer. Win-\ndows can then paint the screen from this offscreen buffer on an as-needed basis. The\nsimulation and rendering occur without any special Windows programming. This\nexample demonstrates the use of multiple simulation tasks and adding/removing tasks\non the fly.\n\nOften, games have frame rates that vary, depending on system capacity and load.\nyet the velocity of moving objects remains constant. While both sample applications\nhave a fixed frame rate, the provided scheduler does support this constant velocity\ntechnique. The key is in the Clock.Update() method that samples the actual real-time\nand advances the simulation by the elapsed time. If an object moves N units in 60 ms.\nit does not matter whether the system renders two 30-ms frames or three 20-m:\nframes—the object moves the same distance in the same real-time, so the velocity is\n\n1.1 Scheduling Game Events 11\n\nconstant. If you wish to have the velocity of simulated objects increase or decrease\nwith the frame rate, change the Clock.Update() method so that it advances in fixed\nintervals, instead of reading the real-time clock.\n\nSo, how does the scheduler manage time, anyway? We need to register some\nevents and see how it works.\n\nScheduling\n\nThe first step in scheduling a task is to specify it as a time event, a frame event, or a\nrender event. This code will schedule a frame event that starts on Frame 200, runs\nevery third frame, and ends before Frame 210 (start 200 + duration 10):\n\nscheduler.Schedule(TASK_FRAME, 200, 3, 10,\npSomeHandler, pUserPointer, &id);\n\nThis task would run on Frames 200, 203, 206, and 209. After executing the final\niteration, the task expires and is deleted by the task manager. Tasks with duration 0\nare perpetual and never expire. In certain cases, you might want to remove a task\nbefore it is complete, or you might want to manually end a perpetual task. To do this,\nyou Terminate() it using the task ID.\n\nHow does the frame get updated? Each time the scheduler ExecuteFrame()\nmethod is called, it first calls Clock. BeginFrame(), which starts a new frame by updat-\ning the frame count and computing new frame start and end times. After updating\nthe frame count, it executes all time events, advances the simulation time to the end\nof the frame, executes all frame events, and then finally executes the render task. (In\nthe sample scheduler, the render task is a special frame task that does not have a start,\nperiod, or duration—It always executes once per frame.)\n\nThe entire simulation can be stopped or restarted using the Run() and Stop()\nmethods. When the scheduler is stopped and then restarted, it computes the elapsed\ntime and subtracts it from the total simulation time. While stopped, the scheduler\nstill performs renders and frame events, but time events are suspended.\n\nAdvanced Concepts\n\nenn RRA LSE SERIES SEE PO OT ET LER ee\n\nThere are a number of ways in which the scheduler can be improved or better utilized.\nScalability, simulation and multithreading are a few of these methods.\n\nScalability\n\nA common problem in game development is scalability. The game should take advan-\ntage of all the available processing power to provide a richer experience, but it still\nneeds to function well on less-powerful systems. Computationally expensive features\nneed to be throttled down or turned off completely. The game should also ‘play well’\nin a multitasking environment—a game that utilizes most of the CPU might prevent\nthe OS from responding to user input in a timely manner. In addition, if the OS\n\nSection 1 General Programming\n\nlaunches any housekeeping tasks in the background, it could slow the game down.\nIdeally, the game should adjust dynamically to the conditions of the system.\n\nCollecting the performance data is half the battle. Since the scheduler can\nbecome a bottleneck by handling all processes, it is a perfect place to put performance\nmonitors.\n\nAs described earlier, the clock takes a snapshot of the current time and compares\nit to the last frame to determine elapsed time. The scheduler can also determine the\nelapsed time of each task by comparing the start time to the end time. This informa-\ntion can either be communicated to the task, or it can be used to determine whether\nor not to run the task and/or how often.\n\nOne way to provide scalability is to require time budgets—the more power, the\nmore time allowed. A task might have a ‘time budget’ per frame. The scheduler tracks\nthe accumulated budget and the accumulated running time, and only executes the\ntask if the current budget exceeds the actual time. For example, a task might have a\ntime budget of 2 ms per frame, but it runs in 3 ms on a slow CPU. The scheduler will\nskip every third frame in order to keep the task within its budget (see Table 1.1.2).\n\nTable 1.1.2 Time Budget Per Task\n\nFrame # Budget Actual\nFrame 1 2 3\nFrame 2 4 6\nFrame 3 6 —\nFrame 4 8 9\n\nSome tasks might have a time budget ‘threshold’—if they exceed their budget.\ninstead of running part of the time, they do not run at all. The scheduler can also\ndetermine the time needed to perform the entire simulation by summing all of the\ntasks. The difference between processing time and frame length is idle time. Ideally, the\ngame should use all the available time to improve gameplay, but should not use mor\nthan what is available, or the frame rate will slow down. The scheduler can add tasks tc\nfill idle time or remove tasks to reduce the load. (There must, of course, be some way\nto specify which tasks can safely be added or removed.) By supplying overall systerr\nusage statistics to tasks, the tasks can then scale themselves to use more or less time\nbased on the data received. It is probably best to have a 5% to 10% idle target to allow\nfor minor fluctuations in actual processing time without slowing things down.\n\nOther options that provide scalability include increasing or decreasing of time\nbudgets, scheduling of idle tasks (which only run during idle time), garbage collectioz\nor other housework, graphics enhancements, or improvement of the AI. When doing\nthis type of management, it is important to avoid oscillation between extremes. Thr\ncan be done by limiting adjustments to small incremental changes rather than larg:\n\n1.1 Scheduling Game Events 13\n\njumps, or by statistical analysis of the effect of previous adjustments in order to\nimprove prediction.\n\nSimulation\n\nThe scheduler can be used to drive a simulation system. Most simulation engines\nbreak time down into discrete steps for purposes of animation and collision detection.\nThe scheduler described in this gem is perfect for this type of simulation system.\n\nIn a simple example of a lunar lander, the lander has a vertical velocity and a for-\nward velocity. Each timestep adds gravity. If we use AI to control the vertical thruster\nof the lander, then at each timestep, the AI samples velocity and adjusts thrust to\ncompensate, allowing for a controlled descent. The timesteps need to be small enough\nto give the AI time to react—otherwise the lander will hit the ground before it can\nrespond effectively. For collision detection, again, you want small timesteps so that\nthe lander will intersect the surface rather than passing completely through it.\n\nMultithreading\n\nIt is possible for the scheduler to manage the execution of subthreads [Carter01, Daw-\nson01]. There are many reasons why you might wish to do this. For example, some\ntasks might work better as a continuous process rather than a series of discrete events\n[Otaegui01]. Such tasks can be written as a thread, and the scheduler can control how\nmuch time the thread is allowed for processing. This approach allows true preemptive\nmultitasking while actually enforcing a time budget.\n\nMultiprocessing systems are slowly becoming more common, and it is likely that\nmultiprocessing will become a standard feature in the near future. Games that are able\nto take advantage of multiple processors will be able to outperform games written for a\nsingle CPU. An easy way for a game to utilize multiple CPUs is to make it mulkti-\nthreaded and let the OS do the work of distributing the threads on available processors.\n\nA multi-CPU scheduler could activate several threads at once so that they could\nrun concurrently. It could also spawn event handlers into specific threads so that mul-\ntiple events can be handled concurrently.\n\nof simulations. A quality scheduler needs to be flexible and efficient. This gem has\ncovered some of the basic scheduler concepts, has provided a sample scheduler, and\nhas shown how to integrate it into conventional and GUI-based applications. Help\norganize your events by using a scheduler in your next game.\n\nReferences .\n[Bourg01] Bourg, David M., Physics for Game Developers, O'Reilly, 2001.\n[Carter01] Carter, Simon, “Managing AI with Micro-Threads,” Game Programming\nGems 2, Charles River Media, Inc., 2001.",
      "page_number": 1,
      "chapter_number": 1,
      "summary": "This chapter covers segment 1 (pages 1-15). Key topics include times, task, and scheduling. ee ee ee ee xxiii\n\nSECTION 1 GENERAL PROGRAMMING .......0.ccen eens nenenaee f\n\n1.1\n\n1.2\n\n1.3\n\n1.4\n\n1.5\n\n1.6\n\n1.7\n\n1.8\n\nIntroduction 2.",
      "keywords": [
        "time",
        "frame",
        "task",
        "Scheduling Game Events",
        "eee",
        "scheduler",
        "simulation time",
        "Events",
        "event manager",
        "task manager",
        "Game Events",
        "Simulation",
        "Game",
        "Frame events",
        "Simulation Time Frame"
      ],
      "concepts": [
        "times",
        "task",
        "scheduling",
        "schedule",
        "events",
        "ees",
        "frame",
        "game",
        "gaming",
        "simulations"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 8",
          "chapter": 21,
          "title": "Segment 21 (pages 197-204)",
          "relevance_score": 0.67,
          "method": "api"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 17,
          "title": "Segment 17 (pages 326-347)",
          "relevance_score": 0.64,
          "method": "api"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 21,
          "title": "Segment 21 (pages 403-420)",
          "relevance_score": 0.62,
          "method": "api"
        },
        {
          "book": "operating_systems_three_easy_pieces",
          "chapter": 12,
          "title": "Segment 12 (pages 103-116)",
          "relevance_score": 0.62,
          "method": "api"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 18,
          "title": "Segment 18 (pages 348-366)",
          "relevance_score": 0.61,
          "method": "api"
        }
      ]
    },
    {
      "number": 2,
      "title": "Segment 2 (pages 16-26)",
      "start_page": 16,
      "end_page": 26,
      "detection_method": "topic_boundary",
      "content": "Section 1 General Programming\n\n[Dawson01] Dawson, Bruce “Micro-Threads for Game Object AI,” Game Program-\nming Gems 2, Charles River Media, Inc., 2001.\n\n[Llopis01] Llopis, Noel, “Programming with Abstract Interfaces,” Game Program-\nming Gems 2, Charles River Media, Inc., 2001.\n\n[Mirtich00] Mirtich, Brian, “Timewarp Rigid Body Simulation,” Computer Graph-\nics Proceedings, SIGGRAPH 2000: pp. 193-200.\n\n[Otaegui01] Otaegui, Javier, “Linear Programming Model for Windows-Based\nGames,” Game Programming Gems 2, Charles River Media, Inc., 2001.\n\n1.2\n\nAn Object-Composition\nGame Framework\n\nScott Patterson, Next Generation\n\nEntertainment\n\nscottp@tonebyte.com\nscott@gameframework.com\n\nhis gem will present a design for a game framework based on object composition\n\nand explain its advantages and design philosophy. We will present reasons why\nthis kind of framework can be useful for implementing the work required for games.\n\nThis game framework can serve as a reference for your own game systems. You\ncan create new systems with the capabilities that you need and create new tasks that\nperform the actions that you need.\n\nWhen we talk about a programming framework, we are referring to a system of\nobjects that work together to provide certain services. An application framework is a\ncollection of classes that provide the services necessary for creating applications. Our\ngoal in this gem is to find out what kind of framework we can build to help create\ngame.applications.\n\nThere are good reasons to use a framework to build an application. Getting some-\nthing running quickly is a primary reason. Time is money, after all. Frameworks typ-\nically contain built-in features, consistent behavior and structure, and well-known\nrules for object access, object ownership, and object lifetimes.\n\nIn this gem, we first summarize game development stages to get an overview of\nthe work that is required. We then discuss the game framework design issues. Finally,\nwe present an overview of the game framework implementation provided on the\n\nCD-ROM.\n\nshows a listing of typical game development stages and identifies the typical goals at\neach stage.\n\n15\n\n16\n\nSection 1 General Programming\n\nTable 1.2.1 Typical Goals During Game Development\n\nStage Goal\n\nConcept Design of functionality and aesthetics. Creation of character, story, and mission\nconcepts.\n\nPrototype Demonstration of key gameplay elements through proof-of-concept demos.\nDemonstration of technology.\n\nPlayable Demonstration of at least one mission or level being played from start to finish.\n\nProduction Completion of designs and implementation for all missions and levels.\n\nWrapping Integration of various game modes and screens. Includes stoty segments, training,\nmission/level selection, win/lose, status/scores, save/load, pause/restart, options/\nconfiguration.\n\nTesting Solving design and implementation problems. Solving compatibility issues.\nIntegration of alternate drivers.\n\nRelease Shipping the game on its first platform. Party!\n\nConversion Alternate language versions. Alternate platforms.\n\nDuring the early stages (concept, prototype, playable), the choice of framework\nmight be focused on getting the program running quickly. At this time, it is quite pos-\nsible that the framework does not seem as important as creating the demonstration of\nconcepts. However, if the framework is not also designed to be useful for the other\nstages of game development, then you might find yourself losing time to refactoring.\n\nDuring the production stage, tools such as viewers and editors become essential.\nViewers are necessary for developers to see how their content looks “in the game.”\nEditors are required for developers to make adjustments to any aspect of the game.\nWhile these kinds of tools can be separate from the game application, it is often\nrequired for viewer and editor capabilities to be incorporated into the game. To do\nthis, there must be code for the “consumer” aspect as well as for the “developer”\naspect. The goal is to build a framework that leverages the shared components of these\nfeatures, yet allows them to be developed independently.\n\nDuring the wrapping stage, we must integrate the various game modes and\nscreens into one seamless product. This integration sometimes suffers from schedul-\ning delays or restructuring of the original design. Having a framework to help manage\nthese game modes and screens, and even the transitions between them, will help this\nprocess go more smoothly.\n\nDuring the testing stage, we might need the ability to start the game in various\nmodes or at certain points within the game. We want our framework to provide this\nkind of flexibility to make it easy to define these various modes and entry points. We\nmight also want to include the ability to switch between drivers while inside the\ngame. If our framework binds a particular type of video technology to our applica-\ntion, switching video drivers would not be possible. Whether we provide driver-\nswitching or not, we can add logging capabilities to our framework to aid the process\nof compatibility testing.\n\n1.2 An Object-Composition Game Framework 17\n\nAfter we reach the release stage, the game team might go on to do conversions of\nthe game, or it might be shipped off to other developers to do the conversions. Either\nway, if our framework is hard to port to another platform, it will cause delays. We\nwould rather have the conversion team spend their time putting in new features and\nenhancements for each platform, rather than spend their time struggling to get it\nworking.\n\nGame Framework Design\n\nNow that we have an idea of the kind of work required to make games, we can look at\nthe design issues in creating a framework. We will cover platform dependence, game\ndependence, object composition, inheritance, frame-based code, function-based\ncode, operation order, object lifetimes, and task integration.\n\nPlatform-Independent Versus Platform-Dependent\n\nGames are usually filled with many concepts that transcend operating systems and\nplatform technologies. These concepts determine the player's enjoyment through\n“gameplay” and “depth.” Conversely, games are also commonly written to take advan-\ntage of specific hardware features that help identify the presentation quality. This pre-\nsentation quality is often responsible for extending a game's feeling of “immersion.”\n\nFrameworks need not be bound to operating systems and technologies. We can\ndefine platform-independent system interfaces for our framework rather than plat-\nform-dependent system interfaces. Even though these interfaces are platform-inde-\npendent, we can use a factory system to create the concrete implementations for\nspecific platforms.\n\nThe more we can separate the game's conceptual work from platform specifics,\nthe easier it will be to replace only the platform-specific code for conversions. So, part\nof our goal in creating a game framework is making it easy to keep game concepts\nindependent of the operating system and platform technology details whenever possi-\nble or practical.\n\nGame-independent Versus Game-Dependent\n\nIf we want to use a framework for many games, it makes sense to have the framework\nbe game independent. However, if we are going to use a framework for a single game\non several platforms, it might be acceptable to have portions of the framework be\ngame dependent.\n\nFor example, if our game controls a specific type of character that has many\ndynamic visual details that depend on the character's state, we might want the render-\ning code to access game-specific states and decide how the object should be rendered.\nThis kind of situation can reduce the number of system interface calls, which simpli-\nfies and speeds up the code.\n\n18 Section 1 General Programming\n\nObject Composition Versus Inheritance\n\nOne way to make an application framework intuitive is to use the template method\ndesign pattern, and create objects that are a subclass of an application class. When we\ndo this, we treat application initialization and destruction as algorithms that sub-\nclasses can redefine. This kind of design pattern is called “class behavioral” because it\nuses inheritance to distribute behavior between classes.\n\nAnother way to define the steps of application initialization and destruction\n(without inheritance) is to define these steps as a list of tasks to process. A task system\nclass can coordinate task execution, and a resource system can reference and manage\nthe task lists and task objects. Now we are “object behavioral” because we are using\nobject composition and our resource system as our mediator for these objects.\n\nUsing a task system like this means that we can now build a framework based on\nobject composition rather than inheritance. Our task system controls task objects\nthrough their interfaces, and our tasks perform work by calling object interfaces. This\nalso means that our framework will not have the typical inverted control structure\nthat is a result of the template method. Instead, our task objects control the software.\nPerhaps this is an object framework rather than a class framework, but it is a frame-\nwork nonetheless.\n\nThe Design Patterns book [GoF94] discusses many advantages of object composi-\ntion. It also highlights two principles of object-oriented design:\n\n¢ Program to an interface, not an implementation.\n¢ Favor object composition over class inheritance.\n\nFrame-Based Versus Function-Based Operation\n\nThere are many types of software that are not concerned with frame timing, where\nfunctions may take seconds, minutes, or even longer to complete. This function-\nbased operation can be much easier to program than frame-based operation.\n\nMost games must be visually and aurally responsive, with many animations and\ndetails being calculated every frame. Each time a visual image and/or audio buffer is ren-\ndered, we have created a frame. Games may be rendered at speeds up to 50 or 60 frames\nper second. This kind of frame-based operation requires game software to execute in\nshort spurts of time. Ifa lengthy operation (over 1/60th of a second) is to be performed,\nit must be broken into shorter pieces or be performed as a background task.\n\nFor our framework, frame-based operation will require a frame system class that\ncan tell our task system class when to call frame-synchronized tasks. Our task system\nwill also be able to process tasks that are not frame-synchronized, which we will call\n“asynchronous tasks.”\n\nSince the frame system controls when to call frame-synchronized tasks, we can\nalso offer the ability to manually step through frames and choose particular frame\nrates. This can be useful for checking animation playback details as well as for other\ndebugging and testing purposes.\n\n1.2 An Object-Composition Game Framework 19\n\nDynamic Versus Static Operation Order\n\nThere are many types of software operations that need to be done in a specific order.\nFor these operations, we must call functions in a particular order or submit tasks in a\nspecific order to our task system. This is an example of static operation order.\n\nGames are normally filled with various screens and transitions that are not typi-\ncally connected in a specific order. Instead, the player's actions determine what hap-\npens next. This is an example of dynamic operation order.\n\nFor our framework, we can provide dynamic operation order by enabling task\nobjects to access the task system interface and submit new tasks.\n\nDynamic Versus Static Object Lifetimes (and\nOwnership Issues)\n\nIn hierarchical systems, we might find that base objects own certain objects that are\nused by inherited objects, while inherited objects can create objects that the base\nobjects know nothing about. Often the lifetimes of such objects are built into the\nhierarchy, and inherited objects cannot dynamically create and delete them. The life-\ntimes of these objects are static in this sense.\n\nIn an object-composition framework, it could be confusing to know when a par-\nticular object owns another object. To resolve this, we can assign object ownership to\nour resource system. This way, any task can connect with system resources as needed\nand not be given management responsibilities. We give our resource system the power\nof object ownership and our tasks the power of object access, which limits the confu-\nsion over ownership issues.\n\nWe can make the lifetimes of these objects dynamic by having tasks issue com-\nmands to our resource system. We can direct the resource system to load and dump\nobjects in collections. For example, a load collection command can be issued before\ntasks that need the loaded objects are started. A dump collection command can be\nissued after those tasks are finished. Alternatively, we can have objects around for the\nentire lifetime of the application.\n\nHorizontal Versus Vertical Integration of Tasks\n\nIn hierarchical systems, it might seem like we are always “under” other objects that\ncontrol us and that our relationship with those objects is “fixed.” Tasks feel vertically\narranged, and changes to higher parts of the system can have far-reaching effects on\nthe operation of lower parts of the system.\n\nIn object-composition framework, it might seem like our programming environ-\nment is “flat” and our relationships with certain objects is more “dynamic.” Tasks feel\nhorizontally arranged, and changes to certain tasks in the system will have little or no\neffect on other tasks in the system.\n\nGame Framework Implementation\n\nie a SR NR RE SER CHS PRR MPA SS SA ARTA IH NAG AG RNMTR BRR SISSON SE HOM IS BEN ATTEN BARRONS SINTRA\n\nNow we present an overview of the implementation of our framework that meets\nthese challenges. The framework is composed of systems and tasks. A special kind of\ntask called the “frame player” provides high-level control of audio-visual rendering\nand logic.\n\nSystems\n\nThe Systems_t class contains pointers to the pure interfaces [Stroustrup97] of the sys-\ntems that our game will use. We choose to provide access to these systems through\npure interfaces so that dynamic system switching is possible and platform-dependent\nsystem code is separated from the platform-independent code that accesses the sys-\ntems. The interfaces available in the Systems_t class are summarized in Table 1.2.2.\n\nTable 1.2.2 The Interfaces Available in the Systems_t Class\n\nSummary\n\nLogSys_t Handles all message logging from the game. Optional output types include\ntext boxes or files.\n\nErrorsys_t Handles error information and states.\nTimeSys_t Reports timing information.\nFactorySys_t Creates objects using Factory IDs.\nResourceSys_t Manages object instances using Instance IDs.\nTaskSys_t Manages task execution and control.\nWindowSys_t Provides window system management and control.\nFrameSys_t Provides frame synchronization services and control.\nInputSys_t Provides input device management and control.\nVisualSys_t Provides visual system management and control.\nAudioSys_t Provides audio system management and control.\nNetworkSys_t Provides network system management and control.\n\nEach system has an Init (Systems_t *pSystems) and a Shutdown() method. Pass-\ning the Systems_t pointer to the objects allows them to access any of the system inter-\nfaces. Including the Systems_t class does not create compiler dependencies on the\nsystems code because the systems are accessed through pointers that only require for-\nward references. This is important, as Systems_t pointers are used in many of the\nframework’s classes. Reducing physical dependencies is an important goal of good\nphysical design {Lakos96].\n\nBecause each of these systems is defined as a pure interface that hides all imple-\nmentation details, we can dynamically switch system implementations as long as\nthose implementations do not have static link dependencies. The break-up of depen-\ndent implementations into dynamically loadable components is an example of the\n\npackages pattern [Noble01].\n\n1.2 An Object-Composition Game Framework\n\n21\n\neitieninnemnnimsintcmeaa mate IIE Lai eNrmaseninmeatteniny Ace et Sckcatrn tn SNC Neen in ih nnn ne LONER NO a IEEE HE\n\nThe source code on the CD-ROM demonstrates how to dynamically switch\nvisual systems. This is done using dynamic link libraries, each of which provides dif-\nferent implementations of the VisualSys_t interface. Here is an example of how to\ncontrol the switch of visual systems:\n\nFactorySys t *pFS = m_pSystems->GetFactorySys();\n\npFS->DeleteVisualSys( m_pSystems->GetVisualSys() );\npFS->SetVisualSysDriver1ID( m_nVisualSysDriverID );\nm_pSystems->SetVisualSys( pFS->CreateVisualSys() );\n\nTasks\n\nThe TaskSys_t class provides an interface to the task system. Using the\nPost_TaskCommand function, we can post a task as either a frame-synchronized task or\nan asynchronous task. The only difference is when the tasks are called. Frame-syn-\nchronized tasks are called when the frame system reports that it is time to run the next\nframe. Asynchronous tasks are called in each loop of the task system.\n\nPost_TaskCommand allows us to add and remove tasks at any time. Here is an\nexample of how to post task commands to stop the current asynchronous task and\nstart a frame-synchronized task:\n\n// get the task system\n\nTaskSys_t *pTaskSys = m_pSystems->GetTaskSys();\n\n// get the resource system\n\nResourceSys_t *pResSys = m_pSystems->GetResourceSys();\n\n// remove the current asynchronous task\npTaskSys->Post_TaskCommand( ASYNC_REMOVE, this );\n\n// get the new task to start\n\nTask_t *pTask = pResSys->GetTask( INSTANCE_ID_TASK_INTRO );\n// push back the new frame-synchronized task\npTaskSys->Post_TaskCommand( FRAMESYNC_PUSH_BACK, pTask );\n\nHere we see that we can access any task using its instance ID by calling\nthe resource system’s GetTask function. Tasks are passed to the Systems_t pointer\nwhen they are connected to the system via the task’s Connect (Systems_t *pSystems)\nfunction.\n\nLayers\n\nThroughout the game development process, there is typically a great amount of work\nassociated to visual rendering design. Rendering can be managed in a high-level man-\nner using a layer system. The importance of a layer system comes into play when the\ngame screen is rendered in a layered fashion. For example, during a 3D game, we\nmight have the world rendered as one layer and perhaps game objects as another layer,\nand then a “heads-up display” as a third layer. We want the ability to push new layers\nonto the scene and have them appropriately affect visuals, audio, and input-handling\nlogic.\n\nTo control layers of visual screens, audio data, and input-handling logic, we intro-\n\n22 Section 1 General Programming\n\nduce a special kind of task called the FramePlayer_t. This task is intended to be\nframe-synchronized and manages audio-visual-layer (AVLayer_t) objects and logic-\nlayer (LogicLayer_t) objects.\n\nAudio-visual-layer objects are called each frame as follows:\n\n// Update AV Layers\nfor( each audio-visual layer (forward-order) )\n{\nAVLayer_t *pAVL = contents of iterator;\npAVL ->Update() ;\n}\n\n// Begin Render Visual\nif( m_pSystems->GetVisualSys()->BeginRender() )\n\n{\nfor( each audio-visual layer (forward-order) )\n{\nAVLayer_t *pAVL = contents of iterator;\npAVL->RenderVisual{) ;\n}\nm_pSystems ->GetVisualSys() ->EndRender();\n}\n\n// End Render Visual\n\n// Begin Render Audio\nif ( m_pSystems->GetAudioSys()->BeginRender() )\n\n{\nfor( each audio-visual layer (forward-order) )\n{\nAVLayer_t *pAVL = contents of iterator;\npAVL ->RenderAudio();\n}\n\nm_pSystems ->GetAudioSys() ->EndRender () ;\n\n}\n// End Render Audio\n\nWe can see that each audio-visual layer is updated first with an Update() call.\nThis is when the audio-visual objects are updated, depending on their state of anima-\ntion. Following this update call, we render the visuals and audio.\n\nLogic-layer objects are called each frame as follows:\n\n// Update Logic Layers\nfor( each logic layer (reverse-order) )\n\n{\nLogicLayer_t *pLL = contents of iterator;\npLL->Update();\nif( pLL->IsExclusive() ) break;\n\n}\n\nWe can see that each logic layer is simply updated with an Update() call. While\naudio-visual-layer updates are meant to handle animation, logic-layer updates are\nused to handle game logic and player input.\n\nwork\n\n1.2 An Object-Composition\n\nSince the logic layers are processed in reverse, and since they stop processing if\nthey're marked exclusive, the last logic layer in the m_LogicLayerPtrList can “over-\nride” previous logic layers. So, pushing back a logic layer can exclusively change the\nway player input is handled, such as is required for game menus, viewers, and editors.\nIn contrast, if we push forward a new audio-visual layer, we only add a new set of\nitems to display and hear.\n\nJust as the task system has task commands, the FramePlayer_t class has layer\ncommands. Here is an example of how to post layer commands:\n\nAVLayer_t *pAVL;\n\nLogicLayer_t *pLL;\n\n// get the resource system\n\nResourceSys _t *pResSys = m_pSystems->GetResourceSys() ;\n\n// get the task to modify\n\nTask_t *pTask = pResSys->GetTask( INSTANCE_ID_TASK_INTRO) ;\n// we know it is a frame player\n\nFramePlayer_t *pFP = (FramePlayer_t *)pTask;\n\n// push back an audio-visual layer\n\npAVL = pResSys->GetAVLayer (INSTANCE_ID_AVLAYER_INTRO) ;\npFP->Post_AVLayerCommand(PUSH_BACK, pAVL);\n\n// push back a logic layer\n\npLL = pResSys->GetLogicLayer (INSTANCE_ID_LOGICLAYER_INTRO) ;\npFP->Post_LogicLayerCommand(PUSH_BACK, pLL) ;\n\nHere we see that we can get any audio-visual layer using its instance ID by calling\nthe resource system’s GetAVLayer function. Similarly, we can get any logic layer using\nits instance ID by calling the resource system’s GetLogicLayer function. Layers are\npassed to the Systems_t pointer when they are connected to the system via the layer’s\nConnect (Systems_t *pSystems) function.\n\nWith this layer system, we can now change audio-visual layering dynamically. All\nof the various game modes and screens mentioned in the wrapping stage can be\nimplemented using layer and task commands. For example, we can push back\nan audio-visual layer for a “heads-up display” when needed. Similarly, we can push\nback audio-visual and logic layers for floating menus. When creating new modes and\nscreens, we have the option of editing the layering of our frame-player task using the\nlayer commands, or we can switch between frame-player tasks using the task com-\nmands mentioned earlier.\n\nFinally, a sophisticated use of layer and task manipulation is in transitions. Items\non one game screen (the first audio-visual layer) can be gradually covered by items of\nanother game screen (the second audio-visual layer). When the transition is complete\nand only the second layer is visible, the first layer can be removed from audio-visual\nprocessing.\n\nSource Code\n\nPec 8 REET\n\nThe CD-ROM includes source code to the game framework implementation and\nsome additional documentation. The code with this book is meant to highlight game\n\nON THE CD\n\nSection 1 General Programming\n\nframework concepts and not game technology concepts. Code updates will be avail-\nable at http://www.gamefgramework.com. Figure 1.2.1 illustrates the modes, tasks,\nand layers that are implemented in the source.\n\nMode Task Audio-Visual Layers Logic Layers\n\nInfo\n‘o) Intro Enter ——+(2)\nNew Game—>{:3\nIntro Intro\n(Start Menu}\n\nLoad Game —>{ 5 )\nRestore Game +6)\nGame\nConfiguration\n\nSystem\nConfiguration\n\n©) Game Game\n(Pause Menu}\n\nEscape —€)\nD307, D3D8, OpenGL —-@\n\nFIGURE 1.2.1 Using the game framework: An example of how game modes can be\nimplemented using tasks, audio-visual layers, and logic layers.",
      "page_number": 16,
      "chapter_number": 2,
      "summary": "We will present reasons why\nthis kind of framework can be useful for implementing the work required for games Key topics include game, object, and tasks.",
      "keywords": [
        "Charles River Media",
        "Game",
        "Game Framework",
        "system",
        "task system",
        "Framework",
        "task",
        "Charles River",
        "River Media",
        "objects",
        "layer",
        "game framework implementation",
        "game framework design",
        "resource system",
        "Object-Composition Game Framework"
      ],
      "concepts": [
        "game",
        "object",
        "tasks",
        "provide",
        "framework",
        "layers",
        "layered",
        "programming",
        "program",
        "design"
      ],
      "similar_chapters": [
        {
          "book": "Game_Engine_Architecture",
          "chapter": 1,
          "title": "Segment 1 (pages 1-18)",
          "relevance_score": 0.61,
          "method": "api"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 2,
          "title": "Segment 2 (pages 19-41)",
          "relevance_score": 0.61,
          "method": "api"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 36,
          "title": "Segment 36 (pages 719-740)",
          "relevance_score": 0.59,
          "method": "api"
        },
        {
          "book": "Data-Oriented Design",
          "chapter": 1,
          "title": "Data-Oriented Design",
          "relevance_score": 0.55,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 2",
          "chapter": 3,
          "title": "Segment 3 (pages 17-24)",
          "relevance_score": 0.55,
          "method": "api"
        }
      ]
    },
    {
      "number": 3,
      "title": "Segment 3 (pages 27-35)",
      "start_page": 27,
      "end_page": 35,
      "detection_method": "topic_boundary",
      "content": "1.2 An Object-Composition Game Framework 25\n\nReference 7\n\n[Boer00] Boer, James, “Object-Oriented Programming and Design Techniques,”\nGame Programming Gems, Charles River Media, Inc., 2000: pp. 8-19.\n\n[Boer00] Boer, James, “Using the STL in Game Programming,” Game Programming\nGems, Charles River Media, Inc., 2000: pp. 41-55.\n\n[GoF94] Gamma, E., et al., Design Patterns: Elements of Reusable Object-Oriented\nSoftware, Addison Wesley Longman, Inc., 1994.\n\n[Lakos96] Lakos, John, Large-Scale C++ Software Design, Addison Wesley Longman,\nInc., 1996.\n\n[LlopisO1] Llopis, Noel, “Programming with Abstract Interfaces,” Game Program-\nming Gems 2, Charles River Media, Inc., 2001: pp. 20-27.\n\n[Meyers96] Meyers, Scott, More Effective C++, Addison Wesley Longman, Inc., 1996.\n\n[Meyers98] Meyers, Scott, Effective C++, Second Edition, Addison Wesley Longman,\nInc., 1998.\n\n[Meyers01] Meyers, Scott, Effective STL, Addison Wesley Longman, Inc., 2001.\n\n[Noble01] Noble, James, Small Memory Software: Patterns for Systems with Limited\nMemory, Addison Wesley Longman, Inc., 2001.\n\n[Stroustrup97] Stroustrup, Bjarne, The C++ Programming Language, Third Edition,\nAddison Wesley Longman, Inc., 1997.\n\n[Vlissides98] Vlissides, John, Pattern Hatching: Design Patterns Applied, Addison Wes-\n\nley Longman, Inc., 1998.\n\n1.3\n\nON THE CD\n\nFinding Redeeming Value in\nC-Style Macros\n\nSteve Rabin, Nintendo of America, Inc.\nsteve@aiwisdom.com\n\nhe lowly C-style macro (#define) is a powerful construct that is severely misun-\n\nderstood. Many people and books characterize it as evil and outdated, replaced by\nthe inline functionality in C++. Unfortunately, that’s a simplistic view that doesn’t\ntake into account the unique functionality that the macro possesses. Shamefully,\nmany C++ books fail to explain the basic properties of macros or even acknowledge\ntheir existence. However, solid explanations can still be found in classic C books such\nas [Kernighan88].\n\nIn a nutshell, the macro is a directive to the compiler’s preprocessor to do some\ncreative text replacement. Thus, no type-checking or other safety checks take place,\nand this is where many programmers get into trouble. As a simple rule, macros\nshouldn't be used to create function-like behavior or constants. For a discussion of the\npitfalls of macros, please refer to [Dalton01], [Hyman99], and [McConnell93].\n\nHowever, this gem isn’t about the problems with macros; it’s about proving that\nmacros are useful and desirable in many surprising ways. Macros allow you to per-\nform fancy text replacement before actual compilation, and that’s exactly what the fol-\nlowing tricks exploit. Note that the source code that appears in each example can also\nbe found on the CD-ROM.\n\nDisclaimer\n\nRR ae eRe eR cRNA ee ASG ARR RP NE IEA MA SN HERE HT\n\n26\n\nWith macros, it’s easy to be carried away into a world o\nHowever, that’s not the intention of this gem. While individuals have their own\nboundaries as to what is acceptable, it is generally understood that making new\ndialects of C/C++ by using macros is undesirable. Anyone coming onto a project\nshould be able to read your code with a minimal amount of effort. So, as you read\nthese tricks, understand that each one must be carefully weighed for its benefit versus\nthe possibility of obfuscation. Confined use of these examples is probably the most\nreasonable way to benefit from this gem.\n\n1.3 Finding Redeeming Value in C-Style Macros 27\n\nof a macro. The first operator is #, and it will instruct the macro to put quotes around\nthe argument that follows it. For example:\n\n#define CaseEnum(a) case(a): LogMsgToFile(#a, id, time)\n\nswitch( msg_passed_in )\n\n{\nCaseEnum( MSG_YouWereHit );\n\nReactToHit();\nbreak;\n\nCaseEnum( MSG_GameReset );\nResetLogic();\nbreak;\n}\n\nAfter the compiler’s preprocessing step, the previous code becomes:\n\nswitch( msg_passed_in )\n{\ncase( MSG_YouWereHit ):\nLogMsgToFile( “MSG_YouWereHit”, id, time );\nReactToHit();\nbreak;\n\ncase( MSG_GameReset ):\nLogMsgToFile( “MSG_GameReset\", id, time );\nResetLogic();\nbreak;\n}\n\nWith this macro scheme, you can easily dump enum names in a reliable and\nmeaningful way, as actual strings, to a log file or the screen. Without this trick, you\nwould need to have a lookup table of all enums-to-strings. Unfortunately, lookup\ntables are often poorly maintained and, thus, not reliable. The other solution is to use\nstrings in the first place, instead of enums, but it’s doubtful you would want to per-\nform routine string compares inside your game. Therefore, the macro trick is a sound\nsolution that is both fast and reliable.\n\nAnother variant is to read in the enumeration from a header file and interpret the\nsingle list into both an enumeration and an array of string names. The following\nshows how this can be done:\n\n// data.h\nDATA(MSG_YouWereHit )\n\nDATA(MSG_GameReset )\nDATA(MSG_HealthRestored)\n\n28 Section 1 General Programming\n\n// data.cpp\n#define DATA(Xx) x,\nenum GameMessages\n\n#include \"“data.n\"\n35\n\n#undef DATA\n#define DATA(x) #x, // make enums into strings\n\nstatic const char* GameMessageNames[] =\n\n{\n#include \"data.h\"\n\n}3\n\n#undef DATA\n\nMacro Trick #2: Compile-Time Constants from\nBinary Representations\n\nThe other special macro operator is ##. This operator lets you paste two arguments\ntogether. For example:\n\n#define cat(a,b) a ## b\nvalue = cat( 1, 2 );\n\nThe preprocessor will turn the previous line into:\nvalue = 12;\n\nWhile this simple example is useless (shown just to illustrate the concept), the ##\noperator can be exploited in very interesting ways. The following trick allows you to\ncreate compile-time constants using binary representations. What is especially inter-\nesting is that this runs completely in the preprocessor with no runtime code gener-\nated. (Special thanks to Jeff Grills who provided this implementation.)\n\nHere's the usage:\n\nBINARY1 (0101); // 0x5\nBINARY2(1010,0101); // Oxa5d\n\nconst int nibble\nconst int byte\n\n// Oxa5a5a5a5\nconst int dword = BINARY8(1010,0101,1010,0101, 1010,0101,1010,0101);\n\nMacro source:\n\n#define HEX_DIGIT_0000 0\n#define HEX_DIGIT_0001 1\n\n1.3 Finding Redeeming Value in C-Style Macros 29\n\n#define HEX_DIGIT_0010\n#define HEX_DIGIT_0011\n#define HEX_DIGIT 0100\n#define HEX DIGIT_0101\n#define HEX_DIGIT_0110\n#define HEX_DIGIT_0111\n#define HEX_DIGIT_1000\n#define HEX_DIGIT_1001\n#define HEX DIGIT_1010\n#define HEX _DIGIT_1011\n#define HEX_DIGIT 1100\n#define HEX DIGIT 1101\n#define HEX_DIGIT_ 1110\n#define HEX DIGIT 1111\n\n>ADADOTMOONAARAN\n\n#define HEX_DIGIT(a) HEX_DIGIT_ ## a\n\n#define BINARY1H(a) (Ox ## a)\n#define BINARY1I(a) BINARY1H(a)\n#define BINARY1 (a) BINARY11 (HEX_DIGIT(a) )\n\n#define BINARY2H(a,b) (Ox ## a ## b)\n#define BINARY2I(a,b) BINARY2H (a,b)\n#define BINARY2(a,b) BINARY2I (HEX_DIGIT(a), HEX_DIGIT(b))\n\n#define BINARY6H(a,b,c,d,e,f,g,h) (Ox##a##b##cH#Hd##eH#THHg#HHh)\n\n#define BINARY8I(a,b,c,d,e,f,g,h) BINARY8H(a,b,c,d,e,f,g,h)\n\n#define BINARY8(a,b,c,d,e,f,g,h) BINARY8I(HEX_DIGIT(a), \\\nHEX_DIGIT(b), HEX DIGIT(c), HEX_DIGIT(d), HEX_DIGIT(e), \\\nHEX_DIGIT(f), HEX _DIGIT(g), HEX DIGIT(h))\n\nMacro Trick #3: Adding a Descriptive Comment to\nStandard Assert\n\nThe standard Windows assert (found in assert.h) is already a macro. It’s extremely\nhelpful, even indispensable to good software engineering—but it can be improved.\nThe biggest improvement is to add a descriptive string so that a meaningful message\nis displayed when an assert is triggered.\n\nWith the following macro, you can easily expand the standard assert to include a\ndescriptive string:\n\nSERCH,\n\n#define assertmsg(a,b) assert( a && b )\n\nExample use:\nassertmsg( time > 0, \"Trigger::Set - The arg time must be > 0\" );\nWhen time is less than or equal to zero, the assert will be raised and the embed-\n\nded message is displayed as part of the failed assertion. You can read more about this\ntrick, as well as other assert tricks, in [Rabin00O].\n\n30 Section 1 General Programming\n\nMacro Trick #4: Compile-Time Assert ;\n\nease saridanreeennnnn ata mao ane ire bee REE TR OMI aR Bae ae eR te mee\n\nOccasionally, you'll have a situation where y you want a a build to immediately fail if\na particular condition isn’t satisfied at compile time. Depending on the size of your\nproject, this can save a lot of time and trouble. The following macro allows you to ver-\nify a statement at compile time, which in effect is a compile-time assert.\n\n#define cassert(expn) typedef char __C_ASSERT__[(expn)?1:-1\n\nFor example, if you're working on cross-platform code, you might want to check\nat compile time that enumerations are the same size as an unsigned integer. Given an\nenumeration such as MyEnum, you can check this by writing:\n\ncassert( sizeof(MyEnum) == sizeof(unsigned int) );\n\nIf a false statement is passed into cassert, it will fail at compile time because it\nattempts to define an array with a negative size. Defining a negative-size array is a bla-\ntant compile error that will immediately stop the build.\n\nMacro Trick #5: Determining the Number of\nElements in an Array\n\nisan: Aitkkvabiton stu NNN aM ta RNAse ANNAN een ER RAM a pH TRR EE HERE ASR AROS ABER EN\n\nSometimes it’s useful to know the number of elements in an array. However, there is\nno obvious way to query this, since it is not stored explicitly—only defined at initial-\nization time.\n\nThe trick to computing the number of elements in an array is to divide the over-\nall size of an array by the size of a given element. For example, if the total size of an\narray is 120 bytes and each element takes up 12 bytes, there must be 10 elements in\nthe array. The size of each element, in bytes, is known at compile time, and the fol-\nlowing macro neatly returns the number of elements.\n\nce\n\n#define NumElm(array) (sizeof(array) / sizeof((array)[0]))\n\nMacro Trick #6: Making _ _LINE__\n\n‘SAAR gaa\n\ninto a String\n\nSeveral very useful macros exist by default. These include:\n\n__LINE__ //an integer of the line number where it appears\n\n__FILE__ //a string containing the file name where it appears\n__DATE__ //a string containing the date when it was compiled\n__TIME__ //a string containing the time when it was compiled\n\nThe main use for these macros is to record information that is useful in debug-\nging. For example, when an assert macro is placed in your code, it takes advantage of\nthe _ FILE__ and __LINE__ macros. Should the assert be triggered, these values are\ndisplayed; thus, you know the exact filename and line number where the problem\noccurred.\n\n1.3 Finding Redeeming Value in C-Style Macros 31\n\nSince these values are normally used for printing out debugging information as\nstrings, here are several macros to turn the __FILE__ string and the __LINE__ integer\ninto a single string containing both:\n\n#define _QUOTE(x) # x\n#define QUOTE(x) _QUOTE(x)\n#define _FILELINE___FILE__ \"(\" QUOTE(__LINE_) \")\"\n\nThis trick doesn’t work with Microsoft Visual C++, since it replaces __LINE__ dif-\nferently than other compilers. Instead of replacing the macro __LINE__ with a simple\ninteger, it is replaced by (__LINE__Var+offset), where __LINE__Var is an internal vari-\nable that represents the line number where the function starts, and offset is an actual\ninteger representing the offset from the start of the function. Therefore, with\nMicrosoft Visual C++, the macro trick might produce a result like:\n\n\"C:\\project\\main.cpp((__LINE_ _Var+5))\"\n\nHowever, this macro trick produces the desired result with both Metrowerks\nCodeWarrior and SN Systems ProDG (a gcc-based compiler).\n\nMacro Trick #7: Protecting Against Infinite Loops _\n\nThe possibility of an infinite loop often looms over particular parts of your code,\nespecially parts that depend on outside data or scripts. A practical safeguard is to cre-\nate a counter that increments every time through the loop and, if it should get too\nhigh, asserts. That is exactly what this next trick will do, except that it will be done in\na transparent manner that can be optionally compiled out for release builds.\n\nThis trick creates a macro called “while limit,” which behaves similar to the\nwhile keyword; however, it takes a second argument that defines the number of itera-\ntions at which it will raise an assert. For example, consider the following code:\n\nwhile limit( node != 0, 1000 ) {\n//some work\nnode = node->next;\n\n}\n\nThe previous example will assert if the loop spins more than 1,000 times. By rais-\ning an assert instead of hanging, testers can more easily diagnose bugs. As an added\nbonus, if the tester chooses to ignore the assert, the while_limit will exit the infinite\nloop and continue normal program execution.\n\nHere’s the macro source:\n\nstatic bool while_assert( bool a )\n{\n\nassert( a && \"while_limit: exceeded iteration limit\" );\nreturn( a );\n\n32\n\nMacro Trick #8: Small, Specialized Languages\n\nSection 1 Generai Programming\n\n#define UNIQUE_VAR(x) safety_limit ## x\n\n#define while_limit(a,b,c) \\\nassert(b>0O && \"while_limit: limit is zero or negative\");\\\nint UNIQUE_VAR(c) = b; \\\nwhile(a && while_assert (--UNIQUE_VAR(c)>=0) )\n\n#define while_limit(a,b) _while_limit(a,b, COUNTER_)\n\nNote that a new default macro, __COUNTER__, is used in the previous code. The\nmacro __COUNTER__ expands to an integer, starting with zero, and increments by one\nevery time it is used. This allows us to create a unique variable each time we use\nwhile_limit. This unique variable is used to keep track of loop iterations. The first\ntime a while limit occurs, the variable’s name will be safety_limito. (The second\ntime, the variable’s name will be safety_limit1.) This unique-naming trick is neces-\nsary so that multiple while_limit macros could be used without their loop-iteration\nvariable names clashing (causing compile errors due to multiple definitions).\n\nThe macro __COUNTER__ is not a standard ANSI C macro and is not implemented\nin all compilers. However, it is implemented in Microsoft Visual C++ and Metrow-\nerks CodeWarrior. For SN Systems ProDG and other gcc compilers, an alternative\ntrick exists by using the __LINE__ macro to help create the unique variable name. The\nfollowing code will work with both SN Systems ProDG and Metrowerks CodeWar-\nrior. (Both variations of while_limit work with Metrowerks CodeWarrior.)\n\nAlternate while_limit macro:\n\nstatic bool while_assert( bool a )\n\n{\nassert( a && \"while_limit: exceeded iteration limit\" );\nreturn( a );\n\n}\n\n#define _UNIQUE_VAR(x) safety_limit ## x\n\n#define UNIQUE_VAR(x) _UNIQUE_VAR(x)\n\n#define while_limit(a,b) \\\nassert(b>0 && \"while limit: limit is zero or negative\"); \\\nint UNIQUE_VAR(__LINE_) = b; \\\nwhile(a && while_assert(--UNIQUE_VAR(__LINE__)>=0))\n\nRN A LR RS IR IR NHN a\n\nMacros can be quite powerful, and this trick probably demonstrates this best. Using\nthe text-replacement property of macros, you can create your own small, specialized\nlanguage that compiles directly into C/C++. Before you jump to conclusions, remem-\nber that we're still striving for readable, maintainable, and debuggable code.\n\nIn the article “Implementing a State Machine Language” (AJ Game Programming\nWisdom (Rabin02)), there is an example of a macro language that standardizes the\nconstruction of state machines and enforces some good programming practices. Con-\nsequently, it makes the state machine easier to build and easier to read. Here is an\nexample of a state machine using the macro language:\n\n1.3 Finding Redeeming Value in C-Style Macros 33\n\nBeginStateMachine\n\nState( STATE_Wander )\nOnEnter\n// C++ code for state entry\nOnUpdate\n// C++ code executed every tick\nOnExit\n// C++ code for state clean-up\n\nState( STATE_Attack )\nOnEnter\n// C++ code for state entry\n\nEndStateMachine\n\nWhile the previous code looks like a completely new scripting language, it com-\npiles into C/C++ using only six macro keywords. The benefit is that native C/C++\ncode can be freely inserted, and it is trivial to debug, since the full power of the debug-\nger is still available. Once you understand the behavior of the state machine, the\nmacro language actually hides the unnecessary details and lets you code the internals\nin a simple and natural way.\n\nThe six macro keywords are as follows (OnEvent is a helper—it’s not used\n\ndirectly):\n#define BeginStateMachine if(state < 0){if(0){\n#define EndStateMachine return(true);}}else{assert(0); \\\nreturn(false) ;}return(false) ;\n#define State(a) return(true);}} \\\nelse if(a == state) {if(0){\n#define OnEvent(a) return(true);}else if(a == event){\n#define OnEnter OnEvent (EVENT_Enter)\n#define OnUpdate OnEvent (EVENT_Update)\n#define OnExit OnEvent (EVENT_Exit)\n\nIf you want to explore this macro-scripting language further, please see [Rabin02]\nfor an in-depth explanation.\n\nMacro Trick #9: lifying Cl s Interfaces\n\nOne of the goals of C++ is to separate the declaration of a class from its definition.\nThis is very useful; it allows you to see the interface that a given class exposes—its dec-\nlaration, usually placed in a header file—without having to understand its actual\nimplementation of that functionality (the class definition, usually placed in a .CPP\nfile).\n\nUnfortunately, the way C++ implements the separation of class declaration and\ndefinition ends up causing a fair amount of extra work. Namely, the signature (func-\ntion name and parameters) of every non-inline function must be stated twice, once in\nthe class declaration and once in the definition.",
      "page_number": 27,
      "chapter_number": 3,
      "summary": "This chapter covers segment 3 (pages 27-35). Key topics include macros, define, and defining. [Boer00] Boer, James, “Using the STL in Game Programming,” Game Programming\nGems, Charles River Media, Inc., 2000: pp.",
      "keywords": [
        "define HEX DIGIT",
        "Addison Wesley Longman",
        "define HEX",
        "HEX DIGIT",
        "DIGIT",
        "HEX",
        "macro",
        "macro trick",
        "define",
        "Charles River Media",
        "Wesley Longman",
        "Addison Wesley",
        "Object-Composition Game Framework",
        "trick",
        "line"
      ],
      "concepts": [
        "macros",
        "define",
        "defining",
        "tricks",
        "programming",
        "program",
        "assert",
        "assertion",
        "line",
        "compiler"
      ],
      "similar_chapters": [
        {
          "book": "makinggames",
          "chapter": 8,
          "title": "Segment 8 (pages 60-68)",
          "relevance_score": 0.63,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 1",
          "chapter": 12,
          "title": "Segment 12 (pages 107-114)",
          "relevance_score": 0.61,
          "method": "api"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 8,
          "title": "Segment 8 (pages 142-159)",
          "relevance_score": 0.61,
          "method": "api"
        },
        {
          "book": "More Effective C++",
          "chapter": 3,
          "title": "Segment 3 (pages 17-24)",
          "relevance_score": 0.57,
          "method": "api"
        },
        {
          "book": "More Effective C++",
          "chapter": 29,
          "title": "Segment 29 (pages 293-301)",
          "relevance_score": 0.57,
          "method": "api"
        }
      ]
    },
    {
      "number": 4,
      "title": "Segment 4 (pages 36-45)",
      "start_page": 36,
      "end_page": 45,
      "detection_method": "topic_boundary",
      "content": "34\n\nSection 1 General Programming\n\n// class declaration in Elmo.h\nclass Elmo\n\n{\n};\n\nvoid TickleMe(int x, int y = 0);\n\n// class definition in Elmo.cpp\nvoid Elmo::TickleMe(int x, int y)\n\n{\n}\n\n// actual implementation of Elmo::TickleMe() goes here\n\nBecause the signature of Elmo::TickleMe() exists in two places, every time we\nwish to change the parameters of the method—or change the function’s name, or\nchange it to be const, perhaps—we need to change it in two places.\n\nUsually, this isn’t a big deal. In most cases, a method will belong only to one class,\nand it’s not problematic to change it in only two places. However, there are some cases\nwhere this aspect of the C++ language can cause you a lot of work. And in some situ-\nations it can become very easy to incur subtle bugs when you change a function's sig-\nnature—bugs that your compiler won't be able to warn you about.\n\nFor example, imagine we have a base class named BaseClass. There are three\nclasses derived from BaseClass—D1, D2, and D3. BaseClass declares a virtual function\nFoo(). BaseClass: :Foo() comes with a default implementation in BaseClass; it’s not\na pure virtual function. Further, let’s assume that the derived class D3 overrides Foo(),\nso that D3::Foo() does something different than BaseClass: :Foo().\n\nNow, let’s say we add a parameter to BaseClass: :Foo(), and we forget to update\nD3::Foo() at the same time. Sadly, our compiler will now lose the connection\nbetween BaseClass: :Foo() and D3: :Foo()—it will assume that they are two entirely\ndifferent functions, and that D3::Foo() is an entirely separate function from Base-\nClass::Foo(). When we try to call Foo() as a virtual function on objects of class\nBaseClass, D3::Foo() will not get called on objects of type D3, as we originally\nintended.\n\nIdeally, we want a method’s signature to exist in only one place. It would be nice\nto be able to declare BaseClass::Foo() and provide implementations in both Base -\nClass and D3 without also having to provide an additional declaration of D3: :Foo0().\n\nThere's also an argument in support of productivity: With inheritance in C++, we\noften end up making many shallow class hierarchies with a single parent and many\nchildren. These generally tend to be much more useful than deep, everything-includ-\ning-the-kitchen-sink hierarchies, which attempt to artificially conglomerate many\nunrelated pieces of functionality into a single, massively extended family.\n\nWith shallow hierarchies, we begin with a base class that exists primarily to\ndeclare an interface—that is, it declares some number of virtual functions, most of\nwhich will be pure virtuals. Quite often, we end up with a large number of classes in\nsuch a family, with a single base class and perhaps a dozen other classes derived from\nthat base class. The problem is that we need to redeclare all of the methods we want\n\n1.3 Finding Redeeming Value in C-Style Macros 35\n\nto override in all of the derived classes we implement. If we have a base class with 10\nfunctions, and we derive 10 classes from that base class, that’s 100 extra function dec-\nlarations, all of which essentially exist only to say, “I, too, implement the functional-\nity declared in the base class.” All of this extra text can make header files difficult to\nmaintain and hard to read.\n\nLet’s imagine we have a class called Creature, and we intend to derive various dif-\nferent classes of creatures from this base class. Creature defines three pure virtual\nfunctions, as shown:\n\nclass Creature\n\n{\npublic:\nvirtual std::string GetName() const = 0;\nvirtual int GetHitPoints() const = 0;\nvirtual float GetMaxVelocity() const = 0;\n}5\n\nFurthermore, assume we derive several different classes of creature (SnowCrab,\nNordicYeti, and SnowshoeBandit) from this base Creature class. Each of our three\nmethods—GetName(), GetHitPoints(), and GetMaxVelocity()—-now exists in seven\nplaces: once in the declaration of Creature, and once each in the declaration and def-\ninition of SnowCrab, NordicYeti, and SnowshoeBandit.\n\nSo now let's assume we make a minor change and modify GetHitPoints() to\nreturn a float instead of an int. We now have to go and modify GetHitPoints() in\nseven different files—Creature.h, SnowCrab.h, SnowCrab.cpp, NordicYeti.h, Nordi-\ncYeti.cpp, SnowshoeBandit.h, and SnowshoeBandit.cpp.\n\nOne good way to handle this is to wrap the methods into what can be called\nan interface macro. This is a macro that simply declares all of the Creature methods,\nlike so:\n\n#define INTERFACE _Creature(terminal) \\\npublic: \\\nvirtual std::string GetName() const ##terminal \\\n\nvirtual int GetHitPoints() const ##terminal \\\n\nvirtual float GetMaxVelocity() const ##terminal\n\n#define BASE_Creature INTERFACE_Creature(=0; )\n#define DERIVED Creature INTERFACE_Creature(;)\n\nThe beauty of this is that we can now vastly simplify the class declarations of\nCreature and all of the classes derived from it:\n\n// Creature.h\nclass Creature\n{\n\n};\n\n// Skeleton.h\n\nBASE_Creature;\n\n36 Section 1 General Programming\n\nSe ee a ke ee ec a es\n\nclass SnowCrab\n: public Creature\n\n{\nhs\n\nDERIVED Creature;\n\n// NordicYeti.h\nclass NordicYeti\n: public Creature\n\n{\n\nDERIVED_Creature;\n}3\n// etc.\n\nNow, whenever we want to change one of the methods in Creature, we no longer\nhave to touch SnowCrab.h, NordicYeti.h, or SnowshoeBandit.h—all we need to\nchange is the interface macro (INTERFACE_Creature in Creature.h). We still need\nto modify the implementations in the various .cpp files; but given that the function is\nchanging, we'd need to do that anyway.\n\nFurthermore, our class declarations have become much more readable. When we\nlook at the class declaration of NordicYeti in NordicYeti.h, we see DERIVED Creature\nplus some number of other methods specific to a NordicYeti and not shared with\nother creatures. This immediately tells us what functionality belongs specifically to\nNordicYeti, and that if we want to see the declaration of the creature-level function-\nality, we should look for it in Creature.h, since that’s where it properly belongs.\n\nIt’s important to note that this interface macro is entirely different from the con-\ncept of an ‘interface’ in a language such as Java or C#. In these sorts of languages, you\ncan treat an interface as an object—you can pass it around as a reference and call any\nof its methods. An interface macro, however, is just a way of encapsulating a set of\nrelated function declarations to hide some of the unnecessary duplication that the\nstructure of the C++ language forces you to maintain.\n\nVery special thanks to Paul Tozour for supplying this macro trick.\n\nConclusion\n\neee\n\nREN REE REY DE REIN ROR UIA\n\nHopefilly, these examples have given you some renewed hope in macros and have\nexpanded your personal toolbox of solutions. Just remember to carefully weigh the\ncost versus the benefit; always strive to make your code easier to understand and more\nrobust. Used judiciously, these macros should make your programming tasks just a lit-\ntle easier and the results a little less prone to error.\n\nReferences\n\n[Dalton01] Dalton, ‘Peter, “Inline Functions Versus Macros,” Game Programming\nGems 2, Charles River Media, Inc., 2001.\n\n1.3 Finding Redeeming Value in C-Style Macros 37\n\n{Hyman99] Hyman, Michael, and Phani Vaddadi, Mike and Phani’s Essential C++\nTechniques, APress, 1999.\n\n[Kernighan88] Kernighan, Brian, and Dennis Ritchie, The C Programming Language,\nPrentice Hall, 1988.\n\n[McConnell93] McConnell, Steve, Code Complete: A Practical Handbook of Software\nConstruction, Microsoft Press, 1993.\n\n[RabinOO] Rabin, Steve, “Squeezing More Out of Assert,” Game Programming Gems,\nCharles River Media, Inc., 2000.\n\n[Rabin02] Rabin, Steve, “Implementing a State Machine Language,” AJ Game Pro-\ngramming Wisdom, Charles River Media, Inc., 2002.\n\n1.4\n\nPlatform-Independent,\nFunction-Binding Code\nGenerator\n\nAllen Pouratian, Sony Computer\nEntertainment RTime\nallenp@csua.berkeley.edu\n\nAree function binding tool scans your C code for function prototypes,\nsigns unique integers to each function, writes out code that hashes the proto-\ntype text names to the integers, and then writes out code for a ‘switch’ to bind these\nintegers to the code that calls the functions.\n\nOnce the code generated by the binding tool is compiled into your program, such\nan interface forms the core of a scripting engine or a network RPC executor without\nthe usual tedious and error-prone maintenance programming.\n\nThis gem is an extension of [Bilas00], from the original Game Programming Gems\n(2000).\n\nYouth and Wisdom\n\nanuassiebineiD\n\n38\n\ni NE area\n\nBack when we were young punks hacking on our first machines, we lacked the wis-\ndom to tweak our software without a rebuild. Later, we wised up a tad and started\nusing command line arguments. Later still, we used option files. Those of you who\nare in-crowd material wrote a tool to make your option files [Rabin00].\n\nNow that we're older punks, we'll design a tool to write the code that handles the\ninternals of calling any function in our programs by text name. For example, it sure\nwould be nice to avoid hard-coding the loading of a level, and script it instead. Also,\nif the design guy orders a new class of enemy bots for your shoot-em-up, wouldn't it\nbe great if the code needed to send the new function calls to the other client machines\nwrote itself automatically?\n\nCygwin\n\nBefore the fine souls at Red Hat published their Cygwin [Cygwin01] package, such a\ncoding stunt was not cheap. The Cygwin libraries allow most POSIX code to build\nand run in Windows 9x/NT/2000/XP environments. Thus, the ancient and venera-\n\nble compiler-generation tools Lex and Yacc, along with grammars and specifications\nfound for free on the Internet [Degener95], mean that everything necessary for pars-\ning C structures, typedefs, and function prototypes is mostly already complete on all\nGNU-supported platforms—complete, that is, on platforms where sufficient clue has\nbeen scraped together to complete the porting task. Since GNU support strengthens\nby the week, genuine versions of Lex and Yacc are there for downloading.\n\nGhost of Gems Past\n\nThe prequel to this gem, ([Bilas00]), thoroughly discussed the issues surrounding var-\nious function-binding mechanisms. Gradually, we were led through the simple yet\nimpractical and painful first and second design attempts. Through the lessons grew\nthe design for an automated and elegant Windows-, x86-, Visual C++ 6.0-specific\nsolution. Specifically, functions tagged for compile-time DLL export were parsed\nfrom compiler-generated export files into a table at runtime. This table then allowed\nthe look-up of function text names for associated IDs and their subsequent execution.\n\nAs we peruse the Lex specification for C [Degener95], we notice #define and\n#include are missing. The C preprocessor handles these and forwards the results to\nthe compiler. Fortunately, the writers of gcc have broken out the preprocessor into a\nseparate utility, called “cpp.”\n\nHere is what we will do. First, take a C module whose functionality you want\nexported, and run it through cpp. Then, for ‘Phase 1’ of this tool, take the product\ngenerated by cpp and extract function prototypes with the tool you will write with\nLex and Yacc. Next, in ‘Phase 2’ of this tool, take these extracted function prototypes,\nassign integer IDs to each of them, and generate C code for a table that associates the\nIDs with the prototypes. In ‘Phase 3,’ we must write out yet more C code for a func-\ntion that resolves function names into IDs, preferably with a ‘move-to-front,’ chain-\ning hash table. Finally, our tool generates a switch statement on said ID, which serves\nup the hard-coded function call with properly cast arguments. Thus, tool-generated\nC code leaves the platform specifics of calling functions to the compiler. Just compile\nand link in the tool-generated C code, and youre ready to go.\n\nOnce we have Lex'd and Yacc'd together our function prototype-reading tool, we\nneed it to shove out some fast C code to bind function text names to IDs. Surpris-\ningly, using a clever ‘move-to-front’ hash-table chaining mechanism [Zobel01] beats\nall trees, including self-adjusting splay trees [Sleator85] by at least threefold! Follow-\ning the Paredo principle, which states that 20% of the data is needed 80% of the time,\nthe most commonly accessed elements are kept at the chain's top.\n\nAfter compiling and linking our tool-generated C code into our games, we are\nready to reap the rewards! We can call our script-execution function on any script file,\nor we can write a new function for our server, and execute it on the server from any\nclient with no coding effort for translation and invocation.\n\n40 Section 1 General Programming\n\nKeep in mind that if all you desire is a way to call your C, C++, or Objective-C\nfunctions from scripts written in Perl, Python, or Tcl/TK, then visit www.swig.org.\nSupport for binding yet more languages to C/C++/objective-C code is in the works.\n\nThe Details\n\nse TR td ne aR RINNE 2 SIERRA RIC\n\nThe task of writing tokenizers for compilers surfaces so often that Mike Lesk and Eric\nSchmidt (Bell Labs) decided to write a tool to simplify the task. Review Chapter 1 of\nthe respective O’Reilly book [Levine95] if you need convincing that Lex will cut your\nworkload drastically.\n\nWe use regular expressions [Borsodi01] to express the tokens, and slam out C\ncode to handle each respective expression. Lex handles the dirty work of writing\nC code to extract the token and calls your C code when it’s found. The following Lex\ncode identifies some famous scientists and mathematicians of history:\n\n%{\n\n/* Put any C code here. It need not be a comment. */\n%}\n\n%% [\\t ]+ /* ignore white space */ ;\n\nNewton | newton { printf(\"Issac Newton\\n\") ; }\nPascal | pascal { printf(\"Blaise Pascal\\n\") ; }\nPasteur | pasteur { printf(\"Louis Pasteur\\n\") ; }\n\n[a-zA-Z]+ {printf({\"%s: don't recognize \\n\", yytext); }\n\n\\&.|\\n { ECHO; /* normal default anyway */ }\n\n56%\nmain{)\n{\nyylex()\n}\n\n/* Again, any C code of yours can go here */\n\nBetween the opening %{ and %}, we insert any C code we want at the top of the\ngenerated C code for this Lexer. Then, we nest the tokens we seek to extract between\nthe two %% groupings, followed by bracketed C code that we want executed when the\ndesired Lexeme is found. After the trailing %%, we again insert any C code we need.\n\nFear not, for you can also call functions and declare/assign variables from the C\ncode that follows each regular expression. Just make sure you link the Lex library into\nyour applications. If you use the Unix make utility, this is most commonly done by\nadding -11 to the line that summons the linker.\n\n1.4 Platform-iIndependent, Function-Binding Code Generator 41\n\noreo mn nuaireres na eerste tem\n\nYacc in Two\n\nThe engineers of the 1970's Bell Labs were an industrious bunch, so Yacc was written\nto ease the task of writing parsers. Just as English grammar specifies the syntax of Eng-\nlish sentences, we write a grammar for C so Yacc can distinguish a line of C from a\nline of Ada. Here is a simple Yacc grammar that will parse the simplest of English\nsentences:\n\n%{\n\n/* Put any C code here. It need not be a comment. */\n#include <stdio.h>\n\n%}\n\n%stoken NOUN VERB PRONOUN\n\n96%5\nsentence: subject VERB {printf(\"Baby talk!\\n\"); }\n\n5\nsubject: NOUN | PRONOUN ;\n56%\n\n#define ERROR_RETURN( intReturnValue, expression,\nstringExplanation ) \\\nif( expression ) \\\n{ \\\nprintf (\"Function Failure: %s in %s at line\n%d\\n\", stringExplanation, \\\n__FILE_, _LINE_ ) ; \\\nreturn intReturnValue ; \\\n+ \\\n\nextern FILE *yyin;\n\nmain(int argc, char* argv[])\n\n{\n\nFILE *fp ;\n\nERROR_RETURN( 1, argc != 2 , “main-->wrong number of arguments\")\n;\n\nfp = fopen(argv[1], “r\" ) ;\n\nERROR_RETURN( 2, !fp , \"main-->Invalid input\nfile\") ;\n\nyyin = fp ;\nwhile(!feof(yyin) )\n\n{\nyyparse();\n\nfclose( fp ) ;\n\n42 Section 1 General Programming\n\n}\n\nyyerror(s)\nchar *s;\n\nfprintf(stderr, “%s\\n\", s);\n}\n\nLike cousin Lex, Yacc allows direct insertion of any C code between %{ and %}\ninto the generated C file. This time, in addition to a C-style comment, we have\narranged for the loading of stdio.h. The words that follow %token designate tokens\nthat the grammar will recognize. Should you choose to use Lex with Yacc, these macro\ndefinitions will be common between your Lex and Yacc specifications.\n\nBetween %% groupings, we describe what are called productions of the grammar,\nwhere the grammar’s syntax is described to Yacc unambiguously. Typically, a pro-\ngrammer will include C code they want executed after a desired production. Follow-\ning the trailing %%, we again include all C code we want to include with the C code\ngenerated by Yacc. There is no need to link in a Yacc library the way we must with\nLex.\n\nduring development. Imagine changing a triggered sound with the change of a named\nWAV file, or any attribute of anything, without a rebuild. Visualize your producer\ndoing this instead, so that you can take time to hunt down another memory leak. If, a\nweek before shipping, someone deems that a game level is too dark—feel your sched-\nule pressure lessen as they adjust one variable at the top of your level-loading script.\n\nAl Directives\n\nIn a Gamasutra article, Charles Guy discussed modeling AI (Artificial Intelligence)\nbiologically with procedural directives [Guy99]. Again, the exported functionality\nallows tweaking by the nontechnical personnel working on the project. AI needs AI\n(Artificial Intervention—Yours!) to function acceptably, and scripts defining such\nbehavior will speed the process and lessen headaches in the long run.\n\nNetworkin\n\nOnce you have function binding integrated into your RPC system, you need\nnot worry about extending functionality when you expand your API. Say we're\nplanning a four-person, peer-to-peer network game, where in order for Player\nA to fire a missile, fire_missile() must be called on computers A, B, C, and D.\nIf the foundation for the calling mechanism on Machine A is laid once in a\ngeneric way using ANSI C variable-length argument lists (which refer to the\naforementioned tool-generated, function prototype table of IDs and encoded\n\n1.4 Platform-Independent, Function-Binding Code Generator 43\n\nConclusion _\n\ncern nnn cterreacemoaeenn Himsa:\n\nargument lists), no extra coding effort will be needed to translate and execute\neach new function at the other end of the network pipe.\n\nExporting and binding functions with tool-generated C code can save us lots of work\nin manually binding functions for scripting and RPC engines. Converting tasks that\ntraditionally required programmer modification over to the hands of designers and\nartists helps speed the iterative design cycle significantly.\n\nrete — SER RNR MnemEmRES\n\nReferences\n\n[BilasO0] Bilas, Scott, “A Generic Function-Binding Interface,” Game Programming\nGems, Charles River Media, Inc., 2000.\n\n[Borsodi01] Borsodi, Jan, “Regular Expressions Explained,” available online at\nhetp://www.zez.org/article/articleprint/11/, 2000.\n\n[Cygwin01] http://www.cygwin.com.\n\n[Degener95] Degener, Jutta, “ANSI C Grammar, Lex Specification,” available online\nat http://www.lysator.liu.se/c/ANSI-C-grammar-l.huml, 1995.\n\n[Degener95] Degener, Jutta, “ANSI C Yacc Grammar,” available online at hetp://\nvww.lysator fu se/c/AN SI-C-grammar-y.html, 1995.\n\n[Guy99] Guy, Charles, “A Modular Framework for Artificial Intelligence Based on\nStimulus Response Directives,” available online at http://www.gamasutra.com/\nfeatures/19991110/guy_01.htm.\n\n[Levine95] Levine, Mason, Brown, Lex & Yacc, O’Reilly & Associates, 1995.\n\n[Rabin00] Rabin, Steve, “The Magic of Data-Driven Design,” Game Programming\nGems, Charles River Media, Inc., 2000.\n\n[Sleator85] Sleator, Tarjan, “Self-adjusting Binary Search Trees,” JACM, Vol. 32, No.\n3, July 1985: pp 652-686.\n\n[Zobel01] Zobel, Heinz, Williams, “In-Memory Hash Tables for Accumulating Text\nVocabularies,” available online at http://goanna.cs.rmit.edu.au/-hugh/zhw- ipl.\n\nheml.",
      "page_number": 36,
      "chapter_number": 4,
      "summary": "This chapter covers segment 4 (pages 36-45). Key topics include function, functions, and functionality. Covers function. In most cases, a method will belong only to one class,\nand it’s not problematic to change it in only two places.",
      "keywords": [
        "Elmo.cpp void Elmo",
        "Elmo.h class Elmo",
        "code",
        "Creature",
        "void Elmo",
        "function",
        "Charles River Media",
        "Elmo",
        "class Elmo",
        "base class",
        "Foo",
        "Yacc",
        "base Creature class",
        "Elmo.cpp void",
        "Lex"
      ],
      "concepts": [
        "function",
        "functions",
        "functionality",
        "classes",
        "code",
        "coding",
        "files",
        "creature",
        "design",
        "designate"
      ],
      "similar_chapters": [
        {
          "book": "C++ Templates_ The Complete Guide",
          "chapter": 21,
          "title": "Segment 21 (pages 651-684)",
          "relevance_score": 0.63,
          "method": "api"
        },
        {
          "book": "More Effective C++",
          "chapter": 14,
          "title": "Segment 14 (pages 133-140)",
          "relevance_score": 0.63,
          "method": "api"
        },
        {
          "book": "Python Distilled",
          "chapter": 38,
          "title": "Segment 38 (pages 345-352)",
          "relevance_score": 0.63,
          "method": "api"
        },
        {
          "book": "Fluent Python 2nd",
          "chapter": 49,
          "title": "Segment 49 (pages 993-1010)",
          "relevance_score": 0.62,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 2",
          "chapter": 7,
          "title": "Segment 7 (pages 53-62)",
          "relevance_score": 0.62,
          "method": "api"
        }
      ]
    },
    {
      "number": 5,
      "title": "Segment 5 (pages 46-58)",
      "start_page": 46,
      "end_page": 58,
      "detection_method": "topic_boundary",
      "content": "1.5\n\nHandle-Based Smart Pointers\n\nBrian Hawkins, Seven Studios\nwinterdark@sprynet.com\n\nt any time, an object in a game can die and leave any pointers to that object dan-\n\nling with dangerous consequences. Handles are a common method for prevent-\n\ning these invalid pointers from being used, but handles incur a substantial overhead if\n\nused for every action to be performed on an object. To reduce this overhead, there is\n\noften a conversion provided from a handle to a pointer, but this can lead to accidental\n\nstorage of the raw pointer without any method of tracking its use. A better solution is\n\nto wrap the handle inside a smart pointer. This provides familiar syntax as well as\ngreater safety and debugging options.\n\nA smart pointer is a C++ class that uses syntax similar to a regular pointer, but it\nprovides added functionality that is not normally available to a regular pointer. One\nof the most common jobs performed by a smart pointer is ownership management of\nthe object data. There are many smart pointer implementations available with differ-\nent ownership strategies for each (deep copy, copy on write, reference counting, and\ndestructive copy), and it is important to consider which type is necessary for the task\nat hand. Andrei Alexandrescu provides a good overview of many smart-pointer fea-\ntures in Modern C++ Design [Alexandrescu01].\n\nLet’s consider when to use handle-based smart pointers. First, the object should\nhave a distinct owner that controls when it is destroyed—for example, if the scene\nmanager is the only one allowed to destroy a game object. If there is no distinct owner\nto determine when the object is destroyed, reference counting might be a better\noption. Second, the object’s destruction time should be unknown. A game object that\nis killed by the player is an example of an unpredictable destruction time. If the time\nan object is deleted is certain, it is usually not necessary to incur the overhead of han-\ndles. Finally, handle-based smart pointers are only necessary when several objects need\nto store pointers to the same object, such as four players that each require a reference\nto the same vehicle object. Otherwise, there is most likely a better solution with\nsmaller overhead.\n\nNow that you know when and why to use handle-based smart pointers, we can move\n\non to the details of implementing them safely and efficiently. But first, a description\n\n1.5 Handle-Based Smart Pointers 45\n\nof how handlc-bascd smart pointers are used will help in understanding what the\nimplementation is designed to accomplish.\n\nThe first step is to create the object instance and assign the resulting dumb\npointer (the term “dumb pointer” is often used to refer to a built-in pointer type) to a\nsmart pointer. There is no reason to keep the dumb pointer around, so this operation\ncan be performed in one line:\n\nt_HandlePointer<class> 1 _handle(new class);\n\nThe designated owner of the object instance can then assign this handle to any-\none that requires a reference to that instance:\n\nt_HandlePointer<class> 1 handleCopy = 1l_handle;\n\nWhen the object’s lifetime is over, the instance’s owner destroys the object.\nBecause the owner stores a smart pointer, a function is required rather than the delete\noperator (operator delete):\n\ng Destroy(l_handle) ;\n\nUsing a handle pointer is as close to using a dumb pointer as possible. For exam-\nple, the handle pointer can be dereferenced using operator -> or operator*. The han-\ndle pointer can also be checked to determine its validity using the same conditional\nthat would be used to check for a null dumb pointer:\n\nif(l_handle) {\n1_handle->m_Member () ;\n(*1_handle) .m_Member () ;\n}\n\nThis check should always be done if there is a possibility that the object has been\ndestroyed, thus invalidating the handle pointer.\n\nsb ENR RG RN ROR ROHN\n\nThe handle is at the heart of a handle-based smart pointer and therefore must be\nimplemented efficiently. The primary operations that are performed on the handle are\nconversion to a pointer and tests for validity. A very efficient way to convert from\nhandle to pointer is to store the pointer in an array and include the array index as part\nof the handle. The conversion then takes two simple operations to complete: First,\nobtain the index from the handle; and then, look up the pointer in the array using the\nindex.\n\nThe preceding conversion is only valid if the handle is still valid. There must there-\nfore be a method of determining that the contents at the index match the handle used\nfor the conversion. To accomplish this, a unique identifier can be assigned to each han-\ndle and stored with the associated pointer in the array. When the handle is invalidated,\n\n46\n\nSmart Pointer\n\nON THE CD\n\nSection 1 General Programming\n\nboth the pointer and unique identifier are removed from the array. Future attempts to\nuse the handle can be detected as invalid because the unique identifier is no longer at\nthat location in the array. Figure 1.5.1 shows a possible layout using this method.\n\nArray of Handle/Pointer Pairs\n\n0 1 2 3\n——O ere) CO eee\n\nHandle | Pointer\n\nUnique ID Array Index\nFIGURE 1.5.1 Example layout for resolving handles to pointers.\n\nWhile there are several methods for generating a unique identifier, a simple\nmethod usually suffices for handles. Simply start with one as the first unique identi-\nfier, and increment by two every time a new unique identifier is requested. The added\nadvantage of this method lies in the fact that zero is never a unique identifier because\nthe one bit is always set. Notice that no mention is made about checking for a dupli-\ncate unique identifier. As long as the bit count of the unique identifier is reasonably\nlarge compared to the number of objects in existence at any one time, the chances\nthat the same identifier will occur at the same location in the array is small enough to\nignore. Preventing the unique identifier from wrapping around will eliminate this\nminute possibility, although it will also limit the total number of objects.\n\nThe smart pointer wraps the handle to provide familiar syntax when using the handle.\nSince there are several good books and articles on all the details of making smart\npointers, we will concentrate on the issues that are specific to handle-based\nsmart pointers. These issues can be broken down into construction, destruction,\ndereferencing, and validation. The sample implementation provided on the CD-ROM\nprovides a fully working example.\n\nConstruction and Destruction\n\nConstructing a smart pointer from a dumb pointer requires the creation of a handle.\nThe constructor passes the dumb pointer to a handle manager in order to create this\n\n1.5 Handle-Based Smart Pointers 47\n\netnnsnncoo see eeerlssenestseeoneb A eeaeb OMS NENA eo ANN\n\nhandle. The handle and the dumb pointer, which will be used for validation and\ndereferencing, are then stored in the smart pointer.\n\nThe handle manager is typically a Singleton class [GoF95]—a class with one\nglobal instance. This is necessary to provide a central location for handle/pointer pairs\nfor later handle lookups. The manager also ensures there is only one handle per\npointer, but this comes with a performance penalty. This check can be avoided if a\ndumb pointer is assigned to a single handle-based smart pointer immediately on\nobject creation, and all subsequent use is through the smart pointer or copies of the\nsmart pointer.\n\nNormally, an object is destroyed using the delete keyword; but that is not possi-\nble with smart pointers. One option is to add a member function to the smart pointer\nthat will call delete on the dumb pointer. This can lead to confusing code, however,\nwhen the same variable has operator-> and operator. applied to it. A better alterna-\ntive is to use a friend function that deletes the dumb pointer when given a smart\npointer as an argument. Once the object is deleted, the handle manager must be\ninformed that the handle is now invalid.\n\nValidation\n\nIf there is the possibility that the object was destroyed, the smart pointer must be\nchecked for validity before it is dereferenced. There are two important conditionals\nthat are used when checking a handle-based smart pointer: equality and inequality.\nInternally, both tests must query the handle manager to determine if the handle is still\nvalid.\n\nThe inequality test is a simple matter of overriding operator!, but the equality\ntest requires a little bit more work to prevent strange behavior on the part of the smart\npointer. A simple class must be created that disables operator delete by declaring,\nbut not defining the operator, and then returning a pointer to a global instance of the\nclass from a conversion operator if the handle is valid. Otherwise, the conversion\nfunction can return a null pointer. More information on why this is the preferred\nmethod can be found in Modern C++ Design [Alexandrescu01].\n\nDereferencing\n\nThe most useful feature of a smart pointer comes from the dereferencing operators\noperator-> and operator*. These operators are the reason for keeping a copy of the\ndumb pointer in each smart pointer; this way, we can quickly return the pointer or a\nreference to the object. These operators should be extremely simple and efficient\nbecause they will be the most-frequently used handle-based smart pointer features.\nDebugging versions of these functions can also perform validation of the handle as an\nadded protection against the mistake of the caller not testing the smart pointer before\ndereferencing it.\n\n48 Section 1 General Programming\n\nenn AR AAA AAR NAR eR RR cman ea\n\nConclusion\n\nHandle-based smart pointers can be an efficient and powerful technique when used\nwith the right types of objects. The combination of handles and smart pointers sim-\nplifies object management and retains syntax familiar to all programmers.\n\nWe've covered the specific issues relating to smart pointers using handles, but\nthere is a lot more information available on smart pointers. Modern C++ Design\n[Alexandrescu01] and More Effective C++ [Meyers96] both contain a wealth of use-\n\nful information on smart-pointer implementation and uses.\n\n] Alexandrescu, drei, Modern C++ Design, Addison Wesley, 2001.\n[GoF95] Gamma, Erich, et al., Design Patterns, Addison Wesley, 1995.\n[Meyers96] Meyers, Scott, More Effective C++, Addison Wesley, 1996.\n\n1.6\n\nCustom STL Allocators\n\nPete Isensee, Microsoft Corporation\npkisensee@msn.com\n\nany games use custom memory allocation strategies, providing their own mal-\n\nloc and free functions or overriding the global operator new and delete. The\nC++ STL (Standard Template Library) provides a powerful extension that allows you\nto use your own allocation and deallocation methods with all standard C++ container\nobjects, including strings. This gem shows how to create custom allocators and inte-\ngrate them into game code.\n\nAs an example, suppose your game creates a list, manipu\nthrows the list away—all within a single function:\n\nstd::list<int> MyList;\n\nfor( int i = 0; i < 100; ++i ) // build the list\nMyList.push_back( i );\n\nMyList.reverse(); // manipulate the list\n\nIf this function is called once per game loop, the penalty you would pay for allo-\ncating and freeing list nodes could easily convince you not to use STL lists. Suppose\nyou could customize the list so that all memory allocations came from the stack rather\nthan the heap. Deallocations would be free, because stack memory is automatically\nreclaimed when the stack object goes out of scope. Here’s how the stack-based list\ncode might look using a custom allocator:\n\n// Create custom allocator object\n\nconst size_t nStackSize = 100 * 12;\nunsigned char Stack[ nStackSize };\nStackAlloc<int> sa( Stack, nStackSize );\n\n// Tell the list about the custom allocator\nstd::list<int, StackAlloc<int> > MyList( sa );\n\n// This code is the same\n\nfor( int i = 0; i < 100; ++i ) // build the list\nMyList.push_back( i );\n\nMyList.reverse(); // manipulate the list\n\n49\n\nON THE CD\n\nSection 1 General Programming\n\nStackAlloc is a custom STL allocator. The StackAlloc type is specified as a tem-\nplate parameter in the list declaration, and the StackAlloc object is passed to the list\nconstructor. In this example, the stack is specified as just large enough to allocate 100\nnodes. In most STL implementations, a list node consists of the object and two point-\ners. The full implementation of StackAlloc is available on the CD-ROM.\n\nPerformance-wise, this particular optimization produces code that runs two to\nthree orders of magnitude faster than the first version, depending on the compiler and\nplatform. Clearly, custom allocators offer huge performance benefits, and the beauty\nof allocators is that you can write your own implementations that use whatever allo-\ncation techniques make sense for your game.\n\nSTL containers include vector, deque, list, map, set, multimap, and multiset. The\nbasic_string object also meets the qualifications for a container. All STL containers\nallocate memory to store objects in the container. These containers allow you to pro-\nvide custom allocators that define how memory will be managed. For example, list\nis defined as the following:\n\ntemplate <typename T, class Allocator = allocator<T> >\nclass list { ... }j\n\nThe Allocator parameter is a default template parameter. In normal usage, it’s\nnot specified, and the default allocator, allocator<T>, is used. The default allocator\nwill be covered in more detail later.\n\nstd::list<int> IntList; // uses default allocator<int>\n\nAllocator Requirements\n\nAny allocator object must meet the minimum requirements set forth by the C++\nStandard in Section 20.1.5 of [Cpp98]. These requirements are not difficult to follow\nand involve writing mostly boilerplate code. However, it’s beneficial to understand all\nportions of the allocator class.\n\nTypedefs\n\nAll allocator objects must include the typedef names shown here. These typedefs are\nalmost always defined as listed in this section. However, the C++ Standard allows\nimplementations to provide alternative definitions. For instance, the pointer typedef\nmight refer to far pointers, or some other pointer type particular to the platform. In\npractice, the freedom to define alternate types is limited, especially since C++ has no\nway of defining a reference type other than good old T&. The moral of the story: Don’t\nalter these typedefs without fully understanding the ramifications.\n\ntypedef size t size_type;\ntypedef ptrdiff_t difference_type;\n\n1.6 Custom STL Allocators 51\n\ntypedef T* pointer;\n\ntypedef const T* const_pointer;\ntypedef T& reference;\ntypedef const T& const_reference;\ntypedef T value_type;\n\nConstruction and Copying\n\nAllocators are regular C++ objects, so there must be a way to construct them, copy\nthem, and destroy them. Here are the declarations for the constructors and destructor:\n\nallocator() throw();\nallocator( const allocator& ) throw();\ntemplate <typename U>\n\nallocator( const allocator<U>& ) throw();\n~allocator() throw();\n\nNotice the unusual template member constructor, which allows an allocator to be\nconstructed given an allocator of another type. Some compilers do not support tem-\nplate members yet, so this constructor may not exist in your implementation. Note\nalso that the C++ Standard explicitly requires that neither the constructors nor\ndestructor throw an exception.\n\nUtility Functions\n\nAllocator objects must provide a small set of utility functions. The most interesting\nutilicy function is max_size, which returns the maximum number of objects that could\nbe conceivably allocated via allocate.\n\npointer address( reference r ) const\n\n{\nreturn &r;\n}\nconst_pointer address( const_reference c ) const\n{\nreturn &c;\n}\nsize type max_size() const\n{\nreturn numeric_limits<size_t>::max() / sizeof(T);\n}\nAllocation\n\nThe allocate function is one of the two critical functions in the allocator object,\nand is the focus of custom allocation strategies. The C++ Standard says that allo-\ncate must return a pointer to raw memory of sufficient size to hold N objects of size\nT, where n is always greater than zero. The function does not construct the objects.\n\n52\n\nSection 1 General Programming\n\nThe second parameter is an allocation “hint,” commonly a pointer to another mem-\nory block used to improve locality of reference. The hint parameter is generally not\nused.\n\npointer allocate( size_type n, const void* pHint );\n\nHere's just one example of how this function could be written to conform to the\n\nStandard:\n\npointer allocate( size_type n, const void* )\n\n{\nassert( n> 0);\nreturn pointer( malloc( n * sizeof(T) ) );\n}\nDeallocation\n\nThe deallocate function is the second critical function of the allocator object. The\nC++ Standard states that this function must free storage for N objects of size T, where\nthe raw memory of those objects begins at a non-null storage location p. The pointer\np must have been previously returned by allocate from an equivalent allocator\nobject, and the function must not throw an exception.\n\nvoid deallocate( pointer p, size_type n );\n\nHere’s an example of how this function could be written to conform to the Stan-\n\ndard:\n\nvoid deallocate( pointer p, size_type )\n\n{\nassert( p != NULL );\n\nfree( p );\n\nIn-Place Construction and Destruction\n\nNotice that unlike new and delete, allocate and deallocate don’t construct or\ndestroy objects—they only deal with raw memory. For performance reasons, alloca-\ntors specifically separate out these operations. For instance, vector: :reserve() allo-\ncates raw memory, but only constructs vector::size() objects. Only if and when\nvector: :resize() is called would uninitialized objects actually be constructed.\n\nThe allocator construct function allows existing memory to be used for con-\nstructing an object in place. You cannot call a constructor directly in C++, but the\nplacement new operator provides the functionality needed. Placement new doesn’t\nactually allocate memory—it calls an object’s constructor using existing memory.\n\nvoid construct( pointer p, const_reference c )\n\n{\n\n// placement new operator\n\n1.6 Custom STL Allocators 53\n\nnew( reinterpret_cast<void*>(p) ) T(c);\n\n}\n\nThe destroy function allows an object to be explicitly destroyed without releas-\ning the memory. You can call a destructor directly in C++, which is exactly what\ndestroy does.\n\nvoid destroy( pointer p )\n\n//{ call destructor directly\n(p)->-T();\n}\n\nThe C++ Standard defines these functions very precisely. They must always\nbehave as shown here. The real purpose of these functions is to hide the notational\ncomplexity from containers.\n\nSuppose you've defined your own allocator object for a list of integers.\nlist<int, MyAlloc<int> > IntList;\n\nYou might be inclined to believe that MyAlloc<int>::allocate would be called\nwhenever a new item was added to the list. You would be mistaken. Most containers\n(vector being an exception) don’t actually allocate the objects they store. They allo-\ncate nodes. Each node contains an object plus one or more pointers. That means that\nallocators must have some way of converting from type T to type node, whatever type\nnode may be. The solution is called rebind.\n\ntemplate <typename U>\nstruct rebind\n{\n\n};\n\ntypedef allocator<U> other;\n\nRebind simply allows allocator<T> to allocate objects of another type, U. For\nexample, given allocator @ of type T, you can allocate an object of type U with the\nexpression:\n\nT::rebind<U>: :other(a).allocate( 1, NULL );\n\nDon’t worry if you don’t understand the gory template details. The important\nthing to remember is that the allocator you define for a given type has a way to allo-\ncate objects of different types (and sizes). The other important thing to know about\nrebind is that it requires a compiler with support for member templates in order to\nwork properly. STL implementations that work with nonconforming compilers must\nprovide their own mechanism for allocating nodes. For instance, older versions of the\n\n54\n\nSection 1 General Programming\n\nDinkumware STL library [Dinkum] provide the function _Charalloc to support\nnonconforming versions of Microsoft Visual C++.\n\nComparing\n\nThe C++ Standard says two things about comparing allocators. First, it states that\nallocators are considered equivalent if and only if storage allocated by one can be de-\nallocated via the other. Then, it says that STL implementations are permitted to\nassume that allocators “be interchangeable and a/ways compare equal to each other.”\nIf these statements sound contradictory, that’s because they are. What the Standard is\nsaying is that allocator comparison is implementation-dependent. Some STL imple-\nmentations allow allocator comparison. Other implementations always compare allo-\ncators as equivalent.\n\ntemplate <typename T1, typename T2>\nbool operator==( const allocator<T1>&,\nconst allocator<T2>& ) throw();\ntemplate <typename T1, typename T2>\nbool operator!=( const allocator<T1>&,\nconst allocator<T2>& ) throw();\n\nIn many cases, it’s perfectly fine to assume that allocators are interchangeable.\nThe classic case is when the allocator has no data members. In other cases, you might\nreally want to compare allocators (for more detail on this issue, see Allocator State\n\nData, below).\n\nThe Default Allooator Object\n\nThe C++ Standard requires that all STL implementations include a default allocator\nobject called “allocator<T>.” This is the allocator that’s used if a custom allocator is\nnot specified. In other words, this is the allocator that your code is probably using at\nthe moment, so it makes sense to know what it is doing.\n\nThe default allocator object is defined in the C++ Standard in Section 20.4.1\n[Cpp98]. You can find the default allocator for your version of the STL in the <memory>\nheader file (or one of the headers included by <memory>).\n\nThe standard says the default allocator must call operator new to allocate storage.\nIf not enough memory is available, it throws the bad_alloc exception. A typical\nimplementation of the default allocate function looks like this:\n\npointer allocate( size_type n, const void* )\n\n{\nassert( n>0O );\nreturn pointer( operator new( n * sizeof(T) ) );\n\n}\n\nThe Standard says the default deallocate function must call operator\ndelete(p). A typical implementation of the default deallocate is:\n\n1.6 Custom STL Allocators 55\n\nWritin Your Own Allocator\n\nvoid deallocate( pointer p, size_type )\n{\n\nassert( p != NULL );\n\noperator delete( p );\n\n}\n\nAs you might expect, the default allocator object simply wraps new and delete.\nImplementations are free to provide additional optimizations in the default allocator\nif they wish. You can examine your version of the STL to see how the default alloca-\ntor is implemented.\n\nAs mentioned above, every allocator object must meet the minimum requirements set\nforth by the C++ Standard. To be useful, it also has to function within any compiler-\nspecific limitations. The best way for you to meet these requirements (and limitations)\nis by copying the default allocator from <memory> and then customizing the allocate\nand deallocate functions, and potentially the constructors, destructors, and compar-\nison operators as well.\n\nHere’s the partial implementation of the StackAl1oc allocator shown at the intro-\nduction of the gem. Full source code is included on the CD-ROM. The allocate\nfunction simply returns a pointer to the next unused portion of stack memory, then\nupdates the number of bytes that have been allocated. If it runs out of stack space, it\nthrows bad_alloc(). The deallocate function doesn’t need to do anything, because\nstack space is automatically reclaimed. All of these functions are inlined template\nfunctions, so deallocate is a no-op in a release build.\n\ntemplate <typename T>\nclass StackAlloc\n\n{\npublic:\n\n// boilerplate typedefs here .\n\n// critical ctor\n\nStackAlloc( unsigned char* pStack,\nsize_t nMaxBytes ) throw()\nmpStack( pStack ),\nmBytesAllocated( 0 ),\nmMaxBytes({ nMaxBytes )\n\n{\n}\n\n// other ctors, dtor .\n// utility functions .\n\n// construct, destroy, rebind .\n\n56 Section 1 General Programming\n\npointer allocate( size type n, const void* )\n\n{\nvoid* pRaw = mpStack + mBytesALLocated;\nmBytesAllocated += ( n * sizeof(T) );\nif( mBytesAllocated+1 > mMaxBytes )\n\nthrow std::bad_alloc();\n\nreturn pointer (pRaw) ;\n\n}\n\nvoid deallocate( pointer p, size_type }\n\n{\nassert( p != NULL );\n\n}\n\n// member data .\n};\n\nPotenti I Uses\n\nWhen should you write your own allocator? If after profiling your game, you’ve deter-\nmined that the default allocator is a bottleneck, consider providing a custom allocator.\nIf your entire game uses a custom solution and you don’t want operator new being\ncalled at all, but you do want to use STL containers, consider writing a custom\nallocator.\n\nThere are far too many allocation strategies to possibly list them all, but Table\n1.6.1 lists a selected number of strategies to consider when creating a custom\nallocator.\n\nTable 1.6.1 Allocation Strategies\n\nType Description\n\nFixed-Size Pools All allocations are the same size; reduces memory overhead per allocation.\n\nShared Memory Allocations use shared memory. See [Stroustrup97] for an example.\n\nMultiple Heaps Allocations come from different heaps, depending on the allocation size or type.\n\nSingle Threaded Allocations and deallocations are not thread-safe; useful within single-threaded code,\n\nGarbage Collected Deallocations don’t free memory; garbage collector function is called to free memory.\n\nStack Based All memory resides on the stack. Useful for containers with short lifetimes.\n\nStatic Memory Allocations come from program data space (static memory).\n\nNever Delete Deallocations never free memory; memory is reclaimed when application exits.\n\nOne-Time Delete Deallocations never free memory; memory is reclaimed by custom function.\n\nAligned Memory is aligned to meet certain requirements. Examples include page-aligned\nmemory or SSE instruction-aligned memory.\n\nDebugging Allocation logging, pinpointing leaks, checking for memory overwrites, peak allocation\n\nsize, and so forth.",
      "page_number": 46,
      "chapter_number": 5,
      "summary": "This provides familiar syntax as well as\ngreater safety and debugging options Key topics include allocators, allocations, and allocate. Handles are a common method for prevent-\n\ning these invalid pointers from being used, but handles incur a substantial overhead if\n\nused for every action to be performed on an object.",
      "keywords": [
        "Pointers Brian Hawkins",
        "smart pointer",
        "pointer",
        "Handle-Based Smart Pointers",
        "Smart Pointers Brian",
        "allocator",
        "Custom STL Allocators",
        "allocator object",
        "object",
        "handle",
        "Brian Hawkins",
        "Smart",
        "dumb pointer",
        "default allocator",
        "default allocator object"
      ],
      "concepts": [
        "allocators",
        "allocations",
        "allocate",
        "allocated",
        "pointers",
        "object",
        "handle",
        "functionality",
        "function",
        "functions"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 7",
          "chapter": 6,
          "title": "Segment 6 (pages 48-56)",
          "relevance_score": 0.61,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 39,
          "title": "Segment 39 (pages 359-367)",
          "relevance_score": 0.61,
          "method": "api"
        },
        {
          "book": "operating_systems_three_easy_pieces",
          "chapter": 17,
          "title": "Segment 17 (pages 154-161)",
          "relevance_score": 0.61,
          "method": "api"
        },
        {
          "book": "Effective_Modern_C++",
          "chapter": 13,
          "title": "Segment 13 (pages 134-141)",
          "relevance_score": 0.59,
          "method": "api"
        },
        {
          "book": "More Effective C++",
          "chapter": 8,
          "title": "Segment 8 (pages 61-75)",
          "relevance_score": 0.59,
          "method": "api"
        }
      ]
    },
    {
      "number": 6,
      "title": "Segment 6 (pages 59-68)",
      "start_page": 59,
      "end_page": 68,
      "detection_method": "topic_boundary",
      "content": "1.6 Custom STL Allocators 57\n\nAllocator State Data\n\nCd\n\nAs mentioned above, STL implementations might allow any allocator to be equiva-\nlent to any other. That implies that unless your particular implementation supports\ncomparable allocators, it’s dangerous for allocators to hold per-object data/state of any\nkind. If you're writing an allocator that must work across multiple implementations,\nthe only safe path is writing allocators with no per-object data. The nice thing about\nthis restriction is that allocators in such implementations generally have no space\noverhead. The drawback is that it might be more difficult to accomplish your task\nwith a custom allocator.\n\nOne of the easiest ways to see if your STL implementation supports allocators\nwith per-object data is to examine the implementation of list: :splice. In the nom-\ninal case, the splice function splices one list to another by shifting pointers, which is\nvery fast. Now, consider the case where the allocators for the lists are truly different—\nusing different heaps, for example. Splice cannot simply change pointers, because the\nresulting list would contain some nodes allocated on one heap and some on another.\nThe resulting list wouldn’t “know” how to delete some of its nodes!\n\nIn the list splice function, if there are two code paths based on the comparison\nof allocators, it’s likely you have an implementation that supports allocators with per-\nobject data. If not, it’s likely your implementation assumes that allocators are all\nequivalent.\n\nRecommendations\n\nBelow is a list of recommendations for writing a custom allocator.\n\n* Copy the default allocator from <memory> and replace allocate and deallocate.\nIf your allocator has state data, update the constructors and destructor. Don't for-\nget to include the global comparison functions.\n\n* Be aware that using allocator<T> does not necessarily mean that only blocks of\nsizeof (T) will be allocated. The rebind function allows other types—and there-\nfore other sizes—to be allocated.\n\n* Typedefs are your friends, especially when dealing with template code. Use type-\ndefs for allocators and containers that use custom allocators. If you need to make\na change, only the typedef will need to be altered.\n\n* Be wary of creating allocators that hold per-object data or that contain “state.”\nYour STL implementation might not support such allocators. Examine the list\nsplice function to determine if your implementation supports allocators with\nper-object data.\n\n* Due to current compiler technology, not all allocator implementations conform\nto the C++ Standard. When in doubt, examine the default allocator in <memory>\nto determine how your implementation works around compiler limitations.\n\n* Don’t add custom allocators until you need to. The great thing about the alloca-\ntor architecture is that allocators can be replaced with very few code changes.\n\n58 _ Section 1 _General Programming\n\nThe code included on ‘the CD- ROM i is ; designed t to > work with Microsoft Visual Stu-\ndio Version 6 and Visual Studio .NET. It was tested with STL implementation Ver-\nsions 3.08 and 3.10 from Dinkumware. These versions do support allocators with\nper-object data and allow nontrivial comparison functions.\n\nExample allocators are provided for a number of strategies, including multiple\nheaps, stack-based allocators, and static allocators. There’s also an allocator that sim-\nply wraps malloc and free.\n\nConclusion\n\nPine LE LRN NRE RARE\n\nWriting a custom 1 allocator is is a matter © of c copying some boilerplate code and cus-\ntomizing a handful of key member functions. Allocators have some curious features,\nand a working knowledge of these features is critical to understanding how allocators\nwork. It’s also important to note that different STL implementations might not sup-\nport allocators with per-object data and might provide custom member functions to\navoid compiler issues. Regardless of the complexities, custom allocators can signifi-\ncantly improve performance and are definitely worth understanding.\n\nReferences\n\n[Alexandrescu0 1] Alexandrescu, Andrei, Modern Ce. ++ , Design, Addison Wesley, 2001.\n[Austern98] Austern, Matt, “What are Allocators Good For?,” C/C++ Users Journal,\navailable online at http://www.cuj.com/experts/1812/austern.htm, May 1998.\n[Austern99] Austern, Matt, Generic Programming and the STL, Addison Wesley,\n1999.\n\n[Cpp98]} ISO/IEC 14882, ANSI C++ Standard, August 1998.\n\n[Dinkum] Plauger, P J., et. al., “Dinkumware Standard Template Library,” available\nonline at http://www. dinkumware.com.\n\n[osuttis99] Josuttis, Nicolai, The C++ Standard Library: A Tutorial and Reference,\nAddison Wesley, 1999.\n\n[Meyers01] Meyers, Scott, Effective STL, Addison Wesley, 2001.\n\n[Plauger01] Plauger, P. J., et. al., The C++ Standard Template Library, Prentice Hall,\n2001.\n\n[Stroustrup97] Stroustrup, Bjarne, The C++ Programming Language, Third Edition,\nAddison Wesley, 1997.\n\n1.7\n\nSave Me Now!\n\nMartin Brownlow, Shiny Entertainment\nmbrownlow@shiny.com\n\nany recent games have been released with one vital feature missing, and this one\n\nfeature has probably generated more user complaints than any other element of\na game. What could possible cause so much commotion? It is none other than the\nability to save the game at any point. Saving your game on demand is generally taken\nfor granted by the game-playing public; and if this functionality is missing, the public\nwill complain loudly and often.\n\nHowever, some categories of games can get away without it. Several game types\nwould actually almost be ruined if you could save at any point. Could you imagine\nBubble Bobble if you could save the game whenever you wanted? Unfortunately, most\nmodern PC games do not realistically have the luxury of excluding a save game feature.\n\nIt is possible to argue that the ability to save at any point can significantly\ndecrease the difficulty of a game, hence adversely affecting or severely curtailing the\nlongevity of a game. This is reason enough for not implementing it. Most games\ninstead support saving only at specific points where certain things can be taken for\ngranted, simplifying the implementation. Unfortunately, this approach usually has a\ndetrimental effect on the whole gameplay experience. Players feel cheated and often\nthink that the feature was omitted to artificially inflate the playing time by making\nthem replay the same 20 minutes over and over again. A better approach would be to\nallow saving the game at any point, but revoking that ability during crucial gameplay\nareas, such as the ubiquitous boss encounter.\n\nSaving a game at an arbitrary position is one of those annoying tasks—to the layper-\nson it seems remarkably simple, but when you get right down to the nuts and bolts,\nyou discover that hard work is involved.\n\nDuring the course of a game, even with clever object reuse, memory gets frag-\nmented and object lists get jumbled. So, at any given time, it is nearly impossible to\nsay where in memory a new object will be generated. A solution to this is to replace all\npointers in the game with handles, which are then de-referenced through a lookup\ntable. However, if you are not using handles, another solution is to change all point-\ners to handles as they are written to disk, and then de-reference the handles back into\n\n60 ; Section 1 General Programming\n\npointers after loading. Note that this will require several passes through the ‘save data’\nprior to saving and after loading.\n\nAnother large hurdle is deciding exactly what to save for each object. Once this\ndecision is made, it is necessary to write functions that read and write the data for\neach object type. Since most games have many types of objects, this can become an\nonerous task. Also, whenever any data structures change, all saved games are invali-\ndated and new code must be written. This is often why the task of writing the save\ncode is postponed until the end of the project. In the worst cases, the code is either\nnot properly tested or it is omitted altogether as pressure mounts to finish the game\nwithin the time constraints.\n\nWhat we need is a little automation. Ideally, we should only have to specify what\ndata elements and types to save for each object class, pass a list of object instances to\n\ney save, and let the save-game manager handle the rest. In this gem, we will be discussing\nowmeco a SAVENGR class framework that manages game saves with this automation. The class\nfiles are available on the CD-ROM.\n\nThe\n\nAfter implementation, the process of saving a game becomes trivial. Simply specify all\nobjects that should be saved with calls to AddSaveObject(), and then call save() to\nsave the game. Loading a game is simpler still—just call Load() and the game is\nloaded.\n\nSAVEMGR builds a list of all the objects that are to be saved with each call to\nAddSaveObject(). When the Save() function is invoked, SAVEMGR goes through this\nlist and calls the Save() member function for each object. When a pointer to an object\nneeds to be saved, SAVEMGR searches through this list to find the referenced object. The\nposition in the list (beginning from one; zero is reserved for NULL pointers) becomes\nthe object’s ID, which is then saved in place of the pointer. Note that if the object\nbeing referenced by the pointer is not in the list, then the game cannot be properly\nsaved.\n\nWhen reading a file, SAVEMGR first reads the number of objects in the file. Then,\nfor each object, it reads its class [D and calls the SAVEMGR: :MakeObject() function to\ninstantiate an empty object of the correct type. Next, SAVEMGR calls the object's Load()\nfunction, which reads the object’s data. When all objects have been loaded in this\nmanner, SAVEMGR makes a final call to each object’s PostLoad() function, which de-ref-\nerences object pointers from object [Ds back into usable pointers.\n\nThe SAVEOBJ Class _\n\nEvery savable class should be derived from the SAVEOBU class and must implement the\npure virtual functions GetSaveID() and GetSaveData(). Optionally, a class can over-\nride the Save(), Load(), and PostLoad() virtual functions, but it must be careful to\ncall the base class version of the functions before returning.\n\n1.7 Save Me Now! 61\n\nHow does it know what data to save for each object? That is where the\nGetSaveData() function comes in. For each class, a static array should be defined that\nspecifies the data elements to write into the save file. This array defines the offset,\ntype, and length of each piece of data. The GetSaveData() function should return a\npointer to the correct array for the class. To retain simplicity, the SAVEMGR class defines\nseveral macros for common types, including pointers, allocated data, and contiguous\ndata blocks. Also, for class hierarchies, there is a macro allowing the class to refer to its\nparent’s save data description.\n\nThe GetSaveID() member function must return a unique ID for each type of\nclass. This ID is then used by the user-defined SAVEMGR: :MakeObject() factory func-\ntion to create a class of the correct type during loading.\n\nData es and Extensions\n\nThe SAVEMGR class natively supports the saving of several different data types through\nmacros that create the save table. These macros automatically fill out the SAVERECORD\nstructure by calculating the offset and length of the given data. The default types sup-\nported are contiguous generic data, pointers, allocated memory, and the save table of\nthe base class. These are listed in the save table through the macros SAVEDATA,\nSAVEPTR, SAVEALLOC, and SAVEBASE, respectively.\n\nThe SAVEDATA macro has two parameters; the first is the type of the class, and the\nsecond is the member variable name. For example, the mat member variable in\nthe PLAYER class would be declared with the macro SAVEDATA(PLAYER,mat) . Similarly,\nthe SAVEPTR macro takes the type of the class and the member variable name.\n\nThe SAVEALLOC macro takes three parameters—the type of the class, the member\nvariable for the memory pointer, and a member variable containing the length of the\nallocation.\n\nFinally, the SAVEBASE macro takes a single parameter—a pointer to the save data\ntable for the base class. For instance, for a class PLAYER derived from the class OBJECT,\nthe save table could contain an entry SAVEBASE (OBJECT: :obj_savetable). If the\nOBJECT class was derived from another class, say MASTEROBJ, then the OBJECT save table\ncould contain an entry SAVEBASE(MASTEROBJ: :mobj_savetable). Then, the PLAYER\nclass would automatically save the data elements for its base OBJECT class and also its\nbase MASTEROBJECT class.\n\nThese macros work by finding the offset of the given data element and its size,\nthen writing this into the save table. The SAVEALLOC function is slightly different,\nhowever. This macro saves not only the offset of the pointer to the allocated data, but\nalso the offset of a variable containing the size of the data that has been allocated. It is\noften necessary to save data types that are specific to the current game state. For\ninstance, we might need to save a pointer to a resource that has been changed from\nthe default. To do this, extra macros need to be defined, and the code to handle these\nmacros must be placed in the SAVEMGR member functions WriteData(), ReadData(),\nand CorrectData(). For our example, the code in WriteData() must translate the\n\n62 Section 1 General Programming\n\nresource pointer into some recoverable form (like the resource ID), and ReadData()\nmust translate it back.\n\nOverriding the Default Functions\n\nRCE\n\nIn some cases, it is desirable not to save certain data to the file, since it is derivable\nfrom other elements in the object. This is where the overridable Save(), Load(), and\nPostLoad() functions come in.\n\nWhen an object is saved, the save manager calls SAVEOBJECT: :Save(). This in\nturn calls SAVEMGR: :SaveData(), which actually writes the data out. If there is work to\nbe done before saving (for instance, deriving Euler angles from a matrix) then we\nmust override the Save() function. Note that the base Save() function must be called\nto perform the actual write.\n\nSimilarly, the Load() function can be overridden. However, there will be no data\nin the class until you have called the base class’s Load() function. Finally, the PostLoad()\nfunction can be overridden and called for each object after all the objects have been\nloaded. Its primary purpose is to restore all the pointers in the object, but it should\nalso be used to restore any data not saved in raw form (for instance, converting Euler\nangles to a matrix).\n\nSimple Example\n\nThe following code demonstrates saving a simple class.\n\nClass PLAYER : public SAVEOBJ\n\n{\npublic:\n/* constructors/members omitted */\nint GetSaveID();\nSAVERECORD *GetSaveData();\nprotected:\n/* This is the table returned by GetSaveData() */\nStatic SAVERECORD player_savedata[];\n/* This is the data for the PLAYER class */\nMATRIX mat;\nNTT *targetNTT;\n}3\n\n/* The data saved for class PLAYER */\nSAVERECORD PLAYER: :player_savedata[] =\n\n{\nSAVEDATA( PLAYER, mat) ,\nSAVEPTR(PLAYER, targetNTT),\nSAVEDONE ()\n\n}3\n\nSAVERECORD *PLAYER: :GetSaveData()\n{ /* return the data table for PLAYER */\n\n1.7 Save Me Now! 63\n\nreturn player_savedata;\n\n}\n\nint PLAYER: :GetSaveID()\n{ /* return a unique ID for this class */\nreturn PLAY_ID;\n\n}\n\n[RR RRRRERERERRERRER RRR EERERERERREREREREERK\n\nThis is the class factory function.\nIt takes a classID and makes an\nobject of the correct type\n\nRRRKKEEKERKKREKREEREREEEREEREKERERERERREEERER |\n\nSAVEOBJ *SAVEMGR: :MakeObject( int classID )\n\n{\nswitch( classID )\n{\ncase PLAY_ID:\nreturn new PLAYER();\n}\nreturn NULL;\n}\n\nThe PLAYER class is derived from the SAVEOBJECT base class and defines the inher-\nited pure virtual functions GetSaveID() and GetSaveData(). GetSaveID() returns\nthe value PLAY_ID, which is then used later in the class factory function,\nSAVEMGR: :MakeObject(), to create a class of the correct type. The GetSaveData()\nfunction returns a pointer to the save table for the PLAYER class, which defines the data\nthat will be saved and loaded. The save table defines just two member variables that\nneed saving—the mat variable and the targetNTT pointer.\n\nConclusion\n\nON THE CD\n\nSaving and loading games is arduous and requires careful data conversion and man-\nagement. With care and a little automation, however, this task can be transformed\ninto a simple task of maintaining one table of data for each type of class. The code\nprovided on the CD-ROM is a skeleton for a save/load manager. Many enhancements\nare possible. For example, the output stream could be passed through a compressor\nlayer or a cryptographic layer. You might want to add a header to the file to enable\nquicker parsing, or include a miniscreenshot to display in the file manger. It is even\npossible to extend the SAVERECORD entry to enable backward compatibility.\n\n1.8\n\nAutolists Design Pattern\n\nBen Board, Dogfish Entertainment, Ltd.\nben_board@yahoo.com\n\nC++ game programmer frequently finds it necessary to gain selective access to\n\nthe set of all objects of a type T (e.g., CAIPedestrian), where T is a leaf type of\nthe hierarchy derived from a base type B (e.g., CAIObject). Since there is often a list in\nthe game containing pointers to all objects derived from B, identifying the relatively\nfew entries of type T requires a wasteful search.\n\nA sensible alternative is to create a separate list containing just those objects of\ntype T, enabling immediate access to those objects in isolation. However, this method\nhas some problems:\n\n¢ We must decide where the list itself should be stored.\n¢ We must ensure objects are added to the list on creation and removed on dele-\ntion.\n\n* Rogue additions or deletions must be guarded against.\n\nCreating each list requires several lines of code in a number of places, and it is\neasy to introduce bugs, particularly by using copy and paste, or forgetting a step in the\nprocess. An ideal solution would be if the programmer could somehow mark the class\nas “to be listed,” and, with no further programmer effort, the class itself would create\nthe list, store it intelligently, and guarantee that it contained just the existing instances\nof itself. This gem provides just such a solution with a design pattern called autolists\nthat achieves all these features, removes much of the potential for bugs, and only\nrequires half a line of code for each class to be listed.\n\nimplementation\n\n64\n\nConsider a class, CListMe. We would like each instance of CListMe to be added to a\nspecial new list on construction and removed on destruction, and we would like to be\nable access this list simply, but in a suitably object-oriented manner.\n\nAutolists achieve this by way of a single C++ template class, TAutolists<T>.\nTAutolists<T> has these crucial features:\n\n¢ It has a static, private member variable of type list-of-pointers-to-Ts.\n* On construction, it casts its this pointer to type T* and adds itself to that list.\n\n1.8 Autolists Design Pattern 65\n\n¢ On destruction, it finds its entry in the list and removes it.\n* TAutolists exposes a read-only interface, allowing useful query functions with-\nout allowing the list to be altered directly.\n\nTo mark a CListMe as “to be listed,” simply derive it publicly from TAutolists\n<CListMe>:\n\nclass CListMe : public TAutolists<CListMe>\n{\n\n// no further references to TAutolists required\n}5\n\nSince the constructor for CListMe must call the parent constructor (that of\nTAutolists<CListMe>), the class's this pointer (cast to a CListMe pointer) is added to\nthe list. When the object is destroyed, the reverse process happens, and the pointer is\nremoved from the list, which is hidden in the parent class’ private scope. In both cases,\nthe derived class has nothing further to do to make this happen.\n\nAccess to the resulting list is via the TAutolists interface—no direct access is\nallowed to the list object itself. The following is a typical example of autolist usage:\n\nCListMe* pLM = TAutolists<CListMe>: :GetAutolistFirst()\n\nwhile (pLM)\n\n{\n\n// use pLM here\n\n// finally:\n\npLM = TAutolists<CListMe>: :GetAutolistNext();\n}\n\nGetAutolistFirst() and GetAutolistNext() both return a T*, which will point\nto either a valid existing T object or NULL if the end of the list has been reached. There\nis almost no danger that a returned non-NULL T* pointer refers to a nonexistent\nobject, given the restrictions on removals from the list. There is nothing for the pro-\ngrammer to forget to do!\n\nNote the explicit scope qualifications of GetAutolistFirst() and GetAutolist-\nNext() by use of the prefix TAutolists<CListMe>::. This is not strictly necessary in\nthe case where only one function of that name is visible (more on this shortly).\n\nIt is difficult to use this implementation incorrectly—there are two interface\nfunctions, which do not take any arguments. We could use an iterator system, but by\nexposing an extra type, requiring the declaration of another variable in the autolist\nloops, adding parameters to the list lookups, and essentially replicating a tiny subset\nof the regular list functionality without all the other useful stuff you can do with iter-\nators—it would be taking a step backward from the no-brainer, no-bugs purity of this\npattern.\n\n66 Section 1 General Programming\n\nComments on the implementation\n\nNow, let us discuss some of the details of this implementation.\n\nCost\n\nThe cost of autolisting a class is trivial: one static list object containing one list ele-\nment per object listed (as it would be with any list), one static iterator per list, and the\nvirtual function table entry for the TAutolists virtual destructor.\n\nNested Iterations\n\nIn the implementation presented, nested iterations of the list are not allowed. If\nGetAutolistFirst() for a list is called while another iteration is in progress further\nup the call stack, the iterator would become corrupted. This is addressed by asserting\nthat the iterator is NULL on starting a new iteration, but if nested accesses are likely\nto be useful, it is simple to replace the single static iterator in the TAutolists\nclass with an array (or list) of iterators to manage an iterator ‘stack’ within\nGetAutolistFirst/Next().\n\nAutolists Without Constructors\n\nA second point to make is that some games avoid using constructors and destructors\nin favor of Initialize and Shutdown methods that are explicitly called shortly after\nconstruction and before deletion in order to gain more control over these important\nphases of an object's life. In this case, it might be necessary to dilute the automation of\nthe pattern by moving the addition to and deletion from the list to separate functions,\nsay InitializeAutolists() and ShutdownAutolists(), and require that the autolisted\ntype call these explicitly—a step that must be remembered by the programmer, but at\na very small cost when considering the benefit.\n\nDownward Casting\n\nOne might raise an eyebrow at the cast down the inheritance tree that takes place in\nthe TAutolist constructor. We recognize this issue, but can see no practical cause for\nconcern, since there is little theoretical doubt about the type safety of the cast. The\ncompilers used do not complain, and problems have yet to be seen while adding to,\nremoving from, or querying a list. It might ease the programmer’s conscience if a\ndynamic cast is performed rather than a static one by enabling run-time type identifi-\ncation (RTTI). However, no such problems should occur.\n\nOther Storage Methods\n\nThe name of this pattern implies that lists are the only (or the preferred) method of\nstoring the instances of a certain class. This is not necessarily the case. A sister class to\nTAutolists might be TAutomaps, for example, which stores each new object in an STL",
      "page_number": 59,
      "chapter_number": 6,
      "summary": "This chapter covers segment 6 (pages 59-68). Key topics include function, functions, and functionality. Covers function. That implies that unless your particular implementation supports\ncomparable allocators, it’s dangerous for allocators to hold per-object data/state of any\nkind.",
      "keywords": [
        "Save",
        "object",
        "list",
        "Data",
        "Allocators",
        "PLAYER class",
        "PLAYER",
        "function",
        "save table",
        "type",
        "game",
        "SAVEMGR",
        "object class",
        "save data",
        "functions"
      ],
      "concepts": [
        "function",
        "functions",
        "functionality",
        "save",
        "saving",
        "saved",
        "allocators",
        "allocated",
        "allocate",
        "allocation"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 7",
          "chapter": 6,
          "title": "Segment 6 (pages 48-56)",
          "relevance_score": 0.61,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 1",
          "chapter": 10,
          "title": "Segment 10 (pages 86-98)",
          "relevance_score": 0.57,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 38,
          "title": "Segment 38 (pages 351-358)",
          "relevance_score": 0.57,
          "method": "api"
        },
        {
          "book": "operating_systems_three_easy_pieces",
          "chapter": 21,
          "title": "Segment 21 (pages 193-203)",
          "relevance_score": 0.56,
          "method": "api"
        },
        {
          "book": "Effective_Modern_C++",
          "chapter": 13,
          "title": "Segment 13 (pages 134-141)",
          "relevance_score": 0.55,
          "method": "api"
        }
      ]
    },
    {
      "number": 7,
      "title": "Segment 7 (pages 69-84)",
      "start_page": 69,
      "end_page": 84,
      "detection_method": "topic_boundary",
      "content": "1.8 Autolists Design Pattern 67\n\nmap. Indeed, one might create a suite of classes covering a range of aggregate methods\nto suit the expected populations of classes and to optimize their accesses. We have\n\nchosen the (STL) list example merely for simplicity.\n\nUse of Multiple Inheritance\n\nIt is also worth discussing the potentially controversial use of multiple inheritance (MI)\nimplied by this pattern. In order to mark a class with one existing parent as “to be\nlisted,” it must add TAutolists, a second parent. This is only a cause of limited con-\ncern; the problems associated with MI are dealt with in the natural use of the pattern.\n\nThe principal problem raised by the use of MI is name clashing—a type in a hier-\narchy ends up inheriting two or more functions with the same name from its parents.\nThis problem might be mitigated by carefully naming the public interface by includ-\ning the word “Autolist” in the Get*() functions. The chances of finding that name\nelsewhere in a hierarchy are slim. Of course, a name can always clash with itself: Con-\nsider the perfectly sensible and useful situation in which class CBase is a parent to class\nCDerived, and both are autolist clients:\n\nclass CBase : public TAutolists<CBase>\n\n{\n\n}\n\nclass CDerived : public CBase, public\nTAutolists<CDerived>\n\n{\n\n}\n\nWithin member functions of Chase, it is possible to access other members of your\nown type by referring to the autolist interface without the usual explicit scope qualifi-\ncation:\n\nvoid CBase::ExamineOtherCBases { )\n\n{\nCBase *pBase = GetAutolistFirst();\n// not strictly necessary to write\n// TAutolists<CBase>::GetFirst(), because this\n// way is unambiguous\n}\n\nHowever, this is not the case within CDerived, which inherits two functions called\nGetAutolistFirst() (one from its own TAutolists inheritance, and one via the\ninheritance from CBase). In this instance, it is necessary to fully resolve the scope:\n\nvoid CDerived: :ExamineOtherDerived ()\n\n{\nCDerived *pDerived = GetAutolistFirst();\n\n// syntax error — ambiguous call\n\n68 Section 1 General Programming\n\nCDerived *pDerived =\nTAutoLists<CDerived>: :GetAutolistFirst();\n// no error, and arguably clearer syntax\n\n}\n\nIn our project, we have imposed the rule chat all uses of autolists, whether or not\nthe scope is ambiguous, should explicitly state the scope in question, partly for read-\nability and partly to maintain good habits.\n\nConclusion\n\nAutolists are a design pattern intended to ease the common game-programming task\nof tracking all instances of a particular class type, without the programmer manually\nmaintaining a list per type (a bug-prone operation requiring several steps).\n\nThis is achieved by a single template class, TAutolists, which, when used as a parent\nclass for a class J; creates a new list of pointers-to- 7, hides its implementation behind\na simple interface, and causes each new instance of T to be added to the list on cre-\nation and removed from the list on deletion—all in half a line’s worth of additional\ncode. Autolists list your objects so you don't have to. The TAutolists<> class defini-\ntion can be found on the CD-ROM.\n\nON THE CD\n\n1.9\n\nFloating-Point Exception\nHandling\n\nSeren Hannibal, Shiny Entertainment\nsorenhan@yahoo.com\n\nMi: programming packages for creating Windows applications create applica-\ntions in which floating-point exceptions are often handled automatically, caus-\ning the processor to keep quiet about any floating-point errors that might occur. This\ngem will show you how to make your program crash when one of these errors occurs,\nby only adding three lines of code. It will also give you a few hints on how to locate\n\nthe bugs.\n\nWhy should these errors be exposed in the first place? There are at least three good\n\nreasons:\n\n¢ Cross-Platform Compatibility: Since other processors and other operating sys-\ntems might be much less forgiving, any code that could potentially cause floating-\npoint exceptions might crash on some platforms and run on others.\n\n* Performance: Depending on the design of the processor, an instruction causing\nan exception might be slower than a well-executed instruction. Furthermore,\nsince many operations work differently with illegal or infinite floating-point val-\nues, the code might run much slower or even lock up. For example, the following\nloop will lock up if x is an infinite number, as half infinite is still infinite:\n\nint counter=0;\nwhile (x>1.0f)\n{\nx=x/2.0F;\ncounter++;\n\n}\n\n* To Avoid Sloppiness: Although most floating-point errors are very innocent,\nthey can easily hide bigger problems that typically surface at 2:00 a.m. the night\nbefore a major deadline.\n\n69\n\n70\n\nener ONAN ENR AHL HN\n\nIt is important not to think of this gem as introducing bugs into programmers’\n\ncode; our goal is only to expose the bugs that are already there. Therefore, it is in the\nbest interest of every programmer to use the method in this gem to find and fix any\ncode that causes floating-point exceptions.\n\nDoes Your Program Handle\n\nFloating-Point Exceptions? 7\nSome compilers (e.g., Microsoft Visual Studio 6) disable floating-point exceptions by\n\ndefault; and therefore, you should always perform a test when switching program-\nming environments. Here is a short piece of test code that, when put into a program,\nshould generate a division-by-zero error. You should be careful to put the test some-\nwhere in the core of your program and not in the very beginning, as some library calls,\nsuch as in the DirectX8 IDirect3DDevices: :Reset(), might disable the floating-point\nexceptions every time it is called.\n\nvolatile float x=1.0f;\nvolatile float y=0.0f;\nfor(int i=0;i<10;i++)\n\n{\n}\n\nX=x/Yy;\n\nThe code uses volatile to prevent the compiler from optimizing the division by\n\nzero out. When put into a project, it should be easy to see if your program ignores\nfloating-point exceptions or crashes it.\n\nException Types\n\nRAL NE\n\nos\n\naaron\n\nThe biggest consideration when enabling the floating-point exceptions is which types\nof exceptions to use. The Windows system routines allow access to six different types:\n\n_EM_INVALID—Invalid Exception. This should always be enabled.\n_EM_ZERODIVIDE—Division by Zero Exception. This should also be enabled.\n_EM_OVERFLOW—Overflow Exception. This should probably be enabled, except if\nthe application is written to work with infinite numbers.\n_EM_INEXACT—Exception for an Inexact Result. This exception should definitely\nnot be enabled, as most floating-point operations are slightly imprecise and\nwould set the flag.\n\n_EM_UNDERFLOW—Underflow Exception. This occurs when an operation gives a\nsmaller result than the floating-point register can contain, and it is rounded to\nzero. This exception should not be enabled, since, for example, the dot-product\nof two perpendicular vectors, with slight imprecision, would result in very small\nnumbers.\n\n_EM_DENORMAL—Denormal Exception. Denormals are slightly specialized cases of\nfloating-point numbers and are the smallest floating-point numbers available in\n\n1.9 Floating-Point Exception Handling 71\n\nthe IEEE754 standard. A very small number would become denormal before\nbecoming zero. Denormals can therefore be unavoidable; and as a general rule,\nthis exception should not be enabled. However, denormals are expensive com-\npared to normal floating-point values, and by testing your code with this flag on,\nyou might discover areas that can be modified to avoid denormals.\n\nThe Code\n\nThe code for enabling the floating-point exceptions is really simple. It reads the old\ncontrol register values, modifies them, and writes them down again. The code is:\n\n#include <float.h>\nvoid enableFPExceptions()\n\n{\nint i = _controlfp (0,0);\ni &= ~(EM_ZERODIVIDE|EM_OVERFLOW|EM_INVALID) ;\n_controlfp (i,MCW_EM);\n\n}\n\nThe tricky part is where to place it within the program. As mentioned above,\nsome libraries overwrite the floating-point exception flags. Therefore, after incorpo-\nrating this function into your code, it is very important that you test it. Again, the test\ncode should be at the core of the program, not just immediately after enabling the\nexceptions. Note that changing the floating-point exception flags can be expensive, so\nit should not be done for every frame. If you know which library functions overwrite\nthe control register, it would perhaps be a good idea to reset the flag before the library\ncall and set it again afterward.\n\nException Handling in Released Projects\n\nYou should also consider whether to enable floating-point exceptions in your released\nprograms or not. There are arguments for and against this, and the answer depends\non the type of program. For a game, it might make sense to disable all exceptions; a\nbug probably will not have any long-term effects when the program is closed down.\nOn the other hand, there is an argument for enabling them in programs such as level\neditors, since a level might get corrupted in memory and then saved to disk.\n\ning Floatin\n\n-Point Exceptions\n\nOk, so you enabled the exceptions and your program crashes. But the code next to the\ncrash looks fine. What is wrong, then?\n\nUnfortunately, the crash does not occur right away. Because today’s processors\nhave multistage pipelines, the floating-point error occurs at the earliest stage during\nthe next floating-point instruction, which might not even be in the same function.\nTherefore, it is very useful to switch to disassembly mode and look at the actual float-\ning-point registers instead of looking at source-level debugging output. Remember\nthis when you are trying to locate bugs that make no sense (at first).\n\n72 Section 1 General Programming\n\ncompatibility, performance, and avoidance of sloppiness. The code to check for float-\ning-point exceptions is simple, but care has to be taken to put it in at the right place\nand to test it carefully. Debugging can be confusing because of the delayed multistage\npipeline, but looking at disassembly instead of source-level output makes it easier.\n\nThere is no reason not to check for floating-point errors, and doing so offers the\npotential for more stability and higher performance. By using the information pre-\nsented in this gem, you will be on your way to writing better code in minutes.\n\n1.10\n\nProgramming a Game Design-\nCompliant Engine Using UML\n\nThomas Demachy,\nTitus Interactive Studio\ntdemachy@titus.fr\n\nL* admit it—as programmers, we are sometimes compelled to turn down great\ngame-design ideas because the game engine cannot cope with them. On the other\nhand, we might be disappointed when the game designer frowns at a brand new\nweather-control system, just because the game takes place underground.\n\nWe have all faced these situations, usually due to the fact that game design and\nengine programming are parallel tasks. Even if there are frequent interactions between\ndesigners and programmers, both have their own ideas of what the game should be.\n\nThis gem will explore collaborative work between the game-design team and the\nprogramming team, using a common graphic language—Universal Modeling Lan-\nguage (UML). By working together on the same model, designers and programmers\nwill focus on the game, and only the game, and thus reduce both delays and develop-\nment costs.\n\nThe Object Is in the Game_\n\nHANA NARA RARER\n\nObject-oriented programming (OOP) was modeled after the real world. Consider an\nobject—it is unique and identifiable, and therefore can be described with properties,\nsuch as its shape or color. In addition, any object interacts with the world and thus has\na specific behavior.\n\nThese two observations are the foundations for object-oriented methods. These\nmethods have been successfully applied to the software industry for more than 20\nyears, and many language implementations are available—Smalltalk, Java, and Visual\nBASIC, to name a few.\n\nFor several reasons, OOP just recently came to our industry with the growing use\nof C++ as a game programming language. For instance, [GPGO1] presents many con-\ntributions concerning the benefits of using C++. However, there is more to C++ than\na ‘plus’ added to C. It is a completely different paradigm, with a strong motto:\n“Think Object!”.\n\n73\n\nSection 1 General Programming\n\nSoftware and Game Design Share History\n\nRecently, one of the most difficult challenges faced in game design is how to break\naway from linear or multilinear storytelling. Too often, situations are described with\neach and every interaction specifically defined. It becomes impossible for the player to\nfreely choose their own unique path.\n\nIn a lecture entitled “The Future of Game Design” [Smith01], Harvey Smith (Ion\nStorm) promotes object-oriented game design in order to gain ‘global consistency’\n(among other benefits). He demonstrates that by using object classes that inherit\nproperties from one another, a more credible game universe can be achieved. Sound\nfamiliar? It probably does.\n\nA Solution for Collaborative Work\n\nSince game design is becoming more object-oriented, now is the time to work\ntogether and use a common language. The Universal Modeling Language was first\nintroduced in the mid-90s and enables this collaborative opportunity. UML is a\ngraphic-modeling toolbox, mainly used for software design; but it was intended from\nthe start to be applied to any kind of design. This gem is not intended to be a UML\ntutorial. There are plenty of resources available in books or on the Web, several of\nwhich are listed in the References section.\n\nAll the World’s a Stage\n\nWhen considering design tools, it’s important to take the dynamic aspect of game’s\ndesign into account. If the world were really a stage, then a modeling language would\nhave its own actors. This is the case for UML. From the game scenario, you can iden-\ntify characters and actions. For UML, an actor is an entity with a role, such as the\nplayer, a nonplaying character, a vehicle, ... even a weather-control system. It intro-\nduces actors, use cases, sequences, and collaborative diagrams.\n\nIntroducing Groody\n\nBoth the game designer and the programmer use the game scenario as the starting\npoint. Imagine you are working on a 2D platform game called Groody. The fairly\nbasic scenario would go something like: Groody features a hero running through a\nscrolling background. He can jump from one white cloud to another, but must blow\nstormy clouds away by using his wind blower. If a stormy cloud hits Groody, he might catch\na cold.\n\nDefining Which Case to Use\n\nThe first step is to identify the actions and actors. For Groody, we identify three actors\nthat can initiate an action—the game player, Groody, and the stormy cloud. Note\nthat the game player and its virtual avatar are two different actors—you don’t run in\n\n1.10 Programming a Game Design-Compliant Engine Using UML 75\n\nfront of your screen like the hero does in the level. We then need to define the ‘main\nactions’ of the scenario. For UML, these actions are formalized as use cases. Use cases\nare very important because they define how the system will be built. In Figure 1.10.1,\nactors are drawn as stick figures, and use cases are drawn as ovals. The lines between\nthe objects symbolize communication. The supported actions can be stereotyped as\n“uses” or “extends,” linking several cases together. In this diagram, the Run Through\nLevel case uses the Jump over white clouds case. Each use case must also be described\nin plain language, including normal control flow, alternative operation, special cases,\n\nand so on.\nRun Through <<uses>>\nLevel\nUse Wind\nGroody Blower\n| a Fly after to hit\nHuman Stormy\n\nFIGURE 1.10.1 Use case diagram for Groody.\n\nUnwrapping the Action\n\nUse cases are wonderful for creating a quick draft of the design concepts, but they can\nbe far too abstract and can be misinterpreted as more-detailed concepts. In an actor\nuse-case relationship, each time that an instance of an actor is created, it will execute\nan instance of the use case, also called the “scenario.” This scenario is unwrapped\nalong a timeline and represented in the sequence diagram (see Figure 1.10.2).\n\nA sequence diagram features the dynamic interactions between objects. If we\nfocus on the Use Wind Blower use case, a typical scenario would be:\n\n* Groody checks to see if he has energy cells left for the wind blower.\n¢ For each cloud in the level, check if there is a clear line of sight (LOS).\n¢ The first cloud with a clear LOS is hit and blown into thin air.\n\nSeveral sequences are defined for each use case. It is the sum of all these scenarios\nthat describes a use case.\n\n76\n\nClasses Move .\n\nRESP ARAN Ra\n\nSection 1 General Programming\n\n| WindBlower CloudsCollection | aCloud:StormyCloud [ Background |\n\nI\n\nGroody\nquery energy level\n\n[energy level Ok]\n\n|\n|\n|\nI\n|\n|\nfind target cloud |\n\n*[for each cloud]\nquery position\n\n*[for each cloud]\ntest visibility\n\n[target visible\nblown away\n\nFIGURE 1.10.2 Sequence diagram for the Use Wind Blower use case (time goes\ndownward).\n\nFrom Sequence to Collaboration\n\nSequence and collaboration diagrams are two sides of the same mirror—they convey\nexactly the same information. The only difference is that the sequence is time-based,\nwhereas the collaboration is object-based (see Figure 1.10.3). The magic of UML\nresides in this simple translation, which is the link between the dynamic and the sta-\ntic parts of the model.\n\nLike Stones Do\n\nea RENT\n\nThe game e of Go is paradoxical in a way. Opponents attack one another and gain ter-\nritories, essentially by laying down stones that will never be physically moved. The\ndynamic is born from the static. We have, until now, focused on the dynamic nature\nof objects and their relationships. In the game engine, however, the dynamic—the\nbehavior—is based on the object properties.\n\nNext, we will focus on the static representation for the game world and on the\n\nmost popular diagram for UML, the class diagram.\n\n1.10 Programming a Game Design-Compliant Engine Using UML 77\n\nWindBlower\n\n4: *[for each cloud]\ntest visibility\n\n3 : *[for each cloud]\nquery position\n\nFIGURE 1.10.3 Collaboration diagram for the Use Wind Blower use case.\n\nTwo Ways To Talk About Classes\n\nLeaning toward ever-more realistic simulations, modern games have to manage sev-\neral thousands of objects, each interacting with a subset of the domain. Class general-\nization (or inheritance) is one of the most powerful object-oriented mechanisms. By\nclassifying objects and creating hierarchies, it drastically downsizes the system’s com-\nplexity.\n\nUsually, inheritance cannot be identified from the dynamic analysis, since it\nmainly links object properties. During the class design, the secret to efficient collabo-\nration between the programmer and the game designer is ‘vocabulary’ (see Figure\n1.10.4). Both domains share the same object-oriented paradigm, but where the\n\nClass A Class A\n\n¢\n—_\n7\n‘\n\nAssociation :\n\"uses\", Aggregation :\n\nGeneralization :\n\"is a kind of\"\n\n\"sends a \"belongs\"\nmessage\", ...\n\nFIGURE 1.10.4 A word for each association.\n\n78\n\nCollaborate and iterate\n\nSection 1 General Programming\n\nar Rac EYED RE RDN NNT RE SN aS ae SEE ah ESS nr ta ISA Leen orees\n\nprogrammer uses the terms “association,” “aggregation,” or “generalization,” the game\ndesigner will refer to “uses,” “possesses,” or simply “is a kind of.” The words are dif-\nferent, but the graphical representations for these concepts are the same.\n\nCreating an Object Hierarchy\n\nThe collaboration diagram usually makes a good starting point. The messages become\nclass operations to be transferred in the class initiating the message. Communicat-\ning classes are in an association relationship, except when the link is asymmetrical. In\nthis case, we have an aggregation. There is aggregation when you can say that one\nobject is part of another, and when the destruction of the owner will force the destruc-\ntion of the owned.\n\nFrom the collaboration diagram (Figure 1.10.3), we define the messages as the\noperation from the calling class. Figure 1.10.5 shows a representation of a class dia-\ngram after one use-case analysis.\n\nWindBlower\nL EnergyLevel:integer\n\nQueryAmmo:integer\nFindTarget:StormyCloud*\nDestroyTarget\n\n(...)\n\n(...) Background\n\nGetEntityPosition:vector2D\nTestVisibility: Boolean\n(..-)\n\nFIGURE 1.10.5 Class diagram (incomplete), after one use case analysis.\n\nUML has more advantages than just simplifying communication between game\ndesigners and programmers. The main idea behind UML is the iterative modeling\n\n1.10 Programming a Game Design-Compliant Engine Using UML 79\n\nprocess. It means that it is not necessary (and not even desirable) to develop the whole\ngame design in UML before beginning the engine implementation. The process is\nincremental, back and forth between game designer and programmer. The use of case\ntools, such as those listed in the References, below, will smooth the entire process. In\nfact, several of these tools have code-generation and reverse-engineering features.\nThus, a programmer can code the game engine and go back to the design when\nneeded.\n\nBecause of its graphical nature, a UML model can be modified at very low cost.\nFor instance, when introducing a new enemy, say a snake, you might want to create\nan abstract enemy class and specialize the cloud class from this new one. This modifi-\ncation implies a minor modification to the class diagram (see Figure 1.10.6). We must\nintroduce the enemy abstract class, create the snake subclass, and then inherit the\nstormy cloud from the enemy class with the generalization link.\n\n| stormycious | | Snake ]\n\nFIGURE 1.10.6 Jncremental class diagram modifications.\n\nWhile implementing source, it implies inheritance modifications, just as with\nother design techniques. However, if you use a UML case tool, the code modifications\nwill be automatically rebuilt.\n\nModifications are not restricted to class hierarchy and can be done at any level. In\nthe sequence diagram (Figure 1.20.2), the Groody actor is responsible for polling\nthe level to find StormyCloud targets. For implementation reasons or to increase the\nreusability of the code, it might be preferable to introduce a combat resolver, estab-\nlishing the interface between the shooter and the target (see Figure 1.10.7). The new\nscenario would be:\n\n80\n\nSection 1 _General Programming\n\n1. Groody informs the combat resolver that he is shooting.\n\n2. The combat resolver determines if there is enough energy left in the wind\nblower.\n\n3. The combat resolver finds a stormy cloud in Groody’s line of sight.\n\n4. When a cloud is targeted, the combat resolver informs it that it is being\nblown into thin air.\n\nThis new scenario results in a new sequence diagram (Figure 1.10.7), which in\nturn produces a new collaboration diagram. The new class, CombatResolver, is simply\ninserted into the class diagram. Implementation constraints do have consequences on\nthe game design, however. Using a case tool, the whole process might take a few\n\nminutes.\nCombat Clouds aCloud:\nResolver WindBlower Collection StormyCloud packground\nT T ! |\nroody | |\nattack query | | | |\nenergy level , | (\n*[for each |\nquery [energy ; cloud} |\nweapon level Ok] ; | query I |\n| findtarget | position \\ |\ncloud |\n|\n|\n|\n|\n[target |\n\na\n\n, Visible] |\n\n| blown |\n\nj away |\n{\n{\n|\n|\n\nFIGURE 1.10.7 Modified version of sequence diagram from Figure 1.10.2.\n\nt tion I\n\nThroughout this gem, we have 1 not written one line of code. This demonstrates the\ncapacity of UML to be completely language-independent. However, implementation\ncan be done from the class diagram at any time. If you are using a UML tool, it can\nusually build the source code from the design automatically.\n\n1.10 Programming a Game Design-Compliant Engine Using UML 81\n\nHard Coding vs. Scripting\n\nSince UML can be translated into many languages, you can choose what will be hard-\ncoded and what will be described with a script. Usually, this decision is made very\nearly in the development process. Using a UML design, functions and classes can be\nincluded in the hard-coded areas or in the scripts.\n\nIf you choose an object-oriented script language, such as embedded Python\n[Python02], you can also use UML to code these game scripts. In fact, there is\nanother UML diagram perfectly adapted for behaviors and Al—the state diagram, as\nshown in Figure 1.10.8. The state diagram has been widely covered for AI state\nmachines [Dybsand00]. It unrolls all the different states that an object can encounter,\nalong with the conditional transitions.\n\nWandering Hit by wind blower\n\nDestroyed\n\nAttack done Touch hero\n\nAttacking\n\nFIGURE 1.10.8 State diagram for the StormyCloud class.\n\nHit by wind blower\n\nApplying UML to Your Project\nSeveral books, like [Muller97], describe the rules for widely used languages when\n\ntranslating the class diagram into plain code. However, the best option is to use a case\ntool that supports the whole iterative process, can generate the code in a chosen lan-\nguage, and can even reverse-engineer your code. This way, you have all the latitude\n\nnecessary to keep both the UML model and the code consistent.\n\nSection 1 General al Programming\n\nCurrently, the most popular UML tools are Together ControlCenter\n[Together02] and Rational Rose [Rational02]. The latter has been reviewed in Game\nDeveloper Magazine [Sari01], a sign that it is making its way into the game-develop-\nment community. There is also an open-source case modeler, ArgoUML [Argo02];\nbut since it is Java based, it does not implement complete code generation yet.\n\nREIL ROB ERE EINND\n\nThis gem proposed techniques for using UML for g game programming. It demon-\nstrated that using a modeling language can help game designers create object-oriented\ndesigns and emphasize the collaborative work between the programmer and the\ndesigner. The most recent version of UML (1.3) has many more features to offer that\ncan be adapted for your team collaboration.\n\nUsing a case tool gives you the ability to work incrementally with object-oriented\nmethods, while keeping complete control over the code and increasing maintainabil-\nity, documentation, and reusability of the game engine.\n\nReferences\n\nBeen Oe AR MING MENS AR ORIEN IO EERE\n\n[Argo02] ArgoUML Project, available online at t http: /Iwrwe. argouml. .org.\n\n[Dybsand00] Dybsand, Eric, “A Finite-State Machine Class,” Game Programming\nGems, Charles River Media, Inc., 2000: pp. 237-248.\n\n[GPG01] DeLoura, Mark, Game Programming Gems 2, Charles River Media, Inc.,\n2001.\n\n[Muller97] Muller, Pierre-Alain, Jnstant UML, Wrox Press, Inc., 1997.\n\n[Python02] Python 2.2 Script Language, available online at http: //www.python.org.\n\n[Rational02] Rational Software Corporation, http://www.rational.com.\n\n[Sari01] Sari, Jonathan, “Product Review: Rational Rose,” Game Developer Magazine,\nJuly 2001: pp. 10-11.\n\n[Smith01] Smith, Harvey, “The Future of Game Design: Moving Beyond Deus Ex\nand Other Dated Paradigms,” available online at http: ://www. ipa. org/Endeav-\nors/Articles/hsmith_intro.htm.\n\n[Together02] TogetherSoft Corporation, http://www.togethersoft.com.",
      "page_number": 69,
      "chapter_number": 7,
      "summary": "This chapter covers segment 7 (pages 69-84). Key topics include classes, programming, and program. Indeed, one might create a suite of classes covering a range of aggregate methods\nto suit the expected populations of classes and to optimize their accesses.",
      "keywords": [
        "game",
        "Game Design",
        "UML",
        "floating-point exceptions",
        "game programming",
        "code",
        "Programming",
        "Exception",
        "exceptions",
        "Design",
        "General Programming",
        "Floating-Point",
        "class diagram",
        "diagram",
        "case"
      ],
      "concepts": [
        "classes",
        "programming",
        "program",
        "game",
        "design",
        "uml",
        "useful",
        "uses",
        "figures",
        "floating"
      ],
      "similar_chapters": [
        {
          "book": "A Philosophy of Software Design",
          "chapter": 2,
          "title": "Segment 2 (pages 10-17)",
          "relevance_score": 0.62,
          "method": "api"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 2,
          "title": "Segment 2 (pages 19-41)",
          "relevance_score": 0.61,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 7",
          "chapter": 2,
          "title": "Segment 2 (pages 9-16)",
          "relevance_score": 0.59,
          "method": "api"
        },
        {
          "book": "A Philosophy of Software Design",
          "chapter": 11,
          "title": "Segment 11 (pages 88-95)",
          "relevance_score": 0.58,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 2",
          "chapter": 3,
          "title": "Segment 3 (pages 17-24)",
          "relevance_score": 0.58,
          "method": "api"
        }
      ]
    },
    {
      "number": 8,
      "title": "Segment 8 (pages 85-92)",
      "start_page": 85,
      "end_page": 92,
      "detection_method": "topic_boundary",
      "content": "1.11\n\nUsing Lex and Yacc To Parse\nCustom Data Files\n\nPaul Kelly\npaul_kelly2000@yahoo.com\n\nNM: game engine subsystems have reached quite a state of complexity—they\nrequire a great deal of data to configure the behavior of that subsystem. It is\nbeneficial to have that data specified outside of code and loaded at game initialization.\nData should be in a format that is easy to modify, which can be done with a custom\ndata file. Briefly, the format of the custom data file will contain the data and descrip-\ntions of the data. The separation of data from the code by using a custom data file has\nseveral benefits:\n\n* Creating a custom data file for the subsystem helps organize the data so that it is\neasy to modify with a text editor [Boer01].\n\n* Artists and game designers can change behaviors of the subsystem to balance\ngameplay.\n\n¢ Data is managed outside of source code. If data is stored within code, then it is\nusually the programmer's responsibility to make data tweaks, which would be a\ntremendous bottleneck to a project.\n\nThe custom data file is input to a tool. The tool takes the text description of the\ndata as input and transforms the textual data into a binary form. The binary file can\nthen be loaded directly into memory at game initialization. This data transformation\nby the tool will require a parser. However, writing custom parsers for all game subsys-\ntems would require a great deal of work. Why reinvent the wheel?! Lex and Yacc, an\napplication toolset that allows programmers to create a ‘programming language’ for a\ngame subsystem, can do most of the work for you. Lex and Yacc can extract data from\na text file and pass the data along to a tool for further processing. This gem presents\nmethods for using Lex and Yacc within a tool for processing custom data files that can\nbe compiled into binary data for a game subsystem.\n\nThe different sections of this gem break down the process of how to build a lexer\nand parser for a custom data file, as well as how to build a simple data file format. The\nfirst two sections provide a brief description of the basic functionality of Lex and Yacc.\nThe third section covers how both work together to parse custom data files. Refer to\n[Levine92] for a more complete reference for Lex and Yacc.\n\n83\n\n84 Section 1 General Programming\n\nThe last two sections cover methods of using Lex and Yacc to generate game data.\nThe first method will discuss generating game data from a custom data file for a game\nsubsystem. The second method will cover creating loadable game data from interme-\ndiate export data files. Finally, an example will be given. The examples in this gem\nwere tested using the non-GNU Flex and GNU Bison (instead of Lex and Yacc). See\nAvailability of Flex and Bison, at the end of this gem, for instructions on how to obtain\nthese applications.\n\nLex generates a source code file that specifies a lexical analyzer (also know as a lexer or\na scanner). In general, a lexer takes an input text file and combines the characters of\nthe text into individual pieces called tokens, which are assigned a meaning by the\nlexer. The tokens can then be passed to the parser [Aho86]. In our case, the parser\nwould be created by Yacc.\n\nThere are three sections to every Lex file: a C code section and the lexer specifica-\ntion, which is followed by another C code section. The first is used for inserting\ninclude files and the declaration of constants, macros, global variables, function proto-\ntypes, and other data types that are used by the lexer and the last (C code) section.\nThe second section defines the lexer. A lexer is defined by regular expressions that will\nbe used to tokenize the input. The last section is where code, such as utility functions\nfor processing input, will be located.\n\nYacc\n\nsna\n\nsah esse et tence se\n\nYacc is a parser generator. Yacc generates a source code file that specifies a parser (and\nan optional header file to be used by the Lex-generated code that contains token\ndefines). In general, a parser takes the tokens produced by the lexer and combines\nthem into phrases that have a particular meaning. Actions can be associated with the\nphrases. In our case of using custom data files, these actions are used to determine\nhow the text file should be interpreted into binary data.\n\nA Yacc specification has a similar setup as a Lex specification. The first section\ncontains C code and is usually used for inserting include files and the declaration of\nconstants, macros, global variables, function prototypes, and other data types that are\nused by the parser and the second C code section. The second section contains the\nparser definition. The parser definition consists of production rules and the associated\naction when a production rule is matched. The last section contains another C code\nsection that contains code used within the parser specification. Functions for error\nreporting and other input processing functions are located in this section.\n\ndvantages and Disadvantages\n\nSo, what is the advantage of using Lex to write lexers and Yacc to write parsers?\n[Levine92] points out that even a small lexer written in C that handles a simple com-\n\n1.11 Using Lex and Yace To Parse Custom Data Files 85\n\nmand language is three times as long as the equivalent Lex program. This could mean\nthat the C version could take three times as long to debug. When using Lex, there is\nonly a need to debug the regular expression or other code that determines string\nmatches for tokenizing the text. The same argument can be made for using Yacc.\nNevertheless, there are disadvantages to using a lexer created by Lex and parser cre-\nated by Yacc. The disadvantages are the same for both. The generated code is often\nmuch larger than it would be if you wrote it yourself. This is due to the necessary code\nthat handles all the functionality of Lex and Yacc—wasted space if that functionality is\nnot used. Also, the execution time of code generated by Lex and Yacc tends to be slower.\nThis because optimizations that could be performed in the coding of a lexer or a parser\ncannot be performed within a Lex lexer and a Yacc parser with as much relative ease.\n\nse RNS\n\ne anding of how Lex and Yacc work independently. How do\nthey work together to construct a parser for a tool? As shown in Figure 1.11.1, source\nfiles generated by Lex and Yacc are compiled and linked into a tool that uses them.\nThe tool will assign the Yacc global variable, yyin, to be a pointer to the custom data\nfile. Next, the tool will call yyparse() to start the parsing of the input text file. (See\nListing 1.11.4 for an example main() for a tool.) The source code that Yacc generates\nhas calls to the lexer functions created by Lex to grab the tokens of the input (the custom\n\nLex specification Lex generated C lexer code\n\nYacc specification Yacc generated C parser code\n\nC compiler generated object files\n\ntool's C source\n\ntool's executable file\n\nLinker\n\nFIGURE 1.11.1 Overview of the creation of a tool that uses a Lex and Yacc specification.\n\n86 Section 1 General Programming\n\ndata file), Data is passed from Lex to Yacc by using the Yacc sunion and another Yacc\nglobal variable, yyival. Data is passed to the tool from Lex and Yacc through global\nvariables. The values of the global variables are assigned within the actions of the\nparser specification (see Figure 1.11.2). The introduction to Lex and Yacc given above\nis a very basic one. For more information about Lex and Yacc, see [Levine92].\n\ncustom data file\n\nget next token\n\ndata file\n\nFIGURE 1.11.2 Interaction of lexer, parser, and a tool that uses them.\n\ndata extracted from\n\nA custom data file can be used to specify data for a game subsystem. The structure of\n\nthe custom data file can be difficult to define. However, most game data has some\nkind of structure that can be exploited to form a data file format that is both sensible\nin design and intuitive to the user. It is best to start simple and build on working cus-\ntom data file formats. For example, take a game that has a weapon system. A weapon\ncan have static and dynamic data. Static weapon data would include things like max-\nimum ammo ina clip, ammo type, and firing rate, to name a few. The static data can\n\ndata file, and the Yacc specification for the custom data file.\n\nListing 1.11.1 Weapon dat\n\nSTART_AMMO\nAMMO 9NM\nDAMAGE 5\nEND\nAMMO. 50CAL\nDAMAGE 15\nEND\nEND\n\nSTART_WEAPON\n\nbe configured using a custom data file. Listing 1.11.1 (on the CD-ROM) is an exam-\nple of a custom data file for a weapon system, the Lex specification for the custom\n\n1.11 Using Lex and Yacc To Parse Custom Data Files 87\n\nWEAPON MP5\nAMMO_CLIP) 30 /* num bullets in clip */\nAMMO_TYPE 9MM /* in millimeters *]\nFIRE_RATE 60 /* in rounds per second */\nEND\n\nWEAPON DESERT_EAGLE\nAMMO_CLIP 10\nAMMO_TYPE 50CAL\nFIRE_RATE 150\n\nEND\n\nEND\n\nThe custom data file must have enough structure so that a Yacc specification can\nbe made to uniquely identify all the elements of the file. This is mostly achieved in the\nabove example by delimiting sections with start and end symbols. Listing 1.11.1 can\nbe used as a template for most simple data-file formats. More-complicated formats\nwill use a similar structure, but will probably embed more nested substructures (areas\nsurrounded by a start symbol and an end symbol).\n\nA similar custom data file, Lex specification, and Yacc specification can be used\nfor power-up data, AI attributes, inventory data, player attributes, vehicle properties,\nand any other data for which a custom data file can be created. These systems would\nhave a similar data file to the weapon system’s data file.\n\nA custom data file can be created for menu or HUD system data, where data\nwithin those items might be dynamic, but the items themselves usually don’t change. A\nwhole specification can be created for menus within a data file that can be used to\nbuild all the screens of the game. For those of you familiar with Windows program-\nming, the resulting file would be similar to a Windows resource file. The specification\nwould tell the location of elements of the menu screen and the possible range of values.\n\nA Complete\n\nON THE CD\n\nLex and Yacc can also be used to parse text data exported from tools like 3D Max. It is\n\nsometimes easier to spot errors in model, terrain, and animation data exports if it is\nexported first to a text file for visual inspection. A parser can be written to convert the\ntext data to a binary file that can be loaded at game initialization. The parser could\nalso do error checking on the data if that is desired. An example of this kind of parser\ncan be found on the CD-ROM. The Packer program takes a text description of a\n.md3 Quake III model file and converts it to its binary representation. Unpacker is\nalso included on the CD-ROM. It converts a .md3 in binary form to its text form.\n\namp\nWe will now present an example (on the CD-ROM) using the custom data file format\nof the weapon system presented in Listing 1.11.1. We'll start by looking at the Lex\nspecification in Listing 1.11.2 (on the CD-ROM). The lexer code (generated by Lex)\nis called from the parser (generated by Yacc) whenever a new token is needed. As you\n\n88\n\ncan see, the lexer simply returns the next token it encounters. If the input text is\n“START_WEAPON,” the token constant TKN_START_WEAPON is returned to the Yacc\nfunction that called for the token. The Yacc functions retrieve tokens until a parse\nmatch is obtained. In addition to the type of token, values used in the parser actions\ncan be returned to the Yacc function via yylval.\n\nListing 1.11.2 Lex specification for weapon data\n\nan\n\n/* C code section for Lex specification */\n\n/*** INCLUDES ***/\n\n#include “weapon_y.h\" /* include token macros\ngenerated by yacc */\n\n#include <stdlib.h>\n#include <string.h>\n\n/*** PROTOTYPES ***/\nvoid RemoveComment (void);\n\nreturn TKN_FIRE_RATE; }\nreturn TKN_DAMAGE; }\n\nFIRE_RATE\nDAMAGE\n\n%}\n/*** LEXER SPECIFICATION ***/\n56%\nSTART_WEAPON { return TKN_START_WEAPON; }\nSTART_AMMO { return TKN_START_AMMO; }\nEND { return TKN_END; }\nWEAPON { return TKN_WEAPON; }\nAMMO { return TKN_AMMO; }\nAMMO_CLIP { return TKN_AMMO CLIP; }\nAMMO_TYPE { return TKN_AMMO_TYPE; }\n{\n{\n\n[0-9]+ { yylval.integer = atoi (yytext);\nreturn TKN_INTEGER; }\n\nu yee { RemoveComment (); }\n\n[a-2A-Z0-9]*[a-zA-Z}][_a-zA-Z0-9]*\n{ strepy (yylval.string, yytext);\nreturn TKN_IDENTIFIER; }\n\n56%\n/* C code section for Lex specification */\n\n/* function to remove a comment from the input data file. */\nvoid RemoveComment (void)\n\n{\nint ct =0, c2 = input();\n\nfor (33)\n{\n\nSection 1 General Programming\n\n1.11 Using Lex and Yacc To Parse Custom Data Files 89\n\nif (c2 == EOF)\n\n{\nbreak;\n}\nif (c1 == '*' && c2 == '/')\n{\nbreak;\n}\nc1 = c2;\nc2 = input();\n\n}\n\nNext, we'll inspect the Yacc specification in Listing 1.11.3. The Yacc specification is\na Backus-Navr Form (BNF) grammar [Aho86] with embedded actions. This Yacc speci-\nfication starts with the values that can be returned from the lexer, designated with the\nxsunion{} group. Next are the token types the lexer can return. These constants will\nbe placed in a header file. (A command-line argument to Yacc is necessary to generate the\nheader file and that header filename will need to be included in the Lex specification file.)\nThe second section of the Yacc specification is the parser definition. When a parser match\noccurs, any action associated with the match is executed. For instance, when “WEAPON\nMP3” is parsed, the action strcpy(weapon_tbl[weapon_cnt], $2->string); is executed,\nand then the parse continues until the whole input file is processed (assuming no errors\nhave occurred). This action specifies copying the production rule’s second token’s string\nvalue (returned by Lex) into the weapon table. The $2 denotes the token and the field\nspecifies what data is expected to be returned from Lex. These are unioned fields so be\ncareful! In this case, $2->string will be the string “MPS.”\n\nListing 1.11.3 Yace specification for weapon data\n_ custom data file.\n\naeRO aM a Oana eS RR GE NTS RR RSME\n\n/*** INCLUDES ***/\n#include \"weapon.h\"\n#include <string.h>\n#include <stdio.h>\n\n/*** GLOBAL VARIABLES ***/\nextern char *yytext;\n56}\n\n/*** TOKENS ***/\n// return types for tokens\n\nS%union\n{\nint integer; // for INTEGER token\nchar string[80]; // for IDENTIFIER token\n}\n\n// used by the lexer as return values so that the\n\n90\n\nSection 1 General Programming\n\n// parser knows which tokens have been found\n%stoken TKN_START_WEAPON TKN_START_AMMO TKN_END\n%stoken TKN_WEAPON TKN_AMMO\n\nS%stoken TKN_AMMO_CLIP TKN_AMMO_TYPE TKN_FIRE_RATE\n%stoken TKN _DAMAGE\n\n// tokens that can return a value from Lex to Yacc via // yylval\n%token <integer> TKN_INTEGER\n\n%stoken <string> TKN_IDENTIFIER\n\n%%\n\n/*** YACC SPECIFICATION ***/\n\n// weapon_data is the start symbol\n\nweapon_data: /* lamda rule - empty rule */\n| weapon_data weapon_section\n| weapon_data ammo_section\n\nweapon_section: | TKN_START_WEAPON weapon TKN_END\nweapon:\n/* lamda rule - empty rule */\n| weapon TKN_WEAPON TKN IDENTIFIER\n{ strcpy (weapon_tbl[weapon_cnt], $3); }\nweapon_attribute TKN_END\n{ weapon_cnt++; }\nweapon_attribute:\n/* lamda rule - empty rule */\n| weapon_attribute ammo_clip\n| weapon_attribute ammo_type\n| weapon_attribute fire_rate\n\nammo_clip:\nTKN_AMMO_CLIP TKN_INTEGER\n{weapon [weapon_cnt].ammo_clip = $2;}\nammo_type:\nTKN_AMMO_TYPE TKN_IDENTIFIER\n{strcpy (weapon [weapon_cnt].ammo_type, $2) ;}\nfire_rate:\nTKN_FIRE_RATE TKN_INTEGER\n{weapon [weapon_cnt].fire_rate = $2;}\n\nammo_section: TKN_START_AMMO ammo TKN_END\nammo:\n/* lamda rule - empty rule */\n| ammo TKN_AMMO TKN_IDENTIFIER\n{ strcepy (ammo_tbl[ammo_cnt], $3) ;}\nammo_attribute TKN_END\n{ ammo_cnt++;}\nammo_attribute:\n/* lamda rule - empty rule */\n| ammo_attribute TKN_DAMAGE TKN_INTEGER\n{ammo [ammo_cnt].damage = $3;}\n%6%\nint yyerror (const char *msg)\n{\nprintf (“%s at '%s'\\n\", msg, yytext);\nreturn 0;",
      "page_number": 85,
      "chapter_number": 8,
      "summary": "This gem presents\nmethods for using Lex and Yacc within a tool for processing custom data files that can\nbe compiled into binary data for a game subsystem Key topics include data, files, and tokens.",
      "keywords": [
        "custom data file",
        "data file",
        "Yacc",
        "Data",
        "Lex",
        "Custom Data",
        "Lex and Yacc",
        "TKN",
        "ammo",
        "weapon",
        "Yacc specification",
        "file",
        "Lex specification",
        "WEAPON TKN",
        "return TKN"
      ],
      "concepts": [
        "data",
        "files",
        "tokens",
        "parser",
        "returns",
        "weapon",
        "sections",
        "section",
        "ammo",
        "include"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 2",
          "chapter": 13,
          "title": "Segment 13 (pages 109-116)",
          "relevance_score": 0.68,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 7",
          "chapter": 55,
          "title": "Segment 55 (pages 530-540)",
          "relevance_score": 0.55,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 7",
          "chapter": 59,
          "title": "Segment 59 (pages 567-580)",
          "relevance_score": 0.51,
          "method": "api"
        },
        {
          "book": "Designing Data-Intensive Applications",
          "chapter": 15,
          "title": "Segment 15 (pages 135-143)",
          "relevance_score": 0.5,
          "method": "api"
        },
        {
          "book": "Designing Machine Learning Systems An Iterative Process for Production-Ready Applications",
          "chapter": 10,
          "title": "Segment 10 (pages 80-87)",
          "relevance_score": 0.5,
          "method": "api"
        }
      ]
    },
    {
      "number": 9,
      "title": "Segment 9 (pages 93-101)",
      "start_page": 93,
      "end_page": 101,
      "detection_method": "topic_boundary",
      "content": "1.11. Using Lex and Yacc To Parse Custom Data Files 91\n\n}\n\nListing 1.11.4 shows the general shell of a main() function from a tool that would\nuse the lexer and parser generated by Lex and Yacc.\n\ne code.\n\n#include \"“y.tab.h\nWEAPON_DATA weapon;\nint main (void)\n{\nFILE *in;\nin = fopen (\"weapon.data\", \"r\");\nyyin = in;\nyyparse() ;\n\n/* process data in weapon and write out as binary\ndata */\n\nreturn 0;\n\nConclusion\n\nThis gem shows how Lex and Yacc can be used to create parsers for custom data files.\nWith Lex and Yacc, you are given access to tools that can generate a very powerful\nparser. Take the time to get to know and become familiar with these tools; your time\nspent will be repaid tenfold in future time savings.\n\nAvailability of Flex and Bison\n\nFlex, a version of Lex that can be found on the GNU Website, and Bison, GNU’s ver-\nsion of Yacc, are available for free at the GNU Website [GNU02]. See [Flex02] and\n[Bison02] for FTP download information.\n\nReferences\n\n[Aho86] Aho, Alfred, et al., Compilers: Principles, Techniques, and Tools, Addison\nWesley, 1986.\n\n[Bison02] Free Software Foundation, March 2002. Bison Flex is available for down-\nload at ftp://ftp.gnu.org/gnu/bison/.\n\n[Boer01] Boer, James, “A Flexible Text Parsing System,” Game Programming Gems 2,\nCharles River Media, Inc., 2001.\n\n[Flex02] Free Software Foundation, March 2002. Flex is available for download at\nftp://ftp.gnu.org/gnu/non-gnu/flex/.\n\n[GNU02] Free Software Foundation, “GNU’s Not Unix!—the GNU Project and the\nFree Software Foundation (FSF),” available online at http://www.gnu.org/,\nMarch 2002.\n\n[Levine92] Levine, John, et al., Lex & Yace, O'Reilly 8& Associates, Inc., 1992.\n\n1.12\n\nMarket Potential\n\n92\n\nDeveloping Games for\na World Market\n\nAaron Nicholls, Microsoft Corporation\naaron_feedback@hotmail.com\n\nUh recently, developing games for multiple language markets was often done as\nan afterthought. Once the product was ready (or nearly so) for release in its core\nlanguage market, the coding work to support other languages would begin, with test\nand localization soon following. The resulting products were often delayed and very\nlimited in terms of language support. However, in recent years, many companies have\nreleased games in multiple language markets simultaneously, and titles such as Star-\ncraft and Diablo 2 have enjoyed phenomenal sales worldwide.\n\nIn order to capitalize upon the full market for a game, it is important to under-\nstand the technical obstacles and processes related to globalization. In addition, inte-\ngration of globalization techniques into the entire developmental process is essential.\nIn this gem, we will present the main issues related to the design, development, and\ntesting of world-ready games, as well as some solutions to the inherent problems.\n\nc.neceoraanonmnsianaantandrmniati ‘AOS ANNSAAALAN ANNA AARNE I CNR NORA RRTAN\n\n‘Traditionally, many games companies have had a tendency to focus on their local\nmarket, ignoring the global potential of a quality title. Many titles have received uni-\nversal praise and strong sales in the U.S., but no attempts were made to introduce the\ntitles to new markets. In other cases, a title is released worldwide, but the game is\nentirely in English—only the manual is translated. Fans of a specific genre and avid\ngamers in the know might be willing to put forth the effort to tackle a game that is\nnot in their native tongue. However, as a wider audience embraces PCs and game\nconsoles, it is important to appeal not only to the hardcore gamer, but to casual\ngamers as well.\n\nIn the past few years, there have been several game releases that have identified\nthe size of the international game market. For example, in 2000 and 2001, South\nKorea proved to be a very promising market. Both Starcraft and Diablo 2 were big\nhits, each selling more than 3 million copies worldwide. Of that total, approximately\none third of the sales were in South Korea alone, with over a million copies of each\n\n1.12 Developing Games for a World Market - 93\n\ngame sold there. The games became cultural phenomena of a sort, with the game\ncharacters featured in toys and on potato chip bags.\n\nSuch success stories have not only been the case with American games selling out-\nside of the U.S. As of January 2002, the best-selling, massively multiplayer, online\nrole-playing game was not Ultima Online, Asheron’s Call, or Everquest, but the Korean\ngame Lineage with over 4 million copies sold—and it hadn't even launched in the U.S.\nand Europe yet! With such examples of success, it is easy to understand the impor-\ntance of designing a game from the ground up to appeal to a world market of gamers.\n\ndisplaying the desired language(s). In addition, you might choose to provide input\noptions and customizations particular to each language version of your game.\n\nFonts\n\nFirst of all, you need fonts that contain all of the characters that must be displayed.\nWhile bitmap fonts are still used in some games, many have moved to TrueType and\nOpenType fonts for ANSI and Unicode character display, respectively. Unicode fonts\ncan contain characters for multiple languages, but they can result in much larger file\nsizes, also.\n\nFortunately, the latest versions of Windows and MacOS support input and dis-\nplay of a wide variety of languages, including the necessary fonts. However, games\ntypically use their own fonts (with the possible exception of install/uninstall), and it is\nimportant to consider a game’s target markets when obtaining or developing fonts. In\naddition, keep in mind that while English text may look perfectly clear in an 8-point\nfont, applying the same size to a traditional Chinese font might produce illegible text.\nYour game should be designed with enough flexibility to take such issues into\naccount.\n\nLine Breaks and Sorting\n\nIf your game supports multiline text input or display, one of the problems that can\narise is that of breaking multiple lines of text. The rules for line-breaking are relatively\nsimple for English and other European languages, but things are not as simple for\nmany other languages. For example, in Chinese and Japanese, spaces typically are not\nused to distinguish individual words in a sentence. Instead, sentences consist of char-\nacters with no spacing, although similar (but double-byte) punctuation is still used.\nAs such, it may be necessary to use more-advanced guidelines for determining where\nto break lines and wrap words. When dealing with multi-byte text, you can adopt the\nfollowing rule: Lines may be broken before, after, or between double-byte characters.\nHowever, when a line break is needed within single-byte characters, you should break\nat the last space or double-byte character.\n\n1.12 Developing Games for a World Market 93\n\ngame sold there. The games became cultural phenomena of a sort, with the game\ncharacters featured in toys and on potato chip bags.\n\nSuch success stories have not only been the case with American games selling out-\nside of the U.S. As of January 2002, the best-selling, massively multiplayer, online\nrole-playing game was not Ultima Online, Asheron’s Call, or Everquest, but the Korean\ngame Lineage with over 4 million copies sold—and it hadn't even launched in the U.S.\nand Europe yet! With such examples of success, it is easy to understand the impor-\ntance of designing a game from the ground up to appeal to a world market of gamers.\n\nFirst Things First—Display and Input\n\nceo RUAN\n\nWhen dealing with international game development, o1 one e of the first challenges is in\ndisplaying the desired language(s). In addition, you might choose to provide input\noptions and customizations particular to each language version of your game.\n\nFonts\n\nFirst of all, you need fonts that contain all of the characters that must be displayed.\nWhile bitmap fonts are still used in some games, many have moved to TrueType and\nOpenType fonts for ANSI and Unicode character display, respectively. Unicode fonts\ncan contain characters for multiple languages, but they can result in much larger file\nsizes, also.\n\nFortunately, the latest versions of Windows and MacOS support input and dis-\nplay of a wide variety of languages, including the necessary fonts. However, games\ntypically use their own fonts (with the possible exception of install/uninstall), and it is\nimportant to consider a game's target markets when obtaining or developing fonts. In\naddition, keep in mind that while English text may look perfectly clear in an 8-point\nfont, applying the same size to a traditional Chinese font might produce illegible text.\nYour game should be designed with enough flexibility to take such issues into\naccount.\n\nLine Breaks and Sorting\n\nIf your game supports multiline text input or display, one of the problems that can\narise is that of breaking multiple lines of text. The rules for line-breaking are relatively\nsimple for English and other European languages, but things are not as simple for\nmany other languages. For example, in Chinese and Japanese, spaces typically are not\nused to distinguish individual words in a sentence. Instead, sentences consist of char-\nacters with no spacing, although similar (but double-byte) punctuation is still used.\nAs such, it may be necessary to use more-advanced guidelines for determining where\nto break lines and wrap words. When dealing with multi-byte text, you can adopt the\nfollowing rule: Lines may be broken before, after, or between double-byte characters.\nHowever, when a line break is needed within single-byte characters, you should break\nat the last space or double-byte character.\n\n94\n\nSection 1 General Programming\n\nIn addition to line/word breaking, sorting rules also vary from language to lan-\nguage, and sorting by character code is usually insufficient. Fortunately, these rules are\nusually defined in the operating system and are typically exposed to you as the devel-\noper through system APIs.\n\nInput Method Editors (IMEs)\n\nOnce you have your characters displaying properly, you need to deal with input as\nwell. While some games allow input only in English, this can be very limiting when\ndealing with saving games, chatting with other players, or jotting down in-game notes\n(for those games with such features). Many users do not speak English as a first lan-\nguage, and limiting input to English can distract gamers and reduce immersion into a\ngame. Although supporting input of European characters requires few changes from\nan English-based product, other languages, such as Korean, Chinese, and Japanese,\nmight require more work to support.\n\nThe first problem with implementing support for input of these languages is that\neach of them has thousands of characters—far too many to fit on a keyboard. When\ndeveloping computer-based games, it might be possible to implement or use existing\ninput method editors (IMEs). An IME is a program that converts keyboard scan\ncodes (and, more recently, pen- or mouse-driven input) into character codes.\n\nFor example, for a user to input the word “sushi” in Japanese, they will first acti-\nvate the IME (usually with a user-defined keystroke or a dedicated key on a Japanese\nkeyboard). The IME then activates, and it intercepts the English letters “s-u-s-h-i” or\na Japanese phonetic equivalent as they are typed by the user. The IME then gives the\nuser a choice of candidate words corresponding to the phonetic spelling input by\nthe author. Once the user selects the desired word (or string), the actual character\ncodes representing the desired Japanese input are sent to the target application. If you\nchoose to support IME input in your game, you should familiarize yourself with the\nIME message codes and architecture for your platform (see References for Web links\nto IME information).\n\nInput Options Without IMEs\n\nUnfortunately, IME support is not always an option. Due to UI design or develop-\nment constraints, it may be impractical to implement or use an existing IME. This is\nusually the case when the target platform is a game console. However, with basic\nknowledge of the target language(s) for a game, it might still be possible to provide\nthe user with some level of input support.\n\nFor example, in a Japanese game, it is possible to allow users to input player\nnames in Japanese by providing an onscreen virtual keyboard containing only the\nkatakana or hiragana (collectively referred to as Kana) characters. These are two sets of\nphonetic characters, either of which can be used to represent any word in the Japan-\nese language. Although either alphabet is sufficient to represent any Japanese word\n\n1.12 Developing Games for a World Market 95\n\nphonetically, each has its own use, somewhat like upper- and lowercase letters in\nEnglish. A hiragana or katakana keyboard to allow input in Japanese can be imple-\nmented in approximately the same amount of screen space required for an English\nupper/lowercase keyboard. An example of such an interface can be seen in Figure\n1.12.1, taken from Microsoft’s Japanese Xbox user interface. However, it is of course\nnecessary to weigh the benefits of such a solution with the impact of such a feature\non testing and development.\n\nSY IOS\n\nFIGURE 1.12.1 On-screen keyboard for input of (A) Japanese hiragana characters, (B) Japanese\nkatakana characters, and (C) English characters, from Microsoft Xbox. Screen shots reprinted by\npermission from Microsoft Corporation.\n\nCharacter Sets\n\nSection 1 General Programming\n\nUnits and Display Formatting\n\nWhen developing a game, it is important that the interface not interfere with immer-\nsion into the game itself. One way in which you can provide the user with a familiar\ninterface is to default to the date, time, and number formats that the user is likely to\nprefer. It can be disorienting to go through savegame files as DD/MM/YY when you\nexpect dates to be displayed in YY/MM/DD format. Similar problems can occur\nwhen dealing with numeric and time formats (is it 1,234.56 or 1.234,562), as well as\nunits for speed, weight, or distance.\n\nWhile it might be appropriate in many cases to choose the most common default\nformat for the target market, keep in mind that some operating systems (especially\nWindows and MacOS) allow users to specify these preferences in great detail. In addi-\ntion, some console makers hard-code these formats differently, depending on the tar-\nget market for the console. If your game retrieves these settings from the system, you\ncan provide the user with their preferred display formats automatically.\n\nWhen implementing support for various languages into a game, there are several dif-\nferent character encoding schemes that can be used. While there seems to be a gradual\nmove toward Unicode on some platforms, there are advantages and disadvantages to\neach character encoding scheme. Typically, the scheme you choose will depend on\nyour platform, target languages, and any dependencies you might have on legacy or\nother code that is not world-ready.\n\nSingle-Byte Character Sets (SBCS)\n\nIn addition to character display, another issue that has to be dealt with is character\nencoding. When dealing with traditional ASCII text, one byte is required to store one\ncharacter. This is called a “single-byte character set” (SBCS) and is often used to\nencode data from English and other European languages.\n\nHowever, even within SBCS, there are multiple systems for encoding. The ASCII\nstandard uses 7 bits to store characters, with the 8th bit (originally) used for parity\nchecking. This allows 128 characters (0-127) to be stored, which is sufficient for\nEnglish text, punctuation, and a few control characters. Unfortunately, this is not suf-\nficient for many other European languages, which need to represent accented charac-\nters, additional letters, and symbols that are not typically used in the English\nlanguage.\n\nIn order to represent these additional languages, several extensions to the ASCII\nstandard were proposed. Since the parity bit is no longer needed, the full 8-bit range\nis utilized, with characters 0-127 typically kept identical to ASCII specifications and\ncharacters 128-255 used to store additional characters, punctuation, and symbols. In\nWindows, for example, these are represented by a form of the ANSI character set\n\n1.12 Developing Games for a World Market 97\n\nknown as ISO-8859. However, in order to represent various languages, multiple code\npages (or encodings of characters to numerical values) have been developed. Typically,\nSBCS code pages differ only in the definition of the upper-range characters 128-255.\nHowever, since single-byte character sets can only represent 256 symbols, it is still not\npossible to represent even the full range of European languages, much less languages\nsuch as Chinese, Japanese, or Korean (often referred to collectively as CJK).\n\nDouble and Multi-byte Character Sets (DBCS/MBCS)\n\nTo represent a wider range of characters, larger character sets were developed. As the\nname implies, a double-byte character set (DBCS) uses two bytes per character, and a\nmultibyte character set (MBCS) contains characters of varying length. One example\nof this is the Japanese Shift-JIS encoding scheme, which uses characters of one or two\nbytes.\n\nIn the Shift-JIS system, single-byte characters fall from 0x00 to 0x7F for ASCII\ncharacters and 0xA0 to OxDF for Japanese single-byte kana. Double-byte characters\nconsist of lead bytes and trail bytes, and lead bytes fall in the range excluded by the\nsingle-byte characters, namely 0x81 to 0x9F and OxEO to OxFC. Such systems can\nencode tens of thousands of characters through this extended encoding; but they are\ntrickier to develop for because character-counting, word-wrapping, and cursor-move-\nment algorithms have to compensate for varying character sizes. In addition, since the\nlead-byte ranges vary for different MBCS encodings, your code might need to provide\ndifferent cases for different Asian languages. Although the term DBCS is often used\nfor encodings such as Shift-JIS, MBCS is a more appropriate definition and is the\nnotation used in the C/C++ standards.\n\nProgramming for Various Byte-Size Character Sets\n\nWhen working with SBCS data, while code pages might be a concern, characters and\nbytes are always one-to-one, requiring few code changes. Memory allocation, cursor\nmovement, searching, editing, and word breaking remain relatively trivial. However,\nwhen coding for DBCS or MBCS data, it is necessary to take into account the fact\nthat a character does not necessarily correspond to a byte, and vice-versa.\n\nTo begin with, when allocating memory for DBCS/MBCS strings, confusing\nbytes with characters can lead to disastrous results. For example, if a player's name is\nallocated as a 16-byte string, and the input algorithm counts user input by characters\ninstead of bytes, a buffer overflow can occur, leading to instability and/or security\nproblems. In addition, the interface needs to handle cursor movement, editing, and\nsearches in terms of characters, rather than bytes.\n\nIn particular, searches are another area that can be problematic. For example,\nwhen parsing a file path, it is essential to distinguish between a forward or backslash\nand the same character code used as a nonlead byte of a double- or multibyte charac-\nter. Failure to do so can lead to file-loading problems, savegame corruption, and other\n\n98\n\nInterface and Design Considerations\n\nSection 1 General Programming\n\nserious bugs that are only reproducible when specific characters in certain languages\nare used.\n\nSince such problems are so difficult to identify (and often discovered by isolated\ncustomers after release), it is necessary that your test team understands and tests for\nthese types of issues in order to prevent them from reaching the finished product.\nFirst of all, care must be taken in development to ensure that all string search and\nparsing algorithms are DBCS/MBCS-aware. In addition, identifying a core set of\nsuch ‘danger characters’ and including them in all string-algorithm testing can be\neffective in detecting problems before the production stage.\n\nMBCS-Specific Problems\n\nIn MBCS systems, editing can be even more complicated. For example, merely hit-\nting the backspace key while editing can trigger a full string parse, required to deter-\nmine the number of bytes to delete. First of all, we don’t immediately know if the byte\nimmediately before the cursor represents a single byte or part of a multibyte character.\nWe can determine that by stepping backward one character at a time until we reach\neither the beginning of the string or a character sequence that is definitively a single-\nor multibyte character. From that point, we can determine the number of bytes in the\ncharacter to be deleted.\n\nIn the worst case, it might require parsing back to the beginning of the string. As\nsuch, it might actually be more efficient to parse the string from the beginning, espe-\ncially when dealing with short strings. However, there is an alternative. Many systems\ncontain MBCS-aware APIs for solving such problems. In Windows, for instance, the\nCharPrev, CharNext, and IsDBCSLeadByte APIs make this process easier by encap-\nsulating this functionality into a simple system call.\n\nUnicode\n\nFortunately, there is a way to support a variety of languages with a single codebase and\nwithout having to deal with code pages and characters of varying lengths. The Uni-\ncode standard defines approximately 40,000 characters in a constant two-byte format,\nsupporting characters, symbols, and codes necessary to display the majority of major\nlanguages in a single code page. Although the standard also specifies extensions for\nsupporting millions of characters and a plethora of languages (even Klingon!), the\ndouble-byte Unicode standard is typically sufficient for most games, and its flexibility\nand universal nature has made it the encoding system of choice for many serious,\nworld-ready games. For more information on Unicode, please see [Unicode02] or the\nlatest published version of the standard. At the time of this writing, the latest version\nis Unicode Standard 3.0.\n\nDENRA AAANSDAE RASTER DPMS EWE HERE H EES NEGA s Oe goer AN RR RRNA sae\n\nIn addition to the character input, encoding, and display issues that were described\nabove, there are several other areas of the game interface and design that must be",
      "page_number": 93,
      "chapter_number": 9,
      "summary": "This chapter covers segment 9 (pages 93-101). Key topics include characters, game, and input. Using Lex and Yacc To Parse Custom Data Files 91\n\n}\n\nListing 1.11.4 shows the general shell of a main() function from a tool that would\nuse the lexer and parser generated by Lex and Yacc.",
      "keywords": [
        "characters",
        "Game",
        "Japanese",
        "Developing Games",
        "input",
        "languages",
        "Free Software Foundation",
        "World Market",
        "English",
        "Character Sets",
        "Market",
        "Fonts",
        "European languages",
        "game characters",
        "Unicode character display"
      ],
      "concepts": [
        "characters",
        "game",
        "input",
        "byte",
        "code",
        "coding",
        "languages",
        "market",
        "japanese",
        "developing"
      ],
      "similar_chapters": [
        {
          "book": "Fluent Python 2nd",
          "chapter": 8,
          "title": "Segment 8 (pages 147-169)",
          "relevance_score": 0.62,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 2",
          "chapter": 12,
          "title": "Segment 12 (pages 101-108)",
          "relevance_score": 0.62,
          "method": "api"
        },
        {
          "book": "Designing Machine Learning Systems An Iterative Process for Production-Ready Applications",
          "chapter": 10,
          "title": "Segment 10 (pages 80-87)",
          "relevance_score": 0.61,
          "method": "api"
        },
        {
          "book": "Effective-Python",
          "chapter": 4,
          "title": "Segment 4 (pages 27-34)",
          "relevance_score": 0.61,
          "method": "api"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 40,
          "title": "Segment 40 (pages 809-829)",
          "relevance_score": 0.61,
          "method": "api"
        }
      ]
    },
    {
      "number": 10,
      "title": "Segment 10 (pages 102-110)",
      "start_page": 102,
      "end_page": 110,
      "detection_method": "topic_boundary",
      "content": "1.1 2 Developing Games for a World Market 99\n\ntaken into account when developing a game for multiple markets. These include\ndevice input and video output, as well as UI design and game content.\n\nVideo Output\n\nWhen developing for game consoles, it is important to keep video standards in mind.\nWhile televisions in the United States, Canada, Mexico, and Japan use the NTSC\nstandard at 30 (60 interlaced) frames per second, most other countries use PAL/\nSECAM, which runs at 25 (50 interlaced) frames per second. As such, be aware that\npre-rendered video for your game might need to be provided in both formats. In addi-\ntion, it is a good idea to ensure that your game does not synchronize rendering or ani-\nmation to a particular standard.\n\nKeyboard Input\n\nA common problem encountered when producing a PC game for a world market is\nthat of keyboard input. While joysticks and gamepads are for the most part standard-\nized, keyboards can vary from region to region. Some games anticipate a predefined\nset of expected scan codes (representing the physical position of a key on the key-\nboard) or virtual key codes or vkeys (typically representing the actual character on the\nkey). If your game is to have appeal in multiple language markets, it is important to\nensure that it works equally well with various keyboard layouts.\n\nThe problem arises when gamers use different keyboard layouts to play the game.\nIn the best case, they find that certain keys just aren't available for mapping. In the\nworst case, keys are misnamed or don't work in the game, a very frustrating experi-\nence. For example, the scan code for the right square bracket “]” on a U.S. English\nkeyboard maps to “+” on the German keyboard and “$” on the French. In addition,\nthe upper range of vkeys contains several values that vary from language to language,\nspecifically Oxba-Oxbf, Oxc0, Oxdb-Oxde, and Oxe2. For more details on scan codes,\nvirtual keys, and ASCII character codes, please refer to Table 1.12.1. Fortunately,\nusing a more-advanced input API, such as Windows DirectInput, can insulate your\ngame from some of these implementation details; it provides a layer of abstraction and\nincludes APIs for mapping codes to keys.\n\nTable 1.12.1 Virtual Keys, Glyphs, and ASCII Codes for Scan Codes\n\nEnglish © ; ; German — French a\nVkey Glyph ASCII\n\n0x29\n0x3d\n\nScancode _Vkey Glyph ASCII\n0x0c Oxbd Ox2d\n\nOxdf\nOxb4\n\n(Continues)\n\n100\n\nSection 1 General Programming\n\nTable 1.12.1 Virtual Keys, Glyphs, and ASCII Codes for Scan Codes (Continued)\n\n0x27\n\n0x28\n0x29!\n0x2b\n0x32\n0x33\n0x34\n0x35\n0x56?\n\nEnglish German French\nOxba ; 0x3b OxcO 6 Oxf6 Ox4d m Ox6d\nOxde ‘ 0x27 Oxde 4 Oxe4 Oxc0 u Oxf9\nOxc0 . 0x60 Oxdc A OxSe Oxde ? Oxb2\nOxdc \\ Ox5c Oxbf # 0x23 Oxdc * Ox2a\n\n0x4d m Ox6d Ox4d mm Ox6d Oxbc ; Ox2c\n\nOxbc , Ox2c Oxbe Ox2c Oxbe ; 0x3b\nOxbe . Ox2e Oxbf : 0x3a\nOxbf / Ox2f Oxbd - 0x2d Oxdf ! 0x21\nOxe2 \\ Ox5c Oxe2 < 0x3c Oxe2 < Ox3c\n\n1 Not available on German keyboard\n2 Not available on French keyboard\n3 Not available on U.S. keyboard\n\nLanguage-Neutral UI Design\n\nRegardless of the character encoding and input method systems used in a game, one\nof the universal problems encountered is with UI design and text layout. This is par-\nticularly problematic in the localization process, when resources from various lan-\nguages are brought into the game. Even if your game’s engine and UI is designed to\nhandle a wide range of character types, it is practically guaranteed that you will\nencounter resizing and/or overlapping issues when you first localize your game.\n\nWhen developing a user interface, it is good practice to leave additional space in\nboth the UI and the necessary data storage to take into account languages that might\nuse longer strings or different fonts. For example, strings translated from English to\nGerman can grow considerably in size. If a UI is built with the English product in\nmind, with graphical buttons or UI components just large enough for the English\nstrings, it might be impossible to produce the same interface for German without\neither modification or excessive abbreviation.\n\nOne often-quoted guideline is that when using English as your source language,\nyou should leave enough room in the UI for strings to grow 30% to 50%. In addi-\ntion, shorter strings might require even more room for growth, especially when a Ger-\nman product is to be produced from an English product. This way, your UI will be\nless likely to require changes when you begin localizing to languages that might\nrequire longer strings.\n\nIn addition, it might be necessary to accommodate a taller font in order for\ndetailed Chinese or Japanese characters to be legible, especially on a console where the\ntarget display device is typically a low-resolution television without sharp pixel render-\ning. If the UI does not provide sufficient leeway for such a change, users might be faced\nwith an interface that is unfriendly or difficult to read. Another problem that can occur\n\n1.12 Developing Games for a World Market\n\n101\n\nis overlapping; strings of text overlap improperly due to size and formatting differences\nbetween languages. Although overlapping and truncated strings might be found\nthrough manual testing of the in-game UI, it is also possible to automate this process\nand programmatically detect potential string problems before they reach the product.\n\nCulture-Neutral Game Design\n\nIn addition to making sure that the interface is designed for its target language, it is\nimportant to ensure that your game does not make any invalid assumptions regarding\ncultural associations or expectations. For example, if your game expects the character\nto drive on the left-hand side of the road, American gamers might be surprised to see\ntraffic coming at them in the right-hand lane unless you make a point of telling them\notherwise. In addition, if you have a ‘call’ button in the UI with an image represent-\ning its function, it might be best to use an icon that is relatively universal, rather than\na picture of an old-fashioned rotary dial or a traditional British phone booth.\n\nCultural and Political Sensitivity Issues\n\nOne final issue is that of cultural and political sensitivity. While many games might be\nset in a fantasy or science-fiction setting, your game will need to sell in the real world,\nand it probably won't do that by violating cultural norms or governmental standards.\nFor example, if you choose to develop a game that has strong adult themes, Nazism,\nor violent material, you might need to consider toning it down or providing a filter\nfor potentially offensive content, depending on your target market.\n\nIn addition, keep in mind the political environments of the markets where you\nanticipate selling your game. For example, if your game shows a map that contains\ndisputed regions (such as Kashmir, the western Sahara, or the Falkland Islands), take\ncare not to offend gamers or officials in your target market. This might mean modify-\ning the detail of the map or shipping different maps for different markets. In addition,\nwhen dealing with disputed territories, such as Taiwan, it might be best to avoid refer-\nring to them with the term “country.” Flags are another touchy issue, as they might\nchange frequently and exist for regions that are not recognized countries. Lastly, you\nshould take care not to offend if your game refers to existing governments, places, or\npeople. When making a game for a world market, it is important to consider the\npolitical ramifications of your content. Otherwise, you might risk alienating gamers\nin your target market or even having your game banned.\n\ntion\n\nRNSIRRR SBS BR MERUNNRT SL HEBBEN RENO EINE IR ORE NNT MOSES ESE SN RANT OIA RRR I\n\nOnce you've developed your game to display, input, and handle data in your target\nlanguage, you still have a problem—your game isn’t actually in the target language\nyet. Localization is the process of translating content and adapting interface/internal\nconfigurations to prepare a software product for another language market. Ideally, it\nshould not involve any changes to the code. Proper care should be taken during the\n\nare\n\nLocali\n\n102\n\ndesign and development process in order to ensure that the localization process goes\nsmoothly.\n\nHard-Coded Strings\n\nQuite possibly, the biggest impediment to the localization process is that of hard-coded\nstrings and resources. When developing software, it is standard practice to store all\nstrings in a resource file outside of the source code. This allows for easy access to and\nmodification of in-game text. If such strings are actually embedded in the code rather\nthan the resources, it can be difficult to find or modify them, although this might not\nbe a problem if the strings don’t need to be changed during the life of the product.\n\nThis problem escalates when localizing a product, as having text in the wrong lan-\nguage is unacceptable. In Windows, for example, many system paths are localized in\nmany of the products, but not all. As such, any reference to system paths (and mem-\nory allocation for such strings) should query the system rather than hard-coding\nthem. In order to prevent localization problems due to hard-coded strings, it is impor-\ntant to establish and follow proper coding standards.\n\nOver-Localization\n\nAs important as localization is for a successful product, it is important to prevent what\nis called “over-localization.” This is where the localization process goes to far, localiz-\ning resources that should not be modified. For example, names of in-game objects\nshould not be localized because they are not exposed to the user, and changing their\nnames might break code that depends upon them. In order to prevent over-localization,\nall resources and strings should be marked with flags that indicate whether or not they\nshould be localized. In addition, when localizing dialogue and media, you might wish\nto document your content before it is sent to localization to ensure that the gamer\nreceives the same experience regardless of the language. For example, if a character\nspeaks broken English in the U.S. version, then the script and voice for that character\nin the localized French version should similarly portray the character as less than flu-\nent in French.\n\nLocalizing Media\n\nLocalization becomes more complicated when applied to nontextual resources. For\nexample, if your game contains graphical resources with embedded text, it is unrea-\nsonable to expect localizers to possess the proper software and skills to edit the image\nand localize it. Instead, all text embedded in graphics should be stored in a separate\nlayer and coordinated with external string tables for ease of localization. This also\nmakes it easier to modify the text in the core language product. In addition, the\ngraphic should be large enough to allow string wrapping or font changes necessary in\nthe localization process.\n\nIn addition, when producing audio or video, remember that the localized version\n\n1.12 Developing Games for a Worid Market 103\n\nmay run longer, especially if the original version contains quickly spoken text. As\nsuch, it is best to ensure that in-game audio/video clips are long enough to accommo-\ndate various-length localized versions, and that gameplay is not affected by these dif-\nferences. In addition, if you are targeting multiple language markets, please keep in\nmind that it can be much more expensive to localize full-motion video (FMV) than\nvideo sequences using the game’s engine. The balance of FMV versus in-game\nsequences is something that must be determined early on in the project. One alterna-\ntive that may help you avoid some of these problems is to localize only subtitles for\nvideo sequences. This significantly reduces problems with media synchronization; but\nyou need to balance those advantages with the potential impact on the user experi-\nence and immersion that it might have on your game.\n\nAnother concern in localization is ensuring that the game has the same feel in\nmultiple target languages. For example, if you choose to localize audio or video in\nyour game, it is a good idea to ensure that the character and tone of the original is\ntaken into account. If a character is to sound paranoid and edgy, it is important that\nthe message gets across in all languages. In addition, if your game has a character that\nis a New York mobster, for a Japanese version, you might choose a voice actor that can\nspeak with a stereotypical, modern Osaka Yakuza accent if that is appropriate to your\ngenre. Lastly, keep in mind that if you use a celebrity in your game, he or she might\nnot be as well recognized in much of your international market.\n\nString and Audio/Video Concatenation\n\nOne final concern is that of concatenation of strings and media. Due to variations in\ngrammar and overall sentence structure, concatenating multiple strings to make a sin-\ngle sentence can be very problematic. As such, if your game must use string concate-\nnation, it is important to involve localization at an early stage to ensure later\nlocalizability. Concatenation is an even greater problem when dealing with audio and\nvideo, and extra care should be taken with a product that will be localized.\n\nDesign and Planning Considerations\n\nOnce you understand the core issues involved in developing games for a world mar-\nket, it is important to integrate this knowledge into the design and development\nprocess. There are several ways to plan multiple language releases of the same game.\nTo begin with, some teams choose to focus on the core language product initially,\nwith consideration for localized versions later in the project. This method has several\nproblems.\n\nTo begin with, the localized versions might be considerably delayed, missing the\nhalo of excitement that can follow a successful release. In addition, this approach\ntends to increase the work for localization and testing, and might significantly hamper\nfunctionality in other languages. However, this could be the only choice if a game is\nreleased for a certain market, but strong interest is shown in other language markets.\n\n104\n\nTesting\n\nSection ai _General Programming\n\nModifying a Game After the Fact\n\nIf you are trying to add multiple language support for a game that is already shipped or\nthat is late in the development process, your choices are limited. First of all, trying to\nconvert the entire game to Unicode late in the project is expensive, time-consuming,\nand error prone. As such, it is usually not even an option. However, it is possible to\nprovide a moderate level of support for various languages at a reasonable development\nand test cost.\n\nTo begin with, it is possible to reduce support for various languages while still\nproviding desired functionality. For example, you might choose to support only Euro-\npean languages in the game UI itself, but implement wider support in the install\nengine and file system. As an alternative, it might be acceptable to allow input only in\nEnglish, but modify the game engine to support storage and display of a wider range\nof languages. Finally, you can modify the game to support MBCS (such as Shift-JIS),\nbut this can incur a large development hit and bug risk. In addition, cross-language\nfunctionality might be limited, such as chat. The determining factors should be a bal-\nance of the cost/time involved and the user experience you wish to provide.\n\nDoing it Right the First Time\n\nAlthough the above options are valid and have been used many times, successful glob-\nalization should be designed from scratch. To begin with, it is much cheaper to\ndevelop a product the right way from the onset, as opposed to tacking on desired fea-\ntures after the fact. In addition, if all versions of the game run off the same code base,\ndevelopment is less complicated and support issues are reduced because only a single\nplatform must be supported and maintained.\n\nIn the long run, it is also cheaper and faster to incorporate globalization and\nlocalization into the core design process. While this integration may incur a small\ndelay the first time around, it can greatly improve the speed with which multiple lan-\nguage versions of your game can ship. In addition, you'll be able to ship these versions\nsimultaneously, and if you choose to release multiple languages in a single media, you\ncan reduce manufacturing and support costs further.\n\nEE BRG EUSA NPAT RR NEE RI INR RAN IR ASO eS RR NNT\n\nSo far, the focus of this gem has been primarily on design and implementation. How-\never, it is important that the same standards of internationalization be applied to testing\nas to development. Testing of different localized versions of a product need not be\nredundant. If your game is single-code base and world-ready, a full test pass needs be\nperformed on only one language version. Testing on other language versions of the\ngame can focus on localization and functionality specific to those versions, although\nsanity testing should be performed across the product. The following are several areas of\ntesting that might require specific attention when dealing with an international game.\n\n1.12 Developing Games fora World Market 105\n\nI Can’t Read It—How Do | Test It?\n\nOne of the first obstacles to testing a localized game is the language barrier. If you're\nlike most companies, you picked your test team because of their technical skills and\ntesting ability in a number of languages seemed a low priority. However, a good test\nteam can test for the majority of functionality bugs without having to learn another\nlanguage.\n\nTo begin with, your testers should know your game inside and out. If they have\nbeen testing the original-language version long enough, they should be able to walk\nthrough the UI with their eyes shut. As long as everything functions as planned,\ntesters should be in familiar territory. One exception might be warning and error mes-\nsages. If they are localized in the test builds, it might be necessary to provide testers\nwith a list of common error/warning messages and phrases (“not found,” “not enough\nspace available,” etc.) and their localized counterparts.\n\nIn addition, if you have someone on staff that speaks the language and can be on\ncall, they can help to quickly identify problems when they occur. With some experi-\nence, testers should become familiar with common messages and known problems in\nthe localized product, so only new or infrequent issues will require attention. How-\never, in-game verification and other testing might require someone fluent in your tar-\nget language. Many technical recruiting, staffing, and contracting companies have\nexperience finding and providing testers with native language experience. You could\nfind it worthwhile to contract one or more testers who are fluent in your target lan-\nguage once localized builds are available. In addition, there are several international\ncompanies to which you can outsource localized testing.\n\nDanger Characters\n\nOnce your team is ready to tackle the testing of a world-ready product, you need to\nidentify your highest-risk areas and integrate this knowledge into your test process.\nOne place to start is with so-called “danger characters.” These are characters that, due\nto their usage or their position in a codepage, tend to cause a disproportionate num-\nber of problems in applications. In particular, danger-character testing is important\nwhen dealing with originally SBCS code that has been modified to be MBCS/DBCS\ncompliant. When dealing with such code, it is not unusual to find search or parsing\nalgorithms that treat strings as being strictly single-byte.\n\nMost operating systems reserve certain characters in their file paths, such as the\nforward/back slashes and the pipe character. A common problem occurs when the\nfilename/path-parsing algorithm is single-byte, generating errors for filenames that\nare perfectly valid. For example, if a user enters a Chinese filename with a double-byte\ncharacter whose code happens to be 0x5C (the ASCII code for the backspace charac-\nter) in the second byte, a single-byte algorithm will likely detect this as a backslash\nand improperly parse the file path.\n\n106\n\nSection 1 General Programming\n\nIn addition, off-by-one errors are not uncommon when dealing with MBCS\ncodepages. These occur when comparisons leave out or include one too many charac-\nters, such as a greater-than instead of a greater-than-or-equals. For example, in Shift-\nJIS, the character value 0xDF represents the highest of the single-byte kana codes,\nwhile 0xE0O marks the beginning of the second DBCS range for leading bytes. In such\na case, it may be useful to test your boundary values (0xDF and 0xE0 in this case) to\nensure that your code does not contain off-by-one bugs.\n\nIn order to produce a list of danger characters, you should evaluate your target\nlanguage/codepage and identify the following characters:\n\n* Any values that the filename/path parser might search for or consider invalid,\nsuch as the pipe, backslash, brackets, file delete marker, and so forth.\n\n* The beginning and ending values for each character range if you are using an\nMBCS character set.\n\n* The lowest and highest possible character values, and also one character beyond\nthose in each direction (these should be noted as invalid characters).\n\nYou should first test these values to ensure that valid and invalid values are treated\nproperly. In addition, for any SBCS values, you should find an MBCS character that\nincludes those values as trailing bytes to ensure that your filename/path parsing will\nnot fail on these values. To be most effective, you should create a universal test string\nthat includes one each of the invalid characters and enter it everywhere possible. If\nyou cannot read the target language, you can have a native speaker write down what\nthe string looks like and how to enter it. In addition, if your game is Unicode and\nallows multiple-language input, a good test string should include text (preferably dan-\nger characters) from multiple languages as well.\n\nBuffer Allocation\n\nAnother common programming bug that can occur when developing world-ready\ngames is in buffer allocation. This type of error is common when a distinction is not\nmade between characters and bytes. For example, if a string is allocated to be 16 bytes,\nit will only hold eight characters if they are double-byte. Testers should know the\nbuffer limits for different strings (they should be detailed in the game specification,\nincluding whether the limits are in characters or in bytes), and perform boundary\ntesting on them with both single- and double-, or multibyte characters if possible.\n\nHardware Configuration\n\nAnother issue that can arise in testing localized games is that of hardware configura-\ntion and input. To begin with, internationally, a wide variety of keyboards are used,\nand certain market areas (such as Korea and Japan) might have their own, language-\nspecific keys on their keyboards. In addition, there can be other variations in hard-\nware worldwide, such as localized drivers on the PC and different default hardware\nconfiguration/controllers on consoles. When testing for these markets, it is important\n\n1.12 Developing Games for a World Market 107\n\nto consider the most-popular configurations (which may affect your supported hard-\nware configurations) and test with these devices to ensure compatibility with your\ntarget market.\n\nSystem Configuration\n\nWorld-ready system configurations comprise their own kettle of fish. With regards to\ntesting, the two things you should look out for are system incompatibilities and user\nsettings. While system incompatibilities are typically spotted early in the development\ncycle due to their severity, user settings are often overlooked. These include, but are\nnot limited to, time, date, and unit formats. PCs and some consoles allow a certain\ndegree of customization in this area, and you should test to ensure that your game\nrespects the users’ preferences.\n\nInput Testing\n\nOne more area that should be given special testing in a world-ready product is that of\nediting and input. Two functions in particular that should be tested (if available in\nyour game) are cursor movement and text editing. Cursor-movement testing typically\ncovers selection and movement of the cursor through text, while editing includes such\nfunctionality as delete, backspace, copy, cut, and paste. To test for problems in these\nareas, you can create a string composed of a mixture of different double-byte (and sin-\ngle-byte if available) characters, and make sure that cursor movement, selection, and\nediting are character-based. In no case should you ever be able to move the cursor to\nthe middle of a character or cut off the leading or trailing byte of a multibyte character.\n\nUl and Localization Testing\n\nWhen performing localization and UJ testing, a sanity check can be performed by a\nnon-native speaker who will look for truncation, resizing, and other obvious visual\nproblems. However, many other problems require the eye of a native speaker, notably\ncontext, string order, and translation testing. Context and string order testing refers to\nverifying the UI content (mostly text) and ensuring that strings are in the right places,\nand that all text is comprehensible and translated properly for the appropriate con-\ntext. String order problems can occur when a string has to be broken into two or more\nparts to accommodate a variable component. Since sentence structures and order are\ndifferent in various languages, care must be taken in both localization and testing to\nverify that all resources are properly presented and in context.\n\nTranslation testing focuses on the validity of the translation itself and can be\nsomewhat vague due to the difficulties of communicating the same message in multi-\nple languages. If your company performs in- house localization, you might be able to\ninvolve the localization team in the testing process, since they are familiar with both\nthe content and the target language. In addition, proper checks in the localization\nprocess can identify mistakes in the original text prior to translation, thus correcting\nproblems before they reach the test team.",
      "page_number": 102,
      "chapter_number": 10,
      "summary": "Fortunately,\nusing a more-advanced input API, such as Windows DirectInput, can insulate your\ngame from some of these implementation details; it provides a layer of abstraction and\nincludes APIs for mapping codes to keys Key topics include games, tested, and strings.",
      "keywords": [
        "game",
        "Developing Games",
        "language",
        "strings",
        "character",
        "localization",
        "addition",
        "World Market",
        "Market",
        "string",
        "target language",
        "localized",
        "product",
        "English",
        "problems"
      ],
      "concepts": [
        "games",
        "tested",
        "strings",
        "string",
        "character",
        "localization",
        "localize",
        "localized",
        "language",
        "codes"
      ],
      "similar_chapters": [
        {
          "book": "Game_Engine_Architecture",
          "chapter": 36,
          "title": "Segment 36 (pages 719-740)",
          "relevance_score": 0.58,
          "method": "api"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 40,
          "title": "Segment 40 (pages 809-829)",
          "relevance_score": 0.54,
          "method": "api"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 14,
          "title": "Segment 14 (pages 269-288)",
          "relevance_score": 0.53,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 2",
          "chapter": 12,
          "title": "Segment 12 (pages 101-108)",
          "relevance_score": 0.51,
          "method": "api"
        },
        {
          "book": "makinggames",
          "chapter": 32,
          "title": "Segment 32 (pages 282-290)",
          "relevance_score": 0.51,
          "method": "api"
        }
      ]
    },
    {
      "number": 11,
      "title": "Segment 11 (pages 111-118)",
      "start_page": 111,
      "end_page": 118,
      "detection_method": "topic_boundary",
      "content": "108 Section 1 General Programmin\n\na world-ready game. In this gem, we have tried to list the major issues that concern\nthis process, along with ways of anticipating and resolving them as they relate to game\ndevelopment. Although it can be a complex process, integrating globalization and\nlocalization into your design process allows you to capitalize on a larger market and\nproduce a better design as well as a better gaming experience.\n\nndard, Version 3. 0, Addison Wesley\n\nPp iprand, Joan, The\nPublishing Co., 2000.\n\n{[Dmoz02] Open Directory Project, “Open Directory - Help Central,” available\nonline at http://www.dmoz.org/Computers/Software/Globalization/. The Open\nDirectory Project’s software alobalization page has links to almost any related\ntopic. March 2002.\n\n{DrIntl02] Dr. International, Developing International Software, Microsoft Press,\n2002.\n\n[Kano95] Kano, Nadine, Developing International Software, Microsoft Press, 1995.\nThe entire book is accessible online at http://www.microsoft.com/globaldev/\ndis_v1/disv1.asp.\n\n[Lunde98] Lunde, Ken, and Gigi Estabrook, C/KV Information Processing, OReilly,\n1998.\n\n[MicrosoftGlobalDev02] Microsoft Corporation, “Microsoft: Global Software Devel-\nopment!,” available online at http://www.microsoft.com/globaldev. Microsoft's\nglobal software development page includes step-by-step globalization guidelines,\nsolutions to common problems, and links to other resources. March 2002.\n\n[MicrosoftIME02] Microsoft Corporation, “Microsoft Global Input Method Editors\n(IMEs) Further Enhance East Asian Text Input,” available online at http://www.\nmicrosoft.com/Windows/ie/downloads/recommended/ime/, Microsoft IME\ndownload page for pre- Windows 2000 systems, March 2002.\n\n[Shmitt00] Shmitt, David, Jnternational Programming for Microsoft Windows,\nMicrosoft Press, 2000.\n\n[Unicode02] Unicode Consortium. The Unicode home page, available online at\nhttp://www.unicode.org, contains general information, standards documenta-\ntion, code charts, and conference proceedings. March 2002.\n\n1.13\n\nReal-Time Input and Ul\nin 3D Games\n\nGreg Seegert, Stainless Steel Studios\ngseegert@alum.wpi.edu\n\neveloping a safe, fast, and responsive user interface and input system for your\n\ngame remains an often-overlooked programming task, but it is one of the most\nvital components in a successful title. In this gem, we will explore various implemen-\ntation details, tricks, and optimizations that will assist you in creating the best UI and\ninput system possible. We will also examine the important role that a user interface\nand input system fulfill in eliminating perceived network latency. This gem assumes a\nbasic familiarity with DirectX, and the code samples and accompanying code are\nimplemented with DirectX8, although the concepts could be applied to any 3D API.\n\nimplementing the User interfac\n\nWhen creating a 3D game, it is helpful to utilize the power of the available 3D hard-\nware to render 2D elements as well. To draw our UI elements, we will simply render\nflat polygons to the screen after setting up our world, view, and projection matrices.\nThe following code sample illustrates setting up Direct3D to render polygons two-\ndimensionally:\n\n// an LPDIRECT3DDEVICE8 variable named “d3dDevice\"\n// has been previously instantiated.\n\nD3DXMATAIX tempMatrix;\n\n// make an identity matrix\nD3DXMatrixIdentity (&tempMatrix) ;\n\n// set dx8's world and view matrices\nd3dDevice->SetTransform(D3DTS_WORLD, &tempMatrix) ;\nd3dDevice->SetTransform(D3DTS_VIEW, &tempMatrix) ;\n\n// set the projection matrix using\n\n// the width and height of the viewport\ntempMatrix. 11 2.0f / width;\ntempMatrix. 41 -1.0f;\n\ntempMatrix. 22 -2.0f / height;\n\n109\n\nion 1 General Programming\n\n110\n\ntempMatrix._42 = 1.0f;\n\nd3dDevice->SetTransform(D3DTS_ PROJECTION, &tempMatrix) ;\n\nAfter we have set up our world, view, and projection matrices, we must simply\nrender two triangles to the screen. The two triangles will form our polygon, which we\ncan color or texture to use as a background, button, or any other 2D component of a\nuser interface. First, after the corresponding UI object is instantiated, create a vertex\nbuffer consisting of the vertices used to specify the two triangles. Set the position of\neach vertex to be the location you want in screen pixel coordinates. Then, for each\nframe call, DrawPrimitive() to render the vertex buffer as a triangle list [(MSDN101].\nThe method of using screen coordinates simplifies the encapsulation of any 2D user\ninterface elements you choose to develop. It is also important to point out that\nDirectX8 offers a method for rendering a sprite in screen coordinates that may be use-\nful [MSDN201]}. An excellent resource to accomplish this goal using OpenGL is the\ngem “Using 3D Hardware for 2D Sprite Effects” [McCuskey00].\n\nUser interfaces have grown increasingly complex over the years. The end user\nexpects a high level of functionality, and it is the programmer’s job to supply these\nfeatures. Table 1.13.1 lists common controls that should be implemented in any\nrobust UI.\n\nTable 1.13.1 Suggested Ul Elements For Implementation\n\n¢ Backgrounds ¢ Edit Box * Sliders\n\n¢ Button ¢ List Box ¢ Static Text\n\n¢ Check Box ¢ Radio Button * Tool Tips\n\n* Combo Box ¢ Scroll Bar * Pages or Forms\n\nSpecifying User Interface Elements\n\nBROCE AEN 8 SEH Be BOR HE EBLE RRS ESE LIES ELISE ES se\n\nTe SOC DALI Sis OR ILE,\n\nOnce the code is written and the various UI elements are tested, it is time to put them\ninto the game. There are many ways to accomplish this goal. Each and every screen\nand element could be hard-coded into the game. However, this method requires pro-\ngrammer intervention to change even the simplest aspect of how the UI is displayed.\nIdeally, we would like to be able to specify the UI in an external file, allowing design-\ners to create and modify the interface as they see fit with virtually no programmer\nintervention.\n\nXML: It’s Not Just for Microsoft Anymore\n\nXML is an acronym for eXtensible Markup Language. Anyone vaguely familiar with\nthe syntax of HTML will most likely be comfortable with XML. In fact, HTML is\n\n1.13 Real-Time Input and Ul in 3D Games\n\nea\n\nON THE CD\n\nexe\n\n111\n\nbeen asec eR err eet ACEP Sh NE ED SST CRA\n\nitself an ‘older cousin’ of XML. XML’ true power is its extensibility—it essentially\nallows the creation of a unique markup language. The backbone of XML is the DTD\n(Document Type Definition). The DTD specifies the constructs and syntax used in\nthe particular instance of XML. The DTD can then be used to ensure that a corre-\nsponding XML file adheres to the correct syntax. The XML standard is well defined,\nand there are numerous resources available to assist in writing and parsing XML\n[W3C102]. Because of the object-oriented and data-driven nature of XML, it is an\nideal candidate for specifying not only a user interface but also virtually all data-dri-\nven elements of the game engine.\n\nThe following code segment is a sample taken from an imaginary XML file used\nto specify a user interface screen. As you can see, the XML file logically outlines the\nuser interface elements in a manner that is easy to parse as well as to read and edit.\n\n<!-- This will create a UI screen with a background,\na title, list box, and an ok button. These are\nall user-defined tags -->\n<UISCREEN NAME=\"screen0\" BACKGROUND=\"screen0_bg.tga\">\n<UITEXT NAME=\"textO\" LEFT=\"10%\" RIGHT=\"90%\"\nTOP=\"10%\" BOTTOM=\"25%\">\n<UITEXTITEM>This is the title.</UITEXTITEM>\n</UITEXT>\n<UILISTBOX NAME=\"listO\" LEFT=\"30%\" RIGHT=\"70%\"\nTOP=\"40%\" BOTTOM=\"70%\">\n<UITEXTITEM>This is item 1.</UITEXTITEM>\n<UITEXTITEM>This is item 2.</UITEXTITEM>\n<UITEXTITEM>%1001%</UITEXTITEM>\n</UILISTBOX>\n<UIBUTTON NAME=\"button0O\" LEFT=\"40%\" RIGHT=\"60%\"\nTOP=\"80%\" BOTTOM=\"90%\">\n<UITEXTITEM>OK</UITEXTITEM>\n<UIEVENT ONCLICK=\"PushScreen\"\nPARAMETER1=\"screen1\"/>\n</UIBUTTON>\n</UISCREEN>\n\nThe DTD for the above segment contains the allowable tags, their parameters,\nand the tags that can be nested under them. One DTD can be used to verify any\nnumber of XML data files. The sample shown here and corresponding DTD can be\nfound on the CD-ROM.\n\nIn this example, the occurrences of <UITEXTITEM> specify text, with %value% indi-\ncating a string table entry. Positions for each UI entity are specified in percentages.\nUsing percentages helps to ensure the UI is displayed as expected in a variety of screen\nresolutions. The <UIEVENT> tags specify what events are valid for a specific UI entity\nand what actions to take when those events are fired. For example, when button “but-\nton0” is clicked, the UI code will execute the PushScreen action with screeni as a\nparameter. Implementing the actions to fire could be accomplished through the use of\nfunction pointers or through a C++ class that is derived from an abstract base class\n\nSection 1 General Programming\n\nrequiring a string name. The action could then be mapped to the appropriately\nnamed object, and code would be executed with the specified parameters.\n\nTo parse an XML file, you can write or reuse a custom parsing routine. Alterna-\ntively, there are a number of free SDKs available that support XML parsing on a vari-\nety of platforms [W3C202]. For Windows developers, Microsoft offers the Microsoft\nXML Core Services (MSXML) 4.0 SDK, which includes full-featured XML parsing\naccessible through C and C++ interfaces [MSDN301].\n\nLocalization Considerations\n\nAs games continually increase in both size and scope, so do their target audiences. In\norder to maximize market penetration, it is imperative to design a game to be easily\nlocalizable to any other language. The user interface is on the forefront of this effort,\nas translated text will eventually be displayed on the screen. The following guidelines\nshould always be considered throughout the development of the user interface and\nthe game engine itself.\n\n¢ Never hard-code any text that might eventually be translated; use a string table\ninstead.\n\n* Use MBCS or Unicode strings.\n\n* Be wary of string concatenation.\n\n* Process WM_CHAR messages for all text displayed to the user.\n\n* Design UI controls to accommodate potentially large strings.\n\n* Use fonts that support multibyte languages.\n\nThe most obvious tenet is to never hard-code any text. Instead, use a string table\nfor all text (excluding debug text, of course). It is also important to use MBCS (multi-\nbyte character strings) or Unicode (wide character) strings throughout the game. If\nyou do not, certain languages will appear to have garbled text. The Standard Template\nLibrary (STL) offers a wide character version of the string class, appropriately named\nwstring. Use caution when concatenating strings. Sentences are formed differently in\nother languages, so it is important to store sentence format in the string table as well.\nAlso, never use DirectInput to process keyboard inputs that will be directly displayed\nto the user as text. Instead, use WM_CHAR messages. When processing WM_CHAR messages,\nWindows will perform the translation based on local information. An equally impor-\ntant task is to design UI controls to accommodate large strings or to expand to fit the\ndisplayed string. A short English phrase could easily become twice as long when trans-\nlated to another language. Lastly, the font used must be carefully chosen and able to\ndisplay multibyte languages. Some system fonts support multibyte languages, making\nthem good selections. If you absolutely must use a custom font, however, a clever\nsolution is to specify the font to use in the string table itself. Then, the localization\nteam could choose the appropriate font for the language they are translating to if\nnecessary.\n\n1.13 Real-Time Input and Ul in 3D Games 113\n\nThe Input System\n\nThe user’s game experience incorporates more than simply the textures used for back-\ngrounds and buttons. Your primary goals should include ensuring that all user input\nis responsive and performs as the user expects it to. We will now cxplore several useful\ntricks to achieve this for the keyboard, mouse, and joystick.\n\nThe Keyboard\n\nDirectInput allows two methods of retrieving data from various input systems:\nimmediate and buffered. Immediate data returns a snapshot of the current state of the\ndevice, while buffered data consists of a sequence of events that have occurred since\nthe last buffered data call. When used for the keyboard, immediate mode returns an\narray of 256 bytes representing the state of the keyboard keys. If the high bit is set for\na particular key index, the key is down. Immediate mode appeals to many Windows\nprogrammers due to its simplicity, its similarity to the Win32 GetKeyboardState()\ncall, and the desire to know exactly what the state of the keyboard is at any given\nmoment. Although this approach is effective, it seems to perform best when the game\nis only processing a small amount of keyboard commands, such as left, right, up,\ndown, and shoot. What about a flight simulator, RTS game, or another game with\npotentially hundreds of hotkey combinations? It could be rather inefficient to loop\nthrough every hotkey that might or might not have been pressed, checking against the\narray returned by GetDeviceState() at every update. Handling events when a key is\nreleased will also require maintaining a copy of the keyboard state as of the previous\nupdate. Additionally, this approach does not handle the case where a user manages to\npress and release one or more keys between updates to the input system.\n\nHow To Never Miss an Input\n\nFortunately, DirectInput’s buffered data mode offers a viable alternative. Rather than\ncalling GetDeviceState(), we will call GetDeviceData(). This will return a list of key-\nboard events that have occurred since the last call to GetDeviceData(). Each keyboard\nevent specifies whether the key was pressed or released, which key it was, and provides\na high-resolution time of when the event occurred. No matter how frequently or\ninfrequently the input system is refreshed, we will know exactly what events occurred\nand in what order.\n\nThe next step is to package up the input event, and put it on a queue of inputs to\nbe processed by the game engine. We will maintain three queues: “just pressed,”\n“pressed,” and “just released.” Storing our inputs in these three queues allows us to\nfire actions depending on the state of the key. For example, holding down the for-\nward-arrow key could accelerate a car in a racing game, while tapping the “A” key\ncould shift gears. The other items to consider are the ‘modifier’ keys. These keys,\nwhich include CTRL, SHIFT, and ALT, are no different than any other key as far as\n\nDirect Input is concerned. This is the desired behavior, as we might wish to fire events\n\n114\n\nON THE CD\n\nThe Mouse and Joystick\n\nSection 1 General Programming\n\nwhen those particular keys are pressed. However, we will also use these keys as modi-\nfiers. For example, CTRL-A will be considered a unique key separate from CTRL and\nA. For this reason, the input system will maintain a current modifier state consisting\nof bit flags that will be updated as the appropriate modifiers are pressed and released.\nTherefore, each packaged input event will consist of the key for that event as well as\nthe current modifier state. Packing the combination of key and modifier state into a\nsingle 16-bit value will allow us to identify a unique key combination for sorting and\ncomparison purposes.\n\nOn each occasion that the input system is refreshed, we will add any input events\nto the appropriate queue. When we are ready to process these inputs, the game engine\nwill iterate through the queues. Each hotkey that we will be checking for can be stored\nas a map of input events to hotkey pointers. This way, look-up is considerably fast for\nlocating the corresponding hotkey (if it exists) and executing the game engine code.\n\nWe now know exactly what keys the user pressed, no matter how often the input\nsystem is refreshed. Furthermore, this method for processing input can serve as an\nimportant optimization, since we are quickly processing a much smaller list of what\nthe user actually did, rather than checking against every possible key combination.\nRefer to the CD-ROM for further implementation details.\n\n=r URED SR A LEALETB LLNS ARLEN ESL P NS SEE ERIE B EEE LSAT NA SELL IM SEEPS IR NTT\n\nThe mouse and joystick can benefit from buffered input in precisely the same manner\nas the keyboard. Instead of key presses, we will package and process mouse and button\nclicks. However, buffered input should not necessarily be used to interpret the axis\nmovement of either the mouse or joystick. During pauses in the execution of the\ngame engine, the mouse cursor or joystick controls might appear to jump around the\nscreen as the buffered axis inputs are processed. The simple solution is to use buffered\nand immediate input. The buffered input is used to process buttons and clicks, while\nthe immediate data modifies the axes.\n\nA Smooth and Responsive Cursor\n\nOne fairly common implementation of the mouse in games is to run the mouse in its\nown thread. This remains a good approach, as the mouse can be updated and ren-\ndered independently of other processing being performed by the game engine. How-\never, the mouse thread might be capped to yield away time, allowing more processor\ncycles for physics, AI, and graphics. Although this makes perfect sense, capping pro-\ncessing of the mouse thread can exhibit undesirable behavior on certain machine con-\nfigurations. If the game is running at over 60 fps (frames per second), a mouse pointer\nupdating only 10 times per second will appear jerky and unresponsive. In this case,\nthe solution is to separate the updating of the mouse axes from the processing of the\nbuttons. Then, the position of the mouse can be updated and the mouse pointer ren-\ndered every single frame, achieving the smoothest possible movement.\n\n1.13 Real-Time Input and UI in 3D Games 115\n\nThe Role of the UI in the Fight Against Lag\n\n‘senoEReRRRIY\n\nSERN\n\nAs the popularity of network games increases, so does users’ expectations of as fast and\nenjoyable online experiences as possible. At times, the user’s expectations can be rather\nunrealistic. A user running a complex network game on a 28.8k-baud modem will\nexpect gameplay as smooth as those users connected directly on a LAN. There is only\na certain degree of optimization and tuning that can be applied to the network\ncode—given the unpredictability of network connections; if the user is not transmit-\nting data fast enough, there is not much more that can be done to accomplish this\nfeat.\n\nThe best way to attack this problem is to simply hide the network latency from\nthe user. Some of the most successful online games, like Quake and Half-Life, use a\nmethod known as client-side prediction. Essentially, the simulation is run on the\nclient’s machine as fast as possible, with the client predicting the position and actions\nof other entities in the game. When network updates are received from the server, the\nclient is corrected if it is not synchronized with the server.\n\nA similar methodology can be applied to all aspects of the user interface and\ninput. Any and all feedback of the game, including updating UI buttons or selecting\nunits, should be performed instantly on the client. For example, if the user presses the\ntrigger button, the gun should fire immediately as the network message is sent to the\nserver. If the user sends a chat message, it should be displayed on the screen instanta-\nneously. If the user clicks a button to build another unit, the onscreen counter should\nincrement without delay. What happens, however, if the command is not allowed,\nrejected by the server, or the network packet is lost?\n\nThere are a number of potential solutions to this problem. It is possible to occa-\nsionally compare the UI with the state of the game world, making corrections when\nnecessary. To help prevent these errors in the first place, the same server-side valida-\ntion of commands and actions can be performed on the client, although this could\nduplicate code and increase processing demands. Lastly, a method of guaranteed mes-\nsage delivery could be implemented for the game. This will allow the client to update\nthe user interface, knowing that eventually the server will receive the command.\nHowever, the drawback to this approach should be fairly obvious. In a high network\nloss situation, the client could potentially be forced to resend a message many times.\nCombined with lag, this method could aggravate, rather than relieve the problem.\n\nConclusion\n\nHopefully, you have found the ideas and tips presented in this gem useful. Though we\nhave only scratched the surface, keeping these points in mind will help you build a\nfast, safe, and robust user interface and input system for your game. The CD-ROM\ncontains a complete keyboard input system that is easily adaptable for any game. The\ninput system implements the fast, buffered-input method mentioned previously.\nAdditionally, the input system is localization friendly and can read hotkey assign-",
      "page_number": 111,
      "chapter_number": 11,
      "summary": "This chapter covers segment 11 (pages 111-118). Key topics include game, gaming, and user.",
      "keywords": [
        "input system",
        "Input",
        "user interface",
        "user",
        "game",
        "XML",
        "user interface elements",
        "Microsoft",
        "Microsoft Global Input",
        "game engine",
        "UITEXTITEM",
        "key",
        "Microsoft Anymore XML",
        "Microsoft Press",
        "interface"
      ],
      "concepts": [
        "game",
        "gaming",
        "user",
        "xml",
        "input",
        "useful",
        "process",
        "processing",
        "code",
        "data"
      ],
      "similar_chapters": [
        {
          "book": "Game_Engine_Architecture",
          "chapter": 1,
          "title": "Segment 1 (pages 1-18)",
          "relevance_score": 0.74,
          "method": "api"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 36,
          "title": "Segment 36 (pages 719-740)",
          "relevance_score": 0.72,
          "method": "api"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 2,
          "title": "Segment 2 (pages 19-41)",
          "relevance_score": 0.71,
          "method": "api"
        },
        {
          "book": "makinggames",
          "chapter": 35,
          "title": "Segment 35 (pages 308-315)",
          "relevance_score": 0.7,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 2",
          "chapter": 12,
          "title": "Segment 12 (pages 101-108)",
          "relevance_score": 0.69,
          "method": "api"
        }
      ]
    },
    {
      "number": 12,
      "title": "Segment 12 (pages 119-128)",
      "start_page": 119,
      "end_page": 128,
      "detection_method": "topic_boundary",
      "content": "116 Section 1 General Programming\n\nments from an external file, allowing completely customizable hotkeys. Also available\n\non the CD-ROM is a simple C++ XML parser, as well as the XML samples used here.\n\nReferences\n\n[McCuskey00] McCuskey, Mason, “Using 3D Hardware for 2D Sprite Effects,”\nGame Programming Gems, Charles River Media, Inc., 2000.\n\n[MSDN101] msdn.microsoft.com, “IDirect3DDevice8::DrawPrimitive,” available\nonline at hetp://www.msdn.microsoft.com/library/en-us/dx8_c/directx_cpp/\nGraphics/Reference/CPP/D3D/Interfaces/IDirect3 DDevice8/DrawPrimitive.as\n\n, 2002.\n\n[MSDN201] msdn.microsoft.com, “ID3DXSprite::Draw,” available online at http://\nwww.msdn.microsoft.com/library/en-us/dx8_c/directx_cpp/Graphics/Refer-\nence/CPP/D3DX/Interfaces/ID3DXSprite/Draw.asp, 2002.\n\n[MSDN301] msdn.microsoft.com, “MSXML 4.0 RTM,” available online at\nhttp://www.msdn.microsoft.com/downloads/sample.asp?url=/MSDN-\nFILES/027/001/766/m sdncompositedoc.xml, 2001.\n\n[W3C102] World Wide Web Consortium, “Extensible Markup Language,” available\nonline at http://www.w3c.org/XML/, 2002.\n\n[W3C202] World Wide Web Consortium, “Extensible Markup Language (Soft-\nware),” available online at http://www.w3c.org/XML, 2002.\n\n1.14\n\nNatural Selection: The\nEvolution of Pie Menus\n\nDon Hopkins\ndon@DonHopkins.com\n\nPp menus are a naturally efficient user-interface technique—directional selection\nof pie slice-shaped targets. The cursor starts out in the inactive center region of a\npie, and all target slices are large, nearby, and in different directions. Pie menus are\nquite easy for new users. You simply follow the pop-up directions to use them. They\nare also extremely efficient for experienced users. Once you know the directions, you\ncan quickly and reliably ‘mouse ahead’ without looking. Fitts’ Law [Fitts54] explains\nthe pie menu advantage—their fast selection speed and low error rate is due to their\nlarge target size and the small distance between each item.\n\nThe evolution of user interface design is driven not only by theory, but also by\npractice. We'll examine the successes and failures of a few real-world examples, not\nonly to avoid re-inventing the square wheel, but also to encourage further creativity.\nThe examples presented here are intended to inspire you to think outside the box and\ndesign new kinds of fun, efficient, and reliable user interfaces.\n\nThe Feng GUI of Pie Menus\n\nUser interface design is not just a process of raw artistic creation nor a legalistic appli-\ncation of interface guidelines and theories. It’s the exploration and discovery of natu-\nrally efficient ways of solving problems, given competing sets of constraints. The\noutcome is always different, because the trade-offs and constraints always vary, but\nmany of the underlying principles are universal.\n\n‘Feng GUD seeks to understand the dynamic flow of mental and physical energy.\nIt orchestrates the flow of attention and gesture throughout the interface as a whole.\nFitts’ Law is useful for scientifically analyzing performance speed and error rate, but it\ndoesn’t capture the human side of the equation. Feng GUI tries to prevent unfortu-\nnate accidents (like the 2000 Florida presidential election ‘Butterfly Ballot’) before\nthey happen.\n\nWhen designing a pie menu, think of Martha Stewart arranging a bunch of flow-\ners into a beautiful bouquet. You must work with what you're given, try to play off the\n\n118\n\nSection 1 General Programming\n\nvisual and semantic symmetries and relationships, and arrive at a pleasing pattern\nthat’s both enjoyable and easy to remember.\n\nTo construct a memorable pie menu tree of submenus, you should emulate\nAlexander Calder’s creating a hanging mobile sculpture. The task not only requires a\nsound understanding of scientific engineering principles, but also aesthetic judgment\ncalls and acrobatic balancing acts.\n\nDoug Engelbart, who invented the mouse and pioneered interactive user inter-\nfaces, strongly believes that the human-tool co-evolution should be based on rigorous\nexploratory use in a wide variety of real-world applications. So don’t just talk about\npie menus—use them, evaluate their performance, and improve upon them!\n\nResearching and Evaluating Pie Menus\n\nThe essential idea of directional menu selection has been around for a long time in\nvarious forms and with different names. Many examples of implementations exist,\nand a detailed history can be found at [PieMenu02].\n\nMany studies have also been done on their effectiveness compared to other UI\napproaches. Gordon Kurtenbach and Bill Buxton (University of Toronto) have\ndemonstrated many interesting results with their empirical research and controlled\nexperiments with marking menus and various input devices. At Alias| Wavefront, they\nhave successfully applied them to Maya, a high-end 3D animation environment, so\nusers can design their own marking menus to customize their environment. In their\nresearch, they studied the learning curve from novice to expert user. They found that\nthere are three stages of behavior along the learning curve:\n\n1. Novice users click up the menu, wait for it to display, look for the desired\nlabel, move the mouse, and click to select the highlighted item.\n\n2. Intermediate users remember the direction, click up the menu, move in a\ndesired direction, wait for the menu to pop up and highlight the desired\nitem, and release the button to confirm the selection.\n\n3. Expert users simply press down the button, move in a desired direction, and\nrelease the button without hesitating.\n\nBecause the physical motions of novice, intermediate, and expert users are the\nsame, pie menus transparently train you to become an expert. Each time you make a\nselection, you're rehearsing the expert mouse-ahead gesture. The intermediate stage is\nlike an escalator along the learning curve. It helps novice users become experts by\nexercising their skills and increasing their confidence to mouse-ahead. Your muscles\nquickly and unconsciously learn to mouse-ahead without looking.\n\nJaron Lanier (VPL Research) put it well: “The mind may forget, but the body\nremembers.” Pie menus exploit your body’s ability to remember muscle motion\nand direction, even when your mind has forgotten the names of the corresponding\nitems.\n\n1.14 Natural Selection: The Evolution of Pie Menus 119\n\nThe nature of the input device used has a significant effect on the selection speed\nand error rate. Mice have been found to be faster and more accurate than trackballs,\nand pens are faster and more accurate than mice.\n\nThe maximum usable breadth (number of items) and depth (submenu nesting\nlevel) is limited by the maximum error rate the application can tolerate. Nuclear\npower-plant interfaces should stick to single level-two and four-item pie menus,\nwhich are extremely reliable. A game like SimCity or an editor like Maya can get away\nwith using deeper menus with more items because it’s easier to recover from selecting\nthe wrong item.\n\nExperienced users perceive single-level pie menus with two, four, and six items to\nbe error-free, and eight items to be very reliable. Kurtenbach and Buxton measured\nthe error rate at less than 10% with four items four levels deep as well as with eight\nitems two levels deep.\n\nIncreasing the number of items in a pie menu has an obvious detrimental effect\non the selection speed and error rate, but the relationship is not simply linear. Even\nnumbers of items are easier to use and remember because more of the items are on-\naxis and symmetrical. On-axis items are easier to select than off-axis items, so it’s good\nto put commonly used items to the North, South, East, and West, and less-common\nitems along the diagonals.\n\nThis even/odd effect is most pronounced when comparing 7 versus 8 items, and\n11 versus 12 items. Eight and 12 items are especially easy to use, because the directions\nare mentally more familiar and physically more on-axis. As the number of items\nincreases, the negative effect of adding another item decreases. So, it’s often helpful to\nadd an extra item to 11-, 7-, and even 3-item menus, just to make them nice and even.\n\nWhen designing nested pie menus, the depth versus breadth trade-off seems to be\nabout even. So, it’s best to let the semantics of the items determine how they should\nbe arranged: shallow menus with many items, or deep menus with few items.\n\nIt’s worth noting that some menus still work better as linear menus. Most linear\nmenus and submenus aren't arranged to take advantage of the pie menu directions,\nand pie menus with too many items are huge and unwieldy. To solve those problems,\nmodifiable pie menus have been developed that the user could customize, and\nscrolling and paging pie menus can handle any numbers of items.\n\nComponent technologies, like ActiveX and Dynamic HTML behaviors, make it pos-\nsible to implement general-purpose, easily reusable plug-in user-interface compo-\nnents. Pie menus can provide configuration languages, property sheets, and\nspecial-purpose editors, which enable designers and users to create and customize\ntheir own menus without programming.\n\nActiveX (also known as COM and OLE) is a component technology developed\n\nby Microsoft. We developed an open-source ActiveX pie menu component that can\n\n120 Section 1 General Programming\n\nbe plugged into any OLE control container, including those used by Internet\nExplorer, Visual BASIC, Visual C++, and many other tools and applications. They're\neasily created and customized through scripting languages like Visual BASIC or\nJavaScript, and they have property sheets to configure their many options, for editing,\nand to preview the pie menus (see Figure 1.14.1).\n\nFIGURE 1.14.1 (A-D) Editing control properties using an example program.\n\nActiveX pie menus support many properties and methods to control their appear-\nance and behavior. You can customize pie menus by writing scripts that manipulate\ntheir properties, call methods, and handle callback events signaled during tracking.\nHowever, their graphical abilities are quite limited when compared to Dynamic\nHTML (see Figure 1.14.2).\n\nThe open-source JavaScript pie menus for Internet Explorer solve this problem\nnicely [JavaScript02]. They're tightly integrated with the Web browser and can take\nadvantage of all of its features. They're easily and completely configured in XML as\nwell as being extremely flexible, because you define their appearance with Dynamic\n\n1.14 Natural Selection: The Evolution of Pie Menus 121\n\nrman ah pH pg Nk ee a oR mon tire ne ea D A MCR at HE ALANINE ASAE EI\n\nFIGURE 1.14.2 (A-I) Pie menus implemented using Dynamic HTML.\n\n122 Section 1 General Programming\n\nscenes Sana Sta A I mn rm AN ERM MAP AANA RHEE natant nt A RNR aC\n\nHTML. These menus a easy for Web page designers to use for static pages and for\nWeb server programmers to use for dynamic online services because they're imple-\nmented as modular ‘Dynamic HTML Behavior Components.’\n\nJavaScript pie menus are specified in XML, so it’s possible for people to manually\nwrite them with a text editor. It is also possible for programs to dynamically generate\nthem from a database. The JavaScript pie-menu component code is cleanly distinct\nfrom the Web page and XML pie-menu specification. You can customize their be-\nhavior by writing event handlers on the Web page in JavaScript, VBScript, or other\nlanguages. They can provide rich, dynamic graphical feedback, because scripts can\nreach into the pie menus and Web pages, and actually modify the Dynamic HTML\non the fly.\n\nUsing XML to specify pie menus has many advantages. The format is indepen-\ndent of the implementation, so the same pie menus can be used across many different\nplatforms. Web servers and browsers can automatically transform application-specific\nXML formats into pie menus by using standard XML-processing tools, like XSTL\nand distributed XML databases. For example, an XSLT style sheet can dynamically\ngenerate a Web page with ‘Punkemon’ pie menus, based on an XML database of trad-\ning-card attributes and links to animations [Punkemon02] (see Figure 1.14.3).\n\nPunkemon Pie Menus! Punkemon Pie Menus!\n\nFIGURE 1.14.3 (A-C) The ‘Punkemon’ example.\n\nThe XML pie menu schema enables editors to automatically validate, construct,\nand edit pie menus. The pie menu schema is on the CD-ROM as well as\n[PieSchema02]. An example editor can be seen in Figure 1.14.4, which is available\nonline [PieEditor02].\n\nFasteroids {Fasteroids01] is both a real-time video game and an empirical user\ninterface experiment; it enables you to compare linear menus and pie menus. The\nJavaScript pie menus also support the old-fashioned linear menu style, and they can\nbe instrumented to record the selection time for experimental purposes. Fasteroids\nalternates between pie menus and linear menus (as shown in Figure 1.14.5), and\nprompts you to select a certain item to blow up the asteroids. It records and displays\n\nON THE CD\n\n1.14 Natural Selection: The Evolution of Pie Menus 123\n\n“Bait Pieblena Preperyy View\n‘Dexeripnam, Pie Mets Va,\n\n<icem name=\"Five\"/>\ncam neem 31>\n<item nemen\"Seyen\"/>\nitem Ammen Lge).\n\n</piemen>\nL </1tem>\n\nite,\nFo nemes*Sourbeaat >\n\n<piemenu\nweoue=\"'switenns\n<item nease=\"On\"/ >\nteem name\" On2\"/> Dee :\n\n</piemenur + Rit Pre bYemm Broperty.-Cemner Background Color\n\nDescraption: Pie Menu Center Backaround Color\n\n</ tiem,\n\ni <item\newes \"Snuch >\n\n<pienene\nfixedredius=\"40%>\n\n‘btanl>\nING ‘sro=\"bieb.jpg\"/>\n</btinl>\n\ns<?eml_version=\"1.0\"2>\n\n<achema\nsmlng*\"het p://va¥. ¥3 .otg/ 1999/TELScheme”\ntargetNemespace=\"httpi//sws. pienent.cci/ piemmeuimiachers~1.0.4947\nsoelns: pie \"http i//wrw.piemecu.con/ piemenwarlschem-1.0.%sa\"\nelement FormDefaaic=\"qualitied”\n\nE versions \"uly 8 2001\">\n\n| <npnptet san> |\nthw : “Baa item Property: [HTML -\n<documentat dom> HIML Bement Content in Pie E h\nA Schesa for Pie Benus.~ by Dori Bopkins cca in Pie Menu Bera E cnpty, the bw Name is chown xwte wd.\n¢</Socummacetion> Element\n\n:fe@y Tie Biebs <8) <ea/ ><img sca~\"bleb-dpg\"7>\n\n<documenceat ion sources \"nt tp: //wws. pismeny.com”>\n\nA B\nFIGURE 1.14.4 (A-B) ie menu schema and editor.\n\nFasteroids Fasteroids\nCopyright (C) 2001 By Yr: Copyright (C) 2001 B:\nRound ? Round 8\nPre Menna Linear Mems\nConstant Itemax Comstant Ite\n\ne Stensoce\n\n‘Mem! Menu ‘Selection ‘Correct Total Average Erret Error\n‘Type Items.' Count Conmt Time Tume Count Rate\nPie Random 3036500 12166672 6%\n: “95620 15675416 9%\n48340 525.435 4\n\nA B\nFIGURE 1.14.5 (A-B) The Fasteroids game and experiment.\n\n124 Section 1 _General Programming\n\naunt RRA RRR eh A ROA OO EOE MNO reese\n\nthe average selection time and error rate, so you can compare pie menus and linear\nmenus for yourself.\n\nFuture Directions\n\npommanierteracenmnnnuneenst\n\nPie menus work well with touchscreens on » handheld devices like the Palm Pilot and\nthe Pocket PC. ‘Finger Pies’ are easy enough to use with your finger, so no pen is\nrequired. A product we have developed called ConnectedTV makes your handheld\ninto a customizable entertainment guide and remote control that’s designed to be\nheld in one hand and operated with the thumb and finger. ConnectedTV lets you use\nfinger pies to make your own personalized television schedule, filter, and program-\nsearch guide; you can flip back and forth through show descriptions and movie\nreviews, and send infrared remote-control commands to change the TV channel and\noperate other equipment.\n\nFast, inexpensive motion detectors that are sensitive enough to detect the direc-\ntion of gravity will soon be built into consumer electronic equipment like cell phones,\nhandheld computers, remote controls, and games. Motion detectors will enable con-\nvenient one-handed scrolling, dialing, panning maps, tilting pie menus, continuous\ngesture recognition, and many other exciting interaction techniques.\n\nGoing to Town with SimCity .\n\nIn 1991, we first ported Sim Ci to , Unix. Ie featured p pie mer menus (see Figure 1.14.6) for\nquickly selecting SimCity editing tools, which was a useful shortcut for the original\nSimCity command palette.\n\nStatic pie menus whose items don’t change can be carefully designed for ease of\nuse and nicely illustrated for aesthetic appeal. We translated the SimCity tool palette\ninto a convenient set of static pie menus. Icons in the pie menus are arranged in the\nsame pattern as the palette, so they’re easy to learn and quick to use.\n\nPop-up pie menus let you quickly switch tools without moving back and forth\nbetween the map and the tool palette. You soon learn to mouse-ahead through the pie\nmenus and submenus just by flicking in the appropriate directions. Thanks to\nMoore’s Law, you can now run Sim City so fast, it’s a strategy twitch game, running at\ndecades per second. Thanks to Fitts’ Law, pie menus help you keep up with acceler-\nated SimCity time by mousing-ahead without looking, and without wasting centuries\ndragging though linear menus.\n\nThe icons of the SimCity tool palette and pie menus are different sizes and shapes\nthan the original, square SimCity tool icons. Their sizes and shapes are related to the\nprices and functions of the tools. Small icons stand for inexpensive tools, like parks or\nbulldozers. Large icons stand for expensive tools, like power plants or airports. Long\nicons suggest linear tools, like roads or railroads. And square icons are for square\nbuildings, like residential zones or fire stations. The purpose behind this oddball icon\ndesign is to make remembering and differentiating between them easier (see Figure\n\n1.14.6).\n\n125\n\n1.14 Natural Selection: The Evolution of Pie Menus\n\n‘nua ad sMarjuty  (9-w) 9*v bk FHNDId",
      "page_number": 119,
      "chapter_number": 12,
      "summary": "Fitts’ Law [Fitts54] explains\nthe pie menu advantage—their fast selection speed and low error rate is due to their\nlarge target size and the small distance between each item Key topics include pies, item.",
      "keywords": [
        "Pie Menus",
        "Pie",
        "Menus",
        "JavaScript pie menus",
        "XML pie menu",
        "Pie Menus User",
        "items",
        "pie menu schema",
        "Static pie menus",
        "pie menu directions",
        "Punkemon Pie Menus",
        "Pie Menus Don",
        "linear menus",
        "Evaluating Pie Menus",
        "Pie Menu Bera"
      ],
      "concepts": [
        "pie",
        "pies",
        "item",
        "menus",
        "user",
        "xml",
        "directions",
        "directional",
        "direction",
        "tools"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 8",
          "chapter": 44,
          "title": "Segment 44 (pages 418-425)",
          "relevance_score": 0.45,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 1",
          "chapter": 33,
          "title": "Segment 33 (pages 308-321)",
          "relevance_score": 0.36,
          "method": "api"
        },
        {
          "book": "More Effective C++",
          "chapter": 1,
          "title": "Segment 1 (pages 1-8)",
          "relevance_score": 0.35,
          "method": "api"
        },
        {
          "book": "AntiPatterns",
          "chapter": 3,
          "title": "Segment 3 (pages 22-29)",
          "relevance_score": 0.34,
          "method": "api"
        },
        {
          "book": "Effective-Python",
          "chapter": 12,
          "title": "Segment 12 (pages 115-125)",
          "relevance_score": 0.34,
          "method": "api"
        }
      ]
    },
    {
      "number": 13,
      "title": "Segment 13 (pages 129-137)",
      "start_page": 129,
      "end_page": 137,
      "detection_method": "topic_boundary",
      "content": "126 Section 1 General Programming\n\n‘CE EC MEIER NE NOE hESC ERC SET OH EEE TOTO EOE I CO Be OOOO AOE 1 nosateievnetercnmmleit MeltenininisieBONlteaRNSAOAEENINEEY\n\nLiving at Home with The Sims\n\nRSS ISSR ES TERESA.\n\nThe pie menus in The Sims use a combination of desaturation, darkening, and alpha\nblending to feather the edges of the menu (see Figure 1.14.7 and Color Plate 1). This\nwas done because we didn’t want the pie menus to obscure too much of the scene\nbehind them. You can see through the pie menu as the animation continues on in\nreal-time behind it. The head of the currently selected person is drawn in the center of\nthe pie menu and follows the cursor by looking at the currently selected item.\n\nIt was necessary to somehow separate the head from the rest of the scene. Other-\nwise, it looked like a giant head was floating in a room of the house, which was some-\nwhat disconcerting and violated the ‘Principle of Least Astonishment.’ Simply\ndrawing a solid menu background would obscure too much of the scene behind the\nmenu. Using a partially transparent menu background still did not visually separate\nthe head from the background scene enough. It looked muddy and cluttered, instead\nof crisp and bright.\n\nInstead of simply alpha-blending the menu background, we actually lowered the\ncontrast, which darkens the image and desaturates the background. The effect was to\ncast a colorless shadow with soft, feathered edges over the animated background,\nagainst which you can easily see the head and menu item labels.\n\n(Give Gift Entertain\n‘tg Give Back Rub\n\nFIGURE 1.14.7 Pie menus in The Sims.\n\n1.14 Natural Selection: The Evolution of Pie Menus\n\n127\n\nInstead of drawing a circular edge around the pie menu, the gray shadow gradu-\nally tapers off, suggesting that the active pie menu target area is not confined to a\nsmall circle. The labels are drawn around the pie menu center with high-contrast drop\nshadows, so they're easy to read.\n\nThe animated head in the center needed to look sharp and bright against the pie\nmenu background. So, the shadow effect looks at the Z buffer to clip around the head\nin the menu center, keeping it crisp and bright. That gives it visual ‘pop,’ which\nclearly separates the user interface from the world, without drawing dividing lines or\nunnecessary visual clutter.\n\nConclusion\n\nRA EE AR EE Nk ORR NR IT SSAA NERS AAS EES\n\nPie menus benefit from the natural consequences of Fitts’ Law. They're neither the\nonly nor the best user interface technique to take advantage of this effect. However,\nthey're a great improvement over today’s standard linear menus and a stepping stone\nto developing even better user-interface techniques.\n\nThe proven advantages that pie menus have over linear menus are their higher\nspeed and lower error rate. They also have the potential to be carefully designed and\nconveniently automated in many different ways, which increases their usefulness for\nmany applications.\n\nComputer games and handheld consumer electronic devices are reshaping the\nway user interfaces are designed because of their new and unusual demands. Real-\ntime games require quick, responsive, engaging user interfaces. Handheld computers\nand phones must be useful for a wide range of people in real-world conditions, so they\ndemand high reliability and ease-of-use.\n\nDesigning a good user interface requires balancing many competing demands\nand guidelines. It’s extremely important not to squander the user’s time or atten-\ntion—consider it your most rare and precious resource. Don’t get tripped up on\nmetaphors—take a step back and look at what’s really going on. Think in terms of the\nuser’s goals, mental models, and physical actions.\n\nBe prepared to throw away your first design. Use your own system on an everyday\nbasis. Continuously iterate the design, based on feedback from empirical testing and\nthe users themselves. Every application and user has different requirements that\ndemand different trade-offs at different times.\n\nDesigning good pie menus takes thought and effort, like writing Haiku. Limit\nthe number of items in each menu, and group them together into memorable, bal-\nanced submenus. Arrange the items in natural directions to exploit their semantic\nrelationships and physical associations. Don’t exclusively use pie menus when other\ntechniques are more appropriate, like sliders, scrolling lists, keyboards, or handwriting\nrecognition. It’s a good idea to provide multiple ways of accomplishing the same task\nwhen it makes the application easier to use.\n\nFeng GUI seeks to integrate the lessons of real life, empirical research, and theo-\nretical principles, and apply them to the enlightened design of efficient, reliable user\n\n128 . Section 1 General Programming\ninterfaces. The “Butterfly Ballot” debacle demonstrated how badly designed user\ninterfaces can have enormously consequential effects on the real world. By striving to\ndesign user interfaces with good Feng GUI, you can improve people’s lives and affect\nthe world in many positive ways.\n\nReferences\n\n[Fasteroids01] Hopkins, Don, Fasteroids, available online at http://www.PieMenu\n.com/fasteroids.html, March 2002.\n\n[Fineman01] Fineman, Howard, “Unsettled Scores,” Newsweek, September 17, 2001.\n\n[Firts54] Fitts, PR M., “The Information Capacity of the Human Motor System in\nControlling the Amplitude of Movement,” Journal of Experimental Psychology,\n1954: Vol. 47, pp. 381-391.\n\n[JavaScript02] Hopkins, Don, “Open Source JavaScript Pie Menus,” available online\nat http://www.PieMenu.com/JavaScriptPieMenus.html, March 2002.\n\n[PieEditor02] Hopkins, Don, “Pie Menu Schema Editor,” available online at\nhttp://www. PieMenu.com/ piemenuschemaeditor.html, March 2002.\n\n[PieMenu02] Hopkins, Don, “Pie Menu Central,” available online at http://www\n.piemenus.com/, March 2002.\n\n[PieSchema02] Hopkins, Don, “Pie Menu XML Schema,” available online at\nhttp://www.PieMenu.com/piemenuxmlschema-1.0.xsd, March 2002.\n\n[Punkemon02) Hopkins, Don, “Punkemon Pie Menus,” available online at http://\nwww. PieMenu.com/punkemon.xml, March 2002.\n\n1.15\n\nLightweight, Policy-Based\nLogging\n\nBrian Hawkins, Seven Studios\nwinterdark@sprynet.com\n\nMo debuggers are powerful and very useful, but there are still places they can-\nnot reach. This is where a simple, lightweight logging system is of great value.\nLogging can be used when a debugger is not available, which is often the case for\ngame designers and testers. Logging also allows the examination of the current game\nstate and similar information, while the game continues running under normal\noperation.\n\nTo accomplish this end, an efficient logging system that is configurable at both\ncompile time and runtime is introduced in this gem. The entire system can be placed\ninto a library, thus maintaining compile time flexibility through the use of policies\n[Alexandrescu01], and includes the ability to remove the logging calls from the final\ngame. Runtime configuration allows the modification of logging data without the\nneed to recompile. This also allows developers to share the same code, but only log\nthe information they want to see. Thus, code can be entered into a source control sys-\ntem without the need to remove logging calls that might be useful later. We will also\nconcentrate on performance throughout the gem.\n\nPolicies define a class interface that is compile-time bound as a template parameter.\nPolicies are similar to the ‘traits’, used by the Standard Template Library (STL) and\nthe Strategy Design Pattern [GoF95]. The end user of a policy-based class can then\ncreate a class that conforms to the specified interface. This class is passed as a template\nparameter to configure an instance of a policy-based class without the need to change\nthe original class code. This makes policies useful in creating robust libraries, a con-\ncept that will be used throughout the design of the logging system. More information\non policies and policy design can be found in Modern C++ Design [Alexandrescu0 1].\n\nDebugging flags\n\nboolean type for determining whether to perform various debugging operations.\n\n129\n\n130\n\nSection 1 General Programming\n\nWhen designing a flag, there are several decisions that need to be made. These deci-\nsions can be grouped into three main choices—initialization, assignment, and storage\ntype— that can be turned into policies, allowing the final decision to be made by the\nflag user. We can then provide implementations of these choices that are useful for\n\nlogging.\n\nInitialization\nThe most important decision is the method of initialization. The policy interface for\ninitialization is:\n\nclass t_InitializationPolicy\n\n{\ntypedef /*type*/ t_Type;\nStatic bool m_Convert(t_Type i_value) ;\n\n3\n\nThe first part of the interface defines the argument type used for initialization.\nThis is the type that will be passed to the flag’s constructor. The debug flag has access\nto this type because it is defined as t_Type. The second part of the interface is a func-\ntion that takes an argument of t_Type and converts it to a boolean value. This func-\ntion must be declared as static, so that it can be accessed without the need to\ninstantiate an instance of the class. With these two pieces, the constructor for the\ndebug flag can be implemented to take an argument, convert it to boolean, and then\nstore the boolean value.\n\nAssignment\n\nThe interface for the assignment policy is identical to the initialization interface. The\ntwo interfaces are separate in order to allow different types for initialization and\nassignment. Thus, the primary difference is only that the assignment policy is used\nto implement operator=, while the initialization policy is used to implement the\nconstructor.\n\nBoolean Storage Type\n\nThe final decision is the boolean storage type. The primary use of this policy is to\nmake the flag either a constant or a mutable boolean flag. By defining the type of the\nflag as constant, assignment is disabled. By defining the type as a normal boolean,\nassignment is made possible. It is also possible to provide more-complex types, as long\nas they support assignment from boolean and conversion to boolean. The policy\ninterface for this is:\n\nclass t_BooleanPolicy\n\n{\n}5\n\ntypedef /*type*/ t_Boolean;\n\n1.15 Lightweight, Policy-Based Logging 131\n\nThe debugging flags greatly benefit from the ability to be initialized using a configu-\nration file, since debugging information can then be enabled without recompiling.\nFor this purpose, a Singleton class [GuF95] is created that provides initialization from\na single configuration file.\n\nInitialization\n\nThe first step is to initialize the configuration Singleton class by parsing the configu-\nration file. A sorted string array, using std::vector or a similar array class, is created\nbased on the contents of the configuration file. Once an array of available strings is\nsorted, we can use a binary search, such as std: :binary_search [Meyers01], to find a\nparticular string. Because most debugging flags are initialized at the start of an appli-\ncation, there is not as much of a concern for performance. Even so, the binary search\nshould be efficient.\n\nUse PIMPL\n\nThe public interface for the configuration file is simple and should not change,\nwhereas the private implementation has several options that might change for various\nreasons. The PIMPL, or Private Implementation, design pattern [Sutter00] is ideal\nfor separating the public interface from the private implementation. The public class\ncontains a pointer to a private implementation class, and the public class passes all\nfunction calls along to the private implementation. The private implementation can\nthen be created in a separate header or in the source file. If private changes are\nrequired later, there will be no effect on users of the public interface. This paradigm\nalso discourages the user of the public interface from relying on private implementa-\ntion details.\n\ninto a single configuration flag. The best approach for this is to provide an initializa-\ntion policy for the debug flag that uses a Singleton configuration class. The definition\nof t_Type, above, would become a string, and the conversion function would call the\nconfiguration Singleton class to convert the string to a boolean.\n\nThe log class brings all the components together with several policy interfaces to form\nthe workhorse of the logging system.\n\nFlag Policy\n\nEnabling and disabling of a log instance is based on the flag policy provided. The flag\npolicy interface is:\n\n132\n\nclass t_FlagPolicy\n\n{\ntypedef /*type*/ t_InitializationType;\ntypedef /*type*/ t_AssignmentType;\nt_FlagPolicy(t_InitializationType i_value);\nt_FlagPolicy& operator=(t_AssignmentType i_value) ;\noperator bool() const;\n\n3\n\nThe first two parts of the interface are type definitions for the constructor and\noperator=. The flag policy must also support a constructor that takes the initializa-\ntion type and an assignment operator chat takes the assignment type. Note that this\npolicy differs from the others described previously because an instance of the flag is\ncreated within the log class, causing the need for a constructor. Finally, the flag policy\nmust support conversion to a boolean value. The debugging flag described earlier fits\nthe required interface.\n\nOperator<<\n\nThere are two primary methods for logging messages: variable-length argument lists\nor operator<<. While variable-length argument lists are a traditional method for log-\nging operations, this method introduces potential problems:\n\n¢ Lack of argument checking.\n\n¢ Lack of type safety.\n\n¢ Lack of extensibility.\n\n* No support for user class types.\n\nIn the best case, these problems could lead to garbage information in the logging\nsystem. In the worst case, logging could end up corrupting or crashing the game. For\nexample, if a string is specified in che output format, but is not included in the argu-\nment list, an invalid memory address is likely to be referenced. On many platforms,\ncertain memory addresses throw an exception even when the data is only being read,\ncausing the game to crash if the invalid memory address happens to land within one\nof these ranges.\n\nThe operator<< solves all of the problems previously listed, but it introduces a new\none. Variable argument list syntax would invoke only one function call, whereas opera-\ntor<< could invoke an unspecified number of functions calls. A buffer is needed to store\nthe result of each subsequent call until the entire log is collected and ready for dispatch.\n\nGiven the tradeoffs, operator<< is the still the best approach, so we deal with the\nbuffer issue by defining a buffer policy.\n\nDefining a Buffer Policy\n\nA buffer implementation, which determines how the log string is stored until being\n\ndispatched, is specified by the buffer policy:\n\n1.15 Lightweight, Policy-Based Logging ; 133\n\nclass t_BufferPolicy\n\n{\ntypedef /*type*/ t_Type;\nstatic const string m ToString(const t_Type &i_buffer) ;\nstatic void m_Clear(t_Type &o_buffer) ;\n\n}5\n\nThe first part of the interface is the buffer class type, an instance of which will be\ncreated with each log class. Note that the buffer type must support all instances of\noperator<< that are to be logged. This allows the log class to pass on all operator<<\ncalls to the buffer policy with a template member function:\n\ntemplate <typename t_Type>\nt_LogImplementation& operator<<(t_Type i_value)\n{ m_buffer << i_value; return(*this); }\n\nAlthough a new class could be implemented, in most cases, the STL\nstd::stringstream is the best choice. The standard string stream also supports the\nother two buffer policy functions.\n\nThe m_ToString function converts the contents of the buffer to a standard string.\nThe standard string will then be passed to the dispatch policy (described later). The\n\nm_Clear function is used to clear the buffer once it has been dispatched.\n\nPerformance\n\nThe most important performance issue to address is log instances that have been dis-\nabled. Enabled logs are not as much of a concern because they are already bottle-\nnecked by the performance of I/O. For disabled logs, a boolean test and a branch\nshould be all that is performed. This prevents the use of a single function for the pur-\nposes of logging, which would require the evaluation of all function arguments. Since\noverloaded operators are really just functions with convenient calling syntax, they are\nnot useful, either.\n\nInstead, it is necessary to fall back to a trusted C paradigm—logical AND, &&. By\nplacing the boolean test before && and the logging function after, the entire logging\ncall is short-circuited when the boolean test is false. There are two steps to accom-\nplishing this result. First, for simplicity, define a macro:\n\n#define LOG(type) (type) && (type)\n\nNote that a macro must be used to ensure the logical AND behavior is preserved.\nA template function would result in a function call that would defeat the purpose of\nusing logical AND. Second, define an inline implementation of operator bool for the\nlog class that only calls the dispatch function when the internal flag is true:\n\nOperator bool() { return(m_flag && m_Dispatch()); }\n\n134 Section 1 General Programming\n\nThis will expand to result in only one test and one branch for disabled flags. You\nmight be wondering about the dispatch call, which appears to be called twice due to\nthe two boolean conversions in the LoG macro. It is called twice for each log, but the\nfirst call performs no dispatch because the buffer is empty.\n\nDispatch Policy\n\nOnce the buffer is full and operator bool is called on the log class, the string is\nextracted, then the buffer cleared. The string is then passed to the dispatch function\ndefined by the dispatch policy:\n\nclass t_DispatchPolicy\n\nstatic void m_Dispatch(const string &i_string);\nhs\n\nThis function can be defined to do any number of things, including writing to\nthe console, writing to a file, displaying the message onscreen, or all of the above.\n\nThe first step in using the logging class is to create an instance of the class. Because\ntemplates are used, it is often helpful to define a shorthand type for various sets of\ntemplate arguments. For example:\n\ntypedef t_FlagImplementation<\nt_FlagConfigurationPolicy,\nt_FlagBooleanMutatorPolicy,\nt_FlagMutablePolicy> t_ConfigurationFlag;\n\ntypedef t_LogImplementation<\nt_ConfigurationFlag,\nt_StandardOutDispatchPolicy,\nt_StringStreamBufferPolicy> t_Log;\n\nFrom this, instances can be created that are initialized from the configuration file:\n\nt_Log LOG_MEMORY( \"MEMORY\") ;\nt_Log LOG_SCRIPT(\"SCRIPT“);\n\nLogging information is very similar to using the standard I/O streaming library.\nThe following is an example of a log:\n\nLOG(LOG_MEMORY) << \"Memory used is \" << 1_memoryUsage\n<< \"\\n\";\n\nThere is also the option to change the state of the logging instance later, for\nexample:\n\nLOG_SCRIPT = false;",
      "page_number": 129,
      "chapter_number": 13,
      "summary": "This chapter covers segment 13 (pages 129-137). Key topics include logging, logs.",
      "keywords": [
        "EEE TOTO EOE",
        "Sims RSS ISSR",
        "NOE hESC ERC",
        "pie menus",
        "OOOO AOE",
        "ISSR ES TERESA",
        "MEIER NE NOE",
        "EEE TOTO",
        "TOTO EOE",
        "Living at Home",
        "RSS ISSR",
        "type",
        "pie",
        "menu",
        "log"
      ],
      "concepts": [
        "logging",
        "log",
        "logs",
        "types",
        "policy",
        "policies",
        "operation",
        "operations",
        "operator",
        "designed"
      ],
      "similar_chapters": [
        {
          "book": "Designing Machine Learning Systems An Iterative Process for Production-Ready Applications",
          "chapter": 33,
          "title": "Segment 33 (pages 281-289)",
          "relevance_score": 0.61,
          "method": "api"
        },
        {
          "book": "A Philosophy of Software Design",
          "chapter": 10,
          "title": "Segment 10 (pages 77-87)",
          "relevance_score": 0.6,
          "method": "api"
        },
        {
          "book": "Generative AI with LangChain_2e",
          "chapter": 32,
          "title": "Segment 32 (pages 270-277)",
          "relevance_score": 0.59,
          "method": "api"
        },
        {
          "book": "Release It! Design and Deploy Production-Ready Software",
          "chapter": 15,
          "title": "Segment 15 (pages 115-122)",
          "relevance_score": 0.59,
          "method": "api"
        },
        {
          "book": "Microservices Up and Running",
          "chapter": 6,
          "title": "Segment 6 (pages 59-67)",
          "relevance_score": 0.58,
          "method": "api"
        }
      ]
    },
    {
      "number": 14,
      "title": "Segment 14 (pages 138-145)",
      "start_page": 138,
      "end_page": 145,
      "detection_method": "topic_boundary",
      "content": "1.15 Lightweight, Policy-Based Logging 135\n\nWith the information presented in this gem, a logging library can be created that is\nboth flexible and efficient. Extensions can be made without the need to change the\nlibrary code through the use of policies. Several basic policies are provided here and\non the CD-ROM, but there is still a wealth of new policies that can be written for\nspecific implementations. We encourage you to explore them.\n\n[Alexandrescu01} Alexandrescu, Andrei, Modern C++ Design, Addison-Wesley, 2001.\n\n[GoF95] Gamma, Erich, et al. Richard Helm, Ralph Richard, Johnson, Ralph, and\nJohn Vlissides, John, Design Patterns, Addison -Wesley, 1995.\n\n[Meyers01] Meyers, Scott, Effective STL, Addison -Wesley, 2001.\n\n[Sutter00] Sutter, Herb, Exceptional C++, Addison -Wesley, 2000.\n\n1.16\n\nManaging the Information _\n\n136\n\nJournaling Services\n\nEric Robert,\n\nUbi Soft Entertainment, inc.\neric.robert@videotron.ca\n\nebugging interactive applications is not a trivial task. Lots of things can go wrong\n\nwithout leading to a crash or without getting caught by proofing code. Also, tim-\ning issues, which are often involved, just make matters worse.\n\nIt is not uncommon to have some sort of state machine with unexpected behav-\nior under specific conditions. The faulty logic that triggered this condition could be\nvery far from the experienced problem in terms of both time and code. Many inter-\nmediate states could get executed before reaching the point where the error is finally\nnoticed. This occludes the real problem from the programmer and significantly\nincreases debugging time. Without any kind of execution history, the problem must\nbe reproduced over and over until the iterative process narrows down and gives a clear\npicture of what is really happening.\n\nProgrammers typically try to trace the code using their debugger. If this is not\npossible, they will start adding some debugging code to generate primitive tracing\ninformation where it might be needed. This is a long and arduous task. On the other\nhand, breaking into the code only reveals the current state of the application. What\nwent wrong could be light-years away and might not be retraced. Since debuggers\ntypically provide many effective ways to stop execution and to monitor memory, they\nare of limited help when it comes to interactive applications. What is needed is some\nway to trace the program’s flow without breaking it.\n\nTherefore, a solution could be to provide real-time information about what is\ngoing on under the hood in a flexible and efficient way. This is what this gem will\nfocus on.\n\nAn important consideration about real-time debugging is the amount of information\npresented to the user. It must be understood that having too much information is just\nas bad as not having enough. A monstrous amount of information will slow down the\nsystem and overwhelm the user. Needless to say, too little information is also quite\nuseless.\n\n1. 16 Journaling Services © 137\n\nThe ideal balance must be reached by presenting the right debugging information\nat the right time. Therefore, the user should be actively involved in the selection of\nthe source of that information. Being able to focus reporting precisely on a specific\nsystem or subsystem can be a very precious tool. This way, journaling services can be\nused to mimic the debugging process and provide support for a divide-and-conquer\napproach known to help find and correct bugs.\n\nThus, the system should consist of a logical state (on/off) associated with each\nsystem or subsystem to support the activation or deactivation of reporting functions.\nIt should be built so that it can provide easier control over groups of states. For exam-\nple, the journaling of a complete system could be disabled without having to specify\neach and every associated subsystem:\n\nJournaling: :setDisable(\"/Core/Loading/...\");\n\nAnother consideration is the location where reports will be written. The user\nmight want data to be presented directly on-screen, sent directly to a file, or maybe\neven across the network if the monitored application is remote. This kind of flexibil-\nity is most welcome in console projects, since debugging is often somehow limited.\n\nBy providing an extensible framework from which alternative output locations\ncan be developed and integrated, the system’s usability will increase substantially.\n\nThe System Hierarchy\n\nUR HN TE HLL I EO A Sat ses nao\n\nOur journaling services are - built around three classes: the § Switch, the SwitchBox and\nthe Journal. Many concrete services can then be built using these basic components.\n\nThe switch is the primary interface that users interact with. It contains a logical\nstate and the associated output location wrapped in a Journal. Each Switch is owned\n\nSwitchBoxX\n\nSwitch A\n\n- On\n- Debugger\n\nYA &Z/A\n\nSwitchBox Y SwitchBoxZ\n\nSwitch A f} Switchc Switch A\n\n- On -On\n- Debugger | | - Log - Debugger\n\nFIGURE 1.16.1 Architectural overview.\n\nSection 1 General Programming\n\nby a SwitchBox, which is part of the SwitchBox tree. By naming each element with\nstrings, the user can refer to them using the path notation.\n\nmySwitch = Journaling: :getSwitch(\"/Core/Loading/Trace\");\n\nIn the hierarchy, each SwitchBox is an internal node, and each Switch is a leaf. So,\nin this example, both “Core” and “Loading” are SwitchBoxes and “Trace” is a Switch.\n\nThe goal here is to have a Switch associated with a particular reporting facility for\na particular system or subsystem. Thus, a complete area of the program could control\nits reporting facilities with a simple query on the current state of its Switch.\n\nif (mySwitch->getState()) {\nmySwitch->getJournal() << \"Some Trace\";\n\n}\n\nBefore presenting some code, it is worth mentioning that while designing this\nsystem, we considered the journaling services to be basic services. Thus, we didn't use\nany kind of dynamic memory allocation (since the memory manager could eventually\nuse those services, creating a dependency loop). We also decided that the whole sys-\ntem should be available before the program entrance (main), since the service might be\nuseful for tracking construction of global objects. Because the initialization order of\nglobal objects cannot be controlled in a portable manner, we aimed for objects that\nwill be initialized on demand.\n\nFirst, users must declare their own SwitchBox and Switch singleton objects in\norder to use them in services. The initialization procedure for both classes is done\nusing the same method. The singleton instance is constructed on its first access using\na static factory method that will insert the object into its owner’s singly linked list.\nNote that macros are available for these tasks, but the generated code for a Switch is\npresented here.\n\n// Header file\nclass SwitchSample : public Switch\n\n{\ntypedef Root OwnerType;\nStatic Switch * ourInstance;\nstatic Switch * staticFactory();\npublic:\n\nSwitchSample() ;\n\nstatic Switch * getInstance() {\nif(ourInstance) {\nreturn ourInstance;\n\n}\n\nreturn staticFactory();\n\n1.16 Journaling Services _ ; 139\n\n}5\n\n// Source file\nSwitchSample: : SwitchSample()\nSwitch (OwnerType: :getInstance(),\n\"My name\",\n“My description\") {}\n\nSwitch * SwitchSample::staticFactory() {\nstatic SwitchSample instance;\nourInstance = &instance;\nreturn ourInstance;\n\n}\n\nSwitch * SwitchSample::ourInstance =\nSwitchSample: :getInstance();\n\nUsing the helper macros usually make more sense.\n\nDECLARE_SWITCH(SwitchSample, Root);\nIMPLEMENT_SWITCH(SwitchSample,\n\n\"My name\",\n\n\"My description\");\n\nThe singly linked list is implemented without memory allocation by considering\neach inserted item as a node of the list. Thus, both classes supply a link to the next list\nitem (called the brother), allowing insertion.\n\nvoid SwitchBox: :addSwitch(Switch * item) {\nif(mySwitches) {\nitem->myBrothers = mySwitches;\n\n}\n\nmySwitches = item;\n\n}\n\nThis kind of structure will enable the implementation of a hierarchical propaga-\ntion of settings. This could be useful to enable (or disable) a Switch for a system and\nall its subsystems at once. Since everything is related somehow to the Root node, it\nalso provides a way to list and manage everything in the system.\n\nIt also gives the opportunity to provide a number of operations on the whole\nSwitchBox tree at once. A class named Journaling implements many of these operations.\n\n// Disable everything at once.\nJournaling: :disableAll();\n\n// Print the whole tree.\nstd::cout << Journaling: : getRoot();\n\nDue to the way instances are defined, the initialization of some branches in the\nSwitchBox tree will be forced if they are used before main. It is only after this process\n\n140\n\nthat the whole tree is really available for operations. Hence, even if the system works\nfor global objects, it is somewhat limited.\n\nEach SwitchBox supplies two singly linked lists that use forward iterators. One is\nfor Switch and the second one is for SwitchBox children. They support both incre-\nment operators and the indirection operator that returns a reference to the associated\nlist item. Thus, in the previous example, if a Switch named “Trace” is added to the\nexisting SwitchBox named “Core”, changing the state of the “Core/Trace” could prop-\nagate at the lower level and update the “Core/Loading/Trace” accordingly.\n\nvoid Switch::setState(bool state, bool recursive) {\nmyState = state;\n\nif(recursive) {\nmyOwner ->propagateState(this) ;\n\n}\n}\n\nvoid SwitchBox: :propagateState(Switch * source) {\nSwitchBox:: Iterator i = getChildrenBegin() ;\n\nwhile(i != getChildrenEnd()) {\nSwitchBox * node = &(*it++);\nnode->setState(source) ;\n\n}\n\nvoid SwitchBox::setState(Switch * source) {\nSwitch: :Iterator i = getSwitchesBegin();\n\nwhile(i != getSwitchesEnd()) {\nSwitch * leaf = &(*i+t+);\n\nif(!strcomp(leaf->myName, source->myName)) {\nleaf->myState = source->myState;\n\n}\n}\n\npropagateState(source) ;\n\n}\n\nOther mechanisms could also be built around the hierarchical system already in\nplace. These might include some sort of extended name-matching using wildcards or\nregular expressions. However, the basic functionality presented here should be enough\nto efficiently use the system and control the flow of information.\n\nThe supplied code sample also implements the Journal propagation and some\nsearching facilities in the SwitchBox tree using path notation. A more elaborate imple-\nmentation could provide (at least) a console command so that the user could modify\nthe system’s Switch states in real-time. Maybe a stand-alone user interface would be\nuseful for remote debugging on systems that do not support a keyboard.\n\n1.16 Journaling Services 141\n\nThe Journal Interface\n\nSSiRRISATRERRRTIN ARRAN TARO ANIMAS TEENAGE LISLE LIER OT VG EAGT RE, AMR RTE MRE TELE ELE EGET\n\nAn output location is associated with a Switch instance using the Journal abstraction.\nIt simply provides a way to output formatted text to different devices. Since instances\nof Journal will be shared, this resource is reference counted.\n\nOne way to implement this is by using the standard libraries with the\nstd: :iostream. Since the design is extensible, we can build our own streams fairly eas-\nily. As an example, a debug stream (specific to Win32) is presented here.\n\nFor those not familiar with the std: : iostream design, it can be divided into two\nlayers. The first implements all formatting concepts with manipulators and operators.\nThe other provides the underlying buffering mechanism. This separation will enable\nus to build our own buffering system and support alternate output locations while\nbenefiting from standard formatting operations. Our debugger stream is built around\na simple deviation from the std::streambuf. Since we only need an output stream,\nthe input part of the buffering is disabled (by default).\n\nThe first step is to build a std::streambuf. A fixed-size buffer is provided for\nbuffering, and only two virtual methods need to be implemented. The first one trans-\nfers the data within the buffer to the debugger with a Win32 call. Note that one char-\nacter is reserved for the null termination. The second function deals with overflow\nsituations.\n\nclass DebuggerStreamBuf : public std::streambuf\n\n{\nchar myBuf [512];\npublic:\nDebuggerStreamBuf() {\nsetp(myBuf, myBuf + sizeof(myBuf) - 1);\n}\nprotected:\n\nvirtual int sync() {\nsize_t len = pptr() - pbase();\n\nif(len > 0) {\nmyBuf[len] = 0;\nOutputDebugString (myBuf ) ;\nsetp(myBuf, myBuf + sizeof(myBuf) - 1);\n}\n\nreturn 0;\n\n}\n\nvirtual int_type overflow(int_type c) {\nsync();\n\nif(c != traits_type::eof()) {\nmyBuf [0] = c;\n\n142 Section 1 General Programming\n\npbump (1);\nreturn c;\n\n}\nreturn traits_type: :not_eof(c);\n};\n\nThe journal provides two additional virtual functions used to delimit the begin-\nning and the end of a reporting event. For the debugger journal, only the end is used,\nwhich provides synchronization with the debugger. So, to implement this journal, the\nstd: :ostream subsystem must simply be initialized with the above std::streambuf.\n\nclass DebuggerJournal : public Journal\n\n{\nDebuggerStreamBuf myStreamBuf ;\npublic:\nDebuggerJournal() {\ninit (&myStreamBuf ) ;\n}\nvirtual char endReport() {\n*this << std::endl << std::flush;\nreturn 0;\n}\n}5\n\nMore-elaborate journals can be built using this method. In the supplied code\nsample, we added a journal that uses a Win32 message box. This way, we can retrieve\nthe user’s answer and act accordingly.\n\nOther implementations can be used to extend the system and add more types of\njournals. For example, it would be useful to have multiple output locations for a\nunique reporting event. However, since the Switch class only contains a single Jour-\nnal reference, a new type of Journal that can handle this case needs to be designed. A\nquick way to resolve this problem is to forward the formatted data string to all other\ninstances of Journal that could be kept in a std: : vector.\n\nvirtual int sync() {\nsize_t len = pptr() - pbase();\nif(len > 0) {\nmyBuf{len] = 0;\nfor(int i = 0; i < myJournals.size(); ++i) {\n*(myJournals[i]) << myBuf;\n}\n\nsetp(myBuf, myBuf + sizeof(myBuf) - 1);",
      "page_number": 138,
      "chapter_number": 14,
      "summary": "This chapter covers segment 14 (pages 138-145). Key topics include switch, journal, and reporting. Extensions can be made without the need to change the\nlibrary code through the use of policies.",
      "keywords": [
        "Switch",
        "Journaling Services",
        "system",
        "Journaling",
        "SwitchBox",
        "myBuf",
        "Policy-Based Logging",
        "Services",
        "Static Switch",
        "logging library",
        "information",
        "trace",
        "std",
        "code",
        "Journaling Services Eric"
      ],
      "concepts": [
        "switch",
        "journal",
        "reporting",
        "virtual",
        "debugging",
        "provided",
        "provide",
        "std",
        "formatted",
        "state"
      ],
      "similar_chapters": [
        {
          "book": "Release It! Design and Deploy Production-Ready Software",
          "chapter": 15,
          "title": "Segment 15 (pages 115-122)",
          "relevance_score": 0.57,
          "method": "api"
        },
        {
          "book": "Computer Systems A Programmer’s Perspective",
          "chapter": 16,
          "title": "Segment 16 (pages 308-330)",
          "relevance_score": 0.51,
          "method": "api"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 15,
          "title": "Segment 15 (pages 289-307)",
          "relevance_score": 0.51,
          "method": "api"
        },
        {
          "book": "Software Architecture",
          "chapter": 25,
          "title": "Segment 25 (pages 231-248)",
          "relevance_score": 0.51,
          "method": "api"
        },
        {
          "book": "Designing Machine Learning Systems An Iterative Process for Production-Ready Applications",
          "chapter": 33,
          "title": "Segment 33 (pages 281-289)",
          "relevance_score": 0.5,
          "method": "api"
        }
      ]
    },
    {
      "number": 15,
      "title": "Segment 15 (pages 146-155)",
      "start_page": 146,
      "end_page": 155,
      "detection_method": "topic_boundary",
      "content": "1.16 Journaling Services 143\n\nreturn 0;\n\nBuilding Journaling Services\n\nSHERRATT RRR AAA NA ROSIE RE ONO GS SBOE R ANIONS S SOS TRINA TERRE NANA\n\nSome typical journaling services are presented here that use the system presented in\nthe previous section to control the flow of information.\n\nInformation Reports\n\nThe first service only reports data to the associated journal. It provides the very basic\nfunctionality needed to use the system.\n\n#define REPORT(Leaf, Expression)\ndo {\nSwitch * leaf = Leaf::getInstance();\n\nif (leaf->getState()) {\nJournal& journal = *leaf->getJournal();\njournal. beginReport();\njournal << Expression;\njournal.endReport();\n} \\\n} while(0)\n\nee ee ee ead\n\nNote that all services are designed as macros to enable conditional compilation\nand remove some or all reporting facilities on specific builds.\n\nTracing Information\n\nAnother useful idea is the stack trace. Knowing what portion of the program is cur-\nrently executing (without stopping it) can be valuable. This is especially true when\ndebugging optimized releases or if associated debugging information is not available.\n\nThe method presented here simply keeps track of the whole call stack at all times.\nEach method must contain some code that will update the stack as the program runs.\nIf one of the methods is missing this piece of code, it will simply not be shown. The\njournaling will report (when enabled) the Enter and Leave events. Nevertheless,\nbecause the stack must be valid even when not reporting, the housekeeping code will\nalways get executed.\n\nvoid foo() {\nTRACE (TraceSwitch); // Add the stack trace here.\n\n}\n\nThis implementation simply pushes the current function name and the associated\nSwitch on the stack. Since many compilers now support a predefined macro describ-\ning the current function name, it will be used here. To differentiate between functions\n\n144 Section 1 General Programming\n\nhaving the same name, we chose to use the function's signature. Note that a pointer to\nthe parent is kept to enable us to walk back up the stack to its top.\n\nclass StackTracer\n\n{\n\nStackTracer * myParent;\n\nSwitch * myLeat;\n\nconst char * myName;\n\npublic:\n\nStackTracer(Switch * leaf, const char * name)\nmyLeaft(leaf), myName(name) {\nmyParent = ourParent;\nreportEvent(\"Enter -- \");\nourParent = this;\n\n}\n\n~StackTracer() {\nreportEvent(\"“Leave -- \");\nourParent = myParent;\n\n}\n\nprotected:\n\nvoid reportEvent(const char * prefix) {\n\n}\n\nstatic StackTracer * ourParent;\n\nhs\n\nThe helper macro can then be easily defined with the compiler-specific definition\nof the function's signature. Note that we are using a predefined compiler macro that\nwas not available in any version prior to Microsoft Visual Studio .NET. Thus, some\ncompilers might not support this feature. Some other compilers, like Metrowerks\nCodeWarrior, support this with the GCC extension __PRETTY_FUNCTION_, which\ndoes the same thing.\n\n#define TRACE(Leaf) \\\nStackTracer \\\nstackTop(Leaf::getInstance(), _ FUNCSIG_)\n\nAt any moment, this ‘virtual’ call stack can be used to report the current position\nof the program. For example, the next service reports the call stack when an unex-\npected condition occurs. This way, the user has more-valuable information than just\nthe traditional filename and line number.\n\n1.16 Journaling Services 145\n\nInteractive Reports\n\nFinally, to give an overview of interactive reports, the common assertion macro will be\npresented. Normally, if the assertion fails, a message box is displayed to prompt the\nuser to choose between aborting the application, debugging it, or simply ignoring\nthe error. The assertion’s logic should not be associated with the Journal, since it\ncould be used with any other interactive services. Therefore, the behavior of this\nreport differs with the above trace service in handling the endReport event. It should\nonly communicate the user’s answer so that it can be dealt with appropriately. All sup-\nported values are enumerated in the Journal interface.\n\n#define ASSERT(Leaf, Condition)\ndo {\nSwitch * leaf = Leaf: :getInstance();\nif (leaf->getState() && !(Condition)) {\nchar result =\ndisplayAssert(leaf->getJournal(),\n\n#Condition,\n_ FILE_,\n__LINE__);\n\nif(result == Journal::ABORT) {\nSystem: : Terminate();\n\n}\nif(result == Journal::BREAK) {\n\nSystem: :Break();\n}\n\n}\n} while(0)\n\nCe MM MM MM MM MM MM Nr ne\n\nNote that this opens the door to something interesting. By using another Jour -\nnal, it is possible to run the application unattended. Assertions will still get caught\nand reported, but no message box will wait on the user.\n\nConclusion\n\nTo summarize, we presented a simple and extensible system built to control the flow\nof real-time information, along with some basic tools to report it. However, it should\nbe clear that the quality of that information and its adequate separation into usable\ntopics are definitively up to the programmer. Remember that time invested in pro-\nducing information reports will pay off when it’s time to debug.\n\nReferences\n\n[Reeves01] Reeves, Jack, “The (B)Leading Edge: Using IOStreams, Part I,” The\nC/C++ User’s Journal Experts Forum, available online at hetp://www.cuj.com/\nexperts/1901/reeves.htm, January 2001.\n\n[Stroustrup00] Stroustrup, Bjarne, The C++ Programming Language Special Edition,\nAddison Wesley, 2000.\n\n1.17\n\n146\n\nReal-Time Hierarchical\nProfiling\n\nGreg Hjelstrom and Byon Garrabrant,\n\nWestwood Studios\n\ngreg@westwood.com\nbyon@byon.com\n\nWr developing most games, a primary goal is to get maximum performance\nout of your code. Knowing where to spend your optimization effort is key to\nattaining this goal. We've all heard variations on the old adage: “A program spends\n90% of its time in 10% of the code.” Profiling is an invaluable tool for finding that\n10% of the code that needs to be optimized.\n\nTwo types of profiling strategies are often employed—sampling and explicit tim-\ning. A sampling profiler works by frequently sampling the position of the instruction\npointer while the program runs. This generates a huge amount of raw data that is\nthen processed to generate profiling data. Sampling profilers can often tell you exactly\nin which line of code most of the time is being spent. Many commercial profilers\nwork this way because modifications to the application code are unnecessary. Unfor-\ntunately, it isn't always practical to use sampling in real-time, due to the amount of\noverhead involved in gathering and processing the sampled data.\n\nThe other profiling method that is commonly used is to explicitly time blocks of\ncode. These measurements can then be displayed in real-time and can aid in finding\ntransient performance problems. This is important because bottlenecks in games are\noften dependent on many factors. It is useful to see how the profiling data changes as\nthe user plays the game and triggers various events. Also, these profiling samples will\ntypically be logically organized. For example, one might log how much time the code\nspends processing AI, rendering, and physics. Then, at any point in time, you can see\nwhich subsystem in the code is taking the most time. The only drawback to this type\nof profiling is that it only gives a general idea of where the code-processing time is\nbeing spent. For example, once you know the AI is running extremely slow, you typi-\ncally have to use a sampling profiler or temporarily add more timing measurements to\nfind out why the AI is running slowly.\n\nIdeally, we would like to have the best of both worlds—real-time profiling with as\nmuch detail as a sampling profiler. This gem will describe a system that, while not\n\n1.17 Real-Time Hierarchical Profiling ; 147\n\nattaining the resolution of a sampling profiler, can efficiently support thousands of\nprofiling samples that are logically and hierarchically organized. A ‘profile tree’ is con-\nstantly updated and can be browsed in real-time, and we can find out where the CPU\nis spending its time.\n\nThe Profile Tree\n\neS RE RENARD IDI BM LER BREE RIL OOS FREE IE OSLO ILE YD LTS\" IE LEST LEE LET LR EERE\n\nThe profile tree is an V-ary tree made of profile nodes. An N-ary tree is a tree where each\nnode of the tree can have any number of child nodes. The topology of this tree is deter-\nmined by the placement of profiling macros in the application’s code. Since each node\nin the tree typically has only a few children, searching and data presentation is efficient.\n\nEach profile node corresponds to a single explicit timing sample of a block of\ncode. Each node tracks the total amount of time spent within that block of code and\nthe total number of times that code has been executed. Samples, which are taken\nwithin the scope of another sample, correspond to a child node of that sample.\nWhenever a new profiling call is made, a new child node is added to or reused in the\ncurrent node.\n\nFor a real-world example, we can examine how this profiling system was used in\nCommand & Conquer Renegade. Renegade had a total of over 1,000 profile nodes(see\nColor Plate 1). However, the profiler was efficient because there were only an average\nof 2 children for any given node, and the worst-case node only had 15 children. As we\nwill show later, the cost of this algorithm is proportional to the number of children in\na node.\n\nRL HRN PRIN ATER ANE TSO NESE NAT RSIS NAN AR GL PRORAL Kaen HNO ATR OID RNAI ARS TAUNNE SRE IITA\n\nTo use this profiling system, PROFILE macros must be placed at key points in the code.\nAs will be described later, placing a PROFILE macro in the code will cause a profile\nnode to be generated. This node will be responsible for timing the scope of the corre-\nsponding code. A good strategy is to place a PROFILE macro at the top of each subsys-\ntem in the application, and refine it as needed.\n\nvoid My_Function(void)\nPROFILE (\"My_Function\")\n}\n\nIt can be helpful to break large routines into several independent profile samples.\nThis is easily accomplished by adding additional scoping brackets to the function,\neach with their own PROFILE macro. Here is an example:\n\nvoid BigFunction(void)\n\n{\n\nPROFILE(\"BigFunction Part 1\")\n\n148 Section 1 General Programming\n\noo\n\nUW\n\nFIGURE 1.17.1 his is a screenshot the real-time hierarchical profiler running inside of Command\n& Conquer Renegade. Only one node of the tree is shown, but the user can navigate the tree in real-\ntime.\n\nPROFILE(\"BigFunction Part 2\")\n\nIt can also be useful to ‘flatten’ the profile structure of a member function in a\nclass hierarchy. The following example shows how you can combine time spent in a\nparticular layer of an overridden function, even when it is called through many differ-\nent derived classes. In this example, time spent in BasePhysics::Timestep() is not\nincluded in CarPhysics: :Timestep(), and all time spent in BasePhysics: :Timestep()\nwill be combined into a single profile sample, even when called from other derived\nclasses (assuming they use this profiling strategy).\n\nvoid CarPhysics: :Timestep(void)\n\n1.17 Real-Time Hierarchical Pr\n\n149\n\n{\n{\nPROFILE(\"CarPhysics::Timestep\") ;\n}\nBasePhyics: :Timestep();\n\n}\n\nBrowsing the Profiling Data\n\nThis profiling system generates a lot of data, so the user must have a way to navigate\nit easily. An iterator is provided that can be used to navigate through the tree and dis-\nplay statistics for the children of the current node. Using this system, a user can chase\ndown a bottleneck in real-time by walking up and down the profile tree, and focus on\nareas of code that are taking a lot of time. For example, a representative profile sample\nfor the main loop of Renegade is listed in Table 1.17.1.\n\nTable 1.17.1 Profile Data for Main Loop\n\nName %Parent %Total Ms/Frame Ms/Call Calls/Frame\n0-Audio 2.01 2.00 0.35 0.35 1\n\n1-Render 51.64 51.40 8.95 8.99 1\n2-Network 1.70 1.69 0.30 0.30 1\n\n3-Think 43.19 42.99 7.49 7A9 1\n4-Pathfind 0.04 0.04 0.01 0.01 1\n\nUnlogged 1.42 1.42\n\nIn this case, the time is mostly split becween Render and Think. Navigating the\ntree is achieved by assigning a numerical index to each child of the current node. The\nuser is allowed to enter either the parent of the current node or any of its children.\nAssume the user wanted to investigate the Render child. They would get a new dis-\nplay, as shown in Table 1.17.2.\n\nTable 1.17.2 Profile Data for Render\n\nName %Parent %Total Ms/Frame Ms/Call Calls/Frame\n0-Switch_Thread 16.39 8.58 1.47 1.47 1\n1-Post_Render 0.28 0.14 0.02 0.02 1\n2-End_Render 8.04 4.21 0.72 0.72 1\n3-DialogMgr 0.09 0.01 0.01 0.01 1\n4-Render_Game 49.55 25.95 4.44 4.44 1\n5-Begin_Render 1.70 0.89 0.15 0.15 1\n6-Shadow_Gen 22.83 11.96 2.05 2.05 1\n\nUnlogged 1.12 0.09\n\n150 Section 1 General Programming\n\nSince Render_Game takes a large portion of this node’s time, the user could then\ndescend the tree to get a breakdown of that node. This process can continue as long as\nthere are children of the node you are interested in.\n\nAll of the statistics in the profiling system represent running totals and averages.\nIt can be useful to use the reset feature to throw out historical data. For example,\nwhen the frame rate drops, we often reset the profiler to get a more accurate measure-\nment of what the code is doing at that time. When the profile system is reset, the tree\nis not actually destroyed; only the timing data contained in the nodes are zeroed out.\n\nimplementation\n\nThe implementation relies on an accurate way to sample time. We used the 64-bit\ncycle counter feature of Pentium CPUs. This counter is incremented every time the\nCPU executes an instruction. By saving the state of the counter at the start of a pro-\nfiling sample and subtracting that value from the state of the counter at the end of a\nprofiling sample, you can very accurately compute the amount of time elapsed. We\nthen divide the number of instructions by the CPU clock speed to determine the\namount of time spent. Our profile nodes accumulate the amount of time in a float-\ning-point variable.\n\nCProfileSample\n\nThis is a small C++ class whose only task is to call the start_Profile() method of\nCProfileManager in its constructor and the Stop_Profile() method in its destructor.\nThis automates the task of starting and stopping a profile sample during the scope of\nthis object. To further simplify the usage, the PROFILE macro is used to automatically\ncreate a CProfileSample object and to easily remove profiling code from release builds.\n\nclass CProfileSample {\n\npublic:\nCProfileSample(const char * name)\n‘ cProfileManager: :Start_Profile(name) ;\n pprofilesample(void)\n‘ CProfileManager: :Stop_Profile();\n}3\n\n#define PROFILE(name) CProfileSample _ profile(name)\n\nCProfileManager\n\nThe profile manager is the external interface to the profiling system. It maintains the\nCurrentNode pointer into the profile tree that corresponds to the scope of the cur-\nrently executing code. It also contains methods for accessing the profile tree for dis-\n\nplay purposes.\n\n1.17 Real-Time Hierarchical Profiling 151\n\nThe Start_Profile() method is used to start a profile sample. It detects recur-\nsion by comparing the name of the requested profile with the name of the current\nnode. When the subnode that matches the given name is found, it becomes the cur-\nrent node. The overhead incurred in this search will be proportional to the number of\nimmediate children linked to the current node. Typically, this is a small number,\nrarely as large as 10. In addition, since we use static strings for all of our profile sam-\nple names, pointer compares are used rather than slower string compares when look-\ning for a particular profile sample.\n\nIn the case that a child with the given name does not exist, a new node will be cre-\nated and linked to the tree. Note that node creation will only occur on the first pass\nthrough a particular code path. In any case, the node’s Cal1() method is then called to\nbegin timing.\n\nvoid CProfileManager: :Start_Profile(const char * name)\n\n{\nif (name != CurrentNode->Get_Name()) {\nCurrentNode=CurrentNode->Get_Sub_Node(name) ;\n}\nCurrentNode->Call();\n}\n\nThe Stop_Profile() method is used to end a profile sample. The first task is to\ncall the Return() method on the current node to complete and record the timing.\nSince the profile manager has maintained the current node being sampled, no search-\ning overhead is incurred in this operation. Assuming we are not in a recursive func-\ntion, the parent node becomes the current node.\n\nvoid CProfileManager::Stop Profile( void )\n\n{\n// go to parent unless recursed\nif (CurrentNode->Return()) {\nCurrentNode = CurrentNode->Get_Parent();\n}\n}\n\nThe remaining methods in the profile manager are either accessors or perform\nsimple administrative functions. For example, the application calls the Increment_\nFrame_Counter() method once per frame in order to support calculation of the num-\nber of calls per frame for any profile sample. The Get_Iterator() and Release_Iter-\nator() methods provide and destroy an iterator that is used to access the profile tree.\n\nCProfileNode\n\nThe CProfileNode is a C++ class that is private to the profiling system; it stores the\ntotal time spent in a block of code and the number of calls of that block of code.\nWhen the CPU is in the scope of a node, the node also stores the starting time.\n\n152 Section 1 General Programming\nTo start a profiling sample, the profile manager calls the Cal1()method on the\nnode. This method simply increments the call counter and, if we are not recursing,\nrecords the starting time.\nvoid CProfileNode::Call( void )\n{\nTotalCalls++;\nif (RecursionCounter++ == 0) {\nProfile_Get_Ticks(&StartTime) ;\n}\n}\n\nAt the end of a profiling sample, the Return() method is called. After checking if\nwe are not recursing, the elapsed time is computed and added to the TotalTime vari-\nable. This function also returns whether or not the code is recursing, so the profile\nmanager knows if the node is completed, in which case it would return to the parent\nnode.\n\nbool CProfileNode::Return( void )\n{\nif (--RecursionCounter== 0 && TotalCalls !=0 ) {\n__inte4 time;\nProfile_Get_Ticks (&time) ;\ntime-=StartTime;\nTotalTime += (float)time / Tick_Rate();\n}\nreturn ( RecursionCounter == 0 );\n}\nCProfilelterator\nThis object provides an easy way to browse the profile tree. It contains methods for\nnavigating the tree and displaying the contents of a particular node. Typically, a node\nalong with its immediate children are displayed to the user. For each child, several sta-\ntistics are available: total time spent, total number of calls, calls per frame, and time\nper frame.\nConclusion\n\n<A SSRN 850 AOE RNR SRO SEE RMHRESS MoS 80 SRA IE ARRAN AS ae\n\nWith the ability to hierarchically profile code in real-time and sample thousands of\nblocks of code efficiently, we’ve found this to be a useful tool for code optimization. It\nis our hope that readers will find this system useful in improving their own code. You\noNTHECD will find an implementation of these classes on the CD-ROM.\n\nReferences\n\nRRR eer NR ARB 2 a sR eS EIST ee\n\n[GPGO00] Rabin, Steve, Game Programming Gems, Charles River Media, Inc., 2000.",
      "page_number": 146,
      "chapter_number": 15,
      "summary": "It provides the very basic\nfunctionality needed to use the system Key topics include profiling, profile, and times. Information Reports\n\nThe first service only reports data to the associated journal.",
      "keywords": [
        "SOS TRINA TERRE",
        "TRINA TERRE NANA",
        "profile",
        "SHERRATT RRR AAA",
        "AAA NA ROSIE",
        "ROSIE RE ONO",
        "ONO GS SBOE",
        "SBOE R ANIONS",
        "ANIONS S SOS",
        "SOS TRINA",
        "TRINA TERRE",
        "TERRE NANA",
        "node",
        "time",
        "Profile Tree"
      ],
      "concepts": [
        "profiling",
        "profile",
        "times",
        "timing",
        "void",
        "nodes",
        "journal",
        "leaf",
        "method",
        "code"
      ],
      "similar_chapters": [
        {
          "book": "Release It! Design and Deploy Production-Ready Software",
          "chapter": 12,
          "title": "Segment 12 (pages 91-98)",
          "relevance_score": 0.61,
          "method": "api"
        },
        {
          "book": "Release It! Design and Deploy Production-Ready Software",
          "chapter": 26,
          "title": "Segment 26 (pages 208-215)",
          "relevance_score": 0.57,
          "method": "api"
        },
        {
          "book": "Release It! Design and Deploy Production-Ready Software",
          "chapter": 3,
          "title": "Segment 3 (pages 19-26)",
          "relevance_score": 0.53,
          "method": "api"
        },
        {
          "book": "Designing Machine Learning Systems An Iterative Process for Production-Ready Applications",
          "chapter": 33,
          "title": "Segment 33 (pages 281-289)",
          "relevance_score": 0.52,
          "method": "api"
        },
        {
          "book": "Designing Data-Intensive Applications",
          "chapter": 12,
          "title": "Segment 12 (pages 109-118)",
          "relevance_score": 0.51,
          "method": "api"
        }
      ]
    },
    {
      "number": 16,
      "title": "Segment 16 (pages 156-165)",
      "start_page": 156,
      "end_page": 165,
      "detection_method": "topic_boundary",
      "content": "2.1\n\nON THE CD\n\nFast Base-2 Functions for\nLogarithms and Random\nNumber Generation\n\nJames McNeill\njames_mcneill@ameritech.net\n\nn this gem, three utility functions are presented for computing values associated\nwith the base-2 logarithms of integers. They are simple, efficient, and correct for\nany 32-bit input value, in contrast to their floating-point alternatives.\n\nes occasionally during the game-\ndevelopment process. The integral logarithm is the real logarithm, rounded up or\ndown to the nearest integer as required. This logarithm is useful when rounding tex-\nture image dimensions up to the nearest power of two, padding data to the nearest\npower of two before using the Fast Fourier Transform, or determining the number of\nlevels a quadtree needs in order to subdivide a grid.\n\nAlthough the logarithm can be calculated using an expression such as\nint(floor(log(n)/1og(2))) or int(ceil(log(n)/1og(2))), the floating-point divi-\nsion can underflow and give incorrect results. A simple test program of the above\nexpressions using 32-bit floating-point arithmetic on an Intel processor showed the\nproblem occurring as low as n = 65536. There are also some environments that are\ndevoid of floating-point functionality, but a mechanism for computing the integral\nlogarithm is still desired.\n\nTo avoid these issues, we use the two integer-only routines described in this gem.\nThey provide correct results over the entire 32-bit input range and are also more effi-\ncient than the corresponding floating-point methods. The expression log2le(n) ,\nwhich stands for “log, less-than-or-equal-to n”, finds the largest non-negative integer\nx such that 2* < n. The expression log2ge(n), which stands for “log, greater-than-or-\nequal-to 7,” finds the smallest non-negative integer x such that 2* 2 n. The code for\nboth of these functions can be found on the CD-ROM.\n\n157\n\n158\n\nSection 2 Mathematics\n\nBit Masks and Random Number Generation\n\nern NER  enoom RR RIES : SSSR\n\nYEE BESS SEAN AROSE NILES OSI S ECORI BBB ANRONM\n\nThe third utility function provided in this gem, bitmask(n), computes a mask in\nwhich all bits used by numbers from one up to, and including, 7 are set to one.\n\nOne use for bitmask() is in generating uniformly-distributed random integers\nthat fall within a specified range. As an example, suppose a random number generator\nrand()generates uniformly-distributed random integers in the range 0 to 32767, but\nwe need a sequence of random numbers in the range [0, 2]. A common approach is to\nuse the modulus operator to map the source range to the target range:\n\nint randomNum = rand() % 3;\n\nAs described in [Booth97], there are a couple of problems with this method. The\nmodulus operator is typically fairly slow, and the results are slightly biased away from\na uniform distribution. Because the target range [0, 2] does not evenly partition the\nsource range of [0, 32767], values of randomNum are not evenly distributed. Zero and 1\neach have 10,923 values of rand() that map to them, while 2 has only 10,922 values\nthat map to it. This is admittedly a small difference, but the disparity can be larger.\nFor instance, if we used this technique to generate numbers in the range [0, 32766},\nzero would be ewice as likely as any other number.\n\nOne way to get evenly distributed results is to generate random numbers and\nthrow them away until we get one within our desired range:\n\ndo { randomNum = rand() } while ( randomNum > 2 );\n\nNow, with our example, this would take a very long time, since values of rand()\nare far more likely to be out of the desired range than in it. However, the above pro-\ncedure can be modified to be quite fast. First, use the modulus operator with an inte-\ngral divisor in the range of rand() to get to an intermediate range of random numbers\nas close as possible to the target range. Then, reject any values from the intermediate\nrange that fall outside the target range:\n\ndo { randomNum = rand() % 4 } while ( randomNum > 2 );\n\nSince most random number generators have a range that is a power of two, we\ncan use bit masking instead of the modulus operator to speed things up:\n\ndo { randomNum = rand() & 3 } while ( randomNum > 2 );\n\nThis is where our function bitmask() comes in. It computes the necessary bit\nmask for use in the previous algorithm, so we can write a general function for getting\nrandom numbers over an arbitrary range:\n\nunsigned random( unsigned range )\n{\nif ( range < 2 )\nreturn 0;\n\n2. 1 Fast Base-2 Functions for Logarithms anc and Random Number Generation — 159\n\nunsigned mask = bitmask(range-1);\n\nunsigned n;\n\ndo { n = rand() & mask; } while (n >= range);\nreturn n;\n\n}\n\nAssuming the values of rand() are evenly distributed, the expected number of\nloop iterations is less than two and approaches one as the intermediate range’s size\napproaches that of the target range. This is substantially faster and more reliable than\nthe alternatives.\n\nHow the Functions Work\n\nRAREST SED GAC IE\n\nThe functions are specialized for 32-bit i integers. This limits the number of distinct\nreturn values to 32 or 33, depending on the function. The function log21e() returns\na value ranging from 0 to 31, log2ge() returns a value ranging from 0 to 32, and\nbitmask() returns a bit mask ranging from 0 to OxFFFFFFFE\n\nOne possible algorithm would be to simply store the 32 or 33 return values in an\narray and do a binary search through it to find the correct result. The functions here\nfollow this approach, but do so without the stored array, since the array entries are eas-\nily computed as needed. Only a few registers are used as a result. Finally, the loops\nhave been unrolled for speed.\n\nThe implementations of each function can be found on the CD-ROM.\n\nON THE CD\n\nei re a te\n\n~ [Booth97) Booth, Rick, Inner Loops: A Sourcebook For Fast 32-Bit Software Devel-\nopment, Addison-Wesley Developers Press, 1997: pp. 223-224.\n\nAOI NORE Re\n\n2.2\n\nUsing Vector Fractions for\nExact Geometry\n\nThomas Young, PathEngine\nthomas@pathengine.com\n\ni tends to happen near the end of the project. A particularly ingenious tester figures\nout that there is a certain corner on a certain level where path-finding fails, leaving\nenemies stuck. Someone else notices that jumping into another corner lets you wan-\nder off the edge of the world. After days of nerve-racking debugging, you figure out\nthe source of the problem—error due to approximation.\n\nIn game programming, fewer problems are more subtle or insidious than round-\noff errors. Perhaps you try to add code to the system to catch these errors. You check\nfor tolerances and write a lot of special-case code. Unfortunately, this merely converts\nthe precision problem into a set of other nasty problems. What error tolerances are\nacceptable? How can we guarantee that the code will work? Lastly, who will ever be\nable to figure out our code when the sequel comes out?\n\nThis gem considers examples in constructive solid geometry and in path-finding\nwhere approximation at points of intersections can cause the algorithms to fail. Tech-\nniques are offered for representing these intersection points without approximation.\nThis enables us to eliminate errors without adding complexity to our algorithms.\n\nThe Problem\n\nSvea\n\n160\n\nSAAN NS RPP PRE EAP RRO LEE\n\nWhen a polygon is rendered to screen pixels, the user won't notice if the least signifi-\ncant bit of the green value is incorrect. Even if screen coordinates are off by a pixel or\ntwo, it’s probably okay as long as there are no visual artifacts, such as cracks between\npolygons.\n\nOn the other hand, there are some key algorithms in game programming that are\nsensitive to even small round-off errors in mathematical calculations. In particular, a\nproblem arises when an algorithm needs to reuse the results of calculations with\nimplicit round-off errors. With a complex algorithm, we often depend on constraints\nholding true for our data structures as the algorithm proceeds. Perhaps we depend on\nthis to have the algorithm terminate.\n\nWhen we try to represent fractional values as floating-point or fixed-point num-\nbers, we often introduce round-off errors that can affect the results of our algorithms.\n\n2.2 Using Vector Fractions for Exact Geometry 161\n\nWe can’t represent 1/3 exactly using a fixed-point or floating-point number of finite\nprecision. Examples of this kind of problem arise in constructive solid geometry\n\n(CSG) and points-of-visibility path-finding.\n\nConstructive Solid Geometry\n\nConsider the problem of Boolean operations between meshes in two dimensions. In\norder to process the mesh efficiently, we will want to specify certain validation condi-\ntions for that mesh. For example, we can require all faces to be convex. We then\ndepend on this validation condition for the algorithm to work.\n\nAs part of the Boolean process, we might detect an overlap between two faces and\nresolve this by introducing extra vertices where edges intersect (see Figure 2.2.1).\n\nFIGURE 2.2.1 Boolean subtraction in two dimensions.\n\nApproximation at these intersections can lead to nonconvex geometry (see Figure\n2.2.2).\n\nFIGURE 2.2.2 Approximation results in a nonconvex face.\n\n162\n\nSection 2 Mathematics\n\nThe same problem exists in three-dimensional constructive solid geometry for\nedges created at the intersection of faces and for vertices created at the intersection of\nan edge with a face.\n\nPath-finding\n\n[Young01] demonstrates how silhouette regions can be used to optimize points-of-\nvisibility path-finding. Each point of visibility corresponds to a corner in the environ-\nment. A point is considered for connection if it appears as a silhouette from the\nperspective of the source point.\n\nFigure 2.2.3 shows how approximation at an intersection can cause path-finding\nto fail. The boundary of a silhouette region intersects with another line, which might\nbe an expanded external edge, another region boundary, or a portal. Approximation at\nthe intersection means that our source point is incorrectly determined to be outside of\nthe silhouette region, so a connection to the associated point of visibility is not gener-\nated. The line from the source point to the target point just clips the edge of the\nobstacle and is, therefore, blocked by collision. The result is that the path-finder fails\nto generate a path to the target area.\n\n. —— Source point\nPoint of visibifity\n\nTarget point\n\nSilhouette region\n\nTarget area\n\nFIGURE 2.2.3 Path-finding fails because the source point is incorrectly determined to be\noutside a silhouette region.\n\nOne solution to this problem is to treat the lines bounding our silhouette regions\nas infinite lines. To test if the source point is in a given region, we test inside of each\nbounding line. However, it is a lot quicker to keep track of which region a point is in\nby detecting which edges are traversed as a point is moved. If our path-finder has to\ndeal with overlapping geometry, then this traversal also serves to delineate between\ndifferent levels of geometry.\n\nIn order to perform our traversal, we need to be able to determine which side of\nour traversal an intersection is on. In Figure 2.2.4, the traversal ends inside the sil-\nhouette region because the intersection is to the right of the line of traversal.\n\n2.2 Using Vector Fractions for Exact Geometry 163\n\nTraversal\n\nFIGURE 2.2.4 Traversal into a silhouette region.\n\nWhy Not Just Use Floats?\n\nFloating-point representation only gives us greater precision near zero. At the edges of\nthe number range, we actually get less precision than with an integer representation\nbecause of the bits required to store the exponent. Floating-point representation\nimplies a grid that looks something like Figure 2.2.5, but with many more gradua-\ntions. Thus, the problem still occurs, since results are still approximated to a grid.\n\nFIGURE 2.2.5 A floating-point grid.\n\n164 —\n\nEven adding arbitrary precision doesn’t solve the problem. For example, we can-\nnot represent 1/3 exactly no matter how many decimal places we use. Some errors will\noccur with a similar frequency no matter how small our grid is. Unless error probabil-\nity becomes infinitely small, reducing the frequency of that error just serves to make\nlife harder for our testers.\n\nimation. We propose vector fractions as one way of achieving this.\n\nIntersection of 2D Lines\n\nConsider two infinite lines in two dimensions, represented with start points and axes\nS, A, and S, A). As long as the lines are not parallel, they will intersect, allowing us to\nrepresent the intersection I as a fractional distance along the axis of one of the lines\n(see Figure 2.2.6 and Equation 2.2.1).\n\nFIGURE 2.2.6 Representing the point of intersection as a vector fraction.\n\nnA\nI=S,+—+ 2.2.1\nit (2.2.1)\nThe numerator and denominator elements n and d are determined by taking dot\nproducts with N,, a vector normal to the axis of the second line (Equation 2.2.2 and\nEquation 2.2.3). These values will be proportional to the lengths of the arrows shown\nin Figure 2.2.6.\n\n2.2 Using Vector Fractions for Exact Geometry 165\n\nn=(S, -S,)-N, (2.2.2)\n\n1=A,-N, (2.2.3)\n\nintersection of a 3D Line with a Plane\n\nThe method extends easily to the intersection of a three-dimensional line with a\nplane. In this case, we can take dot products with the plane normal to obtain a frac-\ntional distance along the three-dimensional line for the intersection.\n\nWorking with Vector Fractions _\n\nWe can apply the same kinds of techniques for working with vector fractions that we\nuse with normal fractions. Most importantly, when we work with vector fractions,\ncross-multiplication enables us to perform certain operations without explicit divi-\nsion. By eliminating division, we can perform the required geometric operations\nwithout approximation. Operations involving addition, subtraction, and multiplica-\ntion of integer values will yield integer values.\n\nTesting Side of Line for an Intersection\n\n‘To determine if a point P is on the right of an infinite line defined by start S and axis\nA, we can test for the inequality in Equation 2.2.4. This equation assumes that the\ndirection of increasing x is to the right of the direction of increasing y:\n\nJ\n\n(2.2.4)\n\nx\n\nTo apply this to a point represented as a vector fraction, we simply substitute a\nfractional representation for P (Equation 2.2.5) and then multiply everything by 4, to\navoid division, giving us the inequality in Equation 2.2.6. This gives us one way to\nimplement the traversal we require through path-finding regions.\n\np=B+L (2.2.5)\nd\nP\n\n(B,4, +C, -8,4,)A, < (Bd, + C, -S,d,)A, \" (2.2.6)\n\nGeneralizing to Other Operations\n\nIt is easy to extend this approach to more-general operations on vector fractions.\nTo perform comparisons between P and a second point Q (also represented as a vec-\ntor fraction, as shown in Equation 2.2.7), we transform the points to a common\ndenominator by multiplying both points by 4,d,. Addition of P and Q yields a vector\nfraction result, as shown in Equation 2.2.8.\n\n166 Section 2 Mathematics\n\nE\nQ =D+— 2.2.\n; (2.2.7)\n\nq\nad Ct+daFE\nP+Q =B+D+—4+_*-\n44,\n\nAnother Way To Traverse—Using Order\nof Intersection\n\nAnother way to solve our traversal problem is by comparing the distances for two\nintersections along a common axis. Figure 2.2.7 depicts the traversal problem. We\nneed to determine the side of our traversal line (S, A3) for an intersection of region\nboundaries (S, A, and S, A,). If we know that the traversal line crosses the boundary\nline S, A, from right to left, then we can compare fractional distances for intersections\nalong the axis A, The inequality in Equation 2.2.9 is true when the boundary vertex\nis to the right of traversal.\n\na\n\nd’\n\nFIGURE 2.2.7 Determining order of intersection.\n\nnd’ >n'd (2.2.9)",
      "page_number": 156,
      "chapter_number": 16,
      "summary": "This chapter covers segment 16 (pages 156-165). Key topics include points, figures, and range. A simple test program of the above\nexpressions using 32-bit floating-point arithmetic on an Intel processor showed the\nproblem occurring as low as n = 65536.",
      "keywords": [
        "Vector Fractions",
        "range",
        "intersection",
        "point",
        "Random Number Generation",
        "target range",
        "Random Number",
        "Vector",
        "Random",
        "line",
        "source point",
        "Number",
        "problem",
        "Equation",
        "traversal"
      ],
      "concepts": [
        "points",
        "figures",
        "range",
        "ranging",
        "fractions",
        "fractional",
        "fraction",
        "problem",
        "line",
        "algorithm"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 7",
          "chapter": 21,
          "title": "Segment 21 (pages 194-209)",
          "relevance_score": 0.54,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 2",
          "chapter": 20,
          "title": "Segment 20 (pages 182-197)",
          "relevance_score": 0.5,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 2",
          "chapter": 38,
          "title": "Segment 38 (pages 377-385)",
          "relevance_score": 0.5,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 7",
          "chapter": 17,
          "title": "Segment 17 (pages 154-161)",
          "relevance_score": 0.49,
          "method": "api"
        },
        {
          "book": "Computer Systems A Programmer’s Perspective",
          "chapter": 9,
          "title": "Segment 9 (pages 158-179)",
          "relevance_score": 0.48,
          "method": "api"
        }
      ]
    },
    {
      "number": 17,
      "title": "Segment 17 (pages 166-173)",
      "start_page": 166,
      "end_page": 173,
      "detection_method": "topic_boundary",
      "content": "2.2 Using Vector Fractions for Exact Geometry 167\n\nBy using integer coordinates and eliminating division, we can perform geometric\noperations without approximation and without requiring any extra precision. How-\never, we have to think carefully about number ranges to avoid the possibility of over-\nflow. The ranges that must be supported will depend on the coordinate range allowed\nfor our geometry, together with the exact operations performed on this geometry.\n\nDeriving Ranges\nLet us assume that the coordinates of all points in our geometry are in the range [0, 7].\nLet us also assume that axis vectors are always formed by subtracting a start point\nfrom an end point.\n\nThe range of vectors formed by subtraction of points will be from [-r, 7]. Both\nthe numerator and denominator in Equation 2.2.1 were determined by dot products\nof these vectors and therefore will have a range [—2r?, 2r?] for the two-dimensional\ncase. For the three-dimensional case, the range is [-3r?, 3r7] for dot products of\nthree-dimensional vectors. Extending the two-dimensional analysis to Equation 2.2.6\ngives us a range [—6r', 6r'] for each side of the inequality. For Equation 2.2.9, we get\n[-874, 874].\n\nFitting the Ranges into Integer Data Types\n\nSay we allow 128 bits to represent —874 to 874. This gives us Equation 2.2.10 for r.\nSolving and rounding to integer coordinates yields a value for r.\n\n8rt = 2'77 -] (2.2.10)\n\nr= DI] (2.2.11)\n\nPoints and vectors can be stored in 32 bits, the results of dot products in 64 bits,\nand products of dot products in 128 bits. For different constraints or if different com-\nputations are required, a different set of ranges and, therefore, a different set of data\ntypes might need to be chosen.\n\nManaging Range Constraints\n\nDefining different data types for different stages of computation can help with man-\naging the different ranges. For example, points and vectors could be implemented as\ndifferent types, as well as dot products and multiplied dot products. With this method,\nwe can use the compiler to check that the correct types are used for a computation.\n\nIt is a good idea to include range checking in the debug build. The impact on per-\nformance can be limited by only checking ranges when data types are constructed\nfrom other data types that do not have a defined range. We would then make sure to\navoid this kind of construction as often as possible.\n\nAt compile time, it might not be possible to know what ranges will be required\nfor complex operations. In this case, or simply as an alternative to working out ranges\n\n168 Section 2 Mathematics\n\nseamanrctuscnttn atten SNE MARRIAGE eA SAE ASE OSE 8 an NRE SE IY HEIR AN POE OR AEA ETS\n\nin advance, it is possible to use an integer class that dynamically allocates storage as\nrequired to represent arbitrarily sized integers. There are a number of packages avail-\nable that can do this. See, for example, [GMP02] and [Haible02].\n\nImplementation Details\n\nSt CA BSS RE BIRD IRS ERO OS ETE ELE SIERO CELLET BOLE NEL ELE\n\nWorking with Big Integers\n\nFor platforms with a register size of 64 bits, working with big integers need not be a\nproblem. For these platforms, multiplication of two 64-bit values will be performed\nin the silicon and yield a 128-bit result across two registers. Addition, subtraction,\nand comparison of 128-bit register pairs is also not a problem.\n\nFor platforms with a 32-bit register size, multiplication of 64-bit integers is a lit-\ntle more expensive; but if done correctly in assembly, it might not be too costly. Be\ncareful with the standard 64-bit extensions provided by your compiler, as the code\ngenerated by these can be slower than you would expect. If multiplication of 64-bit\nintegers is too costly, then an alternative is to reduce the ranges so that only 32-bit\nmultiplication is required.\n\nWhich Kind of Traversal Should We Use?\n\nWe have a choice between Equation 2.2.6 and Equation 2.2.9 for implementing our\ntraversal. Let’s consider these equations in terms of the operations required for imple-\nmenting them.\n\nFor Equation 2.2.6, we can precalculate Bd, and store the result together with\nour fractional representation. Now, testing the inequality only requires four multi-\nplies. However, our intermediate results are obtained by multiplication of a dot prod-\nuct and a point coordinate. So given r as derived in Equation 2.2.11, two of these\nmultiplies must be performed with 128-bit sources. Ideally, we need to avoid multi-\nplying numbers this large because of the resulting performance hit.\n\nOne solution is to reduce the range permitted so that the two final multiplica-\ntions for Equation 2.2.6 can be performed with 64-bit sources. This is the fastest\noption. Alternatively, we can use Equation 2.2.9 with six multiplies that all can be\nperformed with a 64-bit source.\n\nOptimizations\n\nThe ranges derived above are theoretical limits that will rarely be reached in practice.\nIf you are a gambler, you can use fewer bits than are theoretically required for inter-\nmediate values, and perhaps overflow will never occur. Another alternative is to check\nfor overflow and use a separate code path when the overflow occurs. Branch predic-\ntion on the target processor can help improve code performance in this situation. The\nvast majority of the time there will be no overflow, so we need to set up our code so\nthat the branch is predicted correctly for this case.\n\n2.2 Using Vector Fractions for Exact Geometry 169\n\nVector fractions based on a dynamic integer class can result in some very large\nnumbers and a very slow program. In this case, it might be worthwhile to reduce the\nsize of the numbers involved. We can do this by finding the greatest common denom-\ninator of the numerator and denominator of the fraction. Then, we divide both\nnumerator and denominator by this value.\n\nA simpler optimization is to detect when an intersection falls exactly on the coor-\ndinate grid and proceed as if it were a normal point. This is only worthwhile if the\nsavings offset the cost of the test.\n\nConclusion\n\nRIROROROBN\n\nERRERURERIE RR eH RTI\n\nThe mathematical basis for vector fractions is not complicated, but they provide an\nelegant solution for dealing with points at intersections without introducing the error\nof approximation. The elimination of artifacts from approximation removes a major\nheadache when implementing geometric algorithms.\n\nIt’s important to avoid overflow when using vector fractions. The compiler can\nhelp us with this if we use different types for different stages of computation. If we\nknow what geometric queries we need, we can abstract the notion of a vector fraction\nas either a class or as a set of functions.\n\nThe cost of the change can be as little as a few extra multiplies and some extra bits\nto manipulate. Adding these extra calculations means that you'll no longer need\nspecial-case checks for the results of an approximation.\n\nReferences\n\nsree NANRRRTERR RRR ARRRRRARORET\n\n[GMP02] GMP, “GMP,” available oneline at http://www.swox.com/gmp/, January\n2002.\n\n[Haible02] Haible, Bruno, “CLN - Class Library for Numbers,” available online at\nhetp://www.ginac.de/CLN/, January 2002.\n\n[Young01] Young, Thomas, “Optimizing Points-of-Visibility Pathfinding,” Game\nProgramming Gems 2, Charles River Media, Inc., 2001.\n\nHR en RR aE LE RN RR ORR ROR?\n\n2.3\n\n170\n\nuring Error\n\nMore Approximations to\nTrigonometric Functions\n\nRobin Green,\nSony Computer Entertainment America\nrobin_green@playstation.sony.com\n\nhe art and science of writing mathematical libraries has been consistent over the\n\npast 10 years. Many computer science reference books that were written in\nthe 1970s and 1980s are still in common use, and, as mathematics is the universal\ndenominator, these books are usually considered as the last word on the subject. In\nthe meantime, hardware has evolved, instruction pipelines have grown in length,\nmemory accesses are slower than ever, multiplies and square-root units are cheaper\nthan ever before, and more specialized hardware is using single-precision floats. It is\ntime to go back to basics and review implementations of the mathematical functions\nthat we rely on every day. With a bit of training and insight, we can optimize them for\nour specific game-related purposes, sometimes even outperforming general-purpose\nhardware implementations.\n\nBefore we look at implementing functions, we need a standard set of tools for mea-\nsuring how good our implementation is. The obvious way to measure error is to sub-\ntract our approximation from a high-accuracy version of the same function (usually\nimplemented as a slow and cumbersome, infinite series calculation). This is called the\nabsolute error metric:\n\nerror», = Fecal - Spree (2.3.1)\n\nThis is a good measure of accuracy, but it tells us nothing about the importance of\nany error. An error of 3 is acceptable if the function should return 38,000, but an\nerror of 3 would be catastrophic if the function should return 0.008. We will also\nneed to graph the relative error.\n\nF coprox\n\nerror, =1-—*= when fia * 9 (2.3.2)\n\nactual\n\n2.3 More Approximations to Trigonometric Functions 171\n\nWhen reading relative error graphs, an error of zero means there is no error; the\napproximation is exact. With functions like sin() and cos(), where the range is\n[-1.0, 1.0]. the relative error is not that interesting. But functions like tan() have a\nwider range, and relative error will be an important metric of success.\n\nSine and Cosine\n\nFor most of the examples, implementations\nconsidered, but many of the polynomial techniques, with a little tweaking, are applic-\nable to other functions, such as exponent, logarithm, and arctangent.\n\nResonant Filter\n\nWhen someone asks you what is the fastest way to calculate the sine and cosine of an\nangle, tell them you can do it in two instructions. The method, called a resonant filter,\nrelies on having previous results of an angle calculation and assumes that you are tak-\ning regular steps through the series (see Figure 2.3.1).\n\nint N= 64;\nfloat PI = 3.14159265;\n\nfloat a = 2.0f*sin(PI*N);\nfloat c = 1.0f;\nfloat s = 0.0f;\n\nfor(i=0; i<N; ++i) {\nOutput_sine =\noutput_cosine =\nc =c — s*a;\nSs =s + C*a;\n\nS;\nCc;\n\nFIGURE 2.3.1 Resonant filter sine and cosine—eight iterations over 37/2.\n\n172\n\nSection 2 Mathematics\n\nNote that the value of ¢, used to calculate s, is the newly updated version from the\nprevious line. This formula is also readily converted into a fixed-point version, where\nthe multiplication by a can be modeled as a shift (e.g., a multiply by 1/8 converts to a\nshift right by three places).\n\nIf you plan to use this technique to fill look-up tables for later use, you must pay\nclose attention to a (the step size) and to the initial values of c and s. The technique\nrelies on the previous value feeding back into the system, so the initial values of s and\nc affect the final amplitude of the waves (e.g., starting with s = 0.5 and c = 0.5 gives a\npeak value of 0.7). As fast as this technique is for generating sine wave-like signals,\nyou cannot rely on samples at fractions of a cycle returning accurate values. For exam-\nple, say we were looking to take seven steps around a quarter of a circle:\n\nN\na\n\n73\n0.5*sin(PI*N) ;\n\nThe values for iterations seven and eight (counting from zero) are listed in Table 2.3.1.\n\nTable 2.3.1 Testing the Accuracy of the Resonant Filter\n\nIteration Sine Cosine\n7 1.004717676 0.158172209\n8 0.9917460469 -0.0597931103\n27 1.000000000 -0.000000002\n\nThe end points of this function miss the correct values of 1.0 and 0.0 by quite\nlarge amounts (see Table 2.3.1 and Figure 2.3.2). If, however, we extend the table to\ngenerate the whole cycle using 27 samples, we find that the final values for s and ¢ are\ncorrect to nine decimal places. Adding more iterations will reduce this error, but won't\nmake it disappear. Clearly, this approximation is useful for generating long sequences\nof sine-like waves, especially over entire cycles; but it is not well suited to accurate,\nsmall-angle work.\n\nGoertzels Algorithm\n\nA more accurate approach to the same problem is Goertzels algorithm, which uses and\nupdates the two previous values (i.e., it’s a second order filter). With it, we can calculate\na series of sine and cosine values in the series x, = sin(a + *b) for integer values of n:\n\nfloat cb = 2 * cos(b);\nfloat s2 = sin(a + b);\nfloat s1 = sin({a + 2*b);\nfloat c2 = cos(a + b);\nfloat c1 = cos({a + 2*b);\n\n2,3 More Approximations to Trigonometric Functions 173\n\n°\n©\n\n9\nfon)\n\n°\nip\n\n2\nho\n\n0\n\n1 2 3 4 5 6 7\n\nFIGURE 2.3.2 Resonant filter quarter-circle test, seven iterations over 1/2.\n\nfloat s,c;\n\nfor(i=0; i<N; ++i) {\ns =cb * si — s2;\nc = cb * cl — C2;\n\ns2 = $1;\nc2 = cl;\n$1 = §;\ncl =c;\noutput_sine = §$;\noutput_cosine = c;\n\n}\n\nThe technique is only slightly more expensive to run than the previous method,\nbut it has greater setup costs. However, if the setup can be done at compile time, the\nalgorithm is still very efficient (see Figure 2.3.3).\n\nThere are some pitfalls associated with this algorithm, as it is a second-order filter.\nBecause the values of s and c are constructed from the two previous samples, the algo-\nrithm actually outputs a result three iterations later than you might expect. To com-\npensate for this, we need to initialize the sequence carefully, subtracting three steps\nfrom the initial value of a:\n\n// step = N steps over 2*PI radians\nfloat b = 2.0f*PI/N;\n\n// minus three steps from origin\nfloat a = 0.0f -— 3.0f * b;\n\n174\n\nSection 2 Mathematics\n\nFIGURE 2.3.3 Goertzels algorithm: sine and cosine, eight iterations over 3m/2.\n\nAdding in these alterations and putting Goertzels to the quarter-circle test, we find that it\npasses the test well, producing more-accurate results than the resonant filter for fractions of\ncomplete cycles (see Figure 2.3.4).\n\no\nih\n\n1 2 3 4 5 6 7\n\nFIGURE 2.3.4 Goertzels quarter-circle test, seven iterations over 1/2.",
      "page_number": 166,
      "chapter_number": 17,
      "summary": "This chapter covers segment 17 (pages 166-173). Key topics include range, value, and bits. Fitting the Ranges into Integer Data Types\n\nSay we allow 128 bits to represent —874 to 874.",
      "keywords": [
        "range",
        "Vector Fractions",
        "error",
        "Equation",
        "dot products",
        "Resonant Filter",
        "Data Types",
        "float",
        "functions",
        "Vector",
        "Types",
        "Sine",
        "approximation",
        "Geometry",
        "Cosine"
      ],
      "concepts": [
        "range",
        "value",
        "bits",
        "error",
        "points",
        "integer",
        "different",
        "mathematics",
        "mathematical",
        "implemented"
      ],
      "similar_chapters": [
        {
          "book": "Game_Engine_Architecture",
          "chapter": 7,
          "title": "Segment 7 (pages 121-141)",
          "relevance_score": 0.69,
          "method": "api"
        },
        {
          "book": "Computer Systems A Programmer’s Perspective",
          "chapter": 9,
          "title": "Segment 9 (pages 158-179)",
          "relevance_score": 0.63,
          "method": "api"
        },
        {
          "book": "Computer Systems A Programmer’s Perspective",
          "chapter": 4,
          "title": "Segment 4 (pages 60-78)",
          "relevance_score": 0.62,
          "method": "api"
        },
        {
          "book": "Computer Systems A Programmer’s Perspective",
          "chapter": 8,
          "title": "Segment 8 (pages 140-157)",
          "relevance_score": 0.61,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 7",
          "chapter": 21,
          "title": "Segment 21 (pages 194-209)",
          "relevance_score": 0.6,
          "method": "api"
        }
      ]
    },
    {
      "number": 18,
      "title": "Segment 18 (pages 174-181)",
      "start_page": 174,
      "end_page": 181,
      "detection_method": "topic_boundary",
      "content": "2.3 More Approximations to Trigonometric Functions a 175\n\nTable-Based Solutions\n\nAs clock speeds rise and memory-access latencies become longer and longer, sine and\ncosine tables fall out of favor and are no longer the fastest method in all situations.\nNew architectures that provide vector units with closely coupled, fast RAM can still\ngive single-cycle access time for small tables, so the technique must not be discounted\nand will be with us for some time to come.\n\nThe idea is to precalculate a table of samples from a function at regular intervals\nand use the input value to the function to hash into the table, look up the two closest\nvalues and linearly interpolate between them (see Figure 2.3.5). In effect, we are trad-\ning off storage space against speed.\n\n0.5\n\nat\n\nFIGURE 2.3.5 Zable-based sine(16 samples) with and without linear interpolation.\n\nIn order to speed linear interpolation (erp) between samples, we can precalculate\nthe difference between adjacent samples, saving a subtract per look-up, especially on\nSIMD machines where a look-up usually loads a four-vector of floats at a time.\n\nsin(x) ~ table[i] + A * (cable +1]- table|\n= table{;] + A * gradient[Z] (2.3.3)\n\nPrecalculating these differences turns the lerp operation into a single multiply-\nadd.\n\nUsing a table poses the question: How many samples do we need to get N digits\nof accuracy? The table-based sine with 16 samples is shown in Figure 2.3.5, and the\nabsolute error graph is shown in Figure 2.3.6.\n\nThe largest error (or maximal error) occurs where the curvature of the function is\nhighest—in fact, when two samples straddle the top of the curve. The size of the max-\nimal error where the step size is Ax = x, , , — x,, can be shown to be:\n\n176\n\nSection 2 Mathematics\n\n0.015\n0.01\n0.005\n0\n-0.005\n-0.01\n\n-0.015\n\nFIGURE 2.3.6 Absolute error of 16 sample, linearly interpolated sine table.\n\nE=1- cof | (2.3.4)\n\nSo, for a table of 16 samples covering one whole cycle, the maximum relative\nerror will be 1 — cos(m/16) = 0.0192147, giving us just under two decimal places of\naccuracy in the worst case. Turning the problem around, given a known accuracy,\nhow many entries will we need in the table? We just reverse the inequality. For exam-\nple, to approximate sin(x) to 1% error we only need 23 entries:\n\nE=1%\n1-cos(z / N) <1%\ncos(z / N) > 0.99\nN> n/arccos(0.99)\n= 22.19 (2.3.5)\n\nUsing a process called range reduction, we can reconstruct the whole cycle from\njust 45° of samples, meaning that we only need a table of 23/8 = 3 entries. Equation\n2.3.4 will give you the hard upper bound on the error, an error that almost never\noccurs. For a slightly lower bound, you can use a small-angle approximation to the\narccos(), as 1/N should hopefully be a very small angle, giving you a bound of:\n\nN=— (2.3.6)\n\n\\2E\n\n2.3 More Approximations to Trigonometric Functions 177\n\nApplying Equation 2.3.6 to various error factors gives us a feel for situations\nwhere tables would be well used and where more-accurate methods must be used. See\nTable 2.3.2 for some example values.\n\nTable 2.3.2 Size of Table Needed To Approximate Sin(X) to a Given Level of Accuracy\n\nE 360° Range 45° Range\n1% accurate 0.01 23 3\n0.1% accurate 0.001 71 9\n0.01% accurate 0.0001 223 28\n1.0° 0.01745 17 3\n0.1° 0.001745 54 7\n8-bit int. 2? 26 4\n16-bit int. 215 403 51\n24-bit float 105 703 88\n32-bit float 107 7025 880\n64-bit float 10°17 ~infinite 8.7e+8\n\nRange Reduction and Reconstruction\n\nThe sine and cosine functions have an infinite domain. Every input value has a corre-\nsponding output value in the range [0, 1] and the pattern repeats every 27 units. To\nproperly implement the sine function, we need to take any input angle and find out\nwhere inside the [0, 27] range it maps to. This process, for sine and cosine at least, is\ncalled additive range reduction, and is shown in Figure 2.3.7.\n\nTo do this, we need to find out how many times we need to subtract 27 from the\ncurrent value to reduce it to the target range. We divide the input value by 27, trun-\ncate the result toward zero (i-e., convert it to an integer), and subtract that many\ncopies of 27 from it.\n\nVVVN eVV VV VV VV VV VV\ni. =) é 2 4 6\n% %\n\n% 75 % .\n& ’ & é\n% * ?\nso” 1 Sa\n\nFIGURE 2.3.7 Additive range reduction where C=20/16.\n\n178 Section 2 Mathematics\n\nLRA I NR A NSE REREAD ASA RE BH SRS MO ESIC Ca A EH AIC 2 et Ee EN INA\n\nconst float C = 2*PI;\nconst float invC = 1/C;\n\nint k = (int) (x*invC);\ny = x -— (float)k * C;\n\nIn this example, the value of & only tells us how many full cycles we need to sub-\ntract, but if we were to range-reduce using fractions of a cycle then the lower digits of\nk would tell us which ‘quadrant’ the remainder belongs to. Why is this useful? Because\nof these well known relationships:\n\nsin(A + B) = sin(A) cos(B) + cos(A) sin(B)\ncos(A + B) = cos(A) cos(B) + sin(A) sin(B) (2.3.7)\n\nIf we range-reduce to y €[0..1/2], that means we have four segments to our cycle,\nand k mod 4 will tell us which segment to use. If we multiply Equation 2.3.7 through,\nwe find that sin(B) and cos(B) collapse into the constants zero and one, and we get\nfour special cases:\n\nsin( y +0*2/ 2) = sin(y)\nsin( y +1*2/ 2) = cos(y)\nsin(y +2* n | 2) = —cos(y)\n\nsin(y +3*a2/ 2) = —sin(y) (2.3.8)\nleading to code like:\n\nfloat table _sin(float x) {\nconst float CONVERT = (2.0f * TABLE_SIZE) / PI;\nconst float PI_OVER_TWO = PI/2.0f;\nconst float TWO_OVER_PI = 2.0f/PI;\n\nint k = int(x * TWO_OVER_PI);\n\nfloat y = x — float(k)*PI_OVER_TWO;\n\nfloat index = y * CONVERT;\n\nswitch(k&3) {\ncase 0: return sin_table(index);\ncase 1: return sin_table(TABLE_SIZE-index) ;\ncase 2: return -sin_table(TABLE_SIZE-index) ;\ndefault: return -sin_table(index);\n\n}\n\nreturn(0) ;\n\n}\n\nWhy stop at just four quadrants? To add more quadrants, we need to reconstruct\nthe final result by evaluating Equation 2.3.7 more carefully, using either in-lined con-\nstants or a table of values:\n\n2.3 More Approximations to Trigonometric Functions 179\n\ns = sin_table(y);\nc = cos_table(y);\nswitch(k&15) {\n\ncase 0: return s;\ncase 1: return s * 0.923880f + c * 0.382685f;\ncase 2: return s * 0.707105f + c * 0.707105f;\ncase 3: return s * 0.382685f + c * 0.923880f;\ncase 4: return c;\ncase 5: return s * -0.382685f + c * 0.923880f;\n\n}\n\nNote how we have had to approximate both the sine and cosine in order to pro-\nduce just the sine as a result. For very little extra effort, we can easily reconstruct the\ncosine at the same time, and the function that returns them both for an input angle,\ntraditionally present in FORTRAN mathematical libraries, is usually called sincos().\n\nYou will find that most libraries use the range reduction, approximation, and recon-\nstruction phases in the design of their mathematical functions, and that this program-\nming pattern turns up over and over again. In the next section, we will generate an\noptimized polynomial that replaces the table look-up and lerp.\n\nPolynomial Approximations\n\nA person’s first introduction to approximating functions usually comes from learning\nabout the 7aylor Series in high school. Using a series of differentials, we can show that\nthe transcendental functions break down into an infinite series of expressions—for\nexample:\n\n3 5 17 V9\nsin(x) = x — ~ 4% _~% 4* _ (2.3.9)\n3 OSE OD\nIf we had an infinite amount of time and infinite storage, then this would be the\nlast word on the subject. As we have a very finite amount of time and even less stor-\nage, let’s start by truncating the series at the ninth power and multiply through to five\nsignificant digits:\n13,15 1 wy) 9\n\nx-- —_\n\n-— x +——*«\n6 120 5040 362880\n\nX\n\nsin(x)\n\nx — 0.16667x + 0.0083333x° — 0.00019841x” + 0.0000027557x°\n(2.3.10)\nThis is one of the classic infinite series—it exhibits alternating signs and drasti-\ncally reducing factors (1/x! plummets toward zero), two signals that this series is going\nto converge toward the correct value fairly fast. The problems lie in the approxima-\ntion error. If you graph the absolute error of this function (shown in Figure 2.3.8),\nyou find that it is very accurate for small angles around the origin of the Taylor expan-\nsion, but the error increases almost exponentially away from x = 0. Truncating the\n\n180 Section 2 Mathematics\n\nFIGURE 2.3.8 Absolute error of Taylor series over |-1t, 71].\n\nseries later will decrease the error; however, it is more costly, opens you up to more\ndanger of numerical error, and each additional term is another load/multiply-\naccumulate in your program. We need good accuracy across the whole range, and we\nneed it using as few terms as possible.\n\nHow about reducing the input range? If you reduce the range of the sine function\nthat we're trying to approximate, then, yes, we reduce the error because there’s less to\ngo wrong! Along with reducing the range, we could also Taylor-expand around the\ncenter of the range we want to approximate. This will halve the overall error, but at\nthe cost of doubling the number of constants we need—now we need to calculate\nevery power from zero to nine, not just every second one. We can do better than to\nuse a Taylor series as a technique for generating fast polynomial approximations,\n\nMinimax Polynomials\n\nThe Taylor expansion has a poor maximal error. If only we could find a way to take\nsome of this error and spread it out across the whole range. In fact, thanks to a theory\nby Chebychey, it can be shown that every approximation has one special polynomial\nthat has an equal amount of error everywhere—where we have ‘minimized the maxi-\nmal error,’ and it’s called the minimax polynomial. \\ts characteristics are:\n\n* Fora power N approximation, the error curve will change sign NV + 1 times.\n° The error curve will approach the maximal error V+ 2 times.\n\nThe method used to find these polynomial approximations is called the Remez\nExchange Algorithm, and it works by generating a set of linear equations. For example:\n\nsin(x) — a + bx, + cx? = 0 forasetofvalues x, € [2..2] (2.3.11)\n\nThese are solved to find the required coefficients a, 6, and c the maximal error is\nfound and fed back into x,. This highly technical optimization problem is sensitive to\n\n2.3 More Approximations to Trigonometric Functions 181\n\nfloating-point accuracy and is difficult to program, so we call on the professionals to\ndo it for us. Numerical math packages, like Mathematica and Maple, have the neces-\nsary environments with che huge number representations and numerical tools needed\nto give accurate answers.\n\nThe arguments needed to calculate a minimax polynomial are:\n\n¢ the function to be approximated,\n\n¢ the range over which the approximation is to be done,\n\n¢ the required order of our approximation, and\n\n* a weighting function to bias the approximation into minimizing absolute (weight\n1.0) or the relative error.\n\nLet’s find a seventh-order polynomial approximation to sin(x) over the range [0,\n7/4], optimized to minimize relative error. We start by looking at the Taylor expansion of\nsin(x) about x = 0, just to get a feel for what the polynomial should look like. The result\nshows us that the series has a leading coefficient of 1.0 and uses only the odd powers:\n\nsin(x) = x — 0.166666667x°+0.00833333333x° — 0.000198412698x’ (2.3.12)\n\nA raw call to minimax will, by default, use all coefficients of all available powers\nto minimize the error, leading to some very small, odd-looking coefficients and many\nmore terms than necessary. We will transform the problem into one of finding the\npolynomial in the expression:\n\nsin(x) = x + x° P(x’) (2.3.13)\n\nFirst, we form the minimax inequality, expressing our desire to minimize the rel/-\native error of our polynomial P:\n\nsin(x) — x — x° P(x’)\n\n: < error (2.3.14)\nsin(x)\nDivide through by x?:\nsin(x) _ 4+ — P(x?)\nNS oppor (2.3.15)\nsin(x)\n~\n\nWe want the result in terms of every second power, so we substitute y = x7:\n\n51 -+- ry)\nae Pe (2.3.16)\n\n182\n\nSection 2 Mathematics\n\nSo, we have reduced our problem to finding a minimax polynomial approxima-\n\ntion to:\nsin vy 1\nP(y) = WV -= (2.3.17)\ny J\nwith the weight function:\n3/2 .\nW(y) = (2.3.18)\n\nJ\n\nIn order to evaluate the function correctly in the arbitrary, precision environment\nof Mathematica or Maple, it is (ironically) necessary to expand the first expression\ninto a Taylor series of sufficient order to exceed our desired accuracy in order to pre-\nvent the specially written, arbitrary accuracy sine function from being evaluated:\n2 3 4 5\n\n6 120 5040 362880 39916800 6227020800\n\nOur last task is to transform the range we wish to try and approximate. As we\nhave substituted y = x”, so our range [0, 7/4] is transformed to [0, 27/16]. Running\nthese through the minimax function, looking for a second-order result gives us:\n\nPly) = — 0166666546 + 0.00833216076y — 0.000195152832y? (2.3.20)\nResubstituting this result back into Equation 2.3.12 gives us the final result:\nsin(x) = x — 0.166666546x* + 0.00833216076x° — 0.000195152832x” (2.3.21)\n\nIn order to reconstruct these coefficients as single precision floats, we need only\nrecord the first nine significant digits (see proof below), giving us Figure 2.3.9, the\nabsolute and relative error curves over our range with a maximum absolute error of\n2.59e-9 at x = 0.785.\n\nHere is a loose proof. In single precision, numbers in the range [10%, 2!°] = [1000,\n1024] have 10 bits to the right of the decimal and 14 bits to the right. There are\ntherefore (2!° — 10%)2!4 = 393,216 representable values. If we use a decimal notation\nwith eight digits, we can represent (2!°— 107)108= 240,000 values. We therefore need\nnine decimal digits to be able to reconstruct the correct binary number. Similar con-\nstructions along the number line show a need for between six and nine digits. For\n\nmore, see [Goldberg91].\n\nOptimizing for Fioating-Point\n\nThe same technique we used to remove a coefficient can be used to force numbers to\nmachine-representable values. Remember that numbers like 1/10 are not precisely\nrepresentable using a finite number of binary digits. We can adapt the technique\nabove to force coefficients to be our choice of machine-representable floats. Remem-",
      "page_number": 174,
      "chapter_number": 18,
      "summary": "This chapter covers segment 18 (pages 174-181). Key topics include functions, function. Covers function. The idea is to precalculate a table of samples from a function at regular intervals\nand use the input value to the function to hash into the table, look up the two closest\nvalues and linearly interpolate between them (see Figure 2.3.5).",
      "keywords": [
        "error",
        "sin",
        "range",
        "function",
        "Trigonometric Functions",
        "Solutions As clock",
        "float",
        "absolute error",
        "range reduction",
        "polynomial",
        "Functions",
        "approximation",
        "sine",
        "Series",
        "cos"
      ],
      "concepts": [
        "functions",
        "function",
        "sin",
        "floats",
        "tables",
        "value",
        "polynomials",
        "number",
        "samples",
        "case"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 1",
          "chapter": 18,
          "title": "Segment 18 (pages 159-166)",
          "relevance_score": 0.54,
          "method": "api"
        },
        {
          "book": "Computer Systems A Programmer’s Perspective",
          "chapter": 54,
          "title": "Segment 54 (pages 1084-1102)",
          "relevance_score": 0.5,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 1",
          "chapter": 36,
          "title": "Segment 36 (pages 344-351)",
          "relevance_score": 0.5,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 2",
          "chapter": 2,
          "title": "Segment 2 (pages 9-16)",
          "relevance_score": 0.5,
          "method": "api"
        },
        {
          "book": "Computer Systems A Programmer’s Perspective",
          "chapter": 17,
          "title": "Segment 17 (pages 331-351)",
          "relevance_score": 0.49,
          "method": "api"
        }
      ]
    },
    {
      "number": 19,
      "title": "Segment 19 (pages 182-189)",
      "start_page": 182,
      "end_page": 189,
      "detection_method": "topic_boundary",
      "content": "2.3 More Approximations to Trigonometric Functions 183\n\n3e-09\n2e-09\n1e-09\n\n-1e-09\n-2e-09\n\n-3e-09\n\nFIGURE 2.3.9 Absolute and relative error of approximation over (0, 1/4].\n\nbering that all floating-point values are rational numbers, we can take the second\ncoefficient and force it to fit in a single precision floating-point number:\n\n2796201 _\n~ 24 ~\n\nk= —0.16666656732559204101562500000 (2.3.22)\n\nNow that we have our constant value, let’s optimize our polynomial to incorpo-\nrate it. Start by defining the form of polynomial we want to end up with:\nsin(x) = x + kx? + x° P(x’) (2.3.23)\nNow we form the minimax inequality:\nsin(x) — x — kx? — k° P(x’)\nsin(x)\n\n< error (2.3.24)\n\nwhich, after dividing by &, substituting y = x’, and solving for P(y), shows us that we\nhave to calculate the minimax of:\n\nP(y) = cD - y + y (2.3.25)\nwith weight function\n5/2\nW(y) = (2.3.26)\n\nJ\nSolving this and resubstituting gives us a seventh-degree optimized polynomial\n\nover the range [0, 7/4] with a maximal error of 3.39e-8 at x = 0.557, but with better\nsingle precision floating-point accuracy:\n\n184 Section 2 Mathematics\n\n7 — OT 2 + 0.00833220803x? — 0.000195168955x” (2.3.27)\n\nsin(x) = x\n\nThe absolute and relative error of float-optimized approximation over [0, 1/4] are\nshown in Figure 2.3.10.\n\n6e-09\n\n4e-09 f\n\n2e-09 | /\n\nFIGURE 2.3.10 Absolute and relative error of float-optimized approximation over\n[0, 7/4].\n\nA Note on Convergence\n\nTAL RNAI R A SRN\n\npra ie JRA MAREE ARNON CANE RATI RIP\n\nHow do we choose the degree of polynomial that we need to approximate a function to\na given accuracy? We can easily calculate how many bits of accuracy an approximation\nprovides. First, we calculate the maximum error within the range (this will be a small\nvalue, typically something like 5e-4) and take the base-2 logarithm of this value using\nIn(error)/In(2), giving us a negative number that tells us how many bits we will need\nafter the decimal point to be able to represent this value. Generating a table of this value\nfor several important functions shows us some interesting results (see Table 2.2.3).\n\nTable 2.3.3 Number of Significant Bits of Accuracy Versus Degree of Minimax\nPolynomial Approximating the Range [0, 1]\n\n2 3 4 5 6 7 8\n& 6.8 10.8 15.1 19.8 24.6 29.6 34.7\nsin(x) 7.8 12.7 16.1 21.6 25.5 31.3 35.7\nIn(1 + x) 8.2 11.1 14.0 16.8 19.6 22.3 25.0\narctan(x) 8.7 9.8 13.2 15.5 17.2 21.2 22.3\ntan(x) 4.8 6.9 8.9 10.9 12.9 14.9 16.9\narcsin(x) 3.4 4.0 44 4,7 4.9 5.1 5.3\n\nVx 3.9 44 4.8 5.2 5.4 5.6 5.8\n\n2. 3 More ‘Approximations to  Trigonometric Functions 185\n\nFirstly, it shows how well we can use polynomials to approximate exp(x) and\nsin(x), as each additional power gives us pretty much four bits of accuracy. For a 24-\nbit single precision floating-point value, we will only need a sixth- or seventh-power\napproximation. The table also shows how badly Vx is approximated by polynomials;\neach additional power only adds half a bit of accuracy—this is why there are no quick\nand easy approximations to the square root; we must use range reduction with New-\ntons algorithm and good initial guesses to calculate it. Another surprise is tan(x).\nAfter all, it’s only sin(x)/cos(x) isn’t it? Rational functions like this are not well approx-\nimated by ordinary polynomials and require a different toolkit of techniques.\n\nCon lusion\n\ncemennnnnnuiimaraauamnnnnnunne: ar eo\n\nRUAN AS ARRAS PINS RESCH ROR HS RRNA NORE\n\nThe task of writing low-accuracy mathematical functions using high-accuracy tech-\nniques has not been covered in any depth in the literature. But with the widespread\nuse of programmable DSPs, vector units, high-speed yet limited hardware, and more-\nesoteric shading models, the need to write your own mathematical functions is\nincreasingly important.\n\nIntroductions to polynomial approximation always start by saying how accurate\nthey can be, and this obsession with accuracy continues through to extracting the very\nlast bit of accuracy out of every floating-point number. Why this obsession with accu-\nracy? Because if you can build high-accuracy polynomials with less coefficients, you\ncan also build tiny, low-accuracy approximations using the same techniques. The lev-\nels of accuracy you can obtain with just two constants as well as the hugely reduced\nrange can be amazing. Hopefully, this gem has given you the confidence to grab a\nmath package and generate some of your own high-speed functions.\n\nReferences\n\nNatta a RRR RONG RR RBRRTS ES GORDA RRR ARORA HORE EEE\n\n(Codye0) Cody & Waite, ‘Software Manual for the Elementary Functions, Prentice\n\nHall, 1980.\n\n[Crenshaw00] Crenshaw, Jack W., Math Toolkit for Real-Time Programming, CMP\nBooks, 2000.\n\n[DSP] The Music DSP Source Code. Archive available online at http://www.smart-\nelectronix.com .\n\n[Goldberg91] Goldberg, Steve, “What Every Computer Scientist Should Know\nAbout Floating Point Arithmetic,” ACM Computing Surveys, Vol. 23, No. 1,\nMarch 1991.\n\n(Hart68] Hart, J. E, Computer Approximations, John Wiley & Sons, 1968.\n\n[Moshier89] Moshier, Stephen L., Methods and Programs for Mathematical Functions,\nPrentice Hall, 1989.\n\n[Muller97] Muller, J. M., Elementary Functions: Algorithms and Implementations,\nBirkhaiiser, 1997.\n\n[Ng92] Ng, K. C., “Argument Reduction for Huge Arguments: Good to the Last\nBit,” SunPro Report, July 1992.\n\n[Story00] Story, S. and Tang, P. T. PR. “New Algorithms for Improved Transcendental\nFunctions on [A-64,” Intel Report, 2000.\n\nSection 2 Mathematics\n\n[Tang89] Tang, Ping Tak Peter, “Table Driven Implementation of the Exponential\nFunction in IEEE Floating Point Arithmetic,” ACM Transactions on Mathemat-\ncal Software, Vol. 15, No. 2, June 1989.\n\n[Tang90] Tang, Ping Tak Peter, “Table Driven Implementation of the Logarithm\nFunction in IEEE Floating Point Arithmetic,” ACM Transactions on Mathemati-\ncal Software, Vol. 16, No. 2, December 1990.\n\n[Tang91] Tang, Ping Tak Peter, “Table Lookup Algorithms for Elementary Functions\nand Their Error Analysis,” Proceedings of 10th Symposium on Computer Arith-\nmetic, 1991.\n\n[Upstill90] Upstill, S., The Renderman Companion, Addison Wesley, 1990.\n\n2.4\n\nQuaternion Compression\n\nMark Zarb-Adami,\n\nMuckyfoot Productions\nmark@muckyfoot.com\n\nNic’ of today’s computer games use large amounts of animation data, and a large\nportion of the memory used for each animation frame is consumed by the rota-\ntion of the bones. Typically, the rotation data is stored as quaternions. In this gem, we\npropose and compare methods for compressing a four-float quaternion into a 32-bit\n\nquantity.\n\nQuaternions\n\nra\n\nA quaternion Q(x, y, z, w) can be used to represent a rotation matrix. If we consider\nall rotation matrices to represent a rotation of angle @ about axis A(X, ¥, Z), then the\nquaternion for the rotation would be:\n\nQ = (sX,sY,sZ,c)\n\nwhere:\n\nsin(@)\nc = cos(9)\n\nIt is important to note that quaternion Q(x, y z, w) and quaternion Q*(-x, -y, -z,\n-w) represent the same rotation. This is because a rotation of @ about axis A is equiv-\nalent to a rotation of -@ about axis —A. Also, note that all the quaternions we consider\nin this gem are normalized. This means that for every quaternion Q(x, y, z, w):\n\n$\n\netypt+e7 tw’ =1\n\nSmallest Three Method\n\nWe can compress a quaternion by quantizing each element of the quaternion down to\na byte. This is very fast, but it is \\so inaccurate. Because the quaternion is normal-\nized, we can improve the accuracy of quantization by eliminating one of the elements.\nGiven three of the elements, we can calculate the fourth one. Now, we have to decide\nwhich element to exclude. If we remove the biggest element, we will have smaller\n\n187\n\n188\n\nSection 2 Mathematics\n\nnumbers to store! In fact, none of the three smallest elements of a quaternion can have\n\nan absolute value larger than 1 / V2. To understand why this is the case, consider the\nfollowing. The second largest element of a normalized quaternion will be Largest when\ntwo elements of the quaternion have the same value and the other two are zero, as in\n\nQt», v, 0, 0). If we normalize this quaternion, then v must equal 1/V2.\n\nWe don’t have to store the sign of the largest element, since we can make sure it is\nalways positive. If it isn’t positive already, simply negate the quaternion as described\npreviously.\n\nPolar Methods\n\nSSSR RRA ste RRO samen SSB ORS IETISIIE LN LEE TOTES\n\nSince we can store a direction vector (x, y, 2) using just two angles, yaw and pitch,\nwe can also store a quaternion as (yaw, pitch, w). Note that storing (x, y, z) with yaw\nand pitch removes information about its length, but we can restore the correct length\nwith ww, since the quaternion is normalized. If we ensure that w is always positive, then\nwe don't have to store its sign. Once again, if w is negative, we simply negate the\nquaternion.\n\nThe trouble with storing a direction vector as yaw and pitch is that the encoded\nvectors are not evenly dispersed over a sphere. They are instead concentrated at the\npoles. When the pitch of the vector is 7/2, and the vector points straight up at the\npole, we do not want to store a yaw. However, when the pitch of the vector is zero and\nthe vector lies along the equator, we want to store many yaw values. Say we wanted to\nuse 7 bits to encode a direction vector. One solution would be to spread points evenly\nacross the surface of the sphere, store (x, y, 2) or (yaw, pitch) for each point in a lookup\ntable, then store an 7-bit index into that table. While this is okay for small values of 1,\nthe size of the lookup table quickly becomes uncomfortably large!\n\nHowever, there is an effective method for encoding a direction vector without the\nuse of a lookup table. First of all, we store the signs of x, y, and z separately so that we\ncan assume that x, y, and z are all positive. This reduces the problem to an eighth of\nthe sphere. The next step is to number points inside this eighth of a sphere as in Fig-\nure 2.4.1.\n\nNotice that the square numbers appear on the left-hand side of the diagram. This\nallows us to find the row and column of an encoded number, e, like this:\n\nrow = floor(sqrt(e));\ncolumn = e — row*row;\n\nNow, if we let pitch be the row of e, and if we let yaw be the column of e, we can\nefficiently store and retrieve these values. Notice how we will not waste any yaw values\nat the pole, and that we have plenty of possible yaw values at the equator.\n\nImplementation\n\nasm NRE EE TTT eS Se ROSS NASSAR HOSTS SRSES ORS e RUTGERS RSNEHE nn a a HEN\n\nNow, let’s discuss the implementation for the methods we have discussed.\n\n2.4 Quaternion Compression 189\n\nFIGURE 2.4.1 Numbering over an eighth of a sphere.\n\nSmallest Three\n\nThe smallest three method neatly stores a quaternion into 32 bits. We need two bits\nto store the index of the implied (largest) element, leaving 10 bits for each of the\nthree smallest elements. Since we know each of the stored elements lie in the range\n[— 1/V2, 1/V2. we can interpolate those values to [0, 1023] so that the values are rep-\nresented as integers.\n\nPolar\n\nAfter experimenting with various bit allocations, we found the best compression\nwhen we allocated 11 bits to w. We need an additional 3 bits to store the sign of x, »,\nand z, leaving 18 bits to store yaw and pitch. If we are encoding yaw and pitch as a sin-\ngle number, then we can store 2'® values in 512 rows. Alternatively, we can allocate 9\nbits for yaw and 9 bits for pitch. We know they are both in the range [0, 2/2], so we\ninterpolate these values to [0, 511] and store them as integers.\n\nConverting from yaw and pitch to a vector requires sine and cosine calculations\nfor both yaw and pitch, so we recommend using a fast polynomial approximation\n\nSection 2 Mathematics\n\nctr ooh tt tb aOR REE\n\n[Edwards00] to calculate these values. Moreover, because yaw and pitch are always\nwithin [0, 7/2], we can tailor (no pun intended) the approximations to this particular\nrange. We can expand a Taylor series about 1/4 (instead of about 0) and use values\nbetween [0, 1/4] as sample points for a Lagrange series. A Taylor series to order five,\nor a Lagrange series to order four or five is sufficient. The order-four Lagrange series\nis slightly faster, but you lose a bit of accuracy. Also, the order-five Lagrange series\ngives a more accurate approximation than the order-five Taylor series.\n\nThe animation data for our game Blade II is stored hierarchically, hence the vast\nmajority of the quaternions have only a small angle of rotation, 0. Since w is cos(8/2),\nw is usually close to 1 for this data. Note that this would be true to a lesser extent even\nif the quaternions had random angles of rotation, simply because of the nature of the\n\ncosine function. So, to get more resolution for values near to 1, we store V1—w\ninstead of w and recover w at decompression time.\n\nPerformance\n\n{Hie SRR TE eee RRR SRR HARRIS RR AR NOR EY 8 sa?\n\nTo quantify the performance of each compression method, we used the quaternions\nfrom our Blade I] as data. We compressed and decompressed each quaternion Q to get\nanother quaternion, Q’. We converted Q and Q’to matrices, and transformed a set of\npoints with the resulting matrices. Then, for each point, we calculated the distance\nbetween the point transformed with Q and the point transformed with Q’. We repre-\nsent these distances as error for that compression method. We also measured the\ndecompression speed of each method. Figure 2.4.2 shows the relative performance of\neach compression method on our hierarchical data. The approximation method used\nfor the polar methods was an order-five Lagrange polynomial.\n\nDecompression\nTime\n\nmw Polar encoded\n\nMaximum (yaw, pitch) and w\nError @ Polar\n(yaw, pitch,w)\n0 Smallest Three\nAverage\nError\n\nFIGURE 2.4.2 Relative performance of each compression method using Blade IT\nquaternion data.",
      "page_number": 182,
      "chapter_number": 19,
      "summary": "We can easily calculate how many bits of accuracy an approximation\nprovides Key topics include functions, function, and value. A Note on Convergence\n\nTAL RNAI R A SRN\n\npra ie JRA MAREE ARNON CANE RATI RIP\n\nHow do we choose the degree of polynomial that we need to approximate a function to\na given accuracy.",
      "keywords": [
        "Quaternion",
        "yaw",
        "store",
        "Functions",
        "bits",
        "pitch",
        "Floating Point Arithmetic",
        "error",
        "accuracy",
        "approximation",
        "Ping Tak Peter",
        "Elementary Functions",
        "Method",
        "sin",
        "compression method"
      ],
      "concepts": [
        "functions",
        "function",
        "value",
        "point",
        "approximations",
        "approximation",
        "approximate",
        "approximating",
        "accuracy",
        "numbers"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 1",
          "chapter": 19,
          "title": "Segment 19 (pages 167-175)",
          "relevance_score": 0.53,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 1",
          "chapter": 18,
          "title": "Segment 18 (pages 159-166)",
          "relevance_score": 0.48,
          "method": "api"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 7,
          "title": "Segment 7 (pages 121-141)",
          "relevance_score": 0.45,
          "method": "api"
        },
        {
          "book": "AI Engineering Building Applications",
          "chapter": 31,
          "title": "Segment 31 (pages 617-639)",
          "relevance_score": 0.44,
          "method": "api"
        },
        {
          "book": "Computer Systems A Programmer’s Perspective",
          "chapter": 8,
          "title": "Segment 8 (pages 140-157)",
          "relevance_score": 0.42,
          "method": "api"
        }
      ]
    },
    {
      "number": 20,
      "title": "Segment 20 (pages 190-197)",
      "start_page": 190,
      "end_page": 197,
      "detection_method": "topic_boundary",
      "content": "2.4 Quaternion Compression ; 191\n\nsein ttt au ia oto aaa tela ons pisncgronice Mot tt\n\nea A RR RS RI RRS USE RAR\n\nThe real t test of the compression of each algorithm comes from observing the charac-\nters in your game. The worst-case scenario for Blade I is when errors accumulate\ndown the skeleton, especially if the character is holding a long lever (like a shotgun) in\nhis hand! There is a visible improvement when using the polar methods compared to\nthe smallest three method.\n\nAcknowledgments _\n\nLAL LE ENTER RRA\n\nI want to thank Jan Svarovsky and Mike Diskett for their help j in developing the ideas\nin this gem.\n\nitRBRENINRaRN ARS RI RRE IRON IARC eI aR RN\n\nwards00] Edwards, Eddie, “Polynomial Approximations to Trigonometric Func-\ntions,” Game Programming Gems, Charles River Media, Inc., 2000.\n\n[Svarovsky00] Svarovsky, Jan, “Quaternions for Game Programming,” Game Pro-\ngramming Gems, Charles River Media, Inc., 2000.\n\nBones Hierarchy\n\n192\n\nConstrained Inverse\nKinematics\n\nJason Weber, Intel Corporation\njason.p.weber@intel.com\n\nuch of the animation currently used in interactive applications relies on stored\n\nfragments of motion-captured or hand-authored data. Although these motions\ncan be beautifully polished, the repeated use of a limited set of actions can become\nreadily apparent. One key to holding the attention of a user is to continually provide\nnew and unique environments.\n\nTo provide unique animations at runtime, we first need an abstract means to con-\ntrol and deform a mesh, such as with an embedded skeleton. Then, we need to gener-\nate motion for that skeleton from events or items in the proximity of the mesh.\nForward kinematics allows us to simply adjust bone angles like a jointed, wooden\nartist's model. However, we also need the reverse calculation to find suitable angles\nthat will arrange terminal segments, like hands and feet, where we want them. Inverse\nkinematics (IK) provides a fast and robust method to position an arbitrary chain of\nbones so that an end bone attempts to align with a movable ‘effector.’ By providing\nsolutions in real-time, we allow characters to react spontaneously and uniquely to an\nunpredictable environment.\n\nWe describe a well-known method called “cyclic coordinate descent” and demon-\nstrate how to constrain the angular solutions based on the physical limits of the joints.\nWe specifically target the constraint format provided with 3ds max.\n\nPRIMER\n\nARLE ORS PRR RAEN I eRe REO RARER\n\nThe skeletal structure is basically a hierarchy of transforms, like a scene graph. At each\ntransform, we define a bone length, which is really a displacement along that trans-\nform’s local x-axis. By default, the origin of all child bones is positioned at the point\non the end of the parent bone. We allow for an additional arbitrary displacement, but\nin most cases it is zero, because bones usually connect end-to-end.\n\nFor clarity, we will not refer to a “model space” in which the overall character is\nplaced. We will refer to the space that the root bone moves in as the “world space,”\neven though in a real scenario, it will probably be just a node in some greater scene\n\n2.5 Constrained Inverse Kinematics 193\n\ngraph. At each transform in the bone hierarchy, that transform, relative to its parent,\nwill be called a “local” transform.\n\nAt this stage, we represent all rotations using quaternions because of their smooth\ninterpolative qualities [Bobick98]. A quaternion is a four-dimensional extension to\ncomplex numbers. So, just as a complex number can be used for two-dimensional\nrotational computations, w + xi + yj + zk (i = j* = k? = —1, ij = k = —ji) can effectively\nrepresent three-dimensional rotations. Conversions to and from quaternions, as well\nas operations using quaternions, can include nontrivial mathematics, but small\nlibraries and clear examples are readily available [Flipcode98]. We use right-handed\nunit quaternions of the form (w, x, y, z) where (1, 0, 0, 0) represents an identity of no\nrotation. The values are similar to the angle/axis format, where a rotation of (2cos! w)\nradians occurs about a nonunit vector (x, y, Z).\n\nA reference pose for the skeleton describes the state of the hierarchy so that it\naligns with a given undeformed source mesh. (BiPed™, in 3ds max, calls this the “fig-\nure mode.”) The motion of the bones away from reference is used to deform the mesh\nto any arbitrary position. The deformation techniques are a different topic\n[Weber02], so all we have to know about here is that the IK algorithms or interpo-\nlated motion data supply a bone-indexed set of world-aligned transforms at each\nframe. After the parent-relative quaternion values have been determined for a frame,\nthe bone graph is traversed, and the world transforms are generated through simple\nquaternion-quaternion concatenation and quaternion-matrix conversion.\n\nCyclic Coordinate Descent\n\nThe IK system attempts to rotate a chain of participating bones so that the tip of the\nend bone is located at a movable control point, called an effector. There are many\ncomplex and expensive ways to generate inverse kinematic solutions, but fortunately\nthere is a reasonably simple algorithm that is quite fast and surprisingly robust, called\n“cyclic coordinate descent” (CCD), which is nicely outlined in [Lander98]. We use\nquaternions for all the rotational operations.\n\nEach iteration starts with the deepest child bone in the chain. The bone is rotated\nabout its base so that it points directly at the effector. Next, the parent of that bone is\nrotated about its base so that an imaginary line from the base of that parent to the tip\nof the newly rotated child points toward the effector. This is repeated for every bone\nin the chain so that each bone’s imaginary line from its base to that same end bone’s\nendpoint rotates toward the effector. Multiple iterations through the chain can fur-\nther refine the solution to produce a smoother distribution of angles. Even if the effec-\ntor cannot be reached, the solver can make a solid attempt without becoming shaky or\nunstable.\n\nThis method can create a tendency to make the lowest child disproportionally\ndynamic, such as using full wrist deflection just to pick up a ball. It is possible to bias\nthe solution by having some bones only rotate a fraction of the desired change for\n\n194\n\n2 Mathematics\n\neach iteration, but this might increase the number of iterations needed to reach a sta-\ntic solution. To pick up a ball, it is probably easier just to apply the IK effector to the\nwrist instead of the fingertips, and then use a generic pick-up motion for the hand.\nFigure 2.5.1 shows the steps in a descent. The X symbol is the location of the\neffector. The dotted line represents the current base-to-tip angle. Each currently\naddressed bone is rotated to align the dotted line with the desired dashed line.\n\n™—\n\nFIGURE 2.5.1 Steps in cyclic coordinate descent. The X symbol is the location of the\n\neffector.\n\nIf a bone participates in multiple ‘effected’ end bones, the participating bone can\nfirst compute an angular change to satisfy each of the solutions, then use given\nweighting factors to work out a blended solution.\n\nThe number of iterations required to reach an acceptable solution depends on\nwhere each new frame starts the solution. In a conventional approach, you would\nreset the limb to some default state at the beginning of each frame. The solver would\nrun through 10 or so iterations to a fresh solution. However, a small change in an\neffector position can cause a sudden change in the solution. For example, if you are\nmoving an effector for the hand vertically behind the back, the solver might suddenly\ndecide that it is better to reach over the shoulder than under it. An alternative\napproach is to continue from the solution of the previous frame. Then, we can cut\nback to as little as one iteration per frame. By using this incremental method, the\nsolver also is much less likely to flip between marginally superior, but substantially\ndifferent solutions.\n\nAn important factor in generating realistic motion is limiting the angular velocity.\nTo do this, we take the world-based quaternion of the previous frame and compare\nthe new quaternion solution. We convert the delta to angle-axis form and limit the\nangle to a specified maximum. About 3 radians per second seems to be a good default\nlimit, with smaller values increasing the sluggishness. Limiting angular acceleration\nturns out to have minimal value, since it appears that most biological structures can\nachieve full velocity during the timestep of one frame.\n\nSee [Welman93] for detailed explanation of CCD and other methods of inverse\n\nkinematics.\n\n2.5 Constrained Inverse Kinematics 195\n\nRotational Constraints __\n\nThe resulting IK solution will not st work well with physical c creatures unless we account\nfor realistic angular limits. The basis of how constraints are defined and applied is dic-\ntated by the form in which the authoring packages export them. Therefore, we will\ndefine two conventions we need to follow.\n\nEuler Angles\n\nAlthough our rotations are computed using quaternions, the limiting angles are usu-\nally supplied from the artist using Euler angles, an alternative angular representation\nusing three angles applied in succession. For example, Euler angles could represent the\norientation of an airplane by heading, pitch, and bank where pitch is applied after\nrotating by the heading, and bank is applied after rotating for the pitch. Gimbal lock\ncan occur if one of the angles is near 90°, since two of the rotation axes can align and\nbecome redundant. In that case, the third degree of freedom is lost.\n\nConverting from an Euler representation to a quaternion or matrix is as simple as\napplying the three rotational transforms in succession. However, converting back to\nan Euler representation is weakly defined and can have multiple solutions. A conver-\nsion example is in a referenced article, [Flipcode98].\n\nWorld-Aligned Constraints\n\nProgrammers would probably expect the angular limits of a particular bone to be\ndefined relative to the position of its parent. While this is partially true, 3ds max uses\nworld-aligned axes to define the angles about which these limits are to be applied.\nThis means that if the world-relative reference transform of a parent bone is not\naligned with the world axes, then an isolated constraint of a child about one of the\nparent’s local axes is not possible. Because of this, the 3ds max manuals recommend\nthat the constrained bones in the reference pose (their ‘figure mode’) should be coin-\ncidentally aligned with the world. Unfortunately, we cannot simply transform these\nlimits about world-aligned axes to the local axes of the bone. To faithfully reproduce\nthe artist’s intentions, we have to follow these conventions exactly, making conver-\nsions back and forth as necessary.\n\n‘Kine’ Each Bone, and Apply the Constraints\n\nON THE CO\n\nSN ARS AACR MERIT RE RGB RABANNE GILG RA ATOR NRO OED ME EASE ARETE ME NES\n\nThis pseudo-code will describe the entire process of applying IK to one specific bone.\nThis process is applied to the entire hierarchy in a child-first order. For reference, see\nGPGCharacter::KineBone() in the file GPGCharacter.cpp on the CD-ROM. The\nvariable world_relative is true (you may note how much simpler the code would be if\nit were false).\n\nEach bone contains a list of the effector solutions to which it participates. For\neach bone that has an effector, there are usually several bones that participate in the\nsolution to draw that one bone toward the effector. Note that we called this partici-\n\nSection 2 Mathematics\n\npating association to an effector an “effection.” Having an effection doesn’t necessar-\nily mean that the specific bone is trying to reach the effector, but rather it may be\nhelping a descendent bone meet the effector. For example, the upper arm can help the\nhand reach for a ball.\n\nThe float scalar is used to divide influence from multiple effectors. Currently in\nour code, it is evenly divided, so if a bone has an effection to two effectors, each will\nonly have half the effect they would have had by themselves. The following block is\n\napplied once for each bone’s effection.\n\nVector3 effected = current end of effected bone in world space\ndisplaced in local X by the bone length\nVector3 effector = current position of relevant control point in\n\nworld space\nVector3 current = effected, reverse-transformed to local space\nVector3 desired = effector, reverse-transformed to local space\n\nif the difference between current and desired is small, skip to next\nbone\n\nnormalize current and desired\ncompute a quaternion delta that would rotate current to desired\n\nsum all the scaled deltas from the multiple effections and store in\nchange\n\nif velocity-limiting is on, limit change to the max per-frame angle\nallowed; this should be adjusted to the magnitude of the timestep\n\nrotate the bone by the quaternion delta\n\nQuaternion global_rot = parent's world rotation * this bone's local\nrotation (this is the bone's current world transform)\n\nQuaternion parent_delta = parent's reference rotation * inverse of\nparent's current world rotation (this is how much the parent has\ndeviated from reference with respect to the world)\n\nQuaternion global_delta = parent_delta * global_rot * inverse of\nparent reference world rotation (this is the bone rotation in world-\naligned axes adjusted for parent rotation)\n\nconvert Quaternion global_delta to Euler euler\n\nThe next block does the actual limiting of angles. It is applied to euler in each of\nthe three axes. “Active” means it is allowed to move. “Limited” means that the angle is\nconstrained. To avoid gimbal lock, we ignore new x and z angles when the y angle is\nnear + 90° (by about 5% of a radian). We retain old values of x and z until the y angle\nreturns to a safe value.\n\nNote the usage of a variable called dias. When a potential solution goes far outside\nthe constraints, this can prevent it from flipping around and constraining to the opposite\n\n197\n\nlimit. A bias of zero means the bone is currently being limited by the minimum angle,\none indicates it is being limited by the maximum angle, and two indicates no preference.\nWhen thinking about the constraints, it can be helpful to think of a pie slice in a circle\nwhere the two radials are the minimum and maximum angles. Usually, when the result\nends up outside this region, you want to snap to the closest boundary (minimum or max-\nimum). However, if the computed solution is outside the pie slice, but is nearly equidis-\ntant from both limits, it is possible that the clamping routine will flip back and forth\nbetween the minimum and maximum. So, we insert a bias indicating that in order to flip\naround the outside of the pie, the alternate limit must be substantially closer. In our code,\nwe add 10° to the alternate distance before the magnitude comparison.\n\nif active and not limited, skip this axis (any angle is fine)\n\nif not active, set the angle to the reference value; skip to next\naxis\n\nX,Z axes only: if Y angle is near 90 degrees, set angle to last\nframe's value, and skip to next axis (gimbal lock avoidance)\n\nif current angle is within limits, reset bias to 2 (no preference),\nand skip to next axis\n\nmindiff\nmaxdi ff\n\nminimum — angle\nangle - maximum\n\nadjust mindiff and maxdiff to be in range of 0 to 2*PI\n\nif there is a bias preference, adjust angles to make flipping between\nsolutions less desirable by adding the 10 degrees to the opposite\nmin/max diff variable\n\nif maxdiff<mindiff, set angle to max and bias to 1\nif maxdiff>mindiff, set angle to min and bias to 0\n\nstore modified euler in case there is a gimbal lock next frame\nconvert euler to Quaternion global_delta\n\nQuaternion constrained = inverse of parent reference world rotation\n* global_delta * parent reference world rotation\n\nset bone rotation to constrained\n\nrecompute cached current world transform for this bone and all\ndescendents\n\nFigure 2.5.2 shows a character reaching back to an effector about 2/3 meters\nbehind his head. Without the constraints, the solver would have immediately posi-\ntioned the arm in a straight line from the shoulder toward the point. With con-\nstraints, the arm is restricted to its physical limits. Also see Color Plate 2 for an\nexample of this technique on a scorpion tank mesh.\n\n198 Section 2 Mathematics\n\nConclusion\n\nRNR cE cere\n\nfed pe\n\nUsing inverse kinematics in skeletal motions can generate a level of spontaneity that is\ndifficult to produce with pre-authored or captured motion data. By generating the\nmotion in real-time, the characters can react uniquely to an ever-changing situation.\n\nIn our example, we use hard stops to limit the angles. By adding a springiness\nnear the limits, we should be able to reduce the mechanical-looking motions that can\nsometimes occur.\n\nReferences\n\n[Bobick98] Bobick, Nick, “Rotating Objects Using Quaternions,” Game Developer\nMagazine, February 1998: pp. 34-42. Also available online at http://www.\ngdmag.com/.\n\n[Flipcode98] Unattributed, “The Matrix and Quaternions FAQ,” available online at\nfietp: iwww.flipcode.com/documents/matrfag.html, December 1998.\n\n[Lander98] Lander, Jeff, “Making Kine More Flexible,” Game Developer Magazine,\nNovember 1998: pp. 15-22.",
      "page_number": 190,
      "chapter_number": 20,
      "summary": "Inverse\nkinematics (IK) provides a fast and robust method to position an arbitrary chain of\nbones so that an end bone attempts to align with a movable ‘effector.’ By providing\nsolutions in real-time, we allow characters to react spontaneously and uniquely to an\nunpredictable environment Key topics include bones, rotations, and rotational.",
      "keywords": [
        "bone",
        "RRS USE RAR",
        "ons pisncgronice Mot",
        "angle",
        "Quaternion",
        "effector",
        "Quaternion Compression",
        "Charles River Media",
        "parent",
        "world",
        "solution",
        "Game Programming Gems",
        "pisncgronice Mot",
        "parent reference world",
        "Euler Angles"
      ],
      "concepts": [
        "bones",
        "rotations",
        "rotational",
        "rotate",
        "rotated",
        "quaternion",
        "angle",
        "solutions",
        "solution",
        "limits"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 8",
          "chapter": 14,
          "title": "Segment 14 (pages 129-138)",
          "relevance_score": 0.6,
          "method": "api"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 31,
          "title": "Segment 31 (pages 611-631)",
          "relevance_score": 0.47,
          "method": "api"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 4,
          "title": "Segment 4 (pages 64-82)",
          "relevance_score": 0.43,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 7",
          "chapter": 12,
          "title": "Segment 12 (pages 108-115)",
          "relevance_score": 0.4,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 1",
          "chapter": 16,
          "title": "Segment 16 (pages 140-149)",
          "relevance_score": 0.38,
          "method": "api"
        }
      ]
    },
    {
      "number": 21,
      "title": "Segment 21 (pages 198-207)",
      "start_page": 198,
      "end_page": 207,
      "detection_method": "topic_boundary",
      "content": "2.5 Constrained Inverse Kinematics 199\n\n[Weber02] Weber, Jason, “Improved Bones Deformation,” Game Programming Gems\n3, Charles River Media, Inc., 2002.\n\n[Welman93] Welman, Chris, “Inverse Kinematics and Geometric Constraints for\nArticulated Figure Manipulation,” Masters Thesis, Simon Fraser University, Sep-\ntember 1993.\n\nThe author will make an effort to maintain a long-term archive and link site for some\nrelated resources at http://www.imonk.com/baboon/bones.\n\n2.6\n\nCellular Automata for\nPhysical Modeling\n\nTom Forsyth,\nMucky Foot Productions, Ltd.\ntomf@muckyfoot.com\n\nNi current game environments are mostly static. The sorts of things that move\n\nin games are restricted to either small, discrete objects, such as vehicles and peo-\n\nple, or sometimes some larger, mechanical, or prescripted objects. In some cases, the\nwater level in a container can move in scripted ways, but it is only a single horizontal\nplane that moves up or down, and there is no way for the player to directly interact\nwith it.\n\nIn the current state of the art of games, the following effects tend to be either\n\nfaked or not simulated at all:\n\nFire that spreads, ignites flammable objects, and causes damage to them.\n\nWater that can be held in containers, flow through pipes, be pumped around real-\nistically, walked through, weigh objects down, overflow containers, or spread over\nfloors and down slopes.\n\nOil that combines the fluid properties of water with the burning properties of\nflammable materials, such as wood.\n\nExplosions that have realistic damage radii, doing more damage indoors than out-\ndoors, and traveling around corners in realistic ways.\n\nHeat that causes air to rise, causes convection currents, can be pumped around by\nventilation fans, and possibly even carry scents and smells.\n\nSmoke and dust that spread with air currents, are generated by fires or smoke\ngrenades, obscure vision, and choke people.\n\nWalls and environments that can be damaged, destroyed, set on fire, moved, or\ngive limited protection from explosions and attacks.\n\nSome of these features have appeared in games, but usually in heavily scripted and\n\nconstrained ways; frequently they play little part in the actual gameplay and look arti-\nficial—which, of course, is exactly what they are. Using cellular automata (CA) to\nsimulate these ideas can lead to far more dynamic and realistic behavior, and allow\n\n200\n\n2.6 Cellular Automata for Physical Modeling 201\n\nnew types of gameplay and new tactics within games. At the very least, they allow\nmore realism, better graphical rendering, and therefore increase player immersion.\n\nCellular automata (CA), and their close relatives, finite element analysis (FEA) and\ncomputational fluid dynamics (CFD) [CFD], are already used in plenty of applica-\ntions for modeling air and water flow, heat distribution, building stresses and strains,\nand many other aspects of the real world. However, the main emphasis of the acade-\nmic and commercial modelers is on accuracy. As game programmers, our only real\nconcern is whether something looks good enough and runs quickly enough; and in\nalmost every case, the simulation can be enormously simplified while still looking per-\nfectly correct to most people.\n\nThe basics of a CA are simple. The world is divided into a grid of fixed-size cells.\nEach cell has various numbers associated with it to represent its state. Usual values\nheld in cells are the air pressure, temperature, amount of water, which direction the\nwater or air is flowing in, and so on.\n\nEach game turn, every cell is processed, and it compares itself with its neighbor-\ning cells. Differences between them result in changes to the state of the cell and/or its\nneighbors according to various laws. In this gem, these laws will be based very loosely\non real physical laws. One of the best-known CA is called “Conway's Game of Life”\n[Conway]. This is an extremely simple CA. It has a single bit of state—whether the\ncell is full or not—and some extremely simple rules for changing state according to\nthe state of neighboring cells. Nevertheless, even this simple model can give rise to\nsome extremely complex behavior.\n\nThe CAs used in games will have rules based on various physical models to deter-\nmine the amount of heat, air, water, or smoke that is transferred between neighboring\ncells. If we run the rules quickly enough on a sufficient number of cells, water will\nflow downhill and find level ground, gently heated air will form convection currents,\nand strongly heated air will burn objects and, in turn, be heated by the burning\nobjects.\n\nIn a three-dimensional array of cubic cells, there are three possible definitions of\n‘neighbor’ cells:\n\nSREB BBN B8\n\n_ ouuTaRRERRERERARAA\n\n¢ The six cells that share a face with the central cell.\n¢ Those 6, plus another 12 that share an edge with the central cell.\n¢ Those 18, plus another 8 that share a corner with the central cell.\n\nSurprisingly, the rules that are used for physics simulations give almost the same\nresults, whichever of the three definitions we use. Of course, the first version is far\nsimpler, and there is only one type of neighbor cell, rather than three. For this reason,\nit is far easier to only consider as neighbors the six cells that share a face with the cen-\n\ntral cell.\n\n202\n\nSection 2 Mathematics\n\nFirst, choose the physical size of a CA cell. For human-size games, we decided to\nuse cubes that are half a meter across. Any bigger, and a CA cell of air will not fit\ninside a narrow passageway. Smaller cubes give higher resolution and allow for smaller\nPipes, narrower gaps, and so on—but the extra space and processing is expensive. Dif-\nferent scales of games will naturally require a different size of CA cell; however,\nbecause most games are set on a human scale, for convenience, this gem will assume a\nscale of half-meter cube cells in its examples.\n\nAnother important consideration in a human-size game is how to model thin\nwalls. Most internal house walls and doors are only a few centimeters thick. They will\nstop water flow, slow fire down, and stop smoke and air spreading, so they must be\nmodeled in some way. Modeling them conventionally by using many small cells, and\nmarking those occupied by the wall as solid, would require using cells of no more\nthan about 10 cm across, which requires 125 times as many cells—an extremely\nexpensive option.\n\nTwo possible solutions present themselves. One method, used by the first of the\nX-Com series of games in their impressive and innovative use of CAs [XCom], is to\nmodel the faces between the cells as entities, as well as modeling the cells themselves.\nSo walls, floors, and ceilings always lie between two cells, along cell faces. This works\nquite well, but it does mean that there are now two distinct classes of objects—things\nthat fill a whole cube (e.g., rock, dirt, furniture, or tall grass) and things that sit\nbetween two cells (e.g., walls, floorboards, short grass, or doors). This creates annoy-\ning special cases in the code used to model substances and their interactions, and\ncauses code replication between the two types (spaghetti code). However, if this\nmodel fits, then it is a viable one, and it is fairly intuitive—the internal representation\nof objects matches their rendered shape fairly closely.\n\nThe other solution is one that retains its generality without resorting to many\ntiny cells. Rather than aligning cubic cells on a fixed grid, we allow the edges between\ncells to move about a bit according to the contents. This allows a thin wall to be\nchopped into half-meter squares, and each square lives in a cell. Because the walls are\nonly a few centimeters thick, we expand the neighboring cells to take up the extra\nspace. Even though the cells are no longer aligned on a grid, the CA code itself does\nnot know or care what shape the objects it represents are. As far as the CA physics are\nconcerned, everything is still half a meter thick. Most of the work in making things\nlook otherwise is in the rendering, rather than in the CA routines. It is the job of the\nrendering to ensure that water goes all the way to the wall’s mesh and not just to\nthe edge of the CA cube, which would leave a large gap. The only things that need to\nspread adaptively like this are volumetric effects, such as smoke, fire, and water. When\ndrawing a cell with one of these effects, the renderer needs to check each neighboring\ncell to see if its polygonal shape is smaller than the usual half-meter cube. If it is, it\nexpands the size of the volumetric effect to fill the space.\n\nIn this scheme, a one-meter-wide corridor with thin wooden walls is represented\nby a plane of ‘wood’ cells, a plane of ‘air’ cells, and then a plane of ‘wood’ cells. Since\n\n2.6 Cellular Automata for Physical Modeling 203\n\nthe centers of the cells are each half a meter away from each other, the total apparent\nwidth from wall to wall is still one meter. Of course, the graphical representation of\nthe world still shows that the ‘cubes’ of wood are not cubes at all, but flat planes a few\ncentimeters thick; and this is the representation that will be used for any collision\ndetection. But the distinction makes very little difference to the things that are mod-\neled with the CA. Because these entities are fairly amorphous, the difference between\nwhat is rendered (a one-meter gap) and what is actually being modeled (a half-meter\ngap) is very hard for the player to see. Again, accuracy is sacrificed for speed wherever\nthe game can get away with it.\n\nThe next factor to consider is a gameplay decision—the difference between using\nPassive scenery and active scenery.\n\nPassive Scenery\n\nIn this system, as far as the CA is concerned, the scenery is inert—it is not affected by\nthe actions of the CA in any way. This is the simpler of the two representations, but it\nstill allows discrete objects, such as the ubiquitous oil drum and crate, to float away on\nrivers of water or to explode or burn when heated by fire.\n\nBecause the CA only knows about cells, not polygons, the scenery must be con-\nverted into a cell representation—usually as a preprocessing step. These cells are sim-\nply marked as inert volumes that confine the actions of the CAs. Of course, the\nscenery is usually a collection of arbitrary polygons and is not aligned to cell bound-\naries. But the things being modeled with CAs are so amorphous that this difference\ndoes not matter in practice. As long as each solid polygonal wall is converted into a\ncontinuous wall of CA cells, water will not flow through and break the illusion.\n\nEven in this system, special cases should be made for doors that can be opened\nand other animate or moving objects. When doors are opened, they should remove\n(sliding doors) or move (swinging doors) the solid cells that represent them so that\nwater and/or fire can move through them.\n\nActive Scenery\n\nThe far more versatile and adventurous option is to have the scenery modeled by the\nCA as well. This opens up the ‘totally destructible world’ concept that many designers\nare looking to as the next big thing in games, though this concept is not truly new in\ncomputer games [XCom].\n\nIn this system, rather than simply being cells of inert material, scenery is modeled\nby its actual properties, such as temperature, flammability, and so on. As the cells\nmodeled with CA change their state according to the physical rules of the CA, the\ngraphics engine changes how it renders the associated polygonal objects (e.g., sooty,\ndamaged, etc.)\n\nIn the latter case, the graphics engine can either be of the ‘Geo-Mod’ type [Red-\nFaction], or the object itself can simply have been specially marked as destructible and\nhave an alternative, ‘broken’ graphical representation.\n\n204 Section 2 Mathematics\n\n\\sinieansomente iuennaciinmnataanron ooo. sek mame RAM aac Reena EAE MEERA AEDS HEA RASH EE CBI EAS A\n\nThose considering implementing these CA methods will have quickly noticed that\nstoring half-meter cells for even a modest-size level consumes a huge amount of mem-\nory, and the processing and memory bandwidth requirements become severe. The\napproach to doing this efficiently is to not store or process cells that are not partici-\npating in any interesting activities—notably inert walls and/or air at (standard) ambi-\nent temperature and pressure (STP).\n\nAn octree is ideally suited to storing this arrangement, specifically a dynamically\nallocated octree. In any implementation of the octree, remember that the most com-\nmon operation in a CA is “find the cell next to me,” so it makes sense to optimize for\nthis type of operation when implementing the octree. If this request is made and there\nis no neighboring cell in the octree, it is assumed that the neighboring cell is air at\nSTP. The physical simulations are carried out accordingly; and if they result in the\n‘missing’ cell becoming significantly different from STP, a cell with the new properties\nis created and inserted in the octree. When an air cell returns to within a certain tol-\nerance of STP, it is deleted from the octree and is no longer processed.\n\nThe octree holding CA cells can also be useful as a general-purpose octree. Many\ngames use octrees to optimize collision detection and visibility culling, and there is no\nreason the octree cannot fulfill both roles and hold objects not directly related to the\nCA. A fairly easy adaptation to the search algorithms allows the octree to become a\n‘loose octree’ [Ulrich00], which has several other advantages over a conventional\noctree. This does not change its behavior when dealing with the CA aspect of its\nbehavior, since all CA cells are aligned to regular intervals and have a fixed size.\n\nPractical Physics\n\nRATE see ERE\n\nA ne SSSR RP SRN\n\nThe main thing to remember when writing CA physics routines is to keep things sim-\nple. It is surprisingly easy to write very simple routines that take major physical short-\ncuts, yet look perfectly natural to the player. As long as the basics of conservation of\nmass and energy are retained—which is frequently optional—most of the other code\ndeals with keeping the simulations stable.\n\nThe major problem we encountered during implementation was finding good,\nsimple models of various physical features. Most of the standard references deal with the\napplication of Navier-Stokes equations for various materials and implementing them\nwith as little error as possible. This enormously complicates the code, and most of the\nacademic and commercial literature is concerned with these error reductions. For\ngames, what is required is simplicity, not accuracy. Most of the time, finding implemen-\ntations involved getting only the general feel of the behavior from the literature.\n\nCore Processing Model\n\nEB SAARI OER AH 08 RR ss - exter\n\nMost of the properties simulated by the CA work in similar ways. To illustrate these\ncommon methods, here is a very simple fluid simulation that just tries to achieve even\n\n2.6 Cellular Automata for Physical Modeling 205\n\ndistribution of pressure throughout the available space. Even this simplified model is\nvery useful for air and fluid modeling.\n\nfor ( neigh = each neighbor cell )\n{\nif ( neigh->Material->IsInert() ) continue;\nfloat DPress = cell->Pressure — neigh->Pressure;\nfloat Flow = cell->Material->Flow * DPress;\nFlow = clamp ( Flow,\ncell->Pressure / 6.0f,\n-neigh->Pressure / 6.0f );\ncell->NewPressure -= Flow;\nneigh->NewPressure += Flow;\n\n}\n\nThe clamp() operation is performed to prevent NewPressure from going negative.\nThe division by six is because there are six neighbor cells. In practice, even more\ndamping might be needed to retain stability and prevent small oscillations, such as\nwaves on the surface of water, from becoming unrealistic oscillations.\n\nConventionally, once all the cells have been processed in this way, the NewPres-\nsure values are copied to the Pressure values. This double-buffering is necessary,\nrather than simply writing directly to Pressure at the end of the routine. Otherwise,\npressure will be transmitted extremely fast (sometimes instantly) in the direction that\nthe cells are updated, and much slower in the reverse directions. This produces obvi-\nous asymmetry in heat distribution, water flow, and other processes.\n\nThe double visit to each cell can hurt performance considerably, especially as\nthe second visit is simply a copy, and will be limited by memory bandwidth on\nmost modern CPUs. A better method is to store the last turn that a cell was\nprocessed. When subsequently processing that cell, the turn number is checked; and\nif it is earlier than the current turn, the copy is done. Although slightly odd-looking,\nthis is in fact much quicker than scanning the whole array of cells twice. The code\nbecomes:\n\nif ( cell->Turn != CurrentTurn )\n\n{\ncell->Turn = CurrentTurn;\ncell->Pressure = cell->NewPressure;\n}\nfor ({ neigh = each neighbor cell )\n{\nif ( neigh->Material->IsInert() ) continue;\nif ( neigh->Turn != CurrentTurn )\n{\n\nneigh->Turn = CurrentTurn;\nneigh->Pressure = neigh->NewPressure;\n\n}\n\n// same physics code as before\n\n206\n\nAir\n\n“Se a ome REINER DK wis 4ST NN Ee RELA\n\nWater\n\nSMR AEHASLA Sone tc cisions\n\nMS GR aR SAU LEASED DER A ENG SET TIE BRAS\n\nThis simple model works well for uniform redistribution of air pressure. At first\nglance, this is not something that is frequently modeled in games. But in fact, it is one\nof the most common effects—explosions and their effects on things. An explosive is\nsimply a lump of material that produces a huge amount of air in a very short time.\nThey can be modeled through the following steps. First, find the nearest CA cell to\nthe center of an exploding grenade. Second, add a large number to the cell’s pressure.\nThird, let the CA propagate the pressure through the world. Damage is done to the\nsurroundings by either high absolute pressures or high pressure differences—in real-\nity, both do different kinds of damage to different objects; but that is usually unnec-\nessary complication for the purposes of a game.\n\nThe advantages of this method of modeling over conventional ones is that\nline-of-sight is handled automatically. Explosions in confined spaces are far more\ndeadly at a certain range than explosions in open spaces because there is less space for\nthe pressure to dissipate. In addition, it shows that pure line-of-sight is not protection\nenough from explosions—they do go around corners and obstructions to a certain\ndegree.\n\nBecause the simulation of the flow of air is qualitatively correct to the human eye,\ndebris and small objects can be carried along with the explosion; you don’t have to\nworry about the illusion being shattered by debris going the wrong way or through\nsolid walls.\n\nRRR RENN SRR RA 8 ARO HHA Num esRoRERNRE\n\nWater is only slightly more complex than air. The obvious distinction is that air\nexpands to fill the available space with cells changing pressure to do so, while water\nstays at the bottom of its container and is incompressible.\n\nIn fact, the easiest way to simulate the transmission of pressure through water is\nto make it slightly compressible. This means pressure can be stored as a slight excess\nmass of water in the cell, above what the cell’s volume should be able to hold. In prac-\ntice, the amount of compression needed is tiny—allowing just 1% more water per cell\nper cube height is easily enough. In a static body of water whose cells can normally\ncontain 1.00 liter of water each, the cells at the top will contain 1.00 liter, the ones\nunder them will contain 1.01 liters, the cells under those will contain 1.02 liters, and\nso on to the bottom. This tiny amount of compression will be completely unnotice-\nable to the player, but it has enough dynamic range to allow all the usual properties of\nliquids. For example, the levels of water in two containers joined by a submerged pipe\nwill be the same, even if water is poured into one of them; it will flow through the\npipe to the other container.\n\nif ( neighbor cell is above this one )\n\n{\nif ( ( cell->Mass < material->MaxMass ) ||\n\n2.6 Cellular Automata for Physical Modeling 207\n\n( neigh->Mass < material->MaxMass ) )\n\n{\nFlow = cell->Mass - material->MaxMass;\nyelse{\nFlow = cell->Mass — neigh->Mass\n- mMaterial->MaxCompress;\nFlow *= 0.5f;\n}\n}\nelse if ( neighbor cell is below this one )\n{\nif ( ( cell->Mass < material->MaxMass ) ||\n({ neigh->Mass < material->MaxMass ) )\n{\nFlow = material->MaxMass - neigh->Mass;\n}else{\nFlow = cell->Mass — neigh->Mass\n+ material->MaxCompress;\nFlow *= 0.5f;\n}\n}\nelse // neighbor is on same level\n{\nFlow = ( cell->Mass — neigh->Mass ) * 0.5f;\n}\n\nThis Flow value is then scaled and clamped according to some measure of the\nmaximum speed that the fluid can flow, allowing some fluids to appear more viscous\nthan others, and to prevent any resulting masses from going negative.\n\nThe two cases of code for the water model deal with different situations. The first\ncase is where one of the two cells is not full of water—such as on the surface of a body\nof water or if the water is splashing or falling (e.g., in a waterfall). Here, the behavior\nis simple—water flows downward to fill the lower cell of the two to the value Max -\nMass—the mass of water that can be contained by a single cell’s volume. In the previ-\nous example, the mass is one liter of water.\n\nThe second case is where both cells are full of water, or perhaps a bit over-full,\nsuch as in the middle of the body of water. Here, the flow acts to try to make sure that\nthe upper cell has exactly MaxCompress more water than the lower cell. MaxCompress is\nthe amount of ‘extra’ water that can be fitted in because of compression. In the previ-\nous example, it would be the mass of 0.01 liters of water.\n\nFlow\n\nSo far the air and water models have ignored a fairly important property of any liquid\nor gas—its speed of flow. We have simply taken the difference in pressures between\ntwo cells and used that to move mass around. This is fine for relatively static environ-\nments that we wish to bring to a stable state, such as uniform air pressure or water\nfinding its level. Many games will only use these simple properties for all the game-\nplay and realism they need.\n\nSection 2 Mathematics\n\nHowever, what happens in real life is that water and air have momentum (which\nequals flow times mass), and the difference in pressure only influences the flow\nbetween cells; it does not rigidly set it. Storing momentum or flow is important when\nmodeling waves, flowing rivers, and air currents. Although rivers can flow in models\nwithout momentum, they have a very visible slope of at least 10°, which looks very\nbizarre.\n\nTo model momentum or speed of flow during each processing step, the difference\nin masses determines the pressure gradient, as before. However, instead of changing\nthe masses of the cells directly, the pressure gradient only alters the flow between the\ncells. The flow then changes the masses in the cells. The code is slightly more complex\nbecause flow is a three-dimensional vector and not a scalar like mass.\n\nThere are two possible ways to think about flow. The first is to think of a flow\nvector as being the flow through the center of the cell. This is possibly the most intu-\nitive model—the flow and the mass of the cell are both measured at its center. How-\never, in this case, the flow is affected by the pressure differential between the two\nneighboring cells, which in turn determines how mass flows from one neighboring\ncell to the other. Note the slightly odd result that, for a particular cell, the flow stored\nin it is not affected by the mass in the cell itself, but only by its neighbors. Nor does it\nchange the mass of the cell, but only the mass of its neighbors’ cells. This is a slightly\nsurprising result; and in some cases, this can lead to odd behavior.\n\nIt is more useful to think of each component of the flow vector as being the flow\nbetween two adjacent nodes—from the ‘current’ node to the node in the positive rel-\nevant direction. Thus, the flow vector F stored at cell (x, y, z) is interpreted as mean-\ning that F, is the flow from cell (x, y, z) to cell (x + 1, y, z); F,is the flow from cell\n(x, y, 2) to cell (x, y + 1, z); and, similarly, for F,. The ‘meaning’ of the vector F is now\nnot as intuitive, but the physical model does seem more sensible. In practice, this is\nthe most common model; but either model can be used for simulation with appropri-\nate adjustment of the various constants.\n\nThe most important step in this model is to carefully control oscillations. Not\nonly does this model allow waves, but it also tends to encourage them to build up,\nand sufficient damping must be applied to the flow by introducing a simple friction\ncoefficient. Otherwise, waves can build up higher and higher instead of dying down,\nand the liquid or gas starts to do very odd things indeed.\n\nIt is worth mentioning that, although one of the most common applications of\nflow is in rivers, in most ‘human-size’ games, large bodies of water, such as lakes and\nrivers, are frequently far too large to participate in gameplay. Their behavior will stay\nfairly constant whatever the player does; and if they do change, they will do so in\nhighly constrained ways. They do not usually require the flexibility of a CA and are\noften far better modeled and rendered in more-conventional ways. We can use pre-\nanimated meshes, collision models, and scripted events. However, there are many\nother genres that operate on larger scales and will want to properly simulate rivers\n\nwith a CA.",
      "page_number": 198,
      "chapter_number": 21,
      "summary": "This chapter covers segment 21 (pages 198-207). Key topics include cells, modeling, and flowing. The sorts of things that move\n\nin games are restricted to either small, discrete objects, such as vehicles and peo-\n\nple, or sometimes some larger, mechanical, or prescripted objects.",
      "keywords": [
        "Improved Bones Deformation",
        "cell",
        "Charles River Media",
        "flow",
        "Improved Bones",
        "Bones Deformation",
        "water",
        "mass",
        "Inverse Kinematics",
        "pressure",
        "Constrained Inverse Kinematics",
        "air",
        "Game Programming Gems",
        "neighbor cell",
        "games"
      ],
      "concepts": [
        "cells",
        "modeling",
        "flowing",
        "water",
        "physical",
        "physics",
        "pressure",
        "objects",
        "ways",
        "way"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 7",
          "chapter": 10,
          "title": "Segment 10 (pages 91-99)",
          "relevance_score": 0.63,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 22,
          "title": "Segment 22 (pages 205-213)",
          "relevance_score": 0.6,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 1",
          "chapter": 30,
          "title": "Segment 30 (pages 279-290)",
          "relevance_score": 0.58,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 7",
          "chapter": 64,
          "title": "Segment 64 (pages 617-624)",
          "relevance_score": 0.57,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 7",
          "chapter": 62,
          "title": "Segment 62 (pages 601-608)",
          "relevance_score": 0.56,
          "method": "api"
        }
      ]
    },
    {
      "number": 22,
      "title": "Segment 22 (pages 208-217)",
      "start_page": 208,
      "end_page": 217,
      "detection_method": "topic_boundary",
      "content": "2.6 Cellular Automata for Physical Modeling 209\n\ncesarean sosiececssetenenne .\n‘Transmitting heat through the environment, whether from burning objects or from\nother sources, happens through three separate mechanisms: conduction, convection,\nand radiation.\n\nConduction\n\nConduction is the simplest mechanism to simulate. Neighboring cells pass heat energy\nbetween each other so that eventually they reach the same temperature. This is com-\nplicated because different materials are heated by different amounts by the same\nenergy—called the specific heat capacity (SHC), which is usually measured in J/kg°C.\nIfa hot cell made of water (high SHC and hard to heat up) is next to a colder cell made\nof the same mass of iron (low SHC), equilibrium will be reached at somewhere very\nclose to the original temperature of the water, not at the average of the two tempera-\ntures. This is because when a given amount of energy is transferred from the water to\nthe iron, the water’s temperature drops far less than the iron’s temperature rises.\n\nNote that the above example is true for the same mass of each substance. How-\never, iron has a far greater density than water; and therefore, for the same volume, they\nhave very similar heat capacities.\n\n// Find current heat capacities.\nfloat HCCell = cell->material->SHC * cell->Mass;\nfloat HCNeigh = neigh->material->SHC * neigh->Mass;\nfloat EnergyFlow = neigh->Temp - cell->Temp;\n// Convert from heat to energy\nif ( EnergyFlow > 0.0f )\nEnergyFlow *= HCNeigh;\nelse\nEnergyFlow *= HCCell1;\n// A constant according to cell update speed.\n// Usually found by trial and error.\nEnergyFlow *= ConstantEnergyFlowFactor;\nneigh->Temp -= EnergyFlow / HCNeigh;\ncell->Temp += EnergyFlow / HCCell;\n// Detect and kill oscillations.\nif (((EnergyFlow>0.0f)&&(neigh->Temp<cell->Temp) ) | |\n( (EnergyFlow<=0.0f) &&(neigh->Temp>cell->Temp) ) )\n\n{\nfloat TotalEnergy = HCCell * cell->Temp +\nHCNeigh * neigh->Temp;\nfloat AverageTemp = TotalEnergy /\n( HCCell + HCNeigh );\ncell->Temp = AverageTemp;\nneigh->Temp = AverageTemp;\n}\n\nThe code at the end is necessary if two materials with very different SHCs are side\nby side. In this case, the temperatures of the two can oscillate violently and can grow\n\n210\n\nSection 2 Mathematics\n\nout of control. The physically correct solution is to integrate the transfer of heat over\ntime. However, this approach simply finds the weighted average temperature, which\nis the temperature that the system would reach eventually. It is less accurate, but looks\nperfectly natural and is quite a bit quicker to execute. Importantly, it obeys the law of\nconservation of energy, so any artifacts are purely temporary. The longer-term state is\nthe same as a more realistic simulation.\n\nConvection\n\nConvection is the phenomenon of heat rising. Hot areas of fluid, such as air or water,\nare less dense than cold areas, and thus try to rise. This can be simulated by incorpo-\nrating temperature into the model of water or air. If a flow model is being used, the\nflow will be influenced by the relative temperatures of cells as well as their relative\npressures. Otherwise, convection does not work very well, though its effects can be\nfaked as described in the section on fire.\n\nRadiation\n\nHot things glow. They emit light at various wavelengths, which travels in straight\nlines, hits other surfaces, and in turn heats them up. This effect is very important\nphysically, but unfortunately it is also extremely expensive to model. Each source of\nheat must effectively shoot many rays out from itself and heat up whatever they hit.\nRadiative heat modeling is very similar to the radiosity modeling that is used\nwhen creating lightmaps for many current games. Both are extremely expensive to\nmodel in runtime, even crudely, though there are some cunning methods that use a\nheavy amount of approximation to improve the speed of radiative heat modeling.\nEven with these algorithms, modeling even a fraction of the radiative heat seems like\na prohibitive amount of work for a game. These algorithms are also extremely com-\nplex and do not involve the standard cell-to-cell interactions that model all the other\nphysical properties mentioned. For both these reasons, we won't discuss them here.\n\nThe physics of burning materials is frequently extremely complex. There are multiple\nparts that burn at different rates and heats, and there are also different phases of mate-\nrial involved in the process.\n\nTo perform the calculations in real-time, the material models used during the\nprocess need to be trimmed down to their minimum; and for each material, an appro-\npriate model must be chosen that emphasizes the main characteristic.\n\nOf the many models considered, the one that finally seems to give the best results\nfor the least amount of effort is a quadratic approximation of an exponential graph. This\ngraph shows how much heat energy is released per unit of time when a substance burns\nat a certain temperature. There is a maximum amount of energy that can be released, no\nmatter how hot the fire gets. But even at relatively cool temperatures, a lot of heat is\n\n211\n\nreleased. This explains why open fires tend to start small, rapidly grow to a certain size,\nand then not grow any bigger, yet burn for a long time, despite ample availability of fuel.\nThey are simply not generating enough heat energy to compensate for the heat lost to\nthe environment (which is directly proportional to the temperature).\n\nfloat Temp = cell->Temp — material->Flashpoint;\n// Damage the cell.\nCellDamage = Temp * material->BurnRate;\nfloat Burn;\n// Convert to actual burning value.\nif ( Temp > material->MaxBurn * 2 )\nBurn = material ->MaxBurn;\nelse\nBurn = ( 1.0f - ( 0.25f * Temp / material->MaxBurn ) ) * Temp;\nASSERT ( Burn <= material->MaxBurn );\nASSERT ( Burn >= 0.0f );\n// And heat the cell up from the burning.\ncell->Temp += Burn * material->BurnTemp;\n\nNote that the damage done to a cell is proportional to its actual temperature, not\nhow much heat is generated by burning. This allows materials that burn at low tem-\nperatures to nevertheless be far more severely damaged if exposed to high tempera-\ntures. By varying the factors MaxBurn and BurnTemp, burning anything can be\nsimulated—paper, wood, oil, gunpowder, or high explosives.\n\nOf course, one of the major aspects of fire is that it is hot, and thus it relies heav-\nily on the modeling of heat flow by the three methods discussed previously. In real-life\nfires, convection and radiation are incredibly important to their behavior. Convection\nmakes fires spread vertically far easier than spreading horizontally, such as across\nfloors, and leads to distinctive ‘walls of fire’ in burning buildings. Radiation concen-\ntrates fire in corners of rooms, causing fire to spread up the corners of the room first.\n\nSadly, radiative heat, as mentioned above, is extremely hard to model, and con-\nvection, although slightly more straightforward, requires large numbers of air cells\naround the source of the fire to be modeled and updated, which is expensive. It would\nbe far better to find some hacks that simulate some of these features without incurring\nthe considerable expense involved.\n\nA hack for convection effects is simply to make conduction of heat far easier in an\nupward direction. In real life, a section of burning wall heats the air beside it, which\nrises and heats the section of wall higher up. This makes it far easier for the flames to\nspread upward. Using this hack, conduction of heat is made artificially asymmetrical.\nIn the model presented above, a single factor—CconstantEnergyFlowFactor—was\nused for heat conduction for all six neighbors of a cell. Instead of this, a higher figure\nis used when conducting heat upward and a lower figure when conducting heat\ndownward.\n\nA hack for radiation is more difficult, but it is possible that some precomputation\ncould be done using the same techniques as radiosity to decide which parts of a room\n\n212\n\nSection 2 Mathematics\n\nDynamic Update Rates\n\nwould be more susceptible to fire because of the feedback effects of radiative heat.\nOne possibility is computing the hemispherical occlusion term [Hemispherical01]\nand using that to boost the heat generated by fire—generally around edges and\ncorners.\n\nA factor that might not be immediately obvious is that these hacks are far more\ncontrollable than any realistic solution. Convection in real life is a notoriously chaotic\nsystem, and small changes in conditions can cause it to adopt very different patterns\nof flow. This can make designing gameplay around the effect very tricky indeed.\nWhat game and level designers usually require is a high degree of control and pre-\ndictability to carefully create exciting set-pieces for the player to experience. The\nhacks presented above are far more predictable and linear in their behavior, which is\nusually a far more desirable quality in a game than absolute realism.\n\nThe natures of some of the physic\nupdate rates to maintain realism. The flow of any property from one cell to another\ncan only proceed at a maximum speed of one cell per update cycle. Fire might spread\nquickly—at meters per second or faster. Water spilling from a container might move\neven faster—at tens of meters per second. Explosions require extremely high update\nrates—real-life explosion shock waves spread at the speed of sound, roughly 340 m/s.\n\nSimulating all of the above implies that update rates of 680 cycles per second\ncould be required. This is an awesome speed, and it seems unlikely that any current\nplatform can sustain these sorts of update rates for a decent-size game world.\n\nAs with the optimization of not storing or processing cells at STP, it is possible to\nuse the octree to reduce the update rates for cells that do not require fast updates to\nmaintain realism.\n\nWhen a cell is processed, it decides how fast it needs to be updated to maintain a\ngood simulation, based on its current state. Cells involved in explosions require high\nupdate rates; cells holding flowing water, burning objects, or high heat need medium\nupdate rates; cells with fairly static water require lower update rates; and cells that\nhold scenery at ambient temperature require no processing at all until disturbed.\n\nThis speed of processing is then stored in the cell and is also passed up the octree\nhierarchy, each level being marked so that it is processed at the highest update rate of\nany of its children. This then allows the update routine to start at the top node of the\noctree and recurse down the tree. At each level, it decides if the current node would\nrequire processing of the all the child nodes.\n\nOne point to note is that this system only works if the update rates are quantized\nto powers of two. For example, if a child node needs to be updated every third turn,\nbut the parent node is marked as being updated every second turn, every sixth turn\nthe child node needs updating, but the parent does not. Because of the traversal algo-\nrithm’s early-out path, the child does not get updated this time, and in the end only\n\n2.6 Cellular Automata for Physical Modeling _ 213\n\ngets updated every sixth turn. Quantizing update rates to powers of two solves this\nproblem and also allows some slight extra storage efficiency.\n\nAn obvious consequence of this variable update rate is that the physics routines\nneed to be able to handle variable update rates as well. So far, all the code has assumed\nthat it will be run at a set speed, and that the physical constants will be adjusted to\ngive good results for that speed. With variable update rates, the physically correct\nbehavior is to integrate the various equations over the given period. However, one of\nthe purposes of the variable update rate is to choose an update rate that ensures the\ncells have a fairly constant behavior over the update interval.\n\nThis assumption makes integration simple. We just multiply the given behavior\nflow or rate by the time period since the last update. This slight extra complication is\nmore than offset by the savings in processing time and memory bandwidth because of\nthe huge reduction in the number of cells updated per second.\n\nIn many cases where the mathematics are simple, it might be more efficient to\nactually perform the integration. The extra accuracy of the simulation will then allow\nthe use of an even lower update rate, further improving speed overall.\n\nAn unexpected artifact of using a variable update rate can occur when neighbor-\ning cells have very different update rates. Since one cell is being updated much more\nfrequently than its neighbor, it can change rapidly before the other cell has time to\nreact. The solution is to limit the maximum difference in update rates of adjacent\ncells. Every time a cell is processed, as well as exchanging temperature, heat, and sim-\nilar information with neighboring cells, it also ensures that those cells are being\nupdated at least a quarter as fast as itself. We found this factor purely by experimenta-\ntion. Using a factor of two causes too many cells to have their update rates raised\npointlessly by nearby events, when in fact nothing exciting is happening to them.\nUsing a factor of eight or more allows more possible artifacts, but does not reduce the\nprocessing load appreciably. As with the many arbitrary factors that are found by pure\nexperimentation, others should experiment to find what works best.\n\nsituations rarely seen in games today. They allow the player to interact with them\nfully, flexibly, and logically, without the limitations of prescripting. This opens the\nway for more inventive puzzles, more lateral thinking by the player, more freedom to\nexperiment, more realistic rendering, and overall better immersion in the game world\nas a real place, rather than as a collection of polygonal entities.\n\n[CFD] There are innumerable references to the field computational fluid dynam-\nics. Unfortunately, most assume graduate physics knowledge or an extremely firm\n\n214\n\nSection 2 Mathematics\n\nrasp of 3D calculus. One of the more comprehensible of these can be found at\nFeepy/ /www.efunda.com/formulae/fluids/overview.cfm.\n\n[Conway] http://www.dmoz.org/Computers/Artificial_Life/Cellular_Automata/\nConway’s_Game_of_Life/.\n\n{Hemispherical01] “Advanced Shading and Lighting,” presentation at Meltown\n2001: pp. 22-35. Available online at Attp://www.microsoft.com/mscorp/corpevents!\nmeltdown2001/ppt/DXGLighting ppt.\n\n[LorensenCline87] Lorensen, W. E. and Cline, H. E., “Marching Cubes: A High Res-\nolution 3D Surface Reconstruction Algorithm,” Computer Graphics Proceedings\n(SIGGRAPH 1987), Vol. 21, No. 4: pp. 163-169.\n\n[RedFaction] Red Faction, developed by Volicion, Inc. Published by THQ, Inc., 2000.\n\n[Ulrich00] Ulrich, Thatcher, “Loose Octrees,” Game Programming Gems, Charles\nRiver Media, Inc., 2000.\n\n[XCom] X-Com: UFO Defense (U.S.) or X-Com: Enemy Unknown (U.K.), Micro-\nprose, 1994, http://www.codogames.com/UFOUnknownDefense.htm.\n\n2.7\n\nCoping with Friction in\nDynamic Simulations\n\nMiguel Gomez\nkikomu@seanet.com\n\nYur at a playground, holding a block of wood. You stand at the base of a slide\nand shove the block of wood up the ramp. The block slides to the middle of the\nramp, reverses direction, and slides back down to the bottom of the ramp.\n\nYou place the block at the fulcrum of a balanced seesaw and grab one of the ends.\nAs you slowly tilt the seesaw, the block remains stationary at first, but then begins to\nslide down the seesaw. As you increase the tilt, the block slides faster, and eventually\nends up at your feet again.\n\nCan your physics model for friction handle all these cases correctly? For extra\ncredit, can it do all this work without resorting to strange magic numbers and toler-\nance checking?\n\nModeling dry frictional forces is an important aspect of simulating mechanical\nsystems. However, standard numerical integration schemes can fail, since friction is\ndiscontinuous with respect to velocity. This gem uses some simple one-dimensional\nexamples to provide an intuitive understanding of the Coulomb model of friction and\nto illustrate numerical problems that arise when simulating frictional systems. A\nthree-dimensional formulation is given, and a simple numerical method for comput-\ning the trajectory of an irrotational object, sliding and sticking under friction over a\nsurface of constant incline, is presented. Important issues in extending this method to\ncurved surfaces and polygonal surfaces are also discussed.\n\nto existing relative motion between two objects at their region of contact, and static\nfriction (also known as stiction), which equalizes forces tangent to the surface that\nwould otherwise initiate relative motion at a stationary region of contact. The fol-\nlowing examples illustrate the essential differences between static and dynamic\nfriction.\n\n215\n\n216\n\nSection 2 Mathematics\n\n(peat mt Sta HON AE I 2A: AS Cae OSCE\n\nA System with Dynamic Friction\n\nFor our first example, suppose a block is placed on a flat surface. At time ¢ = 0, it\nis given an initial velocity v) > 0 in the x* (positive x) direction, as in Figure 2.7.1.\n(Note that in general, velocity is a vector. Since we are working in one dimension,\nscalar values suffice.) Experiments show that this block will decelerate at a constant\nrate until it comes to rest at some time ¢, after which it remains stationary. Further-\nmore, the rate of deceleration is independent of the block’s mass, m, and is propor-\ntional to the gravitational acceleration, g. If instead we had given the block an initial\nspeed v < 0 in the x direction, friction would have again decelerated the block until\nit had stopped. We can conclude that friction always acts opposite the velocity, v, of\nthe block and that friction exerts no force on the block when v = 0. This implies that\na correct formulation of dynamic friction for this one-dimensional system is:\n\n—sgn(v)u,N when v # 0\n= (2.7.1)\n\n0 when v = 0,\n\nwhere |, is the coefficient of dynamic friction and N is the magnitude of the normal\nforce; that is, the force exerted on the object by the surface in the normal direction (z*\nin this example). Equation 2.7.1 constitutes a one-dimensional formulation of\ndynamic Coulomb friction [Stewart00]. Even though our block exists in the x and z\n\nN= -Fg=mg\n\nFIGURE 2.7.1 A block set in motion on a flat surface will decelerate at a constant rate\nuntil it comes to rest. This rate of deceleration is proportional to gravitational\nacceleration by the coefficient of dynamic friction Ly.\n\n2.7 Coping with Friction in Dynamic Simulations 217\n\naxes, friction is represented as a scalar value, so it’s okay in this simple example to\nthink of friction as a one-dimensional force.\n\nIn this example we assume the block has no motion along the z direction; there-\nfore, the net force in this direction is zero, and N must be exactly equal and opposite\nthe gravitational force mg. By Newton's second law we know that x(z), the x position\nof the block as a function of time ¢, satisfies the system of differential equations:\n\na) = ot) (2.7.2a)\nL\nd’x(t)  do{t\n\nSuppose again that vy > 0. Since v will not change sign before the block stops, the\nsgn(v) term can be omitted, and Equation 2.7.2b can be integrated directly to yield an\nexplicit formula for v(2):\n\nv{t) t\ndv = -{ Ljgat => v(z) = vy — Mgt. (2.7.3)\nC7) 0\nIf the initial x-position of the block is xp = 0, integrating Equation 3 gives\nx(t) t\n[ dx = [ vy — Hygtat = x(z) = Uot — + Ma&t- (2.7.4)\nThe exact time and position at which the block comes to rest are:\n= % (2.7.5a)\nHig\nand\n2\nx, = x(z,) = +20 (2.7.5b)\n2 Hig\nrespectively. For all times ¢ 2 ¢,, the block has stopped; in other words, the solution is\nsimply:\nx(¢) = x,,and o(z) = 0. (2.7.6a, b)\n\nThe position, velocity, and acceleration of the block over time are plotted in Fig-\nure 2.7.2. Notice that the acceleration of the block has a jump discontinuity (an\ninstantaneous change in value) at ¢,. This discontinuity must be taken into account when\nwe develop a numerical method for computing the trajectory of the block.\n\nCoefficients of friction depend on both the apes of surfaces and on the condition\nof the surfaces in contact. See [Beer62] for a table of static friction coefficients for\nsome common surfaces.\n\n218 Section 2 Mathematics\n\nserena vnc re yer RLSM: MA RNA A SRD HRN REE RT ER\n\n4 xv\n\n(b) t\n\n“h a9 ——e\n\n(c)\n\nFIGURE 2.7.2 Plots of (a) position, (b) velocity, and (c) acceleration of a block sliding along a\nflat surface subject to friction. Acceleration goes to 0 instantaneously when v = 0 at time t,,\n\nA System with Static Friction\n\nSuppose now that our block is placed on a platform at an incline @ > 0; and for\nsimplicity, let the x-axis be aligned with the platform and the z-axis point in the nor-\nmal direction. Assume that the block is initially stationary, as in Figure 2.7.3. For\nmost, if not all dry surfaces, there exists some angle @, > 0 below which the block\nremains stationary and above which the block begins to slide. Static friction can there-\nfore be thought of as a constraint force that must satisfy:\n\nFf. <u; (2.7.7)\nwhere is the coefficient of static friction.\n\nFirst, suppose that the incline of the platform is at an angle @ < @, so that the\nblock is stationary. This implies that the frictional force is equal and opposite the x\ncomponent of the gravitational force. When @ = @,, static friction is at its maximum\npossible value (the authors of [Pfeiffer92] refer to this state as “friction saturation”) so\n\nthat\nfi = UN. (2.7.8)\n\nThis implies the relationship",
      "page_number": 208,
      "chapter_number": 22,
      "summary": "This chapter covers segment 22 (pages 208-217). Key topics include cells, heat, and friction. ‘Transmitting heat through the environment, whether from burning objects or from\nother sources, happens through three separate mechanisms: conduction, convection,\nand radiation.",
      "keywords": [
        "Update Rates",
        "heat",
        "Temp",
        "block",
        "update",
        "cell",
        "Friction",
        "rates",
        "Transmitting heat",
        "variable update rate",
        "high update rates",
        "dynamic friction",
        "static friction",
        "temperature",
        "time"
      ],
      "concepts": [
        "cells",
        "heat",
        "friction",
        "update",
        "updated",
        "temperature",
        "burning",
        "modeling",
        "simulate",
        "simulation"
      ],
      "similar_chapters": [
        {
          "book": "Game_Engine_Architecture",
          "chapter": 34,
          "title": "Segment 34 (pages 673-695)",
          "relevance_score": 0.4,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 21,
          "title": "Segment 21 (pages 197-204)",
          "relevance_score": 0.32,
          "method": "api"
        }
      ]
    },
    {
      "number": 23,
      "title": "Segment 23 (pages 218-225)",
      "start_page": 218,
      "end_page": 225,
      "detection_method": "topic_boundary",
      "content": "220\n\nSection 2 Mathematics\n\nIt might seem that the explicit formula for x(z) derived above could be used to cal-\nculate the exact position at the times we want to display the particle. Unfortunately,\nthis approach only works for flat surfaces. For a general curved surface, an explicit for-\nmula cannot be found, so we are forced to find a time-stepping scheme that gives the\nposition at subsequent times.\n\nWe'll start by implementing friction naively and see why discontinuity of acceler-\nation is a real problem when implementing game code. Then, we'll change our fric-\ntion model slightly to try to work around the acceleration problem. Last, we'll\npropose an altogether better mathematical model that takes care of these problems\nfor us.\n\nFirst Approach: Euler’s Method\n\nConsider the first example: a block sliding on a flat surface. Given the position x(2)\nand velocity v(¢) at time ¢, we might try to calculate the position and velocity of the\nblock at a later time, ¢ + 4, in the following way:\n\nx(t +h) = x(t) + hor) (2.7.10a)\n\n)\n\no(t +h) = oft) - A sgn(o(e))u ag (2.7.10b)\n\nThis intuitive approach is called Euler's method [Gerald97]. Due to its simplicity\nand speed, this is the integration method of choice for many game programmers.\n\nLet x = 0, u% = 1, m= 1, By= 1, g= 9.81, and 4 = 0.02. The exact solution indi-\ncates the block will come to rest after ¢, = 0.10194 seconds at a position x, = 0.05097\nmeters. Table 2.7.1 gives the numerical output of Euler’s method for this initial value\nproblem.\n\nTable 2.7.1 Positions and Velocities Resulting from Euler's Method for a Block Slid-\ning on a Flat Surface\n\nt x(t) v(t)\n\n0.00 0.00000 1.0000\n0.02 0.02000 0.8038\n0.04 0.03608 0.6076\n0.06 0.04823 0.4114\n0.08 0.05646 0.2152\n0.10 0.06076 0.0190\n0.12 0.06114 0.1772\n0.14 0.05760 0.0190\n0.16 0.05798 0.1772\n0.18 0.05443 0.0190\n\nNote: The numerical values never converge due to the discontinuity of acceleration at v = 0.\n\n2.7 Coping with Friction in Dynamic Simulations (221\n\nNumerical calculations nearly stop the block after about 0.1 seconds at 0.061\nmeters. Since Euler’s method is only first-order accurate, some error should be\nexpected. What is alarming, however, is that not only does v never converge to zero,\nbut it oscillates about zero asymmetrically so that x actually decreases at a constant rate\nfor times ¢ > ¢. An animation would show the block turning around and moving back\ntoward the origin! .\n\nIt might seem practical to solve this problem by simply setting v to zero when its\nmagnitude falls below some threshold v, > 0. Unfortunately, tuning these types of\n‘magic numbers’ so that a particular system looks intuitively correct is an art. Finding\nvelocity thresholds that work for simulations involving several objects of different\nmasses and friction coefficients requires a lot of time and testing. In essence, it’s nec-\nessary to test each object affected by friction against every surface type on which it\nmight possibly rest. We've simply traded one problem for another, less-tractable one.\nAs we shall see later, velocity thresholds cause more serious problems when evaluating\ntransitions between dynamic and static friction.\n\nSecond Approach: Reformulating Friction\n\nIn retrospect, it now seems obvious that Euler's method would fail for this problem.\nWhen 1 is ‘small,’ our integration method will cause v to overshoot zero and change\nsign. On the following step, acceleration is in the opposite direction, which causes v\nto change sign again. Since v oscillates asymmetrically about zero, the position gets a\nnet translation every two steps.\n\nInstead of fixing the numerical method, we might be tempted to modify our for-\nmulation so that friction is continuous at v = 0. One option is to replace the Coulomb\nformula with viscous damping:\n\nf =-m,N. (2.7.11)\n\nUnfortunately, this formula will cause the block to decelerate too quickly at high\nspeeds and not quickly enough at low speeds. Animations using this formula simply\n\nlook unnatural.\nAnother possibility is to regularize friction (see [Abadie00] or [Stewart00]) so that\n\n-~u,N , when | Sv,\nfai % (2.7.12)\n\n—sgn(v)u,N , when b| >v,,\n\nfor some velocity threshold v, > 0. This formulation resolves the counterintuitive\nbehavior observed at high speeds but has the same problems as viscous damping at\nlow speeds. Furthermore, v, is just another magic number that must be tuned to the\nparticular system. More importantly, these alternate formulations cause problems\nwhen transitioning (either way) between dynamic and static friction.\n\n222\n\nSection 2 Mathematics\n\ncee rN ASE aR BR NE No sesame canes Et ah EES I NRE HABE\n\nThird Approach: Dealing with Nonsmoocthness\n\nIt is possible to find a numerical method that works well, provided we understand\nwhat is going wrong. The trajectory x(t) of our sample problem has two smooth\ndomains (a function x(2) is smooth if its first derivative is continuous and exists every-\nwhere):\n\n—t1 2\nx2) _ Jot — 3 sgn(v)u, gt , whent <¢, (2.7.13)\nx , when 2 ¢,\n\ns\n\nThe function x(z) and its derivative v(t) are both continuous at ¢, but acceleration\na(t), the first derivative of v(2), is not. Euler's method, along with higher-order meth-\nods, assumes that the function x(¢) has a Taylor series on the interval over which we\nare integrating [Gerald97]. This system, however, does not satisfy this property in a\nneighborhood of t, where v goes to zero and the discontinuity occurs. Therefore, any\nmethod that assumes a valid Taylor series for x(¢) will not converge to the correct\nsolution.\n\nSuppose that our current time is ¢ < ¢, and that we want to calculate the position\nat some later time ¢ + 4 < ¢. Over this interval, x(¢) does have a valid Taylor series, so\nwe can expand x(t + 4) in 4 about ¢ to get\n\ndx(t d’x(t\nx(z + h) = x(t) +h at) + ip 4) = x(t) + ho(t) - 1p? sgn(v) yg. (2.7.14)\n\nThe Taylor series for v(t + 4) is\n\nmG + h) = v(t) +h a) = (+) - hsgn(v) zg . (2.7.15)\n\nTogether, these two equations form a Taylor method [Gerald97]. Provided we\nintegrate over time intervals [¢, ¢ + A] that satisfy ¢+ 4 < 4, this method is exact for our\nblock on a flat surface at any incline.\n\nDuring any interval, we know that v will go to zero if the quantity\n\nh, = v (2.7.16)\nsgn(v) 4g\nsatisfies\n0<h <h, (2.7.17)\n\nIf 4, satisfies this inequality at any particular step, we must set v = 0, and consider\nx(t + A,) the position of rest. In general, if the block has acceleration a(t), our method\n\nhas the form\nx(t + h) = x(t) + holt) + 1 ha) (2.7.18a)\n\nv(t +h) = o(r) + ha(z) . (2.7.18b)\n\n2.7 Coping with Friction in Dynamic Simulations\n\n223\n\nAt every step, we check to see if 4, satisfies\nt\n0<h/ = _ ot) <h. (2.7.19)\n\nWhen applied to our test system, this approach gives much better results. In fact,\nTable 2.7.2 shows that ¢, and x, are exact, but more importantly, v(t) = 0 for ¢2 ¢,.\n\nTable 2.7.2. Positions and Velocities Calculated with a Taylor Method\n\n0.00000 0.00000 1.0000\n0.02000 0.01804 0.8038\n0.04000 0.03215 0.6076\n0.06000 0.04234 0.4114\n0.08000 0.04861 0.2152\n0.10000 0.05095 0.0190\n0.10194 0.05097 0.0000\n0.12194 0.05097 0.0000\n\nNote: Positions and velocities calculated with a Taylor method are exact for our test system. Calculating\nan intermediate time step /, ensures that velocity goes to zero and stays there.\n\nTransitioning Between Static and Dynamic Friction\n\nThe previous approach handles only dynamic friction. On slopes, we must evaluate\nwhether or not a transition between static and dynamic friction will occur. When v #\n0, friction is dynamic by definition, so we only need to consider these transitions\nwhen v = 0.\n\nRecall the example of Figure 2.7.3. For inclines @ > @, the block will decelerate to\nan apex, then slide back down. But for 0 < @,, it will stop at its apex and remain sta-\ntionary. If the block is stationary and the forces on the block are changing over time,\nthen we must periodically check to see if static friction can equalize tangential forces\nso that the block remains stationary. In other words, if the net tangential force does\nnot satisfy the inequality\n\n—uN<E< MN; (2.7.20)\nthen the block begins to slide.\n\nThere is an important subtlety, however, that must not be overlooked. When the\nblock transitions from static to dynamic friction, its velocity is zero; so the direction\nof dynamic friction cannot be determined. Since the impending motion willbe in the\ndirection of F,, dynamic friction must therefore act opposite to F..\n\nIt is now easy to see why velocity thresholds cause problems when transitioning\nfrom static to dynamic friction. Upon the first application of dynamic friction, veloc-\n\n224\n\nSection 2 Mathematics\n\nsere\n\nity goes from zero to some value v(t + 4). If |v(t + 4)| < v,, our minimum allowable\nvelocity, then v is set back to zero. However, since a(t) # 0, x(t+ 4) will advance some-\nwhat. If velocity consistently fails to rise above v,, then the block will slowly creep\ndown the slope at a constant speed. For any configuration of 0, 4 and v,, there exists\nsome minimum time step /,,;, below which creep will occur.\n\nWe can now formulate dynamic friction in three dimensions:\n\n—u,Nv whenv #0\nf, = (2.7.21)\n\n—,NE, when v = 0,\n\nwhere E, is the direction of the tangential component of the net force on the object.\nThis formulation is consistent for transitions from static to dynamic friction. Friction\nf, is now a vector. We assume that velocity has no normal component so that the unit\nvector V is tangent to the contact surface. The normal force is the vector N = Nan,\nwhere n is the unit normal direction.\n\nWhen v = 0, static friction tries to counter tangential forces, and its magnitude\nmust satisfy\n\nf=\n\nThe interpolated Taylor method derived above will still work, provided we can\naccurately predict whether or not v goes to zero during the integration interval.\n\nDue to the nonlinearity of the three-dimensional problem, we cannot solve for 4,\nexactly, so we must find some way of estimating its value. The time rate of change of\nthe square of the magnitude of velocity is\n\nad 2 ad ay\n\nial =“f{y-.v)=2v-—=2a- 2.7.23\na | v(2) | a (v v) 2v a 2a-v. (2.7.23)\nIf we assume that the acceleration a and the direction of velocity is constant over\n\nthe interval [z, ¢ + 4], then only the magnitude of velocity changes over time. We can\nintegrate Equation 2.7.23 to find 4;\n\n< u,N. (2.7.22)\n\ni 2a-vdt=2a a vat=2a -(x(¢ + h) - x(+)) =2a- Ax, (2.7.24)\n\nSince we are assuming the direction of v is constant and its magnitude decreases\nat a constant rate, we get\n\n2a: Ax =2a- 3 vA, =a-vh., (2.7.25)\nIf this rate of change is negative, then we get\nhb, =-—— (2.7.26)\n\nso .\na:v\n\n2.7 Coping with Friction in Dynamic Simulations 225\n\nThis reduces to the one-dimensional formula when v and a are in the same\ndirection.\n\nGeometric issues\n\nSmoothness\n\nOne common way to represent a two-dimensional surface is as a polygonal mesh.\nAnother common representation is the heightfield, in which elevations of a surface are\nstored over a regularly spaced grid. Unfortunately, both of these representations can\nlead to convergence problems if discontinuities in slope are not properly dealt with.\n\nConsider the example illustrated in Figure 2.7.4. When the block hits the slope,\ngravity will instantaneously change from acting solely along the normal direction to\nhaving a component opposite friction, and the net acceleration will experience a jump\ndiscontinuity. If this is not dealt with properly, it can lead to the same convergence\nproblems described here.\n\nFIGURE 2.7.4 A block sliding along a flat surface will experience a discontinuity in tts\nacceleration when the slope suddenly changes.\n\nOne possible remedy is to interpolate the position and velocity to the point at\nwhich the change in slope occurs. For a heightfield, this might be practical; but it\ncould be inefficient for arbitrary polygonal meshes. This approach might also cause\nproblems for an implementation that treats impacts (which involve instantaneous\nchanges in velocity) generally.\n\nAnother possibility is to smooth the surface so that its directional derivative (see\n[Davis91]) is continuous. For a heightfield, this would require quadratic spline inter-\npolation (see [Watt00]) along the x and y directions. For arbitrary polygonal meshes,\na subdivision scheme might be required.\n\nThe best approach must be decided by the application developer, but the effects\nof discontinuities in acceleration on the convergence of the method should be kept in\nmind.\n\n226\n\nSection 2 Mathematics\n\nCurvature\n\nThough we now have a good model for representing frictional forces operating on flat\nsurfaces, extending this model onto curved surfaces is nontrivial. If you want to try to\nextend it, note the following: When the surface curves upward, integration will push\nthe object into the slope and give v a component normal to the surface. This can be\ndealt with by simply resetting the position of the object and removing the normal\ncomponent of velocity following the integration step.\n\nWhen a surface curves downward, however, it must be decided whether or not\nthe object should leave the surface. Although not very robust, using a velocity thresh-\nold on the normal component of velocity seems to be the most common approach.\nWhen using this approach, these thresholds must be adjusted to get the desired\n\nbehavior.\n\nConclusion\n\ni BTR 0 aA RA NN BN AOE SIT SB AME RR\n\nReferences\n\nWe have used some simple one-dimensional examples to illustrate the Coulomb\nmodel of friction. We have also explored reasons why certain numerical methods are\ninsufficient, and we have developed a simple but effective numerical method for com-\nputing the three-dimensional trajectory of an object sliding over a surface of constant\nincline. Now, go build yourself a playground!\n\n[Abadie00] Abadie, Michel, “Dynamic Simulation of Rigid Bodies: Modeling of\n\nFrictional Contact,” Impacts in Mechanical Systems: Analysis and Modeling, Springer-\nVerlag, 2000.\n\n[Beer62] Beer, F. P. and Johnston, E. R., Jr., Mechanics for Engineers: Statics and\n\nDynamics, McGraw-Hill, 1962.\n\n[Davis91] Davis, H. E and Snider, A. D, Introduction to Vector Analysis, 6th\n\nEdition, Wm. C. Brown Publishers, 1991.\n\n[Gerald97] Gerald, C. E and Wheatley, P. O., Applied Numerical Analysis, 6th\n\nEdition, Addison Wesley, 1997.\n\n[Pfeiffer92] Pfeiffer, F and Hajek, M., “Stick-Slip Motion of Turbine Blade-\nDampers,” Philosophical Transactions: Physical Sciences and Engineering, Nonlin-\near Dynamics of Engineering Systems, 1992: Vol. 338, No. 1651, pp. 503-517.\n\n[Stewart00] Stewart, D., “Rigid-Body Dynamics with Friction and Impact,” SIAM\nReview, 2000: Vol. 42, No. 1, pp.3-39.\n\n[Watt00] Watt, A., 3D Computer Graphics, 3rd Edition. Addison Wesley, 2000.\n\nSOREN ARTES EE TTT ON IRIAN\n\n3.1\n\nOptimized Machine Learning\nwith GoCap\n\nThor Alexander, Hard Coded Games\nthor@hardcodedgames.com\n\nachine learning is an emerging technology that will make a big impact on the\n\nway games are made in the future. From a production standpoint, machine\nlearning will bypass need for the thousands of lines of brittle, special-case AI logic that\nis used in many of today’s games. Training a computer-controlled character by observ-\ning a human, expert player will bring great advances in the level of intelligence that\ncan be displayed. Game designers will be able to role-play the personalities of a wide\narray of characters, which can be stored in libraries and then later imported into their\ngames like traditional content assets.\n\nThis gem presents an optimized version of GoCap, a method we developed to\ntrain Al characters by observation [Alexander02]. Think of it as ‘motion-capture for\nAI.’ Some figures contained in this gem are shown using UML (Unified Modeling\nLanguage) notation. For an in-depth discussion of UML, see [Booch98].\n\nGoCap Architectural Overview\n\nTo employ GoCap, we need to engineer our system to record the inputs to the system\nas a human plays the game, and then map them to the action that the player chooses\nto execute, and under the current simulation conditions. To make this useful, we will\nhave to build the game in such a way that a human trainer can play all of the game\nactors, including the enemies. To do this, we must first define a few classes to support\n\ntraining.\n\nActionState\n\nAn ActionState is an atomic element of a finite-state graph. It stores the legal transi-\ntions that it can make to other action states in a transitionList. The ActionState\nalso maintains an ActionRuleSet that enumerates all of the rules under which the\nstate should be used. Each ActionRule has its own Evaluate() method that computes\nand returns some game-related value that defines the rule (see Figure 3.1.1).\n\n231",
      "page_number": 218,
      "chapter_number": 23,
      "summary": "This chapter covers segment 23 (pages 218-225). Key topics include friction, frictional, and velocity. We'll start by implementing friction naively and see why discontinuity of acceler-\nation is a real problem when implementing game code.",
      "keywords": [
        "Dynamic Friction",
        "friction",
        "Method",
        "Dynamic",
        "Euler method",
        "Taylor method",
        "block",
        "velocity",
        "static friction",
        "surface",
        "Dynamic Simulations",
        "position",
        "approach",
        "Taylor",
        "numerical method"
      ],
      "concepts": [
        "friction",
        "frictional",
        "velocity",
        "velocities",
        "game",
        "approach",
        "model",
        "problem",
        "block",
        "numerical"
      ],
      "similar_chapters": [
        {
          "book": "Game_Engine_Architecture",
          "chapter": 34,
          "title": "Segment 34 (pages 673-695)",
          "relevance_score": 0.46,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 18,
          "title": "Segment 18 (pages 172-180)",
          "relevance_score": 0.44,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 1",
          "chapter": 16,
          "title": "Segment 16 (pages 140-149)",
          "relevance_score": 0.43,
          "method": "api"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 33,
          "title": "Segment 33 (pages 652-672)",
          "relevance_score": 0.42,
          "method": "api"
        },
        {
          "book": "makinggames",
          "chapter": 2,
          "title": "Segment 2 (pages 9-16)",
          "relevance_score": 0.42,
          "method": "api"
        }
      ]
    },
    {
      "number": 24,
      "title": "Segment 24 (pages 226-233)",
      "start_page": 226,
      "end_page": 233,
      "detection_method": "topic_boundary",
      "content": "Section 3 Artificial Intelligence\n\nL ActionState actionRuleSet\n\ntransaction List\n+AllRulsFired() : boolean\n+GetReleventTangent Set()\n+GetRuleSet() :actionRuleSet\n+Transistion() +RemoveRule() : boolean\n\nFIGURE 3.1.1 Class diagrams for ActionState with actionRuleSet and actionfule.\n\nActor Class\n\nAn actor is a simulation object that is capable of interacting with the game environ-\nment. Each actor has a control state that defines if the actor is currently under player\ncontrol, AI control, or is in the training state. The control state can be swapped on the\nfly to transition the actor between one of these states. The actor’s PerformAction()\nmethod will delegate processing to the current control state, which will determine the\ndesired ActionState to transition to.\n\nContro(State\n\nA Controlstate defines from where the associated actor can accept commands. When\nin a training state, the player controls the actor, as in the user-controlled state; except\nnow, the computer can observe and learn from the actor's actions.\n\n[Actor ControlState\n+PerformAction() +PerformAction()\n+RequestAction() +RequestAction()\n+SwapControlState()\n\noo\n[ UserControlState AlControlState TrainingState\n-ActionRequestQueue -ControlStateAuto : AlControlState\n+ClearActionRequestQueue() -ControlStateUser : UserControlState\n-DequeueActionRequest() +PerformAction()\n\n+PerformAction() +RequestAction()\n-QueueActionRequest() -Train() : boolean\n\n+RequestAction()\n\n—\n\nFIGURE 3.1.2 Controlstate class hierarchy.\n\nUserControlState\n\nFor use in client/server environments, the UserControlState maintains a queue of\npending action requests that have been received from the player. This control state’s\nPerformAction() method will pull requests from this queue when it is called. The\n\n3.1 Optimized Machine Learning with GoCap 233\n\nqueue can be replaced with an immediate request-handling method if the training\nenvironment runs locally, without need of a server.\n\nAlControiState\n\nThe AlControlState is responsible for determining the appropriate action to perform\nwhen an actor in this state calls its PerformAction() method. The example presented\nin here implements a rule-based AI decision system encoded with hash maps.\n\nTrainingControlState\n\nThe TrainingControlstate adds a private Train() method that it will use to learn\nunder which conditions to transition to a given ActionState.\n\nCar To Drive\n\nose\n\nMURR ERNLINRENBR RR\n\nTo illustrate how GoCap works, we present the example of driving a toy car around\nsome obstacles and the car’s learning when to turn to avoid the obstacles. This exam-\nple will also illustrate the process of mapping action states to the rules that detail\nwhen to use them.\n\nDefining Action States\n\nOur toy car has five basic action states that define the operations that it can perform\nand limit the transitions between them. Table 3.1.1 enumerates the states, and Figure\n3.1.3 depicts the transitions between them, shown as arrows.\n\nTable 3.1.1 Action States for Driving a Car\n\nAction State Description\n\nStop Stop the car from moving (default state).\nMoveFwd Move the car forward in the direction it is facing.\nTurnRight Steer the car to the right.\n\nTurnLeft Steer the car to the left.\n\nMoveBwd Back the car up.\n\nOnce we have defined the states, we will need the transitions between them so\nthat we can build the classes to implement them. Figure 3.1.4 shows the class diagram\nfor these action states. Each state can be encapsulated in its own instance of an\nActionState. Note that this implementation yields a state graph containing the legal\ntransitions between states, but it does not embed any knowledge of when to make\nthose transitions.\n\n234\n\nSection 3 Artificial Intelligence\n\nTurnRight\n\nTurnLeft\n\nFIGURE 3.1.3 Action states for driving and the transitions between them.\n\nActionState\n| Cid\n[ t—“C;i‘“CC*dzC\n\nMoveFwd MoveBwd\n\nTurnRight\n\n|\nLd\n\nFIGURE 3.1.4 Class diagram for movement action states.\n\nDefining Rules\n\nNow we need to determine the rules that will detail when our car can transition to\nthese action states. Each ActionState is associated with an ActionRuleSet that con-\ntains the rules under which we can use the state (see Figure 3.1.1). Each ActionRule\nhas its own Evaluate() method that computes and returns some game-related value.\nFor our car, we will define six sensors that will detect proximity to possible collisions.\nEach of these sensors will be implemented with an Evaluate() method. These methods\nwill cast a ray from the car’s origin, out in the sensor direction. If the sensor collides\nwith an obstacle, then the method will compute distance to the obstacle and return the\n\n3.1. Optimized Machine Learning with GoCap\n\n235\n\nproximity as 1/distance, ensuring that the distance is always greater than or equal to 1.\nThis yields a floating-point proximity value from 0.0 to 1.0. Table 3.1.2 details the\n\nsensors we will use. Figure 3.1.5 illustrates how these probes will be attached to our car.\n\nTable 3.1.2 Sensors for detecting collisions.\n\nSensor Description\nFWD Probe forward directly in front of the car.\n\nFWD-L Probe forward to the left of the car.\nFWD-R Probe forward to the right of the car.\n\nLEFT Probe left of the car.\nRIGHT Probe right of the car.\nBWD Probe directly behind the car.\n\nFIGURE 3.1.5 Attaching sensors probes to a car.\n\n236 Section 3 Artificial Intelligence\n\nTurnLeft\n\ncic\n\nFIGURE 3.1.6 Rules for the TurnLeft behavior.\n\nWith our Evaluate() methods encapsulated in each rule, we can now build the\nActionRuleSet for each ActionState. Figure 3.1.6 depicts the TurnLeft action state\nwith its associated six sensor rules. Figure 3.1.7 shows the class diagram for the Turn-\nLeft state and rules.\n\nLearning the Rules\n\nSARA RO ERNE RETRACING\n\nNow, we are ready to train our car’s rules. We do this by swapping the car’s actor to the\ntraining control state with a human player in the driver's seat, as described here.\nPseudo code is provided to illustrate the process.\n\nHRM OR RRR ANB RB HEIST ANAS RATERS TORSO LACES TENANT ERE ERNE\n\nActor. SwapControlState( TrainingControlState )\n\n3.1 Optimized Machine Learning with GoCap 237\n\nActionRuleSet\n\nStop | MoveFwd TurnLeft TurnRight\nLe\nLd PT LT\n\nFIGURE 3.1.7 Class diagram for TurnLeft ActionState rules.\n\nWhen the player steers to avoid obstacles, the training actor is informed of the\naction requests. The TrainingControlState will allow the user control state to per-\nform the requested steering action as normal, but it will grab the resulting Action-\nState and pass it to the Train() method.\n\nTrainingControlState:PerformAction( Actor )\n\n{\nActionState = UserControlState.PerformAction()\n\nTrainingControlState.Train( ActionState )\n\nCluster Maps for Floating-Point Valued Rules\n\nTo allow us to dynamically train the rules, each rule has a ClusterMap associated with\nit. A cluster map is a one-dimensional, spatial-partitioning data structure. This struc-\nture can be partitioned into a number of cells that provide coverage appropriate to the\ndomain of the associated rule. To cover our Evaluate() method’s domain of 0.0 to\n1.0, we will use a 10-cell cluster map. If we required greater precision to cover the rule\ndomain, we could increase the number of cells. A 10-cell cluster map can be imple-\nmented as a hash map that is indexed by an integer key value between zero and nine.\nFigure 3.1.8 shows the related classes.\n\nThe ClusterMap class provides a CalculateIndex() method that can perform an\nindex calculation on the floating-point value returned by the Evaluate() method to\ntransform it into an integer representation. This gives us the hash map key that corre-\nsponds to the evaluation value. We can feed this key to the Lookup() method on the\nClusterMap class to get the individual Cluster object that represents the cell. The\ncluster map serves to round off or quantize the floating-point input value so it fits into\nthe nearest cell.\n\nTrainingControlState:Train( ActionState )\n{\n\nSection 3 Artificial Intelligence\n\nActionRule [ ClusterMap Cluster\n[>———-hashMap -firingThreshold\n-Evaluate() +CalculateIndex():int -trainingMarkerCount\n+Fire() +Hashindex() +Fire()\n+Reinforce() +Lookup() +Reinforce()\n\nFIGURE 3.1.8 Class diagram for ClusterMap.\n\nFor Rule in ActionState.GetRuleSet {)\nClusterMap = Rule.GetClusterMap()\nValue = Rule.fEvaluate( Actor )\nIndex = ClusterMap.CalculateIndex( Value )\n\nKey = ClusterMap.HashIndex{ Index )\n\nCluster = ClusterMap.Lookup( Key )\nCluster.Reinforce()\n\nEnd For\n\n}\n\nThe Reinforce() method is where the actual training occurs. Each Cluster\nmaintains a trainingMarkerCount that is incremented during training. This marker\nindicates that the player activated this action rule with this evaluation value. As the\nplayer feeds more input into the training system, we will get more values that fall into\nthis cluster. Every time we get a hit in the cluster, we increment the marker count\nuntil it reaches some preset firing threshold. We add this threshold to account for\nnoise or error in the input data. In practice, you might need to set this threshold sig-\nnificantly high if your training data is prone to noise or error.\n\nCluster: Reinforce({)\n\n{\ntrainingMarkerCount ++\nIf trainingMarkerCount > firingThreshold then\ntrainingMarkerCount = firingThreshold\nEnd If\n}\n\nEarly in our training, the cluster maps will only contain a few training markers.\nAs training goes on, more data flows into the system, and more rules are learned.\nEventually, we will tend to reach a point of equilibrium where we have learned all of\nthe rules that match the input action choices. We can detect this equilibrium by com-\nparing the player’s input against the action that the AIControlstate would pick itself.\nWhen they match on a continuing basis, we can signal the player to stop training.\n\nSwapping Control to the Al\n\nNow that we have a fully trained rule set, we can detach our human trainer and swap\nto AI control. When the actor performs its next action, it calls on its decision process\nand newly trained rules to determine its course of action.\n\n3.1 Optimized Machine Learning with GoCap 239\n\nActor .SwapControlState( AIControlState )\nActionState = Actor.PerformAction( )\nIf ActionState Is Not None Then\nCurrentState = Actor.GetCurrentActionState()\nCurrentState.Transition( ActionState )\nEnd If\n\nThe cluster's Fire() method can now test the evaluation values against the train-\ning markers in the cluster map. If a rule evaluates to a value that falls into a cluster\nthat has enough markers to reach the threshold, then that rule fires. If all of the rules\n\nin the rule set fire, then the associated ActionState is returned for activation.\n\nAIControlState:PerformAction( Actor )\n\n{\nfired = 0\nActionState = Actor.GetCurrentActionState()\nFor Action in ActionState.GetTransitions()\nFor Rule in Action.GetRuleSet()\nClusterMap = Rule.GetClusterMap()\nValue = Rule.Evaluate( Actor)\nIndex = ClusterMap.CalculateIndex(Value)\nKey = ClusterMap.HashIndex( Index )\nCluster = ClusterMap.Lookup( Key )\nIf Cluster.Fire() Then\nfired++\nEnd If\nEnd For Rule\nIf fired = Action.GetRuleSet().Count() Then\nReturn Action\nEnd If\nEnd For Action\nReturn None\n}\n\nConclusion\n\ned\n\nAE sk NOUR RRO A ATER AER ATS SEER\n\nThis gem outlined an implementation of GoCap using hash maps for the dynamic\nlearning of rule clusters. This enhancement provides a significant performance\nincrease over the previous version, which used sparse arrays. The nested structure of\nthe AI decision loop makes it a good candidate for further optimization with SIMD\ntechniques, but that is a story for another day.\n\nan SARE ORR REAR ROSEN Ti FSR RS RENT SCE\n\n[Alexander02] Alexander, Thor, “GoCap: Game Observation Capture,” Al Game\nProgramming Wisdom, Charles River Media, Inc., 2002.\n\n[Booch98] Booch, Grady, The Unified Modeling Language User Guide, Addison Wes-\nley, 1998.\n\nAe RN",
      "page_number": 226,
      "chapter_number": 24,
      "summary": "This chapter covers segment 24 (pages 226-233). Key topics include training, actions, and rule. Actor Class\n\nAn actor is a simulation object that is capable of interacting with the game environ-\nment.",
      "keywords": [
        "action states",
        "action",
        "state",
        "Car",
        "control state",
        "Actor",
        "rules",
        "Car Action State",
        "Cluster",
        "actionRuleSet transaction List",
        "Optimized Machine Learning",
        "ActionState",
        "method",
        "transaction List",
        "cluster map"
      ],
      "concepts": [
        "training",
        "actions",
        "rule",
        "actor",
        "cluster",
        "states",
        "car",
        "value",
        "valued",
        "probes"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 7",
          "chapter": 25,
          "title": "Segment 25 (pages 238-245)",
          "relevance_score": 0.53,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 28,
          "title": "Segment 28 (pages 261-272)",
          "relevance_score": 0.5,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 21,
          "title": "Segment 21 (pages 197-204)",
          "relevance_score": 0.49,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 2",
          "chapter": 25,
          "title": "Segment 25 (pages 240-248)",
          "relevance_score": 0.48,
          "method": "api"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 2,
          "title": "Segment 2 (pages 9-16)",
          "relevance_score": 0.46,
          "method": "api"
        }
      ]
    },
    {
      "number": 25,
      "title": "Segment 25 (pages 234-242)",
      "start_page": 234,
      "end_page": 242,
      "detection_method": "topic_boundary",
      "content": "3.2\n\n240\n\nArea Navigation: Expanding\nthe Path-Finding Paradigm\n\nBen Board and Mike Ducker,\nDogfish Entertainment\nben_board@yahoo.com, mike@ducker.org.uk\n\nPah indne constitutes one of the primary areas of game AI and is a major con-\ncern in almost all modern computer games. The simple act of producing a route\nfrom A to B could introduce a significant CPU hit, depending on the complexity of\nthe world and the manner in which the task is broken down. The traditional\napproach to solving the path-finding problem involves placing nodes across the game\nworld and connecting them by edges, where the direct route linking any two points is\nfree from obstruction.\n\nThe placement of these nodes can be achieved in many ways: by the level designer\nas part of the design process, by a procedural method as part of an export process, or\nby the nature of the game world in which the environment might be split into some\nset of formalized shapes, such as a tile map.\n\nOnce the world is deconstructed into nodes and connections, path-finding is nor-\nmally carried out by some form of heuristic search to discover the list of connections that\nwould provide a route from a character's start point to their goal. Arguably, the most pop-\nular form of heuristic search in computer games today is A*, an explanation of which can\nbe found in [Stout00] or on various gaming Web sites throughout the Net. This algo-\nrithm simply expands the best node in the current list until the goal node is reached or no\nvalid nodes remain to be expanded (i.e., the attempted path-finding has failed).\n\nThis gem presents a paradigm shift in the way a given world is deconstructed for\npath-finding. Rather than using nodes as the fundamental components of path-finding,\nit is suggested that regions of the environment be segregated into areas, each represented\nby one node in the search space, and that these areas be connected to one another if nav-\nigation between them is possible. Upon implementation of this paradigm in our game,\nwe will have profited from significant improvements in the following areas:\n\n¢ Speed and storage efficiency due to a huge decrease in nodes used in the search\nalgorithm.\n\n¢ Realistic movement—by moving from area to area, individuals are not restricted\nby unnecessarily precise waypoints.\n\n3.2 Area Navigation: Expanding the Path-Finding Paradigm 241\n\nTraditionally, path-finding has used the waypoint as its fundamental component for\nthe traversal of a simulated environment. By deconstructing the world into a series of\nconnected nodes (connections exist between a pair of nodes if those nodes can be nav-\nigated without obstruction), the world can be viewed as a graph of vertices and edges,\nthus allowing state-space searches and graph theory to be directly applied. An intro-\nduction to graph theory can be found in [Sedgewick89].\n\nThis abstraction from a complex environment, possibly containing detailed 3D\nmodels obstructing much of the landscape, allows simple, yet powerful algorithms to\nconnect two geographically dispersed points by the shortest possible route.\n\nWhile the node is a sensible choice for performing state-space searches, given its\nsimilarity to the vertex in graph theory, it lends itself rather easily to certain common\nscenarios where its straightforward use can lead to inefficiency. Imagine the simplest\nform of environment—a 2D tile map. Figure 3.2.1 shows a simple tile map contain-\n\nFIGURE 3.2.1 A simple tile map for a 2D world. Light areas are walkable,\ndark areas are unwalkable.\n\n242\n\nSection 3 Artificial Intelligence\n\ning two types of terrain: walkable (light) terrain and unwalkable (dark) terrain. The\nsimplest procedural method of producing nodes for this map is to place a single node\nat the center of each tile, and then connect each one to its horizontal and vertical\nwalkable neighbors, as shown in Figure 3.2.2.\n\nrt yf oe\n\nFIGURE 3.2.2 Procedurally placed nodes and connections.\n\nOf course, using this procedure generates seemingly redundant nodes on the\nunwalkable tiles. They are only truly redundant if their type (the particular aspect that\ndetermines their navigability) is guaranteed not to change, and there are no characters\nin the game world that are able to use them.\n\nSuch a complete system of nodes ensures that an obstacle-free path can be found\nfrom any walkable tile to any other walkable tile (if such a path exists), but at the sig-\nnificant cost of time and storage per node (for every tile). A preferred solution would\n\n3.2 Area Navigation: Expanding the Path-Finding Paradigm 243\n\nrequire fewer nodes, carefully chosen to encode the same accessibility information in\nless space.\n\nAny algorithm for node application must function under the following con-\nstraints to ensure that the path it generates is free of static obstacles:\n\n¢ Each node must represent a group of tiles that share the property that any pair of\ntiles in that group can be navigated between (without obstruction).\n\n¢ Each potentially navigable tile on the map must be represented by exactly one\nnode.\n\nThe method above recognizes those constraints only by applying a high degree of\nredundancy. If we could address that redundancy by identifying the minimal set of\nnodes necessary to encode walkable versus unwalkable regions, we could still enjoy\nthe benefits of the graph-search approach, but in optimal space and time.\n\nThe following section explains the paradigm shift in which each node represents\na nonuniform area of tiles.\n\nwith the New\n\nWhen approaching the problem of path-finding, the form of the environment should\nbe considered so that the path-finding algorithm can be optimally written for the\ngame in question. There are two underlying considerations for deconstructing the\n\nTR RRB AES EN A A ABB 2 OHA RN MORRIS ESOT EE EM INE RIE\n\nworld:\n\n© The number of nodes it 1s deconstructed into: The fewer the better; the fewer nodes\nthere are, the quicker the heuristic search.\n\n© The usefulness of the resulting nodes for path traversal: \\t is preferable that the nodes\nallow characters to walk the path within the maximal limits set by the walkable\nenvironment.\n\nThe use of areas rather than points is beneficial in both cases.\n\nThe world is broken into areas, each being of uniform navigability and internally\ntraversable in a straight line without having to avoid static obstacles. If one can navi-\ngate between two areas, then the areas are connected by a ‘portal’ that is in the shape\nof the contact region between the two areas. In the tile-world example, the tiles can be\nsplit into areas as shown in Figure 3.2.3. Note that our tile-world example is rectan-\ngular, but the new approach is extendable to convex polygonal regions for the general\ncase.\n\nAs seen in Figure 3.2.3, no points are arbitrarily used in path-finding. This mir-\nrors the common-sense approach used by the majority of people when solving the\nsame problem in real life. When attempting to plan a path from one position to\nanother, you would normally only use two points: the start point and the end point.\nAll other sections of the path are generalized areas, split up by the way you perceive\nthe world. When walking from your bedroom to your bathroom in the morning (or\nearly afternoon), you might consider stairs, landings, corridors, or even other rooms\n\nSection 3 Artificial Intelligence\n\n244\n\neo S sees\nIe:\n\nbs.\n\nlkable areas connected by porta\n\ning the world into wa\n\n3 Break\n\n2\n\nFIGURE 3\n\nin these\n\nth\nthere are no\n\nally no moti-\n\nints Wi\n\nhowever, consider particular po\nfic reason to (once at the top of the stairs,\n\n>\n\nYou don’t,\n\ning your path\n\nwhile plann\n\nis some speci\nions to be made unt\n\nareas, unless there\n\nmore dec\n\nil you reach the bottom!). There is norm\n\n1s\n\nalk\nAny path\night |\n\nyou just w\n\nit;\nion\n\nir shared portals until you reach your destinat\n\nk to any specific spot within a corridor before you leave\n\n4\nis\n3\n>\nfs]\nuv\n; aT\na\ng 2\no §\n-~\naq 8\n2s\na oO\n>\n\nbar-\n\nine,\n\nwithin a single area is always a stra\n\nos\n5\nvu\ns\nge\n£3\ng 2\nSg\nnr\n\nomen)\nAG\ng\nvw Ss\na &\neS\noe PN\na5\nsp\nae\n\nIt should be noted that the use of areas does not overly affect the basic heuristic\n\n68s\naaqs\nge yx\nwu\nSYeE\na\noes\n33%\na) 3\ngf\nase\n) =\novo\ns35\nfo}\n@a@ezt\nvod\nn=\neye\no © &\ngo yg\nBES 8\nwa B\n£2 5\nsex\num -\nBo ¢\nSee\n$25\np oo\nee&e\non 6\nve g\nco\n\nRR\ng § =\n£0 §\nmod\noP u\now V\na Ya\na & go\n2&2\no 2 8\nao\n\n-traversal\n\nic path\n\n1st\n\nistances actually traveled, given a real\n\nher values than the d\n\nhig\n\ngive\n\n3.2 Area Navigation: Expanding the Path-Finding Paradigm 245\n\nFIGURE 3.2.4 A simple metric for movement cost between areas.\n\nalgorithm. A better solution would be to use the distance from the central point of the\n\nportal used to enter an area to the central point of the portal used to exit that area. For\n\ninstance, if your path took you from area A to B to C during your path-finding\n\nprocess, the distance cost of traveling from B to C would be the distance from the\n\nportal connecting A to B to the portal connecting B to C, shown here in Figure 3.2.5.\nTo summarize the path-generation algorithm:\n\n¢ The world is split into an optimal set of areas, where each area is uniformly navi-\ngable, and any two points within the area can be traversed in a straight line with-\nout impediment.\n\n¢ Each of these areas is represented by a node in a graph, and two nodes are connected\nby an edge if their associated areas have a common navigable interface (a portal).\n\n246 Section 3 Artificial Intelligence\n\nroe ornare ee eer a BASU Ua ate annonce EEN EASA ENERO Cn i ene tI SCH ANe teNERNEENE 2 seinonseeseeatentenAGunOH mE ne ORDER NEPEAN\n\nFIGURE 3.2.5 A more realistic metric for movement cost between areas.\n\n* Basic paths are generated by determining the containing areas for the start and\nend points of the journey, finding the associated nodes, and then searching the\ngraph to find the best route between the two points.\n\n* Once this area-wise route is found, a specific path is created by moving between\nthe portals linking successive pairs of areas. This is path traversal, which shall be\ndiscussed shortly.\n\nNow that the basic concepts have been introduced, the next section will continue\nwith the tile-world example and explain a method of producing optimal areas from\nthe environment.\n\n3.2 Area Navigation: Expanding the Path-Finding Paradigm 247\n\nDivide and Conquer\n\nConstructing areas from raw terrain data is a very game-specific problem. It is possi-\nble you will have to extract the processed areas from polygons flagged for terrain type,\nor even from open spaces in a fully 3D game. This section will focus on the simplest\ncase as an example and show a method of rectangularizing a tile world to produce\nresults as seen in Figure 3.2.3.\n\nWhile there are many possible ways of producing a set of rectangles from a given\ntile set (each having its own merits and flaws), for the purposes of producing rectan-\ngles for path-finding, the following aspects are important to consider:\n\n° The rectangles produced should be as large as possible. The larger the rectangles, the\nquicker the path-finding process will occur, since fewer rectangles are necessary.\n\n° The rectangles should be as square as possible. For the purposes of path-finding, the\nrectangles will produce better paths if the ratio of width to height is close to one.\nThis helps avoid the problem outlined in Figure 3.2.4 and leads toward more-\nrealistic looking paths.\n\n© The rectangularization algorithm should be fast. In games where the type of land-\nscape can be changed dynamically and rectangularization must be performed in\nreal-time, the algorithm for rectangularization should be as fast as possible.\n\nThe following pseudo-code rectangularizes the world with reasonable speed, pro-\nducing more-evenly sided rectangles with an adjustable level of performance between\noptimized rectangles for path traversal and optimized speed. Where offline processing\nis possible, speed optimization is not a key issue and can be ignored in favor of better\noptimized rectangularization. The algorithm is presented as pseudo-code here due to\nthe length of the full code, which can be found on the CD-ROM.\n\nThe rectangularization function is defined as:\n\nRectangularizeWorld( MapCellTypes cellType, int\ninitialTestSize)\n\nwhere the parameter cellType defines the type of environment the function will rec-\ntangularize (walkable, unwalkable, or some other defined type), and the parameter\ninitialTestSize defines the size of the largest square tested, and is used to trade opti-\nmal rectangularization for optimal speed.\n\nThe first step in the function is to count the number of cells of the required type.\nThis is used to abort out of the function if that cell type is lacking in the current envi-\nronment. Only cells that are not already contained within an area are considered.\n\nint CellCount = number of free cells of type cellType\nif CellCount = 0 then exit\n\nThe next step is to ensure that the size of the square used for the comparisons\nis smaller than the square root of the number of cells of the required type. If the\ntest size defines an area larger than the number of cells that the required type can\n\n248 Section 3 Artificial Intelligence\n\noccupy, then there is no way that the square will find an area consisting entirely of\nthose cells.\n\nif initialTestSize > sqrt(CellCount)\nthen initialTestSize = sqrt(CellCount)\n\nThe main loop of the rectangularization process begins by testing the world with\na square of the maximum defined size and decreasing that square with each iteration\nuntil it is zero.\n\nfor testSize = initialTestSize, testSize > 0, testSize = testSize - 1\n\nThe square is passed across the map from bottom left to top right:\n\nFor startX = 0 to mapWidth — testSize\nFor startY = 0 to mapHeight - testSize\n\nThe square defines an area of the world that is tested for uniform cells (of the\nrequired type) such that no cell under the square is contained by another area.\n\nFor testX = startX to startX + testSize\nFor testY = startY to startY + testSize\nIf cell{testX][testY] is not free or not of the required type,\nfail\n\nIf the square fails, then move it to the next testing position and test again. If the\nsquare contains only free cells of the required type, then attempt to expand the square\nNorth, East, South, and West by one cell width, one direction at a time. New cells\nadded to the area by each expansion are permanently added to the rectangle (if they\nare of the required type and contained by any other area). The algorithm continues to\nexpand in all four directions until it fails to give a valid set of cells.\n\nFail = 0\nWhile fail < 4\nFor North, South, East, and West\nExpand the area by one cell width\nIf the new rectangle is valid\nFail = 0\nElse\nFail = Fail + 1\nContract the rectangle along this direction\n\nAt this point, we have an area defined by this expanded rectangle that should be\nadded to the list of areas.\nFor x = rectStartX to rectEndXx\nFor y = rectStartY to rectEndy\nCell{x][y] set to unavailable\n\nAdd new area to area list",
      "page_number": 234,
      "chapter_number": 25,
      "summary": "This gem presents a paradigm shift in the way a given world is deconstructed for\npath-finding Key topics include area, nodes, and path.",
      "keywords": [
        "Mike Ducker",
        "areas",
        "Area Navigation",
        "nodes",
        "Paradigm Ben Board",
        "Path-Finding",
        "world",
        "Path-Finding Paradigm",
        "Path-Finding Paradigm Ben",
        "path",
        "type",
        "tile",
        "square",
        "Dogfish Entertainment ben",
        "Paradigm"
      ],
      "concepts": [
        "area",
        "nodes",
        "path",
        "cells",
        "optimal",
        "optimally",
        "optimized",
        "tile",
        "algorithm",
        "process"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 1",
          "chapter": 27,
          "title": "Segment 27 (pages 248-255)",
          "relevance_score": 0.59,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 7",
          "chapter": 9,
          "title": "Segment 9 (pages 76-90)",
          "relevance_score": 0.58,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 1",
          "chapter": 31,
          "title": "Segment 31 (pages 291-298)",
          "relevance_score": 0.55,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 1",
          "chapter": 29,
          "title": "Segment 29 (pages 266-278)",
          "relevance_score": 0.54,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 1",
          "chapter": 30,
          "title": "Segment 30 (pages 279-290)",
          "relevance_score": 0.54,
          "method": "api"
        }
      ]
    },
    {
      "number": 26,
      "title": "Segment 26 (pages 243-252)",
      "start_page": 243,
      "end_page": 252,
      "detection_method": "topic_boundary",
      "content": "3.2 Area Navigation: Expanding the Path-Finding Paradigm 249\n\nCellCount = CellCount — new area size\nIf CellCount = 0 then exit\n\nBy altering the maximum size of the initial comparison square, it is possible to\ntrade speed optimization for optimal rectangularization. If the initial side length is set\nto one, then the minimal number of rectangle comparisons will be made, hence opti-\nmizing the speed of the procedure. If it is set to a maximum value, the width of the\nmap for instance, then far more rectangle comparisons will be made; however, the set\nof areas produced will adhere to the first two aspects of optimal rectangularization. It’s\na tradeoff that the developer must choose for their particular need.\n\nPath Traversal _\n\nrious: SOAPS SSSSERRESRMNIE LES CLA ht SMS Net RE\n\nOnce a path has been produced, the next step is for a character to follow that path to\nthe destination. There are two aspects to basic path traversal: attraction toward some\ngoal and repulsion from static obstacles along the way. The attraction is either toward\nthe next portal on the path or toward the goal point if the character has entered the\ngoal area. The repulsion comes from proximity to nonwalkable areas. (There are no\nstatic obstacles within each area, by definition.)\n\nTo move a character toward its next area in a realistic manner, two simple modes\nof attraction are used in conjunction (as seen in Figures 3.2.6 and 3.2.7):\n\n1. Attraction to the central point of the portal.\n2. Attraction along the normal of the portal. (The portal’s normal is defined\nby a vector perpendicular to the portal’s vector.)\n\nThese modes can be applied to varying degrees depending on the position of the\ncharacter relative to the portal. If the character does not lie on a point along the por-\ntal normal, then attraction along the normal of the portal will not result in a convinc-\ning movement to the new area. So, some amount of attraction to the center of the\nportal might be necessary. Figure 3.2.8 shows the portion of area B where attraction\nby the normal alone will result in the transition from area B to area C.\n\nAn example attraction algorithm is to use the normal vector shown in Figure\n3.2.7 while in the shaded area and a mixture of the two vectors outside that area\n(increasing the proportion of the central-point vector with distance along the line of\nthe portal).\n\nRepulsion works similarly to the normal attraction, except that the direction of\nthe normal is reversed such that the vector is heading into the character's current area\nrather than out of it. In the specific case of the simple tile world described so far, it\nwould be necessary to store a list of walls as well as portals, so that the walls could be\nused to repulse the characters from nonwalkable cells. In the more general case, every\ncell type would have its own area list, and all areas would have portals to all their\nneighbors. Neighbors leading to areas that a specific character could not use would\nrepulse that character by using a different area type in the traversal algorithm.\n\n250 Section 3 Artificial Intelligence\n\nsee\n\n—\n\nee\neG\n\nFIGURE 3.2.6 Autraction to area C by the central point of the portal connecting areas B\nand C.\n\nFigure 3.2.9 shows the map broken into walkable and unwalkable areas, with\npoints defining the center of each portal.\n\nFor each unwalkable area connected to the character’s current area, a repulsion\nvector is applied along the normal to the portal. This repulsion is only applied if the\ncharacter is within the confines of the portal, as shown by the shaded area of Figure\n3.2.10.\n\nFinally, once the path traversal is in place, dynamic object avoidance can be\nachieved by using basic flocking techniques and adding repulsion vectors from other\ncharacters in the world to the path-traversal vectors. For more information on flock-\ning see [Reynolds87] or [Woodcock00].\n\n3.2 Area Navi\n\ntion: Expanding the Path-Finding Paradigm ; — 251\n\nFIGURE 3.2.7 Attraction to area C by the normal of the portal connecting areas B and C.\n\nDynamic Landscapes\n\nDeconstructing the world into areas is a CPU-intensive process that must be carried\nout at appropriate points during runtime, if at all. It is preferable to carry out the pro-\nduction of areas during some batch process as the level is loaded. However, if the envi-\nronment is dynamic due to player interaction or scripted changes, then the\ndeconstruction process might have to be called during runtime. In these cases, speed\nis a primary consideration, and the process of deconstruction must be approached in\nsuch a way as to avoid frame lag without reducing the quality of the areas produced.\nThis is achievable as follows:\n\n252 Section 3. Artificial Intelligence\n\nee ee ec ee en ee ec ee\n\nFIGURE 3.2.8 The shaded area defines the portion of area B where attraction by the\nnormal of the portal connecting areas B and C (shown in Figure 3.2.7) will suffice to\ntraverse a character from area B to area C.\n\n° Initially, use the fastest deconstruction algorithm. With the rectangularization\nalgorithm detailed above, choose an initialTestSize value of 1. This might pro-\nduce an inferior set of rectangles for path traversal than a higher value would, but\nthe speed of the process is maximized.\n\n¢ During runtime, minimize redundant rectangularization (i.e., do not rectangu-\nlarize areas that are unaffected by the environment change).\n\n* Re-rectangularize the environment for optimal path traversal at an appropriate\ntime. Reconstruct the entire world when a slight lag would not be noticed, such\nas when the player switches to an in-game menu.\n\nFIGURE 3.2.9 The entire map is broken into walkable and unwalkable areas connected\nby portals with their centers marked by points.\n\nRemember, altering the set of areas not only requires deconstructing the world,\nbut it also requires recalculating the characters that are positioned in those areas.\n\nWhile this gem has focuse\n\napproach is applicable to every type of game world (including 3D). All that is\nrequired is a method of deconstructing the world into efficient areas that obey the\nrules described above as well as redefining the connecting portal region.\n\n254 Section 3 Artificial Intelligence\noc :\n:\nAo\nFIGURE 3.2.10 Repulsion is applied to characters within the area defined by the normal\nof the portal, which is shown by the shaded section of area B.\nConclusion\n\nThis gem presents a highly efficient algorithm for creating and following paths in a\nvariably navigable environment—one that we are using successfully in our current\ntitle. By identifying optimal areas within the environment that are trivially navigable,\nrepresenting them with a single node, then linking these nodes wherever the associ-\nated areas have a navigable interface, we are able to quickly produce paths covering\nlong distances. Redundancy is minimized, resulting in high speed and storage effi-\nciency. To support this process, a method of determining these optimal areas has been\nsuggested. Also, in order to use the resulting area-wise path and apply it to a navigat-\n\n3.2 Area Navigation: Expanding the Path-Finding Paradigm _ 255\n\ning character, a path-traversal method has been described. The results are inexpensive\nand the paths realistic.\n\necon aenene ROI LR RO LEI OLEY TRE ILL RPE TO TOLLE SN AE ALLE ITEC.\n\n[Reynold87] Reynolds, Craig, “Flocks, Herds and Schools: A Distributed Behavioural\nModel,” Computer Graphics Proceedings (SIGGRAPH 1987): pp. 25-34.\n\n[Sedgewick89] Sedgewick, Robert, Algorithms, Second Edition, Addison Wesley,\n1989.\n\n{Stout00] Stout, Bryan, “The Basics of A* for Path Planning,” Game Programming\nGems, Charles River Media, Inc., 2000.\n\n{Woodcock00] Woodcock, Steve, “Flocking: A Simple Technique for Simulation\nGroup Behavior,” Game Programming Gems, Charles River Media, Inc., 2000.\n\nWhat Is a Finite-State Machine?\n\n256\n\nFunction Pointer-Based,\nEmbedded Finite-State\nMachines\n\nCharles Farris, VR1 Entertainment, Inc.\n\ncharlesf@vri.com\n\nhe goal of this gem is to create an FSM (Finite State Machine) implementation\n\nusing function pointers, inheritance, and function overloading. This implemen-\ntation has three design requirements: object-oriented implementation, minimal cod-\ning, and fast execution.\n\nThe first requirement, object-oriented implementation, is very important in\nmodern games development. Many developers are moving toward object-oriented\nlanguages, such as C++ and Java, because these languages support features like\nabstract object manipulation and inheritance. To be used effectively in an object-ori-\nented programming (OOP) environment, an FSM implementation needs to be\nobject-oriented in design.\n\nThe second requirement, minimal coding, arises from a fundamental rule in soft-\nware engineering: “Keep It Simple, Stupid.” Accordingly, this implementation makes\nthe addition of FSM functionality as simple as inheriting a class and adding some\nmember variables and functions.\n\nFinally, this implementation uses function pointers to avoid computationally\nexpensive if-then-else comparisons at runtime (Calder94].\n\nThe most general definition of an FSM describes it as a model of an event-driven sys-\ntem. A system's behavior is represented within an FSM as a set of states, a set of input\nevents, and a state-transition function. A simple lightbulb example is demonstrated in\nTable 3.3.1 and Figure 3.3.1.\n\nFor a more in-depth description of FSMs and their application to game program-\nming, both Eric Dysband’s “A Finite-State Machine Class” (Dysband00] and Andre\nLaMothe’s Tricks of the Windows Game Programming Gurus (LaMothe99] are excellent\n\nsources of information.\n\n3.3 Function Pointer-Based, Embedded Finite-State Machines 257\n\nTable 3.3.1 Lightbulb State Transition Function\n\nCurrent State Input Event State Transition\nOn Switch On\n\nOn Switch Off Off\n\nOff Switch On On\n\nOff Switch Off\n\nSwitch Off\n\nSwitch On\nFIGURE 3.3.1 Lightbulb FSM.\n\nWhy Use FSMs?\n\nIn game programming, FSMs are generally used to control a game object’s behavior at\nruntime by selectively executing portions of the object’s code based on the current\nstate. While FSMs can be used to control virtually any game object, they are\nextremely popular for AI programming for the following reasons:\n\n¢ FSMs are useful for reducing complex behaviors into smaller, simpler behaviors.\n\n* FSMs are useful for synchronizing an Al’s behavior with external events, such as\nanimations, sounds, or timers. FSMs allow developers to integrate animations\nwith AI behavior without placing too many restrictions on the animator’s artistic\nvision.\n\n¢ FSMs are much easier to debug and tune than other AI techniques, such as neural\nnetworks or genetic algorithms [Woodcock00, Woodcock01]. FSMs generate\n\n258 Section 3 Artificial Intelligence\n\ndeterministic behavior during execution because state transitions are predefined\n- for a given state and input event.\n\nFSM Implementation\n\nFirst, we need to make some assumptions regarding our game objects. Each object\nshould be represented by a C++ class, have a function called Update() that is called\nevery tick, and have a set of state functions (which are called in the Update() func-\ntion). Given these assumptions, an FSM implementation requires a variable to track\nthe current state and some code for handling the state transitions. Most importantly,\nit needs some code for mapping the current state to the appropriate state functions in\nthe game object.\n\nFSM integration\n\nFSM implementations can be integrated into game objects in one of two ways. The\nfirst and simplest method is to include an instance of the FSM within the game\nobject. The second method is to embed the FSM within the game object via inheri-\ntance. Both methods have advantages and disadvantages, but this gem will use the\nsecond method for two main reasons. First, inherited FSMs allow greater flexibility\nbecause the FSM’s state-transition logic can use the game object’s data directly. Sec-\nond, embedded FSMs have slightly better performance, since there is less redirection\nrequired when accessing the FSM.\n\nThe main disadvantage with inherited FSMs lies in the dependency between the\nFSM and the game object classes, which can pose a challenge later on in development,\nsince changes to the inherited FSM class might require extensive modifications to the\nderived classes.\n\nThe Switch implementation\n\nThe most common form of FSM implementation is the switch implementation. In\nthis implementation, the current state is stored as an integer, and a switch statement\nis used to map the current state to the state function calls [LaMothe99]. The primary\nadvantages of this approach are ease of implementation and low memory usage.\n\nHowever, the common switch implementation does have disadvantages. First,\nthe switch implementation is not very object-oriented [Sweeney00]. Adding states\ninvolves modifying the switch statement. When these modifications are combined\nwith inheritance and function overloading, the end result is often ‘spaghetti’ code.\nAlso, for large projects with multiple developers, the non-object-oriented design\nof the switch implementation can lead to significant maintenance and debugging\nproblems.\n\nSecond, the performance of this implementation is dependent on the size of the\nFSM. Most switch statements are converted into if-then-else statements by the\ncompiler and are difficult to optimize. For an FSM having states, the program will",
      "page_number": 243,
      "chapter_number": 26,
      "summary": "This chapter covers segment 26 (pages 243-252). Key topics include area, state, and figures.",
      "keywords": [
        "Area",
        "FSM",
        "FSMs",
        "FSM implementation",
        "portal connecting areas",
        "portal",
        "Switch",
        "State",
        "implementation",
        "Switch implementation",
        "game",
        "game object",
        "Current State",
        "attraction",
        "character"
      ],
      "concepts": [
        "area",
        "state",
        "figures",
        "object",
        "path",
        "function",
        "functionality",
        "functions",
        "algorithm",
        "game"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 1",
          "chapter": 25,
          "title": "Segment 25 (pages 227-237)",
          "relevance_score": 0.77,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 1",
          "chapter": 26,
          "title": "Segment 26 (pages 238-247)",
          "relevance_score": 0.7,
          "method": "api"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 1,
          "title": "Segment 1 (pages 1-18)",
          "relevance_score": 0.69,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 2",
          "chapter": 3,
          "title": "Segment 3 (pages 17-24)",
          "relevance_score": 0.68,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 2",
          "chapter": 12,
          "title": "Segment 12 (pages 101-108)",
          "relevance_score": 0.68,
          "method": "api"
        }
      ]
    },
    {
      "number": 27,
      "title": "Segment 27 (pages 253-260)",
      "start_page": 253,
      "end_page": 260,
      "detection_method": "topic_boundary",
      "content": "3.3 Function Pointer-Based, Embedded Finite-State Machines 259\n\naverage about #/2 if-then-else comparisons before finding the appropriate state\nfunction call. If the FSM is distributed over a class hierarchy, the search for an appro-\npriate state function might require several virtual function calls up the class hierarchy\nin addition to the if-then-else comparisons.\n\nA more object-oriented solution to the function-mapping problem is to encapsu-\nlate the state function calls within the current state variable. Since the state functions\nare usually associated with the game object, implementing the state functions directly\nwithin a state object is not practical. However, the state functions can effectively be\nstored within a state object through the use of function pointers.\n\nFunction Pointers\n\nFunction pointers in C are very straightforward, but the syntax is somewhat cryptic.\n<return type>(*<pointer>) (<arguments>)\n\nIn C++, nearly all function calls are made to class member functions. Function\npointers to these functions require significantly more syntax because the functions are\nclass-specific. Accordingly, the declaration syntax requires the class name.\n\n<return type>(<class>: :*<pointer>) (<arguments>)\n\nLet’s assume IsOdd() is a member function of a class called “cMath.” The function\npointer declaration to Isddd() would be:\n\nbool (CMath: :*pfnFunction) {int )=&CMath: :IsOdd;\n\nThe class-specific nature of function pointers to member functions extends\nbeyond the declaration syntax. Function pointers to member functions cannot point\nto functions in a derived class unless the function is already declared in the base class\n[Stroustrup97]. This is a serious limitation because all functions must be declared in\nthe base class, resulting in severe code bloat. On the plus side, function pointers to\nvirtual functions will resolve to the proper function call using the virtual function call\nmechanism. This allows function pointers to member functions to work properly in\nderived class hierarchies (assuming the functions are declared in the base class).\n\nExecution of a member function through a function pointer also presents a prob-\nlem. Member functions use a different calling convention from regular functions as\nthey pass the class instance to the function via a hidden parameter (the this pointer).\nThus, execution of a member function through a function pointer requires a class\ninstance. The code below illustrates the execution of the IsOdd{) member function\nthrough the pfnFunction function pointer.\n\nCMath Instance;\n\nbool bResult=(Instance.*pfnFunction) (5);\nCMath *pInstance=&Instance;\n\nbool bResult=(pInstance->*pfnFunction) (3);\n\n260\n\nSection 3 Artificial Intelligence\n\nWith these limitations, the use of function pointers to store the state functions\nseems difficult at best. For the moment, let us assume that workarounds exist, so we\ncontinue to examine the use of function pointers in an FSM implementation. (For\nmore on function pointers, Lars Haendel’s “The Function Pointer Tutorials” [Haen-\ndel01] is an excellent reference on function pointers, and it is available online.)\n\nThe Function Pointer Implementation\n\nIn a function pointer implementation, each state is now represented as an object.\nWithin this object, the state function calls are stored in function pointers, and the\nfunction mapping occurs when the state is initialized. The FSM tracks the current\nstate by maintaining a pointer to the current state object, and the state function calls\nare executed directly from the state object through the function pointers.\n\nThe primary advantage of the function pointer implementation over the switch\nimplementation is its object-oriented design. The function mapping is now part of\nthe state object and not the game object. This difference in implementation avoids\nthe necessity of extending the FSM execution code into the game object classes.\nInstead of overloading the Update() function in the derived class, new states can be\nadded to the FSM by merely including new state objects.\n\nAnother advantage of this implementation is that the performance is indepen-\ndent of the number of states within the FSM. Since each state object knows exactly\nwhat functions to call, there are no if-then-else comparisons and no traversal of the\ngame object’s class hierarchy.\n\nThis implementation does have some disadvantages, however. Implementation is\nmore difficult due to the limitations inherent in function pointers to member func-\ntions. In addition, this implementation requires significantly more memory, as the\nstate function mapping is now stored as a set of function pointers instead of being\ncompiled into the code.\n\nThe Implementation (CFSM)\n\nIn order to best satisfy the design requirements, the CFSM implementation will consist\nof a base class using the function pointer implementation, as previously described.\nThe CFSM implementation has two separate parts: the state objects and the FSM.\n\nThe State Objects\n\nIn the game object assumptions, we stated that each state in the game object would be\nrepresented as a set of functions. In the CFSM implementation, each state is represented\nby three functions. As an example, let us create a game object class called CEnemy,\nwhich implements an idle state.\n\nclass CEnemy : public CFSM\n\n{\nvoid BeginStateIdle();\n\n3.3 Function Pointer-Based, Embedded Finite-State Machines __ _ 261\n\nhs\n\nvoid StateIdle();\nvoid EndStateIdle();\n\nThe BeginStateIdle() and EndStateIdle() functions are called during state\ntransitions and provide a convenient location for initializing and cleaning up states.\nThe StateIdle() function is the main state function and is called every tick from the\nUpdate() function. Since three functions make up each game object state, the CFSM\nstate object uses three function pointers to store the state functions.\n\nTo create state objects, a two-class hierarchy is necessary. The base class, cstate,\nprovides a generic interface for executing the stored state functions.\n\nclass CState\n\n{\npublic:\nvirtual ~CState() {}\nvirtual void ExecuteBeginState()=0;\nvirtual void ExecuteState()=0;\nvirtual void ExecuteEndState()=0;\n}3\n\nThe second class, CStateTemplate, is derived from CState. To avoid the problem\nof class-specific function pointers, CStateTemplate is a template class.\n\ntemplate <class T>\nclass CStateTemplate : public CState\n\n{\nprotected:\ntypedef void (T::*PFNSTATE) (void) ;\nT *m_pInstance;\nPFNSTATE m_pfnBeginState;\nPFNSTATE m_pfnState;\nPFNSTATE m_pfnEndState;\npublic:\n\nCStateTemplate() : m_pInstance(0),\nm_pfnBeginState(0),\nm_pfnState(0) ,m_pfnEndState(0) {}\n\nvoid Set(T *pInstance,PFNSTATE pfnBeginState,\nPFNSTATE pfnState,PFNSTATE pfnEndState)\n\n{\nm_pInstance=pInstance;\nm_pfnBeginState=pfnBeginState;\nm_pfnState=pfnState;\nm_pfnEndState=pfnEndState;\n\n}\n\nvirtual void ExecuteBeginState()\n\n{\n(m_pInstance->*m_pfnBeginState) ();\n\n}\n\nvirtual void ExecuteState()\n\n262 Section 3 Artificial Intelligence\n\n{\n(m_pInstance->*m_pfnState) ();\n}\nvirtual void ExecuteEndState()\n{\n(m_pInstance->*m_pfnEndState) ();\n}\n\nhs;\n\nCStateTemplate implements the three state function pointers as well as a pointer\nto the class instance. The execution functions from the CState class are overloaded\nand implemented in CStateTemplate. Since CState is the base class for CStateTem-\nplate, a game object can create class-specific state objects using CStateTemplate\ninstances. The FSM implementation, however, can use the state objects generically by\ntreating them as instances of CState and thus avoids having to know the details of a\ngame object in order to execute its state functions.\n\nThe FSM\n\nWith state objects now defined, the CFSM base class can now use them to implement\nthe FSM.\n\nclass CFSM\n\nprotected:\nCState *m_pCurrentState;\nCState *m_pNewState;\nCStateTemplate<CFSM> m_StateInitial;\npublic:\nCFSM();\nvirtual ~CFSM() {}\nvirtual void Update();\nbool IsState(CState &State) ;\nbool GotoState(CState &NewState) ;\nvirtual void BeginStateInitial() {}\nvirtual void StateInitial() {}\nvirtual void EndStateInitial() {}\n\n};\n\nThe current state, m_pCurrentState, isa pointer to a CState object. The use of a\nCState pointer allows the FSM to completely implement the state function execution\ncode within the CFSW’s Update() function. In addition to the current state pointer, a\nCState pointer, m_pNewState, is also declared. This variable is tracked by the FSM and\nwill cause the FSM to execute a state transition if set.\n\nThe CFSM implementation defines an initial state using the CStateTemplate class\nand stores it in the state object m_StateInitial. This state is provided so that the\nFSM implementation always has a state to execute. The CFSM constructor initializes\nthe initial state along with the pointers to the state objects.\n\n3.3 Function Pointer-Based, Embedded Finite-State Machines 263\n\nCFSM: :CFSM()\n\n{\nm_StateInitial.Set(this,BeginStateInitial,\nStateInitial,\nEndStateInitial) ;\nm_pCurrentState=static_cast<CState*>(\n&m_StateInitial) ;\nm_pNewState=0;\n\n}\nThe execution of the state functions occurs in the Update() function.\n\nvoid CFSM: :Update()\n\n{\nif (m_pNewState)\n{\nm_pCurrentState->ExecuteEndState();\nm_pCurrentState=m_pNewState;\nm_pNewState=0;\nm_pCurrentState->ExecuteBeginState() ;\n}\nm_pCurrentState->ExecuteState();\n}\n\nUpon entering the Update() function, the FSM checks for a state transition using\nthe m_pNewState variable. If one is pending, Update() calls the ExecuteEndState()\nand ExecuteBeginState() functions, and changes the current state.\n\nThe GotoState() and IsState() functions are provided to simplify the handling\nof state objects. The GotoState() function sets the new state variable and causes a\nstate transition on the next Update() function call.\n\nbool CFSM::GotoState(CState &NewState)\n\n{\nm_pNewState=&NewState ;\nreturn true;\n\n}\n\nThe IsState() function provides a syntax-friendly method of comparing the cur-\nrent state to any given state.\n\nbool CFSM::IsState(CState &State)\n{\n\n}\n\nreturn (m_pCurrentState==&State) ;\n\nUsing CFSM\n\nBy way of example, we are now going to create a game object that simulates a light-\nbulb. The game object will use the FSM introduced at the beginning of this gem, and\nthe CFSM class will provide the FSM functionality.\n\n264\n\nSection 3 Artificial Intelligence\n\nAdding CFSM to a Class\n\nFirst, we create a class called CLightBulb and derive it from the CFSM base class. To\nimplement the states, we add two state objects using the CStateTemplate class and the\ncorresponding state functions. The two input events are handled through the\nSwitchOnEvent() and SwitchOffEvent () functions.\n\nclass CLightBulb : public CFSM\n{\nprotected:\ncStateTemplate<CLightBulb> m_StateOn;\ncStateTemplate<CLightBulb> m_StateOff;\npublic:\nCLightBulb();\nvirtual void SwitchOnEvent();\nvirtual void SwitchOffEvent();\nvirtual void StateInitial({);\nvirtual void BeginStateOn({);\nvirtual void StateOn() {}\nvirtual void EndStateOn() {}\nvirtual void BeginStateOff{);\nvirtual void StateOff() {}\nvirtual void EndStateOff() {}\n\nhi\n\nThe constructor initializes the CFSM base class and initializes the two state objects.\n\nCLightBulb::CLightBulb() : CFSM()\n\n{\nm_StateOn.Set(this,BeginStateOn,StateOn,\nEndStateOn) ;\nm_StateOff.Set(this,BeginStateOff,StateOdff,\nEndStateOff ) ;\n}\n\nNext, we add the SwitchOnEvent() and SwitchoffEvent() functions for handling\nthe input events and state transition logic.\n\nvoid CLightBulb: :SwitchOnEvent()\n\nif (IsState(m_StateOff) )\nGotoState(m_StateOn) ;\n\n}\nvoid CLightBulb: :SwitchOffEvent()\n{\nif (IsState(m_StateOn) )\nGotoState(m_StateOfFf) ;\n}\n\nSince this is a simple example, the state functions are mostly stub functions.\nHowever, the BeginStateOn() and BeginStateOff() functions contain code for dis-\nplaying the current state so we can follow the FSM’s execution.\n\n3.3 Function Pointer-Based, Embedded Finite-State Machines 265\n\nvoid CLightBulb: :StateBeginOn()\n\n{\ncout << \"State: On” << endl;\n}\nvoid CLightBulb: :StateBeginOff {)\n{\ncout << \"State: Off” << endl;\n}\nFinally, the StateInitial() function is overloaded to ‘jump-start’ the lightbulb\nFSM.\nvoid CLightBulb: :StateInitial({)\n{\nGotoState(m_StateOfFf) ;\n}\n\nChanging an FSM’s Behavior in a Derived Class\n\nLet us create a new class to simulate a flashing light. Since a flashing lightbulb is sim-\nilar to an ordinary lightbulb, we can use the CLightBulb class and simply extend its\nbehavior. First, we need to derive a new class called cFlashingLightBulb from\nCLightBulb. We then need to add a new state for handling the flashing and overload\nthe On state functions from CLightBulb.\n\nclass CFlashingLightBulb : public CLightBulb\n{\nprotected:\ncStateTemplate<CFlashingLightBulb> m_StateOnDim;\nunsigned int m_uTimer;\npublic:\nCFlashingLightBulb({) ;\nvirtual void SwitchOffEvent() ;\nvirtual void BeginStateOn();\nvirtual void StateOn();\nvirtual void BeginStateOnDim() ;\nvirtual void StateOnDim();\nvirtual void EndStateOnDim({) ;\n\noe\nLike the previous example, the new state is initialized in the constructor.\n\nCFlashingLightBulb: :CFlashLightBulb() : CLightBulb()\n\n{\nm_StateOnDim(this ,BeginStateOnDim,StateOnDim,\n\nEndStateOnDim) ;\n}\n\nThe flashing behavior will be handled by cycling between the On and On Dim\nstates, with a timer controlling the flash interval. The On state functions from\nCLightBulb are overloaded to reflect the new behavior.\n\n266\n\nvoid CFlashingLightBulb: :BeginStateOn()\n\n{\nCLightBulb: :BeginStateOn() ;\nm_uTimer=10;\n}\nvoid CFlashingLightBulb: :State0n()\n{\n--m_uTimer;\nif (m_uTimer==0)\nGotoState(m_StateOnDim) ;\n}\n\nLikewise, we implement the On Dim state functions.\n\nvoid CFlashingLightBulb: :BeginStateOnDim( )\n\n{\ncout << \"State: On Dim\" << endl;\nm_uTimer=10;\n}\nvoid CFlashingLightBulb: :StateOnDim()\n{\n--m_uTimer ;\nif (m_uTimer==0)\nGotoState(m_StateOn) ;\n}\n\nFinally, we update the SwitchOffEvent() function to take into account the new\nstate.\n\nvoid CLightBulb: :SwitchOffEvent()\n\nif (IsState(m_StateOn) || IsState(m_StateOnDim) )\nGotoState(m_StateOff) ;\n\n}\n\nDuring execution, the FSM will cycle between the On and On Dim states, thus\nsimulating the behavior of a flashing light. This example illustrates both the use of\nnew states and the overloading of existing states to extend the behavior of the FSM.\n\nConclusion\n\nThis gem illustrates an FSM implementation using function pointers that allows\ndevelopers to quickly add FSM functionality to either new or existing game objects.\nWhile applicable for game development in its current form, the FSM implementation\npresented here is minimal and intended mainly to be used as a starting point for\ndevelopers wishing to create their own FSM implementations. Accordingly, there are\nmany areas of possible modification, including memory optimizations, more-compli-\ncated state-transition logic, customized state objects, and additional error checking.",
      "page_number": 253,
      "chapter_number": 27,
      "summary": "Execution of a member function through a function pointer also presents a prob-\nlem Key topics include function, functions, and functionality. If the FSM is distributed over a class hierarchy, the search for an appro-\npriate state function might require several virtual function calls up the class hierarchy\nin addition to the if-then-else comparisons.",
      "keywords": [
        "function pointers",
        "state",
        "Function",
        "state functions",
        "functions",
        "FSM",
        "Function Pointer Implementation",
        "CFSM",
        "state objects",
        "virtual void",
        "void",
        "state function calls",
        "pointers",
        "state function pointers",
        "virtual"
      ],
      "concepts": [
        "function",
        "functions",
        "functionality",
        "state",
        "stated",
        "void",
        "classes",
        "virtual",
        "pointer",
        "implementing"
      ],
      "similar_chapters": [
        {
          "book": "More Effective C++",
          "chapter": 14,
          "title": "Segment 14 (pages 133-140)",
          "relevance_score": 0.64,
          "method": "api"
        },
        {
          "book": "C++ Concurrency in Action",
          "chapter": 14,
          "title": "Segment 14 (pages 123-131)",
          "relevance_score": 0.61,
          "method": "api"
        },
        {
          "book": "C++ Concurrency in Action",
          "chapter": 53,
          "title": "Segment 53 (pages 582-589)",
          "relevance_score": 0.59,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 2",
          "chapter": 26,
          "title": "Segment 26 (pages 249-257)",
          "relevance_score": 0.59,
          "method": "api"
        },
        {
          "book": "More Effective C++",
          "chapter": 32,
          "title": "Segment 32 (pages 320-329)",
          "relevance_score": 0.59,
          "method": "api"
        }
      ]
    },
    {
      "number": 28,
      "title": "Segment 28 (pages 261-270)",
      "start_page": 261,
      "end_page": 270,
      "detection_method": "topic_boundary",
      "content": "3.3 Function Pointer-Based, Embedded Finite-State Machines 267\n\nReferences\n\n[Calder94] Calder, Brad, Dirk Grundwald, and Benjamin Zorn, “Quantifying\nBehavioral Differences Between C and C++ Programs,” available online at\nhetp://www.cs.colorado.edu/department/publications/reports/docs/CU-CS-698-\n94.ps, January 1994.\n\n[Dysband00] Dysband, Eric, “A Finite-State Machine Class,” Game Programming\nGems, Charles River Media, Inc., 2000: pp. 237-248.\n\n[Haendel01] Haendel, Lars, “The Function Pointer Tutorials,” available online at\nhttp://www.function-pointer.org, October 2001.\n\n[LaMothe99] LaMothe, Andre, Tricks of the Windows Game Programming Gurus,\nSams, 1999: pp. 729-734.\n\n[Stroustrup97] Stroustrup, Bjarne, The C++ Programming Language, Third Edition,\nAddison Wesley Longman, Inc., 1997: pp. 418-421.\n\n[Sweeney00] Sweeney, Tim, “Unreal Technology FAQ,” available online at http://\nunreal.epicgames.com/UnrealScript.htm, June 2000.\n\n[Woodcock00] Woodcock, Steve, “Game AI: The State of the Industry,” Game\nDeveloper Magazine, August 2000: pp. 34—43.\n\n[Woodeock0 1} Woodcock, Steve, “Game AI: The State of the Industry,” Game\nDeveloper Magazine, August 2001: pp. 24-32.\n\n3.4\n\nAreas\n\nmeniscus .\n\n268\n\nTerrain Analysis in an RTS—\nThe Hidden Giant\n\nDaniel Higgins,\nStainless Steel Studios, Inc.\ndan@stainlesssteelstudios.com\n\nA’ children (and, well, even as adults), we strive to understand the world around\nus. By the time we enter school, we can easily recognize and identify many\nthings. We know what a street is, or a building, and can recognize the sky, the ocean,\na hill, and a forest. Even if we had silly notions as kids, such as the woods behind our\nsuburban home actually being part of a forest that stretched on for miles, we at least\nrecognized these terrain elements and many of their properties.\n\nMoving into the virtual world, computer games strive to provide a rich environ-\nment for players by creating a world that is full of interesting terrain elements. Just as\na teenager can decide either to cut through the woods to get to a friend’s house or go\nby way of the street, programmers can use the same type of terrain information to\nmake decisions. Programmers might have a virtual teenager avoid traveling through\nthe forest if it’s after sunset, or perhaps take a chance on the forest if they are walking\nwith a group of friends.\n\nGathering the information about the world environment is called terrain analysis.\nIt is a vital element of today’s computer games, especially real-time strategy (RTS)\ngames. Unfortunately, this important task can be overlooked or grossly underesti-\nmated in terms of development time. Make no mistake—writing a terrain-analysis\nengine can be a gigantic undertaking, depending on how much information you want\nto analyze. However, it is one of the most important developmental tasks in an RTS\ngame.\n\nGARB RE EES H IN BETIS A E UMR ENE HEE\n\nThe first step in terrain analysis is planning. When choosing what terrain elements to\nanalyze, we must consider: “What areas do I need to know about?” Will you want to\nrecognize forests, choke points, or oceans in your game? Brainstorm a list of world\nareas you will want to recognize.\n\nAfter brainstorming a list of areas, you might find that these areas need to be\ndivided into two major categories: static and dynamic. Despite conceptual differ-\n\nin an RTS—The Hidden Giant 269\n\nences, static and dynamic areas can be represented very similarly (if not identically) in\ncode. Since both are very similar, you should consider writing a generic “Area” base\nclass full of virtual methods that will facilitate easier future programming.\n\nStatic Areas\n\nStatic areas don’t change throughout the course of the game. Generally, static areas\ntend to have the most points (or tiles) and cover the largest areas. In contrast to\ndynamic areas, static areas must be preprocessed before the game starts. This is an\nadvantage over dynamic areas because dynamic areas might need frequent processing\nbefore, during, and after the game.\n\nReprocessing a very large area during runtime could make the game slow down to\na crawl, or it could even freeze the game world. That would be a disaster for a game\nand obviously should be avoided. Static areas are therefore a necessity in order to\nreduce processing time during a game.\n\nSome examples of static areas are:\n\n¢ Continents: Continents are one of the most important areas of terrain analysis.\nEvery point on every map should exist on some type of continent, even if the\npoint is a cliff, an ocean, or a waterfall. Continents are used to determine\nthe accessibility properties of different parts of the map. You might have naval\nunits that can only travel in ocean continents, land units that can only traverse\nland continents, or air units that can fly over all continent types.\n\n¢ Hills: If an RTS engine makes use of true line of sight or gives an advantage to\nfighting on an elevation, then detecting hills is a good idea. In Empire Earth, we\ndefined a hill as a collection of points adjacent to each other that are above a cer-\ntain elevation level. We found hills to be very useful for adding to the perception\nthat the computer player played intelligently. Archers owned by the computer\nplayer might flee to a nearby hill to attack from an elevated point, or perhaps the\ncomputer player would choose a hill near a resource site as a good spot for a guard\ntower.\n\n* Shore Tiles: A shore tile is defined as a tile that meets the ocean and the land.\nThis means some shore tiles exist mainly in the ocean and some exist in the shal-\nlow water where most land units can walk. A game with shore waves can use shore\ntiles to determine if they should make a wave, how far out it should start in the\nocean, and what its neighboring waves should look like. Shore tiles can also be\nvery useful for determining at what point a transport ship should pick up or drop\noff a unit.\n\n¢ Shore Rings: Shore rings are defined as tiles that exist within some distance of\nland. If a tile exists two tiles from land, then it would be stored in ‘shore ring 2.’\nShore rings work great for RTS games with units that can span multiple tiles.\nSince collision detection with large units can be a tricky issue, one way to keep\ngigantic ships like aircraft carriers from traveling too close to the land is to build\nrings around the coastline. Any number of rings can be used to keep different\n\n270\n\nSection 3 Artificial Intelligence\n\nsizes of ships from reaching the land. If keeping ships away from coastlines is not\nan issue, this is probably not an area that needs to be processed.\n\nDynamic Areas\n\nDynamic areas, which change with the runtime variations of the world, help keep a\ngame from getting stale and add longevity to a product. Computer players that react\nto a changing world provide a greater illusion of intelligence to human players and\ncan give players a fresh gaming experience every time they play.\n\nIn the code, dynamic areas look much the same as static areas, but dynamic areas\ncarry an inherent danger with them. If an area is very large and needs to be\nreprocessed often during a game, it can cause the game to run poorly or even freeze.\nThis can be avoided with some creative tricks, but efficiently reprocessing dynamic\nareas goes beyond the scope of this gem.\n\nSome examples of useful dynamic areas in an RTS are:\n\n* Forests: Forests are defined as a collection of trees that all touch each other.\nForests need to be dynamic, since if a player chops down a tree, the old location\nof the tree should no longer report that it belongs in a forest. If we assume people\nunderstand and recognize forests, then it’s easy to put them to good use. The uses\nof forests should be intuitive. For example, if the player selects a citizen, then\nclicks on a tree in the middle of a forest, the player will probably expect that the\ncitizen (or unit) would harvest from a tree in the vicinity of the unreachable one\nthat was clicked on. If we have analyzed the forest, then we have a variety of sim-\nple ways to find the perfect tree to chop. One technique is simply to go to the\nclosest tree to the unit. Another technique is to calculate the line from the unit to\nthe selected tree, find the first tree in the forest that the line intersects, and then\nsend the unit to that tree. The AI can also use knowledge about the forest for var-\nious tasks, such as planning where to build a wall or where to hide units for an\nambush.\n\n¢ Towns: In the everyday world, most people think of a town as a collection of\nbuildings that are within proximity of each other. The concept is much the same\nin an RTS, with the exception that in the game world, towns should be repre-\nsented as a convex hull in which a number of buildings live (see Figure 3.4.1).\n\nTowns are dynamic because they can grow, shrink, or even merge when a\nbuilding is created or destroyed. Towns also differ from most other areas because\nthe convex hull encompassing all the points is more significant than the points\ninside (individual buildings). In a sense, if one wants to see if a given point were\ninside a town, then they would need to get its convex hull and do a point-in-\npolygon test instead of checking its actual points.\n\nTowns are created and destroyed when buildings are built or razed. The\nprocess of assigning a building to a town starts with the newly constructed build-\ning checking its distance to each town’s convex hull. The distances are then used\nto determine if the new building should join a town, merge two or more towns,\n\n3.4 Terrain Analysis in an RTS—The Hidden Giant 271\n\nfe map1_ply - Terain Analysis Test Application :\n\nCreate: 5248 us (5 ms}\nSlowInsert: 5545 us (5 ms)\nBuildPointList: 9804 us (9 ms]\nContains: 3011 us (3 ms)\nExtremePaints: 98 us (0 ms}\nRemove: 61 us (0 m3}\n\nFIGURE 3.4.1 Highlighted area indicates a town.\n\nor create a new town of its own. If a building is within the acceptable distance of\ntwo towns, the towns merge and become a single, larger town.\n\nAn identified town can also serve a greater purpose than just mapping out a\ncluster of player buildings. Storing information about a town can help the AI\nunits make intelligent decisions about where to attack, with what units, and what\nstrategy is best for approaching a town.\n\nA few of the many pieces of information that can be stored about a town are:\n\n* IsCoastal: In many situations it can be quite useful to know if a town is\nlocated near an ocean. The most obvious use for this is to let the computer\nplayer quickly know if they should bother bringing in sea units to bombard\nthe town.\n\n272 Section 3 Artificial Intelligence\n\n* TownCost: Computing the economic cost of all the buildings in the town can\ntell the computer player if this is the enemy's biggest town, or if it’s really just a\nsmall hamlet.\n\n¢ Choke Points: Choke points are defined as a narrow routes, such as between two\nforests, which provide passage through to other regions. Choke points are useful\nfor RTS computer players in that they can indicate good guard locations, ambush\nspots, and wall building locations. They can even help a computer player avoid\nblocking itself in by indicating where not to construct buildings. A more detailed\nchoke point description and algorithm can be found later in this gem.\n\n¢ Herds: Herds are packs of similar animal units that share a territory and group\ndynamics. Tracking herds as areas provides a way to keep the herd acting realisti-\ncally, such as having territory disputes or moving around the game world as a\ngroup.\n\ne Armies: Armies are certainly dynamic. They can grow and shrink many times in\nthe course of a game. They are primarily useful for the computer player and its\nplayer interaction, but there are other creative game-engine uses for armies as\nwell, including group movement and group behaviors.\n\nBuilding Generic Areas\n\nObject-oriented programming (OOP) techniques can sometimes have a large up-\nfront development cost; but in general, they make subsequent development faster and\neasier. Designing a generic area system is an example of how OOP can make life easier\nin the long run.\n\nAn area class needs only a few data members. It needs to know the points inside\nthem, the convex hull of those points (more on that soon), the type of area they are,\nand lastly, it needs to have a unique ID. In addition to data, areas should have some\nvirtual methods to make using them a snap.\n\nVirtual methods should include:\n\n* Create(): Creates the area.\n\n* GetClosestPoint(): Gets the closest point to a given point.\n\n* GetClosestPointToArea(): This method takes another area and returns the clos-\nest point between the two areas.\n\n© GetClosestPointToHull(): This is different than GetClosestPoint() because it\nrelies on checking the hull. You could make your derived classes call GetClosest -\nPointToHull() in the GetClosestPoint() method. This is most useful for areas\nlike towns, which have few actual points (the buildings); but you want it to seem\nlike every point in a town is actually stored inside this object (instead of just the\nfew that were used to make the hull).\n\n* GetRandomPoint(): This is probably the most useful area-related method. Using\nthis for computer-player guard destinations saves development time and can help\ncreate the illusion of intelligence.\n\n3.4 Terrain Analysis in an RTS—The Hidden Giant 273\n\nOptimization Tip: When you derive a continent area, consider putting lots of\nother areas inside the continent class. For example, have a vector of choke points on\nthe continent so that programmers can quickly get the choke points that they want.\nThis can also serve as a memory optimization for other areas. Using continents as sort\nof a hash table can cut down the search time for tasks, like finding which forest’s hull\na user clicked in. If you return the continent the user clicked on and only search that\nforest, you've cut down your search time.\n\nBuilding your area system with a generic base class will make using your areas a\nlot easier. Your computer player can often make intelligent decisions just by perform-\ning some basic actions on areas without having to know much about the area with\nwhich they are interacting.\n\nOne of the more-complex areas of simulating human intelligence deals with the com-\nputer’s lack of vision. A human can receive an enormous amount of data in a few\nblinks of an eye, while our computer companions cannot. We can simulate this\nbehavior by using a simple and powerful geometric shape, the convex hull.\n\nA convex hull is a shape that does not fold in on itself. If one were to walk clock-\nwise around the edges of a hull, they would turn only to the right and never to the\nleft. Also, If you were to draw a line between those points, the line would never leave\nthe convex hull.\n\nWhile a convex hull is a shape that can exist in many dimensions, for reasons of\nefficiency and usefulness to most RTS engines, it’s generally safe to focus on the 2D\ncase. Certainly, developing a hull system that works in multiple dimensions has its\nbenefits given the development time or specific need for them.\n\nWhy Use Convex Hulls?\n\nConvex hulls take up very little memory, can be very efficient, and provide a fuzzy\nlevel of accuracy. On one end of the spectrum, you could have perfect accuracy by just\nkeeping a list of all the points, but this would be costly in terms of memory usage as\nwell as performance. A concave hull could be more accurate, but it would cost more\nin memory and performance. On the other end of the spectrum, you can use bound-\ning boxes or bounding circles to approximate the areas in question. Both of these use\nvery little memory and can be more efficient (performance-wise), but they suffer from\npoor accuracy in representation. The convex hull brings all of these together, giving us\ngood accuracy, good performance, and low memory usage.\n\nConvex hulls can be used in almost every area of an RTS game engine. They are\nideal for determining if a unit is hidden in the vicinity of a forest or ifa unit has crossed\nthe borders of a town. They also make the creation of complicated AI behaviors simple\nto implement because they provide the programmer with a quick representation of an\narea. Being a special geometric shape, they are bound to mathematical rules that allow\nthe AI to make optimizations and assumptions based on those rules (see Figure 3.4.2).\n\nRemove: 61 us (0 ms)\n\n'fsssercessasssss==sss=\n\nFIGURE 3.4.2 A convex hull surrounds an area (shown in a test application).\n\nIt’s not just the useful tasks alone that make the investment in convex hulls so\nappealing. The development time for hulls is fairly short, since the math knowledge\nrequired for writing 2D convex hulls is small (i-e., implementation shouldn't be diffi-\ncult for programmers who aren’t math gurus).\n\nWhat's in a Hull?\n\nA convex hull is really a polygon with special rules. It therefore makes sense to begin\nthe construction of a convex hull class by constructing a base polygon class. It is also\na good idea to make the polygon/convex hull class a template, since most tasks in an\nPC-based RTS game can use integer-based hulls for added performance. Otherwise,\nwe use float-based hulls.\n\nin an RTS—The Hidden Giant 275\n\nTable 3.4.1 Data Members for a Polygon Class\n\nType Variable Description\nvector<U2DPoint<T>> mPoints All the vertices of the polygon.\nU2DRectangle<T> mBoundingBox Quick representation of the\narea of the polygon. Its area\ncovers the extreme points of\nthe hull or polygon. The box\nhas two points, one at top left,\nand the other at bottom right.\nU2DPoint<T> mCenterPoint Center of mass point. This is\n\nvery handy for making quick,\nfuzzy decisions about distances\n\nto a polygon, or as a homing\n\nbeacon for this shape.\nfloat mArea The area inside the polygon.\n\nNote: U2DPoint<T> is a template xy point class, and U2DRectangle<T> is a template rectangle class\nwith top, left, right, and bottom coordinates.\n\nData members for a polygon class might appear like those shown in Table 3.4.1.\n\nSince this is a base class, there are quite a few necessary virtual methods that it\nshould provide in addition to the normal Get/Set and construction/destruction\nmethods.\n\n* CalculateArea(): Determines the area of the polygon or hull.\n\n* ClearPolygon(): Clears the polygon’s data.\n\n* Contains(): This inline version does a fast point-in-rectangle check before calling\nthe virtual and more-expensive ContainsInPoly() method.\n\ninline bool Contains(const U2DPoint<T>& inPoint) const\n{ return (this->mBoundingBox.Contains(inPoint)) ?\nthis->ContainsInPoly(inPoint) : false; }\n\n* ContainsInPoly(): This virtual method does the appropriate point-in-polygon\ntest for the given point.\n\n* Create(): This creates the polygon, and an optional sorted flag is passed as an\noptimization for shapes like the convex hull.\n\n* CreateCenterPoint(): This virtual method computes the center point using the\nappropriate algorithm. One way to compute the center point is the center-of-\nmass method described here.\n\nU2DPoint<float> theSums(0.0f,0.0f) ;\nlong theSize = this->mPoints.size();\nlong theLoop;\n\n276\n\nSection 3 Artificial Intelligence\n\nsavour RSE EEN SAN A ER Rh RO HS SN OSH NTO ATOM HOES\n\n/* Sum up all the points. */\nfor(theLoop = theSize - 1; theLoop >= 0; theLoop--)\n\n{\n// cast to floats regardless of template type.\n\ntheSums .SetX(theSums .GetX() +\n((float)mPoints[theLoop] .GetX() /(float)theSize) );\n\n// cast to floats regardless of template type.\n\ntheSums.SetY(theSums.GetY() +\n\n((float)mPoints[theLoop].GetY() / float)theSize));\n}\n\n//{ cast it into the right format: (template function)\ntheSums .CopyTo(this->mCenterPoint); }\n\n* €xpand(): A handy method for increasing the size of polygons proportionally by\nexpanding outward, a simple expand algorithm would be to draw a line from\neach vertex to the center point and project that vertex away from the center.\n\n* GetClosestPoint(): One of the most useful methods for a convex hull, GetC1los-\nestPoint() returns a potentially fabricated point on the hull. It’s a good idea to\nhave two closest-point methods, one for returning the closest vertex and one for\nreturning the closest line-intersection point on the hull or polygon.\n\n* GetClosestPoints(): Use this method to find the closest point given two poly-\ngons or convex hulls.\n\n* GetIntersection(): Returns true if the two polygons intersect and can optionally\ncreate a polygon representing the intersection.\n\n* SortPoints(): This is a template function used to sort the points.\n\ntemplate<class K> // inFO is a function object.\ninline void SortPoints(const K& inFO)\n{ std::sort(mPoints.begin(), mPoints.end(), inFO); }\n\n* TrimToVitalPoints(): This is where the convex hull-creation algorithm should\nrun; however a normal polygon would probably do nothing in this method.\n\nDeriving from U2DPolygon<T>, the convex hull class needs to overload some of\nthe polygon’s base class methods, and one of the most important methods is Create().\n\nThe Create() method is the entry point for the convex hull-creation algorithm.\nPicking the right algorithm to construct a hull will make a big difference in hull-cre-\nation performance. There are many published convex hull-creation methods and util-\nity functions [O’Rourke98]. One of the favorites among programmers, and the\nmethod used in Empire Earth, is Graham’s algorithm [O’Rourke98].\n\nOptimization Tip: The most expensive part of Graham's algorithm is sorting the\npoints; passing in an ‘already sorted’ flag for those rare occasions when you already\nhave a list of sorted points will save you some CPU time.\n\nConvex hulls are very effective elements in terrain analysis as they allow the pro-\ngrammer to create lots of incredible features in relatively little time. Powerful features",
      "page_number": 261,
      "chapter_number": 28,
      "summary": "This chapter covers segment 28 (pages 261-270). Key topics include areas, points, and game. [Dysband00] Dysband, Eric, “A Finite-State Machine Class,” Game Programming\nGems, Charles River Media, Inc., 2000: pp.",
      "keywords": [
        "convex hull",
        "Dirk Grundwald",
        "Benjamin Zorn",
        "Areas",
        "Embedded Finite-State Machines",
        "hull",
        "dynamic areas",
        "Game",
        "convex",
        "convex hull class",
        "points",
        "RTS",
        "Static Areas",
        "RTS game",
        "town"
      ],
      "concepts": [
        "areas",
        "points",
        "game",
        "gaming",
        "methods",
        "hulls",
        "useful",
        "uses",
        "towns",
        "classes"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 7",
          "chapter": 64,
          "title": "Segment 64 (pages 617-624)",
          "relevance_score": 0.55,
          "method": "api"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 9,
          "title": "Segment 9 (pages 160-181)",
          "relevance_score": 0.54,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 7",
          "chapter": 63,
          "title": "Segment 63 (pages 609-616)",
          "relevance_score": 0.53,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 24,
          "title": "Segment 24 (pages 222-231)",
          "relevance_score": 0.53,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 1",
          "chapter": 25,
          "title": "Segment 25 (pages 227-237)",
          "relevance_score": 0.52,
          "method": "api"
        }
      ]
    },
    {
      "number": 29,
      "title": "Segment 29 (pages 271-278)",
      "start_page": 271,
      "end_page": 278,
      "detection_method": "topic_boundary",
      "content": "277\n\nand low development costs are two things that designers, gamers, and programmers\ncan all smile about.\n\nThe Giant in the Matchbox\n\nORS NERS a PANERA ASAE RELL ARRT EPA ION CLE Sad\n\nHaving the convex hull of an area is terrific—until you need to get an actual point\nfrom the area. If you want a real point (a point that exists on a continent, for example,\nand not just in its convex hull), then you will need a data structure to contain all of\nthe continent's points.\n\nEgads! You're probably imagining thousands or millions of points floating around\nin memory. It is true that gigantic maps and even some smaller maps will be serious\nmemory hogs unless we can employ smarter techniques.\n\nWhat we need is a memory superhero, something to crunch all these evil points\ninto a tiny space without causing a major CPU hit. Answering the call for this crisis is:\nMajor Matchbox—the template-based U2DMatchboxContainer class.\n\nThe u2DMatchboxContainer class, known throughout the rest of this gem as the\n“matchbox container,” is a series of linked lists that contain point ranges and simulate\nactual points. A matchbox container is really just a one-dimensional array in x, which\ncan contain linked lists of start and end y value nodes.\n\nConsider a square blank map that consists of a single land continent. If the map\nis 400 x 400, then the continent contains 160,000 points. If we put these points\ninside a matchbox container, the 160,000 points end up turning into only 400 points,\nsince we only need to store one point for each x value. This is because the continent is\nalready convex (it’s a square). If we take a more-complicated example and store the\npoints from Figure 3.4.3a in a matchbox container, the end result would look much\n\nlike Figure 3.4.3b.\n\nConti\n\nnent “|\n\ne=end\n\nor Area _ sie = start and end nodes\n\nA B\n\nFIGURE 3.4.3 (a) A continent or area. (6) How a continent’ points would be stored in a matchbox\n\ncontainer.\n\nSection 3 Artificial Intelligence\n\nWhat’s in the Matchbox?\n\nThere are three important structures in the matchbox system—the matchbox con-\ntainer node, the matchbox container list header, and the manager of all these: the\nmatchbox container. Inside the matchbox container lives an array of header nodes.\nThe array represents the x-axis, although it could just as easily represent the y-axis, or\neven be dynamically based, which would take up less memory.\n\nData members for the matchbox container are shown in Table 3.4.2. Note that\n\nthis should be made into a template class; but for simplicity, this is being shown as an\ninteger container.\n\nTable 3.4.2 Data Members for the Matchbox Container\n\nvector<MatchboxListHeader*> MPointArray X-axis representation of\n\nVariabl Description\n\npoints. Each element in the\narray is a y (start-end) point\n\nlong\n\nrange-linked list.\nMOffset Odds are that x won’t start at\nzero; but we want our array\n\nlong\n\nto start at zero, so we will\nshift all incoming x\n\ncoordinates by this amount.\nThis means if our points go\nfrom x,y (10,50) to (25,99),\nthen our offset would be 10.\nMSize Number of points inside this container.\n\nSome of the methods for the matchbox container are:\n\nBuildPointList(): Fills the incoming vector with all of our points. In a sense, it\nputs all of our points into an array format. Passing in a step level is important for\ntemplate versions because, if this container used floating-point numbers instead\nof integers, the step level would indicate at what rate we increment each value as\nwe generate our list of points.\n\nComputeCenterPoint(): This handy method uses a center-of-mass computation\nto determine the center of all these points.\n\nContains(): Returns true if the passed-in-point exists (real or implied) inside this\ncontainer.\n\nCreate(): Creates our container from the passed-in-points.\n\nGetClosestPoint(): Odds are, you'll eventually want to quickly retrieve the clos-\nest point to a passed-in-point or another matchbox container.\nGetOnlyExtremeEdgePoints(): This gets only the extreme edges of a polygon.\nThis means if a continent is doughnut shaped, none of the inner-rim doughnut\n\n3.4 Terrain Analysis in an RTS—The Hidden Giant 279\n\npoints would be returned. This is ideal for optimizing the computation of a con-\nvex hull. It's a huge optimization to build a hull with 200 points instead of\n80,000. It’s also possible to write a very fast convex hull-creation method based\non previously known extreme points and incorporating the sorting implied in the\nstorage of this structure.\n\n® GetRandomPoint(): By passing in a random number generator, you can have a get-\nrandom-point method that will be used more than you might expect.\n\n* Insert(): Having three insert methods is useful. One method takes a point,\nanother takes a vector of points, and a third method takes a matchbox container.\n\n* Remove: Given a point or a vector of points, this method should remove them\nfrom the container.\n\n* Operator[]: A useful method that simulates an array traversal.\n\nMatchboxListHeader\n\nThis class contains a linked list of container nodes and a size. It does most of the work\nby inserting, removing, and merging nodes.\n\nMatchbox Container Node\nThe matchbox container node contains a start y and an end y coordinate. All methods\nin it are based on checks to see if a passed in point or coordinate exists within its start-\n\nto-end range.\nA Contains() method would look like this:\n\ninline bool Contains(long inNum) const\n{ return (inNum >= this->mStart && inNum <= this->mEnd); }\n\nBy putting the pieces of the matchbox nodes, header, and container together,\nyou'll have a fast data structure capable of handling many points in a small amount of\nmemory. It’s an incredibly useful tool for optimizing terrain analysis and other areas.\nMost game engines use points, and therefore should have this or a similar structure in\ntheir toolbox.\n\nYou will recall that choke points are narrow passages that provide access to other\nregions. That being said, the method of creating choke points is really unique to every\ngame. In the RTS game Empire Earth, choke points are created when two or more\nlarge areas—such as a forest, cliff, ocean, or edge of the map—are near each other but\ndo not touch (see Figure 3.4.4).\n\nFrom out of the Blue\n\nImagine it is a bright sunny day and you want to send a cavalcade of riders and vil-\nlagers north toward the plains to build a settlement. You seem cheery and optimistic\n\n280\n\nSection 3 Artificial intelligence\n\nas you set out on your journey. You anticipate a smooth trip, since reports of enemy\nsightings along the road have been minimal.\n\nWhile on your journey, you approach a passage that is flanked by a forest on either\nside. The passage seems harmless enough as your traveling companions bask in the\nbright morning sun and smile at the sound of singing birds. Midway through the\nwooded lane, the songs of the birds become drowned out by a volley of curses and the\nthunder of hooves, which seem to come from all directions. The passage, once a tran-\nquil scene, now seems to be collapsing in around you with a hail of fiery arrows and\ncharging horsemen! Screams fill the air as you beckon your troops to turn back. You\nwheel and turn, only to have lines of despair crease your forehead. You watch helplessly\nas the rear of your army collapses under a mass of enemy troops. Your army breaks in a\npanic, and you stare, too shocked to move, at the helpless villagers that were under\nyour protection. You put your hands to your ears, attempting to block the screams that\nwere once laughing, joking voices. There is no escape, the enemy is everywhere at once,\nand the only choice is to charge blindly into the rising dust at either the front or the\nrear of the passage. You know what must be done; and you begin your final assault. You\nare now one of the screaming horde, sword raised, horse charging, and for the few\nmoments before you are cut down, you try to even the score a bit.\n\nThe Plan\n\nHow did the computer player plan such an evil encounter? Was it good planning,\nluck, or perhaps just knowing information about the terrain? As you might imagine,\nchoke points are great for planning ambushes. Let’s walk through how the computer\nwas able to plan this attack.\n\nFirst, the computer must pick a choke point from which to launch its ambush.\nMaybe it selected a random choke point or found a highly traveled one, or perhaps it\neven selected one between the enemy (the human player) and the main town. Regard-\nless of how it was chosen, the computer might choose to divide its ambush troops into\nfour divisions and place them all at opposite, extreme points of the choke point, as\nindicated in Figure 3.4.4.\n\nNotice that the four black Xs are the farthest points of the choke point. This is\nwhere the computer player hides its troops and waits for the enemy to pass. It waits\nand watches until the enemy has reached the center of the choke point (the + sign),\nthen the computer lets out a howl and attacks!\n\nIn Empire Earth, having the choke point, together with its points and its convex\nhull, made planning and executing this ambush simple. The computer player did not\nhave to do a lot of intensive CPU planning. Instead, it simply picked a good spot and\nthen waited for its opportunity to attack.\n\nFinding the Choke Point\n\nThe algorithm for finding a choke point temporarily costs a large amount of memory\nand CPU time, all of which fortunately go away once the choke points have been\n\n3.4 Terrain Analysis in an RTS—The Hidden Giant _ 281\n\nFIGURE 3.4.4 Ambush in a choke point.\n\ncomputed. Most of the memory requirements involved go into making the algorithm\nrun quickly, so you can trade performance for memory if you wish.\n\nBefore we describe the algorithm, keep in mind that you'll need quite a few\n(mainly integer) arrays that are the size of the world. Don’t panic; this is only tempo-\nrary memory and will be returned after the choke points are computed. If you can’t\nafford the memory even temporarily, consider breaking the world down into conti-\nnents or some other area division first, and then use the bounding box of the conti-\nnent or area as the ‘map of the world.’\n\nThe idea behind this algorithm is that each terrain area is given an influence\n(called throughout the rest of this gem as an “aura”) that can grow. The number of\npasses this algorithm will perform determines how much this aura will grow. If two or\nmore auras intersect each other, then a choke point is formed.\n\nThe main loop of the algorithm is as follows:\n\n// copy the original map into choke point map.\nCopyOriginalMapInt oChokePointMap(inMap, theOutMap) ;\n\n// inPasses controls how much area's auras grow.\nfor(theLoop = inPasses - 1; theLoop > 0; theLoop--)\n{\n\n282 Section 3 Artificial Intelligence\n\ninfluence\naura\n(light grey)\n\nFIGURE 3.4.5 An area (dark color) and its influence aura (light gray).\n\n// copy the map. (uses cached map from above\n\n// the loop)\n\nCopyOriginalMapIntoChokePointMap(inMap,\ntheResultMap) ;\n\n// apply the algorithm\nApplyChokePointAlgorithmToMap(theOutMap,\ntheTempMap, theMaxX, theMaxyY));\n\n}\n// create the final choke points.\n\nCreateChokePointAreas(inMap) ;\n\nBefore the main loop begins, we have to generate and cache a map of obstacles. If\na tile has an obstacle on it, then the tile gets a blocked cost (whatever is appropriate\nfor your game), otherwise it gets a zero cost.\n\nThen, for every tile in the world:\n\n// cache the XY array position\nlong thexY = ((theXLoop * theMaxX) + theYLoop);\n\n// if this tile is blocked, fill in the areas id\nif (ChokePoint: : IsBlockedTile(inMap ->GetTile(theXLoop,\ntheYLoop), theXLoop, theYLoop, theArealID) )\n\n{\n// store the blocking area's id and set a cost.\nChokePoint: :sTerrainIDMap[thexY] = theArealID;\nChokePoint: :sCostMap[theXY] = kBlockedCost;\n\n}\n\nelse\n\n3.4 Terrain Analysis in an RTS—The Hidden Giant 283\n\nelt IE SON ER US RR RH RCE EERE LE ORO\n\nChokePoint::sTerrainIDMap[thexXY] = 0;\nChokePoint: :sCostMap[thexY] = 0;\n}\n\nAfter caching these values in the static cost/terrain ID map, subsequent calls to\nCopyOriginalMapIntoChokePointMap() will simply do a memcpy()of the sCostMap.\n\nThe real algorithm is in the ApplyChokePointAlgorithmToMap() method. This\nmethod must loop through every tile in the world (‘“tile” in this case means the map\nof open and obstacle tiles). If a tile does not have an obstacle, then for each of this\ntile’s neighbors, we sum up all the costs for all the nonblocking tiles. To add up each\nneighbor's cost, we simply refer to the ‘current cost map,’ which means we get all the\ncosts from previous algorithm passes. Using the costs from prior passes is what makes\nthe auras grow.\n\nIf we get a tile with a cost when looping through the neighboring tiles, we then\ncache its area ID. This tells us from which area the aura grew. That’s not enough,\nhowever, since we have to identify whether this cost came from our aura or a different\none.\n\nAs the auras grow, they mark tiles as being from their aura. If the auras intersect,\nthey mark tiles with a ‘compound-area’ ID. If we see that one of our neighbors has\neither the compound-area ID or an aura ID that is not our own, then we keep this\ncost. Otherwise, we set our cost to zero if no neighbors have a cost and come from\neither a different aura or a compound aura. This keeps areas from creating choke\npoints with only themselves.\n\nAt the end of our tile loop, each tile takes the sum of its neighbors (zero if they\nwere not a compound aura or a different aura) and divides the sum by the number of\nqualified neighbors that contributed to our sum. That tends to give the choke points\nan hourglass shape, but you can fine-tune this to achieve different results.\n\nAfter executing all the desired passes, you end up with an array of scores that are\neither zero, blocked, or some other score. The last step is to gather the adjacent scores\nand create choke points out of them. The perfect tool for this (and all other terrain\nanalysis detection tasks) is the A* machine described in the book Al Wisdom [Hig-\ngins02a]. If you don’t want to create an A* machine, then a flood-fill algorithm can\ngather these scores and create the choke point areas.\n\nThis algorithm sounds expensive, but with the right optimizations, it can be very\nfast.\n\nWhen you write a terrain-analysis engine, much of its success is determined by\nhow generic it can be written and how optimized it is. In Empire Earth, we used an\nA* machine, which is a highly optimized and generic tool that can be used for every-\nthing from path-finding units to creating forest areas and other terrain-analysis tasks\nas well.\n\n284 Section 3 Artificial Intelligence\n\nConclusion\n\n‘ss Mea RR ARI\n\nCertainly, one of the major tasks faced when creating an RTS engine is terrain analy-\nsis. Successful games can still ship without complex terrain analysis, but the more\ntools provided to programmers, the more plentiful and advanced the game features\nwill be. Terrain analysis demands a high-performance, generic engine, and developing\nsuch an engine takes a significant amount of time. However, if done well, and if the\nterrain information is used creatively, it pays for itself many times over.\n\nSRR SAR es eR ES ERRORS TTR RT en\n\nReferences\n\n[Higgins02a] Higgins, Daniel F, “Generic Path-finding,” AJ Game Programming\nWisdom, Charles River Media, Inc., 2002.\n\n[Higgins02b] Higgins, Daniel E, “How to Achieve Lightning Fast A*,” AJ Game Pro-\ngramming Wisdom, Charles River Media, Inc., 2002.\n\n[O’Rourke98] O’Rourke, Joseph, Computational Geometry in C, Second Edition,\nCambridge University Press, 1998.",
      "page_number": 271,
      "chapter_number": 29,
      "summary": "This chapter covers segment 29 (pages 271-278). Key topics include point, contain, and maps. If you want a real point (a point that exists on a continent, for example,\nand not just in its convex hull), then you will need a data structure to contain all of\nthe continent's points.",
      "keywords": [
        "matchbox container",
        "choke point",
        "points",
        "Matchbox",
        "container",
        "Matchbox ORS NERS",
        "PANERA ASAE RELL",
        "ASAE RELL ARRT",
        "RELL ARRT EPA",
        "ARRT EPA ION",
        "EPA ION CLE",
        "ION CLE Sad",
        "choke",
        "Matchbox Container Node",
        "choke point areas"
      ],
      "concepts": [
        "point",
        "contain",
        "maps",
        "map",
        "area",
        "costs",
        "terrain",
        "tile",
        "aura",
        "methods"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 1",
          "chapter": 30,
          "title": "Segment 30 (pages 279-290)",
          "relevance_score": 0.51,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 2",
          "chapter": 32,
          "title": "Segment 32 (pages 306-318)",
          "relevance_score": 0.51,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 1",
          "chapter": 62,
          "title": "Segment 62 (pages 597-603)",
          "relevance_score": 0.49,
          "method": "api"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 9,
          "title": "Segment 9 (pages 160-181)",
          "relevance_score": 0.49,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 1",
          "chapter": 28,
          "title": "Segment 28 (pages 256-265)",
          "relevance_score": 0.47,
          "method": "api"
        }
      ]
    },
    {
      "number": 30,
      "title": "Segment 30 (pages 279-287)",
      "start_page": 279,
      "end_page": 287,
      "detection_method": "topic_boundary",
      "content": "3.5\n\nAn Extensible Trigger System\nfor Al Agents, Objects,\nand Quests\n\nSteve Rabin, Nintendo of America, Inc.\n\nsteve@aiwisdom.com\n\nWw\": your players exhaust the single-player version of your game and then search\nonline for more levels or the level editor, you should be prepared to quench\ntheir thirst. Extensible levels and quests are the hallmark of a well-designed game, and\nenable a faithful following to extend your game’s normal life span. Whether your\ngame is an RTS, an RPG, or an action game, you should allow the player some way to\ncustomize the levels and build new areas to conquer.\n\nBaldur’s Gate, StarCraft, and Dungeon Siege are all great games that allow the\nplayer to create new quests, and in certain cases, modify and extend the AI. However,\nthe player is not a programmer, and you shouldn't force them to learn a fictional pro-\ngramming language and debug their creations. Simplicity is the key to allowing the\naverage player to tinker with your game, and it can be achieved by implementing an\nextensible trigger system.\n\nIntroducing t the the Trigger System —\n\nA trigger system is a centralized piece © of code that does o: one ne thing: It evaluates condi-\ntions and executes responses. If a set of conditions is met, a set of responses is exe-\ncuted. This simple system is elegant, easy to implement, and easy to data-drive\n[Rabin00]. It can solve a variety of problems and is especially good at being modified\nby designers and players. Best of all, it makes it easy to create exciting, new, interactive\nenvironments for the players to explore.\n\nConsider a game where you take a brave band of adventurers to explore a dun-\ngeon. As you trace through the catacombs, a pillar crumbles and almost crushes your\nleader. As you reach an impressive stone door, an icy draft snuffs your torches. After\nlighting your last torch, you decipher the inscription on the door and it reads, “Heavy\nare the hearts who pass through this doorway.” With a little thought, you place the\nmembers of your party on the heart-shaped floor tiles, and the door slowly grumbles\nopen.\n\n285\n\n286\n\nObject-Owned Trigger | Systems\n\neR\n\nSection 3 Artificial Intelligence\n\nEach of the previous events can be specified with a trigger system using the sim-\nple condition-and-response paradigm. When a party member walked within a meter\nof a particular pillar object, it responded by falling. When the party walked within\ntwo meters of the door, the response was to play a sound effect for wind and extin-\nguish the surrounding torches. When each heart-shaped floor tile was touched by a\nmember of the player’s party, the response was to slide open the door and play a stone-\ngrinding sound effect.\n\nA trigger system can be made with just enough hooks that both your designers\nand your players can spend hours making innovative scenarios and quests. The Star-\nCraft level editor is a fine example of a trigger system that you should examine and\nplay with. Many of the following ideas will expand on that particular functionality.\n\naan RARE oS REE Ra rR IRR\n\nWhile a master trigger system seems like the natural choice (as demonstrated in\n[Orkin02]), perhaps a more-powerful architecture is to consider a trigger system class\nthat any agent, object, or quest can own. Not every object requires one, but the abil-\nity to own an instance of a trigger system keeps data encapsulated within the objects\nand makes the system more flexible and object-oriented. It’s also natural to think of\ntriggers existing on particular items, so the concept is still easy for players to grasp.\n\nConsider the pillar that falls over when someone stumbles near it. We could\ndefine such a pillar in a level editor and attach a trigger definition that encompasses\nthe falling behavior. Then, a designer or player could place dozens of these pillars in\nthe game and they all magically display the same behavior, since the trigger behavior\nis directly attached to the object. In this way, any agent, object, or quest can own a\ntrigger system that is completely dedicated to that single entity.\n\nDefining a Condition\n\nRET HIB INAT NY Ta NN TINH BERTHS GER SS WH\n\nA condition can be any event or state that you can quantify i in your game. Conditions\nare fixed in the executable, but are highly configurable through arguments or a level\neditor. Below is a list of possible conditions:\n\n¢ Player within radius R of spot (x, y, z)\n\n* Player within boxed area position (x, , z)\n¢ Proximity of an enemy to the player\n\n° Life of the player below X%\n\n* Object X in player's inventory\n\n* Object X equipped by player\n\n¢ Player was killed\n\n¢ Player reached X level\n\n¢ Player talked to character X\n\n¢ Player killed enemy X\n\n° Player received message X\n\n3. 5 An Extensible Trigger System for Al Agents, Objects, and Quests — oe 287\n\nConditions Connected with Boolean Logic\n\nsthgoaeeenansgaunesbonmnnnmessien RE MSA RAR RSET RCH\n\nAAR A AE RRS EOR TREE\n\nIn order to make conditions even more flexible, it is advantageous to allow conditions\nto be linked together with Boolean operators, such as AND, OR, NOT, or XOR. For\nexample, if a door is to open when you are equipped with the ice sword, ice shield,\nand ice armor, these conditions must be ANDed together. If a door opens if you are\nholding either the silver key or the skeleton key, then those conditions must be ORed\ntogether. Figures 3.5.1 and 3.5.2 demonstrate these conditions with a tree structure.\n\nIf true, trigger fires\n\na at Door Opens\n\nEquipped\nIce Armor\n\nEquipped Equipped\nIce Sword Ice Shield\n\nFIGURE 3.5.1 [fall three conditions are “true,” then the door will open.\n\nIf true, trigger fires\n\n— Door Opens\n\nHolding Holding\nSilver Key Skeleton Key\n\nFIGURE 3.5.2 Jf either condition is “true,” then the door will open.\n\nThe situation gets even more interesting if you require that the player have the ice\nsword, ice shield, and ice armor equipped, as well as possessing either the silver key or\nthe skeleton key. Figure 3.5.3 shows this configuration.\n\nThe visualization from these first three figures is important, since it provides a\ngood way to structure the code. If each element is a class, we can have two types of\nclasses: an Operator class and a Condition class. The Operator class can be configured\nto behave like any Boolean operator. It also contains a list of pointers to Operator\ninstances or Condition instances, which are the subjects of the single Boolean opera-\ntor. The Condition class is able to evaluate any testable condition and contains the\narguments that customize it.\n\nDefinin\n\nSection 3. Artificial intelligence\n\nIf true, trigger fires\n—_—_ > Door Opens\nEquipped\nIce Armor\nHolding Holding\nSilver Key Skeleton Key\n\nFIGURE 3.5.3 A more-complicated set of conditions for the door to open.\n\nEquipped\nIce Shield\n\nA response can be any state or action in the game that you want to change. Again,\nthese are fixed in the executable, but they can be customized through arguments or a\nlevel editor. The following is a list of possible responses:\n\n* Level/Quest complete\n\n¢ Hurt/Heal player by X points\n\n¢ Give player X experience\n\n¢ Open/close/lock/unlock door\n\n¢ Spawn X creatures of type Y\n\n* Kill X creatures\n\n¢ Play sound\n\n¢ Play random sound from list\n\n¢ X% chance of playing sound\n\n¢ Move player/enemy X to spot (x,y,z)\n¢ Spawn special effect in spot or on player/enemy\n¢ Set player/enemy X on fire\n\n* Poison player/enemy X\n\n¢ Stun player/enemy X\n\n¢ Make player/enemy X invincible\n\n¢ Make player/enemy X invisible\n\n¢ Reset trigger\n\n¢ Send message X to player\n\nIf a particular set of conditions is met, the response will be executed. However,\nthe responses can be further expanded to include a list of responses, instead of just\n\n289\n\none. In this way a single trigger can either affect several things simultaneously when it\nfires or randomly choose between several possibilities.\n\nEvaluating a Trigger\n\nOnce a trigger is defined\nwhen it should fire. The first consideration is if a particular condition should be\nevent-driven (waiting for an event to be reported to the trigger system), or if it should\npoll the world (checking for the truthfulness of the condition every couple of game\nticks). In practice, you'll want the flexibility to create conditions that are either event-\ndriven or polled; it will be advantageous to build in this dual functionality.\n\nFor conditions that are event-driven, we need an interface for events to enter the\ntrigger system. The simplest mechanism is to use event messages. Event messages are\nsimply a notification that some event has occurred, along with any relevant data. For\na more in-depth discussion of event messages, refer to [Rabin02].\n\nFor conditions that are polled, we can call an update function within the trigger\nsystem that allows for each polling condition to do its work. Event-driven conditions\nwould ignore this update.\n\nWhether an event message or a polling update enters the trigger system, we need\na way for it to propagate through the conditions. Figure 3.5.4 shows an example of a\ncondition set that requires both event messages and polling. The left condition is\nwaiting for a collision event, while the right condition will poll for the condition\nwhen a polling update is received.\n\nWhen an event message or polling update enters the trigger system, it is routed to\nthe root Operator instance of each trigger. The Operator then passes it through to its\nchildren and expects either a “true” or “false” to be returned. Each child in turn passes\n\nEvent Messages\nand\nPolling Updates\n\nIf true, trigger fires Spawn 10\nRats\n\nPlayer Within Player Health\n10 meters Above 50%\n\nFIGURE 3.5.4 A trigger example that contains an event-driven condition (bottom left)\nand a polling-based condition (bottom right).\n\n290\n\n_Section 3 Artificial Intelligence\n\nit to its own children. When it reaches a condition, the child then returns “true” or\n“false” based on the new state of the condition. The return values are then evaluated\nat every Operator instance, and then passed up to its parent.\n\nIt is important to note that the Operator class should use lazy evaluation when\nprocessing its children. If any condition is not satisfied according to the operators, the\ntrigger testing is abandoned at this time. For the example in Figure 3.5.4, an event\nmessage sent to the left condition, which happens to result in “false,” should cause the\nevent message to never be sent to the right condition. This will help reduce the\namount of processing required.\n\nAnother important thing to note when using event-driven conditions is that they\nmust remember events until they are manually reset. With the example in Figure\n3.5.4, if the player gets within 10 meters, a collision event should be sent to the trig-\nger. The condition should remember that event and always return “true” upon further\nevent messages or polling updates.\n\nAt some point, the conditions for the specific trigger will all return the proper value,\ncausing the trigger to fire. Once a trigger is fired, it will remember and not fire again.\n\nSingle Shot and Reload Times\n\n“SbORR SY eR oa er oaananiOSE Sats: RARER ER AAN\n\neiconinnnnee CREE\n\nAll triggers should have two additional properties that are defined by the designer:\n\nbool SingleShot; // Whether the trigger should only\n// fire once.\n\nfloat ReloadTime; // If it should fire multiple\n/{ times, how long before it\n// resets.\n\nThese two properties allow triggers to fire more than once. The SingleShot prop-\nerty determines whether the trigger should fire once or be allowed to fire multiple\ntimes. If SingleShot is “false,” then the ReloadTime determines how long before the\ntrigger resets all of its conditions and accepts events again.\n\nCombining Triggers with Flags and Counters\n\nqr cReRNPRREARNRGN\n\nERA URNA SO AIR BH RRR a RARE ME HERMES.\n\nTriggers can be combined together only if they are able to set intermediary states that\nevery trigger within the system has access to. Thus, every trigger system can be outfit-\nted with a set of flags and counters to keep track of triggers that have fired. To make\nthis as general as possible, we'll let each trigger create arbitrary flags simply by refer-\nring to them with a string name. The trigger system will create a flag as it is refer-\nenced, or set and keep it around until the system is destroyed.\n\nConsider these new conditions:\n\n¢ Is flag_name true/false?\n\n* Is flag_name even/odd?\n\n* Is flag_name1 and flag_name2?\n\n* Js flag_name1 and not flag_name2?\n\n3.5 An Extensible Trigger System for Al Agents, Objects, and Quests 291\n\n¢ Is flag_name1 OR flag_name2?\n\n¢ Is flag_name1 XOR flag_name2?\n\n* Is flag_name1 and flag_name2 and flag_name3?\n¢ Is flag name count equal to X?\n\n* Is flag_name count more than X?\n\n¢ Is #lag_name count less than X?\n\nConsider these new responses:\n\n¢ Increment the value represented by flag_name.\n\n* Decrement the value represented by flag_name.\n\n¢ Set the value represented by flag_name to a value of X.\n\n¢ Set the value represented by f1ag_name2 to the value of flag_name1.\n* Toggle the boolean value represented by f1ag_name.\n\n¢ Set the boolean value represented by f1ag_name to TRUE.\n\n¢ Set the boolean value represented by flag_name to FALSE.\n\nWith these flags and counters, we can have the trigger system mark or count\nevents, such as counting how many times a player visits a particular area. In addition,\nthe trigger system can now be made to only trigger on particular sequences of events,\nlike stepping on three individual tiles in a specific order. Because these flags and coun-\nters hold state information, many more types of triggers are now possible.\n\nThe example in Figure 3.5.5 shows how to cause a clue to be dropped if the\nplayer can't get through a particular door and is visiting certain areas over and over\n\n> Increment . Increment\n\nPlayer in\nAreaA\n\nFIGURE 3.5.5 Three triggers that work together through a counter named “Visited.” If\nthe player visits Areas A and C alternatively eight times without unlocking Door D, then\na clue is dropped.\n\n292\n\nSection 3 Artificial Intelligence\n\nagain in desperation. Note that there are three separate triggers that are cooperating\nthrough a counter named “Visited.”\n\nNote that with the addition of flags and counters, the trigger system becomes\nstrikingly reminiscent of a blackboard architecture [Isla02]. The flags and counters\nmake up the blackboard, and the triggers are the knowledge sources (KSs) that operate\non the blackboard data. However, since the triggers mostly act on data coming from\noutside of the blackboard, the trigger system is not formally a blackboard architecture.\n\nTrigger Systems Versus Scripting Languages\n\nPRU aRRIRRA SH ORR aR IRRRTININ SGRBBORUDRNS TARANEH 2 AAA OE LARA H ORN I\n\nYou have probably noticed that the functionality of the t trigger system, especially with\nthe addition of state information, is becoming strikingly similar to the functionality\nof a scripting language. While the functionality does overlap, consider these benefits\nof using a trigger system instead of a full-featured scripting language:\n\n° A trigger system can be specified completely within a GUI. Scripting languages are\nrarely focused enough to allow this type of simplified and robust authoring.\nIncorrect syntax isn’t a problem, since triggers are structured around conditions\nand responses.\n\n° A trigger system 1s very accessible to users. The concept is easier to understand, and\nmore people will actually try to use it.\n\n° A trigger system is constrained. Since the trigger system is well-constrained, the user\nis unlikely to crash the game, since they can only perform a small, focused, well-\ntested set of actions (responses).\n\n° A trigger system is quick to implement and modify. A trigger system can be imple-\nmented in a fraction of the time of a full scripting language. The time scale is on\nthe order of weeks compared to a scripting language, which can take months or\nyears to implement [Tozour02], [Brockington02].\n\n° A trigger system is easy to document. A trigger system is relatively simple to write\ndocumentation and examples for—something always needed if you want the user\nto roll their own after the game is released.\n\nLimitations\n\nARR RE RHE 9 A BR amma ari DIER 89 rR RR SAH RY LER ET ROO HER,\n\nThe main n limitation of the system described is that it doesn’t scale well. However, this\ncan be fixed with some extra code to cull irrelevant triggers. Proximity culling has\nproven to be quite effective.\n\nAnother limitation of the system is that the vocabulary for defining conditions\nand responses is fixed within the executable. Thus, hooks into the code have to be\ndeliberately placed by programmers. This is also a good thing, since it helps to safe-\nguard your game from random or malicious tinkering.\n\n3.5 An Extensible Trigger System for Al Agents, Objects, and Quests 293\n\nConclusion\n\nRRS RNR eke IN SESE TENDONS TTA RAST SE Rn EAN a Qe Sa RRL eee gwoRseRRERE ERENT\n\nAn extensible trigger system might be a luxury for many games with tight develop-\nment schedules, but it’s a worthy feature that will add value and depth to your game.\nIn addition, an extensible trigger system is also an effective way to have level designers\nconstruct logic without having to become proficient programmers. While a trigger\nsystem at first glance can seem too simple a solution, the goal is to empower designers\nand players. The easier it is to define content and level-specific logic, the bigger your\ngame can be and the more fun your players will have.\n\nReferences\n\nNEAR RITRE\n\n[Brockington02] Brockington, Mark, and Mark Darrah, “How Not To Implement a\nBasic Scripting Language,” AJ Game Programming Wisdom, Charles River Media,\nInc., 2002.\n\n[Isla02] Isla, Damian, and Bruce Blumberg, “Blackboard Architectures,” AJ Game\nProgramming Wisdom, Charles River Media, Inc., 2002.\n\n[Orkin02] Orkin, Jeff, “A General-Purpose Trigger System,” Al Game Programming\nWisdom, Charles River Media, Inc., 2002.\n\n[Poiker02] Poiker, Falco, “Creating Scripting Languages for Non-Programmers,” A/\nGame Programming Wisdom, Charles River Media, Inc., 2002.\n\n[Rabin00] Rabin, Steve, “The Magic of Data-Driven Design,” Game Programming\nGems, Charles River Media, Inc., 2000.\n\n[Rabin02] Rabin, Steve, “Enhancing a State Machine Language Through Messag-\ning,” Al Game Programming Wisdom, Charles River Media, Inc., 2002.\n\n[Tozour02] Tozour, Paul, “The Perils of AI Scripting,” AJ Game Programming Wis-\ndom, Charles River Media, Inc., 2002.\n\nea RRNA ERR ORR SIN PE Ck LOS NUL A A RRS ERTS",
      "page_number": 279,
      "chapter_number": 30,
      "summary": "This chapter covers segment 30 (pages 279-287). Key topics include trigger, players, and conditions. However,\nthe player is not a programmer, and you shouldn't force them to learn a fictional pro-\ngramming language and debug their creations.",
      "keywords": [
        "Trigger System",
        "Extensible Trigger System",
        "Trigger",
        "System",
        "Nintendo of America",
        "player",
        "Charles River Media",
        "Extensible Trigger",
        "conditions",
        "Condition",
        "game",
        "flag",
        "Charles River",
        "River Media",
        "Game Programming"
      ],
      "concepts": [
        "trigger",
        "players",
        "conditions",
        "condition",
        "events",
        "flags",
        "scripting",
        "levels",
        "data",
        "objects"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 2",
          "chapter": 12,
          "title": "Segment 12 (pages 101-108)",
          "relevance_score": 0.53,
          "method": "api"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 2,
          "title": "Segment 2 (pages 19-41)",
          "relevance_score": 0.53,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 7",
          "chapter": 10,
          "title": "Segment 10 (pages 91-99)",
          "relevance_score": 0.52,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 7",
          "chapter": 25,
          "title": "Segment 25 (pages 238-245)",
          "relevance_score": 0.52,
          "method": "api"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 40,
          "title": "Segment 40 (pages 809-829)",
          "relevance_score": 0.52,
          "method": "api"
        }
      ]
    },
    {
      "number": 31,
      "title": "Segment 31 (pages 288-295)",
      "start_page": 288,
      "end_page": 295,
      "detection_method": "topic_boundary",
      "content": "3.6\n\n294\n\nTactical Path-Finding with A*\n\nWilliam van der Sterren, CGF-Al\n\nwilllam@cgf-ai.com\n\nf all games were just about getting from point A to point B, AI would solely have to\nprovide the shortest paths. A standard A* algorithm could do the job. However,\noften when trying to reach point B, the AI also needs to avoid being seen or shot at.\nThis is called tactical path-finding, a situation where the AI needs to balance short\ntravel times with avoiding hostile observation and fire (see Figure 3.6.1). Whether\nhandling a tank platoon retreating behind a ridgeline or an X-Fighter sneaking\nthrough a cloud of meteoroids, the AI needs to consider enemy positions and their\nlines of fire.\nTactical path-finding not only adds a realistic touch to AI movement, but it also\npresents a more-rewarding and less-predictable opponent for the player. This gem will\nhelp you to extend the standard A* algorithm so it generates tactical paths.\n\ndestination\n\nFIGURE 3.6.1 A path that alternates exposure with cover and concealment.\n\n3.6 Tactical Path-Finding with A* 295\n\nFirst, we will introduce a small change to the ‘shortest-path’ A* algorithm by\nincreasing the costs for movement through locations subject to enemy observation or\nfire. As a result, A* will generate paths that atrempt to avoid enemy observation and\nfire. These attempts, however, often look artificial and are not tactically sound.\n\nWe will then look at a few of these ‘flawed’ tactical paths, figure out why these\npaths are flawed, and how we can correct this in our A* cost function. We will also\ncompare the computing costs of finding tactical paths with those of finding shortest\npaths. Obviously, finding tactical paths will be more expensive, but we will look into\na few techniques and tricks to limit the overhead of the A* search and the line-of-fire\nevaluations that need to be done during the tactical path computation.\n\nOn the CD-ROM, you will find an extended version of James Matthews’ A*\nExplorer tool [Matthews01]. With this tool, you can experiment with tactical A* (and\nfollow all the examples included in this gem).\n\nA* is a generic search algorithm. To allow it to find paths for our AI, we equip it with\na cost function and a heuristic function [Stout00]. For path-finding, the cost function\ncomputes the exact cost of moving from one location to another. These movement\ncosts are computed from the distance traveled and the speed allowed by the terrain.\n\nThe heuristic function for path-finding typically provides an estimate of the\nremaining costs to the destination, such as the vector length divided by the maximum\nspeed. Listing 3.6.1 shows an example of a cost function and a heuristic.\n\nListing 3.6.1 Cost function and heuristic for evaluating shortest paths.\n\nfloat MovementCostNodeToNode(node* aFromNode, node* aToNode) {\nfloat dist, fromMoveCost, toMoveCost;\ndist = (aFromNode->origin —\naToNode->origin) .Length();\n\naFromNode->GetLocalMovementCosts();\naToNode->GetLocalMovementCosts();\n\nfromMoveCost =\n\ntoMoveCost =\n\n// take the average\n\nreturn kTravelTimeFactor * dist *\n(fromMoveCost + toMoveCosts) / 2;\n\n}\n\nfloat HeuristicNodeToDestination(node* aToNode,\nnode* aDestination) {\nfloat dist;\ndist = (aToNode->origin —\naDestination->origin) .Length();\n\nreturn kTravelTimeFactor * dist *\n(minimalMoveCostForAnyLocation) ;\n\n296 Section 3 Artificial Intelligence\n\nne kote Cc LEE RE EN ee SRN HOE RA Senn oneeKoRUN Ryn RIE\n\nUsing such a cost function and heuristic A* will find and return a path with the\nlowest costs to the destination. Typically, the AI is interested in the path that gets it to\nthe destination most quickly, so the costs are expressed as time.\n\nIf we now introduce additional costs for visiting locations in the enemy’s line of\nsight and line of fire, the resultant generated paths will also attempt to avoid observa-\ntion and hostile fire. Our revised A* algorithm will automatically balance short travel\ntime versus visiting risky locations, based on the weights for each type of cost\n\n[Reece00].\n\nListing 3.6.2 Cost function for evaluating tactical paths.\n\nIER SHA RTS ATR StH RREARE RAGAN REE\n\nSUE RN\n\nfloat TacticalCostNodeToNode1 (node* aFromNode,\nnode* aToNode) {\nfloat travelTime, riskFrom, riskTo, riskTotal;\ntravelTime = MovementCostNodeToNode(aFromNode,\naToNode) ;\n\n// use duration of move, and average risk of\n\n// both locations\n\nriskFrom =\nGetRiskOfEnemyObservationOrFire(aFromNode) ;\n\nriskTo =\nGetRiskOfEnemyObservationOrFire(aToNode) ;\n\nriskTotal = (riskFrom + riskTo) / 2 * travelTime;\n\n// return the weighted combination of travel\n\n// and risk costs\n\nreturn kTravelTimeFactor * travelTime +\nkRiskFactor * riskTotal;\n\n}\n\nYou'll find an example of a more-tactical A* cost function in Listing 3.6.2. The\nadditional risk costs depend on the risk sampled at each of the nodes and the travel\ntime needed to move from one node to the other. If the nodes are not too far apart,\nthis approximates the total risk of moving from one node to the other. Otherwise, you\nmight need to sample the risk at additional locations between the nodes.\n\nThe GetRiskOfEnemyObservationOrFire() function determines the risk of a given\nnode by checking the enemy’s ability to observe or fire at that position from all of the\nknown or presumed enemy positions. This typically involves performing a number of\nray casts in the game world geometry. Because these ray casts are often expensive, this\ngem will also discuss how to create small lookup tables of precomputed line-of-fire\ninformation.\n\nListing 3.6.2 explicitly does not provide a tactical version of the heuristic. Because\nwe don’t know about the risk in the remaining part of the path, we can only estimate\nthe remaining travel time. The HeuristicNodeToDestination() already does this, so\nwe'll just leave it alone.\n\nHave a look at the results in Figure 3.6.2. In Figure 3.6.2a, you see a ‘traditional’\nshortest path, happily passing through potential hostile fire (gray areas). In Figure\n\n3.6 Tactical Path-Finding with A* 297\n\n3.6.2b, you see the result of our TacticalCostNodeToNode1() cost function. Just by\nadding costs for the risk of being under fire, we can obtain paths that show a clever\nand convincing balance between speed and cover.\n\ndestination éstination\n\n_{ under fire\n\nA B\n\nFIGURE 3.6.2 (a) Shortest path. (b) Path offering protection and concealment.\n\nWe are not done yet! In a large number of situations, this simple tactical A* cost\nfunction will provide paths that are tactically flawed and break the illusion of intelli-\ngence. Another problem is that the ‘tactical’ nature of path-finding also comes with a\n(CPU) cost.\n\nIn the remainder of this gem, we will first identify and correct a number of tacti-\ncal flaws in our cost function. Then, we will investigate the additional costs of tactical\npath-finding and come up with some ways to limit these costs.\n\nTactical Improvements to Flawed Paths\n\nALLIANT OUI IN ELEMENTS BUR DOES TUTE R TEE AA ITNT DU RL RE RU RNT RN TAN IRU ACS ARTY\n\nIt only takes one AI flaw to break the illusion of intelligence. When the player has\ncarefully led wingmen, squads, or his tank platoons to an assault position, there is\nnothing more annoying than seeing them getting killed due to a lack of tactical\nunderstanding. Unfortunately, the tactical cost function defined previously lacks this\nunderstanding in a couple of places:\n\n* It does not distinguish between long and short exposures to hostile fire, but sim-\nply adds up the total exposure;\n¢ It assumes that threats remain static during the path’s duration.\n\nWe will look into each of these problems and come up with improvements to the\ntactical-cost function to try to solve them.\n\nosure Time and Enemy Modelin\n\nRRR RETREAT\n\nImagine a helicopter traversing some terrain defended by surface-to-air missile launch-\ners. Imagine that the helicopter can reach its destination via two paths of identical\n\nHAHAH RNC ERNR MURR:\n\n298 Section 3 Artificial Intelligence\n\nlength. One path exposes the helicopter to the missile launcher only once but for 20\ncontinuous seconds. The other path exposes the helicopter for 20 seconds also, but in\nfour stretches of 5 seconds, each exposure separated by at least 5 seconds of conceal-\nment. Both paths are equal to our cost function, Tact icalCostNodeToNode1(), which\nsimply adds up the amount of exposure. So, which one should the helicopter really\nchoose?\n\nTo the enemy, the duration of the helicopter’s exposure is very important. The\nsingle 20-second exposure might just be long enough for a missile launcher to detect\nand lock on to the helicopter so it can launch a smart missile. If the helicopter picks\nthe path with four brief exposures, however, this is less likely to happen. Whether it’s\nmissile launchers that need to lock on, snipers requiring time to properly aim, or\nguards turning around in response to some noise—they all prefer their target to have\nlong exposure times with only brief intervals of cover.\n\nTo take into account the enemy’s ‘aiming’ ability, therefore, we need to extend our\nnodes and cost function:\n\nListing 3.6.3 A* node with one additional field to take into account\n_the _enemy’s aiming quality.\n\n“struct node {\nnode(): aiming(0) { }; // default ctor: start\n// with zero aim\nnode(float anInitialAim) : aiming(anInitialAim) { };\n\nfloat location[3];\nfloat aiming;\n\n}5\n\nIn the cost function, we use and update the aiming information detailed in List-\n\ning 3.6.4.\n\nListing 3.6.4 Cost function tactical path.\n\nspate\n\n_ RRSP NN RR IES ATE RES AAAI STN\n\nfloat TacticalCostNodeToNode2 (node* aFromNode,\nnode* aToNode) {\nfloat travelTime, riskFrom, riskTo,\nriskTotal, aiming;\n\n// compute travelTime and riskTotal\n\n// update aiming quality based on risk,\n// and add it to risk\naiming = aFromNode->aiming;\nif ( riskTotal > 0 ) { // spotted,\n// so increase aiming\naiming = min({kMaxAiming, aiming + travelTime);\n} else { // not spotted, so decrease aiming\naiming *= power(kAimingDamping, travelTime) ;\n\n3.6 Tactical Path-Finding with A* 299\n\n}\n\nriskTotal += kAimingFactor * aiming;\n\n// store aiming quality at destination\naToNode->aiming = aiming;\n\n// return the weighted combination of\n\n// travel and risk costs\n\nreturn kTravelTimeFactor * travelTime +\nkRiskFactor * riskTotal;\n\n}\n\nFigure 3.6.3 shows a simple test case generated against the helicopter path prob-\nlem, and the graphs below the image show the exposure and aiming quality for each\npath.\n\nthreat threat threat threat\nrit nas\n\ndestination\n\ncosts\n\nFIGURE 3.6.3 A flawed tactical path where one long exposure is preferred over four brief\nones.\n\nBoth paths feature the same amount of exposure to hostile fire—20 seconds. In\nthe top path, the exposure (dark bars) consists of four intervals separated by an inter-\nval of cover of equal length. In the bottom path, the exposure consists of one interval\nof 20 seconds. For both paths, aiming by the threat (gray bars) starts as soon as the\npath is exposed. The aiming quality increases with each exposure until a maximum\nhas been reached. As soon as the path is no longer exposed, the aiming decreases (gray\nbars). The threat might predict the movement on the covered path for a while, but the\naiming decreases with time. For the top path, the total amount of ‘aiming’ when\nexposed is less (gray bars with borders) than that for the bottom path. The intervals of\n\nsence pM ADR REE NERA\n\nThreats\n\nSection 3 Artificial Intelligence\n\ncover between the exposures decrease the enemy’s aiming ability and prevent it from\nstaying at its maximum.\n\nSimilarly, when the AI starts a search for a tactical path from a position already\nexposed to hostile fire, it should start assuming the enemy has a maximum aiming\nquality. This will result in paths that try to visit nearby cover early on its path.\n\nThus, by also modeling the enemy’s ability to improve its observation and aim in\nour A* cost function, we get tactically better paths. Our A* now prefers brief expo-\nsures separated by long intervals, rather than the alternative of long exposures and\nshort intervals of cover, which definitely looks more intelligent.\n\nDon’t Remain Static\n\nem\n\neR\n\nUnfortunately, in most games, threats are not static. They patrol an area or move out\nupon spotting a unit in their path. Our current tactical A* solution, however, will\nhappily plan a movement lasting perhaps 10 seconds, using the exact threat positions\nat a single moment. By ignoring the threat’s movement, much of the ‘tactical quality’\nof the path is left to chance, and so is the player’s perception of the AI.\n\nTo obtain better tactical paths, we must anticipate the enemy's movements. This\nis less complex than it sounds and can be done without using ‘chess AI with minmax-\ntrees’ to anticipate the most likely enemy movement. Instead, we can just assume that\nthe enemy also occupies each and every position within a few steps of their current\nposition. Have a look at Figure 3.6.4:\n\nNote how much the path in Figure 3.6.4a depends on the initial position of\nthe threat. The path chosen is not robust against threat movement, and it ignores the\nlarger presence of obstacles and the cover on the left side of the map.\n\n. destination... : vers destination\n\nA B\n\nFIGURE 3.6.4 (a) Tactical path assuming threats remain static. (b) A path assuming threats move\n\ntwo Steps.\n\n3.6 Tactical Path-Finding with A* 301\n\nWhen we assume that threats occupy all positions within two steps of their initial\nposition, we indeed pick a more pessimistic scenario. The result, as shown in Figure\n3.6.4b, is more robust against threat movement and also favors the higher availability\nof obstacles on the left side of the terrain. It’s hard to fault the Al for picking this path.\n\nMost game AI implementations provide a fast way to obtain all positions within\na few steps of the threat. These usually correspond with the outgoing waypoints or\nneighboring nodes.\n\nable to use cover and concealment in a\nplausible and effective way. There is more to tactics than just cover and concealment.\nHere are some more tactical considerations that can easily be taken into account by\nour tactical A* cost function.\n\nNot all lines-of-fire are equal. If the AI will face only a few enemies, it is wise to\ncount the number of hostile lines-of-fire to a given path position, rather than just dis-\ntinguishing ‘cover’ and ‘risk’ positions. The distance to the threat and the threat’s\nweapon might also have a large influence on the risk of being in the line-of-fire.\n\nGames rewarding stealth and/or locations with shade, foliage, or small objects\noffer important protection from observation. The path-finding algorithm will prefer\nthese locations if the cost function includes a small penalty for all other locations.\n\nEven in the absence of known threats, there can still be tactical path-finding.\nRather than avoiding known and suspected hostile lines-of-fire, it is now important to\navoid weak combat positions. For example, a tank should not unnecessarily cross\nridgelines because its weaker bottom might be exposed, or it might stand out against\nthe skyline. Similarly, a marine should avoid using ladders because his movement on\na ladder is very predictable, and he is unable to return fire while climbing it. Visiting\nthe location of a recently shot squad member probably isn’t smart either. Many tacti-\ncal properties of a location can be analyzed and precomputed, as is explained in [Ster-\nren01]. By introducing additional costs for visiting these locations, the paths\ngenerated by our tactical A* path-finding will try to avoid them.\n\nObviously the added tactical ability of A* described here comes with some additional\nCPU and memory costs as compared to a standard A*. Our approach compares even\nless favorably with the fast, yet predictable precomputed path lookup tables used by\nsome games. As a point of reference, finding a tactical path with A* was about 10\ntimes more expensive than finding a shortest path for squad AI in a Quake-based\ngame.\n\nOn the other hand, most AI movement does not require a tactical path. Often it\nsuffices to replan a squad’s tactical path once every three seconds or so. The individual\nsquad members then move in brief, ‘shortest path’ hops along this path, and a few\nline-of-sight checks are used to find cover.",
      "page_number": 288,
      "chapter_number": 31,
      "summary": "Tactical path-finding not only adds a realistic touch to AI movement, but it also\npresents a more-rewarding and less-predictable opponent for the player Key topics include path, tactical, and tactically. Covers function.",
      "keywords": [
        "cost function",
        "path",
        "Tactical",
        "tactical path",
        "cost",
        "Tactical Path-Finding",
        "van der Sterren",
        "William van der",
        "function",
        "aiming",
        "function tactical path",
        "finding tactical paths",
        "tactical cost function",
        "enemy",
        "node"
      ],
      "concepts": [
        "path",
        "tactical",
        "tactically",
        "aim",
        "aiming",
        "costs",
        "threats",
        "float",
        "exposure",
        "function"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 7",
          "chapter": 34,
          "title": "Segment 34 (pages 321-328)",
          "relevance_score": 0.54,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 1",
          "chapter": 27,
          "title": "Segment 27 (pages 248-255)",
          "relevance_score": 0.53,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 2",
          "chapter": 31,
          "title": "Segment 31 (pages 295-305)",
          "relevance_score": 0.51,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 27,
          "title": "Segment 27 (pages 248-260)",
          "relevance_score": 0.49,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 2",
          "chapter": 25,
          "title": "Segment 25 (pages 240-248)",
          "relevance_score": 0.47,
          "method": "api"
        }
      ]
    },
    {
      "number": 32,
      "title": "Segment 32 (pages 296-313)",
      "start_page": 296,
      "end_page": 313,
      "detection_method": "topic_boundary",
      "content": "302 Section 3 Artificial Intelligence\n\nLet’s have a look at the origins of some of these additional costs, what they add,\nand what we can do to limit them. First, we'll consider the line-of-fire tests, which\noften add the largest costs. Then, we'll look at A* and its tactical cost function, and\nthe larger search space involved.\n\nEfficient Line-of-Sight/Fire Tests\n\nAN EORTC RCRA Cte ee\n\nScena RRA RT\n\nIn many games, line-of-sight and line-of-fire (LOF) tests consume considerable CPU\ntime. For tactical path-finding, however, it suffices to use approximations of the\nactual lines-of-fire (the AI might not have spotted all threats and threats may move or\nlook the other way). Trading CPU time for a lookup table of sampled lines-of-fire\nmight be a good option in this case.\n\nIf the terrain is not too large, you might consider using a lookup table with one or\nmore bits per line-of-sight/fire, as described in [Lidén02]. Such a lookup table con-\nsumes O(*) memory. Alternatively, you can record the incoming lines-of-sight and\nlines-of-fire per location in terms of sectors, consuming O(N) memory. This\napproach and the results for our 2D example are illustrated in Figure 3.6.5.\n\nincorrect: ©\n\n8 sectors of\n45 degrees;\nLOF in three\ndistances\n\nincorrect\ndanger zone\n\ns t e:\n11+ already a LOF from far\n\n10 - a LOF from medium distance\n01.- a LOF from near distance\n\n00 - no LOF from this direction\n\nall 8 sectors together make one 16 bit word\n\nFIGURE 3.6.5 Sector-based LOF lookup and the resulting path.\n\nUsing one 16-bit word per location, information is precomputed and stored. For\neach location, every sector describes the worst-case distance from which a potential\nenemy in that sector can have a line-of-fire to that location. This worst-case distance\nis represented using four values, from ‘no line-of-fire at all in this sector’ to a ‘line-of-\nfire at the maximum engagement distance.’ Note that the value stored is a pessimistic\none: a single position in the sector that has a line-of-fire is sufficient to mark that sec-\ntor as having a LOF from locations in that direction.\n\n3.6 Tactical Path-Finding with A* 303\n\nDuring an A* search, an approximation of the line-of-fire from a given threat\nposition can be efficiently determined using the sector-based lookup table (see Listing\n3.6.5). For the threat and position, the corresponding 45° sector and distance are\ncomputed. The lookup table then tells us whether it is possible for the location to be\nfired at from the threat’s sector and for the threat-to-fire into the location's sector. If\nboth lines-of-fire are feasible, the threat likely has a line-of-fire.\n\nObviously, such a small sector-based lookup table does not represent all lines-of-\nfire correctly. You can easily verify this by comparing the lines-of-fire in Figure 3.6.4\nwith the danger zones in Figure 3.6.5. In many cases, the (pessimistic) errors corre-\nspond to lines-of-sight easily achieved by the threat if the threat were to move. In\nother cases, such as the danger zones outside the box, the errors are more serious.\nWith a few more bits and smaller sectors, however, you can easily reduce the number\nof errors.\n\nFor 3D environments and for games offering partial cover (which removes the\nsymmetry in lines-of-fire), you might need to store some more bits. Still, this sector-\nbased lookup approach stores lines-of-sight for some 1,000 locations in a few tens of\n\nkilobytes and is generally quite efficient.\n\nListing 3.6.5 Computing an approximate risk using sector-based,\nprecomputed LOF information\n\nWA DAA AANA ARRAN ALLIS NOL AM PANE R iH dH iit ar DAT RTH ISR INST AT LIE EN I\n\nfloat GetApproximateRiskFromThreat(node* threat,\nnode* location) {\nint sector = GetSectorForLine(threat, location);\nint reverse sector = (sector + 4) % 8;\nfloat distance =\nGetDistanceForLine(threat, location) ;\n\nNARI NORTH hs loose\n\nif (HasLineOfFireFromSector(location->id,\nsector, distance)\n&& CanFireIntoSector (threat->id,\nreverse_sector, distance) )\nreturn distance / kMaxDistance;\n\nelse\nreturn 0.0;\n}3\nbool HasLineOfFireFromSector(int index, int sector, :\nfloat distance) {\nunsigned int allsectors = sectors[index] ;\nunsigned int mask = (0x3 << sector);\nunsigned int value = ((allsectors & mask) >>\nsector) ;\nreturn ( (value == 3 && distance < kMaxReach )\n|| (value == 2 && distance < kFarReach  )\n|| (value == 1 && distance < kMediumReach) );\n}3\n\nbool CanFireIntoSector(int index, int sector,\n\nSection 3 Artificial Intelligence\n\nfloat distance) {\n// assume firing is symmetric, otherwise\n// an extra table is needed\nreturn HasLineOfFireFromSector (index,\nsector, distance);\n\nExtended A* Costs\n\nsm IR IRENE Mena Re hee eg TaN eA NSN S ANTE ERS NL SERS RE EEO BS\n\nAs mentioned earlier, in its tactical format, A* consumes more CPU and memory, pri-\nmarily through the tactical cost function and the larger search spaces being explored\nby A*. One source of additional cost is the floating-point arithmetic in the tactical\ncost function. You can gain performance by implementing approximate versions of\nfloating-point computations using integer math. You should do this only after having\nverified and tuned the path-finding with the more ‘exact’ floating-point cost func-\ntions to avoid introducing other problems.\n\nThe space being searched by the tactical A* algorithm is typically much larger\nthan one for a standard A* algorithm, as is shown in Figure 3.6.6. The larger search\nspace is a result of the added line-of-fire obstacles that typically are placed between the\nstart and destination position of the path. A* will spend a lot of effort exploring loca-\ntions to the rear and the sides, since those seem safer. It does not help that the heuris-\ntic cannot reflect these added line-of-fire obstacles.\n\ndestination\n\ndestination\n\nunexplored\n| search space\n\nA B\n\nFIGURE 3.6.6 (a) Search space for shortest path. (b) Search space for tactical path.\n\nOne way to reduce the search space is to introduce even more-costly ‘virtual’\nobstacles. If you want your AI to find a tactical path to a forward destination, why not\nrestrict its attempts to evaluate positions deep in the rear or far to the sides by tem-\nporarily marking those nodes ‘off-limits’? Nothing says you can’t use the algorithm to\nignore these areas.\n\n3.6 Tactical Path-Finding with A* 305\n\nAnother way of reducing the search space is to use hierarchical path-finding, exe-\ncuting the path-finding in ‘layers.’ First, generate a shortest path search at a higher\nlevel between areas of the map. Then, select the areas used for that shortest path and\ntheir neighboring areas, and run the tactical path-finding to the locations within the\nselected areas. Both Board/Ducker [BoardDucker02] and White [White02] address\n\narea navigation in their gems.\n\nExplorer (ASE) application on the CD-ROM. James Matthews [Matthews01] laid\nthe foundation for this A* tool. The tactical enhancements and line-of-fire approxi-\nmation described in this gem were added. Note that the A* implementation in this\nASE is not representative of a high-performance tactical A*. Instead, the algorithm\nhas been designed for hosting alternative cost functions and visualization.\n\nFinding tactical paths with A* is a bit more complex than treating locations under\nenemy fire as terrain that is expensive to visit. You also should look at the path from\nan enemy perspective and deal with enemy aiming and movement in the cost func-\ntion. These features will ensure paths that intelligently use stretches of cover and con-\ncealment to limit the risk of hostile fire, even when the enemies move. Using a similar\napproach, you can extend A* to pick paths that stay in touch with friendly or hostile\nelements, if that is important. Hopefully, this gem offers sufficient help to add these\nfeatures to your game with efficiency.\n\nReferences\n\n[BoardDucker02] Board, Ben and Mike Ducker, “Area Navigation: Expanding the\nPath-Finding Paradigm,” Game Programming Gems 3, Charles River Media, Inc.,\n2002.\n\n[Lidén02], “Strategic and Tactical Reasoning with Waypoints,” AJ Programming Wis-\ndom, Charles River Media, Inc., 2002.\n\n[Matthews01], A* Explorer, available online at http://www.generation5.org, 2001.\n\n[Patel99] Patel, Amit J., “Amit’s Thoughts on Pathfinding”, available online at\nhttp://www-cs-students.stanford.edu/~amitp/gameprog.html, November 18, 2001.\n\n[Rabin00] Rabin, Steve, “A* Speed Optimizations,” Game Programming Gems,\nCharles River Media, Inc., 2000.\n\n[Reece00] Reece, Doug, et al., “Tactical Movement Planning for Individual Combat-\nants,” Proceedings of the 9th Conference on Computer Generated Forces and\nBehavioral Representation, available online at http://www.sisostds.org/cgf-br/\n9th/, 2000.\n\n[Sterren01] van der Sterren, William, “Terrain Analysis for 3D Action Games,” Game\nDevelopers Conference 2001 Proceedings, paper and presentation available\nonline at www.cgf-ai.com, 2001.\n\n306 Section 3 Artificial Intelligence\n\n[Stout00] Stout, Bryan, “The Basics of A* for Path Planning,” Game Programming\nGems, Charles River Media, Inc., 2000.\n\n[White02] White, Stephen, “A Fast Approach to Navigation Meshes,” Game Pro-\ngramming Gems 3, Charles River Media, Inc., 2002.\n\n3.f\n\nA Fast Approach to\nNavigation Meshes\n\nStephen White and\nChristopher Christensen,\nNaughty Dog\n\nswhite@naughtydog.com,\ncchristensen@naughtydog.com\n\nAv problem in video games is how to navigate around objects in a complex\nenvironment. In the case of Jak and Daxter: The Precursor Legacy, we wanted\ncreatures to be able to maneuver around highly detailed 3D environments, where\neach level was composed of millions of polygons and filled with many creatures and\nobstacles. We wanted the creatures to move intelligently and to exhibit several types of\nmovement behaviors. Due to the density of creatures in our world, we needed a sys-\ntem that was faster than the more-common navigation techniques, such as A*; but it\nstill needed to be flexible, accurate, and give the appearance of intelligent movement.\nTo solve this problem, we developed our own navigation mesh technology, which\nadmirably solved our needs, but also had a few interesting limitations.\n\nStatic vs. Dynamic Obstacles\n\nare Rr pn ERD ee CAT PRR AR RIRR\n\nThe most fundamental problem of navigation is how to get from point A to point B.\nThe shortest distance between these two points is a straight line. However, a straight\nline isn’t appropriate when there is an obstacle blocking a direct movement between\nthe two points. Obstacles can be broken down into two categories: static and\ndynamic. Static obstacles are obstacles that don't move, ever. These are our favorite\ntype of obstacles since there are many optimizations that can be made to navigate\naround them. Examples of static obstacles are cliffs, walls, trees, and pillars. Dynamic\nobstacles are obstacles that can move or be removed, such as other creatures, the\nplayer, moving platforms, and crates. Dynamic obstacles are more difficult to deal\nwith since their ability to move makes it difficult to use precomputed solutions. To\nmake things worse, a dynamic obstacle might move in such a way as to invalidate a\npreviously computed path. Since static and dynamic obstacles have so many different\nadvantages and disadvantages, we chose to approach the problems separately.\n\npa aNec A\n\n307\n\n308 Section 3 Artificial Intelligence\n\nNav Meshes\n\nThe most common type of static obstacle encountered in Jak and Daxter was the ter-\nrain. Natural boundaries, such as walls and cliffs, described an area within which a\ncreature could maneuver. Inside that boundary there could be other static obstacles,\nsuch as trees, large rocks, pillars, gaps too large to leap across, and other things that\nthe creature should not be allowed to pass through.\n\nTo describe where a creature was allowed to maneuver within an area, the artists\nmodeled a ‘nav mesh.’ The mesh was a collection of triangles, and each triangle repre-\nsented a valid area where the creature could maneuver. The mesh was modeled to the\nextent of the natural boundaries of the desired area, and holes in the mesh were used\nto represent areas where the creature could not travel within the natural boundaries.\nNote that our nav meshes were largely two-dimensional in nature and defined a\ntwo-dimensional area where a creature could travel. There was, however, a three-\ndimensional element to our meshes, which will be explained later.\n\nAs an example, suppose there is a clearing that we want a creature to be able to\nnavigate within (see Figure 3.7.1). In this clearing, there is a large rock that the crea-\nture should not pass through. The artist would model a nav mesh that would both\ndescribe the extent to which the creature can travel as well as a hole cut out around\nthe rock (see Figure 3.7.2). Each triangle in the mesh would describe a valid area\nwhere the creature is allowed to travel. By restricting the creature’s travel to the two-\ndimensional space described by the mesh triangles, the creature could neither exit the\nclearing nor pass through the rock.\n\nThe beauty of this system was in its simplicity. Both area-boundary and inner-\nobstacle problems were solved using the same solution. A fairly simple nav mesh\ncould even represent highly detailed and complicated terrain.\n\nclearing\n\nFIGURE 3.7.1 A clearing with a static obstacle.\n\n3.7 AFast Approach to Navigation Meshes 309\n\nortals\n\nFIGURE 3.7.2 A clearing with a nav mesh added.\n\neieesnories 2a maamUAY\n\nThe triangles of the nav mesh do more than just establish an area where a creature can\nwalk—they also establish what we refer to as “portals.” Portals can be thought of as\ndoorways to other triangles. In the case of our nav meshes, the portals were repre-\nsented by the edges of the triangles. As a simplification, we established that our\nmeshes could not contain any T-junctions, which simply meant that we only allowed\nan edge to be shared between no more than two triangles. Since a triangle has three\nedges, this means that a single triangle could be connected to at most three other tri-\nangles; so a single triangle has at most three portals leading to other connected trian-\ngles. This limitation did pose some three-dimensional issues, but it did give us some\nnice data characteristics. For one thing, we could use two bits to specify a portal of a\ntriangle (first portal, second portal, or third portal) and still have one value left over\nfor other uses.\n\nSuppose our problem is moving from point A to point B. If point A represents\nthe creature, point B represents the desired destination of the creature, and both\npoints are within the same triangle, then we know that the creature can move directly\ntoward point B, since we already know that the creature can move anywhere within\nthe triangle. A problem arises when the destination is not contained within the same\ntriangle as the creature. In this case, the creature might need to choose a direction that\nwill both keep the creature on the nav mesh and intelligently move the creature along\na path that will reach the desired destination, even if that path temporarily moves the\ncreature in a direction away from the desired destination.\n\nSo, if we're on some triangle and our desired destination is on some other trian-\ngle, how do we decide which way to go? The solution that we used was to precompute\na two-dimensional array that specified the portal to use to get from any triangle to any\n\nSSRN BS\n\n310\n\nSection 3 Artifici\n\nIntelligence\n\nother triangle on the mesh. Remember that it only took two bits to specify a portal, so\nthe memory cost of our table was roughly equal to squaring the number of triangles\nin the mesh and dividing by four. This means that the table for a mesh of 256 trian-\ngles (the maximum our implementation allowed) cost only 16 KB of memory. In\npractice, our nav meshes rarely exceeded more than 64 triangles (one kilobyte of\nmemory) and were often smaller. Also, since multiple creatures typically shared the\nsame nav mesh, there were relatively few nav meshes overall, so the memory cost was\nnot significant. Now, consider the advantages of having this two-dimensional table.\nFiguring out which portal to use is now extremely fast, since it is a simple table\nlookup. The entry in the table is found by using the index of the source triangle and\nthe index of the destination triangle. If the table was composed of byte values instead\nof two-bit values, then the C code might look like the following:\n\nportaliIndex = portalTable[destTrilIndex][srcTriIndex];\n\nOf course, using a byte table would quadruple the memory cost for little gain, so\nour bit-packed table code becomes:\n\nbitIndex = 2*(destTriIndex*triCount + srcTrilIndex);\nbyteIndex = bitIndex / 8;\n\nbyteShift = bitIndex & 7;\n\nportalIndex = (portalTable[byteIndex] >> byteShift)&3;\n\nOnce we know the portal to use for a given triangle, we can take the desired direc-\ntion vector from point A to point B and then solve for the point on the portal that\nmost closely matches our desired direction. The creature then moves in the direction\nof the point on the portal until it reaches the portal, where it transitions to the trian-\ngle on the other side of the portal. If point B is within the creature’s new triangle, then\nthe creature can move directly to point B. If point B is still not within the creature's\nnew triangle, then another look-up in the table is done to determine which portal to\nuse next. The logic repeats until the creature eventually reaches the triangle that con-\ntains point B.\n\nAs an example, refer to Figure 3.7.3. Point A starts the creature out located within\ntriangle 0, and point B (its destination) is located within triangle 3. Since point A is not\nin the same triangle as point B, a look-up in the table is done to determine which por-\ntal to use, and the returned value tells us to use the portal connecting triangle 0 to tri-\nangle 1. A point is found on that portal that most closely matches the desired direction\nof point B, and the creature is moved to that point. The creature is then considered to\nbe within triangle 1. This behavior is repeated until the creature enters triangle 3,\nwhich is where point B is located; and the creature can then move directly to point B.\n\nAlthough the above example was fairly simple, the same logic works for far more\ncomplicated cases. Consider Figure 3.7.4 (on page 000), which shows the same sim-\nple logic applied to navigating a more complicated mesh.\n\nThis logic works for forking and looping paths. When there is more than one\nportal that can be used to reach a destination, the table entry specifies which portal\n\n3.7 A Fast Approach to Navigation Meshes 311\n\ntri 1 tri3\n\n‘ i ir)\n\\ ‘oe\n\\ ooo \" }\n. oo ; ‘\n‘ aoe - : . i\naa \\\nwet \\\n= \\ \\.\n\\ :\nj\nA |\n; \\. i\n\\\n, \\. i\nj \\ F ‘ /\n\\ i < ;\n: \\ ; \\ i\n\\ : :\ni \\ { ;\nj :\nSF\ntrio tri2\n\nFIGURE 3.7.3 Navigating from A to B on a simple mesh.\n\nrepresents the shortest route to the destination. However, there is actually one com-\nplication to consider. A triangle represents an area, and not a single point. This means\nthat the distance between a point on one triangle and a point on another triangle can\nvary dramatically, depending on where the points are located on their respective tri-\nangles. Since the precomputed table tells us how to get from one triangle to another\ntriangle, rather than how to get from an exact position on a triangle to an exact posi-\ntion on another triangle, the precomputed portal might not actually lead to the short-\nest path to the destination. In practice, however, this was rarely a problem, since if\nmore than one path covered a similar distance, then it really didn’t matter that the\nchosen path wasn’t always the shortest.\n\nBuilding the Table\n\nSo, how do you precompute the table? Several methods could be used, but the\nmethod that we chose was to compute a point to represent the center of each triangle.\nPreferably, this was a point that was equidistant to the three corners of the respective\ntriangle. We then used a simple flood-fill algorithm to find the paths connecting the\ntriangles. If more than one path was found between two triangles, then the algorithm\nwould discard the longer path.\n\nAn important item to consider when constructing the nav mesh is that it repre-\nsents a single path to each destination. Each portal should provide a single, clear route\nbetween any two areas in order to produce acceptable results. Providing more than\n\n312\n\nSection 3 Artificial Intelligence\n\n5 eS Rr DN St EL STONER eR at: aeEHSTNNsCS\n\nf \\\n4 : A\n4 A B / \\\n+ j .\na a.\ney rt é\n* 1 /\n« a /\ns : /\n* \\ rj / ’\n* \\ LS f\n© \\ nj 4\n* \\ '\n® . ‘\nee i cen é _ ~\n—_ . . oer\n\\ . o* i ‘\n‘ s of\n\\, °\nS e @ i\nN ‘ o* .\nLoos ° .\n\\, 29” j \\\n‘ \\\n/ e ‘\\ i\n¢ \"\no\nU i i\ni A \\ iH\nS /\n\nFIGURE 3.7.4 Navigating around a corner.\n\none portal to pursue a single path could result in zigzagging movement. Figure 3.7.5\nshows a case where it is unclear at precompute time which portal is the best way to get\nfrom point A’s triangle to point B’s triangle. In this example, only one portal is chosen\nat precompute time, which would be inappropriate at runtime, since it does not inter-\nsect a direct path from point A to point B. Figure 3.7.6 shows the proper way to con-\nstruct this nav mesh, where the direct path is always taken.\n\n3. 7 A Fast Approach to Navigation Meshes 313\n\n. a\n\nFIGURE 3.7.5 Poor mesh construction.\n\nFIGURE 3.7.6 Good mesh construction.\n\nAdditional Portal Issues\n\nSS NteRRNTIN i a psianirennERE\n\nAlthough the concept of using portals is quite te simple, there are a few complications in\ntheir implementation. One such complication is that as point A approaches a portal\nedge, the test for whether the vector from point A to point B intersects the portal edge\nmight become unreliable. For example, floating-point round-off errors might shift\npoint A outside of the current triangle, causing the test to go awry. Also, when the\nsource-to-destination vector is nearly parallel to the portal edge, the intersection test\ncan give unreliable results. To avoid these problems, we checked to see if the source\n\nNER RE AHSAN\n\nRDA RARE ARRESTS NOR ES\n\n314 Section 3 Artificial Intelligence\n\ntic rte RN Se FA on her ORL HEE ey na NaH HRSA MENGE\n\npoint was closer than some chosen epsilon distance to the portal edge. When it was,\nwe simply looked ahead to find the next portal on our path that wasn't so close to the\nsource point and used that as our portal.\n\nAnother item to consider is choosing alternate directions when the desired direc-\ntion vector does not intersect the portal. It might not be clear which of the two portal\nendpoints is the best choice to follow. Choosing an endpoint based on which end-\npoint most closely matches the desired direction might not be sufficient. For example,\nif the desired direction vector is perpendicular to the portal and moving away from it,\nthen either of the portal’s endpoints is equally desirable. Floating-point precision and\nother minor variations could cause undesirable oscillations. One method that can\nresolve this ambiguous situation is to look ahead at successive portals until a portal is\nfound that clearly indicates which endpoint of the current portal is closest to our\nfuture path. This ‘look-ahead’ technique also has the added benefit of creating more-\ndirect navigation as the creature travels around winding pathways. Since this tech-\nnique is rarely needed and usually only requires a few triangles of look-ahead, the\nextra CPU cost is minimal.\n\nRepresenting Creatures\n\neA\n\nUsing a nav mesh, we are able to travel intelligently from one point on the mesh to\nanother point on the mesh. Most creatures, however, occupy more space than a single\npoint, and so a question arises about how to account for their thickness. Since effi-\nciency was more important to us than accuracy, we simply used a circle to represent\nthe two-dimensional area of a creature on the nav mesh, where the radius of the circle\nrepresented the thickness of the creature. Using circles gave us some problems with\ncreatures that were not very circular in shape. For example, a horse doesn’t look very\ncircular when viewed from above. If you made the circle big enough to enclose the\nentire horse, then other creatures would avoid the sides of the horse, and the horse\nitself wouldn't be able to squeeze into an area that it visually should fit into. If you\nmade the circle smaller so that creatures could get closer to the horse, then youd let\nthe ends of the horse poke out of the circle, where they might occasionally overlap\nsomething else.\n\nDespite these problems, we felt that the advantages of using circles outweighed\nthe disadvantages. For Jak and Daxter, we were always able to find a radius that\nappeared to be a reasonable compromise between these two adverse effects. Another\nadvantage to using circles was that rotation didn’t have to be factored in when check-\ning for collision with the nav mesh or other dynamic obstacles.\n\nInstead of trying to adapt our nice, simple, point-to-point nav mesh logic to a\nmuch more computationally expensive circle-to-circle logic, we opted to preshrink\nour nav meshes to account for the radii of the creatures that may be using it. The con-\ncept is simple in that instead of modeling the nav mesh to exactly abut against obsta-\ncles, the mesh is modeled to stay at least some radius from all obstacles. Figure 3.7.7\nshows how a nav mesh might be modeled for a small creature, and Figure 3.7.8 shows\n\n3.7 A Fast Approach to Navigation Meshes\n\nFIGURE 3.7.7 Mesh for small creatures.\n\nthe same scene with a nav mesh modeled for a larger creature. If we guarantee that the\ndistance from the edges of the nav mesh to all static obstacles is greater than or equal\nto the radius of the creatures that use the nav mesh, then the creature can be repre-\nsented by a point instead of a circle.\n\nThis is an enormous optimization, since moving a point around the nav mesh is\nmuch simpler than moving a circle around the mesh, though it does come with some\nproblems. The biggest problem is that different types of creatures might want to use\nthe same nav mesh, and some creatures might have significantly larger circles than\nother creatures. If the nav mesh is modeled to work for the larger creatures, then the\nsmaller creatures might not be able to move very close to the static obstacles. In gen-\neral, this wasn’t a problem for us, but occasionally we had situations where the dis-\ntance of the nav mesh was far enough from static obstacles that the player could stand\nnext to a wall and a smaller creature couldn't get close enough to the wall to attack the\nplayer. To fix this undesirable behavior, we would adjust the distance of the nav mesh\nto any surrounding static obstacles until we found a compromise in which larger crea-\ntures would overlap the static obstacles slightly, but smaller creatures would be able to\nreach the player.\n\nOur second biggest problem was that it was often difficult to judge what distance\nto use when modeling a nav mesh. The appropriate distance to use was based on the\nradii of the circles representing the creatures on the mesh, and the types of creatures\nand radii of their circles were subject to occasional design and programming changes.\n\n316\n\nSection3 Artificial Intelligence\n\nLL\n\nFIGURE 3.7.8 Mesh for large creatures.\n\nDynamic Obstacles\n\nsesamiae aa rea\n\nis na RIN Ce\n\nUsing circles to represent creatures gave us the advantage that we could treat creatures\nas points when moving them around the nav mesh. This is also true for moving crea-\ntures around dynamic obstacles, such as other creatures. Instead of using computa-\ntionally expensive logic for moving a circle around other circles, we can simply inflate\nthe circles of surrounding obstacles by the radius of the creature currently being\nmoved. For example, Figure 3.7.9 shows a creature of radius r and two dynamic\nobstacles with different radii, and Figure 3.7.10 shows how we treat the creature as a\npoint by adding its radius to the obstacles. By inflating surrounding circles before\nmoving a creature, we've unified the representation of a creature to being a single\npoint and reduced our navigation issues to the relatively simple problem of moving a\npoint inside the bounds of a mesh while avoiding surrounding circles.\n\nTo navigate the point among the circles, we checked to see if the direction that we\nwanted to travel would cause us to collide with any nearby circles. If not, then we\ncould go ahead and move in the desired direction. If it was determined that a collision\nwould occur, we computed two new vectors that would steer us clear of the collision\n(see Figure 3.7.11).\n\nThese two vectors could be considered as rotations away from the original vector:\na rotated vector to steer to the left of the obstacle, and a rotated vector to steer to the\n\n3.7 AFast Approach to Navigation Meshes 317\n\nobstacle\nobstacle\n\né\n\ncreature\n\nFIGURE 3.7.9 Creature as circle with two circular dynamic obstacles.\n\ni\n\npo\n\nFIGURE 3.7.10 Creature simplified to a point with obstacles enlarged to\ncompensate.\n\nright of the obstacle. We would then check these two new vectors to see if either of\nthem would collide with any other obstacles. If so, then we would appropriately rotate\nthe right-most vector to the right or rotate the left-most vector to the left to avoid any\nadditional obstacles. Once all potential obstacles had been accounted for, the two\nresulting vectors showed two possible ways to move that would avoid the dynamic\n\n318\n\nSection 3 Artificial Intelligence\n\nFIGURE 3.7.11 Getting around a dynamic obstacle that intersects\nour desired path.\n\nobstacles’ blocking the originally desired direction of movement. To avoid an undesir-\nable cyclic movement behavior and to keep things simple, we usually chose the vector\nthat more closely matched the creature’s last direction.\n\nOne problem we had with this approach was that the creature could occasionally\nbecome stuck inside of other dynamic obstacles. This was commonly caused by float-\ning-point precision issues, but it could also occur due to various other movement\nbehaviors. Instead of trying to solve the thorny problem of not allowing overlaps to\noccur under any situation, we opted to have an embedded creature attempt to move\naway from the obstacles that overlapped it. Basically, we identified which circle the\ncreature overlapped the most, and after computing the directions to avoid the other\ncircles, we blended those results toward the direction away from the overlapping cir-\ncle, proportionate to the amount of the overlap. This technique caused overlap cases\nto resolve themselves in a reasonable manner.\n\nAnother potential problem was that a creature could become completely sur-\nrounded by other dynamic obstacles such that the left and right vectors both faced\nexactly opposite of the originally desired vector. We chose to ignore handling this\ncase, which meant that a creature could potentially move to a position that would\ncause them to overlap one of the surrounding dynamic obstacles. In practice, how-\never, this wasn’t an issue for us, especially since creatures naturally tended to move\naway from overlaps.\n\nNavigation of Both Static and Dynamic Obstacles\n\nOur final logic for maneuvering creatures turned out to be quite simple and broke\ndown into the following steps. First, we found the best direction to reach our destina-\n\n3.7 A Fast Approach to Navigation Meshes\n\n319\n\ntion using the nav mesh and its portals. We then checked to see if the resulting direc-\ntion would hit any dynamic obstacles (circles). If so, we modified the direction to\navoid them. Finally, we checked to sce if this new direction would lead us off of the\nnav mesh. If so, we clamped the movement to the nav mesh.\n\nThe final step of clamping movement to stay on the nav mesh was done for effi-\nciency and required a little bit of finesse. One problem was that a creature might\nbecome blocked and be forced to stop. Another issue was that we sometimes allowed\na creature's movement vector to be bent against the edge of the nav mesh instead of\nbeing simply clamped. The bent vector allowed the creature to continue moving, but\nwe didn’t do an additional check to see if the bent vector would cause the creature to\noverlap nearby circles; so a creature might subsequently become embedded within\nanother creature. Since our circle avoidance logic made creatures naturally want to\nmove away from overlaps, this usually wasn’t an issue between two moving creatures.\nWe did, however, encounter issues when a moving creature overlapped a dynamic\nobstacle that didn’t move, such as a crate. To eliminate this problem, we made sure\nthat nonmoving dynamic obstacles, such as crates, were not placed near the bound-\naries of a nav mesh.\n\nAdditional Nav Mesh Thoughts\n\n‘SiH aURReRm SIAR IRNI RON RESUS ROIS BN SRILA RpR SS RSRRRNNDRE NNT EAI\n\nOur nav meshes predominantly denoted two-dimensional areas where dynamic\nobstacles were allowed to move. This sufficed in most cases, since most creature setups\ncan be described using two-dimensional boundaries. However, we occasionally had\nsituations that required three-dimensional information. For example, if we wanted to\nput a creature on a circular staircase that spiraled upward, it would not be sufficient to\nuse just a two-dimensional nav mesh to describe the staircase. For this type of situa-\ntion, we had a maximum height that the creature could be from the surface of a nav\nmesh triangle in order to be considered on that triangle. This gave the ability for a nav\nmesh to have three-dimensionally crisscrossing triangles, as long as the triangles that\noccupied the same two-dimensional space were at sufficiently different elevations so\nthat it was clear which triangle a creature was using.\n\nAnother enhancement that we made to our nav mesh system was the ability for\ncreatures to jump across certain obstacles to reach the desired final destination. For\nexample, a creature might jump across small chasms in pursuit of the player. Model-\ning triangles across the chasm and marking those triangles as special ‘gap triangles’\naccomplished this ability. When a creature crossed a portal into a gap triangle, a\nsearch found the triangle on the far side of the gap, and the creature was sent a mes-\nsage telling it to jump across the gap to that triangle. In order to keep the creature\nfrom landing on top of a dynamic obstacle on the other side of the gap, the creature\nused a temporary circle that reserved a safe landing place.\n\nKAA EMSC TRI.",
      "page_number": 296,
      "chapter_number": 32,
      "summary": "This chapter covers segment 32 (pages 296-313). Key topics include creatures, meshes, and mesh. Then, we'll look at A* and its tactical cost function, and\nthe larger search space involved.",
      "keywords": [
        "nav mesh",
        "creature",
        "mesh",
        "point",
        "Nav",
        "triangle",
        "obstacles",
        "Dynamic Obstacles",
        "portal",
        "Nav Meshes",
        "Navigation Meshes",
        "Artificial Intelligence",
        "path",
        "nav mesh triangle",
        "Static obstacles"
      ],
      "concepts": [
        "creatures",
        "meshes",
        "mesh",
        "path",
        "distances",
        "obstacles",
        "figuring",
        "point",
        "sectors",
        "triangles"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 1",
          "chapter": 30,
          "title": "Segment 30 (pages 279-290)",
          "relevance_score": 0.73,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 2",
          "chapter": 32,
          "title": "Segment 32 (pages 306-318)",
          "relevance_score": 0.68,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 1",
          "chapter": 31,
          "title": "Segment 31 (pages 291-298)",
          "relevance_score": 0.67,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 24,
          "title": "Segment 24 (pages 222-231)",
          "relevance_score": 0.63,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 7",
          "chapter": 64,
          "title": "Segment 64 (pages 617-624)",
          "relevance_score": 0.6,
          "method": "api"
        }
      ]
    },
    {
      "number": 33,
      "title": "Segment 33 (pages 314-325)",
      "start_page": 314,
      "end_page": 325,
      "detection_method": "topic_boundary",
      "content": "320 Section 3 Artificial Intelligence\n\nConclusion\n\nenisaReROOORONE SAIN\n\nOur navigation mesh system admirably fit our needs for the development of Jak and\nDaxter (see Plate 3). We were able to create many different types of creatures that\nexhibited a variety of behaviors while intelligently navigating our complex three-\ndimensional environments. Although navigational approaches exist that might pro-\nvide more-robust general solutions to this difficult problem, our system excelled at\nbeing both fast and conceptually simple, creating a winning combination for us.\n\n3.8\n\nChoosing a Relationship\nBetween Path-Finding\nand Collision\n\nThomas Young, PathEngine\nthomas@pathengine.com\n\nlor many games, the Al is all about characters moving around within an environ-\n\nment. It’s no use having sophisticated decision-making systems if the resulting\ndecision can’t be executed when the player moves behind a bunch of crates. On the\nother hand, if a character correctly understands how to deal with the obstructions in\nits environment, then even a very simple decision-making structure can result in\nimpressive-looking AI.\n\nWe can think of the pathfinder as a system with the responsibility of understand-\ning collision. The relationship between path-finding and the collision system is a key\narchitectural issue when creating characters that understand how to react to the\nobstructions in their environment. Three different approaches to this architecture and\nthe implications of each approach will be explained in this gem.\n\nMoving Under the Control of Collision\n\nWe don't want characters walking through walls, tables, or other obstructions. To pre-\nvent this from happening, character movement can be controlled by a collision sub-\nsystem. Decisions made by the AI are subject to arbitration by this subsystem before\nbeing implemented as character movement.\n\nThis creates a strong dependency between code that generates character movement\nand collision code that arbitrates that movement. Behavior code depends on the results\nof the collision code in order to work as intended. Imagine the situation where behav-\nior code thinks a character can walk directly toward the player, but in fact that charac-\nter is snagged on an obstruction. The behavior code must take collision into account.\n\nThe Collision Model for Path-Finding\n\nA pathfinder allows certain possibilities for movement and disallows others. This\nimplies a certain understanding about how collision works. We can call this the\npathfinder’s collision model.\n\n321\n\n322\n\nSection 3 Artificial Intelligence\n\nWe can often describe this collision model in terms of path-finding space and\nobstructed space. In a tile- or cell-based pathfinder, path-finding space is defined by the\nset of unobstructed tiles or cells. Figure 3.8.1a shows a tile-based path-finding space\n(white cells) and obstructed space (black cells). In a points-of-visibility- or waypoints-\nbased system, the path-finding space is represented explicitly along with a set of\npoints. Figure 3.8.1b shows what the path-finding space might look like in this case.\n(Note that this path-finding space must correspond with the set of points used, oth-\nerwise the pathfinder will not function correctly.) When generating a path, the\npathfinder allows the possibility of movement within the path-finding space, but it\ndoes not allow paths to cross through obstructed space.\n\nFIGURE 3.8.1 Path-finding space for (A) a tile-based system and (B) a points-of-\nvisibility system.\n\nIt is the relationship between this collision model for path-finding and the colli-\nsion actually applied to movement that differentiates the three approaches to be\ndiscussed.\n\nApproach #1: Fault-Tolerant Al\n\nSRN SOR GIHTUHE Re I HY RNAI TE OB ANSE\n\nA defined relationship between the collision model used by path-finding and collision\nactually applied means that there is an interdependency, or linkage between these two\nsystems. The implication is that whoever codes the path-finding system will need to\nbe aware of any changes to the collision system (or vice versa) to make sure that the\nrelationship is not broken.\n\n3.8 Choosing a Relationshp Between Path-Finding and Collision 323\n\nCARRERE\n\nFrom an architectural point of view, reducing interdependencies is good practice.\nHuman behavior doesn’t depend on our knowing the precise physics behind collision\nwith our environment. We have a rough idea of how to move through our environ-\nment, get by with feedback mechanisms and so on, and avoid collisions. Can we use a\nsimilar approach for our AI and thereby avoid direct linkage with the collision system?\n\nThe idea behind the fault-tolerant approach is that the collision model for path-\nfinding need only roughly correspond to the actual, more-detailed collision applied to\nmovement. The pathfinder’s representation might perhaps be edited manually to\napproximate collision, or it could be built automatically from the same world and\nobject representations used by collision without any further assumptions about how\nthat collision works. The pathfinder is used to generate guide paths, and then the AI\nuses fault-tolerance methods to ensure that characters can actually move along those\npaths under arbitration by the collision system.\n\nIn Figure 3.8.2, collision takes place between a character and the obstacles drawn\nin black. The pathfinder approximates this with a polygonal path-finding space,\ndrawn in white. The black line shows a guide path returned by the pathfinder. The\ngray line shows the direction in which the character must move to avoid collision\n(with the obstructions in black) while continuing in the general direction of the guide\npath. [Reynolds97] describes how steering behaviors can be combined to achieve this\n\nkind of effect.\n\nFIGURE 3.8.2 Steering to avoid collision.\n\nThe fault-tolerant approach is attractive because it produces plausible results\nfrom the point of view of modeling real-world behavior. If we have simple collision\nand a relatively small world to test our behaviors against, then this approach can\nwork well. The more closely path-finding space approximates real collision, the bet-\n\n324\n\nSection 3 Artificial Intelligence\n\nter this approach will work. However, if we have reasonably complex collision, then it\nwill be difficult to approximate this with a pathfinder. If our behaviors will be applied\nin a large number of different situations, then we can also expect problems with this\nmethod.\n\nIn some situations, it is difficult to find the correct steering. For the character in\nFigure 3.8.3, it is necessary to change direction several times in order to get through\nthe gap. The squiggly gray line in Figure 3.8.3 indicates the steering that is required. If\nthe correct steering cannot be found in a situation like this, the result will probably just\nbe a character floundering momentarily against an obstruction. In a more extreme sit-\nuation, the result could be a character getting stuck in between obstructions.\n\nFIGURE 3.8.3 Steering correctly can be a complex problem.\n\nTo find the correct steering in a difficult situation requires future possibilities for\nmovement to be taken into account. The gray line in Figure 3.8.3 is really a detailed\npath for planned movement as opposed to a steering vector. A combination of path\nsections needs to be found to solve for movement through the gap. The first section\nof this needs to correctly position the character for movement along the second sec-\ntion, and so on. In this case, finding the correct steering really requires planning and\nsome detailed understanding of collision.\n\nSometimes, it might not actually be possible to move along the guide path. Con-\nsider for example a gap slightly narrower than that in Figure 3.8.3. In this case, we\nwould like characters to recognize in advance that a gap cannot be passed and choose\nanother, more appropriate path. Again, this requires planning and detailed under-\nstanding of collision.\n\nWe can perhaps extend the fault-tolerant approach to address these problems by\nusing planning mechanisms that adapt to feedback from collision. The first time a\n\n3.8 Choosing a Relationshp Between Path-Finding and Collision 325\n\nApproa\n\ncharacter arrives at the gap in Figure 3.8.3 and fails to find a way through with reac-\ntive behaviors, we could mark that gap as blocked in our path-finding representation.\nThis kind of fault tolerance is difficult to implement and still does not provide any\nreal guarantees about behavior. There is nothing to stop a character from walking into\na situation that they cannot steer out of.\n\nAnother approach might be to use machine-learning techniques, such as neural\nnetwork training, to build behavior directly from collision feedback. These kinds of\ntechniques effectively automate the linkage between collision and behavior—but note\nthat a dependency on collision still remains. The results of these kinds of techniques\ndepend very much on the exact nature of the collision, so any change in the collision\nsystem introduces the risk of breaking behaviors. Even if the collision system doesn’t\nchange, these techniques do not work well in collision situations that are different\nfrom those they were trained on.\n\nIf we need guarantees about behavior, then we are probably better off accepting\nlinkage between AI and collision. This enables us to design an understanding of colli-\nsion into our Al.\n\nch #2: Path-Finding in a Subset of\nructed Space\n\nBAAS SURRY CNHOSS RNR EE ARR A RRA NOON RNAS CRRA TTR TANIA ISMN AHI\n\nWith this approach, we can define a relationship between collision and path-finding\nwhile avoiding the need for interdependencies between these systems. Specifically, we\nneed to guarantee that all points in path-finding space are unobstructed by collision;\nor in other words, that valid space for the pathfinder is a subset of true unobstructed\nspace.\n\nTrue unobstructed space means the set of positions where a character can be\nplaced without being in collision. If the orientation of a character affects whether that\ncharacter is in collision, then that orientation adds an extra dimension(s) to unob-\nstructed space, and therefore a position in unobstructed space will include orientation\nas a component. For this approach, path-finding space can be represented in fewer\ndimensions than true unobstructed space, and the boundary of path-finding space is\nsimplified. What is important is that the movement through positions in path-find-\ning space is guaranteed to be collision-free.\n\nFigure 3.8.4 shows how path-finding space might be constructed for this\napproach. In this case, the rotational dimension of collision is eliminated by using a\nbounding box that is large enough to fit the character at any rotation. Sets of obstruc-\ntions are simplified by taking convex hulls and then expanding the resulting geometry\nby the shape of our bounding box. (See [Young01] for more detail.) The result is that\nwe can guarantee that our character will not collide at any rotation of that character\nfor any position in path-finding space.\n\nWe can use a similar approach for tile-based path-finding. In this case, we can\nrender expanded shapes into the path-finding grid and flag any grid tiles overlapped\nby these shapes as obstructed.\n\n326\n\nSection 3 Artificial Intelligence\n\nFIGURE 3.8.4 Path-finding in a subset of unobstructed space.\n\nThe advantage of this approach is that the pathfinder can now tell us how to\nmove without colliding. A path returned by the pathfinder can be followed without\nthe need for a layer of reactive behaviors because we know that the path will be unob-\nstructed. The AI still doesn’t know how to get through the narrow gap, but now this\nis integrated into movement-planning so that our behavior can choose another path\nor do whatever is appropriate. If we want our character to be able to get into the top-\nleft part of our environment, then we will need to widen the gap; but now we can use\nthe pathfinder to tell us about this kind of problem automatically.\n\nBecause path-finding space is only a subset of true unobstructed space, we must\ndeal with the possibility that characters might find themselves outside of valid space.\nCharacters should never get to an invalid position by following paths returned by the\npathfinder; but we must consider the possibility that characters might be pushed out-\nside of path-finding space by interactions with other characters, the force of an explo-\nsion, or whatever.\n\nThe pathfinder cannot tell a character outside path-finding space how to get back\ninto path-finding space without colliding. Once a character is outside of path-finding\nspace, we have the same kind of problems as with the previous approach. We can use\nreactive methods to get back to a valid position, but if a character is pushed into a nar-\nrow gap, then there is still a possibility that the character might get stuck. This situa-\ntion is a lot less likely because characters will not move into gaps by themselves; hence,\nthe reactive methods can be focused on simply getting characters back to a valid\npoint. They are simpler to code and more functional.\n\nA good, practical solution that enables us to give guarantees about character\nbehavior is to allow characters to cheat collision when moving back into path-finding\nspace. If everything works correctly and problematic configurations of geometry are\n\n3.8 Choosing a Relationshp Between Path-Finding and Collision 327\n\navoided, then this shouldn't be needed, but designing this into our system can give us\na lot more peace of mind during beta testing. (Beware of potential consequences of\ncheating collision, as discussed below.)\n\nFinding a Valid Position\n\nThe simplest way to obtain a valid position for a character that has somehow found\nitself outside of path-finding space is to keep track of the last known good position. This\ncan give bad results if a character moves a significant distance while outside path-finding\nspace (see Figure 3.8.5a). Additionally there will be times when we need to deal with a\nposition outside path-finding space for which there is no last-known good position.\n\nA more elegant approach is for the pathfinder to provide a query that returns the\nclosest point inside path-finding space to a given point outside that space. This works\npretty well and applies more generally; but in certain situations, the resulting point\nmight be on the other side of a wall from a character's current position (Figure\n3.8.5b). If this happens, the character will not be able to get back into valid space by\nmoving toward that point unless they are allowed to cheat collision. If they are\nallowed to cheat collision, then the result is that a character gets through a wall and\ninto another part of the game. This can sometimes have humorous consequences, but\nis nonetheless a pretty serious bug.\n\nA B C\n\nFIGURE 3.8.5 (A-C) Finding a valid position.\n\nPutting Backbones in the World\n\nWe can improve the closest valid point method by adding an extra level of hard-colli-\nsion ‘backbones’ to the world (Figure 3.8.5c). These backbones can be represented\nexplicitly or can be based on the existing world representation. If the world is already\ndivided into cells, then it could be sufficient to use boundaries between cells as back-\nbones. The closest valid point query is then modified to look for the closest point that\ndoes not involve crossing a backbone. This gives us a more appropriate result.\n\n328 _ Section 3 Artificial Intelligence\n\nFor the case where characters are allowed to cheat collision while returning to\npath-finding space, the backbones provide a way for us to enforce constraints about\nconnectivity in the game world. Theoretically, this means that path-finding around\nbackbones might now be required in order to maintain our guarantee that characters\ncan always get back to a valid position; but in practice, this will probably not be nec-\nessary. If we do implement path-finding around backbones, then this will also be use-\nful for hierarchical path-finding (see [Rabin00)).\n\nApproach #3: Using the Pathfinder Itself for\nCharacter Collision\n\nASH SSSRURNMRMEY Cre NMRENRANNN\n\nBoth of the previous approaches are complicated by the possibility of situations where\nobstruction by the collision system is not understood by the pathfinder’s simpler\nmodel. We can avoid this with a third approach, which uses the pathfinder itself to\nprovide character collision. This approach guarantees that characters cannot be\npushed out of path-finding space and, therefore, that the pathfinder will always be\nable to understand a character’s current position (and that paths returned by the\npathfinder can always be followed). This gives us a simplified architecture and reliable\ncharacter movement, but at the cost of having to use simplified mechanics for charac-\nter collision.\n\nThere are other advantages to using simplified character collision. The collision\nwill be extremely fast, robust, and predictable. We can use the collision system to\nimplement constraints on game progression or to trigger scripts and be confident that\nthis will all work exactly as intended. On the other hand, we potentially lose a lot of\ninteresting interaction between the character and the world, which a sophisticated\ncollision system would have provided.\n\nCharacters might still need to deal with target positions outside path-finding\nspace, and for this, we might still need a query to find the closest valid point. The\nadvantage is that we no longer depend on these methods to extract a character from\npotentially being stuck in positions.\n\nEAE HER ERE EEA SE RHE Ns AREER ESTEE ORES SS TRIOS RAAT\n\nLayered Collision\n\nIn order for the AI to understand the mechanism that controls character movement,\nwe need to simplify this mechanism; but complex collision interaction is necessary if\nwe want to create an interesting and believable environment. The trick to meeting\nboth of these requirements at the same time is to use a layered collision architecture.\n\nIf behavior is implemented in terms of movement through path-finding space\nand the pathfinder understands the system that governs that movement, then we have\nall the guarantees that we need. Movement through path-finding space will often\nmean the translational part of the movement of a character’s local origin. In our lay-\nered architecture, a path-finding collision layer deals with this part of character move-\nment. More-sophisticated interactions can be provided in a world collision layer as\nlong as those interactions do not affect this movement of the character’s origin.\n\n3.8 Choosing a Relationshp Between Path-Finding and Collision 329\n\nWorld collision can take responsibility for extra dimensions of the character's\nposition (such as the vertical coordinate of that position or the orientation of the\ncharacter) if those dimensions are not relevant to the pathfinder’s collision model.\nNote that if a character needs to turn in a certain direction in order to move, then we\nhave to be careful when applying world collision to character orientation. World col-\nlision can also give us 3D interactions between a character’s limbs and the environ-\nment as long as that character's skeleton remains anchored to the character’s origin.\n\nBy designating certain events as temporary or exceptional, we can add more-\ninteresting interactions to the system. It makes sense for certain events to interfere\nwith the ability of a character to move along a path; so for these types of events, we\ncan allow world collision to affect movement through path-finding space. Consider\nfor example the blast from an explosion or interaction with a projectile. The only con-\nstraint for these types of events is that the character should not be moved outside\npath-finding space by the interaction, so we know that the character will be able to get\nup afterward and resume path-finding. Figure 3.8.6 shows how a force resulting from\na 3D interaction might be fed back into the path-finding collision layer.\n\n~_@,’\n\n~——— Interaction in 3D\n\n\\\n\nForce applied in\npathfinding ~__\ncollision\n\nFIGURE 3.8.6 Interaction between collision layers.\n\nIm lementing Movement Along a Path\n\nsUNURARE RAAT ARE STIRRUP NENA RONEN AER ASER CRRA EAE ATR AUT NAMES LTE TH SOTA TRATES\n\nFor the second and third approaches, we assume that a character moving along a path\nwill not leave path-finding space. In order to ensure that this is true, we have to be\ncareful exactly how movement along a path is implemented.\n\nIt is quite common to implement character control through a turn-and-move\ninterface. A range of angles might be used to detect success in turning toward the next\npath target before moving forward. However, this will result in characters clipping\ncorners (Figure 3.8.7a). Even if we get the angle exactly right, a character might still\nend up at an invalid position by overshooting a path target (Figure 3.8.7b). With\napproach number two, this means the pathfinder must find the closest valid point,\n\n330 Section 3 Artificial Intelligence\n\nA B c D\nFIGURE 3.8.7 (A-D) Moving along a path.\n\nbut moving to that point will interfere with smooth movement along the path. For\napproach number three, these problems can result in a character being blocked by\npath-finding collision and unable to move along the path. Making the characters slide\nalong the edges of path-finding space will help in many cases, but not all.\n\nThe code required to eliminate these kinds of errors in a turn-and-move interface\ngets quite complex. We can simplify the situation by switching to parametric move-\nment along a path (Figure 3.8.7c). Turn constraints can still be satisfied before start-\ning to move along a path, but for turn constraints during movement along the path,\nwe are better off modifying the path to satisfy the constraints (Figure 3.8.7d).\n\nEven with parametric movement, there are issues about the approximation for\npoints along a path. The most common problem will be when a path follows a diago-\nnal boundary of path-finding space, as shown in Figure 3.8.8a. Approximating a point\nat a given distance along this path might result in a point that is just outside path-find-\ning space. In this case, we could avoid the problem by choosing the direction of\napproximation, depending on the direction of the path before and after this section.\n\nHowever, choosing the direction of approximation will not solve a situation such\nas that shown in Figure 3.8.8b. Here, even though we’ve approximated the point in\nthe right direction with respect to the angle of the following corner, we still come up\nwith a point inside an obstacle. A more general solution is to attempt to move to a\nfirst approximation, and only if this fails generate another point by approximating in\nthe other direction.\n\nIn a situation such as that shown in Figure 3.8.8c, there might be no valid points\nalong a path section. This kind of situation is pretty rare; so for static maps, we can\nadd code to the map-validation routines to check for this possibility and, if it occurs,\nsimply modify the maps to remove the problem. For geometry that changes at run-\ntime, we don’t have this option. One solution is to restrict the edges of dynamic\ngeometry to horizontal, vertical, or 45° lines because the problem cannot occur with\n\nthese kinds of edges.\n\n3.8 Choosing a Relationshp Between Path-Finding and Collision 331\n\nFIGURE 3.8.8 (A-C) Problems with approximation.\n\nConclusion\n\nThe relationship between AI, path-finding, and collision is a key issue for movement-\nbased Al. The fault-tolerant approach produces the most plausible results from the\npoint of view of simulating real behaviors and requires minimal constraints on path-\nfinding and collision. However, this approach can add a lot of complexity to the\nimplementation of behavior, which makes it very difficult to build behaviors that will\nwork reliably in all circumstances.\n\nPath-finding in a subset of truly unobstructed space gives reliable behavior most\nof the time at the cost of requiring some minimal linkage between the path-finding\nand collision subsystems. Since characters can still get outside path-finding space, we\nstill need to be able to deal with this case. It is possible to guarantee the results of\nbehavior with this approach if we allow characters to cheat collision in certain cir-\ncumstances,\n\nUsing the pathfinder itself to control character collision results in the simplest\narchitecture and the most reliable behavior. If it is essential to guarantee the results of\nbehaviors, then this is the approach to use. More-interesting collision interactions can\nbe provided through a layered collision architecture.\n\nThe second and third approaches can perhaps be seen as ‘control freak’\napproaches. To make these approaches work best, we need to extend this attitude to",
      "page_number": 314,
      "chapter_number": 33,
      "summary": "This chapter covers segment 33 (pages 314-325). Key topics include collision, collisions, and path. This creates a strong dependency between code that generates character movement\nand collision code that arbitrates that movement.",
      "keywords": [
        "path-finding space",
        "Collision",
        "Path-Finding",
        "character",
        "space",
        "collision system",
        "Character Collision",
        "path",
        "pathfinder",
        "path-finding collision",
        "movement",
        "Collision Model",
        "approach",
        "character movement",
        "system"
      ],
      "concepts": [
        "collision",
        "collisions",
        "path",
        "space",
        "approaches",
        "approach",
        "world",
        "behaviors",
        "points",
        "position"
      ],
      "similar_chapters": [
        {
          "book": "Game_Engine_Architecture",
          "chapter": 32,
          "title": "Segment 32 (pages 632-651)",
          "relevance_score": 0.68,
          "method": "api"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 33,
          "title": "Segment 33 (pages 652-672)",
          "relevance_score": 0.67,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 1",
          "chapter": 30,
          "title": "Segment 30 (pages 279-290)",
          "relevance_score": 0.66,
          "method": "api"
        },
        {
          "book": "operating_systems_three_easy_pieces",
          "chapter": 4,
          "title": "Segment 4 (pages 25-32)",
          "relevance_score": 0.66,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 1",
          "chapter": 41,
          "title": "Segment 41 (pages 389-403)",
          "relevance_score": 0.65,
          "method": "api"
        }
      ]
    },
    {
      "number": 34,
      "title": "Segment 34 (pages 326-336)",
      "start_page": 326,
      "end_page": 336,
      "detection_method": "topic_boundary",
      "content": "Section 3 Artificial Intelligence\n\n332\nthe mechanisms for implementing movement along paths. These approaches do not\ngive the most plausible architecture for behavior simulation, but for games that make\ndifficult demands on the AI, they provide a way to get through beta without too\n\nYP y to g 8\n\nmuch cost to hair or to sanity.\n\nReferences\n\nstv aa oreo ER BRN RATA ISAH ARRAN LESLIE SOTO NI ELLE LILO REE ERAS TRL TEL LON TS ITE\n\n[PathEngine] Path Engine, available online at http://www.pathengine.com, January\n\n[Rabin00] Rabin, Steve, “A* Aesthetic Optimizations,” Game Programming Gems,\nCharles River Media, Inc., 2000.\n\n[Reynolds97] Reynolds, Craig, “Steering Behaviors for Autonomous Characters,”\navailable online at http://www.red3d.com/cwr/steer/, September 6, 1997.\n\n[Young01] Young, Thomas, “Expanded Geometry for Points-of- Visibility Path-find-\ning,” Game Programming Gems 2, Charles River Media, Inc., 2001.\n\n4.1\n\n338\n\nT-Junction Elimination\nand Retriangulation\n\nEric Lengyel, Terathon Software\nlengyel@terathon.com\n\nuppose that a scene contains two polygons that share a common edge as shown in\n\nFigure 4.1.1a. When two such polygons belong to the same object, the vertices\nrepresenting the endpoints of the common edge are usually not duplicated. Instead,\nboth polygons reference the same vertices to save space and bus bandwidth. Graphics\nhardware is designed so that when adjacent polygons use exactly the same coordinates\nfor the endpoints of shared edges, the rasterizer produces pixels for each polygon that\nare precise complements of each other. Along the shared edge, there is no overlap\nbetween the pixels belonging to one polygon and those belonging to the other; and,\nmore importantly, there are no gaps between the polygons.\n\nA problem arises when adjacent polygons belong to different objects that have\ntheir own copy of the endpoint vertices for the shared edge. These vertices might\ngreatly differ in each object’s local coordinate space. For instance, when the vertices\n\n(a) (b)\n\nFIGURE 4.1.1 (A) Adjacent polygons sharing a common edge. (B) Adjacent polygons\nwith edges falling within the same line in space, but not sharing the same endpoints.\n\n339\n\nare transformed into world space, floating-point round-off error could produce\nslightly different vertex positions for each object. Since the vertex coordinates are no\nlonger equal, a seam might appear when the polygons are rasterized.\n\nA greater problem occurs when two polygons have edges that fall within the same\nline in space, but they do not share the same endpoints, as illustrated in Figure 4.1.1b.\nIn such a situation, a vertex belonging to one polygon lies within the interior of an\nedge belonging to the other. Due to the shape that the edges form, the location at\nwhich this occurs is called a T-junction. Because the adjacent edges do not share iden-\ntical endpoints, T-junctions cause visible seams in any game engine that does not\neliminate them.\n\nThis gem describes how to detect possible sources of these seams in complex 3D\nscenes and how to modify static geometry so that visible artifacts are avoided. Since T-\njunction elimination adds vertices to existing polygons (that are not necessarily con-\nvex), we also discuss a method for triangulating arbitrary concave polygons.\n\nT-Junction Elimination\n\npiesinae care NN RR EONNNONe ae\n\nHERR RRS ERR eNO RASHLSNSSRS SSID ON MAE RARE\n\nGiven an immovable object Ai in our world, we e need to ) determine whether there exist\nany other immovable objects possessing a vertex that lies within an edge of object A.\nWe only consider those objects whose bounding volumes intersect the bounding vol-\nume of object A. Let object X be an object that lies close enough to object A to possibly\nhave adjacent polygons. We treat both objects as collections of polygons having the\ngreatest possible number of edges. We perform triangulation of these polygons after the\nT-junction elimination process in order to avoid the creation of superfluous triangles.\n\nBefore we locate any T-junctions, we first want to find out if any of object A’s ver-\ntices lie very close to any of object X’s vertices. We must transform the vertices belong-\ning to both objects into world space and search for vertices separated by a distance less\nthan some small constant €. Any vertex V, of object A that is this close to a vertex Vy\nof object X should be moved so that V, and Vy have the exact same world-space coor-\ndinates. This procedure is sometimes called welding.\n\nOnce existing vertices have been welded, we need to search for vertices of object\nX that lie within a small distance € of an edge of object A, but which do not lie within\nthe distance € of any vertex of object A. This tells us where T-junctions occur. Let P;\nand P, be endpoints of an edge of object A, and let Q be a vertex of object X. The\nsquared distance d? between the point Q and the line passing through P, and P, is\ngiven by\n\n2 =(Q-B) _[@-2)-@-Pf (4.1.1)\n\nIf d? < €”, then we know that the point Q lies close enough to the line containing\nthe edge of object A, but we still need to determine whether Q actually lies between\nP, and P,. We can make this determination by measuring the projected length ¢ of the\n\n340 Section 4 Graphics\n\nline segment connecting P; to Q onto the edge formed by P; and P,. As shown in\nFigure 4.1.2, this length is given by\n\nt= ja — P,|| cos a, (4.1.2)\n\nwhere @ is the angle between the line segment and the edge. Using a dot product to\ncompute the cosine, we have\n\n(2-9) -(B - Bi) (4.1.3)\n\nBl\n\nIf t > lr, - P|| — €, then the point Q does not lie within the interior of the edge\nformed by P, and P,. Otherwise, we have found a T-junction, and a new vertex\nshould be added to the polygon of object A between P, and P,, precisely at Q’s\n\nlocation.\n\nFIGURE 4.1.2 The length t is equal to the distance from P, to the projection of point Q,\n\nonto the edge between P, and P;.\n\n. :\nRetriangulation\n\nEO RRO NI ARROEN\n\nRR si\n\naR RRS EUAN ASAIN et ER RE\n\nAfter all the static world geometry has been processed, we must triangulate the result-\ning polygons so that they can be passed to the graphics hardware. Any vertex added to\na polygon to eliminate a T-junction is collinear (or at least nearly collinear) with the\n\n4.1. T-Junction Elimination and Retriangulation\n\n341\n\nendpoints of the edge for which the T-junction occurs. After all T-junctions have been\neliminated for a single polygon, its edges might contain several vertices that fall in a\nstraight line. This prevents us from using a simple fanning approach that might ordi-\nnarily be used to triangulate a convex polygon. Instead, we are forced to treat the\npolygon as concave.\n\nThe algorithm that we describe takes a list of 2 vertices wound in a counterclock-\nwise direction as input and produces a list of m — 2 triangles. At each iteration, we\nsearch for a set of three consecutive vertices for which the corresponding triangle is\nnot degenerate (not wound in the wrong direction) and does not contain any of the\npolygon’s remaining vertices. Once such a set of three vertices is found, the middle\nvertex is disqualified from successive iterations, and the algorithm repeats until only\nthree vertices remain.\n\nIn order to determine whether a set of three vertices is wound in a counterclock-\nwise direction, we must know beforehand the normal direction No of the plane con-\ntaining the polygon being triangulated. Let P,, P,, and P; represent the positions of\nthe three vertices. If the cross-product (P, — P,) x (P3 — P,) points in the same direc-\ntion as the normal Np, then the corresponding triangle is wound counterclockwise. If\nthe cross-product is near zero, then the triangle is degenerate. Thus, two of our three\nrequirements for a triangle are satisfied only if\n\n(P, -P,)x(P,-P)-N.>e (4.1.4)\n\nfor some small value € (typically, € = 0.001).\n\nOur third requirement is that the triangle contains no other vertices belonging to\nthe polygon. We can construct three inward-facing normals, N,, N,, and N;, corre-\nsponding to the three sides of the triangle, as follows.\n\nN, = N, x(P, -B)\nN, = N, x(P; — Py)\n\nN, = N, x(P, - Py) (4.1.5)\n\nAs shown in Figure 4.1.3, a point Q lies inside the triangle formed by P,, P,, and\nP; if and only if N, - (Q— P,) > -€ for every i = 1,2,3.\n\nSince we have to calculate the normals given by Equation 4.1.5 for each triangle,\nwe can save a little computation by replacing the condition given by Equation 4.1.4\nwith the equivalent expression\n\nN, -(P,-P,)>e (4.1.6)\n\nThis determines whether the point P; lies on the positive side of the edge con-\nnecting P, and P,.\n\n342 Section 4 Graphics\n\nFIGURE 4.1.3 A point Q lies inside a triangle if and only if it lies on the positive side of\n\neach of the three edges of the triangle.\n\nImplementation\n\nEE\n\nSoo NAAT RAPIER REAR RR ER RRR NTIS\n\nThe source code provided on the CD-ROM demonstrates an implementation of the\n€e2%% — retriangulation algorithm. This particular implementation maintains a working set of\noNTHECD —_ four consecutive vertices and, at each iteration, determines whether valid triangles can\nbe formed using the first three vertices or the last three vertices. If only one of the sets\nof three vertices forms a valid triangle, then that triangle is omitted, and the algorithm\ncontinues to the next iteration. If both sets of three vertices can produce valid trian-\ngles, then the code selects the triangle having the larger smallest angle. In the case that\nneither set of three vertices provides a valid triangle, the working set of four vertices is\n\nadvanced until a valid triangle can be constructed.\nThe method presented by the source code was chosen so that the output of the\nalgorithm would consist of a series of triangle strips and triangle fans. Such triangle\nstructures exhibit excellent vertex cache usage on modern graphics processors. The\n\n343\n\n4.1. T-Junction Elimination and Retriangulation\n\nimplementation also includes a safety mechanism. If a degenerate, self-intersecting, or\notherwise nontriangulatable polygon is passed to it, then the algorithm terminates\nprematurely to avoid becoming stuck in an infinite loop. This happens when the code\ncannot locate a set of three consecutive vertices that form a valid triangle.\n\nConclusion\n\nRendering artifacts such as seams between adjacent objects can be avoided by welding\nnearly-coincident vertices and performing T-junction elimination.\n\nWhen these operations are performed as a preprocessing step, the resulting set of\npolygons may contain three or more collinear vertices. Fortunately, these polygons\ncan be triangulated using a simple but robust algorithm that emits a single triangle at\na time and recursively triangulates smaller sub-polygons.\n\n4.2\n\nFast Heightfield Normal\nCalculation\n\nJason Shankel, Maxis\nshankel@pobox.com\n\na are two-dimensional arrays of height values, commonly used to store\nterrain or water surface data, and are also commonly used for calculating bump\nmaps. This gem will describe how we can take advantage of the special characteristics\nof heightfield meshes to significantly optimize vertex normal calculation.\n\nlighting- and/or environment-mapping calculations are needed for the final rendering\nresult. There are two kinds of normals typically associated with a 3D mesh—face nor-\nmals and vertex normals. Face normals are, as the name implies, normals associated\nwith each face in a mesh. Vertex normals are normals associated with each vertex.\n\nFace Normals\n\nCalculating face normals is relatively straightforward. Pick two edges of the face that\nshare a common vertex and define two vectors (v, and v2) pointing along the edges\nwith their origin at the shared vertex. The face normal (m;) is a unit vector pointing in\nthe direction of the cross-product, , of v, and v2. Note that any two edges will do for\ntriangles, as shown in Figure 4.2.1.\n\nne = (v, X vy)! |v, X 0, | (4.2.1)\n\nVertex Normals\n\nVertex normals are a little less straightforward. While there is only one correct normal\nfor a given face, a given vertex might have multiple normals, each associated with a\nparticular face or group of faces. However, for meshes that are fairly smooth (which is\ntypical for heightfields), we can find a reasonably unique vertex normal by averaging\nthe normals of each face that touches the vertex. This average should be weighted by\nthe relative angle of each face at the vertex to prevent thin or highly tesselated faces\nfrom skewing the result.\n\n344\n\n4.2 Fast Heightfield Normal Calculation 345\n\nng = (019 v9)/lv, 9 v9|\n\nFIGURE 4.2.1 Calculating a face normal for a triangle.\n\nLet {72), 7, 3...2,} be the normals of the faces touching vertex v, and let {a), a,\n4;...a,} be the angles between the edges of faces 1 through n.\n\nThe normal at vertex v is given by Equation 4.2.2, as shown in Figure 4.2.2.\n\nn\n\nn — 120\n\n7 (4.2.2)\n\nny = (1141+ NzA7+ 1343+ N4gA4)/(a,+a7+ 43+ a4)\n\nFIGURE 4.2.2 Calculating a vertex normal using face normals,\n\n346 Section 4 Graphics\n\nSESE CER ANAS! eS eA REAR RRRRA\n\nHeightfield Normals\n\nThe vertices of a heightfield mesh can be defined as follows by v,,, where\n\nVp = {x y, A(x, yh. (4.2.3)\n\nIn Equation 4.2.3, x and y are regularly-spaced indices into the heightfield grid,\nand A(x,y) is the height at x,y. For a given vertex v in the heightfield, we can arrange\nthe neighboring vertices as shown in Figure 4.2.3. For simplicity, 4,4 refer to the\nvalues of A() for the four neighbors, and the four vectors which have their origins at v\nand point to the neighboring vertices are labeled 14,4.\n\nvy={x,y+1, Aa}- v\n\nv3={x-1, y,h3}-v v,={x+l, y,Ay}- v\n\nv={ x,y,h}\n\nvg={xy-1, Ag} o\n\nFIGURE 4.2.3 Heightfield vertex neighbors.\n\nSimplifying with Assumptions\nGiven the unique characteristics of heightfield vertices, we can make a number of\nassumptions that simplify the general vertex normal formula.\n\nFirst, we can assume that each vertex in the heightfield belongs to exactly four\nfaces. Note that, strictly speaking, this might not be the case. We are assuming that\nthe mesh is composed of quads, when it will most likely be composed of triangles.\nHowever, this assumption should not adversely affect the quality of our normals.\n\nSecond, we can assume that each of a vertex’s faces contributes equally to the ver-\ntex normal, thus eliminating the need for performing a weighted average. Again, this\nassumption is not completely safe. If two neighboring height values greatly diverge,\nthen the angle of their corresponding face will significantly diverge from 90°, thus\n\nield Normal Calculation 347\n\nchanging the ‘correct’ contribution of the face. However, in cases where neighboring\nheight values diverge significantly, the local vertices no longer have unique normals;\nand any formula, even the ‘correct’ one, will produce suspect results.\n\nFinally, since the x and y values are regularly spaced, when we set the origin at »,\nthe neighboring vertices will all have x and y values of 1, -1, or 0. These constants will\ngreatly simplify the cross-product formula.\n\nDoing The Math\n\nLet’s start with the original formula:\nn\ndna\n\nn, = 20 (4.2.4)\n\nn\na\n1=0\n\nNext, since there are only four faces and each contributes equally to the normal,\nwe can simplify the average:\nn,=(n, +n, +n, + 14)/4 (4.2.5)\n\nNow, when we go to calculate 7. 4, we will find that the cross-products reduce to\nsimple terms:\n\nn= 0,XV,= {-A, - h, 1}\nNy =V, X03 = {h,,—h,,1}\nNy =0;X04 = {h,h,,1}\n\nNg =U, XV, = {—h,,Ag.1} (4.2.6)\n\nIdeally, we would like 2,4 to have equal magnitudes, since variation in their\nmagnitudes will affect the averaging formula. However, since the magnitudes of 7, 4\nonly significantly vary in cases where the neighboring height values diverge, we can\nget away with using 7,4 as they are.\n\nAdding up, we get:\nn, = (n, +, +5 +14) 4 = {2(b, — hy), hy — hy), 44 (4.2.7)\n\nSince the magnitude of , is not important at this stage, we can multiply the\nwhole thing by two just to simplify the arithmetic:\n\nn, = {(bs ~ by)» (by — hy)» 2} (4.2.8)\n\nSince /,, 4 are most likely just memory lookups, it is clear that this formula is sig-\nnificantly faster than averaging four cross-products. It is important to remember that x,\nis not a unit vector and might need to be normalized, depending on your application.",
      "page_number": 326,
      "chapter_number": 34,
      "summary": "This chapter covers segment 34 (pages 326-336). Key topics include vertex, normal, and normalized. [Young01] Young, Thomas, “Expanded Geometry for Points-of- Visibility Path-find-\ning,” Game Programming Gems 2, Charles River Media, Inc., 2001.",
      "keywords": [
        "Artificial Intelligence",
        "vertices",
        "vertex",
        "normals",
        "object",
        "T-Junction Elimination",
        "triangle",
        "polygons",
        "vertex normal",
        "edge",
        "adjacent polygons",
        "Face normals",
        "T-Junction",
        "face"
      ],
      "concepts": [
        "vertex",
        "normal",
        "normalized",
        "vertices",
        "polygons",
        "triangles",
        "face",
        "graphics",
        "calculate",
        "calculation"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 7",
          "chapter": 44,
          "title": "Segment 44 (pages 413-428)",
          "relevance_score": 0.67,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 1",
          "chapter": 31,
          "title": "Segment 31 (pages 291-298)",
          "relevance_score": 0.61,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 2",
          "chapter": 35,
          "title": "Segment 35 (pages 347-359)",
          "relevance_score": 0.61,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 1",
          "chapter": 30,
          "title": "Segment 30 (pages 279-290)",
          "relevance_score": 0.6,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 2",
          "chapter": 32,
          "title": "Segment 32 (pages 306-318)",
          "relevance_score": 0.6,
          "method": "api"
        }
      ]
    },
    {
      "number": 35,
      "title": "Segment 35 (pages 337-346)",
      "start_page": 337,
      "end_page": 346,
      "detection_method": "topic_boundary",
      "content": "348 Section 4 Graphics\n\nacetate nnstonnnlttcinrtaatsine ni fain RE aan BenittnechNctre Oe oNhn  ae RSE EANEn R eacnaeeneoReR ENERO\n\nConclusion\n\net wi Sad\n\nHeightfields are often used to store landscapes and other static objects. For these\nkinds of applications, the speed of vertex normal calculation is probably not an issue,\nas normals will most likely be calculated offline or only once at data load.\n\nHowever, for applications that use dynamic heightfields (say, to simulate the sur-\nface of a body of water or for procedural bump-map animation), speed is of the\nessence. This gem has shown how we can significantly improve the performance of\nthe standard vertex normal formula by taking advantage of the special characteristics\nof heightfield vertices.\n\nSample Code\n\npom\n\nThe sample code applies the fast normal formula to a heightfield, which animates\nbetween flat and a fractally-generated random landscapes. The sample code uses\nOpenGL and GLUT. See Color Plate 4 for some screenshots of this application.\n\nON THE CD\n\nRefe nces\n\neo REE SITNNR EB AOL REE RTS RHI NN ANCA RRR SIRES\n\n] Ebert, D., et al., Texturing and Modeling, AP Professional, 1994.\n[Fernandes00O] Fernandes, Antonio Ramires, “Terrain Tutorial,” available online at\nhttp://www. lighthouse3d.com/opengl/terrain/, September, 2000.\n\nFast Patch Normals\n\nMartin Brownlow, Shiny Entertainment\nmbrownlow@shiny.com\n\nSS\" patches are a memory-efficient way of creating smooth surfaces that can be\nrendered at many levels of detail. However, having a smooth surface is not as use-\nful if you cannot light it properly. For that, you need the normal vector at each vertex.\nAlas, this needs to be computed afresh for each vertex.\n\nAlthough the method described here works for any basis matrix, for the purposes of\nthis gem, we will limit ourselves to discussion of bicubic Bézier patches (referred to\nhereafter simply as “patches”). These patches are represented by 16 control points\narranged in a 4 X 4 grid. The control points form a convex hull that the actual surface\nlies within. Only the four corner control points actually lie on the surface.\n\nA surface normal (hereafter referred to as “normal”) is a unit vector that lies per-\npendicular to the surface at the point it is associated with. This vector has many uses,\nthe most common of which are lighting and collision detection.\n\nA point on a patch is defined uniquely by two parametric coordinates, which are\nusually referred to as u and », and have a valid range of [0.0, 1.0]. These are not to be\nconfused with texture coordinates (although they might be used directly as such). If\nwe regard the patch as a 4 X 4 grid of control points, then the u value represents the\nhorizontal fraction of the way across the grid, and the v value represents the vertical\nfraction. The actual-world position of a (u, v) point depends entirely on the control\npoints. Indeed, if the control points are not evenly spaced in the world (as is more\noften the case than not), then a continuous step in the u direction can produce steps\nof varying lengths in the world.\n\nThe efficient tessellation and rendering of patches is beyond the scope of this\ngem. Many excellent texts exist that detail the different methods for drawing patches\n(see [Farin96], [Foley96], and [Gallier00]). A description of any single one of them\nhere would be inappropriate, since this method of generating normals is applicable to\nmost, if not all, methods of rendering a patch.\n\n349\n\n350 Section 4 Graphics\n\ntao npc inelebem enn ae eeOOet RR eerste Stacie Si mMM DREHER Ht tienen ooeolaen ES age eR ROR Da RO BEE EERE HIRES ANY\n\nTraditional Approaches\n\n_HomrERERNNOR ENRRRETHRCNNRRRRRE RMON\n\nThe most obvious approach to generating a patch vertex normal involves examining\nits neighbors. By considering the previous and next vertex in both the w and »v direc-\ntions of the patch, you can approximate the surface tangents. The normal is then sim-\nply the normalized cross-product of these two vectors.\n\nAnother method is to use the first derivative of the patch equations to directly\ngenerate the two tangent vectors. However, although this does not require any neigh-\nbors, it still needs a cross-product and a normalize operation per vertex.\n\nA ER SP TR ARR ORRIN ROS\n\nConsiderations\n\nRN RRR i\n\nIn order to efficiently process a patch on current PC graphics hardware, you must use\nwhat is called a “vertex shader.” This is basically a custom program written in a mini-\nmal but powerful instruction set that executes once for each vertex in the vertex\nstream. To gain the maximum parallelism and throughput, a vertex shader is restricted\nto operate on only one vertex at a time; it cannot access any vertex other than the one\ncurrently being processed. In other words, every vertex in the stream must contain all\nthe information needed to process it. It is also desirable to have the minimum amount\nof information per vertex to reduce the time spent by the graphics card in actually\naccessing the data, and to maximize the time spent in processing it. Obviously, our\ntarget is to have the vertex stream just contain the patch (#, v) coordinates for each\nvertex. Since the # and v coordinates have a range of [0.0, 1.0], and it is unlikely that\nwe will need more than about 100 subdivisions, it is possible to encode these into\nbytes, giving an impressive two bytes per vertex in the vertex stream!\n\nA Simpler Method\n\n‘a\n\nSHRM\n\nThese two methods presume that we only know the position at each control point,\nfrom which we can generate the curve equations and, ultimately, the normals. What if\nwe also have the normals at each control point to start with?\n\nThese are easily generated at each control point using a variety of methods,\nincluding the two methods previously described. A control point would then consist\nof a position and a normal. Any skinning code applied to a control point’s position\ncould also be applied to its normal. Given this, all we have to do is interpolate the\nnormal across the patch, just as we do the position. This has the added advantage of\nbeing a nonlinear interpolation, which will better approximate the real normal.\n\nThis meets all our hardware requirements; it requires only the (w, v) patch coor-\ndinates of the current vertex to correctly generate its position, normal, and texture\ncoordinates. It also has the advantages of working for any basis system and using\nexactly the same code as the position generation, just using control normals instead of\ncontrol points.\n\n4.3 Fast Patch Normals 351\n\nOther Advantages\n\nPECAN dee eB AOR RS BS TR TENN HEEB Ue eS\n\nAnother advantage of this method is that by generating the normals in different ways,\nyou can eliminate shading artifacts from curve continuity issues. If we treat the set of\ncontrol meshes for the whole object as a single continuous mesh, then we can create\nvertex normals for each control point exactly as we would for a Gouraud-shaded\nmodel. Although the normals wouldn't strictly be correct with respect to the curves, it\ncan give the model a much smoother look that would otherwise take the modeler\nmuch longer to create. If the normals are generated in this way, we eliminate curve-\ncontinuity issues in the model. This method also eliminates any shading issues that\nare introduced during the skinning process, when the curves lose continuity with each\nother as they are influenced by different bones.\n\nMost modern graphics architectures use a vector-based processor that operates on\nfour data elements simultaneously. This method uses two vectors, but each contains\nonly three items. We can use this to our advantage and interpolate two extra values\nacross the patch. This could be used for a variety of things, such as arbitrary texture\nmapping or a varying alpha value for better transparency effects.\n\nExactly How Accurate Can This Be?\n\n‘eoteiauuarga aise tenance eee Reh A NAME ARUN ICSE\n\nA Bézier curve has the property that the control points form a bounding mesh that\nthe curve never exceeds. This means that the interpolated normal will never be greater\nthan the modulus of the control mesh normals. However, except in the case of a\nstraight curve segment, a Bézier curve never passes through the center two control\npoints. In other words, the modulus of the interpolated normal will always be less\nthan or equal to the modulus of the control normal. The result is an interpolation\nthat is somewhere between linear and the correct arc interpolation. In practice, the\nnormal difference across the patch is not too large, meaning that the interpolation is\nvery close to the correct value.\n\nFor other curve basis systems, the problem can be a little more severe, with the\nnormals getting quite large for sudden, sharp turns on the surface. However, with\nstrategic use of most modern graphic cards’ ability to automatically normalize nor-\nmals, this is less of an issue than it would otherwise be.\n\nConclusion\n\n2s SHARIR TSUN HP UA a A ERT RE RIN eS OR RNS\n\nPatch surfaces are useful for creating smooth, resolution-independent geometry with\nminimal memory usage. By treating the normal at each control point as a second con-\ntrol mesh, we can quickly approximate the correct surface normal. Although the\nresults are not strictly correct, they can produce superior results by eliminating shad-\ning errors due to curve discontinuity introduced during skinning.\n\nase\n\n352 Section 4 Graphics\n\nesas he eee EAS\n\nReferences\n\n“sss eA LL RR RS NAOT TNE ES HORAN AN RSE NN IRE ERRORS RRR\n\n[Farin96] Farin, Gerald E., Curves and Surfaces for Computer Aided Geometric Design:\nA Practical Guide, Fourth Edition, Academic Press, 1996.\n\n[Foley96] Foley, Van Dam, et al., Computer Graphics: Principals and Practice, Second\nEdition in C, Addison Wesley, 1996.\n\n[Gallier00] Gallier, Jean, Curves and Surfaces in Geometric Modeling: Theory and Algo-\nrithms, Morgan Kaufmann Publishers, 2000.\n\n4.4\n\nFast and Simple\nOcclusion Culling\n\nWagner T. Corréa, Princeton University;\nJames T. Klosowski, IBM Research;\nand Claudio T. Silva,\n\nAT&T Labs-Research\n\nwtcorrea@cs.princeton.edu, jklosow@us.ibm.com,\nand csilva@research.att.com\n\ni many graphics applications, such as building walkthroughs and first-person\ngames, the user moves around the interior of a virtual environment and the com-\nputer creates an image for each location of the user. For any given position, the user\ntypically sees only a small fraction of the scene. Thus, to speed up the image render-\ning, an application should avoid drawing the primitives in the environment that the\nuser cannot see. There are several classes of algorithms to determine which primitives\nshould be ignored or culled. Back-face culling algorithms determine those primitives\nthat face away from the user. View frustum culling determines the primitives that lie\noutside of the user’s field of view. Occlusion culling determines the primitives that are\noccluded by other primitives.\n\nWhile back-face and view frustum culling algorithms are trivial, occlusion culling\nalgorithms tend to be complex and usually require time-consuming preprocessing\nsteps. This gem describes two occlusion culling algorithms that are practical, effective,\nand require little preprocessing. The first one is the prioritized-layered projection\n(PLP) algorithm, which is an approximate algorithm that determines, for a given bud-\nget, a set of primitives that is likely to be visible. The second algorithm, cPLP is a con-\nservative version of PLP that guarantees finding all visible primitives.\n\ndetermine which primitive fragments are visible; that is, which fragments are con-\nnected to the eye-point by a line segment that meets the closure of no other primitive\n[Dobkin97]. Researchers have studied this problem extensively, and many approaches\n\n353\n\nP\n\nto solve it exist [Cohen-Or01, Durand99]. A recent survey on visibility algorithms,\n[Cohen-Or01] classifies algorithms according to several criteria. We will now briefly\nsummarize those that are most relevant to our gem.\n\nFrom-Point Versus From-Region\n\nSome algorithms compute visibility from the eye-point only, while others compute\nvisibility from a region in space. Since the user often stays in a region for some time,\nthe from-region algorithms amortize the cost of visibility computations over a num-\nber of frames.\n\nPrecomputed Versus Online\n\nMany algorithms require an offline computation, while others work in real-time. For\ninstance, most from-region algorithms require a preprocessing step to divide the\nmodel into regions and compute region visibility.\n\nObject Space Versus Image Space\n\nSome algorithms compute visibility in object space using the exact, original 3D prim-\nitives. Others operate in image space using only the discrete, rasterized fragments of\nthe primitives.\n\nConservative Versus Approximate\n\nFew visibility algorithms compute exact visibility. Most algorithms are conservative\nand over-estimate the set of visible primitives. Other algorithms compute approxi-\nmate visibility and do not guarantee finding all visible primitives.\n\nPLP [Klosowski00] is an approximate, from-point, object-space visibility algorithm\nthat requires very little preprocessing. PLP can be understood as a simple modifica-\ntion to the traditional hierarchical view-frustum culling algorithm [Clark76]. The tra-\nditional algorithm recursively traverses the model hierarchy from the root node down\nto the leaf nodes. If a node is outside the view frustum, we ignore the node and its\nchildren. If the node is inside or intersects the view frustum, we recursively traverse its\nchildren. The traversal eventually visits all leaves within the view frustum.\n\nThis PLP algorithm differs from the traditional one in several ways. First, instead\nof traversing the model hierarchy in a predefined order, PLP keeps the hierarchy of\nleaf nodes in a priority queue called the front and traverses the nodes from highest\nto lowest priority. When we visit a node (or project it, in PLP parlance), we add it to\nthe visible set. Then, we remove it from the front and add its /ayer of unvisited neigh-\nbors to the front (hence, the algorithm’s name, “prioritized-layered projection”). Sec-\nond, instead of traversing the entire hierarchy, PLP works on a budget, stopping\n\n4.4 Fast and Simple Occlusion Culling 355\n\nthe traversal after a certain number of primitives have been added to the visible\nset. Finally, PLP requires each node to know not only its children, but also all of its\nneighbors.\n\nAn implementation of PLP can be simple or sophisticated, depending on the\nheuristic to assign priorities to each node. Several heuristics precompute the initial\nsolidity of a node and accumulate the solidities along a traversal path. The node’s accu-\nmulated solidity estimates how likely it is for the node to occlude an object behind it\n[Klosowski00]. In this gem, we use an extremely simple heuristic to assign priorities\nto the nodes. The node containing the eye-point receives priority —1, its neighbors\nreceive priority —2, their neighbors receive priority —3, and so on. Using this heuristic,\nthe traversal proceeds in layers of nodes around the eye-point. This is simple to imple-\nment, very fast, and quite accurate. We will show accuracy measurements when we\npresent the runtime results. The only precomputation this heuristic requires is the\nconstruction of the hierarchy itself.\n\nWe use PLP as a front-end to the hardware’s implementation of the z-buffer algo-\nrithm [Foley90]. For a given budget, PLP gives us the set of primitives it considers\n\n€ » most likely to maximize image quality. We simply pass these primitives to the graph-\noNTHECD ics hardware. The C++ implementation of PLP can be found on the CD-ROM.\n\nTh\n\nPLP Algorith\nAlthough PLP is, in practice, quite accurate for most frames, it does mot guarantee\nimage quality, so some frames might show objectionable artifacts. To circumvent this\npotential problem, we use cPLP [Klosowski01], a conservative extension of PLP.\n\nThe main idea of cPLP is to use the visible set given by PLP as an initial guess,\nwhile adding nodes to the visible set until the front (of the priority queue) is empty.\nThis guarantees that the final visible set is conservative [Klosowski01]. There are\nmany ways to implement cPLP, including exploiting new platform-dependent hard-\nware extensions for visibilicry computation. The implementation we describe in this\ngem uses an item-buffer technique that is portable to any system that supports\nOpenGL.\n\nThe cPLP main loop consists of two steps. First, we determine the nodes in the\nfront that are visible. To do this, we draw the bounding box of each node in the front,\nusing flat shading with a color equal to its identification number. We then read back\nthe color buffer and determine the nodes seen. Second, for each front node found\nto be visible, we project it (adding it to the visible set), remove it from the front,\nand then add its unvisited neighbors to the front. We iterate the main loop until\nthe front is empty. The bottleneck of the item buffer-based implementation of cPLP\nis in reading back the color buffer. To avoid reading the entire color buffer at each\nstep, we break the screen into tiles. Tiles that are not modified in one step can be\nignored in subsequent steps. The C++ implementation of cPLP can be found on the\n\nCD-ROM.\n\ncena rat\n\nHB Ratnam ea a SO EN\n\n356 Section 4 Graphics\n\nACAARRAATARRN SRNR\n\nPLP and cPLP are attractive visibility algorithms for several reasons:\n\n¢ PLP and cPLP are from-point algorithms, and they make no assumption about\nthe model. In contrast, some from-region algorithms assume the model consists\nof axis-aligned rooms and portals [Teller91, Funkhouser93], which might be a\nsignificant restriction.\n\n¢ PLP and cPLP require little preprocessing. For most heuristics, the precomputa-\ntion consists of creating the model hierarchy and computing simple summary sta-\ntistics per node, such as the total number of primitives. This can be done quickly,\neven for a large model. On the other hand, other techniques [Teller91, Hong97,\nZhang97] can require preprocessing times on the order of hours or days, even for\nrelatively small models.\n\n¢ Although occlusion culling algorithms such as PLP avoid rendering unseen\ngeometry, they might still render small primitives that have little effect on the\nfinal image. As shown by [El-Sana01], PLP can be easily integrated with level-of-\ndetail management.\n\n¢ PLP is suitable for time-critical rendering. Even if we use the lowest levels of\ndetail, the number of visible primitives in a given frame might overwhelm a low-\nend graphics card. The PLP budget gives the user a convenient way to balance\nboth accuracy and speed. The impact of slightly incorrect images on the user’s\nperception of the walkthrough is often far less than the impact of low frame rates\n{Funkhouser96].\n\nPLP is most useful when higher frame rates are more important than absolute\naccuracy—for example, when the user is moving fast to get to a certain point. On the\nother hand, cPLP is necessary when artifacts are not acceptable, such as when the user\nhas reached his target and is closely examining its details. Ideally, an application\nshould allow the user to switch back and forth between PLP and cPLP on the fly.\n\nUNC power-plant model on a Pentium III, 733-MHz computer with a Nvidia\nGeForce2 graphics card. We collected statistics for both PLP and cPLP using a 500-\nframe path. Figure 4.4.1 shows a typical frame of this path using a budget of 140,000\ntriangles per frame.\n\nFor PLP, the average frame rate was 10.1 Hz, with 75% of the tests having a\nframe rate above 9.3 Hz. For cPLP, the average frame rate was 2.1 Hz, with 75% of\nthe tests having a frame rate above 1.5 Hz. Although the rates for cPLP are lower than\nthe rates for PLP, the image is guaranteed to be 100% correct. We measured the accu-\nracy of PLP by counting the number of incorrect pixels in the images it generated ver-\nsus the correct images generated. The average accuracy for PLP was 96.3%; and for\n75% of the test, the accuracy was above 94.9%.\n\n4.4 Fast and Simple Occlusion Culling 357\n\nFIGURE 4.4.1 Using the prioritized-layered projection algorithm (PLP) to walk through\nthe 13-million triangle UNC power plant model. On a 733-MHz Pentium IIT\ncomputer with Nvidia GeForce2 graphics, PLP achieves an average frame rate of 10.1\nHz and an average accuracy of 96.3%.\n\nBecause of the layered traversal of the model hierarchy, the wrong pixels tend to\nbe at regions far from the eye-point. Sometimes the artifacts are noticeable, but they\nare usually tolerable and have little impact on the user's experience. Recall that we\nachieved this level of accuracy with the embarrassingly simple heuristic of traversing\nthe model hierarchy one layer at a time. We believe this accuracy can be even better\nwith more-sophisticated heuristics.\n\nConclusion\n\nPLP and cPLP are practical solutions to the ubiquitous visibility problem. PLP allows\nthe user to trade off accuracy for speed. With PLP there is no guarantee of image\nquality; however, in practice, it is good enough to give the user a sense of smooth nav-\nigation. Whenever 100% accuracy is critical, the program could switch to cPLP and\nstill be able to walk through the model at slower frame rates.",
      "page_number": 337,
      "chapter_number": 35,
      "summary": "Although the method described here works for any basis matrix, for the purposes of\nthis gem, we will limit ourselves to discussion of bicubic Bézier patches (referred to\nhereafter simply as “patches”) Key topics include normals, normalized, and normalize.",
      "keywords": [
        "PLP",
        "control points",
        "normal",
        "vertex",
        "Fast Patch Normals",
        "control",
        "algorithms",
        "occlusion culling algorithms",
        "Patch",
        "eacnaeeneoReR ENERO Conclusion",
        "patch vertex normal",
        "primitives",
        "culling algorithms",
        "vertex normal",
        "cPLP"
      ],
      "concepts": [
        "normals",
        "normalized",
        "normalize",
        "algorithms",
        "graphics",
        "points",
        "patch",
        "patches",
        "visible",
        "visibility"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 8",
          "chapter": 5,
          "title": "Segment 5 (pages 41-49)",
          "relevance_score": 0.54,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 1",
          "chapter": 38,
          "title": "Segment 38 (pages 363-370)",
          "relevance_score": 0.44,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 1",
          "chapter": 43,
          "title": "Segment 43 (pages 413-421)",
          "relevance_score": 0.44,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 1",
          "chapter": 37,
          "title": "Segment 37 (pages 352-362)",
          "relevance_score": 0.41,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 7",
          "chapter": 45,
          "title": "Segment 45 (pages 429-442)",
          "relevance_score": 0.39,
          "method": "api"
        }
      ]
    },
    {
      "number": 36,
      "title": "Segment 36 (pages 347-355)",
      "start_page": 347,
      "end_page": 355,
      "detection_method": "topic_boundary",
      "content": "358\n\nReferences\n\nSection 4 Graphics\n\nThere are several ways to improve upon what we have presented in this gem.\nFirst, we have presented only one simple heuristic for estimating the visibility of a\nnode. More sophisticated heuristics exist [El-Sana01], and there is still room for\nimprovement. Second, these algorithms could be combined with level-of-detail man-\nagement [El-Sana01]. Finally, these algorithms could be used to drive caching\nschemes to handle models that are larger than the available main memory.\n\nRRO RUA BRIE RASTA\n\n[Clark76] Clark, James H., “Hierarchical Geometric Models for Visible Surface\nAlgorithms,” Communications of the ACM, 19(10): 547-554, October 1976.\n[Cohen-Or01] Cohen-Or, Daniel, Yiorgos Chrysanthou, Cldudio T. Silva, and Frédo\nDurand, “A Survey of Visibility for Walkthrough Applications,” ZEEE Transac-\n\ntions on Visualization and Computer Graphics.\n\n[Dobkin97] Dobkin, David and Seth Teller, Handbook of Discrete and Computational\nGeometry, Computer Graphics Chapter, CRC Press, 1997.\n\n[Durand99] Durand, Frédo, “3D Visibility: Analytical Study and Applications,”\nPh.D. Thesis, Université Joseph Fourier, Grenoble, France, 1999.\n\n[El-Sana01] El-Sana, Jihad, Neta Sokolovsky, and Cldudio T. Silva, “Integrating\nOcclusion Culling with View-Dependent Rendering,” in Proceedings of IEEE\nVisualization, 2001: 371-378.\n\n[Foley90] Foley, James D., Andries van Dam, Steven K. Feiner, and John FE. Hughes,\nComputer Graphics: Principles and Practice, Second Edition, Addison Wesley,\n1990.\n\n[Funkhouser93] Funkhouser, Thomas A. and Carlo H. Séquin, “Adaptive Display\nAlgorithm for Interactive Frame Rates during Visualization of Complex Virtual\nEnvironments,” Computer Graphics Proceedings, SIGGRAPH 1993: pp.\n247-254.\n\n[Funkhouser96] Funkhouser, Thomas A., “Database Management for Interactive\nDisplay of Large Architectural Models,” Proceedings of Graphics Interface ‘96:\npp. 1-8.\n\n[Hong97] Hong, Lichan, et al., “Virtual Voyage: Interactive Navigation in the\nHuman Colon,” Computer Graphics Proceedings, SIGGRAPH 1997: pp.\n27-34.\n\n[Klosowski00] Klosowski, James T. and Claudio T. Silva, “The Prioritized-Layered\nProjection Algorithm for Visible Set Estimation,” in JEEE Transactions on Visual-\nization and Computer Graphics, April-June 2000, 6(2):108—-123.\n\n[Klosowski01] Klosowski, James T. and Cldudio T. Silva, “Efficient Conservative Vis-\nibility Culling Using the Prioritized-Layered Projection Algorithm,” in JEEE\nTransactions on Visualization and Computer Graphics, October-December 2001,\n7(4):365-379.\n\n[Teller91] Teller, Seth and Carlo H. Séquin, “Visibility Preprocessing for Interactive\nWalkthroughs,” Computer Graphics Proceedings, SIGGRAPH 1991: pp. 61-69.\n\n[Walkthru01] The Walkthru Project at UNC Chapel Hill, “Power Plant Model,”\navailable online at http://www.cs.unc.edu/~geom/Powerplant/.\n\n[Zhang97] Zhang, Hansong, Dinesh Manocha, Thomas Hudson, and Kenneth E.\nHoff III, “Visibility Culling Using Hierarchical Occlusion Maps,” Computer\nGraphics Proceedings, SIGGRAPH 1997: pp. 77-88.\n\n4.5\n\nTriangle Strips _\n\nTriangle Strip Creation,\nOptimizations, and Rendering\n\nCarl S. Marshall, Intel Labs\nCarl.S.Marshall@intel.com\n\nn the current age of high-performance consoles, triangle strips have moved to the\n\nforefront of primitive selection when representing and rendering geometry. This\ngem focuses on how to generate triangle strips from arbitrary 3D polygonal models.\nWe will describe and provide source code for developing long triangle strips. After\ndescribing the triangle strip algorithm, we will explain the benefits of triangle strips,\nthe possible pitfalls encountered when creating them, and how to submit them to the\ngraphics API. In addition, several other triangle strip creation algorithms will be\nreviewed and critiqued.\n\nA triangle strip (tri-strip) is a series of connected triangles. The connection of the tri-\nangles allows vertex caching so that graphics cards can reuse the shared edges between\nthe triangles. Figure 4.5.1 shows a simple triangle strip with shared edges V,V3 and\nV3V4. In order for a triangle to be a part of a triangle strip, the triangle must contain\nthe same smoothing group and material group as the other triangles in the tri-strip. A\nsmoothing group is a group of triangles that all have one normal per vertex, and\na material group is a group of triangles that all have the same lighting and texture\nproperties.\n\nBackground\n\nThe technique of using triangle strips has been around for a long time. Before that,\nthe general format for submitting triangles to the API was to explicitly send each ver-\ntex’s position, normal, and color. But because fewer vertices need to be sent for trian-\ngle strips, this gives them a tremendous advantage over a pure triangle graphics API\ncall. Today, vertex indexing has virtually displaced the earlier process and now is the\nprimary method for submitting polygons to a graphics card. [Marselas00] suggests\nthat by using triangle strips and vertex indexing, it is possible to bring the vertex-to-\n\n359\n\n360 Section 4 Graphics\n\nV4\n\n(A)\n\nVy V3 V5\n\nVo Counter-Clockwise V4\n\n(B)\n\nVy Clockwise V3 Clockwise Vs\n\nFIGURE 4.5.1 (A).A simple triangle strip with shared edges V,V; and V3V,. (B) The\nordering of the triangles in the tri-strip alternate between clockwise and counterclockwise\nordering.\n\ntriangle ratio close to 1:1 for certain meshes. This gives tri-strips the advantage of data\nreduction.\n\nTriangle strip creation has four goals:\n\n1. To minimize the number of tri-strips\n\n2. To minimize the number of repeated vertices\n3. To minimize the number of isolated triangles\n4, To maximize vertex caching\n\n4.5 Triangle Strip Creation, Optimizations, and Rendering 361\n\nThese goals often conflict with one another. For example, it is difficult to gener-\nate extremely long tri-strips or cache friendly tri-strips without repeating many ver-\ntices. It is also better to have several isolated triangles (tri-strips of three vertices) than\na few tri-strips of four vertices because you can batch the isolated triangles into an\nindexed vertex list.\n\nBenefits\n\nUsing triangle strips instead of independent triangles will allow for a reduced submis-\nsion of vertices or vertex indices. Depending on how the triangle strips are submitted\nto the graphics hardware, you can receive substantial savings in vertex data, transfor-\nmation, and lighting. Triangle strips can also give you an advantage with vertex\ncaching on the graphics card.\n\nTriangle Strip Creatio\n\nThere are several triangle strip creation algorithms in the research space, but each\nalgorithm has its advantages and disadvantages, due to the fact that finding the opti-\nmal tri-strips is an NP-complete problem. [Evans96a] uses a quad-based mesh to\noptimize tri-strips within patches, whereas [Hoppe99] uses a cache-friendly triangle\nstrip approach. The approach we chose is to optimize the length of the triangle strip\nto overcome the graphics API overhead.\n\nSince it is impossible to have the perfect triangle stripping of a mesh for any situ-\nation, we have:to create algorithms that will find the most optimal tri-strips for the\nspecific implementation. The algorithm that we use aggressively generates tri-strips\nfrom any arbitrary 3D polygonal model. This tri-strip generation algorithm can be\nplaced into any of your favorite 3D authoring tools, or it can be run as a stand-alone\ntool. The goal is to generate long tri-strips and then write them out into a format that\nis easily rendered. Color Plate 5 shows a sample image of two models after the trian-\ngle strip algorithm has been run on the mesh.\n\nDefinitions\n\nBefore we go into our creation algorithm, it will help to define a few terms. An active\nedge is the edge of a triangle within the strip onto which new triangles can be added.\nThe active edge is between the second and third vertices of the last triangle to be\nadded to the triangle strip. The bold edge in Figure 4.5.2a shows the active edge, DE,\nin which the triangle with vertex F can be added. A swap is used when the active edge\ndoes not align with the neighboring triangle to be added to the strip. Figure 4.5.2b\nshows a case in which the active edge is DE, but the next triangle to be added is on\nedge CE. To add the new triangle, vertex C will have to be repeated and then swapped\nwith vertex E. This will keep the proper clockwise, counterclockwise ordering. The\nlast term we will define is called a flip, which is when two duplicate vertices have to be\nadded and swapped to add a new vertex, as shown in Figure 4.5.2c.\n\n362 Section 4 Graphics\n\n(A)\n\n(B)\n\n(C) ‘S\n\nA\n\nFIGURE 4.5.2 The various stages in which triangles can be added to a triangle strip.\n\n(A) A tri-strip with a vertex index ordering of ABCDE and an active edge DE. Since the\nactive edge borders the new triangle, F can just be added to the end of the tri-strip. The\nnew tri-strip is ABCDEE (B) Tri-strip ABCDE with active edge DE. To include vertex\nE Cwill have to be duplicated and then swapped with E, since the active edge does not\nborder the new triangle to be added. The new tri-strip is ABCDCEE (C) A case where\nreordering the first face of a triangle strip to match the second face is crucial to minimize\nrepeated vertices. If the triangle strip started as CAB, then B and C would have to be\nrepeated to add vertex D. CABBCD is the new triangle strip. If the active edge is facing\naway from the second triangle, then two vertices have to be repeated.\n\n4.5 Triangle Strip Creation, Optimizations, and Rendering 363\n\nThe preprocess stage is used to create metrics for generating quality triangle strips.\n\n1. Find a triangle with the smallest area, which we will call the origin triangle.\nTo avoid poor triangle stripping, you might want to get the 10 smallest-area\ntriangles in the mesh and select between those triangles for the origin\ntriangle.\n\n2. Select a vertex of the origin triangle or create its centroid, which will be the\nstarting point for the triangle strip algorithm.\n\n3. Create a centroid for each triangle. This can be easily done by averaging the\nthree vertices of each triangle (see Equation 4.5.1). C is the centroid posi-\ntion, and V,, V;, and V3 are the vertex positions of the triangle.\n\n4, For each triangle, calculate and store the Euclidean distance between the\nstarting vertex and the centroid.\n\nC=(V,+V,+V,)/3.0 (4.5.1)\n\nCreation Algorithm\n\nOnce we have the preprocess stage complete, we can start generating triangle strips.\nEach time a triangle of the mesh is added to a tri-strip, mark the triangle invalid.\n\n1. Select a valid triangle. This triangle will be the first triangle of the triangle\nstrip.\n\n2. If the triangle has neighbors, select the triangle with the smallest distance\nvalue, and make it the current triangle. Otherwise, end the triangle strip\nand go to Step 6.\n\n3. Reorient the first triangle so that its active edge matches the second triangle.\nThe edge between the second and third vertices should match the neigh-\nboring triangle.\n\n4. Get the neighbor of the current triangle by finding the triangle with the\nsmallest distance value, which was stored in preprocess Step 4. If the trian-\ngle does not align with the active edge, then a vertex will have to be repeated\nwith a swap in order to continue creating the triangle strip (see Figure\n4.5.2c).\n\n. Go to Step 2.\n\n6. Check to see if any remaining triangles are not included in a tri-strip. If so,\n\ngo to Step 1.\n\nWr\n\nThe high-level pseudo-code for running the tri-strip algorithm is show in Listing\n4.5.1.\n\n364 Section 4 Graphics\n\nLISTING 4.5.1 High-level pseudo-code for running the tri-strip algorithm.\n\nvoid main( )\n\n{\nMesh *pMesh;\n\nLoadMesh(pMesh); // Load 3D polygonal mesh\noriginTriangle = FindSmallestAreaTriangle() ;\nCalculateCentroidForEachTriangle() ;\n\n// Get Euclidean distance from centroid of\n// the origin triangle to the current\n\n// triangle origin\nCalculateDistanceFromToEachTriangle(\nOriginTriangle) ;\n\n// Generate the triangle strips\nTriStripGeneration(pMesh) ;\n\n// Run a second pass filter to see if any of\n\n// the previous triangle strips can be connected\nConnectTriangleStrips() ;\n\nConvertTriStrips(); //Use custom data structure\n\n}\n\nOnce the creation algorithm is finished, the output will be N triangle strips. Each\nof these triangle strips will belong in one smoothing group and have the same mater-\nial ID. Once the tri-strips are stored in memory, you can customize the data into any\nformat that is required by your game I/O.\n\nConnecting Triangle Strips\n\nAs a second pass, the triangle strips can be analyzed to see if there are any points at\nwhich they can be connected to each other. The analysis starts by finding all of the\nstarting edges and ending edges of each triangle strip along with the face index\nattached to each edge. Then, the starting and ending edges are compared with those\nof all of the other triangle strips to see if a match occurs. Once a match is found, the\ntwo triangle strips are analyzed to see which stage they fall into (from Figure 4.5.2).\nMost cases will require some number of vertex repetitions to merge the triangle strips.\nOne of the simpler cases is when an isolated triangle is matched with another triangle\nstrip. In most cases, the isolated triangle’s vertices can be reordered to conform to the\nmatching triangle strip.\n\nOptimizations\n\nseat RR NRE RS\n\nSince the goal of developing triangle strips is to increase performance, optimizations\nare a key part of any triangle strip generation algorithm. Optimizations can be placed\ninto several areas of the triangle strip development process: preprocess, generation,\nand runtime.\n\n4.5 Triangle Strip Creation, Optimizations, and Rendering 365\n\nPreprocess:\n\n* Create meshes with only a few smoothing groups (more than one normal per\nvertex).\n\n* Limit the number of material groups per model.\n\n* Optimize the model so that polygonal faces do not swap back and forth between\nmaterial groups or smoothing groups. This will limit the length of a triangle strip.\n\n¢ Sort triangle strips via material groups before submitting them to the graphics\ncard.\n\n¢ Eliminate all dummy faces. A dummy face is when two or more of the three ver-\ntex locations are equivalent. This can cause the triangle strip to flip inside out and\npossibly get culled when rendered.\n\nGeneration:\n\n* Batch isolated triangles into a single, indexed buffer.\n\n¢ Try to merge triangle strips that have neighboring beginning or ending triangles,\nwhere possible.\n\n¢ Know the cache size of the hardware, and optimize as appropriate.\n\nRuntime:\n\n© Use an indexed array API call instead of a pure ordered vertex submission call.\n* Reduce state swapping and dynamic texture coordinate changes.\n\nRendering\n\nMost graphics APIs have support for rendering triangle strips. There are usually a cou-\nple of formats you can choose from when submitting triangle strips to the graphics\ncard. One format requires sending the vertex data for each vertex in the triangle strip.\nThis is very expensive, since many vertices will be duplicated due to shared edges by\nmultiple triangle strips. Another format requires submitting the triangle strips via an\nindexed format. An indexed format is one in which you submit a vertex pool, and the\ntriangle strip vertex indices into the vertex pool. One issue with most graphics APIs is\nthat they only allow one triangle strip submission per API call. In some APIs, you can\nsubmit dummy vertices to allow the submission of multiple triangle strips. [Nei-\nder99] and [Microsoft00] both list the API submission calls for triangle strips.\nOpenGL uses the primitive type GL_TRIANGLE_STRIP, and Microsoft Direct3D uses\nD3DPT_TRIANGLESTRIP.\n\nCache-Friendly Triangle Strips\n\nAnother triangle strip creation algorithm creates triangle strips that are cache friendly\nby minimizing vertex cache misses [Hoppe99]. [Nvidia00] uses a vertex-caching\nscheme that will run as a post-process on previously created triangle strips in order to\noptimize cache usage. The advantage to this approach is that you can optimize trian-\n\n366 Section 4 Graphics\n\ngle strips to a specific graphics card. Of course, the drawback with this routine is that\nthe optimizations can hinder you if the same content is used on another graphics card\nwith a different cache size.\n\nAs soon as a vertex or face is removed from the mesh, it can have a dramatic effect on\nthe triangle strips that were created at the higher resolution by breaking them up and\ncreating invalid faces. There are a couple of ways to solve this problem. The first\nwould be to create a set of triangle strips for every resolution of the model. This is\nextremely impractical and would balloon your memory usage. The second choice\nwould be to create the triangle strips on the fly and store them in memory until the\nresolution changes. We chose the second method, only allowing triangles to be added\nto a triangle strip that neighbored its current active edge or required a swap. If no\nneighbors existed, then the triangle strip would be ended. The key here is to optimize\nthe data structures for fast neighbor lookup and traversal. The advantage is the ability\nto use triangle strips with dynamic geometry; however, this will require additional\noverhead in memory.\n\nyou consider rendering primitives for your geometry, triangle strips can help provide a\nbeneficial speed-up compared with submitting simple triangle lists. We encourage you\nto test your geometry with triangle strips and compare the differences for yourself.\n\n[Evans96a] Evans, Francine, Steven Skiena, and Amitabh Varshney, “Optimizing Tri-\nangle Strips for Fast Rendering,” Visualization 96 Proceedings, IEEE, 1996: pp.\n319-326\n\n[Evans96b] Evans, Francine, Steven Skiena, and Amitabh Varshney, “Completing\nSequential Triangulations Is Hard,” Technical Report, Department of Computer\nScience, State University of New York at Stony Brook, 1996.\n\n[Hoppe99] Hoppe, Hughes, “Optimization of Mesh Locality for Transparent Vertex\nCaching,” Computer Graphics Proceedings, SIGGRAPH 1999: pp. 269-276.\n\n[Isenburg00] Isenburg, Martin, “Triangle Strip Compression,” Graphics Interface, pp.\n197-204, 2000.\n\n[Marselas00] Marselas, Herb, “Optimizing Vertex Submission for OpenGL,” Game\nProgramming Gems, Charles River Media, Inc., 2000.\n\n[Microsoft00] Microsoft DirectX 8.0 Software Development Kit, available online at\nhttp://www.msdn.microsoft.com/downloads, 2000.\n\n[Neider99] Neider, Jackie, et al., OpenGL Programming Guide, Version 1.2, Addison\nWesley, 1999.\n\n[Nvidia00] Nvidia NvTriStrip v1.1., available online at http://developer.nvidia.com/\nview.asp*lO=nvtristrip_v1_1, 2000.",
      "page_number": 347,
      "chapter_number": 36,
      "summary": "This chapter covers segment 36 (pages 347-355). Key topics include triangle, vertex, and strips.",
      "keywords": [
        "Triangle Strips",
        "Triangle",
        "Triangle Strip Creation",
        "Computer Graphics Proceedings",
        "Strips",
        "Computer Graphics",
        "triangle strip algorithm",
        "Graphics",
        "Strip Creation",
        "Graphics Proceedings",
        "vertex",
        "triangle strip vertex",
        "rendering triangle strips",
        "triangle graphics API",
        "simple triangle strip"
      ],
      "concepts": [
        "triangle",
        "vertex",
        "strips",
        "stripping",
        "graphics",
        "rendering",
        "optimizations",
        "optimize",
        "optimal",
        "optimizing"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 2",
          "chapter": 43,
          "title": "Segment 43 (pages 424-431)",
          "relevance_score": 0.73,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 7",
          "chapter": 44,
          "title": "Segment 44 (pages 413-428)",
          "relevance_score": 0.7,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 2",
          "chapter": 36,
          "title": "Segment 36 (pages 360-367)",
          "relevance_score": 0.68,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 2",
          "chapter": 48,
          "title": "Segment 48 (pages 469-476)",
          "relevance_score": 0.65,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 53,
          "title": "Segment 53 (pages 511-519)",
          "relevance_score": 0.64,
          "method": "api"
        }
      ]
    },
    {
      "number": 37,
      "title": "Segment 37 (pages 356-366)",
      "start_page": 356,
      "end_page": 366,
      "detection_method": "topic_boundary",
      "content": "4.6\n\nComputing Optimized\nShadow Volumes for\nComplex Data Sets\n\nAlex Viachos and Drew Card,\n\nATI Research\nAlex@Viachos.com and DCard@ati.com\n\nA s graphics hardware performance increases, shadow volumes become a more rel-\nevant topic for the game industry. In this gem, we describe a method for com-\nputing the exact front cap geometry visible from a given static light source. This is the\nexact geometry that is visible from the light’s point of view, and it is useful for calcu-\nlating shadow volumes. Previous work has been done on this topic; however, most\nmethods suffer from either infinite recursion (with complex polygonal models) or fail\nto solve for cyclically overlapping polygons. The method presented here also works\nfor scenes that have intersecting polygons.\n\nPrevious Work\n\nThe Weiler-Atherton algorithm {Weiler77] provides an interesting method for com-\nputing front cap geometry. The advantage of its method is that it does not require a\nperfectly sorted list of polygons with respect to the light source. Additionally, the\nWeiler-Atherton algorithm solves for cyclically overlapping polygons. However, when\nusing even a slightly complex scene, this method lends itself to infinite recursion due\nto precision errors when using 64-bit, floating-point variables. The method presented.\nin this gem borrows some of the basic methods from the Weiler-Atherton algorithm,\nbut it approaches the problem from a different direction.\n\nsource are somewhat complex. Starting with all the front-facing polygons that lie in\nthe light frustum, roughly sort them back-to-front. A simple quick-sort based on each\npolygon’s closest vertex will suffice. At this point, you want to assign each polygon a\nunique ID for later reference. You might also want to store these polygons into bins to\n\n367\n\nSection 4 Graphics\n\npe sree 22 A A NT HHT TH HHH na eR aE EEN\n\nenable quicker searching. We call these polygons the “input array.” We also need an\n“output array,” which will be initialized as empty.\n\nNow we perform a series of operations on each of the polygons in the input array.\nFirst, create a beam (a small frustum) from the light source and the polygon. Three of\nthe four clip planes that make up the beam are simply the planes defined by the light\nposition and each edge of the polygon. The fourth clip plane is the plane of the poly-\ngon itself. All of the geometry that we have stored so far in our output array that falls\ninside the beam’s frustum is discarded. The remaining fragments are stored back into\nthe output array (see Figure 4.6.1).\n\nSince it is sometimes impossible to perfectly sort polygons (as with cyclically\noverlapping polygons), there may be polygons remaining in the output array that\nobscure the currently selected polygon from the light’s viewpoint. To account for this\ncase, we recurse one level deep for each of the obscuring polygons. A temporary array\nis created with just the current input polygon, and it is clipped using the beams of\neach obscuring polygon. The remaining polygons (in the temporary array) are copied\nto the output array. If there are no obscuring polygons, we simply add the input poly-\ngon to the output array (see Figure 4.6.2).\n\nAfter processing each input polygon, we need to run an optimization algorithm\non the output polygon array to reduce the amount of polygon splitting. This algo-\nrithm is explained in the following section. Note that this step needs to occur at each\niteration of the main loop.\n\nAfter looping through all the input polygons, solve for T-junctions in the final out-\nput array to prevent rasterization artifacts. At this point, the clean front caps have been\ncreated, and the shadow volume can now be easily generated. Since the front caps do\nnot overlap from the light’s point of view, a copy of the final front cap geometry can be\nprojected onto the far plane of a spotlight frustum to generate the back cap. Point\nlights can be split into eight subregions to facilitate the creation of the volume.\n\nFIGURE 4.6.1 Ax illustration of beam construction and output polygon culling. The\ndark gray polygon is the currently selected one, and the white polygons are in the output\narray. A beam is created from the light point (in this case the eye-point) and the selected\npolygon. The output polygons are then clipped against this beam.\n\n4.6 Computing Optimized Shadow Volumes for Complex Data Sets 369\n\nOriginal if Recursive xt Unobstructed\n\\ Front Cap\n\nBeam \\ Beam\n1 \\\n- i\nLe 1 \\\n- isti Pe G6,\nNia Vw, s me\nN \\ ‘\\ a a\n\\ 1 \\\n\\ .\nPolygon ¢\\ \\ Recursive\n\\ | ‘> Bean\n‘ \\ Frusum\nBeam ‘\\\n\nFrustum\n\n(B) (C)\n\nFIGURE 4.6.2 Dealing with obstructing output polygons. Shown from a top\n(orthographic) view. (A) The light beam is illustrated by the dotted lines surrounding the\n(black) beam polygon. (B) The light-gray polygon, which is in the output array, is clipped\nby the original beam frustum from (A). Since a portion of the clipped polygon obstructs\nthe currently selected (black) polygon, a recursive step is taken to create a beam frustum\nwith the clipped portion, and the original (black) polygon is clipped against it. (C) The\nresult is the exact front cap geometry.\n\nOptimization Al orithm —\n\nAs previously mentioned, an optimization algorithm is required in order to avoid\nnumerical inaccuracies and improve performance. In many cases, the repetitive clip-\nping to beam frustums can create excessive numbers of sliver polygons. To help avoid\nthis, all subpolygons created from an original input polygon are collapsed into the\nsmallest number of polygons possible at each pass through the loop.\n\nThe input stream should also be optimized before the main loop. This will make\nit unnecessary to optimize across the original polygon boundaries at every iteration.\nOptimizing in groups based on the original input polygons does everything that is\nrequired.\n\nThere are two algorithms that can be utilized to optimize the polygonal mesh.\nThese algorithms, which we will outline here, provide a method for determining\nwhich vertex should be removed or which edge collapsed. The remaining n-gon will\nthen need to be retessellated into triangles using a robust tessellation algorithm such\n\nas that in [deBerg00].\n\nVertex Removal\n\nAn example of removing a vertex is illustrated in Figure 4.6.3. The first step is to build\na mesh from all of the triangles that correspond to an original input triangle (by the\ntriangle ID). Next, build an edge table for all of the edges in this mesh. For each ver-\n\n370 a 7 Section 4 Graphics\n\ntarget\nvertex\n\nFIGURE 4.6.3 Removing a vertex.\n\ntex in the mesh, choose a starting triangle that contains that vertex, and use the edge\ntable to walk clockwise around the vertex to neighboring triangles that also contain\nthat vertex. Continue to walk around the vertex until no more triangles exist in the\nchain or until the original triangle is reached. If the walk around the vertex is success-\nful (i.e., a full walk back to the original triangle is completed), then the vertex can be\n\nremoved.\n\nEdge Collapse\n\nAn example of collapsing an edge is illustrated in Figure 4.6.4. Similar to the vertex-\nremoval algorithm, the first step is to build a mesh from all of the triangles that corre-\nspond to an original input triangle. Now, build an edge table for all of the edges in the\nmesh. For each vertex in the mesh, choose a starting triangle, which contains the ver-\ntex, and use the edge table to walk clockwise around the vertex to neighboring trian-\ngles that also contain the vertex. Compare the current triangle’s leading edge with the\noriginal edge for collinearity, using a cylinder test (or sum up the angles of the trian-\ngles and test for equality with 180°). If the two edges are found to be collinear, col-\nlapse the edge by combining the two adjacent edges into a single edge and removing\nthe shared vertex.\n\nNote that keeping track of the original edges of the input triangles might also\nreduce the computation time for the edge collapse. This method allows for the com-\nparison of the edge IDs while also reducing possible error due to floating-point\ninaccuracies.\n\n4.6 Computing Optimized Shadow Volumes for Complex Data Sets 371\n\nBefore\n\nshared vertex\n\nFIGURE 4.6.4 Collapsing an edge by removing a shared vertex.\n\nFor an example of precomputed shadow volumes combined with other rendering\ntechniques in real-time, see Color Plate 6.\n\ntion,” Computational Geometry Algorithms and Applications, Second Edition,\n2000: pp. 45-61.\n\n[Weiler77] Weiler, K. and P. Atherton, “Hidden Surface Removal Using Polygon Area\nSorting,” Computer Graphics, SIGGRAPH, 1977: Vol. 11, pp. 214-222.\n\n4.7\n\nSubdivision Surfaces for\nCharacter Animation\n\nWilliam Leeson, Trinity College, Dublin\n\nwleeson@indigo.ie\n\nonstructing surfaces through subdivision has become popular with high-end ren-\n\ndering packages over the past few years. This is due in no small part to the stun-\nning visuals produced by companies such as Pixar [DeRose98]. These schemes solve\nmany of the problems associated with other curved-surface techniques, such as\nNURBS surfaces. Since they behave in a way similar to polygonal meshes, there are\nfewer restrictions. Character skins can be used almost directly with some subdivision\nschemes. Others require some modification in order to get a good representation of\nthe original mesh.\n\nThis gem introduces subdivision surfaces as a means of improving the appearance\nof game characters. First, we will present the different schemes available, focusing on\ntwo implementations of subdivision surfaces. Then, we will explore a number of opti-\nmization methods based on culling and preprocessing.\n\nSubdivision Schemes\n\n372\n\nThere are two main types of subdivision surfaces [Kobbelt98], namely approximating\nand interpolating schemes. The three most important properties of subdivision sur-\nfaces, as relates to this gem, are:\n\n° Efficiency\n¢ Affine invariance (i.e., transformation of the control points transforms the surface)\n* Continuity (i.e., they can produce smooth surfaces)\n\nSubdivision schemes use a mask to define a set of vertices and corresponding\nweights. There are two types of masks for each scheme: the odd mask and the even\nmask. Odd masks are used to produce new vertices, while even masks are used to\nrefine old vertices for the newly produced mesh. These two types can be further\ndivided into edge, crease, and normal masks. Additionally, in order to be able to rep-\nresent sharp features, special crease masks must be created. For triangular schemes,\nvertices with a valency (number of connected vertices) of six are known as ordinary\nvertices. The others are called extraordinary. The masks are applied to each vertex in\n\n4.7 Subdivision Surfaces for Character Animation 373\n\nFIGURE 4.7.2 Butterfly interpolating subdivision surface for four iterations.\n\nthe mesh to produce a new mesh. After successive applications of the mask, the mesh\nconverges to a surface (see Figures 4.7.1 and 4.7.2). The masks can also be applied to\nthe texture coordinates in exactly the same manner. This generates the texture coordi-\nnates for each vertex. Generally, approximating schemes are faster because they have\nfewer constraints imposed on them, as they do not have to interpolate the control\npoints. However, when dealing with edges and noncontinuous surfaces, special masks\n(which take these circumstances into account) must be applied.\n\nApproximating Schemes—Loop Subdivision\n\nLoop subdivision [Loop87] is perhaps the simplest subdivision scheme. It has a very\nsmall support area. The mask for this scheme is given by Equation 4.7.1 (see Figure\n\n4.7.3).\n1 3\ng (* + v») + a? + 7) even\n»y Qu, + (1 = nQ)y; odd\njr\nwhere\n3n\n2 — n>3\na=+)/2- 3d oo 2% orQ=48\nn{8 \\8 4 n 3\n— rza= 3\n16\n\n374\n\nSection 4 Graphics\n\nvy\n\nv\nv4 . y v2 ‘\nv3\n\nFIGURE 4.7.3 Loop subdivision mask.\n\nA convenient feature of the Loop scheme is that the tangent vectors can be com-\nputed for each point using\n\n—1 °\n\nx 2ni\n= by cos — v;\n5 n\n7=0\n\n(4.7.2)\n\n-] .\na,\n= by sin — »,\n#=0 n\nwhere »; is one of the 7 vertices that is connected to the vertex we are trying to find a\nnormal for. Note that different masks are needed for computing the tangents at a\nboundary edge [DeRose98]. Although sin and cos are expensive to compute,\noptimizations (which will be described later) can be used to remove them from the\ncomputation.\n\nInterpolating Schemes—Modified Butterfly\n\nThe butterfly scheme got its name from the distinctive shape of its mask, which\nresembles that of a butterfly. The original butterfly [Dyn90] method is probably the\nmost common interpolating scheme used, but it does not guarantee a continuous sur-\nface for arbitrary meshes. For a small amount of extra work, a modified scheme\n[Zorin96] can be used. Fortunately, it has the same small support area as the original\nscheme. Like most interpolating schemes, there is no even mask. The original vertices\n\n4.7 Subdivision Surfaces for Character Animation\n\n05 % v7\n\nFIGURE 4.7.4 Butterfly subdivision mask.\n\nare reused, since the surface must pass through them. An example mask is shown in\n\nFigure 4.7.4.\n\nv; even\n\n(4.7.3)\n\nv,=4 1 1 1\n\n-=( + vu, + U6 + v3) + gl + v,) +5 (% + v5) odd\n\nUnlike the Loop method, computing the tangent vectors can be quite involved. It\n\nis probably quicker to compute them from the faces, so that information will not be\ncovered in this gem.\n\nHierarchical Half-Edge Mesh\n\nOne of the most difficult aspects of using a subdivision scheme is creating a suitable\ndata structure [Weiler85] for traversing the nodes so that the subdivision rules can be\napplied. A half-edge data structure can be created for each level of subdivision. The\n\n376\n\nSection 4 Graphics\n\nores ennui nO oer InegeAAeR NI: sAlaAnUEMESH IRR RUSSO necivemmuceeeenniiromaioninas\n\nhalf-edge data structure uses a vertex, an edge, and a face structure to make up the\n\nmesh:\n\nstruct vertex\n\n{\nedge *p_edge;\n\nstruct edge\n\n{\nedge *p_ pair;\nedge *p_next;\nedge *p_prev;\nface *p_face;\nvertex *p_ vertex;\n}3\nstruct face\n{\nedge *p_edge;\n}\n\n/*\n\n/*\n/*\n/*\n/*\n/*\n\n/*\n\nedge vertex starts */\n\nother half of edge */\n\nnext edge in face */\nprevious edge in face */\nface edge is part of */\nvertex that starts edge */\n\nan edge in the face */\n\nThis data structure is similar to a winged-edge data structure. A half edge is an\nedge that is split between two neighboring faces. Each edge points to its next and pre-\nvious edges. (Actually, the original half-edge data structure did not have a pointer to a\npreceeding edge, but it makes some queries easier.) It also references the face it is part\nof, as well as the vertex starting the edge (see the previous code). Each edge need only\npoint to one vertex. Each vertex points to the edge it starts, and each face points to\n\none of the edges that make up the face (see Figure 4.7.5).\n\nFIGURE 4.7.5 Half-edge mesh.\n\n4.7 Subdivision Surfaces for Character Animation\n\n377\nThis arrangement allows for easy querying of neighboring faces and connected ver-\ntices. For example, to determine all the vertices connected to a given vertex, simply go to\nthe half edge associated with that vertex. Then, move to that half edge’s pair edge—this\nhalf edge references the first connected vertex. If this is repeated until we return to the\ninitial edge, then all connected vertices will have been found (see Figure 4.7.6).\n\nKASS\nNg\n\nFIGURE 4.7.6 Connection traversal order for finding connected vertices to vp.\n\nEven if the half-edge data structure is not used directly within the sub-\ndivision computation, it is a fast and convenient way to determine the rele-\nvant indices for the masks. The half-edge data structure is also perfect for\nexamining other properties of the mesh, such as connectivity and error\ndetection (e.g., more than two faces sharing an edge). In order to store the\nhierarchical information, each face can also store pointers to its siblings.\nAlternatively, each sibling can be stored at an address in an array kn + 7+ 1,\nwhere 7 is the sibling's number 0...(4-1), is the parent’s offset, and & the\nnumber of siblings. An important aspect of this structure is that it cannot\nhave an edge shared between more than two faces without undergoing\nmodification. This can cause trouble if there is no checking done when a\nmesh is loaded (don’t say you weren't warned). In any event, the two\nschemes presented here do not have masks to cater for this situation.",
      "page_number": 356,
      "chapter_number": 37,
      "summary": "Previous Work\n\nThe Weiler-Atherton algorithm {Weiler77] provides an interesting method for com-\nputing front cap geometry Key topics include edge, polygonal, and polygons.",
      "keywords": [
        "edge",
        "vertex",
        "polygon",
        "Subdivision",
        "Subdivision Surfaces",
        "Original",
        "mesh",
        "output array",
        "beam",
        "array",
        "schemes",
        "Surfaces",
        "face",
        "data structure",
        "Shadow Volumes"
      ],
      "concepts": [
        "edge",
        "polygonal",
        "polygons",
        "vertex",
        "schemes",
        "figures",
        "subdivision",
        "surface",
        "method",
        "point"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 7",
          "chapter": 44,
          "title": "Segment 44 (pages 413-428)",
          "relevance_score": 0.56,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 1",
          "chapter": 45,
          "title": "Segment 45 (pages 431-441)",
          "relevance_score": 0.5,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 7",
          "chapter": 45,
          "title": "Segment 45 (pages 429-442)",
          "relevance_score": 0.5,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 1",
          "chapter": 42,
          "title": "Segment 42 (pages 404-412)",
          "relevance_score": 0.47,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 2",
          "chapter": 35,
          "title": "Segment 35 (pages 347-359)",
          "relevance_score": 0.46,
          "method": "api"
        }
      ]
    },
    {
      "number": 38,
      "title": "Segment 38 (pages 367-374)",
      "start_page": 367,
      "end_page": 374,
      "detection_method": "topic_boundary",
      "content": "378 Section 4 Graphics\n\nreso eaten OT EG eo teaetcecnenE H HEE OEE b li een rorteeacevannett\n\nWhen animating a character, a bone hierarchy is often needed. Implementing a bone\nhierarchy is a trivial task, so we won't go into much detail here. The bone hierarchy is\na simple transformation hierarchy where a series of transformations are applied to the\nnodes. As the hierarchy is descended, each node and its vertices are transformed by\nthe current transformation. Fortunately, when using subdivision surfaces for character\nanimation, we only need to transform the control points of the mesh to alter\nthe shape of the skin. This is advantageous, since fewer transformations will be per-\nformed.\n\nWeighted Vertex-Accumulation Buffer\n\nVertex weighting introduces complications to the task of transforming the vertices. To\nimplement skinning, a buffer is used to accumulate the resulting vertices. This is then\nused as the vertex buffer for the subdivision scheme. As the hierarchy is descended,\neach node is transformed by the current transformation matrix, multiplied by its\nweight, and then added to the accumulation buffer. With this method, the initial sub-\ndivision mesh is not altered by the skinning procedure. Now the subdivision mesh\ncan be altered at will, preventing the accumulation of floating-point errors. As an\nadded advantage, the subdivision surface and skinning procedures are now separated\nand will not interfere with each other, making the implementation easier.\n\nOptimizations\n\nWhen using many subdivision surfaces together, it is important to reduce the overall\nworkload this causes. We will describe four schemes that can be used to reduce the\npotential workload in two distinct places in the subdivision hierarchy.\n\nHierarchical Back-Face Culling\n\nThe technique of hierarchical back-face culling is based on the clustering idea of hier-\narchical visibility culling [Kumar96], where faces are grouped together. Since we are\nusing subdivision surfaces, we know that child faces have similar properties to their\nparents. Therefore, if their parents and neighbors all face away from the view, then so\ndo the children. This technique is very effective, especially when high polygon counts\nare involved. It is also used to reduce the number of subdivision faces that need to be\nprocessed, since we avoid the subdivision of hidden surfaces. A more thorough inves-\ntigation of this technique was presented in a SIGGRAPH sketch by Carlo Séquin\n[Séquin01].\n\nView-Frustum Culling\n\nAnother optimization method is lazy spatial subdivision, which uses the subdivision\nhierarchy to skip processing subsurfaces. This method involves using either a k-d\n\n379\n\n(BSP) tree or an octree to separate faces into visible, hidden, or partially visible status\nwith respect to the view frustum. Thus, if the viewer is looking at the characters’ faces,\nthe subdivision is only performed on those faces. This is very important if an opti-\nmum frame rate is desired.\n\nEach subdivision mesh is contained in a bounding box. If the whole bounding\nbox is visible, then it is drawn. Otherwise, the box is split into another four boxes,\nwhose visibilities are then determined. This continues until either the maximum\ndepth is reached or the minimum number of faces is reached. Determining these con-\nditions is crucial to optimizing this algorithm and depends on the rendering method\nor graphics card used. One of the problems with this technique is that some polygons\nmight occupy more than one bounding box. This would cause those polygons to be\ndrawn or tested against the frustum multiple times. To stop this from happening,\neach face is tagged with the frame number each time its visibility is determined. Then,\nwhen processing other nodes, faces that are tagged can be left out, thereby reducing\nthe number of faces that have to be tested against the frustum. By using this test, we\ncan cull out faces where subdivision is unnecessary and only subdivide those that are\nin the frustum. For small meshes, it is preferable to use the view frustum directly for\nculling visible faces.\n\nFIGURE 4.7.7 Lazy frustum cull using BSP tree.\n\n380\n\n; Section 4 Graphics\n\nThe two previous approaches are used to mark faces that are deemed either visible\nor invisible. This data is then used to reduce the number of child faces produced by\nsubdivision or to cull out any faces before they are sent down the rendering pipeline.\n\nThe next two optimizations are methods that precompute data in order to reduce\nthe cost of traversing the half-edge data structure. These techniques, unfortunately,\ncan significantly increase the amount of memory required, but they do substantially\nspeed up the display and generation of subdivision surfaces.\n\nPrecomputed Face Vertex Indices\n\nPrecomputation of the face vertex indices is very useful when it comes time to display\na face in the subdivision surface. This is an index array and needs to be done only\nonce for the surface. The idea is to store the indices of the vertices that make up the\nfaces prior to using the subdivision surface. Thus, they do not have to be computed\neach time the surface is going to be rendered. This is then used as part of a vertex\narray. The face index array looks like:\n\n{(2, »Vyy> v3), Lees (2, Uy Vn, )} (4.7.4)\n\nPrecomputed Weights and Vertex Indices\n\nPrecomputation of the weights and vertex indices is used for the generation of even\nvertices and also for the refinement of odd vertices, making traversal of the half-edge\nmesh unnecessary. Basically, a set of weights (w;) and indices (v,) for each vertex (2) in\nthe mask are computed and stored with the destination index (v,) of the resulting ver-\ntex. Thus, a simple for loop is all that is necessary to generate the next set of vertices.\nThis scheme can also be used to compute the tangent vectors for the Loop and but-\nterfly schemes, avoiding the use of sin and cos. The method differs slightly for each\nsubdivision scheme. The butterfly scheme requires less memory, as it has a fixed num-\nber of vertices for each mask. Thus, eight vertex indices and weights are stored, as well\nas the destination index for the resulting vertex. The butterfly weight-and-index array\nlooks like:\n\nnx {(205%0)s--+(ve»w5),2} (4.7.5)\n\nThe Loop scheme is a bit more complicated. The even masks do not have a fixed\nnumber of vertices from which the resulting vertices are generated. Thus, to store\nthese, we have to add an extra field that identifies how many vertices are stored. For-\ntunately, the odd masks have a fixed number and can be stored in a similar manner to\nthe butterfly scheme, but with only four indices and weights. A Loop odd and even\nweight-and-index array looks like:\n\n((+0,w)s-+-(v4s04),24) odd\n\n(é, (v>@o)s++- (414) 74} even (4.7.6)\n\nnx\n\n4.7 Subdivision Surfaces for Character Animation — 381\n\nThe storage costs can be further reduced. If the vertices are always stored in the\nsame order, then weights are the same for the odd masks. Therefore, they do not need\nto be stored. To use the arrays, the program simply runs through the sets, multiplying\nthe vertex by its weight and adding that result to the total for the vertex.\n\nPutting It All Together\n\naa\n\nAARC\n\nThe implementation of the subdivision schemes i is pretty y straightforward. In this\nimplementation, a multiple pass approach is adopted, where a new level of the mesh\nis generated on each pass. This method makes the code fairly simple and enables the\noptimizations to be performed on each pass, if necessary. For each pass, the vertices\nare stored in a single array, whose size grows to accommodate the number of vertices\nneeded. On the final pass, the vertices and faces are dumped into a geometry array,\nwhich is then sent down the rest of the rendering pipeline.\n\nStoring the Data\n\nArrays are used to store the data for subdivision surfaces. This is for speed reasons as\nwell as for ease of management. It is also relatively easy to pass the arrays directly to\nthe graphics API in the form of vertex arrays. Arrays are far easier to manage, since\nonly one big allocation is ever needed. Then, if the space is too small, we can reallo-\ncate more memory. This way, only the first few frames are slow (until sufficient mem-\nory has been allocated). Arrays tend to use less memory because pointers do not need\nto be stored for simple hierarchical and linear storage schemes. Since the memory is\nallocated as a single chunk, it caches much better and, therefore, is accessed faster.\nAnother significant advantage of the array-based approach is that when using the\naccumulation buffer for skinning, the face indices and other reference data need not\nbe regenerated. This is because each vertex generated is stored at the same relative\nlocation in the array.\n\nRemoving What Is Not Seen\n\nThe visibility culling is only performed on the original mesh to save time, since it is an\nexpensive option. While determining the visible faces is relatively easy, deciding\nwhich faces are needed to produce child faces is a bit harder. In order to do this, we\nneed to know in advance how many levels of subdivision are required. This is because\nthe support areas required by the subdivision schemes overlap, producing a depen-\ndence hierarchy (see Figure 4.7.8). The more levels of subdivision required, the larger\nthe support area must be. An alternative to explicitly determining these regions is to\nuse a lazy evaluation method that generates faces as they are needed. Unfortunately,\nthese methods prove to be slower, as the memory accesses are fragmented.\n\nLuckily, the support areas for the butterfly scheme and Loop scheme are very sim-\nilar, with the butterfly being marginally smaller (see Figure 4.7.8). This allows us to\n\nuse the same methods to determine the extra faces needed in addition to those that are\n\n382 Section 4 Graphics\n\nchisierohe etl eReteiinr inNee NH ineeeaHatoceeeceaitseueee a mbna or\n\nFIGURE 4.7.8 Support areas required by Loop and butterfly subdivision schemes.\n\nvisible for a given subdivision level. It also highlights the fact that for a mesh with rel-\natively few nodes, such as a cube made with triangles, the child node can be quite\ndependent on the rest of the mesh.\n\nRendering the Frame\n\nTo render the surfaces, a list of triangles, vertices, normals, and texture coordinates are\nput into a vertex array and then rendered. A simple API separates the rendering API\nfrom the rest of the code. This allows more-complex operations and rearrangement of\nthe scene to facilitate faster rendering by minimizing state changes.\n\nSource Code\n\n‘ee tance NR HR RA TE\n\nA sample program is available on the CD-ROM.\n\nON THE CD\n\nConclusion\n\n\"Sn nae trata NSB STR SBR AS RA AN NNSA TN 8 one\n\nSubdivision surfaces can be used to create very detailed characters with natural forms.\nThe same formulas can also be applied to the texture parameters to generate proper\nsurface coordinates. In addition, many of today’s modeling packages provide support\nfor subdivision schemes. They also furnish a very easy route for increasing the amount\nof detail. However, these subdivision methods don’t provide an easy means to reduce\nthe mesh detail from the initial mesh. This is where progressive meshes [Svarovsky00,\nHoppe96] would be more useful. It would be great to combine the two methods—\nuse subdivision to increase detail, and use progressive meshes to reduce it. Subdivision\nsurfaces also reduce the number of transformation operations necessary to perform\n\n4.7 Subdivision Surfaces for Character Animation 7 a ; 383\n\nskinning, as only the initial mesh needs to be modified. Modern accelerators provide\nT&L support and vertex-weighting extensions, however, using these features with\nsubdivision surfaces is possible. To do this, the view frustum is trarisformed, rather\nthan the vertices of the mesh. Then, when the culling is done with this modified frus-\ntum, the untransformed visible triangles are sent to the graphics card for transforma-\ntion and display.\n\nReferences\n\n[DeRose98] DeRose, Tony, et al., “Subdivision Surfaces in Character Animation,”\nComputer Graphics Proceedings (SIGGRAPH 1998): pp. 85-94.\n\n[Dyn90] Dyn, Nira, et al., “A Butterfly Subdivision Scheme for Surface Interpolation\nwith Tension Control,” ACM ‘Transactions on Graphics, Vol. 9, No. 2, pp.\n160-190, 1990.\n\n[Hoppe96] Hoppe, Hugues, “Progressive Meshes,” Computer Graphics Proceedings\n(SIGGRAPH 1996): pp. 99-108.\n\n[Kobbelt98] Kobbelt, Leif, et al., “Subdivision for Modeling and Animation,” Course\nNotes (SIGGRAPH 1998).\n\n[Kumar96] Manocha, Kumar, et al., “Hierarchical Visibility Culling for Spline Mod-\nels,” Graphics Interface, 1996: pp. 142-150.\n\n[Loop87] Loop, Charles, “Smooth Subdivision Surfaces Based on Triangles,” Master’s\nThesis, University of Utah, Department of Mathematics, 1987.\n\n[Séquin01] Séquin, Carlo, et al., available online at http://www.ce.chalmers.se/staft/\ntomasm/research/subdiv/, December 25, 2001.\n\n[Svarovsky00] Svarovsky, Jan, “View-Independent Progressive Meshing,” Game Pro-\ngramming Gems, Charles River Media, Inc., 2000.\n\n[Weiler85] Weiler, Kevin, “Edge-Based Data Structures for Solid Modeling in\nCurved-Surface Environments,” IEEE Computer Graphics and Applications,\nVol. 15, No. 1, pp. 21-40, 1985.\n\n[Zorin96] Zorin, Denis, et al., “Interpolating Subdivision for Meshes with Arbitrary\nTopology,” Computer Graphics Proceedings (SIGGRAPH 1996): pp. 189-192.\n\n‘nRCRRRNSIEE\n\n4.8\n\n384\n\nBackground\n\nImproved Deformation\nof Bones\n\nJason Weber, Intel Corporation\njason.p.weber@intel.com\n\nItists can produce beautifully realistic meshes to represent the actors in their\n\names. To bring them to life, these models need to be animated for a wide vari-\n\nety of behaviors. Storing a full set of vertex positions for every frame of animation is\n\nnot only prohibitively memory-consumptive, it restricts movements to only those\n\nactions explicitly created by the artist. So, many applications use a hidden hierarchy of\nsegments that looks and acts very much like a subset of a natural skeleton.\n\nBy transforming each vertex of a mesh through multiple matrices instead of just\none, and then by doing a carefully weighted average of the results, we are able to\nsmoothly deform these meshes to any position and play back the results at any frame\nrate. This approach permits a significant reduction in the required animation data\nand allows the skeleton, and thereby the mesh, to be spontaneously adjusted to any\npose, perhaps reacting to unpredictable events in its environment.\n\nHowever, the popular deformation algorithm has some problems when used in its\noriginal form. We will demonstrate how large deflection angles cause joints to shrink,\npotentially even to a point. Fortunately, this can be overcome by adding a small chain\nof additional bones at troublesome joints, such as the elbows and knees. By carefully\nreworking the weighting data to account for these ‘links,’ we can use the same simple\ncore deformation algorithm and only incur the small additional burden of a few extra\nbones.\n\nThe skeletal structure is a hierarchy of transforms, like a scene graph. At each trans-\nform, we define a bone length, which is really a displacement along that transform’s\nlocal x-axis. By default, the origin of all child bones is positioned at the displaced\npoint on the end of the parent bone. We allow for an arbitrary additional displace-\nment, but in most cases where bones connect end-to-end, it is zero.\n\nA reference pose of the skeleton describes the state of the hierarchy where it aligns\nwith the given undeformed mesh. (Biped, in 3DS Max, calls this the “figure mode.”)\nThe motion of the bones away from the reference pose is used to deform the mesh to\nany arbitrary position. The motion of these bones comes from some driving source,\nsuch as motion capture, authored motion, or inverse kinematics [Weber02]. (For a\nlonger description of the background material, refer to the GDC 2000 proceedings\n[Weber00].)\n\nSimple Methods\n\n[Woodland00] and is also nicely explained in Jeff Lander’s Game Developer article\n[Lander98]. As an example of this technique, consider vertices on an elbow whose\nposition needs to be affected by the current transform of both the upper and lower\narm bones. As we pass each vertex in the elbow through each of the two transforms,\nwe get two different resultant vertices. If we then do a weighted average of these trans-\nformed vertices, we get a reasonable ‘in-between’ position. An important guideline\nhere is that these weightings for the vertices should smoothly transition from 100%\nupper arm to 100% lower arm from the top of the elbow to the bottom. Otherwise,\nthe mesh will stretch abnormally and might appear to tear.\n\nAs the deflection angle of the lower arm increases and the difference in the results\nfrom each bone increases, serious visual abnormalities could arise. For example, the\nworst case might be if you twist the child bone 180° about its lengthwise axis. The\ntwo transformed resultants are on opposite sides of the elbow, so a 50/50 average is at\na point inside the elbow. The overall effect is much like twisting or bending a card-\nboard paper towel tube. Figures 4.8.1 and 4.8.2 show illustrations of problem cases.\n\nFIGURE 4.8.1 Twisted elbows: a simple skinning method demonstrated on the left arm contrasted\nwith an enhanced technique on the right arm.",
      "page_number": 367,
      "chapter_number": 38,
      "summary": "Weighted Vertex-Accumulation Buffer\n\nVertex weighting introduces complications to the task of transforming the vertices Key topics include faces, mesh, and meshes.",
      "keywords": [
        "subdivision surfaces",
        "subdivision",
        "HEE OEE",
        "faces",
        "subdivision schemes",
        "vertices",
        "Face Vertex Indices",
        "Vertex",
        "surfaces",
        "mesh",
        "Graphics",
        "Vertex Indices",
        "Computer Graphics Proceedings",
        "teaetcecnenE H HEE",
        "Smooth Subdivision Surfaces"
      ],
      "concepts": [
        "faces",
        "mesh",
        "meshes",
        "method",
        "bones",
        "array",
        "weighted",
        "visibility",
        "visible",
        "visibilities"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 7",
          "chapter": 44,
          "title": "Segment 44 (pages 413-428)",
          "relevance_score": 0.59,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 1",
          "chapter": 48,
          "title": "Segment 48 (pages 462-474)",
          "relevance_score": 0.56,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 2",
          "chapter": 35,
          "title": "Segment 35 (pages 347-359)",
          "relevance_score": 0.52,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 5,
          "title": "Segment 5 (pages 41-49)",
          "relevance_score": 0.48,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 7",
          "chapter": 45,
          "title": "Segment 45 (pages 429-442)",
          "relevance_score": 0.46,
          "method": "api"
        }
      ]
    },
    {
      "number": 39,
      "title": "Segment 39 (pages 375-382)",
      "start_page": 375,
      "end_page": 382,
      "detection_method": "topic_boundary",
      "content": "386 . Section 4 Graphics\n\nFIGURE 4.8.2 Corresponding effect with elbows bent. The right arm uses the enhanced\ntechnique.\n\nAdding the Bones\n\nRa aS RN SR RR TER\n\ncd\n\nIf large angles cause defects, one solution is to limit all deflections to a small angle. We\ncannot really restrict the motion of the existing bones, but we can distribute these\nlarge angles over several smaller bones conveniently placed at the joints. Since a\ndeflection of 60° seems to be a safe limit, using three or so of these ‘links’ should usu-\nally be sufficient. The length of the links can be left to the author of the model. We\nare often content with a default value derived from the mesh’s cross-sectional radius at\n\nthe joint and the length of the child bone:\n\ntotal_linklength=0.3*child_length+1.5*joint_radius\n\nThe placement of the bones should look something like a spline. The bones\nshould stay arranged end-to-end, but they may slide together a little as the joint flexes.\nWe don’t have to actually shorten the bones, but the overlap will naturally compress\nthe mesh slightly. Our solution is demonstrated in GPGBoneNode: :CalcBoneLinks() in\nGPGBoneNode.cpp on the CD-ROM, and it works as follows.\n\nTo compute the position of the bones, first consider three points, as shown in Fig-\nure 4.8.3a—the original joint connection A, the first link center B, and the last link\ncenter C. They will form a triangle as the joint flexes. For each link, take two points,\none along BC and the other along either BA or AC, depending on whether the link is\nin the first or second half of the chain. The displacement of these points along these\nlines is proportional to the ordering of the link along the chain. Once you have these\ntwo points, take a weighted average to find the center for the desired link. The\nweighting goes linearly from 100% of the point on BC at either the first or last link to\n\n4.8 Improved Deformation of Bones\n\nFIGURE 4.8.3 (A) A small chain of bones added to the joint. (B) Example of new\nweighting relationships.\n\n388\n\neek eriamnea nti niatmmnonneinnnanetiynaeeiib Wisin nrxteuttenineiiolini nsiceeeutaninneitoklttctr cinta mre eR pinionionuniisitnnoonteio\n\nSection 4 Graphics\n\n50/50 for a link in the exact center. Rotations of the links are computed as the linear\ninterpolation of the overall change in angle so that the total deflection is evenly\ndistributed.\n\nThe instantiation and weighting of the links only need to occur once. The posi-\ntion and rotation of the links need to be recomputed every time the parent or child\nmoves, potentially every frame.\n\nChanging the Weights\n\nTE ED AMATO ENE NINTTI TS ESSE RON 2 ILHAM LDS\n\nMost of the weights around a bone-linked joint will need to be reassigned. The\nweights should transition smoothly from the original parent to the first link, then\nalong to each element in the chain, and finally to the original child bone. If there is no\nfork at this joint and all the original influences were assigned only to this parent and\nchild bone, it is sufficient to use the longitudinal (x) position to find which two bones\nto attach to (including the new link bones). If we look at the links as an integer num-\nber line, with the parent bone as zero and the original child as (number_of_links+2),\nthen we use the local x position of the vertex along the chain, scaled to the size of the\nnumber line. We find the integer numbers above and below where that vertex falls\nand use the fractional part to determine the weights. For example, if our local x posi-\ntion scales to 2.3 in ‘bone link space,’ the new weights will be 70% for the second link\nbone and 30% for the third link bone.\n\nIf there is a fork in the bone hierarchy nearby, more information needs to be con-\nsidered, even if there is not an explicit sibling to the particular child bone. The hip\nand shoulder areas are two good examples of this type of situation. The goal for any\nparticular link chain is to only reassign a fair fraction of the parent’s influence and\nleave the remainder of the influence for other bones to consider. For example, a vertex\non the chest near the shoulder might be partially influenced by the motion of the\nupper arm, but it is also well anchored to one or more spinal bones. When adding\nbones between the clavicle and upper arm, we don’t want to reassign the portion that\nbelongs to the spine.\n\nTo determine this fair fraction, all the weights are found for the particular vertex\nthat have the same parent as an ancestor to the child in question. These ‘competitors’\nreduce how much influence we can reassign for that child. To make sure the effect is\nnot dependent on the order that the weights are processed, only competitor entries\nthat follow the current weight entry on the weight list are considered. Adding up\nthese competitor weights, we determine the fraction as:\n\nfraction = 1 — competitor | (competitor + childweight)\nThe weight to be reassigned is then:\nfraction * parentweight + childweight\n\nAt this point, we continue as in the unforked case. We adjust the existing stored\nparent weight in place. For our two new weights, we can first overwrite the previous\n\n4.8 Improved Deformation of Bones 389\n\nchild entry, which has now been entirely reassigned, and then add a new weight entry\nfor the second influence.\n\nFigure 4.8.4a shows a shoulder joint with reassigned weights. This diagram shows\nwhich of the given links the vertices are weighted to. It does not show the magnitude\nof the weights or any weights to other bones, like the spine. A chain of three links\nconnects the clavicle bone to the upper arm. Lines are drawn from each vertex to the\n\noe : io \\of eS\n\nFIGURE 4.8.4 New weighting with three added links (A) for a shoulder mesh (B).\n\n390\n\nSection 4 Graphics\n\n\\itceerteennattemstttensiivinattss eos glancing ecestcarMemcnenac ret Ab i vRNA RHONA NRGiASESENi CROOK AAARANEIIDTA NRA ADELE EN HatotentneeatonenEIOHESeIt\n\nON THE CD\n\ncenter of each bone that the vertex is influenced by. The shade of the line matches the\nshade of the bone, varied for clarity. Note how the links have influences deep into the\nchest. These create a gradual stretching of the skin when the arm is moved.\n\nNormal-Derived Influence Fade\n\nThere is one side effect we cannot ignore. Since we are reassigning based purely on\nposition, joints with apparent right angles in the mesh can incur excessive bulging.\nThe shoulders tend to display this problem. When the upper arm moves up, the side\nof the chest will push out sideways, as though it were a very wide region of the arm\n(see Figure 4.8.5).\n\nWe can use the inherent difference in the normal direction to correct for this. We\ntake the dot product of a vertex’s normal with respect to the longitudinal bone axis.\nFrom this result, we subtract the x displacement of the vertex along the bone, divided\nby the approximate fadius at the joint (the subtracted value and the result both have a\nfloor of zero). This reduction has the effect of isolating the correction toward the par-\nent side of the joint. The secondary result is a fraction from 0.0 to 1.0, which we\nsquare for good measure. This fraction is applied to the weight that was previously\ndestined to reassignment. That portion of the weight is not reassigned, but directly\nadded to the parent’s weight. In our example code, see GPGSkin: :RelinkWeights() in\nGPGSkin.cpp on the CD-ROM.\n\n(A)\n\nFIGURE 4.8.5 Raised arms (A) without and (B) with normal-derived influence fade.\n\n391\n\nit is critical chat we lay out our runtime data in a cache-friendly manner. The biggest\ndecision to make is whether to process the weights in a ‘bone-major’ or ‘vertex-major’\nfashion.\n\nFor the bone-major method, you have to first clear all the vertex positions and\nnormals in the mesh. Then for each bone, you process all the vertices that the bone\ninfluences, accumulating fractional components to their stored positions and nor-\nmals. While this will probably keep the current matrix in cache, it reads and writes the\nmesh in a very scattered manner.\n\nIn the vertex-major method, we process the vertices in order, pulling in matrices\nas necessary. While this may incur some scattered access to the matrix array, the\nadvantages are numerous. First of all, there is no clearing stage. We know when the\nfirst write to a vertex occurs, so that access can be a pure set instead of an add. Since\nthe weights for a vertex are clumped together, we can accumulate the results in a local\nvariable and dump them out with one write per vertex, instead of one read and one\nwrite per weight per vertex.\n\nWe have tried it both ways, and for all our measurements, the vertex-major\napproach was at least twice as fast, and probably much faster, even with all the opti-\nmizations we were able to add later on due to the flexibility of the layout.\n\nTransform Matrices\n\nEvery bone in the skeleton has a transform, including the added bone links. Until the\nactual deformation stage, we use quaternions because of their superior interpolative\nqualities [Bobick98]. However, for raw vertex transforms, using the matrix form is\nalmost four times faster. So, just before the core deformation loop, we fill in a nicely\npacked array of 3 x 4 matrices, one for each bone. Each matrix is assigned the inverse\nof the bone’s reference transform, multiplied by the bone’s current transform. In this\nway, we can transform directly from the original, undeformed mesh without having\nto store vertex offsets relative to each bone.\n\nThe core deformation loop contains only about 50 lines of code. See\nGPGSkin: :ComputeDeformedVerticesPacked() in GPGSkin.cc on the CD-ROM.\n\nPackweights |\n\nSince the vertex weights will usually be a larger data structure than the matrix array or\neven the mesh, it is important to keep the weight list small in order to reduce the\namount of data we need to process each frame. This not only saves space, but it\nshould really optimize our cache usage. However, we/also need to be aware that exces-\nsive byte conservation might throw off the word alignment, which would be just as\ndetrimental to the process.\n\n392\n\nSection 4 Graphics\n\nThe packweight structure is a big byte block with alternating sections of one ver-\ntex definition and one or more boneweight influences. The vertex definition contains\nthe vertex index, a copy of the undeformed vertex position and normal, and the num-\nber of weights to follow. The boneweight block contains just the bone index into the\nmatrix array and the fractional weight. As we read any block, we can prefetch the next\none.\n\nNote that storing the vertex position and normal in the weight list means that we\ncan continuously deform to an output mesh without having to retain an undeformed\ninput mesh, If we wanted to allow outside modifications to the input mesh, such as\nwith a piorphing modifier, we would not store that data in the weight list, but we\nwould have to take the penalty of rereading vertices from the input mesh every frame.\nSee the file GPGPackWeights.h on the CD-ROM for our example code.\n\nON THE CD\n\nNormal Renormalization\n\nWe can perform a weighted average of multiple normals just like we do with the posi-\ntions, but the result will have a reduced magnitude. These differences are easy to fix.\nSince the reduced normals are known to have a range of magnitude from 0 to 1, you\ncan use a modest table to eliminate the sqrt() operation. If you do not renormalize\nthem, they could cause a reduction in lighting intensity. Our observations show very\nlittle difference, so you might want to consider leaving them as is or hook the option\n\nto a quality toggle.\n\nLERNER ETSI SURE BS HR A ENE\n\nRRR rd\n\nBones-based animation can be a key to reducing animation overhead and allowing for\nspontaneous and. unique behaviors. Existing deformation techniques can be made\nvery fast and are easily extended to overcome some inherent limitations.\n\nAdditional topics could cover the generation and manipulation of the original\nvertex weights. Color Plate 7 demonstrates improvements achieved by using a com-\npletely automated procedure to generate raw weights, remove anomalies, smooth the\ndistribution, and add bone links.\n\nThe improvement in the waist is mostly due to the regenerated weights. The\nupper leg benefits dramatically from using the links to reduce shrinkage. Even the\nshoulder and knees improve significantly by eliminating excessive stretching. Also, the\nchest looks more realistic, since using links in the shoulder permits a wider spread of\ninfluences over the surrounding mesh.\n\nReferences\n\nRRR RRR ERR RR ROR ES ENR ARMAS ERE RENT NR NHS PO RRA I RIRRRALNRRA OBEN SEA BIE MTORO\n\n[Bobick98] Bobick, Nick, “Rotating Objects Using Quaternions,” Game Developer\nMagazine, February 1998: pp. 34-42. Also available online at http://www.\ngdmag.com.\n\n[Lander98] Lander, Jeff, “Skin Them Bones: Game Programming for the Web Gen-\neration,” Game Developer Magazine, May 1998: pp. 11-16.\n\n_saenttrny\n\n4.8 Improved Deformation of Bones\n\n[Weber00] Weber, Jason, “Run-Time Skin Deformation,” Game Developers Confer-\nence Proceedings (GDC 2000): pp. 703-721. Also available online at\nftp://download.intel.com/ial/3dsoftware/animatedoc.pdf.\n\n[Weber02] Weber, Jason, “Constrained Inverse Kinematics,” Game Programming\nGems 3, Charles River Media, Inc., 2002.\n\n[Woodland00] Woodland, Ryan, “Filling the Gaps—Advanced Animation Using\nStitching and Skinning,” Game Programming Gems, Charles River Media, Inc.,\n2000: pp. 476-483.\n\nThe author will make an effort to maintain a long-term archive and link site for some\nrelated resources at http://www.imonk.com/baboon/bones.",
      "page_number": 375,
      "chapter_number": 39,
      "summary": "This chapter covers segment 39 (pages 375-382). Key topics include bones, weighted, and vertex.",
      "keywords": [
        "bone",
        "Weights",
        "vertex",
        "link",
        "child bone",
        "link bone",
        "added bone links",
        "joint",
        "mesh",
        "vertex weights",
        "original vertex weights",
        "bone link space",
        "weight list"
      ],
      "concepts": [
        "bones",
        "weighted",
        "vertex",
        "links",
        "deformation",
        "influences",
        "influenced",
        "improved",
        "improvements",
        "improve"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 7",
          "chapter": 44,
          "title": "Segment 44 (pages 413-428)",
          "relevance_score": 0.58,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 1",
          "chapter": 48,
          "title": "Segment 48 (pages 462-474)",
          "relevance_score": 0.52,
          "method": "api"
        },
        {
          "book": "operating_systems_three_easy_pieces",
          "chapter": 25,
          "title": "Segment 25 (pages 231-249)",
          "relevance_score": 0.5,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 1",
          "chapter": 30,
          "title": "Segment 30 (pages 279-290)",
          "relevance_score": 0.48,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 7",
          "chapter": 49,
          "title": "Segment 49 (pages 479-486)",
          "relevance_score": 0.47,
          "method": "api"
        }
      ]
    },
    {
      "number": 40,
      "title": "Segment 40 (pages 383-392)",
      "start_page": 383,
      "end_page": 392,
      "detection_method": "topic_boundary",
      "content": "4.9\n\nA Framework for Realistic\nCharacter Locomotion\n\nThomas oung, PathEngine\nthomas@pathengine.com\n\nith today’s hardware, we can render extremely realistic-looking characters.\n\nHigh-fidelity motion-capture systems are widely available for providing anima-\ntion data. However, in most games, as soon as a character starts to walk, the illusion of\nreality is destroyed. The character's feet slide against the ground, the character is\nrotated arbitrarily in mid-animation, or the animation jumps suddenly to a com-\npletely different state.\n\nEven a small amount of foot-sliding is noticeable. As soon as we see a foot slide\nagainst the floor, we know that breaking friction has been overcome. Without friction\nbetween the foot and the floor, there is no mechanism that a character’s forward\nmotion can be attributed to, so the movement of the character is strongly perceived as\nunrealistic.\n\nIt is difficult to solve all the constraints for realistic animation at the same time.\nWe can ensure smooth transition between animations with a tweening modifier. This\nmodifier calculates the in-between (or tween) positions in animation poses. We can\nsolve the problem of arbitrary targets for locomotion by modifying the translation\nresulting from each animation segment. However, a straightforward implementation\nof these modifiers will result in foot-sliding.\n\nThis gem presents a solution to this problem based on adjusting the position of\nthe feet only when they are already in motion. A framework is described for applying\nthis idea to the problem of realistic character animation by using independent modi-\nfiers for different parts of a skeleton.\n\nProblem: Locomotion to an Arbitrary Target —\n\nSARS MAHAN NUS NNT NORE ARR U AR A ARSN RU RAR\n\nToward the end of the 2D era, we started t to see games such as Prince of Persia and\nFade to Black, which featured beautifully sequenced animations. The trick was that\nthe game environment was built from unit-length tiles on a fixed grid. Since the ani-\nmation was designed around exactly the same unit-length, it was possible to guaran-\ntee that the animation ended perfectly, just pixels in front of a wall or a cliff.\n\n394\n\n4.9 A Framework for Realistic Character Locomotion\n\n(A) (>>+——> —_ > x\n\n®) (>>> >\n\n— &\n\nFIGURE 4.9.1 A character with fixed animations attempting to move to arbitrary points and angles.\n(A) The character will not reach the point with a start, walk, walk, stop sequence. (B) The character\nwill overshoot the target with a start, walk, walk, walk, stop sequence. (C) The character will not\npoint toward the target with one or two rotation animations.\n\nAs soon as the possibilities for movement include turning in arbitrary angles and\nmoving forward, the situation becomes more complicated because we can no longer\nconstrain this movement to a fixed grid. Now we are stuck with the problem of char-\nacters needing to move arbitrary distances and turn in arbitrary angles.\n\nThe character in Figure 4.9.1 has an animation for starting to walk, a walk cycle\nanimation, and an animation for stopping. In Figure 4.9.1a, two walk cycles will not\ntake the character far enough, but in Figure 4.9.1b, three will take the character too\nfar. Figure 4.9.1¢ shows how the same problem applies when turning arbitrary angles.\nIn this case, the character only has one turn animation. Playing the animation once\ndoes not turn enough, but playing it twice turns the character too far. We can improve\nthe situation by providing more animations for a character to choose from, but the\nbasic problem remains.\n\nPlan and Modify\n\nWe can solve this problem by modifying the translational or rotational offsets for ani-\nmations as they play. In Figure 4.9.2, the closest set of animations in length is chosen\nprogrammatically from the available animations. The offset required to take the end\npoint of the animations to the target is split across the animations and applied as a\nmodification to each animation. The animation sequence now ends exactly at the tar-\nget point.\n\n396\n\nSection 4 Graphics\n\n‘ene ses Reh Aes EE EEE EEE GA ENE ROARS OCA OEE HDETSERAOOE HAA OEE NRE\n\n) >>> >\n\nacon\n\nFIGURE 4.9.2 Plan and modify movement to arbitrary targets. (A) Calculating the necessary\nadjustment to move to the target. (B) Distributing the adjustment among the fixed animations.\n(C) The same process with angles.\n\nIn order to modify the translational or rotational result of an animation, we sim-\nply apply an offset to the position or orientation of the character origin with a\n‘ramped’ multiplier that goes from 0 to 1 smoothly as the animation is played. How-\never, since this multiplier will change during parts of the animation, such as when a\nfoot is supposed to be stationary, the result is foot-sliding.\n\nmooth Transition Between Animations\n\nsane 6 tr a RR\n\nMotion-captured moves will never start or end in exactly the right stance, no matter\nhow good the actor is. Concentrating on hitting the right stance can also have a neg-\native effect on the quality of motion. It is a shame to discard a capture in which the\nactor got the movement right, just because the capture ends a bit out of stance. With\nmotion-captured animation, we need to transition smoothly between captures that\nare out of stance. Even if we are working with hand-animated moves that start and\nend in perfect stance, we still need to be able to transition early out of a move.\n\nAn Approach\n\nThe best result will be achieved by transitioning directly between the state of the\nskeleton at the end of one motion and the state at the start of the next motion, as\nopposed to transitioning in and out of a predefined stance. Since we do not want to\ninterrupt the flow of movement, a transition should be made while the animation is\nplaying. For the greatest flexibility, we should not project which animation will play\nnext until we must play that animation. Based on these considerations, a good\napproach to the problem is to modify the start of each animation to be the same as the\n\n4.9 A Framework for Realistic Character Locomotion 397\n\n(A) (B) (C)\n\nFIGURE 4.9.3 Transition between stances. (A) State of skeleton at end of previous\nanimation. (B) State of skeleton at start of following animation. (C) Applying the same\nmodification later in an animation causes problems at a foot.\n\nend of the previous animation, and then ease out this modification as the animation\nis played.\n\nThe character in Figure 4.9.3a shows the state of the skeleton at the end of the\nprevious animation. Figure 4.9.3b shows the skeletal state at the start of the following\nanimation. We need a modification that will transform the skeleton from the state in\nFigure 4.9.3b to the state in Figure 4.9.3a. We also need to be able to smoothly tran-\nsition back to the original position as the second animation plays.\n\nA common approach to solving the transition problem is to store the state of a\nskeleton as a set of hierarchical relative orientations and to interpolate between these\norientations. Orientations are often interpolated with the use of spherical linear inter-\npolation of quaternions. (See [Shankel00] for a more detailed description of quater-\nnion interpolation.) If we use this interpolation method, then our modification takes\nthe form of a set of quaternion offsets for each joint. This modification can be eased\nout by multiplying the offsets by a ‘tween ratio’ that goes from 1.0 to 0.0, over the\nduration of the current animation. Figure 4.9.3b shows how a set of rotations at the\njoints can take the skeleton to the desired position. The origin for the character in\nFigure 4.9.3 is between the hips. As the height of the origin can vary with animation,\nour modification should also include an offset to this height.\n\nProblems with this Approach\n\nThe first problem with this kind of straightforward interpolation approach is that for\nany modification that affects the position of the feet, easing out that modification will\nalso affect the feet. If this happens while the foot is supposed to be stationary against\n\n398\n\nSection 4 Graphics\n\nthe floor, then we get foot-sliding. The amount of sliding will depend on the size of\nthe original discrepancy and the length of time over which our modifier is eased out.\n\nThe second problem is that our modifier will give us undesirable results when it\nis applied to the skeleton later on in the animation. Figure 4.9.3b shows the rotations\nthat will be applied by our modifier to the left leg. We know that these rotations result\nin a ‘correct’ position for the skeleton when applied to the first frame of animation\nbecause the rotations were chosen to achieve a specific target position when applied at\nthis point. Figure 4.9.3c shows how the application of the same rotations to the leg\nlater on in the animation results in the foot hovering above the floor. The interface\nbetween the foot and the floor over a period of animation depends on a combination\nof translation at the origin and rotation of the leg. Applying a modifier to the rotation\nof the leg breaks this interface. This will result in feet hovering or interpenetrating the\nfloor, feet being positioned at the wrong angle with respect to the floor, and feet slid-\ning against the floor when they are supposed to be stationary. The problem gets worse\nas the skeleton gets further from its start position. We can improve the situation by\neasing out our modification more quickly, but this will affect the smoothness of the\ntransition and make the foot-sliding more pronounced over the ease-out duration. So,\nonce again, while we have an approach for transitioning between two animations, the\nsliding-feet problem still plagues our result.\n\nA Framework for a Solution: Local Modifiers\nwith Independent Tween Ratios\n\nSEERA con ete\n\nRRR Ran\n\nBy modifying an animation slightly as it is played, we can solve some problems in\ncharacter locomotion. However, if this modification affects the positions of the feet\nwhile they are supposed to be stationary against the floor, then there is still a problem.\n\nWe can choose when to reduce our tween ratio. If a character jumps in the air\nhalfway through an animation, then we can delay tweening until both feet leave the\nfloor and finish tweening by the time the character lands. This would eliminate prob-\nlems resulting from changing tween ratio while the feet are on the floor. Unfortu-\nnately, most animations will have at least one foot on the floor most of the way\nthrough the animation.\n\nAffecting Feet Only When They Are Already Moving\n\nThe trick is to use independent modifiers for different parts of a skeleton. This way,\nwe can ease out each modifier over different sections of the animation. Thus, to mod-\nify an animation without introducing foot-sliding, we use a separate modifier for each\nleg. For a walk animation in which the left foot moves first, followed by the right foot,\nwe ease out the left-leg modifier while the left foot is moving forward, then we wait\nuntil the right foot starts to move before easing out the right-leg modifier.\n\nWe can generalize this to any kind of animation and automate the process of\ndetermining when to perform the ease-out for each modifier. Figure 4.9.4 shows a\ntwo-step animation with the corresponding movement profile for each foot. We can\n\n4.9 A Framework for Realistic Character Locomotion 399\n\nmesa eee Meee eewA OI sauces HENGE ORRSMRA DERE AT ORS REE\n\nLeft Foot\n\nRight Foot\n\nFIGURE 4.9.4 A two-step animation with corresponding movement profile ford the 1 fet\n\ntake the tween ratio for each leg directly from this movement profile. The tween ratio\nat a given point can be set as the movement up to that point divided by total move-\nment over the course of the animation.\n\nIf a foot does not move at all during the animation, or if there is insufficient total\nmovement (and so the rate of tweening would be too fast), then we can choose either\nto allow some foot-sliding for that animation or allow the modifier to remain at the\nend of the animation without being eased out completely.\n\nBecause the feet will move slightly as a result of error accumulation down the\nskeleton hierarchy and/or because of error in the original motion capture, it helps to\nset a threshold for foot movement and ignore any movement below that threshold.\n\nApplication: Locomotion to\n\naR ONO)\n\nan Arbitrary Target\n\neR ES REAR TATOO\n\nFor the problem of locomotion to an arbitrary target, we need the animation to be\nunmodified at the start, but uniformly offset at the end. By applying an offset at the\ncharacter origin, we already bring the feet and legs to the correct position by the end\nof the animation. However, to apply our framework to this problem, we need some\nway to apply this offset at different times for each foot.\n\nThe solution is to keep track of three tween ratios.’ A straightforward, ramped\ntween ratio controls a global offset applied to the character origin. Tween ratios,\ndetermined from the movement profiles of the feet, keep track of the desired amount\nof offset at each foot. A modifier is then applied at each leg to correct the difference\nbetween the tween ratio already applied by the global modifier and the desired tween\nratio for that foot. Figure 4.9.5 shows how this would apply to the two-step anima-\ntion in Figure 4.9.4. Halfway through the animation, the global tween ratio is 0.5; the\nleft foot has finished its step and therefore should be at 1.0, and the right foot has not\nmoved yet, so it should be at 0.0. To correct the positions of the feet, the left leg needs\nto be modified by 0.5 and the right leg by —0.5.\n\n400 _Section 4 _Graphics\n\nseatsioisentoutanretanon i eons nm eR SenSneeeeeeeeeenaribNRLREADR NERIND ONAN TOR HHA RRS catennce tpn eect\n\nFIGURE 4.9.5 Correcting a global modifier. The arrows show modifications applied to a\nskeleton at different points in a two-step animation. The skeleton in gray shows the\nsituation halfway through the animation.\n\nA rotational or translational modifier will need to be set up as required to create\nthe same effect as the global modifier, when the modifier is applied with a positive\nvalue, or to cancel that effect when the modifier is applied with a negative value. If the\ncharacter origin is at the hips, then a rotational modifier can simply rotate the leg by\nchanging the orientation of the hip joint. A translational modifier will be more\ninvolved, and we have some choices about how to implement this.\n\nTranslational Modifiers\n\n_SeRSUSUREAA Tr mctuannineIRRRR RERUNS EBA EU PR RN\n\nA translational modifier for a L foot needs to apply an offset to the position of that foot\nand set up the rest of the leg appropriately, without affecting the position of the hips.\nThis is a classic problem for inverse kinematics (IK) (see, for example, [Tolani00]).\nWith an IK approach, a set of constraints is solved for the leg, with the goal of putting\nthe foot in the desired position. We have to take into account the possibility that the\nIK can fail. In this case, we could put the foot at the closest position that we can\nachieve within the given constraints. Figure 4.9.6a shows a required offset for the\nfoot. Figure 4.9.6b shows how an IK solution might achieve this offset as a combina-\ntion of rotations at the joints.\n\nA simpler alternative is to point the ankle in the desired direction by rotating the\nhip joint and then apply scaling to the leg to bring the ankle to the correct position,\nas shown in Figure 4.9.6c.\n\nAt first glance, the IK solution looks better because it maintains skeletal con-\nstraints correctly throughout the animation, but there are some problems with this\napproach. A straightforward IK solution does not take into account the need for con-\nsistency across frames. Small changes in the position of the IK target can lead to big\n\n4.9 A Framework for Realistic Character Locomotion 401\n\n\\ a _ __ e\n(A) (B) (C)\n\nFIGURE 4.9.6 Transform modifiers. (A) The required offset. (B) Rotations at joints\nfound by inverse kinematics. (C) A simpler approach rotates the whole leg and then scales\n\nto fit.\n\nchanges in the position of the leg and inconsistency between frames. These inconsis-\ntencies between frames can result in unnatural animation.\n\nThe most important constraint for consistent animation is that the modifier\nshould have a very small effect on the leg for a small offset. In order to enforce this\nconstraint in the IK solution, we need to reformulate the problem for IK. We can\nredefine the problem and find a modification to the angles in the leg in order to\nachieve an offset to the position of the foot. Unfortunately, there is no guarantee that\nthe position of the leg in the original animation conforms to the constraints of our IK\nin the first place.\n\nIn practice, the simpler approach is recommended (applying a single rotation at\nthe hip and then scaling). This gives us smoother animation and an acceleration at\neach point in the leg that corresponds better to the original animation. For a small\noffset, we are guaranteed a small modification. The angle at the knee is also preserved\nwith this method. Because we do not enforce constraints at the hip, however, the\nskeleton can get into some strange positions; and while using a small amount of scal-\ning on the leg will not be noticeable, any significant amount will look very odd. For\nthese reasons, we should try to avoid using large values for modifiers and also try to\navoid leaving modifiers on characters when they are stationary.\n\nSometimes, even a small amount of scaling can mess up the skinning. One trick\nwe can use as an alternative to a simple scaling is to stretch the leg along the direction\nof the bones without scaling in the other directions.\n\n402 Section 4 Graphics\n\nApplication: Transitions\n\nRRR REREAD HERE ORR ORI RARER CARER THS REARS DARREN MSE AES\n\nWe can apply the same framework for transitions between animations. By using sepa-\nrate modifie ach leg, we can eliminate problems resulting from changing the\ntween ratio while a foot is supposed to be stationary. However, applying a modifier to\nthe angles of the legs while the character origin is moving will still cause problems at\nthe feet.\n\nThe solution is to use an ‘anchored modifier.’ This essentially does the same thing\nas the translational modifiers previously discussed, but also affects the orientation of\nthe foot. Instead of specifying an offset, we specify a target position for the foot in\nworld space (or in the character's local coordinate system, if that does not change as\nthe animation plays). The target position for the anchored modifier is the position of\nthe foot at the end of the previous animation. Assuming that the foot is correctly\nplaced with respect to the ground at that point, the modifier will ensure that the foot\nremains correctly placed with respect to the ground until that foot starts moving. As\nsoon as the foot starts moving, the modifier can be eased out.\n\nAn anchored modifier will ensure that the position of the feet corresponds to the\nend of the previous animation, but it does not do anything about the rest of the leg.\nEven if the hip and the leg do not move across the transition, if the position of the leg\nin-between those points does not match up across that transition, then the animation\ncan still appear jerky. We can solve this problem by simply applying spherical interpo-\nlation to the leg as before, but with the anchored modifier applied to the result of that\ninterpolation.\n\nseeiesesnmmmen\n\nFurther Details\n\nRRNA NINERS ee Sete tec A HR RH LAR A RN NS MI SE RRS NANA RUAAERAOT ERATE A NNO\n\nSingle-Step Animations\n\nIn a two-step animation where both feet move over the course of the animation, we\nget the chance to ease out modifiers on both legs while the animation is playing. Tran-\nsition modifiers enable us to generalize the technique also to single-step animations.\nAny modifiers not eased out by the end of an animation will be dealt with by modi-\nfiers at the start of the next animation.\n\nKeeping Characters Moving\n\nIn order to make characters look alive, we must keep them moving. We can use a col-\nlection of moving-on-the-spot animations to avoid characters standing completely\nstationary. If these animations include moving the feet slightly, then this gives the ani-\nmation system a chance to ease out any remaining modifiers.\n\nThe player will most likely notice irregularities in a character’s posture when that\ncharacter comes to a stop. Therefore, it is a good idea to ease out any modifiers when\na character stops. If there is a pause key, then the same concerns apply for paused\naction.\n\n4. ‘Oo A Framework for Realistic Character Locomotion | 403\n\nLimiting Modifiers\n\nDegenerate captures, which are a long way out of stance, can result in modifiers with\nlarge values. Sequences of animations over which a given foot does not move at all can\nresult in the errors at transitions getting built up into large modifiers. It is a good idea\nto limit the range of values that can be applied through a modifier in order to prevent\nstrange effects in these kinds of situations.\n\nConclusion\n\n_ stamens esata mame et ea SRI RR i Ae ASTER SSE NR NN HE OR ROR RE\n\nIn order to solve problems in character locomotion, we often need to modify anima-\ntion. Unfortunately, modifying animation can break the interface between the foot\nand the floor, and can result in unrealistic-looking movement. By using separate mod-\nifiers, and therefore independent tween ratios for each leg, we can apply modifications\nto each leg at a time when the corresponding foot is already moving and avoid prob-\nlems of foot-sliding.\n\nReferences\n\n[Shankel00} Shankel, Jason, “Interpolating Quaternions,” Game Programming Gems,\nCharles River Media, Inc., 2000.\n\n[Tolani00] Tolani, Deepak, et al., “Real-time inverse kinematics techniques for\nanthropomorphic limbs,” available online at http://hms.upenn.edu/software/ik/\nikan_gm.pdf, September 8, 2000.\n\nSADDLE ERTS ENG ILL ASSTT NT AL SAT IEE AEDES",
      "page_number": 383,
      "chapter_number": 40,
      "summary": "This gem presents a solution to this problem based on adjusting the position of\nthe feet only when they are already in motion Key topics include animation, animations, and modifier.",
      "keywords": [
        "animation",
        "Realistic Character Locomotion",
        "Character",
        "foot",
        "Character Locomotion",
        "modifier",
        "animations",
        "realistic character",
        "leg",
        "realistic character animation",
        "position",
        "Character Locomotion Thomas",
        "problem",
        "feet",
        "Locomotion"
      ],
      "concepts": [
        "animation",
        "animations",
        "modifier",
        "modifying",
        "modified",
        "character",
        "problem",
        "foot",
        "applying",
        "applies"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 7",
          "chapter": 12,
          "title": "Segment 12 (pages 108-115)",
          "relevance_score": 0.46,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 13,
          "title": "Segment 13 (pages 121-128)",
          "relevance_score": 0.42,
          "method": "api"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 31,
          "title": "Segment 31 (pages 611-631)",
          "relevance_score": 0.42,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 2",
          "chapter": 41,
          "title": "Segment 41 (pages 405-415)",
          "relevance_score": 0.39,
          "method": "api"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 4,
          "title": "Segment 4 (pages 64-82)",
          "relevance_score": 0.39,
          "method": "api"
        }
      ]
    },
    {
      "number": 41,
      "title": "Segment 41 (pages 393-400)",
      "start_page": 393,
      "end_page": 400,
      "detection_method": "topic_boundary",
      "content": "4.10 —_\n\nammable Vertex Shader\n\n404\n\nA Programmable Vertex\nShader Compiler\n\nAdam Lake, Intel Labs\nadam.t.lake@intel.com\n\nhis gem discusses the implementation of a compiler for programmable vertex\n\nshaders. There are many reasons why it is now desirable for graphics program-\nmers to consider compilers for programmable shading hardware. Some examples\ninclude increased readability and greater portability of the programs we write for pro-\ngrammable hardware. As the underlying instruction set changes, we do not need to\nrewrite our shaders. If the shader is written in a high-level language, we need only\nretarget the front end of our compiler to a new code generator for the new instruction\nset. This allows shaders written in a high-level language to be compiled to the shader\nimplementation in OpenGL, DirectX, or an in-house software-rendering library.\nAlso, by writing a shader in a high-level, C-like language, it is easier for us to read and\nwrite new shaders. This makes it easier to make changes to your shaders library.\n\nThe CD-ROM includes a full implementation of a simple vertex shader com-\npiler. It also contains documentation on how to create a workspace for building com-\npilers and an example that compiles the OpenGL lighting equation into a DirectX\nvertex shader! To give a practical foundation to this gem, we are focusing on the ver-\ntex shader implementation in DirectX8. Future implementations might vary, but the\nframework and infrastructure we provide should still be applicable.\n\neiprmamaaRBRETIe\n\nA vertex shader is a program that takes the standard lighting equation parameters, such\nas color, position, normal, and texture coordinates (known as the vertex stream), as\ninput and computes the final values that are submitted for rasterization. Material and\nlight parameters are sent to the vertex shader through a set of constant registers that\ndo not change while a specific vertex stream is being processed by the vertex shader. A\nwidely used vertex shader implementation, DirectX8, has 96 constant registers, 12\ntemporary registers, and 16 vertex registers [Microsoft00] (see Figure 4.10.1). The\noutput of this program (the final vertex properties) are loaded into a set of output reg-\n\n4.10 Programmable Vertex Shader Compiler\n\n405\n\nVertex Registers\n(16)\n\nVertex Program -! Temporary Registers\n(128 instructions) = tex) (12)\n\nConstant Registers\n(96)\n\nOutput Registers\n(5)\n\nFIGURE 4.10.1 DirectX8 shader architecture. There are 16 registers for vertex data, 96\nfor constants, 12 temporary registers, and 5 for output. In DirectX8, there is a limit of\n128 instructions per vertex program. Temporary registers are the only registers that are\nread/write.\n\nisters that, after transformation and lighting calculations have been performed by the\nvertex shader, are passed to the pixel shader for final display. All registers are four-\ncomponent vectors. Individual elements can be referenced in an individual instruc-\ntion using x, y, z, and w as accessors of the elements. We will not cover pixel shaders\nin this gem, but more information can be found in the References.\n\nAs previously mentioned, the vertex shader program utilizes a set of assembly\ninstructions along with the values in the input registers to compute values to the out-\nput registers. Mathematical operations such as add, mult, max, and min are supported,\nas well as a set of higher-level assembly instructions, such as dp3, dp4, logp, and dst.\n([Microsoft00] and [Microsoft01] offer a detailed instruction set.) An example assem-\nbly program is given in Listing 4.10.1.\n\n406\n\n_Section 4 Graphics\n\nListing 4.10.1 A cartoon vertex shader in vertex shader assembly\n[Lake01].\n\noe Ha BRAT Epa eeeninee pe eamNRNee te NNR ER RRMA\n\nVertex Transform\n\nrN is a temporary register\n\nvN is a vertex register\n\ncN is a constant register\n\noPos and oTo are output registers\n\nee ee ee ee\n\nTransform to view space\nm4x4 rg, vO, c8;\n; Transform to projection space\nm4x4 r10, r9, c12;\n; Store output position\nmov oPos, r10;\n’\n\n3; Lighting calculation (N.L dot product)\n\nt]\ndp3 oT0.x, c20, v3;\n\nThe Compiler\n\niH oS RRA RRR HERR\n\nrari RE OR RRO BORE NE LB MANNE\n\nThe compiler consists of six key components. It will translate the high-level language\ninto a lower-level instruction set. We introduce each here and go into greater detail in\n\nlater sections (see Figure 4.10.2).\n\nSymbol Table—Contains keywords and variables used in the program. Used to\nlook up and store the register to which a variable has been assigned.\nScanner—Works with the parser to accept or reject a program. Builds tokens, or\nsymbols, out of the characters that are passed to the scanner. Passes these tokens\nto the parser and adds new variables to the symbol table. (Lex is short for lexical\nanalyzer. In practice we use flex, the gnu version of Lex, to create our scanner.)\nParser— Works with the scanner to accept or reject a program. Builds statements\nfrom the tokens the scanner passes as input. Uses these statements to create the\nabstract syntax tree. (Yacc stands for yet another compiler compiler [Levine92]. In\npractice we use bison, the gnu version of Yacc, to create our parser.)\n\nAbstract Syntax Tree (AST)—Each time the parser accepts a statement, it adds it\nto the syntax tree. The syntax tree is passed from the parser to the code generator.\nCode Generator—Walks the AST and emits code for the vertex shader based on\ndata in the AST.\n\nTemporary Register Allocator—Manages the temporary register set used by the\ncode generator.\n\nThe compiler we are generating is simple when compared to the complexity of a\n\nstandard compiler, which has support for loops, branches, and extensive optimization\n\n4.10 Programmable Vertex Shader Compiler 407\n\nON THE CD\n\nitnuneseecseeeseusrooneettsoncetraor steak hnee A eeoO EO NOS MAA R m HAN eR\n\n—\n\n| Scanner\n\nFIGURE 4.10.2 We start with a high-level program that is passed to our compiler. First,\nwe use our scanner and parser to determine whether we have a valid program. During\nthis process, we also build a syntax tree and a symbol table. Next, we pass these to the code\ngenerator. The code generator walks the syntax tree and emits a valid vertex shader\nassembly program.\n\nVertex\nShader\nAssembly\nProgram\n\nHigh-Level\nProgram\n\nGenerator\n\nroutines. We could add many enhancements. This is definitely an opportunity for\nfuture work, and you are encouraged to experiment, optimize, and augment the\nexample source code provided on the CD-ROM.\n\nCompiler Components\n\nThe compiler is broken up into seven components: the language, scanner, parser,\nabstract syntax tree, symbol table, temporary register set, and code generation.\n\nThe Language\n\nThe first task is to define the language we are going to compile. Since we are inter-\nested in creating a language that is familiar, we based it on a C-like procedural lan-\nguage model. Eventually, we want to support things like parameter-passing, function\ncalls, and loops; but for the first version, we do not handle these constructs. We would\nalso like to migrate many of the features and keywords into a Renderman-like lan-\nguage in the future. While this is too complicated for the vertex shaders, a real-time\nRenderman language is inevitable in the future of fully programmable graphics\npipelines.\n\nSince vertex shaders do not currently support looping or branching, we do not\nneed to support the syntax for these elements. However, we do have a large set of val-\nues that we would like to utilize in our vertex shader. These are listed in Table 4.10.1.\nEach of these values are considered constant, or nonvarying across a particular mesh\nduring its rendering. We assign each of the values into a specific register in the con-\nstant register set. There is an agreement between the application and the shader that\nthe value will be stored in that particular register, and both the application and the\ncompiler agree on which register this value resides in. For example, in our compiler,\nwe store the light direction for the first light, LightDiro, in constant register 26. The\napplication must put the light direction into this register for the shader, or the shader\n\n408\n\nSection 4 Graphics\n\nTable 4.10.1 Keywords Used in Vertex Shading Language\n\nProperty Keywords\n\nVertex Light Material Output\n\nPos LightDiro..4 MatAmb oPos\n\nNormal LightAmbo. .4 MatDif oColor\n\nTexCoordo. .4 LightDifo. .4 MatSpec oFog\nLightSpeco. .4 MatShininess oTexture\n\nLightPoso. .4\n\nNote: In the example, we do not use the second color channel or the second texture layers that\nare part of the output register set in DirectX8.\n\nwill read bogus data contained in the register. The compiler knows where this value is\nstored by looking up LightDiro in the symbol table and returning the register index\nwhere it was assigned. In our example, this is the method GetRegNumFromName (char\n*name) in the class CTempRegSet. Table 4.10.2 lists the math keywords that are used in\nour vertex shader.\n\nScanner\n\nThe scanner is also known as the “lexical analyzer.” The lexical analyzer works with\nthe parser to determine whether your program can be accepted as input. Again, our\nscanner is simple. We recognize the list of tokens in the symbol table, as well as vari-\nables (strings that are not keywords), punctuation, floating-point numbers, math\noperations, and comments using regular expressions defined in our token list.\n\nThe CD-ROM contains an example in the directory for this gem, (see scanner.l).\nLex is used to build the actual C program that is then compiled to build the scanner.\nDetails of this process are beyond the scope of this gem, but it’s always interesting to\ntake a look at the C file generated, lex.yy.c.\n\nTable 4.10.2 Math Keywords\n\nMath Keywords\ndot3 cos clampTo1 floor normalize negate\ndot4 sin sqrt ceiling maxWithoO\n\nNote: The math keywords are in addition to the +,-,* ,/,*, (, and ) operators. Notice there\nis only support for unary operators. Binary operators would be an obvious addition. For exam-\nple, max(x,y).\n\n4.10 Programmable Vertex Shader Compiler 409\n\nThe scanner has three sections. The first section, denoted by the {% and %} oper-\nators, includes the C definitions that will be necessary for your scanner. The second\nsection, denoted by the %% at the beginning and end of the segment, includes the\nactual rules that the scanner recognizes, from highest to lowest precedence. The final\nsection, after the last %%, is used to insert any C/C++ code that is needed by the rules.\nTypically, these are functions to look up symbols, functions to handle error control, or\nfunctions that handle error reporting.\n\nTo create a lexical analyzer, or scanner, from the file scanner.l, we use the GNU\ntool flex, which is available at [Streett02]. These are not shipped on the CD-ROM\nand need to be downloaded to compile the example compiler.\n\nParser\n\nThe parser works in conjunction with the scanner to accept or reject a program.\nWhile the scanner recognizes tokens, or symbols, the parser accepts or rejects sets of\nsymbols, or statements. For example, the expression AmbientLight = AmbientMaterial\n* LightAmbO is one statement. It is made of six tokens—the variables, the arithmetic\nsymbols, and the semicolon at the end of the statement. As the scanner scans the sym-\nbols, it first recognizes the string AmbientLight as a new variable, adds it to the sym-\nbol table, and passes it to the parser. The parser can find no statement that consists of\njust a variable name, but it has several that start with the variable name, so it goes\nahead and stores it on a stack of symbols. For this example, assume the stack starts\nempty, and we are only trying to recognize this statement. Next, = is considered.\nAgain, this symbol is placed on the stack. Eventually, the entire expression is recog-\nnized as a set of symbols because it matches one of the statements in the language. In\nthis case, it matches the statement Expr T_PLUS Expr. All of these elements are\npopped off of the stack, and the process begins again with the next statement. If the\nprogram is complete, and we are not left with only the start symbol on the stack, then\nwe know that the program has a syntax problem. Similarly, if we are processing a sym-\nbol combined with a stack that has no opportunity to match any of the rules of the\ngrammar, then the program has a syntax problem, and parsing stops. The start sym-\nbol is assumed to be the first symbol in the grammar description of the parser. In our\nexample grammar file, yaccer.c, the start symbol is Program.\n\nThe parser has three sections that are structured similar to the scanner. First, the\nsection between {% and %} contains C-related data structures that are needed in the\naction section of the grammar. Second, between the pair of %% symbols, is the gram-\nmar. The grammar is the set of statements the parser will recognize. Each statement in\nthe grammar has an action section. An action section is C code that describes what to\ndo if the statement is matched. In other words, if the set of symbols on the stack with\nthe most-recently recognized symbol (or token) matches this statement, then take the\nfollowing actions. In our parser, the action is to simply add this statement to the\nabstract syntax tree, as follows:\n\nSection 4 Graphics\n\nExpr: Expr T_PLUS Expr\n{\n\n$$ = new CastNode(\"Expr\");\n\n((CastNode *)$$)->addChildNode(0,(CastNode *)$1);\nCastNode *pNewNode = new CastNode(\"T_ PLUS\");\n\n((CastNode *)$$) ->addChildNode(1,(CastNode *)pNewNode) ;\n((CastNode *)$$) ->addChildNode(2,(CastNode *)$3);\n\n}\n\nIn this example, the first line contains the rule. It says that if two expressions are\nfound with a plus sign in between, then we are to pop these elements off of the stack\nand reduce the stack to the single token, Expr. In addition to this reduction, there are\na set of actions we are to take between the { and } that consist of C code. The $$ refers\nto the left-hand-side token Expr. Each of the subsequent $1, $2, and so forth, refer to\nthe right-hand-side (RHS) tokens from left to right, respectively. Here, we are creat-\ning a new node in our AST and adding children to that node that correspond to the\ntokens on the RHS. The (CastNode *) type cast is necessary because we have declared\neach of these tokens as type void. (For more information, see [Levine92].)\n\nThe preceding description of the scanner and parser are only meant to provide\nyou with enough information for a basic understanding of how these tools are used in\nthe context of the vertex shader compiler. If you are interested in adding symbols,\nchanging their names, or changing their assigned registers, the information presented\nhere should be sufficient. However, any reader interested in doing their own nontriv-\nial modifications to the compiler (adding functionality like type-checking or a more\nsophisticated symbol table) is encouraged to read the how-to manual on Lex and Yacc\n[Streett02]. Another excellent reference is the classic by John Levine [Levine92]. All\nthree should be consulted if you are building your own compiler.\n\nAbstract Syntax Tree\n\nThe abstract syntax tree is the data structure produced by the parser as it validates the\nstatements during parsing. As each statement is determined to be valid, it is added to\nthe AST. When the parsing is complete, the AST is passed to the code generator,\nwhich walks the tree and emits code for each statement in the parse tree. It is consid-\nered an abstract syntax tree because it does not contain all of the syntax elements of\nthe grammar [Aho86]. For example, the semicolons are not stored in the tree because\nthey are not needed to emit the code. In contrast, a concrete syntax tree would keep\nevery token that is parsed.\n\nSymbol Table\n\nThe symbol table stores symbols that are used in the compiler. At startup, it is initial-\nized with all of the keywords and symbols used in the language. As the compiler\nparses the program, new variables are added to the symbol table. If the symbol already\nexists, then a reference to that symbol is recorded in the symbol table (see Table\n4.10.3).\n\nON THE CD\n\n4.10 Programmable Vertex Shader Compiler ; ;\n\n\"Senate REO SN RIN CeO ccc ce\n\n411\n\nTable 4.10.3 A Symbol Table Entry\n\nRegister Pointer\n\nRegister Register Component to next\nName Type Scope Token Type Number (x, y,z,w) Entry\n\"LightDir1\" \"Keyword\" 0 T_STRING eRegTypeConst 37 eRegCompAll NULL\n\nNote: An entry consists of the name of the symbol, the symbol type, its scope, and the token that repre-\nsents the symbol in the scanner. It also contains the register number, type of register, and the specific\n\n’ component of the four-component register once the symbol has been assigned to a register. Finally, we\n\nplace a pointer to the next symbol in the table. An example symbol table is contained in the file CSymbol-\nTable.cpp on the CD-ROM.\n\nTemporary Register Set\n\nFigure 4.10.1 showed that there is a set of temporary registers that we use as our work-\ning set when creating our assembly instructions. We have created a CRegister class\nthat simply marks a register as empty or full. From this class, we construct a CTem-\npRegisterSet class that manages the temporary registers. The types of things we can\ndo to a register are: mark it as full or empty, MarkAsFilled() and MarkAsEmpty();\nrequest a specific register, RequestSpecificReg(); or get the next available register,\nGetNextAvailableTempReg(). This class is used in the code generator.\n\nCode Generation\n\nThe code generator contains the heart of the compiler. The code generator takes in an\nAST that was produced from a correct grammar. It then walks this AST and emits\ncode for each statement it finds. Two alternatives for optimization exist at this point.\nThe first and most obvious is to run different algorithms over the tree; each algorithm\ndoes a different type of optimization. Another would be to output an intermediate-\nlevel language description and run your algorithms on that intermediate language.\nSeveral of these techniques are discussed in [Muchnick97]. The point of this gem is to\nget you started with a working compiler that you can then extend by adding enhance-\nments and optimizations appropriate to your target platform—this is where that cus-\ntomization can begin!\n\nConclusion\n\nTo see the results, compile the example vertex shader compiler with the shader on the\nCD-ROM as input. Now, imagine that you are working on a new shader. Would you\nrather debug the high-level code or the assembly that is generated? There will always\nbe a need to get close to the hardware for certain applications, but having a compiler\nhandy to do the dirty work is probably a better solution in many cases. This compiler\nhas been used to generate shaders successfully for applications using DirectX8. As",
      "page_number": 393,
      "chapter_number": 41,
      "summary": "4.10 —_\n\nammable Vertex Shader\n\n404\n\nA Programmable Vertex\nShader Compiler\n\nAdam Lake, Intel Labs\nadam.t.lake@intel.com\n\nhis gem discusses the implementation of a compiler for programmable vertex\n\nshaders Key topics include registers, compiler, and compiles.",
      "keywords": [
        "Vertex Shader Compiler",
        "Vertex Shader",
        "Programmable Vertex Shader",
        "Vertex",
        "Shader",
        "Symbol Table",
        "Shader Compiler",
        "register",
        "Compiler",
        "Programmable Vertex",
        "vertex shader program",
        "vertex shader assembly",
        "Symbol",
        "Shader Compiler Adam",
        "temporary register set"
      ],
      "concepts": [
        "registers",
        "compiler",
        "compiles",
        "vertex",
        "symbol",
        "program",
        "scanner",
        "type",
        "lighting",
        "sections"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 2",
          "chapter": 43,
          "title": "Segment 43 (pages 424-431)",
          "relevance_score": 0.63,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 1,
          "title": "Segment 1 (pages 1-13)",
          "relevance_score": 0.54,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 1",
          "chapter": 36,
          "title": "Segment 36 (pages 344-351)",
          "relevance_score": 0.52,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 1",
          "chapter": 54,
          "title": "Segment 54 (pages 523-530)",
          "relevance_score": 0.52,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 7",
          "chapter": 59,
          "title": "Segment 59 (pages 567-580)",
          "relevance_score": 0.52,
          "method": "api"
        }
      ]
    },
    {
      "number": 42,
      "title": "Segment 42 (pages 401-412)",
      "start_page": 401,
      "end_page": 412,
      "detection_method": "topic_boundary",
      "content": "412 ; Section 4 Graphics\n\nwith all projects, there are plenty of opportunities for improvement, and we welcome\nany contributions that readers would like to make.\n\nAcknowledgments\n\nLLL M EE LL LITER\n\nNone of this work would have been possible without the support of the management\nof the Intel Labs Graphics and 3D Technologies team (G3D). I’m especially grateful\nto Carl Marshall and Stephen Junkins for continuing to push me that little bit further\nto complete the task and rise to the next challenge. Thanks also to Jeff Lander and\nMike Macpherson for reading early drafts and providing feedback.\n\net ue gg HR re RT RRA NSN NES\n\n[Aho86] Aho, Alfred, Ravi Sethi, and Jeffrey D. Ullman, Compilers: Principles, Tech-\nniques, and Tools, Addison Wesley, 1986.\n\n[Lake01] Lake, Adam, “Cartoon Rendering Using Texture Mapping and Programma-\nble Vertex Shaders,” Game Programming Gems 2, Charles River Media, Inc.,\n2001.\n\n[Levine92] Levine, John, Tony Mason, and Doug Brown, Lex and Yacc, O’Reilly and\nAssociates, 1992.\n\n[Moller 02] Méller, Tomas and Eric Haines, Real-Time Rendering, Second Edition,\nA.K. Peters, Ltd., 2002.\n\n[Microsoft00] Microsoft DirectX 8.0 Software Development Kit, available online at\nhttp://www.msdn.microsoft.com/downloads, 20000.\n\n[Microsoft01] Microsoft DirectX 8.1 Software Development Kit, available online at\nhttp://www.msdn.microsoft.com/downloads, 2001.\n\n[Muchnick97] Muchnick, Steven S., Advanced Compiler Design and Implementation,\nMorgan Kaufmann, 1997.\n\n{Olano00] Olano, Marc “Interactive Shading Language, Language Description,”\nCourse Notes on Approaches for Procedural Shading on Graphics Hardware\n(SIGGRAPH 2000).\n\n[Proudfoot01] Proudfoot, Kekoa, William R. Mark, Svetoslav Tzvetkov, and Pat\nHanrahan, “A Real-Time Procedural Shading System for Programmable Graphics\nHardware,” Conference Proceedings (SIGGRAPH 2001).\n\n[Streett02] http://www.monmouth.com/-wstreett/lex-yacc/lex-yacc.html. Flex and\nbison ports to Win32, including source and documentation.\n\n[Upstill89] Upstill, Steve, The Renderman Companion: A Programmer’ Guide to Real-\nistic Computer Graphics, Addison Wesley, 1989.\n\n[Woo099] Woo, Mason, et al., OpenGL Programming Guide, Third Edition, Version\n\n1.2, Addison Wesley, 1999.\n\n4.11\n\nBillboard Beams\n\nBrian Hawkins, Seven Studios\nwinterdark@sprynet.com\n\nazzling special effects are a key component to the graphical flair of many games,\n\nand an effect that appears again and again is the laser light beam. Beams are used\nfor everything from spacecraft weaponry to magic spells, and solid beams can also be\nused to create structural elements in buildings.\n\nSeveral methods are available for creating a beam effect, each of which has its own\ndisadvantages. The simplest technique uses multiple spherical billboard sprites along\nthe line of the beam. This can require a large number of sprites to create a small num-\nber of beams, and the visual illusion can break down under numerous conditions,\nsuch as during the production of larger beams. A much more economical technique\nuses only a single rectangle rotated around the axis of the beam to face the camera as\ncompletely as possible. This efficiently produces a convincing beam from the side\nview, but the polygonal nature of the beam be $ apparent as the view approaches\na straight-on perspective.\n\nThese two methods can be combined to create a better method that is both effi-\ncient and maintains visual integrity under most conditions. Two triangles are oriented\ntoward the camera to form the endpoints, and two more triangles form the main\nbeam section. The rest of this gem describes in detail the positioning and texture\nmapping of the triangles to create the illusion of a three-dimensional beam.\n\nMatrices\n\nA billboard matrix is determined for each endpoint, given the camera-to-world\nmatrix, and the two endpoints of the beam. An ordinary billboard matrix for a cam-\nera-oriented sprite uses the same orientation as the camera-to-world matrix with a dif-\nferent position. However, for a beam, the billboard matrices should be oriented along\nthe beam’s screen direction. Therefore, the front vector remains the same as the cam-\nera-to-world matrix, but the up and right vectors must be modified. First, a direc-\ntional vector for the beam is obtained from the two endpoints:\n\nB=B, -B,\n\n413\n\n414 so — _— a _Section 4 Graphics\nNext, a directional vector, termed the “eye vector,” from the camera position to\none of the beam endpoints is calculated:\nT\nE= [Mos M3 M,,| ~ Bw\nThen, the cross-product of the eye vector and the beam vector produces a vector\nthat is oriented perpendicular to the beam vector in screen space:\nP=BXxE\nFinally, the normalized cross product of the perpendicular vector and the camera-\nto-world front vector provides the up vector for the billboard matrices:\nT\nF= [Moo Mo M,9|\n_ FXxP\n[Fx P|\nFrom this, the right vector is easy to calculate:\nR=FxU\nNow, the billboard matrices for each endpoint are generated from the orientation\nvectors and the endpoint positions:\nF. U, R, B 1x F. U, R, Bo.\nM, = f U, R, B, and M, = f U, k, B,,\nE, U, R, B lz F, U, R, B 2z\n0 0 0 1 0 0 0 l\nVertices\n\nsmn bin BEARERS BRAM rR ORIN\n\nFigure 4.11.1 shows the two triangles that will form the end caps of the beam,\nwhose radius is specified by S$, once transformed by the appropriate billboard matrix.\nVertices V,, V2, and V; are transformed by Mj, and Vy, V;, and V¢ by M>. Vertices V,,\nV3, V4, and V; can then be used to form the other two triangles that make the beam.\nThe two end triangles will then be camera-oriented, which in turn will cause the other\ntwo triangles to be camera-oriented as well.\n\nA further optimization can be achieved on most modern architectures by passing\nthe triangles as a triangle strip, thus reducing the number of vertices sent per beam\nfrom 12 to 6. For this to work, the vertices are sent in order from V, to V¢, and shared\nvertices must share the same properties. This second requirement is of particular\nimportance when considering texture mapping.\n\nSOARS ASML IMR RE\n\n415\n\nV1(0,s,0)\nV2(-s,0,0) V3(s,0,0)\nVa(-s,0,0) Vs(s,0,0)\nVe(0,—-s,0)\n\nFIGURE 4.11.1 Vertex coordinates before transformation.\n\nSSRRERRRAR RS oRREREH AEN RIOR RMN URRRRRERATT SS\n\nFigure 4.11.2 shows the two main texture mapping alternatives that allow for triangle\nstrip creation. Vertices V, to V¢ are matched up with the corresponding texture coor-\ndinates T, to Ts. When choosing which layout to use, consider the tradeoffs between\nthe two options. The first method, shown in Figure 4.11.2a, matches the actual shape\nof the beam better and therefore suffers fewer graphical artifacts. However, the texture\nspace left is broken into two triangles that might be hard to use for other textures. The\nsecond method, presented in Figure 4.11.2b, is more efficient in its use of texture\nspace, but it achieves this by stretching the texture in such a way that visual artifacts\ncould be introduced in the final image. This problem is not seen in most beams, mak-\ning the second method the preferred choice unless a noticeable visual problem is\nencountered.\n\n416 Section 4 Graphics\n\nter EN EL NEE\n\ncsbnenesnesieunaine eens wininns och ease OM MRE LR DEAN CH\n\nTe(1,1) T.@,1)\n\nTs(,0.5) T2005) $T:(0.50.5)\n\nT:(,0) ' T0.50)\n\nFIGURE 4.11.2 Example texture layout with texture coordinates.\n\nope RRL\n\nThe algorithm presented here provides a generic method of efficiently rendering\nbeams. The performance could be enhanced by tailoring the algorithm to take advan-\ntage of particular architectural features of the platform that is used, while still main-\ntaining the visual effect desired. Let the fireworks begin.\n\n4.12\n\n3D Tricks for\nisometric Engines\n\nGreg Snook, Bungie Studios\ngregsn@microsoft.com\n\nfrome engines are one of the last bastions of two-dimensional graphics left in the\ngame industry. While this gem proposes some 3D methods to enhance what is\nessentially a sprite-based display system, it tries to preserve the essence of sprite-based\ngraphics. While you could simply represent a majority of the game objects with 3D\nmodels to get the same visual effect, the ideas presented here maintain the use of\nsprites by adding a few tricks to make them appear as flexible as 3D models. The con-\ncepts may also be useful in other 3D engines as a replacement for flat billboard sprites\nof as a means to represent distant objects at a lower level of detail.\n\nConsider an isometric game engine where each game object is created in some 3D\nmodeling package. The game world itself is divided into rectangular volumes, which we\nwill call “cells.” Each cell is represented in the game by a single 2D image. These images\nare orthographic projections of the cell contents onto a plane placed at the front of the\ncell (see the projected texture created in Figure 4.12.1). Since we view the game through\nan orthogonal camera, rendering the game world is a matter of figuring out which cells\nare onscreen, and then drawing the image of each cell’s contents at the appropriate\nscreen coordinates. There is no scaling or perspective correction needed to display the\ncells, so our 2D cell projections have completely replaced the original 3D models.\n\nTo move into a 3D, perspective-correct environment, we need to add what our\n2D projections are lacking—depth information. This converts our 2D images into\nsomething approaching a voxel representation. We will look at a few methods to ren-\n\nder these depth-enabled images in a 3D setting.\n\nMoving into the Third Dimension |\n\nents\n\nrae.\n\nThe first step in moving into 3D is to change our rendering method. The most com-\nmon way to draw 2D images within a 3D system is through the use of billboards.\nThese are flat pieces of geometry onto which the individual cell images are texture-\nmapped. If one billboard is used for each of the game cell images, and the scene is ren-\ndered through an orthogonal camera, then the display will look nearly identical to the\n\noriginal 2D version. The billboards have become a replacement to the traditional\n\n417\n\n418\n\nSection 4 Graphics\n\nCell Volume\n\nAlpha layer ~~\nProjec (Depth)\n\nTexture\n\nFIGURE 4.12.1 An orthogonal projection of the original cell contents creates both the\ntexture image and per-pixel depth information, stored as shades of gray in the alpha\nchannel.\n\ndrawing method, yielding the same result. Using a nonorthogonal camera will handle\nall the distance-related scaling and parallax effects, but will immediately show the bill-\nboard’s lack of depth.\n\nTo create the illusion of depth in the billboards, some volumetric data for each\ntexture must be recorded. Remember that each image placed on the billboard cards is\nintended to represent the objects within a certain volume of space. This is essentially\na projection of the cell’s contents onto a plane. Per-pixel depth information can be\nrecorded, representing the distance from the projection plane to the point of intersec-\ntion with the cell’s contents (see Figure 4.12.1). This per-pixel depth information is\nthe catalyst for each of the three methods presented here for creating a volumetric rep-\nresentation from the billboard image. It also proves useful when calculating per-pixel\nbump-mapping information for the texture—a technique that can be used in tandem\n\nwith any of the methods described here.\n\nMethod 1: The More Billboards the Better\n\nThe elevation map method, first described by Sim Dietrich [Dietrich00], is a tech-\nnique that uses multiple billboards to represent a volume of space. Each billboard is\ntextured with a slice of the cell volume, so that together they approximate the original\ngeometry when stacked facing the camera. Dietrich also showed that all the billboards\nin a cell group can be mapped with a single texture containing depth information for\n\nthe cell within the alpha channel of the texture. Using hardware-enabled alpha test-\n\n4.12 3D Tricks for lsometric Engines 419\n\noreeeumoninneneiuneiosbienieasen stesso SaaS AHR\n\nFIGURE 4.12.2 An exploded view of mutltiple-depth slices, texture-mapped on stacked\nbillboards to emulate a solid object.\n\ning, individual depth layers of the cell texture can be drawn on each billboard. This\nallows for the creation of a pseudo-volumetric solid with a few polygons and a single\ntexture (see Figure 4.12.2).\n\nThe desired depth value is placed in the alpha component of each vertex’s diffuse\ncolor. Using a subtraction operation within the texture stage, this value is subtracted\nfrom the alpha channel of the texture sample. The hardware is set up to perform an\nalpha test to reject pixels that are less than zero after the subtraction operation. This\nensures that only those portions of the texture that have a depth value higher than the\nvalue set into the vertex color are drawn.\n\nIn DirectX8, the setup is just a few simple render and texture states:\n\nSetRenderState(D3DRS_ALPHATESTENABLE, TRUE) ;\nSetRenderState(D3DRS_ALPHAREF, 0) ;\nSetRenderState(D3DRS_ALPHAFUNC, D3DCMP_GREATER) ;\n\nSetRenderState(D3DRS_ALPHABLENDENABLE, TRUE) ;\nSetRenderState(D3DRS_SRCBLEND , D3DBLEND_ ONE);\nSetRenderState(D3DRS_DESTBLEND , D3DBLEND_ZERO);\n\nSetTextureStageState(0, D3DTSS_COLORARG1, D3DTA_TEXTURE) ;\nSetTextureStageState(0, D3DTSS COLORARG2, D3DTA_DIFFUSE) ;\nSetTextureStageState(0, D3DTSS COLOROP, D3DTOP_SELECTARG1) ;\n\nSetTextureStageState(0, D3DTSS_ALPHAARG1, D3DTA_TEXTURE) ;\nSetTextureStageState(0, D3DTSS_ALPHAARG2, D3DTA_DIFFUSE) ;\nSetTextureStageState(0, D3DTSS_ALPHAOP, D3DTOP_SUBTRACT) ;\n\n420\n\nON THE CD\n\nSection 4 Graphics\n\nDepending on the camera type used to view the scene, it might be necessary to\ndraw the cell from some wide angles. The elevation map holds up quite well in these\nsituations, but might begin to show silhouette artifacts as the viewing direction\napproaches a parallel angle to the billboards. To account for this, additional angled\nbillboards can be added to handle the wider viewing angles. Because the desired depth\nvalue for each billboard is encoded into the diffuse color of its vertices, Gouraud shad-\ning between the vertex colors allows for the slice to occur on just about any angle\nneeded.\n\nAnother drawback of the elevation map technique is that it deals with depth as a\nheight map. Only one height value is used per pixel to define the image volume, giv-\ning the resulting object an extruded appearance when viewed from an angle. To help\nalleviate this problem, a second depth map can be used to define the rear of the\nobject, giving us two values per pixel: one to define the depth value at the front of the\nobject and one to define the back.\n\nThis is created in the same manner as our current depth texture using a camera\nplaced on the opposite side of the cell volume. During rendering, a pixel shader can\nbe used to perform a second subtraction operation, this time using the depth infor-\nmation in the second texture. If both subtraction operations provide a positive result,\nthe point in question is between the front and back depth buffer values, and is output\nto the screen. If either subtraction operation is negative, the point is either in front or\nin back of our object volume and is rejected. The sample application included on the\n\nCD-ROM shows this technique in action.\n\nMethod 2: Warping Textures\n\nWhile not the fastest method for representing a cell’s contents on a billboard, proce-\ndurally warped relief textures do provide the benefit of no additional geometry. What\nthey suffer from is a preprocessing step to warp the billboard texture each time the\nviewing angle changes. Because this can be somewhat costly in terms of performance\nand requires a discrete texture for each cell, it is only useful for unique objects in the\ngame. However, single-instance objects, such as the player’s character or boss mon-\nsters, can get a strong sense of depth from relief textures.\n\nThe notion of relief textures is borrowed from Manuel Oliveira and Gary Bishop,\nwho developed the technique at the University of North Carolina at Chapel Hill\n[Olivera99]. The idea is based on the fact that the texture contains per-pixel depth\ninformation for the cell, which can be reprojected onto the billboard plane to emulate\nanother viewing angle. Given a camera position, each pixel in the texture can be off-\nset to a new position on the texture, given its original texture position and depth\nvalue. The resulting texture, created after all pixels have been offset, describes the cell\ncontents as seen from the position of the viewer (see Figure 4.12.3).\n\nThe trouble is that this is a two-pass operation. Pixels must first be offset along\nthe w axis of the texture, then again along the » axis to locate their final resting place.\nIn the interest of speed, the v-offset operation can often be skipped and still produce\n\n4.12 3D Tricks for Isometric Engines 421\n\nON THE CD\n\ndepth value { view vector\n\nbillboard\n\noriginal pixel — offset pixel\n\nFIGURE 4.12.3 Viewed from above, this diagram shows the reprojection of a pixel onto\nthe billboard plane. The offset location is calculated from the original pixels (x, y)\nlocation on the billboard and the depth information encoded into the texture’ alpha\nchannel.\n\na believable result. The nature of most isometric game objects (usually tall, thin enti-\nties such as bipeds) and the screen's aspect ratio help to hide the effects of this cheat.\nIn the sample code provided, only the u offset is performed during the texture warp.\n\nWhen performing the w-offset operation, there is the possibility of holes being\ncreated in the image (locations to which no pixels have been offset), and occlusion\nproblems (locations where more than one pixel offset to the same position) might\noccur. To handle occlusion, the texture must be processed in the direction of the pixel\noffset. This ensures that pixels closer to the camera overwrite those further away. For\nexample, if the billboard is located on the camera's left side, the pixels will be offset to\nthe right. In this case, the texture must be processed from left to right to ensure that\npixels closer to the camera (toward the right of the image) overwrite those further\naway. If the billboard is to the right of the camera, the opposite is true, and the texture\nmust be processed in right-to-left order. In the worst case, where the billboard strad-\ndles the camera's view vector, the texture must be processed in both directions,\noccluding toward the center.\n\nHoles are created when two adjacent pixels in the original texture map to two\nnonadjacent positions after the warp is performed. In these cases, the desired view of\nthe object is from an angle not accounted for in the original orthographic projection\nof the depth values. A suitable result can still be obtained by performing a blend\nbetween the two separated pixels to fill the gap.\n\nThe final result yields a texture that is properly warped for the given viewing\nangle. This texture can then be mapped directly on the billboard for display. The sam-\nple program provided on the CD-ROM shows this technique in action.\n\n422\n\nSection 4 Graphics\n\nMethod 3: Vertically Interlaced Textures\n\nThe final method presented here builds off of the relief textures used earlier. Using the\nprogrammable pixel shaders in Direct X8 (or greater) on suitable hardware, a blend\nbetween prewarped versions of our texture can be performed during rendering. This\nwill emulate various viewing angles.\n\nThink of the texture mapped across the billboard as a sheet of paper riddled with\npinholes, through which the cell contents can be seen. Each texel is a pinhole, and the\ncolor placed there is what is seen though the hole. What the relief textures do, in a\nsense, is compute what would be seen through the pinholes at various angles.\n\nIn this final method, a texture is created that contains four views of the cell con-\ntents interlaced as vertical strips. Using a pixel shader and a second utility texture, the\ninterlaced strips are blended on the GPU. This provides nearly the same quality as the\nrelief texture method, without the need for a procedural texture warp. The downside\nis that some texture resolution is lost along the x-axis of the texture in order to pack in\nthe various image samples. For every pixel in the original image, there must instead be\na horizontal sample set of four pixels, one for each viewing angle. This method can\nalso extend into the v-axis of the texture, but at the cost of more texture resolution\n(see Figure 4.12.4).\n\nThe pixel shader is built around the bump environment map instruction\n(texbem). It works in two basic steps. First, it converts the incoming (u,v) coordi-\nnates, pointing them to the start of the desired sample set. Second, it offsets the new\nu coordinate to the desired viewing angle within that set, using the texbem instruc-\ntion. The result is a per-pixel blend between two of our four viewing angles, packed\ninto the texture.\n\nThe first step of the shader uses the utility texture mentioned earlier. This texture\ncontains a lookup table that converts our incoming wv coordinate pair to the start of\n\nTextureA TextureB  TextureC —‘Textu\nFIGURE 4.12.4 The interlaced texture is created by sampling identical pixel locations in\nthe source textures and organizing them into sample sets of four pixels each.\n\n4.12 3D Tricks for Isometric Engines\n\nON THE CD\n\nReferences\n\n423\n\nthe sample set in the second texture. This texture should be the same width as the\ninterlaced texture and is filled with the value (w*4) for every pixel on the w-axis. If the\nbillboard is given texture coordinates along u from 0.00 through 0.25, then the utility\ntexture will convert the incoming value to the range [0.0, 1.0] in steps that are equiv-\nalent to a four-pixel span within the interlaced texture. This forces each incoming tex-\nture coordinate to point to the start of our four-pixel sample set.\n\nThe second step is to offset this value to select the desired pixel within the sample\nset. This offset value is in the range [0.0, four_pixel_span], which can be calculated in\na vertex shader and written into a second set of uv coordinates for each vertex. The\nfour_pixel_span value is the width, in texture space, of four pixels. This can be calcu-\nlated as 4 divided by the width of the image in pixels.\n\nFinally, the texbem instruction performs the offset from the start of the sample set\nto the desired sample within, resulting in a per-pixel blend of the two closest camera\nviews. Source code on the CD-ROM shows the implementation details of both the\nvertex and pixel shader. Also, Color Plate 8 shows three methods of generating\npsuedo-3D images from a 2D image source.\n\ncena AANA RNR NNR ROUT\n\nWhile no billboard method can fully replace a complex 3D model, these techniques\ndemonstrate that prerendered images can still be used in a 3D environment with great\neffect. With some careful content creation, it is certainly possible to create an object\nthat is nearly indistinguishable from the original model. Whether you wish to update\nan isometric sprite engine or need an easy way to bring more objects into your 3D\nworld, we hope these ideas will prove useful.\n\n[Dietrich00] Dietrich, Sim, “Elevation Maps,” available online at Nvidia's developer-\n\nsupport Web site: http://developer.nvidia.com/docs/IO/1334/ATT/Elevation-\nMaps2.doc, January 2000.\n\n[Olivera99] Olivera, Manuel M. and Gary Bishop, “Relief Textures,” available online\nat UNC's Image-Based Rendering Web page: http://www.cs.unc.edu/~ibr/pro-\njects/RT/RT.html, April 1999.",
      "page_number": 401,
      "chapter_number": 42,
      "summary": "This chapter covers segment 42 (pages 401-412). Key topics include texture, textured, and billboard. Covers method. [Lake01] Lake, Adam, “Cartoon Rendering Using Texture Mapping and Programma-\nble Vertex Shaders,” Game Programming Gems 2, Charles River Media, Inc.,\n2001.",
      "keywords": [
        "Texture",
        "Billboard",
        "cell",
        "depth",
        "Intel Labs Graphics",
        "beam",
        "pixel",
        "relief textures",
        "method",
        "Graphics",
        "camera",
        "Texture Mapping",
        "vector",
        "image",
        "depth information"
      ],
      "concepts": [
        "texture",
        "textured",
        "billboard",
        "pixels",
        "depth",
        "methods",
        "mapping",
        "map",
        "maps",
        "beams"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 2",
          "chapter": 43,
          "title": "Segment 43 (pages 424-431)",
          "relevance_score": 0.77,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 1",
          "chapter": 59,
          "title": "Segment 59 (pages 570-580)",
          "relevance_score": 0.7,
          "method": "api"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 23,
          "title": "Segment 23 (pages 441-462)",
          "relevance_score": 0.66,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 2",
          "chapter": 48,
          "title": "Segment 48 (pages 469-476)",
          "relevance_score": 0.64,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 7",
          "chapter": 46,
          "title": "Segment 46 (pages 443-452)",
          "relevance_score": 0.64,
          "method": "api"
        }
      ]
    },
    {
      "number": 43,
      "title": "Segment 43 (pages 413-421)",
      "start_page": 413,
      "end_page": 421,
      "detection_method": "topic_boundary",
      "content": "4.13\n\nCurvature Simulation Using\nNormal Maps\n\nOscar Blasco, Aside Software\noscar@asidesoft.com\n\noday’s in-game models are still far from being realistic. Prelit textures are the com-\n\nmon way to simulate curvature using low-detail models. Nevertheless, current\nhardware is now capable of calculating per-pixel lighting equations (both the com-\nmon and not-so-common). This gem explains how to perturb the normals on a sur-\nface to simulate the curvature of a denser model by using bump mapping. We will\nenhance the visual quality without losing speed or having to abandon more-tradi-\ntional ways of adding detail (e.g., handmade bumps; see Figure 4.13.1 and Color\nPlate 9).\n\nFIGURE 4.13.1 Result of the bump-mapping process. Left to right: The low-resolution model, the\noriginal model, and two examples of the final result using bump mapping.\n\n424\n\n4. 130 Curvation Simulation Using Normal Maps 425\n\nNormal Maps\n\nBump mapping is a per-pixel process that disturbs the intensity of the light at the cur-\nrent point. This means that we can lighten or darken the pixel that is being rendered.\nIn other words, we can compute the lighting equation on a per-pixel basis rather than\non a per-vertex basis. Equation 4.13.1 shows a simple and common lighting equation\nwith a specular component:\n\ncolor = (n . !) - Surface _ Color + (n . by (4.13.1)\n\nSHURA RRR:\n\none teecRNRSID\n\nIn our case, 7 is stored as a texel in a texture (the coordinates of the vector codi-\nfied as an RGB color), which is called a normal map. The hardware is responsible for\ncalculating the dot product between 7 and / (the same for » dot 4), and then uses the\nresult as a modulation factor for the surface color. Note that / is transformed to local\nspace, and the dot product is done in texture space (more on this later).\n\nOverview of the Process\n\nso or a NR a A NNR\n\nThe curvature simulation algorithm presents a general scheme for obtaining the detail\nof a dense model so that it can be used on a lower-resolution model for real-time ren-\ndering. By modulating the lighting across the low-resolution model surface, we will\nsimulate the captured detail.\n\nThe first model is a dense mesh, which is modeled as if it were going to be used\nfor nonreal-time rendering. A second, similar model has a more reasonable number of\ntriangles to be used for rendering at interactive rates. It also has uv coordinates for tex-\nturing. The low-resolution model does not need to be a simplified version of the\ndense one, which is why this technique is a viable solution. It allows the modeler to\nmodify the low-resolution mesh to fix problems or to simply use another mesh with\nno direct relationship.\n\nAs we said, our objective is to store the detail that is not present in the low-reso-\nlution mesh into a normal map. This is done by capturing the curvature of the origi-\nnal model while taking into account that our low-resolution mesh has a curvature of\nits own. This curvature is defined by the normals on the dense model, so we need to\ncapture those normals and store them into a map.\n\nAt runtime, the generated texture will perturb the normal for each point on the\nlow-resolution mesh. This changes the dot products in the lighting equation (Equa-\ntion 4.13.1) and produces the simulation of curvature. Each texel is perturbed to\nmake the surface seem like the original object at that point (note that our normal map\nmust have a finite size). The algorithm can be outlined as follows:\n\n* Preprocessing\n¢ Computing the map\n¢ Post-processing\n\n426 Section 4 Graphics\n\nComputing the map requires:\n\n¢ Rasterizing each polygon into the map (using the uv coordinates of each vertex).\n* Calculating the perturbed normal at each texel.\n\nPreparing Our Data\n\nERRNO tC RR PORES RRA\n\nWe will need some data before starting:\nFor the high-resolution model:\n\n¢ Normals at each vertex, which are smooth across the model.\n\nFor the low-resolution model:\n\ne A tangent-space basis at each vertex (smooth tangent, binormal, and normal)\n¢ The wv texture coordinates of vertices\n\nThe tangent-space bases are needed to transform the computed normals into tex-\nture space.\n\nIt is easy to see why the object has to be uv mapped; otherwise we would not\nknow how to map the low-resolution mesh map to the texture. (See “Known Issues”\nto explore the common problems related to uv coordinates.)\n\nCasting Rays\n\nNow let’s discuss how to calculate the perturbed normal at each texel. Since the two\nmeshes do not share vertices, we have to shoot rays from the low-resolution mesh sur-\nface and check where they intersect with the dense model.\n\nSander, et al. [Sander] discuss about two ways to choose the direction of the rays.\nThe first and easiest way is to use the normal of the current face (closest-point). A sec-\nond way requires interpolation of the normals along the surface to use as the direc-\ntions (normal-shooting).\n\nAs you can see in Figure 4.13.2, normal-shooting parameterization leads to better\nresults, while closest-point produces more discontinuities.\n\nSR RRND RRR TARR,\n\nClosest-Point Normal-Shooting\n\nhigh resolution model\na ~~\n»\n\nx\nN _W\n\nN\n-\n\nlow resolution model\nFIGURE 4.13.2 Rays traced using closest-point and normal-shooting.\n\n427\n\n4.13 Curvation Simulation Using Normal Maps\n\nFor each ray, once we have shot the ray and obtained the point of intersection\nwith the dense model, the normal at that point is computed using the barycentric\ncoordinates within the triangle.\n\nBarycentric coordinates are an easy way to define a point inside a triangle. Let P\nbe our intersection point defined in object space, and v,, v,, and v, will be the vertices\nof the triangle. We can calculate them as follows:\n\n_ lea-a)r Pa) (4.13.2)\n\n(4.13.3)\n\nw =1-(u+2) (4.13.4)\n\nThe barycentric coordinates are relative to the areas of the subtriangles defined by\nthe intersection point and the triangle vertices (Figure 4.13.3).\n\nThey are useful for collision checking because any property defined per-vertex\ncan be interpolated using u, v, and w. For example, the intersection point is defined\nas:\n\n(4.13.5)\n\nP=u-ytv-ytw-d,\n\nThe steps that we have covered in this section are: First, for each point on the\nlower-resolution mesh, shoot a ray along the interpolated normal and obtain the\nintersection point in a triangle of the high-resolution model. Second, compute its\nbarycentric coordinates so we can interpolate the normal of the high-resolution mesh\nat that point. As you can see, we now have what we are looking for—a normal vector.\nNow we must store it into the normal map.\n\nV2\n\nYo Vy\nFIGURE 4.13.3 Barycentric coordinates are relative to the area of each subtriangle.\n\n428 Section 4 Graphics\n\nsome nenn ondnoloe gla RaINaaeineiuReNSiGrNaRNanineaeaenncots art titrboBbMe nana mame nRRALNE ANN KRaALASI DBE ZT Bes pb BEN neckkeSiter osteo neieakicnetiekineneBhAOBIHIAAEIDESAMWBEEKDDEENKADDEMINRE EIA\n\nFIGURE 4.13.4 The captured normal (H) is converted to texture space (H’).\n\nGetting the Detail\n\nce HE Ha TR RU NORE tee ASH RIAN RGN RS ANNA\n\nSince we chose to evaluate the lighting j in texture space, a transformation of space is\nneeded to use the captured normal (see Figure 4.13.4).\n\nThe tangent, binormal, and normal at any point on the surface form a matrix\n(Equation 4.13.6), which is a transformation from model space into texture space.\n(Equation 4.13.7 is the transformed normal.) T, B, and Nare also called the tangent\nspace basis (Lengyel01].\n\nT Tx Ty Tz\n\nM=|B |=)Bx By Bz (4.13.6)\nN Nx Ny Nz\nx Tx Ty Tz Hx\nH'=|y|=|Bx By Bz lel Hy (4.13.7)\nz Nx Ny Nz Hz\n-Processing\n\nAfter computing the normal rr map, it will still have many empty regions. During ras-\nterization, texture filtering will alter the normals we use, due to these gaps in the nor-\nmal map. We solve this by filling the normal map with a light blue color—RGB (127,\n127, 255) or vector (0.0, 0.0, 1.0).\n\n4.13 Curvation Simulation Using Normal Maps 429\n\nThe blue color is often sufficient, but we can do something else to achieve better\nresults. With an edge-expansion filter, we Can expand the colors of the polygon edges\nin the texture. This will fix any hardware filtering issues.\n\nSave your texture using an image format that does not alter the texels. For exam-\nple, JPEG is not a good idea, since it uses a lossy compression algorithm that denor-\nmalizes the normals.\n\nKnown Issues\n\nLLL AL ALLL LAT TL ATT ES RI BOSRO AR RCT EROTO TIS LOLS ° ePhoaeies\n\nThere are two reasons for problems that we might encounter when using the ray-trac-\ning scheme presented here. One is the uv-coordinates, and the other one relates to\nmissed rays or incorrect intersections.\n\nIf the models have significant differences (e.g., a ray intersects the surface of the\ndense mesh twice), we will get wrong normals. It is important to instruct the model-\nets to avoid such situations (see Figure 4.13.5).\n\nAs for #v coordinates, there are two major problems that need to be addressed:\n\n° Discontinuities in the tangent space bases. This problem is common to any bump\nmapping that computes the lighting in texture space. Doing the lighting in tex-\nture space allows us to change the geometry and still use the same normal map.\nThe problem is that due to the uv mapping, the tangent space bases are not\nsmooth along the model surface, which produces discontinuities in the light vec-\ntor. Doing the lighting in model space completely avoids the problem; although\n\nhigh-resolution model\n\nlow-resolution model\n\nFIGURE 4.13.5 The ray-casting algorithm does not know which intersections are incorrect.\n\n430 Section 4 Graphics\n\natisieiosoooiianteeseee nie kaeinneteargtOnr sii RORA PENCE O/B OEE ERNEED REA ee te EMO\n\nit has a counterpart: If the normals were defined in model space, we would need\nto change them each time the geometry is deformed. However, you can transform\nthe light into the new space defined by the deformed geometry to solve the prob-\nlem. In any event, this all depends on the engine design and quality desired.\n\n° Incorrect mapping. The algorithm has a huge dependency on uv coordinates. The\nobject needs to be well mapped in order to avoid strange results.\n\nAnother Approach\n\n_SaaRUR ae HNERERURRAR ARRREMRU NS RARER RT ANNOTATE IKON\n\nIt is interesting to talk about other approaches for computing the normal map, par-\nticularly when the models have spatial similarities. We will consider that the low-\nresolution mesh was obtained directly from the dense one using some simplification\nalgorithm, and that this algorithm only used the vertices from the original model.\nMoreover, the original model was already uv mapped, or it was added using some\nscheme. With those conditions, we can easily make a direct relationship between the\nmodels for each texel, since they have common vertices (the same 4 coordinate and v\ncoordinate).\n\nThis scheme can be simplified if we do not transform the normals into texture\nspace. Since this is exactly the same as drawing the normals of the dense model\ndirectly to the normal map, we can implement this scheme using 3D hardware raster-\nization. This is very useful if we are able to uv map the model.\n\nConclusion\n\neR\n\nKENSAL LITERATE RL NRA CONNER\n\nThis gem strives to make the algorithm presented as general as possible, though gen-\neralization also implies less accuracy and less speed. By ‘general,’ we mean it does not\ndepend on any relationship between the models. The exact goal was to make an\napproach, which allows the artist to modify the vertices of the low-resolution mesh.\nOther algorithms used to extract the original curvature depend on the fact that the\nmodels share vertices (and their properties, like uv coordinates). A simplification algo-\nrithm that uses edge collapses is often used to obtain the low-resolution mesh from\nthe dense model. The disadvantages of this are obvious: Simplification tends to create\nfaces with no uniform size, and the mesh is hard to unwrap (map with uv coordi-\nnates). Also, if the original objects were already uv mapped, the mapping usually gets\ncorrupted. Nevertheless, there are cases in which you might want to use this.\n\nAfter generating the normal map, we can still add hand-made bumps for small\ndetails; in fact, it is actually desirable to do so. Modeling such details in a dense mesh\nis hard and completely inefficient. The ray tracing will not be able to get the same\nprecision as if we were to add it with hand-made bumps. They can be added to the\ngenerated normal map with simple normal-map combiner code; only a perturbation\nof the normal stored in the texture is needed.\n\n4.13 Curvation Simulation Using Normal Maps 431\n\nFIGURE 4.13.6 Example of a perturbed sphere. The top two images are the original\nobject, the bottom two are the final result using the algorithm.\n\nAcknowledgments\n\nom SRLS IRE ra NN rs ORRIN RSE ARR aS SAR oR RRR enn eA STANCE IRCNS\n\nI would like to thank Julio Cesar Espada for all the models he created (especially for\nthe head in Figure 4.13.1) and for his feedback in using and testing this technique. I\nwould also like to thank Ignacio Castafio for his comments and support.\n\nReferences\n\n‘santo cae aa aR RNIN He RR\n\n[Ebert] Ebert, David S., et al., “Texturing and Modeling: A Procedural Approach,”\n(SIGGRAPH).\n\n[Kilgard] Kilgard, Mark J., “A Practical and Robust Bump-Mapping Technique for\nToday's GPUs,” paper available online at nVIDIA site: http://developer.nvidia\n.com/docs/IO/1329/ATT/bumpmap. pdf.\n\n[Lengyel01] Lengyel, Eric, Mathematics for 3D Game Programming & Computer\nGraphics, Charles River Media, 2001.\n\n[Sander] Sander, Pedro V., et al., “Silhouette Clipping,” SIGGRAPH 2000 Proceed-\nings: pp. 327-334. Available online at http://research.microsoft.com/~hoppe/.\n\nRU HE TR a NPA\n\n432\n\nSection 4 Graphics\n\n[Watt92] Watt, Alan H. and Mark Watt, Advanced Animation and Rendering Tech-\nniques, Addison Wesley, 1992.\n\n[Wynn] Wynn, Chris, “Implementing Bump-Mapping Using Register Combiners,”\navailable online at nVIDIA site: hep developer avdia com/ docs 10/1273/\n\nATT/BumpMapping WithRegisterCombiners.pdf.",
      "page_number": 413,
      "chapter_number": 43,
      "summary": "This gem explains how to perturb the normals on a sur-\nface to simulate the curvature of a denser model by using bump mapping Key topics include normal, maps, and mapping.",
      "keywords": [
        "normal map",
        "Normal",
        "model",
        "Normal Maps Oscar",
        "map",
        "Maps Oscar Blasco",
        "Normal Maps Bump",
        "dense model",
        "low-resolution model",
        "space",
        "low-resolution mesh",
        "mesh",
        "texture space",
        "texture",
        "low-resolution model FIGURE"
      ],
      "concepts": [
        "normal",
        "maps",
        "mapping",
        "map",
        "models",
        "space",
        "point",
        "textures",
        "way",
        "ways"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 1",
          "chapter": 56,
          "title": "Segment 56 (pages 542-549)",
          "relevance_score": 0.52,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 5,
          "title": "Segment 5 (pages 41-49)",
          "relevance_score": 0.41,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 2",
          "chapter": 45,
          "title": "Segment 45 (pages 440-449)",
          "relevance_score": 0.39,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 7",
          "chapter": 43,
          "title": "Segment 43 (pages 404-412)",
          "relevance_score": 0.39,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 7",
          "chapter": 48,
          "title": "Segment 48 (pages 468-478)",
          "relevance_score": 0.38,
          "method": "api"
        }
      ]
    },
    {
      "number": 44,
      "title": "Segment 44 (pages 422-430)",
      "start_page": 422,
      "end_page": 430,
      "detection_method": "topic_boundary",
      "content": "4.14\n\nMethods for Dynamic,\nPhotorealistic Terrain Lighting\n\nNaty Hoffman and Kenny Mitchell,\nWestwood Studios,\n\nnaty@westwood.com,\nkmitchell@westwood.com\n\nurrent rendering technologies enable us to include expansive and detailed out-\n\ndoor scenes in our games, using large numbers of triangles. However, an impor-\ntant part of the visual complexity and appeal of an outdoor scene is due to its lighting,\nnot just its geometry. If the lighting is static, it is simple enough to precompute a\nhigh-quality lighting solution—but what should we do when the lighting changes\ndynamically? This gem will present several methods for producing high-quality, phys-\nically based lighting solutions for terrain under dynamic lighting conditions.\n\nlight correctly. Light is electromagnetic radiation in the\nvisible portion of the spectrum (about 400-700 nm). The most common metric for\nlight is radiance, or light flux along a ray. To understand how radiance is defined, visu-\nalize a small square (area A) centered on the light ray and perpendicular to it (see Fig-\nure 4.14.1a).\n\n(A) (B)\nFIGURE 4.14.1 (A-B) Radiance area A along a light ray and patch Aon the radiance sphere.\n\n433\n\n434\n\nSection 4 Graphics\n\nLight energy continuously passes through this square in all directions and fre-\nquencies. In RGB space, this energy (and any quantity derived from it) is specified as\nthree numbers. This can roughly be thought of as dividing it into three ‘buckets,’\nbased on frequency. At a given point in time, we measure the rate of energy over time\n(light power or radiant flux ®). The amount of flux going through the square depends\non the size of the square, and doesn’t really indicate the amount of light along the ray.\nWe can measure the flux per area at the intersection point p (M = d® / dA, or power\nper area, measured in watts per square meter). However, M includes light going in all\ndirections, not just along the ray—we need to take direction into account. In Figure\n4.14.1b, we see a sphere (radius R) centered on p, and a small patch (area A’) on this\nsphere surrounding the ray. A part of M (which we will call AZ‘) goes through this\npatch—/M' does not depend on the radius of the sphere, but only on the part of the\nsphere’s area covered by the patch. This represents a range of directions and is called a\nsolid angle (w = A' / R, measured in steradians). The quantity of light along the ray is\nthe radiance (ZL = dM' / dw, measured in watts per meter squared per steradian). Radi-\nance is power per projected area per solid angle—the projected area being measured\nperpendicularly to the ray. If we use an area that is at an angle to the ray (e.g., when\nlooking at light reflected from a surface), then a correction factor equal to the dot\nproduct between the surface normal and the ray is needed.\n\nIn outdoor scenes, radiance can vary by six orders of magnitude [Debevec98], but\nmost hardware limits us to a small range of light values. In this gem, we will compress\nall light values into the [0, 1] range. A related issue is the nonlinear relationship\nbetween pixel values and display radiance. The human visual response to light intro-\nduces other issues. We have chosen to ignore these problems and deal only with linear\nradiance values.\n\nAnother important quantity used in measuring light is the irradiance, E. This is\nsimilar to the flux per area, M above (with the same units), except that instead of mea-\nsuring the total of all the outgoing light at a point, it measures the total incident\n(incoming) light. Since this is measured at a surface, the incoming radiance at a point\npis integrated over a hemisphere H(p) that is centered on the surface normal N(p):\n\nE(p)= | 1,(p-V)N(p): Var (4.14.1)\n\nVeH(p)\n\nHere, V is an outgoing unit vector in the hemisphere H(p), L,(p, —V) is the inci-\ndent radiance at p from —V, and dQ is the differential solid angle used for integration.\nThe dot product is the projected area correction factor.\n\nIn this gem, we deal only with Lambertian (diffuse) terrain surfaces. For such sur-\nfaces, the outgoing radiance L, is the same in all directions and is equal to the irradi-\nance multiplied by the color C(p) divided by m:\n\nL,(2) = ov) E(p) (4.14.2)\n\n4.14 Methods for Dynamic, Photorealistic Terrain Lighting © 435\n\n\"ease eniesuunusbonuutesateante xi npisieieeineeeoiiesonieaeatderrasdsn eed doceteecombneetse ASAE SSCS SUSAN (He AORN RNHRanoRsoB ooo DEnNHUD RRB EREDAR ENBEUNEN\n\nThe color is an RGB triple, in which each value is between 0 and 1. A color of 0\nreflects none of the incoming energy in the relevant band of frequencies, and 1 reflects\nall of it.\n\nThe problem we are trying to solve here is the calculation of L,(p) for all the\npoints on a heightfield terrain (at a finite resolution) under changing lighting condi-\ntions. Since the terrain is Lambertian, and we assume that C(p) is known, this is\nequivalent to calculating F(p). For this, we need to know the incoming radiances from\nall directions in H(p). These directions are divided into three groups: those from\nwhich the sun is visible, those from which the sky is visible, and those from which\nother terrain points are visible. We assume that certain data is available at each\nmoment in time: the sun’s position, angular size, and radiance. We might also want\ninformation about cloud positions, and other data. Note also that the sky’s radiance\nmight vary over different parts of the sky.\n\nNow, the directions in which other terrain points are visible pose a difficult prob-\nlem. In order to know the incoming radiance for these directions, we need to first\nknow the outgoing radiance for other terrain points. If the radiance and positions of\nthe sun and sky were static, we could use an iterative algorithm such as radiosity to\nprecalculate a solution, but this is not practical in the dynamic case.\n\nA A Taxonomy of Solutions\n\noT EN SRA HORRENAS RES BSS SM OMAN ARTE TERRERNTRRERARRS\n\nWe will present a range of techniques to solve the radiance calculations. These tech-\nniques will differ in the amount of precalculation and storage needed for the results,\ntheir limitations and assumptions, and how well the outcomes approximate the cor-\nrect results. Most of them require too much precalculation to be usable with\ndeformable terrain (we will note the exceptions). Since there are two sources of\nlight—sun and sky—we can split the problem into a ‘sunlight-only’ subproblem and\na ‘skylight-only’ subproblem. Most of these techniques solve only one of these sub-\nproblems, in which case two techniques must be used and the resulting radiances\nsummed.\n\nSome of these solutions involve calculating light values on the CPU and upload-\ning light maps to the graphics card. In this case, care must be taken so that the CPU\nand bandwidth consumptions are not too high. Since lighting values usually change\nslowly, we can amortize the update over multiple frames. We experimented with mul-\ntithreading for a while; however, we ended up with a single-threaded, double-buffer-\ning scheme that calculated and uploaded chunks of an active texture while using the\nprevious texture for rendering. When the active texture was complete, we swapped\nthe active and rendering texture and started again.\n\n436 Section 4 Graphics\n\n_eeekmarteneeonenmmeibocasinnmennn sige! OI KTM heneecRmcRDSRINENE OHNO tt tra theta SESH issbtetetraoroeeet nanan psec eoeansahiecenrmetas\n\nSunlight: Horizon Angles,\nShadow Ellipses, and PTM\n\nNNN EG : aR\n\n‘sats efeciniauamen natin At tet cea NNN\n\nThe solutions in this section solve the ‘sunlight-only’ subproblem. Most of the solu-\ntions to this subproblem ignore light reflected from other terrain points. Our experi-\nence has shown that as long as inter-reflections are taken into account in the skylight\nsubproblem, the results are acceptable. That said, it is preferable to take sunlight\ninter-reflections into account if possible, and we will show one technique that does so.\nWithout inter-reflections, the sun’s contribution to the irradiance at p is\n\nEx(?)= J Lan N(p): Vea (4.14.3)\n\nVeSN H(p)\n\nwhere S is the set of directions that point at the sun. Since the sun’s solid angle, @,,,,\nis small, then we can assume that the result of the dot product is constant, and we get\n\nEan(P) = Opn(P)@sunZainN (2) * Veun (4.14.4)\n\nwhere V,,,, is the direction to the sun’s center and O,,,(p) the percentage of the sun\nthat is outside H(p) or otherwise occluded at p. The two quantities, which vary\nbetween terrain points, are the dot product and the occlusion factor. To reduce the\ncost of calculating the dot product, we quantized the normals of all the terrain points\ninto a 256-entry normal table in a preprocessing stage. Then, for each frame, we cal-\nculated the dot product between each entry in the table and the current sun vector.\nThis reduced the dot product calculation for each point to a simple table lookup.\nAnother possibility is to use a normal map and dot3 texture blending in hardware.\n\nThere are several methods for calculating the occlusion factor. One of these meth-\nods uses horizon mapping, which was introduced by Max in [Max88]. This idea is\nbased on storing the horizon angles for each point in a given set of directions (see Fig-\nure 4.14.2a). If the sun motion is restricted to an arc that passes through the zenith,\nthen two horizon angles suffice. Given this information, determining whether a point\nis in shadow or not is simply a matter of comparing the angle of the sun to the horizon\nangle in that direction. If the sun angle @ is below the horizon angle g, the point is in\nshadow (0O,,,,(p) = 0). Otherwise, it is not (O,,,,(p) = 1). Soft shadows can be supported\nby tracking two angles for the sun (8,,, and O,or0m> the angles to the sun’s top and bot-\ntom) and comparing both to the horizon angle. If p 2 0,,,, then O,,,(p) = 0. If 9 S$ 4...\ntom then Osun(p) = 1. If Oop > P > Ahorrom> then Osin(P) = (Arop -— P) / 1, where OF is the\nangular diameter of the sun. We have had good results with storing the horizon angles\nas 16-bit fixed-point numbers and doing the calculations on the CPU, as well as stor-\ning them in 8-bit texture channels and performing the calculations in a pixel shader.\nFor efficiency, the direction along which the horizon angles are defined should corre-\nspond to rows in the heightfield array. This will help when calculating horizon angles.\nYou should scan along the heightfield to a fair distance on each side, since hills can cast\nquite long shadows when the sun is at oblique angles. Note that horizon angles must\nalways be clamped to H(p), or errors will result (see Figure 4.14.2b.).\n\n4.14 Methods for Dynamic, Photorealistic Terrain Lighting 437\n\n(B)\n\nFIGURE 4.14.2 (A) Terrain profile showing sun angle ® and horizon angle @. (B)\nHorizon angles must be clamped to H(p).\n\nOf all the sunlight methods, horizon mapping requires the least amount of pre-\nprocessing. It would be possible to handle occasional local changes to the heightfield\n(such as small craters) by recalculating the horizon maps in the affected area and to\nsome distance on both sides.\n\nOcclusion can also be calculated using shadow ellipses, introduced in [Hei-\ndrich00). Here an ellipse is fitted to the set of visible angles from each point. This\nellipse is parameterized using six numbers, which can be stored in two RGB texture\nmaps. Software, register combiners, or pixel shaders can then be used to evaluate sun\nocclusion for each point. This method cannot do soft shadows easily. Its main advan-\ntage over horizon angles is that it can handle arbitrary sun positions. (See [Hei-\ndrich00] for details and [Kautz00] for implementation details using hardware under\nOpenGL.)\n\n438 . Section 4 Graphics\n\nPolynomial texture maps (PTMs), introduced in [Malzbender01], can also be\nused for evaluating sunlight. This is one of the few techniques that can handle terrain\ninter-reflections for sunlight. To create a terrain PTM, first render a series of N images\nof the terrain using a radiosity package, with the sun at several different positions. The\nsun does not need to move in an arc through the zenith as it does in horizon mapping,\nbut it does need to be restricted to a one-dimensional arc. Use a sun color of\nRGB(1,1,1). Then process the resulting NV images into a single PTM. The first step is\nto separate the color and luminance values for each image. Then, fit a quadratic uni-\nvariate polynomial (apx* + a)x + az) to the N luminance values for each pixel, with the\nsun’s position along its arc as the variable. Finally, generate two RGB textures: One\nstores one color value per pixel (by averaging across all images), and the other stores\nthe three coefficients of the per-pixel luminance polynomials. At runtime, the poly-\nnomials are evaluated with the current sun position, either in software or in a pixel\nshader. The result is combined with the color value and modulated with the current\nsun color. (More details on PTMs are in [Malzbender01], and tools for implementing\nthem are available in the download section of the associated Web site. Note that the\npaper deals mostly with bivariate polynomials requiring six coefficients, which is more\ncomplex and expensive than is needed for the purposes of this gem.)\n\nIf lighting conditions depend only on a single variable (like the time of day), it is\npossible to use PTMs to get the full lighting solution. In this case, a separate polyno-\nmial will probably need to be stored for each R, G, and B channel to capture the color\nvariations, requiring nine values per pixel instead of six (three + an RGB color).\n\nSkylight: Radiosity Approximations and Patches\n\n_SegReehaeRStaee aRRRRSeeRaRC enti sin EeRR sete ENN RR\n\nThe solutions in this section solve the ‘skylight-only’ subproblem. First, we will han-\ndle the case where the entire sky is assumed to have the same radiance. This approxi-\nmation is not as bad as it would seem. We have used it with good results. In this case,\nall we need to do is calculate the lighting for our terrain with a sky radiance equal to\nRGB(I,1,1), and then store the result in a RGB texture. At runtime, we multiply this\ntexture with the current RGB sky radiance to get the desired result. The color in the\ntexture will be relatively subtle, since it will result from inter-reflections with the col-\nored terrain. If space is at a premium, the texture could be converted to 8 bit-per-pixel\ngrayscale with a small loss in quality.\n\nIf precalculation time and space are not a problem, then the best way to generate\nthe skylight texture is to use a radiosity package, with the terrain and a hemispherical\ndistributed light source as input. If this is not practical (for time or space reasons, or\nbecause the terrain might change), then there is a useful approximation that can gen-\nerate a very similar result in far less time. Stewart and Langer found in [Stewart97]\nthat in a scene lit by a diffuse hemispherical illuminator, a point p tends to ‘see’ other\npoints in the scene that have a similar radiance value. So, we can assume that for all V\nin H(p), where another terrain point is visible, L;(p, -V) = L,(p). Stewart and Langer\nshowed that the error introduced by this approximation is small. The significance of\n\n4.14 Methods for Dynamic, Photorealistic Terrain Lighting 439\n\nthis is that it breaks the interdependence between different terrain points, enabling us\nto derive a closed-form expression for E(p). Stewart and Langer have derived a closed\nform using horizon angles to determine which directions are covered by terrain. Their\nformulation uses any number of horizon angles. We have had good results with eight\n(which is a convenient number for computation, since it corresponds to the rows,\ncolumns, and diagonals of the heightfield array). Assuming there are eight horizon\nangles (measured from the vertical, and not from the horizontal, as with sunlight) 90,\nD1 Px Oz Po Ds Po and Pz the skys contribution to the irradiance, including inter-\nreflections, at p is:\n\nby Me) (4.145)\n\n1(p) = 5 N(e) . ¥ (2 _ 2281s sin, (° _ sn 28s cos; & sin’ ®\n\n(4.14.6)\n\nAsin; = - a= (i + ) - an( ) (4.14.7)\n4 4\n\nAcos; = cof 2 J = cof 2 (i + | (4.14.8)\n\n(For details on the derivation of Equations 4.14.5—8, see either the original paper\n[Stewart97] or the summary in [Hoffman01].) The horizon angles used here can be\nscanned to a relatively short distance, unlike those used for sun shadows. Of course, if\nyou are already calculating horizon angles for sunlight shadows, there is no reason not\nto use those for two out of the eight angles. Since this technique uses relatively little\npreprocessing, it can also handle occasional minor edits to the heightfield (e.g., small\ncraters) by recalculating the skylight texture in the affected area and a small distance\naround it.\n\nIf assuming a single radiance value for the sky does not produce acceptable\nresults, the sky subproblem can be further broken up into sub-subproblems. For\nexample, the sky could be divided into NV patches, and N skylight textures could be\ncalculated, each one based on the terrain being illuminated only by the relevant patch.\nAt runtime, each of the skylight textures is modulated by the radiance of the relevant\npatch, and the results are summed together. Each of these skylight textures is essen-\ntially a basis function for calculating the final skylight solution. These basis functions\ncan be calculated either via radiosity or by Stewart and Langer’s method ([Stewart98]\nderives the necessary math). Another possibility is to use the method in [Sloan 02],\nwhich can handle very complex skylight distributions.\n\n440\n\nAnimated Cloud Shadows\n\nON THE CD\n\nSection 4 _ Graphics\n\nsco tt tuner atscoeeeh nao Scents tthe BRL eM aR RMT RHONA HEENE SH AEMOOIMOIIBOEE a rome MceLMcREENeEtee\n\nseen nme RRNA\n\nse TR RUS ER\n\nClouds are seldom absent from an outdoor scene, and the shadows cast by clouds are\nequally important to overall realism. Clouds’ shadows are cast onto terrain through the\nocclusion of light from the sun. With increasing cloud density, sunlight is obscured\nmore, resulting in darker areas on the ground. Therefore, it follows that a simple model\nof such shadows can be incorporated into a scene by multiplying the inverted cloud\ndensity with sunlight and oll the result to the sky’s light contribution\n\nE(p) = Egy (9) +[1- D(p)| Euan (4.14.9)\n\nwhere D(p) is the cloud density as aa onto the point p. Strictly speaking, the\nmapping of a cloud to its shadow on the ground is a perspective projection from the sun\nonto the earth's curved terrain at an angle. However, as the sun's distance is very far rela-\ntive to the area cast in shadow, it is common to assume a planar projection. A less accu-\nrate assumption frequently made in the calculation of texture-mapping coordinates for\ncloud shadows is that the sun is located vertically above the terrain. This assumption\npermits optimization by directly applying the ground-plane world-space location (G,,.)\nof terrain vertices to texture coordinates using only scale and bias factors:\n\nuv = G,,, Scale + Offset (4.14.10)\n\nWithout this assumption, a more complex texture projection matrix is required,\nresulting in more cycles per vertex. This per-vertex cost is particularly important with\nterrain meshes, which involve large numbers of vertices. However, when modeling the\nchange in time of day, the sun’s angle should be taken into account in the texture-pro-\njection calculation.\n\nWith the exception of events like storm clouds and twisters, clouds generally\ntravel in a linear direction. So, animating the movement of clouds is reduced to\nupdating texture offsets in the direction of cloud movement. However, care must be\ntaken in the projection to avoid generating out-of-range texture coordinates.\n\nOn the CD-ROM, a DirectX8 PC cloud-mapping sample demonstrates the use\nof vertex- and pixel-shading hardware for the method just described. First, the vertex\nprogram transforms the world-space vertex position to the screen. Doing this as early\nas possible is important in order to permit the graphics hardware to determine\nwhether to reject the vertex through clipping.\n\ndp4 oPos.x, VPOSITION, c[CV_VIEW_PROJECTION_0]\ndp4 oPos.y, VPOSITION, c[CV_VIEW_PROJECTION_1]\n\ndp4 oPos.z, VPOSITION, c[CV_VIEW_PROJECTION 2]\ndp4 oPos.w, VPOSITION, c[CV_VIEW_ PROJECTION 3]\n\nThe terrain’s color texture is mapped as a planar projection and is performed\nusing the world-space vertex position in the ground plane. This is then scaled and\nbiased using the single multiply add (mad) instruction.\n\nmad oTO.xy, VPOSITION.xz, [CV_BASE_TEX_PROJ].xy,\nc[CV_BASE_TEX_PROJ].zw\n\n4.14 Methods for Dynamic, Photorealistic Terrain Lighting\n\nssonneeeneenonenntnenne acacia ananassae cee eR Rae eR EEN NOOO GS AREAS ASN NEON\n\n441\n\nThe sunlight texture is mapped in the same way, but the projection is redone, as\nit is more efficient to recalculate here than to store the result and copy to the output\ntexture register.\n\nmad oT1.xy, VPOSITION.xz, c[CV_BASE_TEX_PROJ].xy,\nc[CV_BASE_TEX_PROJ].zw\n\nNext, the cloud layer is mapped. Again, this is simply a case of scale and bias\noperations, with the addition of the animation of the texture offset.\n\nmad o T2.xy, VPOSITION.xz, c[CV_CLOUD_TEX_PROJ].xy,\nc[CV_CLOUD_TEX_PROJ].zw\n\nThe second cloud layer projection is applied to a fourth set of output texture\ncoordinates in the same way, with alternative scale and bias parameters. Note that the\nonly input stream to the vertex program is the world-space location of the vertex.\nEverything else is generated procedurally from that. This benefits us by reducing the\nbandwidth to the vertex processor (again this is an important concern with high-den-\nsity meshes, such as terrains).\n\nIn the pixel shader, each texture is combined according to Equation 4.14.9 to\nyield the final rendered result. After the texture declarations, the average density of the\ntwo cloud layers is calculated.\n\nadd_d2 AVG_CLOUD_DENSITY, TEX_CLOUD_LAYER_O,\nTEX_CLOUD_LAYER_1\n\nThis is then inverted and multiplied by the contribution from the sunlight texture.\n\nmul CLOUD_SHADOW_LUM, TEX_SUNLIGHT,\n1-AVG_CLOUD_DENSITY\n\nNext, a constant skylight color factor is multiplied by the terrain texture color.\n\nmul SKYLIGHT, TEX_TERRAIN_COLOR, CP_SKYLIGHT\n\nFinally, the skylight contribution is added to the shadowed sunlight factor, times\n\nthe terrain color.\n\nmad OUTPUT_REG, CLOUD _SHADOW_LUM, TEX_TERRAIN COLOR,\nSKYLIGHT\n\nFor this example, the constant sky radiance factor and sun radiance textures were\nstatically pregenerated using Terragen [Terragen01]. They were extracted from Terra-\ngen images using the following methods:\n\n¢ For the color texture, place the sun vertically above the terrain and disable terrain\nshadows.\n\n¢ For the skylight factor, render terrain with a gray surface with sun at an angle, and\nsample the darkest point in the image.\n\n¢ For the sunlight texture, subtract the skylight factor from the above image.",
      "page_number": 422,
      "chapter_number": 44,
      "summary": "A part of M (which we will call AZ‘) goes through this\npatch—/M' does not depend on the radius of the sphere, but only on the part of the\nsphere’s area covered by the patch Key topics include lighting, texture, and radiance.",
      "keywords": [
        "Terrain",
        "Photorealistic Terrain Lighting",
        "Horizon Angles",
        "sun",
        "terrain points",
        "texture",
        "light",
        "radiance",
        "Terrain Lighting",
        "Angles",
        "cloud",
        "Horizon",
        "Photorealistic Terrain",
        "color",
        "point"
      ],
      "concepts": [
        "lighting",
        "texture",
        "radiance",
        "terrain",
        "cloud",
        "area",
        "sun",
        "skylight",
        "angle",
        "shadow"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 8",
          "chapter": 3,
          "title": "Segment 3 (pages 23-30)",
          "relevance_score": 0.43,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 2",
          "chapter": 40,
          "title": "Segment 40 (pages 394-404)",
          "relevance_score": 0.4,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 5,
          "title": "Segment 5 (pages 41-49)",
          "relevance_score": 0.4,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 1",
          "chapter": 57,
          "title": "Segment 57 (pages 550-561)",
          "relevance_score": 0.39,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 1",
          "chapter": 58,
          "title": "Segment 58 (pages 562-569)",
          "relevance_score": 0.39,
          "method": "api"
        }
      ]
    },
    {
      "number": 45,
      "title": "Segment 45 (pages 431-439)",
      "start_page": 431,
      "end_page": 439,
      "detection_method": "topic_boundary",
      "content": "Sect ion 4 Graphics\n\neen Fon ERS\n\n442\n\nThe cloud density texture was generated by hand. This texture could also be used\nto render the clouds themselves.\n\nVideo-Based Solution\n\nstores RN RRR Ua RR ae CURRIER\n\nA brute-force method for generating dynamic te terrain lighting is to render canned\nsequences using an advanced offline rendering tool, then play back the sequence onto\na video texture. Any view-independent lighting effects could be represented entirely\nin the video texture. Certain view-dependent effects, such as fog, might be applied to\nthe video texture with traditional techniques. Furthermore, a novel, detailed bump-\nmap effect can be achieved by applying a lit video texture to the terrain at a smaller\nscale.\n\nWith no time constraints imposed, unlimited complexity could be applied to this\nsolution. However, a serious caveat is the high offline cost of generating video sequences.\nThis time-consuming process must be appropriately budgeted during the develop-\nmental process. With that in mind, the remaining challenge of this technique is the\nefficient playback of video textures in the 3D scene.\n\nPC and console hardwares are moving toward accelerated support for video tex-\ntures in 3D, albeit at a slower pace than vertex and pixel processing. For example, the\nimage-processing unit ([PU) on the PlayStation2 accelerates decompression of mpeg\nframes. However, the path that video data must take via the IPU before reaching\nvideo memory is somewhat convoluted [Hoffman01]. On the PC, such support is\npresently orthogonal to textured geometry support in 3D, although advanced video-\ndecompression hardware has existed for some time.\n\nAn attractive potential hardware solution would be to decompress a video texture\nformat from video memory prior to the pixel shader stage. This would have the ben-\nefits of greatly reduced bandwidth and accelerated decompression.\n\nRENE\n\nNonterrain Objects\n\nA large task to consider when rendering outdoor environments with dynamic lighting\nis the effect of objects, such as buildings and vehicles, on the terrain. Many methods\nexist for rendering general shadows in real-time [Haines01], which can be applied to\nterrain shadows in various situations.\n\nIn one technique, decal shadow texture projection, the texture is pregenerated (or\ngenerated by rendering the shadow to a texture surface) and mapped onto the terrain.\nA slight z-bias is required to avoid z-buffer conflicts when the projected decal mesh\ndoes not match the underlying terrain mesh [McNally99]. This method produces\ndetailed soft shadows, can quickly shadow large numbers of static objects (such as\ntrees), and can easily be integrated with a shadow level-of-detail scheme.\n\nFor dynamic objects, techniques range from drop shadows to stencil- and\nshadow-buffer methods. The choice depends on hardware performance and con-\nstraints. However, the need for fast projection onto an arbitrary terrain mesh is com-\n\neC\n\n4.14 Methods for Dynamic, Photorealistic Terrain Lighting 443\n\nmon among these methods. This can be optimized by assuming an axis-aligned sun\nposition and, in the case of a heightfield, an axis-aligned mesh.\n\nConclusion\n\nLAR IE ORIEL EELS LESTE SE ENE NEET ESTNESTSSLLOES LETS IE DELS DIL IEE EII IBIAS\n\nWe have presented various methods for achieving photorealistic, quality terrain light-\ning under changing lighting conditions in real-time. For an example of photorealistic\nterrain lighting in real-time, see Plate 10. The methods have differing tradeoffs and\ncharacteristics in order to fit different types of games, platforms, and development\npipelines. If you are developing a game with outdoor environments, we hope at least\none of these methods will prove useful.\n\nReferences\n\n[Debevec98] Debevec, Paul, “Rendering Synthetic Objects into Real Scenes: Bridgin:\nTraditional and Image-Based Graphics with Global Illumination and High\nDynamic Range Photography,” Computer Graphics Proceedings (SIGGRAPH\n1998), pp. 189-198.\n\n[Haines01] Haines, Eric, et al., “Real-time Shadows,” GDC 2001 Conference Pro-\nceedings, also available online at http://www.gdconf.com/archives/proceedings/\n2001 /haines. pdf.\n\n[Heidrich00] Heidrich, Wolfgang, et al., “Illuminating Micro Geometry Based on\nPrecomputed Visibility,” Computer Graphics Proceedings (SIGGRAPH 2000):\n\n. 455-464. Also available online at http://www.cs.ubc.ca/~heidrich/Papers/.\n\n[Hoftman01] Hoffman, Naty, et al., “Photorealistic Terrain Lighting in Real-Time,”\nGame Developer Magazine (July 2001): pp. 32-41.\n\n[Kautz00] Kautz, Jan, et al., “Bump Map Shadows for OpenGL Rendering,” available\nonline at http:/ /evww.napi-sb.npe, del ~jnkautz/projects/shadowbumpmaps/.\n[Malzbender01] Malzbender, Tom, et al., “Polynomial Texture Maps,” Computer\nGraphics Proceedings (SIGGRAPH 2001): pp. 519-528. Also available online at\n\nhttp://www.hpl.hp.com/ptm/.\n\n[Max88] Max, Nelson, “Horizon Mapping: Shadows for Bump-Mapped Surfaces,”\nThe Visual Computer (July 1988): pp. 109-177.\n\n[McNally99] McNally, Seamus, “Treadmarks Engine.” Phone conversation available\nonline at http://www.vterrain.org/.\n\n[Sloan02] Sloan, Peter-Pike, et al., “Pre computed Radiance Transfer for Real-Time\nRendering in dynamic, Low-Frequency Lighting Environments,” to appear, Pro-\nceedings of SIGGRAPH2002. Available online at http://research.microsoft.com/\n~ppsloan/.\n\n[Stewart97] Stewart, James, et al., “Towards accurate recovery of shape from shading\nunder diffuse lighting,” EEE Transactions on Pattern Analysis and Machine Intel-\nligence (September 1997): pp. 1020-1025. Also available online at http://www.cs\n-queensu.ca/home/jstewart/papers/.\n\n[Stewart98] Stewart, James, “Fast horizon computation at all points of a terrain with\nvisibility and shading applications,” JEEE Transactions on Visualization and Com-\nputer Graphics (March 1998): pp. 82-93. Also available online at http://www.cs\n.queensu.ca/home/jstewart/papers/.\n\n[Terragen01] Fairclough, Matt, “Terragen.” Software available online at http://www\n\"planetside.co.uk/terragen,\n\n4.15\n\nPhysical Properties of Cube Maps\n\n444\n\nCube Map Lighting\nTechniques\n\nKenneth L. Hurley, NVIDIA Corporation\nkhurley@nvidia.com\n\nCc: maps were introduced to game developers in DirectX7. In 1999, NVIDIA\nintroduced the Geforce 256 and brought cube maps to the mass PC gamer mar-\nket. Until now, they had been mainly used to render shiny objects. However, the cube\nmap can be used in more-interesting ways. This gem will describe some ways to\nencode different lighting conditions as well as other properties within cube maps. It\nwill give a brief overview of the properties of cube maps and how to index into them.\nSome references for fallback methods will also be given. This gem is DirectX-centric,\nbut the same principles can be applied to OpenGL.\n\nSOROS LORRI HRE REET EOBR PA ALY ER TE A LITE\n\nCube maps are represented as six textures in hardware. Each texture represents a side\nof a cube. Normally, code is written so that a reflection vector is used to index into the\ncube map. A three-component vector is then passed into the hardware, which gives\nthe hardware the information needed to pick the correct face and select the uv coor-\ndinates for that face (Figure 4.15.1). The hardware uses the longest component of the\nthree components to select the face. For instance, if the vectors (0.4f, 0.5f, 0.7f) were\npassed into the hardware, it would select the positive z face of the cube map, since 0.7\nis the largest component. The hardware would then use the other two components\n(0.4f, 0.5f) to select the uv coordinates. One difference between cube maps and regu-\nlar texture addressing is that the uv coordinates are signed values, and the texture is\naddressed such that the center of the cube face is uv coordinate (0, 0). Normal texture\nmapping uses the upper-left corner as the (0, 0) uv coordinate.\n\n445\n\n+y Direction\n\n|\n{\n{\n|\n\n—\n\n+X\n\n-x Direction +z Direction +x Direction -Z Direction\n\n+X -Z\n\n-y Direction\n\nI,\n+X\n\nFIGURE 4.15.1 Hardware layout of a cube map.\n\nHow Get Data to/from a Cube Map\n\neveral ways. The easiest way\nto create a .dds cube map file is to use Microsoft's DirectX Texture Tool, which is\nincluded with DirectX8. The following code demonstrates loading a cube map from\n\na .dds file.\n\nLoading cube maps in DirectX8 can be accomplished in s\n\nLPDIRECTSDCUBETEXTURES m_pCloudTexture;\n\nD3DXCreateCubeTextureFromFile(m_pD3DDev, \"cloudtex.dds\",\n&m_pCloudTexture) );\n\nMake sure to use D3DXCreateCubeTextureFromFile and not D3DXCreateTexture-\nFromFile with a LPDIRECTSDTEXTURES pointer, as DirectX8 will accept the call, but\nstrange results will occur upon rendering. To render the selected texture, simply set the\ntexture in one of the texture stages. The following code is a sample of how to do this.\n\nm_pD3DDev->SetTexture (0, (LPDIRECT3DBASETEXTURE8)m_pCloudTexture) ;\n\nAnother way to load the texture is from six individual bitmap files. This requires\na call to D3DXCreateCubeTexture to create the cube map texture and then a call to\n\n446\n\nSection 4 Graphics\n\netna eaatottnacennobnaaiaoaassnemoonbiinsoetinatieeiaitr teeter tena LAE no LRN RHE RARER\n\nGetCubeMapSurface for each face of the cube map. Alternatively, the texture maps can\nbe loaded with one of the D3DXLoadSurface* functions.\n\nRendering with the Cube Map\n\ngc em tt EN RRR sr me RN RT TING BHT EI IIE SAT ESR ROLE BIE TN ARIAT,\n\nSetting up the 3D texture coordinates for a cube map can be done in one of several\nways. Prior to DirectX8, a programmer would use code similar to the following to set\nup rendering of cube maps:\n\nfor( LONG i = 0; i < cV; i++ )\n\n{\n// eye vector (doesn't need to be normalized)\nFLOAT fENX = m_vEyePt.x - pVIn->v.x;\nFLOAT fENY = m_vEyePt.y - pVIn->v.y;\nFLOAT fENZ = m_vEyePt.z - pVIn->v.z;\nFLOAT fNDotE = pVIn->v.nx*fENX + pVIn->v.ny*fENY +\npVIn->v.nz*fENZ;\nFLOAT fNDotN = pVIn->v.nx*pVIn->v.nx + pVIn->v.ny*pVIn->v.ny +\npVIn->v.nz*pVIn->v.nz;\nFNDotE *= 2.0;\n// reflected vector\npVIn->v.tu = pVIn->v.nx*fNDotE - fENX*fNDOtN;\npVIn->v.tv = pVIn->v.ny*fNDotE - fENY*fNDotN;\npVIn->nz = pVIn->v.nz*fNDotE - fENZ*fNDotN;\npVIn++;\n}\n\nThis code calculates the reflection vector on a per-vertex basis and places the vec-\ntor into the 3D texture coordinates that are to be passed to the hardware.\n\nDirectX8 introduced a new method for dealing with cube maps. Vertex buffers\ncan now be set up to use either the fixed function pipeline or vertex and pixel shaders.\nThe fixed function pipeline of DirectX8 is very similar to that of DirectX7. It can be\nset up by specifying texture stage states and render states, with the cube map-specific\nrender states for the fixed function pipeline being D3DRS_LOCALVIEWER and D3DRS_\nNORMALIZENOAMALS. The texture stage state that needs to be considered is D3DTSS_\nTEXCOORDINDEX. For this gem, the D3DTSS_TCI_PASSTHRU texture stage state value is the\nfocus. This instructs the hardware to use the texture coordinates directly without\ntransforming them in any way.\n\nIn DirectX8 and above, vertex shaders can be used to change the normal based on\na rotation. The vertex shader then puts the normal into the output texture coordinate\nthat corresponds to the texture stage where the cube map was selected. The following\ncode snippet demonstrates how to do this.\n\n;transform normal, put into texture coordinate output\ndp3 oTO.x, srcNormal, c[CV_ROTATION_X]\ndp3 oT0.y, srcNormal, c[CV_ROTATION_Y]\ndp3 oT0.z, srcNormal, c[CV_ROTATION_Z]\n\n4. 15 _Cube Map Lighting Techniques 447\n\nEncodin Cloud Cover\n\nES TERE\n\nEncoding cloud cover into a cube map is not as straightforward as it might at first\nappear. Fractional Brownian motion (fBm) and Perlin noise [Perlin85] are used exten-\nsively to create 2D cloud textures. This technique works quite well and allows the reg-\nular textures to tile seamlessly; however, these images cannot be loaded into cube\nmaps without apparent seams. The reason for these seams is that the edges of the 2D\nimage only match with parallel edges. The top and bottom edges will only match with\neach other, but not with the side edges, since they do not tile with the top or bottom\nedges. This poses a problem for cube maps, since all the edges must match in order to\nprevent seams. The solution is to use a 3D fBm or Perlin noise function to encode the\nclouds into a cube map. The following code will do this.\n\nD3DXVECTORS3 tVec;\n\n// now loop through each pixel of the cube map, gathering the fBm\nfor (i=0; i<CUBEMAP_TOTAL_DIR; i++)\n\n{\ndest = m_CubeFacesData[i];\nfor (pos.y=0; pos.y < m_CubeSize.cy; pos.yt+)\n{\nfor (pos.x = 0; pos.x < m_CubeSize.cx; pos.x++)\n{\nGetCubeVector(i, &pos, &m_CubeSize, &tVec);\n*dest++ = fBm(tVec);\n}\n}\n}\na\n// Function: GetCubeVector\n// Description: returns a 3 vector given a from an x,y, face of a cube\n// map\n// Parameters: face = face of cube map to calculate vector from\n// tInfo = x,y, width and height of cube map face texture\n// vecOut = 3 vector pointer for output\n// Returns: pointer to vecOut\n/ /SSesssessssssssssssssrsssssssSssssessssSSSSSS Ss SsSSSSSsSSssSSSSSSss=a=\n\nD3DXVECTOR3 *CCubeMapDoc::GetCubeVector(DWORD face, const CPoint *pos,\nconst CSize *size, D3DXVECTOR3 *vecOut)\n\n{\nfloat s, t, sc, tc;\n\n// move pixels to center\n\n= ((float) pos->x + 0.5f) / (float) size->cx;\nt = ((float) pos->y + 0.5f) / (float) size->cy;\nsc s*2.0f - 1.0f;\nte = t*2.0f - 1.0f;\n\nswitch (face)\n\n{\n\ncase CUBEMAP_POS xX:\nvecOut->x = 1.0f;\n\n_somosrgnmiienrotitremmeicunnensn atin eh ssenctiter thyme anne OE ND RONEN\n\n}\n\nvecOut->y = -tc;\nvecOut->z -SC;\nbreak;\n\ncase CUBEMAP_NEG_X:\nvecOut->x = -1.0f;\nvecOut->y = -tc;\nvecOut ->z SC;\nbreak;\n\ncase CUBEMAP_POS_Y:\nvecOut->x = SC;\n\nvecOut->y = 1.0f;\nvecOut->z = tc;\nbreak;\n\ncase CUBEMAP_NEG_Y:\nvecOut->x = SC;\n\nvecOut->y = -1.0f;\nvecOut->z = -tc;\nbreak;\n\ncase CUBEMAP_POS Z:\nvecOut->x = sc;\n\nvecOut->y = -tc;\nvecOut->z = 1.0f;\nbreak;\n\ncase CUBEMAP_NEG_Z:\nvecOut->x = -SC;\nvecOut->y = -tc;\nvecOut->z = -1.0f;\nbreak;\n\n}\n\nD3DXVec3Normalize(vecOut, vecOut);\nreturn vecOut;\n\nSection 4 Graphics\n\nTo use this cube map for a sky sphere, create a sphere that is representative of the\nworld’s atmosphere and use the coordinates as lookups into the cube map. There is no\nneed to normalize the coordinates, since the lookup into the cube map does not\nrequire a normalized vector. Here is a code snippet for a vertex shader that demon-\n\nstrates this technique.\n\nvs.1.1\n\n;transform position\n\ndp4 oPos.x,\ndp4 oPos.y,\ndp4 oPos.z,\ndp4 oPos.w,\n\n; Output texture coordinates\n\nsrcPosition,\nsrcPosition,\nsrcPosition,\nsrcPosition,\n\nc[CV_WORLDVIEWPROJ_0]\nc[CV_WORLDVIEWPROJ_1]\nc[{CV_WORLDVIEWPROU_ 2]\nc[CV_WORLDVIEWPROJ_3]\n\nmov destTexCoord, srcPosition\n\nAnimating the clouds is fairly straightforward. Using DirectX8, rotate the sky\n\nsphere using a rotation matrix passed into the vertex shader.\n\n4.15 Cube Map Lighting Techniques 449\n\nA side benefit of encoding the clouds in a cube map is that shadows from the\nclouds can be drawn onto the terrain. The alpha can be encoded with the inverse\ngrayscale image of the clouds, minus the sky color. The color can also be obtained in\na pixel shader by taking one minus the color from the original cloud cube map. The\npositions for the terrain are used as indices into the cube map, and the alpha compo-\nnent is used to darken the terrain. This has the added benefit of creating soft shadows\nfrom your preblended clouds with semitransparent edges. The lighting calculations\nfor the terrain, with regards to the sun, could also be altered by using this value. For\ninstance, the light calculation can be blended with half of the alpha channel values,\ngiving the effect of semitransparent clouds.\n\nEncodin Lights in a Cube Map\n\nStatic and dynamic lights can be encoded in a cube map in a number of ways. Infinite\nstatic lights, like the sun, can be prerendered into the cube map using the techniques\ndescribed to index into the cube map. The normal of the vertex is used to index into\nthe cube map and retrieve the light that is rendered into the cube map. This works\nwell for infinite static lights, but not for dynamic lights. Dynamic lighting usually\nrequires multiple texture passes. The idea is to render the moving lights into the cube\nmap by using a 90° field of view and pointing the camera at each side of the cube.\nThe camera position to render from would be the position of the object that is being\nlit. This technique would work well for rendering a scene that had, for example, a\ndisco ball where there could be 100 lights or so in the scene. Rendering the disco\nroom and objects in the room could be accomplished using this technique. The cube\nmaps do not have to be very big for this technique to work convincingly, so keep this\nin mind when calculating the rendering time.\n\nEncoding Diffuse Lighting in a Cube Map\n\nDiffuse maps can also be incorporated into scenes with many lights by using the\nabove code that traversed through a cube map to build the cloud texture. For each uv\ncoordinate on a face of a cube map, a vector 7 (normal) is calculated. For vector n,\nanother vector / (light) is calculated from each uv coordinate of each cube face. These\ntwo vectors are used in a dot product operation to determine the cosine of the angle\nbetween the two vectors. This is the same calculation used in standard vertex lighting.\nIf the result of the dot product is negative, it is safe to assume that vector / is not con-\ntributing to vector m. Otherwise, the result of the dot product is the weighting factor\nthat is used to blend the pixels of the cube map together. The pixels chosen for the\nblending operation are from the uv coordinates that were used to calculate the two\nvectors 7 and /. This, in essence, samples a hemisphere of pixels centered about vector\nn. The cube map in Figure 4.15.2 is the result of this sampling. To use this cube map\nfor lighting, the sample should be gamma corrected, as some range is lost in the con-\nversion into low dynamic range.\n\n450\n\nSection 4 Graphics\n\nFIGURE 4.15.2 Encoded diffuse cube map.\n\nEncoding of a specular map can be accomplished in much the same way as the dif-\nfuse map by following the same guidelines for traversing the cube map and sampling\neach direction as before. Instead of taking a dot product for the weighting of the two\nvectors, take the mth root of the dot product, where is specified as the specular expo-\nnent. Some user interaction will have to occur for this phase, as the specular exponent\nvaries on a material-by-material basis.\n\nEncoding a Day/Night Cycle into the Cube Map\n\nDay/night cycles can also be used with the cloud cube map p by using the technique\ndescribed to create a cloud cube map and only encoding the grayscale portions of the\nclouds. When lighting the sky sphere, clamp the dot product with a value that repre-\nsents the lowest point on the horizon that changes color. The sky color is passed to the\npixel shader as part of the lighting calculation, and, as the sun rotates, the color of the\nsky sphere can be changed by writing the color to vertex memory. As the sun\napproaches the horizon, the sky color can be ramped from blue to orange. After the\nsun passes the horizon, simply ramp the colors, based on time, from orange to black.\nThe nice thing about clamping the dot product is that any color can be picked based\non the clamp value.",
      "page_number": 431,
      "chapter_number": 45,
      "summary": "This chapter covers segment 45 (pages 431-439). Key topics include texture, textured. Video-Based Solution\n\nstores RN RRR Ua RR ae CURRIER\n\nA brute-force method for generating dynamic te terrain lighting is to render canned\nsequences using an advanced offline rendering tool, then play back the sequence onto\na video texture.",
      "keywords": [
        "Cube Map",
        "Cube Maps",
        "Cube Map Lighting",
        "Cube",
        "een Fon ERS",
        "cloud cube map",
        "map",
        "cube map texture",
        "Fon ERS",
        "texture",
        "Graphics een Fon",
        "Map Lighting Techniques",
        "Maps",
        "cube map face",
        "Cube Map Day"
      ],
      "concepts": [
        "texture",
        "textured",
        "map",
        "mapped",
        "maps",
        "light",
        "render",
        "rendering",
        "shadows",
        "video"
      ],
      "similar_chapters": [
        {
          "book": "Game_Engine_Architecture",
          "chapter": 25,
          "title": "Segment 25 (pages 482-502)",
          "relevance_score": 0.66,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 2",
          "chapter": 44,
          "title": "Segment 44 (pages 432-439)",
          "relevance_score": 0.65,
          "method": "api"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 23,
          "title": "Segment 23 (pages 441-462)",
          "relevance_score": 0.65,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 2",
          "chapter": 45,
          "title": "Segment 45 (pages 440-449)",
          "relevance_score": 0.64,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 2",
          "chapter": 43,
          "title": "Segment 43 (pages 424-431)",
          "relevance_score": 0.63,
          "method": "api"
        }
      ]
    },
    {
      "number": 46,
      "title": "Segment 46 (pages 440-447)",
      "start_page": 440,
      "end_page": 447,
      "detection_method": "topic_boundary",
      "content": "4.15 Cube Map Lighting Techniques ; 451\n\nConclusion\n\nsc oeraeeReeR RANA RI i SN TEE NAAN NUE TET CEERI TN INIT RNR ES EERR RE NN ACD ETS MONEE PARR AEERE RE\n\nCube maps can be used for a wide variety of effects besides rendering shiny reflective\nobjects. This gem describes some more-interesting uses for cube maps. Note that\nhardware that doesn’t support cube maps can still take advantage of these techniques\nby using sphere maps or dual-paraboloid maps [Heidrich99]. In this case, the calcula-\ntions will have to be done using texture coordinate generation or using the CPU to\ncalculate the uv coordinates.\n\nThe source code for a few demonstrations of the described techniques can be\nfound on the CD-ROM. An animated cloud cube map over terrain and the diffuse\nlighting (envlight.nvp) code snippet are included. Also, see Color Plate 11.\n\nON THE CD\n\nReferences\n\n[Debevec97] Debevec, Paul E. and Jitendra Malik, “Recovering High Dynamic\nRange Radiance Maps from Photographs,” (SIGGRAPH 1997): pp. 369-378.\n\n[Elias02] Elias, Hugo, “Perlin Noise,” available online at http://freespace.virgin.net/\nhugo.elias/models/m_perlin.htm, January 5, 2002.\n\n[Heidrich99] Heidrich, Wolfgang and Hans-Peter Seidel, “Realistic, Hardware-\nAccelerated Shading and Lighting,” Computer Graphics Proceedings (SIG-\nGRAPH 1999): pp. 171-178.\n\n[Perlin85] Perlin, Ken, “An Image Synthesizer,” Computer Graphics Proceedings (SIG-\nGRAPH 1985): pp. 287-296.\n\n4.16\n\n452\n\nParameters and Procedures\n\nProcedural Texturing\n\nMike Milliger, 2015, Inc.\nmikem@2015.com\n\nrocedural texturing is an area of research that includes topics ranging from\n\nFourier synthesis to stochastic models to creating textures based on chemical gra-\ndients. Darwyn Peachy, in Texturing & Modeling, defines procedural as a way “to dis-\ntinguish entities that are described by program code rather than by data structures\n[Ebert98].” In the context of games and this gem, we are mainly concerned with the\nability to map a texture image onto a surface through mathematical functions.\n\nWhenever discussing procedural texture mapping with artists, almost invariably\ntheir first response is, “So, you are trying to put me out of a job?” All the content cre-\nators can put their sharp objects down; in the end, hand-painted textures will always\nlook better than pure texture synthesis done through the use of programs. Using a\nprocedural system exclusively for a title would not only be inefficient task-wise for a\nbalanced development team, but the system would also be inadequate from an aes-\nthetic point of view. A combination of procedural and traditional methods will\nstrengthen the artwork of a game and make the game environment look more natural.\nNot only can we generate unique, new textures with procedures, we can manipulate\nthe various properties (color, location, aspect ratio, etc.) of pregenerated images. The\ngoal of this gem is to introduce basic concepts for using procedures to manipulate and\nsynthesize images for games and to give simple guidelines for implementation.\n\nsoso\n\nThe creation of a procedural texture requires two elements—a procedure that will be\nused to generate the texture and the parameters that control this procedure.\n\nParameters\n\nParameters passed into generating procedures guide the outcome of the texture.\nManipulating variables in mathematical functions generally creates the variations in\nprocedural textures. Much as an audio engineer mixes sound signals by using a variety\nof electronic processing gear, the visual-effects artist manipulates a variety of signal\ngenerators and processing functions to create a unique texture. Often, we use the\nsame terminology. Signals (or base textures) are generated at various wavelengths and\nare filtered and blended through a variety of controls. Common parameters for pro-\n\n4.16 Procedural Texturing 453\n\nFocusing on Games\n\ncedural algorithms include terms like “frequency,” “amplitude,” and “bias.” However,\ninstead of manipulating sound, these functions are used to manipulate texture prop-\nerties, such as color values and translucency.\n\nProcedures\n\nThe majority of procedural effects used in games have been based on Ken Perlin’s\nfamily of procedural algorithms, known as “noise.” A pseudo-random number gener-\nator (PRNG) is at the heart of most noise procedures, and this randomness helps gen-\nerate natural-looking effects. Noise is the workhorse of procedural textures and the\nmost-applicable and widely used type of procedure for games. There are many deriva-\ntions of noise—value noise, gradient noise, value-gradient noise, lattice convolution,\nand sparse convolution. All of these procedures are variations on the idea of turning\npseudo-random numbers into sources of textures for graphic images [Macri00]. The\nPRNG generates a lattice. A lattice refers to an m-dimensional, smoothed grid of uni-\nformly distributed points in texture space, each containing a random number (float).\nThe spacing of these points determines the frequency. Several sources of noise of dif-\nferent frequency can be combined together. Each of these noise sources (or octaves)\ncan be added together to form a final image using various mathematical methods.\nThese methods are then fine-tuned to create specific effects. For example, Kim Pallis-\nter's gem in Game Programming Gems 2 [Pallister01] explains how to use noise to gen-\nerate dynamic, procedural clouds by summing octaves into turbulent noise.\n\nNoise algorithms are a direct method for the creation of a procedural texture\nsource. Another method for texture generation takes a texture source and evolves it\nover time using an algorithmic procedure. One such procedure is cellular automaton\n[Macri00]. When used to generate procedural textures, an initial texture is divided\ninto a number of discrete samples called “cells” or “texels.” The color at every texel in\nthe image defines the current state of the cellular automaton system. At every itera-\ntion of the procedure, each texel in the texture is modified according to a set of rules.\nThese rules generally involve setting each texel to be the weighted average of a speci-\nfied set of the neighboring texels. Using these simple systems, a great variety of effects\ncan be achieved. For example, setting each cell’s value to be the averaged value of the\nneighbor cells beneath it can simulate a fire effect. At each iteration of the system,\nthe virtual flames in the texture spread upward [Macri00].\n\nIterative procedures, such as cellular automaton, complement direct methods,\nlike the noise functions. For example, a pseudo-random noise procedure can generate\na group of randomly scattered points that can then be used as the initial system state\nfor the iterative algorithm.\n\ns sIEL Romer eT RRE RRR NH RRURR NERA ARRAN ESA ARR INRA MRR RRO\n\nProcedural texturing techniques have been used in a variety of computer graphics\napplications, such as scientific visualization and visual effects. This gem is focused on\nthe use of these techniques in game applications.\n\nSection 4 Graphics\n\nUses of Procedural Textures\n\nProcedural texturing is still in the early stages as far as prime-time game development\nis concerned. Most of the effects in past games have been simple water or fire effects.\nHowever, procedural texturing excels at representations of natural phenomena and\ncan be used to generate textures for wood, marble, snow, grass, stars, or volumetric\neffects, such as clouds [Pallister01]. These are exactly the type of surfaces that are\ncommonly needed in game projects.\n\nA generated texture can be used in a static manner much like any other form of\ntexture. By using the texture-transformation capabilities of modern graphics hard-\nware, the texture can be moved over the image’s surface. A series of textures can be\ngenerated and then played back as an animated texture. This is a common practice in\nmany games. However, a predictable pattern can often be seen on the surface, and\nthe effect is easily spotted when the animation repeats. To some extent, this takes the\nviewer out of the immersion of the game. The real power of procedural textures is\nachieved when the textures are generated in real-time within the game project.\nBecause the procedures are mathematical and with endless variation, repetitive cycles\nare eliminated.\n\nIn addition to their use as color source material, procedural textures can be used\nas bump, diffuse, specular, or dynamic environment maps in multitexture systems. A\nprocedural texture could be used to show cracks or dents in a surface by perturbing\nthe texture space normals using a function. Diffuse mapping with noise can break up\nlarge areas of solid color and show unevenness (large areas of solid color tend to stand\nout and look fake). Fractal terrain is often a noise image used as a heightfield (dis-\nplacement map) on a dense mesh, Many outdoor engines use this technique to gener-\nate the geometry for unique terrain instead of storing all the data. Since the noise\nimage is made by a seeded PRNG, the terrain can be generated again into the same\nshape if the player returns to the same area.\n\nAdvantages of Procedural Textures\n\nThere are many advantages to using procedural textures in your game. The decision\nto use them often boils down to a classic problem in computer science: the trade-off\nbetween computation time and memory size. Even though it takes processor time to\nbuild the texture, there is virtually no memory footprint. Also, procedural textures are\nnot limited by bandwidth constraints. There is no need to continually load and refer-\nence texture memory for pixel colors. Since the texture is regenerated every frame,\nthere is no reduction in the fidelity of the image. This is especially beneficial in first-\nperson games where the view can move extremely close to a surface. A bark texture on\na tree could be regenerated each frame as a player moves toward the tree, increasing in\ndetail as the view moves closer.\n\nWhile most procedures are written in highly optimized assembly code, rendering\nscenes with a lot of different procedural textures will lower the frame rate. We can\nhave a large number of surfaces that utilize procedures in a single level, as long as most\n\n4.16 Procedural Text\n\nring 455\n\nof them are not visible at the same time. It is simple to cull textures that do not appear\non the screen and to skip the calculations. Procedural textures lend themselves to\nreuse, and we can use the same texture for multiple objects, like a fire procedure for all\nthe torches in a hallway. Although procedures are hard to debug, given their lack of\ncontrol and randomness, this can also be the source of pleasant surprises (serendipity)\n[Ebert98]. Even so, procedures can be controlled to some extent by parameters that\nchange the outcome texture rather than being limited to a fixed image.\n\nProcedural textures can be one-, two-, or three-dimensional. Three-dimensional\ntextures serve as new tools for artists and programmers to create effects. A procedurally\ngenerated, three-dimensional texture will allow a plane, intersecting at any angle with\nthe volume (color space), to be textured appropriately and in relation to the rest of the\ncolor space. This technique is also known as “solid texturing.” The color space incor-\nporates the use of a 3D array of color values for texturing, and the textured object is\nplaced within this color space. Destructible environments are becoming more com-\nmon in games, and solid texturing will amplify the reality of objects in the scene. Imag-\nine a pillar mapped with procedurally generated marble getting caught on the wrong\nend of a rocket launcher and blown into large chunks. Not only will the inside of the\nremaining pillar be mapped with the continuous veins of marble, the chunks blown off\nof the pillar will be mapped as well, as long as they are in the color space. Believable\ncaustics and clouds can also be achieved with this technique. Procedural textures have\nno fixed area and can cover arbitrary-size areas without repetitions and seams. To add\ndetail for large areas, increase the number of octaves in the procedure.\n\nGetting Procedural Textures in the Game\n\nThere are two basic types of procedural textures that can be used in your game: real-\ntime and pregenerated. Pregenerated procedural textures can be made in content\napplications such as Lightwave or Photoshop, or in a professional procedural texture\npackage such as DarkTree, and then mapped in the traditional method (losing some\nbenefits of calculating them in real-time). DarkTree allows users to modify parameters\nvisually by piping functions into each other, generating different effects. Results are\ndisplayed in real-time, giving the user instant feedback about the effect. Animated\ntextures can also be saved out on a frame-by-frame basis.\n\nIf you want to implement a real-time procedural system in your game engine,\nthen there are some general heuristics that will be helpful. The first step is to create a\nsolid workflow that is fairly simple. A top priority should be to make it simple for\nnoncoder types. An authoring tool with sliders and an instant previewing window is\nmore than worth the effort of writing it. The key is to allow content creators to con-\ntinue doing what they do best, making art instead of typing arcane parameters in a\ntext editor. The authoring tool should save out the parameters and procedure name\nfor the surface to a shader file; and when the level or area loads, the parameters gener-\nated by the tool are passed into the procedure when drawing the surface. Assign rea-\n\n456\n\nHardware Acceleration\n\nSection 4 Graphics\n\nsonable defaults to surfaces that can be overridden if values exist for the surface\ndescription.\n\nIn the future, games can look forward to a more Renderman-like environment for\ntexturing and shading. Most game engines already have, or are moving toward, shader\nsystems. A standardized, shading language for games would allow a clean method for\ndefining parameters and applying functions to materials.\n\nOther Uses for Procedural Functions\n\nWhile this gem mainly focuses on image synthesis, most procedural techniques can be\nextended to other aspects of game development. We have already discussed using\nnoise to make terrain. When it comes to animation, a user could apply noise to IK-\nbased death animation so that several bad guys that die in the same room do not end\nup in the same death pose. When using morph targets, add a noise weight to the ver-\ntices in order to get different results, such as random blinking or variable tail flips on\ndolphins. Perlin has demonstrated the use of noise for generating facial expressions\n[Ebert98]. Procedural modeling is an increasing area of interest for game designers,\nespecially for memory-challenged architectures. Trees and their branches could be\nprocedurally spawned, resulting in a variety of vegetation without the need to store\nmassive amounts of geometry.\n\nsrr RSE SRR ARAN LRH A TORSIIAT AAAI AOI INE\n\nCalculating the texture during runtime on a per-pixel basis takes a lot of computa-\ntional time. Having the majority of per-pixel work done by the graphics hardware\ninstead of the main processor is one way to offset the computational cost of proce-\ndural calculations. Now, with the latest consumer graphics hardware, we can have\nreal-time procedural textures in games without a large performance hit on the main\nprocessor. If you don’t have the graphics chipset that can handle per-pixel operations\nand coloring effects, then the calculations will take place on the main processor.\n\nThe main issue for real-time generation of procedural textures is the ability of the\ngraphics hardware to render directly to a surface. This can be done with capable hard-\nware using either Direct 3D or OpenGL. As an example, a pseudo-random function\ncan be used to create several source noise textures of various frequencies. These source\nnoise textures can then be combined by rendering them to a surface using the avail-\nable hardware blending and filtering modes. On graphics hardware that supports\nmultitexture rendering, several textures can be combined in a single pass. The results\nof these operations can then be used as a texture that is applied to an object in the\ngame scene.\n\nBeyond this kind of direct, procedural texture creation, it is even possible to cre-\nate iterative cellular automaton system directly in hardware. Using hardware that sup-\nports blending four simultaneous textures, and feeding the results back into the\nsystem, effects such as animated fire and water can be generated [James01].\n\n4.16 Procedural Texturing 457\n\nConclusion\n\nseg aR Saree\n\nsaa\n\nProcedural texturing is a powerful and flexible way to g\nify existing textures. ‘he techniques have not found their way into a lot of games,\neven though procedures would strengthen the artwork of a game. This is mainly due\nto the time necessary to perform the per-pixel operations needed to generate the tex-\nture. With consumer-level hardware now able to perform pixel operations on the\ngraphics chipset, which frees up the main processor, we should see more procedurally\ngenerated effects in future games. There is no doubt that the most popular families of\nprocedures, noise and cellular systems, will be leading the way.\n\nThe included sample demonstration code from Simon Green (NVIDIA) shows\nthe use of graphics hardware to create dynamic procedural 3D textures. It uses a sin-\ngle precomputed 3D noise texture, which is accessed multiple times using the texture\nmatrix to control the frequency and the register combiners to weight and sum each\nlayer and produce the final color.\n\nThe 3D texture is 64xX64x64 texels in size and uses the single-channel ‘lumi-\nnance’ format, and therefore consumes only 256 KB of memory. It is interesting to\nnote that although the period of this texture is relatively small, it is surprisingly diffi-\ncult to see any repeating patterns once the octaves have been combined together. The\nnovel part of this technique is that the noise texture is prefiltered using a cubic filter.\nThis helps avoid some of the artifacts that would occur if we just used a texture with\nrandom texels and let the hardware linearly interpolate between them. It also allows\nus to precompute the absolute function that is needed for the Perlin ‘turbulence’\nfunction.\n\nTo produce the final fractal noise pattern, we use four or more 3D texture\nlookups for the noise texture. Each layer is known as an octave, since the frequency\ntypically doubles each time, just as in a musical scale. We use the texture matrix to\nscale each set of texture coordinates and thereby increase the spatial frequency for each\noctave, but this could also be done easily using a vertex program. Interesting animated\neffects can also be created by translating or rotating the texture coordinates of each\nlayer at different rates. This is much cheaper than actual four-dimensional noise\nwould be. The best results seem to be achieved when the speed of animation for each\noctave is proportional to the spatial frequency.\n\nFinally, the register combiners are used to weight the value from each octave by\nthe correct amplitude and sum the contributions of all the octaves together. Once we\nhave the final (scalar) summed noise value, there are various ways to produce a color\nfrom this. For simple coloring effects, the register combiners can be used to interpo-\nlate between two or more colors based on the noise value, but for more nonlinear pat-\nterns (such as veined marble), we can use a color table. One way to achieve this\ninvolves rendering the scene to a texture, and then in a second pass, drawing a screen-\naligned quad using the dependent_gb texture shader and a one-dimensional texture\nthat maps the noise values to colors. The alpha test function of the graphics hardware\ncan also be used to discard pixels that are above or below a certain threshold, creating\n\n458 Section 4 Graphics\n\ninteresting ‘corroded’ looks. Future programmable hardware will be able to do this\n(and more) in a single pass and provide much more flexible procedural texturing pos-\nsibilities.\n\ni exturing & Modeling, Second Edition, AP Profes-\n\nsional, 1998.\n\n[James01] James, Greg, “Operations for Hardware-Accelerated Procedural Texture\nAnimation,” Game Programming Gems 2, Charles River Media, Inc., 2001.\nDemos available online at http://developer.nvidia.com.\n\n[Macri00] Macri, Dean, and Kim Pallister, “Procedural 3D Content Generation,”\navailable online at http://cedar.intel.com/, February 8, 2001.\n\n[PallisterO1] Pallister, Kim, “Generating Procedural Clouds Using 3D Hardware,”\nGame Programming Gems 2, Charles River Media, Inc., 2001.",
      "page_number": 440,
      "chapter_number": 46,
      "summary": "This chapter covers segment 46 (pages 440-447). Key topics include texture, textured, and procedures. The source code for a few demonstrations of the described techniques can be\nfound on the CD-ROM.",
      "keywords": [
        "TEE NAAN NUE",
        "NAAN NUE TET",
        "NUE TET CEERI",
        "ACD ETS MONEE",
        "ETS MONEE PARR",
        "MONEE PARR AEERE",
        "procedural textures",
        "texture",
        "Procedural",
        "TEE NAAN",
        "NAAN NUE",
        "NUE TET",
        "TET CEERI",
        "CEERI TN INIT",
        "INIT RNR"
      ],
      "concepts": [
        "texture",
        "textured",
        "procedures",
        "procedural",
        "noise",
        "color",
        "games",
        "generation",
        "generate",
        "generating"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 2",
          "chapter": 49,
          "title": "Segment 49 (pages 477-489)",
          "relevance_score": 0.62,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 7",
          "chapter": 62,
          "title": "Segment 62 (pages 601-608)",
          "relevance_score": 0.54,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 1",
          "chapter": 56,
          "title": "Segment 56 (pages 542-549)",
          "relevance_score": 0.53,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 7",
          "chapter": 64,
          "title": "Segment 64 (pages 617-624)",
          "relevance_score": 0.53,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 2",
          "chapter": 50,
          "title": "Segment 50 (pages 490-497)",
          "relevance_score": 0.52,
          "method": "api"
        }
      ]
    },
    {
      "number": 47,
      "title": "Segment 47 (pages 448-455)",
      "start_page": 448,
      "end_page": 455,
      "detection_method": "topic_boundary",
      "content": "4.17\n\nUnique Textures\n\nTom Forsyth, Mucky Foot\n\ntomf@muckyfoot.com\n\nIr the real world, no two surfaces are the same. They have a myriad of tiny differ-\nences—wood grain, surface texture, dirt marks, scuffs, faded paint, footprints, graf-\nfiti, and so forth. Nevertheless, computer games reuse the same textures over and over\nagain. In the past, this was done for practical reasons. Video memory was in short\nsupply, and using a different texture for each surface in a scene would have caused\nexcessive paging in and out of textures, even for static views.\n\nNow, video memory is relatively cheap and plentiful, but there are new problems.\nWe demand higher-resolution textures, which chew memory at a prodigious rate.\nAlso, we are creating such mammoth worlds to play in that no single team of artists\ncould possibly create unique data for every surface, even if there was the disk space to\nstore them all.\n\nMany of these problems can be solved by generating textures in a more proce-\ndural way, rather than relying on the hand of the artist to generate every single texel.\nThe core idea that we will explore in this gem is how to use a relatively small number\nof artist-generated source textures and combine them at runtime using a variety of\nblends, fractal methods, and random numbers to create the textures required for the\nscene.\n\nProcedural Textures\n\nssa ERR Nilen oR,\n\nAs described in Mike Milliger’s gem in this section [Milliger02], the use of procedural\ntextures allows artists to do less actual pixel-pushing, and start generating descriptions\nof classes of surfaces. These descriptions can then be applied to large areas of levels\nand multiple objects in that level. Because the descriptions use pseudo-random num-\nbers for some of their values, each instance will be slightly different in exact appear-\nance, just as they are in real life. The important thing is to allow the artists to take\nback full control at any stage of the process—for certain important items, they will\nwant to lock down a finished article and not have it change in any way. However, for\nalmost all the terrain and scenery in a game world, this rigid control is not necessary.\n\n459\n\n460\n\nSmart Texture C\n\nComposition Model\n\nsnaainccannoranuniiotanenisseunnineninea iulrmelneiiaoiiein® HioKREstiRNNeisoisnehtirm een\n\nBecause each surface’s texture is uniquely generated, each one can adapt to the\ngeometry of the object it is mapped onto. The most obvious benefit is that texture\nseams vanish—continuous textures, such as rock or wood, can flow smoothly and\ncontinuously around any geometry. Artists frequently struggle with conventional\nmethods, and it is hard to hide seams while avoiding excessive texel distortion. Also,\nexposed corners can be scuffed, concealed corners can gather dirt, and surfaces\nexposed to the sun will be bleached.\n\naching\n\nRaa Na RTT AN\n\nSRSA RSENS\n\nAt the heart of a typical graphics system is a texture cache. The graphics system can\nthen composite the various source textures together in cunning ways to create the\nfinal result. In some cases, this composition might be complex and slow, so it is\nimportant to avoid cache thrashing in order to be compatible with ‘dumb but fast’\ncaches (e.g., the Direct3D texture cache).\n\nIf you expect or find the texture cache to be relatively slow, some simple refine-\nments can be made to improve performance. For example, you can work out the\nhighest-resolution mipmap level that will be required for a given texture on an object.\nThis is usually as simple as dividing a constant (calculated offline) by the object’s dis-\ntance and taking the base-2 logarithm. This gives a conservative estimate and assumes\nthat the texture will be viewed perpendicular to the viewer's line of sight. More-\naggressive estimates that take viewer/surface orientation into account can be made,\nbut they are more expensive (for example, on a curved surface, it is likely that some\n\npart of the texture will always be roughly perpendicular to the viewer).\n\nay\n\nThe simplest method is the Photoshop ‘stack’ method—a series of RGBA layers, each\nwith a source texture, composited on top of the last result with a type of blend. How-\never, any useful blending controlled by random numbers requires a more-complex\nsystem based on a tree of blends, not just a single stack. In addition, you are often\nrequired to composite together many alpha channels and then do a color blend using\nthe resulting alpha channel. Since these alpha channel-only blends are common, there\nneeds to be an explicit way of labeling layers and blends as alpha-only to ensure that\nfull 32-bit RGBA textures are not used all the time—thus, ensuring more-efficient\nmemory access.\n\nThe tree model is only required for a tenth of the blends in most cases. We will\nrefer to layers and blends between them, rather than tree nodes and leaves, regardless\nof the internal representation.\n\n4.17 Unique Textures 461\n\nLayer Mapping and Transforms\n\nThe most fundamental aspect of a layer is its mapping onto the geometry. This is usu-\nally determined by the 3D package: either by explicit uv mapping, or by some sort of\nplanar or spherical projection. This includes the layers representing source textures,\nthe intermediate layers, and, most importantly, the target layer—the texture that will\nbe generated by the composition and actually passed to the graphics chip to texture\nthe image.\n\nThe mapping of the source and target layers do not need to have any relationship\nto each other. Frequently, a single source will be mapped over a join between two or\nmore target textures, ensuring a smooth transition between the two. Typically, data on\nsource layers and for mapping will be determined per-vertex rather than per-triangle,\nwhich allows textures to be combined to flow continuously over any surface shape. In\nmany cases, at a particular vertex, some layers will be discontinuous (such as paint\nschemes on walls or vehicles), while others will be continuous (such as dirt or scratch\nmarks). When designing the data structures, it is important to remember that in most\ncases, an object cannot simply be partitioned into different materials with one texture\nper material. Once the composition is done and the target textures are generated, this\nis precisely what happens to the data that is passed to the low-level mesh rendering\nsystem, but this model does not work at a higher level.\n\nIn addition to raw layer uv mapping data, additional data can be held at each ver-\ntex. This data can control aspects of the blends performed and will usually be linearly\ninterpolated between the vertices. For example, the random numbers that control a\nblend might be biased and scaled by values held at each vertex; this way the artist can\nlabel some vertices as more dirty or less dirty, rougher or smoother, and so on. Getting\nthese values into the 3D model is a problem that some 3D packages do not handle\nvery well (vertex coloring is poorly supported, and multiple channels can be even\ntrickier). In some cases, these values might need to be encoded into another texture\nlayer instead and possibly converted to per-vertex values later by a preprocessing stage.\n\nLayers can also have their wv mappings perturbed or determined by various other\nmethods. For example, rotations, scales, skews, and so on are all possible (usually con-\ntrolled by random numbers), as are hard-coded complex methods—for example, a\nbrick wall might be generated by compositing many individual source bricks, each\nbrick taken randomly from a selection of 20 or so. In this case, the source of the brick\nis a random number, quantized to 20 positions, and the destination is the staggered-\nbrick pattern of the wall. This would normally be done with two transforms, one to\nshift the chosen source brick to the upper-left corner and one to shift it into the cor-\nrect position on the target texture. At runtime, the two would be combined in an\noverall uv transformation before any texels were actually read.\n\nThe layers can be derived from a variety of methods. For example, the artist can sup-\nply a bitmap, or procedural data, such as Perlin noise [Perlin], or cellular automata\n(CA) to generate moss or wood grain [Ebert94]. All the parameters for these various\nmethods can be derived from per-pixel or per-vertex factors supplied by the artists or\nfrom pseudo-random numbers derived from the supplied information.\n\nThe sources can also be filtered. The most usual filter is a simple scale and bias on\nthe RGB or alpha values, especially when applied to noise functions or other similar\nremappings, such as sigmoid curves or step functions. Interpolating splines of 1° to 4°\ncan be useful and give the artist gamma, contrast, and brightness controls with a sin-\ngle graph. Most of these methods simply generate a 256-entry lookup table (or some-\ntimes three different RGB tables), and this is then applied to the image. Other\ncommon filters are blurs and edge-finding methods, and similar 2D convolution-\nkernel-based techniques. These are implemented as single-source blends.\n\nCompositing Methods\n\nSERRE RAR SOR HOSE RCNA ARATE CARE STAR ER TNS SARE NSDL IONE\n\nMost of the standard Photoshop blends should be supported, such as the standard\nalpha blend, multiplicative, additive, subtractive, and so on. Table 4.17.1 shows some\nsimple Photoshop blending methods with their equivalent mathematics and alpha-\nblend settings. Note that these blends will frequently be applied using alpha blends,\nnot using multitexture. Although in many cases using multitexture methods is theo-\nretically more efficient than multiple alpha-blending passes, in practice it is some-\ntimes a struggle to conform to the restrictions of multitexture.\n\nIn some cases, triadic blends—blends with three sources—can be required, for\nexample, in a blend between two alpha channels with the blend factor determined by\na third alpha channel. Sometimes this requirement can be worked around using mul-\ntiple two-argument blends, but this will be slower and less flexible, so it is worth keep-\ning the blend architecture open enough to allow blends that take any number of\n\nTable 4.17.1 Photoshop Blending Methods and the Equivalent Multipass Alpha Blend\nSettings\n\nPhotoshop Blend Mathematical Operation\n\nAlpha Blend (source, combine, destination}\nNormal Arg1*alpha + Arg2*(1-alpha) SRCALPHA, ADD, INVSRCALPHA\n\nMultiply Argl * Arg? DESTCOLOR, ADD, ZERO\nAdditive Argl + Arg2 ONE, ADD, ONE\nSubtractive Arg] — Arg2 ONE, SUBTRACT, ONE\nScreen Arg1+Arg2-Arg1*Arg2 INVDSTCOLOR, ADD, ONE\nLighten Max (Argl, Arg2) ONE, MAX, ONE\n\nDarken Min (Argl, Arg2) ONE, MIN, ONE\n\n4.17 Unique Textures 463\n\ninputs. Triadic blends should be implemented using multitexture hardware if possi-\nble, as this avoids additional temporary textures.\n\nNumber Controls\n\nEN SANTANDER ONE RAN RRR NNR aa\n\nAs a result of using unique texturing systems, artists require increasingly sophisticated\nways to generate numbers as blend factors or mapping transforms. At first they need\nobvious things in the system—a slider they can move, a pseudo-random number gen-\nerator with fixed scale and bias, and so on. Then they might want to make a hundred\nof the objects and only use one slider to control the parameters of all the objects.\n\nYou might find the need for variables and mathematical operations on them, in\nwhich case you could employ a full programming language (Python, LUA, LISP,\netc.—take your pick). However, artists prefer more-visual programming techniques—\nboxes that hold variables, arithmetic operations, and so on. So, you might want to\nconsider a graphical representation. In practice, we found that a tree structure pre-\nsented in a similar style to file-selector trees was best for calculating values. We added\ndraggable rubber-band lines between them for showing where the results were used in\nthe blends or other calculations.\n\nDynamic Textures\n\nSSSR RSA RRA ee eA SRR RR\n\nSERN!\n\nAnother powerful technique changes the layers according to gameplay. The most\nobvious examples are footprints, blood splatters, bullet holes, and explosion scorch\nmarks. These are typically simple layers that have their 4» mappings determined in\nreal-time. The advantages of these over conventional geometry decals is clear: There\nare no z-fighting issues, no extra geometry required to draw each frame, a much wider\nvariety of effects and texture variations are possible without losing batching efficiency,\nand much ‘smarter’ blends are possible.\n\nOne example when dynamic texture blends might be useful is on bump maps.\nSimply alpha-blending multiple Dot3 bump maps together does not work very well.\nThey overlap (e.g., multiple footprints in sand), and typically the interaction between\nthem does not make sense—one footprint simply obscures part of the another com-\npletely. However, we can composite the individual heightfields of the footprints using\na max blend that takes the maximum of the two height values (or indentations). Once\nthey are composited, the result is added to the original surface’s heightfield. Only then\nis the complete heightfield turned into a Dot3 normal-map texture with a filter. With\nstandard decals that simply alpha-blend into the frame buffer, this sort of compositing\nis impossible.\n\nAnother use of this method is to composite multiple shadow maps together in a\nscene. For example, in a forest, the shadow maps of trees do not actually need to pre-\ncisely match the shape of the trees—using just three or four different maps can easily\nprovide enough variation to fool the eye. This method would increase texture-cache\nperformance. As an additional bonus, the shadow map can be recomposited if, for\n\n464 Section 4 Graphics\n\neee sorrento anette ene noecnnesa N\\aeoEontncneeel ee ceMeeeeK RECO ERO\n\nexample, any trees are destroyed during gameplay. Alternatively, as the sun moves, the\nshadow maps can be recomputed with the new light-source direction in mind.\n\nScalability and portability are important on PC systems as well as consoles. It is\nimportant to spend the available cycles and memory where the player can see it.\n\nUnique texture systems already have scalability built in. Using a simple distance-\nbased estimation of the maximum size of mipmap level, the compositing is done only\non the texels that are likely to be visible. This optimizes CPU time and enables video\nmemory to be used more efficiently to generate higher-resolution textures only on the\nobjects that are visible.\n\nUsing a scalable system also allows for more realism when it’s most needed. For\nexample, in a hectic firefight, players care about frame rate, not the quality of the tex-\ntures. When the firefight is over, the player can admire their gruesome handiwork.\nWith less movement, fewer textures are being brought into the cache every second,\nand frame rate is not so crucial, so the composition system can spend more time on\nthe textures.\n\nThings that can be done to enable this scalability are:\n\n* Reduce the size of source textures, using smaller mipmaps. This increases mem-\nory cache efficiency and reduces disk accesses on a demand-loaded or virtual-\nmemory system.\n\n* Reduce the size of target textures. This means fewer texels to composite and\nreduces swapping of textures in and out of video memory.\n\n* Simplify sampling filters. Instead of Gaussian or trilinear filters, use bilinear fil-\nters or even-point filters.\n\n* Simplify image filters. Light blurs or edge-enhancements can be omitted alto-\ngether, and filters that use large convolution kernels can be replaced by lower-\nquality versions using smaller kernels.\n\n* Reduce the number of blends by marking certain blends with a level-of-detail fac-\ntor. For example, detail textures and decals can be removed or reduced without\ntoo much quality loss. They can always be added back in when the scene's level of\ndetail increases again.\n\nSome of these items can also be applied selectively to distant textures.\n\nSomething to be careful not to do is recompositing all textures when the scene-\nwide level of detail changes. This will lead to two problems: First will be a large frame-\nrate stall as every texture in the scene is recomposited. Second, all the textures will\nvisibly change, giving a nasty, popping effect. A far better method is to only recom-\nposite textures when they are offscreen. If a texture does need to be recomposited\nwhile onscreen for whatever reason, at least spend the time to alpha-blend between\nthe two versions in order to eliminate the visible pop.\n\n4.17 Unique Textures 7 465\n\nIdeally, all compositing would be performed by the graphics chip. That is what the\ngraphics chip is designed to do—take several textures, apply uv transformations to\nthem, apply some pixel effects to them, and then blend them with an existing image.\nIt is designed to do all this in parallel, achieving amazing throughput. Unfortunately,\nsome of the filters and blends that are required are fairly complex, and hard or impos-\nsible to do on the majority of graphics chips. Additionally, there are often problems or\nspeed penalties when swapping source and target textures in and out of video mem-\nory, and performing the compositions on the graphics chip can become counterpro-\nductive. There will always be a blend that an artist vitally requires near the end of a\nproject that just cannot be done by the graphics chip. For this reason, it is a good idea\nto always have a method of composition that is entirely CPU-based, even if a lot of\nthe operations can then be moved to the graphics chip for speed.\n\nPc\n\nThe PC’s CPU is good at compositing. The MMX (SIMD small-integer) instructions\nare powerful and fast, and most simple blends and filters will be limited by memory\nbandwidth rather than CPU speed. Memory is plentiful and backed by a ‘huge’ vir-\ntual memory store that is itself a form of cache.\n\nUsing the graphics chip to perform composition is trickier for PC games than for\nconsole games. The wide diversity of PC graphics cards makes life particularly diffi-\ncult here. Render-to-texture capabilities vary widely (even on recent cards) from no\nsupport to full support. Additionally, the range of blends and filters available again\n\nvaries widely, and many require multiple passes to emulate, reducing speed.\n\nXBox\n\nThe XBox shares some similarities with the PC. The CPU is the same, and it has very\nfast MMX instructions for image composition, so that part of the pipeline can be\nshared. However, the graphics chip is smart and can do 90% of the filters and blends\nthat are required without CPU assistance. Best of all, the graphics chip and CPU\nshare the same memory, which means that at each stage of the composition, the faster\nof the two can be used for that stage. Since graphics data is all stored in system mem-\nory, there is no need to worry about copying the data back and forth. Unfortunately,\nthis does create some bandwidth and fill-rate issues.\n\ned on the CD-ROM shows a very simple procedural landscape.\nThere is only one source texture used, which has been colored differently according to\nthe terrain type at each vertex. The texture is also shifted randomly at each vertex\nbefore being applied. When compositing a particular texture, the terrain types for\neach of the 25 vertices on that texture are blended together. Then, any decals (here a\n\n466 Section 4 Graphics\n\nsimple-colored ‘splat’) are alpha-blended over the top. The data for the decals hangs\noff the nearest landscape vertex, so retrieving the relevant list of decals for a particular\ntexture is very quick.\n\nHolding down the shift key shows a false-color picture of the different mipmap\nlevels used—all the mipmap calculations are done as if the camera were placed in the\nmiddle of the landscape. The central mipmaps are 256 X 256 texels, reducing by a fac-\ntor of two each time with distance.\n\nThis demo illustrates several things. Seamless texturing using a small number of\nsource textures (just one in this case) is simple and effective. A large number of decals\ncan be applied to a surface with relatively minor speed penalties, unlike traditional\nframe-buffer composition. A smart texture cache and simple distance-based mipmap-\nping substantially reduces the amount of compositing and texture memory required.\nFinally, even a software implementation of composition can be quick and effective—\nthis demo uses no graphics hardware capabilities for its compositing.\n\nUnique texturing encompasses a whole range of interesting features. The main aim is\nto make every texture in the world unique and to remove the cookie-cutter look from\ngames. The same technology can be used for cunning effects.\n\nImmersion is improved by having surfaces change depending on their positions\nin the game world. Extra details normally produced with detail textures, light maps,\nand decals can be added more efficiently, cheaper, and with more flexibility. Artists’\ntime is reduced by freeing them from large amounts of tedious pixel-pushing, even on\nhuge and diverse worlds, while allowing them more time to fine-tune the really\nimportant bits of a scene.\n\nFinally, using a scripting language to drive the texture-composition engine gives\nartists and designers awesome flexibility and opportunity to create worlds with a look\nnot commonly seen in today’s computer games.\n\nReferences\n\n[Ebert94] Ebert, et al., Texturing and Modeling: A Procedural Approach, AP Profes-\nsional, 1994.\n\n[Milliger02] Milliger, Mike, “Procedural Texturing,” Game Programming Gems 3,\nCharles River Media, Inc., 2002.\n\n[Perlin] Ken Perlin’s page about noise: http://mrl.nyu.edu/ ~ perlin/doc/oscar.html.",
      "page_number": 448,
      "chapter_number": 47,
      "summary": "The core idea that we will explore in this gem is how to use a relatively small number\nof artist-generated source textures and combine them at runtime using a variety of\nblends, fractal methods, and random numbers to create the textures required for the\nscene Key topics include textures, blends, and layers.",
      "keywords": [
        "Textures Tom Forsyth",
        "Textures",
        "Unique Textures Tom",
        "Mucky Foot",
        "Tom Forsyth",
        "blends",
        "source textures",
        "Textures Tom",
        "Unique Textures",
        "graphics",
        "graphics chip",
        "source",
        "texture cache",
        "target textures",
        "methods"
      ],
      "concepts": [
        "textures",
        "blends",
        "layers",
        "memory",
        "mapped",
        "maps",
        "map",
        "source",
        "methods",
        "artists"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 7",
          "chapter": 48,
          "title": "Segment 48 (pages 468-478)",
          "relevance_score": 0.66,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 2",
          "chapter": 49,
          "title": "Segment 49 (pages 477-489)",
          "relevance_score": 0.58,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 1",
          "chapter": 57,
          "title": "Segment 57 (pages 550-561)",
          "relevance_score": 0.53,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 7",
          "chapter": 49,
          "title": "Segment 49 (pages 479-486)",
          "relevance_score": 0.53,
          "method": "api"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 23,
          "title": "Segment 23 (pages 441-462)",
          "relevance_score": 0.52,
          "method": "api"
        }
      ]
    },
    {
      "number": 48,
      "title": "Segment 48 (pages 456-465)",
      "start_page": 456,
      "end_page": 465,
      "detection_method": "topic_boundary",
      "content": "4.18\n\nTextures as Lookup Tables\nfor Per-Pixel Lighting\nComputations\n\nAlex Viachos, John Isidoro,\nand Chris Oat; ATI Research\n\nAlex@Vlachos.com, jisidoro@atil.com,\ncoat@ati.com\n\nhe latest generation of graphics hardware has brought forth a new level of per-\n\npixel programmability for real-time applications [Microsoft02]. However, they\nare limited by both the size and the types of instructions that can be performed.\nBecause of this limitation, programmers need to utilize a new set of tricks to perform\nmore-advanced graphics algorithms on a per-pixel basis. In this gem, we show ways to\nuse texture maps as a means to solve functions through a lookup table, focusing on\nlighting computations. This technique saves precious pixel shader instructions, and in\nmany cases, it is the only way to make certain per-pixel effects possible on the current\ngeneration of hardware.\n\nSpecular Per-Pixel Lighting Without Using a Cube\n\nthat the halfway vector, 4, can become denormalized when it is linearly interpolated\nacross a polygon. One standard solution is to use a normalization cube map to renor-\nmalize the halfway vector [Baker01]. Normalization cube maps have the disadvan-\ntages of requiring an additional texture fetch as well as consuming a lot of texture\nmemory. An alternative to using normalization cube maps followed by a 1D specular\ntexture fetch is to use an 2.4/h.h map as a lookup table in your shader. This optimiza-\ntion reduces the number of texel fetches required per pixel from two to one. However,\nthe normalization cube map is still used to normalize tangent space light vector, /.\n\n¢ Fetch 7 (per-pixel normal) from the normal map (bump map).\n¢ Halfway vector (H) is stored as a 3D texture coordinate and interpolated across\nthe polygon causing it to be denormalized at each pixel.\n\n467\n\n468 Section 4 Graphics\n\nFIGURE 4.18.1 n.h/h.h Map (k = 32). An example of a procedurally created n.hih.h\nmap that allows for per-pixel specular lighting with a specular exponent of 32.\n\n* Store ./ in the first component of the texture coordinate.\n\n* Store 4.4 in the second component of the texture coordinate.\n\n* Using this 2D texture coordinate, fetch into the n.4/h.4 map. The resulting texel\nfetched is the specular lighting term raised to some constant power &.\n\nCreating the .4/h.h map is relatively simple (see Figure 4.18.1). The map is a\nmonochrome image that potentially uses 1/18th of the texture memory required by a\nnormalization cube map (six RGB color faces of a cube). The 2.h/h.4 map is essen-\ntially a lookup table for the following function:\n\nret) ={((4)((e4\"\")) 4.18.1)\n\nwhich can also written as\n((n.») 1 Jal) (4.18.2)\n\nThe following is a DirectX8.1 pixel shader (Version 1.4) that performs the\nn. hl h.h mapping:\n\n3(0.0, 0.5, 1.0, 1.0)\nSetPixelShaderConstant 0 psCommonConst\nSetPixelShaderConstant 1 ambient\nSetPixelShaderConstant 2 diffuse\n\n4.18 Textures as Lookup Tables for Per-Pixel Lighting Computations 469\n\nPer-Pixel Specular Exponent Using an (n.h)}* Map\n\nSetPixelShaderConstant 3 specular\nStartPixelShader\nps.1.4\ntexld r0O, tO ;normal map n\n;tangent space H (not necessarily normalized)\ntexcrd r2.rgb, t2\n;tangent space L (normalizer cube map lookup)\ntexld r4, t1\ndp3_sat r4, rO_bx2, r4_bx2 ;(n.1)\ndp3_sat r3.r, rO_bx2, r2 ;(n.h)\ndp3_sat r3.g, r2, r2 ;(h.h)\nphase ‘\n;Base map\ntexld ri, to\n3(n.h)/(h.n)*k map lookup\ntexld r2, r3\nslight = n.1 * diffuse + ambient\nmad r5.rgb, r4, c2, cl\n;basemap * light\nmul r5.rgb, r1, r5\n3(specular * color) + (basemap * light)\nmad_sat rO.rgb, r2, c3, r5\nt+mov_sat r0.a, cO.b\nEndPixelShader\n\nee\n\nSSSI ASEAN OAUTH RRRRARURROR RRR RSENS RRS\n\nUsing a method similar to the one previously described, it is possible to specify a\nunique specular exponent on a per-pixel basis. This requires some additional math in\nthe pixel shader. A specular exponent (shininess) map, as well as the creation of an\n(n.h)* texture, is also required. The grayscale specular exponent map is often stored in\nthe alpha channel of the base texture. This is what an artist paints to define the spec-\nular exponent & at each pixel.\n\nFetch x (per-pixel normal) from the normal map (bump map).\n\nFetch & from the exponent (shininess) map.\n\nHalfway vector (H) is stored as a 3D texture coordinate and interpolated across\nthe polygon causing it to be denormalized at each pixel.\n\nStore (7.4) in the first component of the texture coordinate.\n\nStore (&*4./) in the second component of the texture coordinate.\n\nStore (4.4) in the third component of the texture coordinate.\n\nA projective, dependant texture fetch is required into the (7.4)* map. The projec-\ntion causes the first two coordinates to be divided by the third, resulting in\n((n.4)?/(h.A), k). The texel fetched with these coordinates is the specular lighting\nterm raised to the per-pixel power &.\n\nJust like the .4/h.4 map, the n.4* map is used to reduce the amount of math you\n\nwould otherwise have to do explicitly in the pixel shader (such as normalizing 4 and\nraising 7.4 to a power of &). In this case, & = [0.0, 1.0], where 0.0 corresponds to the\nminimum & value used during (n.4)* texture creation, and 1.0 corresponds to the\n\n470\n\n: Section 4 Graphics\n\nmaximum & value in the n./* texture. When doing the dependent texture fetch, use\nthe projective divide (_dz in D3D) to divide the first two coordinates by the third.\n\nThis projective divide causes the resulting texture lookup coordinates to be:\n\n$= ((n.) * (»4)) / (4.4) = (n.h) | (4.18.3)\nt-k\n\nFor n.h* mapping, the texture lookup table computes the following function:\n\nf (st) = °°\" (4.18.4)\n\nBy performing the texel fetch from this map, using the above coordinates, the\nequation becomes:\n\n((v.4) / fal)’ (4.18.5)\n\nThis results in the standard Phong specular lighting component raised to the\nexponent &. The beauty of this technique is that the projective texel fetch both nor-\nmalizes the 4 vector and performs the exponentiation. The tiled quad at the bottom\nof Color Plate 14 was rendered using an (n./4)* map to achieve varying degrees of spec-\nular lighting on a per-pixel basis. The specular exponent varies per-pixel as defined by\nthe exponent map shown in Figure 4.18.4. Figure 4.18.3 is an example of a procedu-\nrally generated (n.4)* map that allows for per-pixel specular lighting with a per-pixel\nexponential range of [0, 64].\n\nFIGURE 4.18.2 An RGB texture of a tiled surface without any lighting.\n\n4.18 Textures as Lookup Tables for Per-Pixel Lighting Computations\n\n471\n\nFIGURE 4.18.3 A procedurally generated (n.h} (k=[0,64]) map that allows for per-\npixel specular lighting with a unique specular exponent specified at each pixel.\n\nFIGURE 4.18.4 Grayscale specular exponent map that is used in combination with the\ntexture from figure 4.18.3 to obtain artist-editable per-pixel specular exponents.\n\n472\n\nColor-Shift Iridescence\n\nSection 4 Graphics\n\n;(0.0, 0.5, 1.0, 1.0)\nSetPixelShaderConstant 0 psCommonConst\nSetPixelShaderConstant 1 ambient\nSetPixelShaderConstant 2 diffuse\nSetPixelShaderConstant 3 specular\nStartPixelShader\nps.1.4\n;dot 3 map (specular exponent stored in alpha)\ntexld r0, to\ntexcrd r2.rgb, t2 ;tan H\n;tangent space L (normalizer cube map lookup)\ntexld r4, t1\ndp3_sat r4, rO_bx2, r4_bx2 ;(n.1)\ndp3_sat r3.b, r2, r2 ;(h.h)\ndp3_sat r3.r, rO_bx2, r2 ;(n.h)\nmul r3.g, r3.b, rO.a ;k*((h.h))\nmul r3.r, r3.r, r3.r 3(n.h)*2\nphase\n;Base map\ntexld r1, to\n;Attenuated (n.h)*k map\ntexld r2, r3_dz\n3n.1 * diffuse + ambient\nmad r5, r4.r, c2, cl\n;diffamb = basemap * (n.1 * diffuse + ambient)\nmul r5.rgb, r1, r5\n;diffamb + (specular * specular color)\nmad_sat rO.rgb, r2, c3, r5\n+mov_sat r0.a, c0.b\n\nEndPixelShader\n\nAnother rendering effect using texture lookup tables is color-shift iridescence. This\ntype of iridescence can be seen on insects’ wings, certain finishes on glasswork, and\npearl-like objects. The effect this algorithm simulates is based on the empirical obser-\nvation that the color at a particular point on an object tends to change in hue depend-\ning on the angle between the view vector and the surface normal. This is usually\ncaused by a thin layer of semitransparent film on an object that diffracts different fre-\nquencies of incident light in different directions. The base algorithm performs stan-\ndard Phong lighting and then multiplies the specular highlight color by a texel\nfetched from a 1D, hue-based gradient texture addressed by (n.v), where 7 is the per-\npixel normal, and v is the tangent space view vector. See Color Plate 15 for images of\nhue-based gradient and objects rendered using color-shift iridescence. The following\npixel shader performs the color-shift iridescence. Note that this example uses the\n(n.h)* technique of the previous subsection.\n\n3(0.0, 0.5, 1.0, 1.0)\nSetPixelShaderConstant 0 psCommonConst\nSetPixelShaderConstant 1 ambient\n\n4. 18 Textures as Lookup Tables fe for Per-Pixel Lighting Computations © 473\n\nSetPixelShaderConstant 2 diffuse\nSetPixelShaderConstant 3 specular\nStartPixelShader\n\nps.1.4\n\n;dot 3 map (Specular exponent stored in alpha)\n\ntexld ro, to\n\n;tan H\n\ntexcrd r2.rgb, t2\n\n;tangent space L (normalizer cube map lookup)\n\ntexld r4, t1\njtangent space V (normalizer cube map lookup)\ntexld r5, 3\n\ndp3_sat r4.gb, r0_bx2, r4_bx2 ;(n.1)\ndp3_sat r4.r, rO_bx2, r5_bx2 ;(n.v)\ndp3_ sat r3.b, r2, r2 ;(h.h)\ndp3_sat r3.r, rO_bx2, r2 ;(n.h)\nmul r3.g, r3.b, rO.a ;k*((h.h))\nmul r3.r, r3.r, r3.r j(n.h)*2\n\nphase\n\n;Base map\n\ntexld ri, to\n\n;Attenuated (n.h)*k map\n\ntexld r2, r3_dz\n\n;Iridescent map 1D tex map lookup\n\ntexld r3, r4\n;lridescent * Specular\nmul_sat rO.rgb, r2, r3\n3n.1 * diffuse + ambient\nmad rS, r4.g, c2, c1\n;diffamb = basemap * (n.1 * diffuse + ambient)\nmul r5.rgb, rt, rs\n;diffamb + specular * specularcolor\nmad_sat rO.rgb, r0, c3, rsd\n+mov_sat r0.a, cO.b\n\nEndPixelShader\n\nPer-Pixel Point Lights with Correct\nPer-Pixel Falloff\n\nASN CR SRAM\n\nAnother useful application for texture lookup functions i is correct per-pixel light\nattenuation. Computing distance falloff for point lights is traditionally sampled at the\nvertices and the distance is then linearly interpolated for per-pixel effects. The prob-\nlem with this approach occurs when a light is near the surface of a large polygon, and\nthere is no vertex to catch the light near the light source.\n\nThe approach for this algorithm is to calculate the distance from each pixel to the\nlight source instead of each vertex. This results in the exact falloff value, based on a\ngiven light source, thus avoiding the common problems with the vertex-based\n\nLARNER TITRES\n\napproach.\n\nThe vertex shader computes the vertex position in normalized light space (NLS)\ninstead of directly using the distance from the vertex position. The NLS transform is\na translation by (-lightPos), then a uniform scaling by (1 / lightFalloff). This\n\n474 Section 4 Graphics\n\nFIGURE 4.18.5 1D point light texture that renders light color and intensity change as a function of\ndistance from the point light source.\n\ngives us each vertex’s position in NLS. The pixel shader then computes the distance\nsquared on a per-pixel basis by simply taking the dot product of this interpolated ver-\ntex position with itself. Then, a 1D texture is sampled using the NLS distance squared\nas the texture coordinate. This allows you to vary the intensity and color of the light\nusing distance in any way possible. The per-pixel nature of the algorithm solves any\nvertex-sampling issues. Since NLS position is linear by definition, this approach\nworks perfectly without artifacts. This method hides a per-pixel square-root function\nin a texel fetch (see Figure 4.18.5).\n\nPer-Pixel Spotlights and Directional Lights with\nCorrect Per-Pixel Falloff\n\nA natural extension of the per-pixel point light attenuation is to model spotlights and\ndirectional lights. This technique is similar to the point light shader above, but it\nrequires slightly different vertex and pixel-shader operations. Instead of creating a 1D\ntexture for the light, a 2D texture is required. The # axis of the texture is indexed with\ndistance squared in the same way as a point light. However, the v axis of the texture\nencodes falloff based on the spot angle (the angle between the NLS vertex position\nvector and the spotlight direction).\n\nTo use this 2D texture, we extend the notion of normalized light space to repre-\nsent a rotation, as well as extending a scale factor and a translation. This rotation\nmatrix is composed of the light’s orthonormal basis with the light direction as the z-\naxis.\n\nIn the vertex shader, similar to point lights, the vertex position is transformed\ninto normalized light space. In the pixel shader, we can load this new position into a\nregister as a set of texture coordinates and perform a dot product with itself to get the\nNLS distance squared (exactly like point lights, above). This NLS position is also\nloaded into a separate register with a projection modifier, causing the first two com-\nponents to be divided by the first. This will compute the projected position. This pro-\njection performs a divide by z in NLS, which gives the spotlight its cone-like shape.\nThen, by doing a dot product with itself, we get a squared, scaled distance from the\nNLS z-axis, which acts like an ‘angle’ in the range 0-1. If the dot product is done\nwithout a modifier, this value represents an angle of 0°-90°.\n\nThese two dot product values are then used as a lookup into a 2D texture, which\nis a visually convincing approximation to the usual spotlight distance multiplied by\nthe angle equation, assuming squared values as input.\n\n4.18 Textures as Lookup Tables for Per-Pixel Lighting Computations 475\n\nTable 4.18.1 Available Scale Factors and Resulting Frustum Angles\n\nScale Factor _d8 _d4 _d2 None _x2 _x4 _x8\nFrustum Angle (°) 165.7 151.9 126.8 90.0 53.1 28.1 14.3\n\nIf we simply do a dp3 as written below, the 2D texture map represents values\nwithin a 0°-90° light frustum. This means that the texture created for the spotlight\nmust encode the full 0°-90° frustum. For lights with larger or smaller cones, texels can\nbe better utilized by selecting an appropriate range. Using scale factor instruction\nmodifiers, the 2D texture can represent other frustum angles. The formula for frus-\ntum angle is 2*arctan(1/scale factor). Table 4.18.1 shows the available scale factors\nand the resulting frustum angle:\n\nBy using the scale factors for the frustum angle, the y resolution of the texture\nlookup table can be decreased for smaller frustum angles because much less space is\nbeing represented. If the desired frustum angle is not listed in the table, just choose\nthe closest table entry that is larger than the frustum to be represented, and make up\nthe difference by scaling down the lookup table in the y direction.\n\n;(0.0, 0.5, 1.0, 1.0)\nSetPixelShaderConstant 0 psCommonConst\nStartPixelShader\nps.1.4\n;NLS pos\ntexcrd r1.xyz, t1.xyz\n;NLS pos in xy plane scaled by 1/z\ntexcrd r2.xy, t1_dz.xyz\n;distance squared from light\ndp3 ri, ri, ri\n;Sset z= 0\nmov r2.b, cO.r\n;(dist in xy plane scaled by 1/z)*2\ndp3 ri.g, r2, r2\nphase\n;Base\ntexld ro, to\n;Light attenuation\n\ntexld r1, r1\n;Base* light\nmul rO, r0, ri_x2\n5\" * NLL\nmul rO, rd, vO\nEndPixelShader\n\nRemoving the _dw from the second texcrd instruction provides a cylindrical\ndirectional light frustum. This removes the scaling by 1/z of the distance in the xy-\nplane and gives the light’s domain a cylindrical shape (see Figure 4.18.6). Note that\nthis light still has a position and a falloff from that position. If positional distance\nfalloff is not desired, just remove the first dot product and use the second dot product\nto index into a 1D texture.\n\nSection 4 Graphics\n\nFIGURE 4.18.6 2D spot/directional light texture that renders how, along one axis, light\ncolor and intensity changes as a function of distance from the light source. The other axis\nrenders how the light changes as a function of angle from the light vector. This example\nassumes a 90° frustum and is a perfect candidate for using the 53.1° frustum to save\ntexture usage.\n\nConclusion\n\n‘SSeoRUTE\n\nORTLAND TASS ANI SHARIN RAEI RRR HITTITE ERP RE ICS LAT OL ANA RTS AN AR UMARINE\n\nWe have shown a variety of effects using textures as function lookups. Using this idea,\nmany graphics algorithms that have been per-vertex-only techniques can now be per-\nformed per-pixel. Of course, these are just a few useful examples of the many effects\nthat can be achieved with this technique.\n\nReferences\n\naR SARA a AN eset eR ERA SA Tn NIT\n\n[Baker01] Baker, D. and C. Boyd, “DirectX 8.0 Shader Applications (Per Pixel Light-\ning),” DirectX Developer Day, 2001, available online at http://www.microsoft\n.com/corpevents/gdc2001/developer_day.asp.\n\n[Microsoft02] MSDN. Microsoft.com, “DirectX 8.1 Pixel Shader Reference,” avail-\n\nable online at http://msdn.microsoft.com/library/default.asp?url=/library/en-us/\n\ndx8_c/directx_cpp/Graphics/Reference/Shader/Pixel/Instructions/Instructions.a\n\nsp, February 2002.",
      "page_number": 456,
      "chapter_number": 48,
      "summary": "This chapter covers segment 48 (pages 456-465). Key topics include lighting, textures, and pixel. Because of this limitation, programmers need to utilize a new set of tricks to perform\nmore-advanced graphics algorithms on a per-pixel basis.",
      "keywords": [
        "map",
        "texture",
        "cube map lookup",
        "light",
        "Specular",
        "texture lookup table",
        "map lookup",
        "Per-Pixel",
        "ATI Research Alex",
        "texture coordinate",
        "Per-Pixel Lighting Computations",
        "specular exponent",
        "cube map",
        "texture lookup",
        "Lookup"
      ],
      "concepts": [
        "lighting",
        "textures",
        "pixel",
        "map",
        "mapping",
        "specular",
        "base",
        "based",
        "tables",
        "normalization"
      ],
      "similar_chapters": [
        {
          "book": "Game_Engine_Architecture",
          "chapter": 23,
          "title": "Segment 23 (pages 441-462)",
          "relevance_score": 0.72,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 2",
          "chapter": 43,
          "title": "Segment 43 (pages 424-431)",
          "relevance_score": 0.68,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 1",
          "chapter": 54,
          "title": "Segment 54 (pages 523-530)",
          "relevance_score": 0.64,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 1",
          "chapter": 57,
          "title": "Segment 57 (pages 550-561)",
          "relevance_score": 0.63,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 7",
          "chapter": 45,
          "title": "Segment 45 (pages 429-442)",
          "relevance_score": 0.63,
          "method": "api"
        }
      ]
    },
    {
      "number": 49,
      "title": "Segment 49 (pages 466-476)",
      "start_page": 466,
      "end_page": 476,
      "detection_method": "topic_boundary",
      "content": "Rendering with Handcrafted\nShading Models\n\nJan Kautz,\nMax-Planck-institut fiir Informatik\nkautz@mpi-sb.mpg.de\n\nuite a few techniques have been proposed on how to implement more-complex\n\nand more-realistic shading models for graphics hardware [Heidrich99, Kautz99],\nmaking them useful for games. Still, these techniques are rarely used, probably due to\ntwo reasons: complex implementation issues and unintuitive parameters for the shad-\ning models used. We propose to use a simple technique called normal distribution\nfunction (NDF) shading. \\t allows an artist to handcraft shading models, with the\nshape and color of highlights simply stored in bitmaps. The technique uses per-pixel\nshading, and can also be used in conjunction with bump mapping. Anisotropic shad-\ning models can also be created.\n\nA shading model determines how much light reflects off a surface, depending on the\ndirection to the light source, 4, the direction toward the viewer, v, and the surface\nnormal, n.\n\nSo far, most-interactive rendering systems use the Blinn-Phong [Blinn77] model,\ndue to its simplicity:\n\n= h(n 1) + k(h- n)” (4.19.1)\n\nThe parameter &, is the diffuse coefficient, usually stored in a color texture map;\nk, is the specular coefficient, often chosen globally, but sometimes stored in a gloss\nmap; and the parameter N is the specular exponent, which changes the shininess of\nthe material. The vector 4 is the normalized halfway vector between the view and\nlight directions.\n\nAs you can see, this model mainly uses simple operations, except for the one\nexponentiation. On today’s graphics hardware it can be implemented with a pixel\nshader [Kilgard00, Mitchell01], since dot products and dependent texture reads are\navailable.\n\nss aR\n\n477\n\nSection 4 Graphics\n\nNonetheless, the lit objects often look like shiny plastic. It is nearly impossible to\nmake a piece of cloth look like cloth. For anisotropic shading, which is used to render\nmaterials like brushed aluminum, Blinn-Phong cannot be used at all, since it is only\nisotropic (i.e., orientation independent).\n\nPrevious Methods for Incorporating Better\nShading Models\n\nA few methods have been proposed that can incorporate better shading models [Hei-\ndrich99, Kautz99], but these usually have limitations, such as unintuitive parameters,\nor require measured data that is not widely available.\n\nMicrofacet-Based Shading Models\n\n[TRU Rena NE LIER SS NI RAR RENNES PION\n\nSAE CAN NO oe\n\nShading models that are based on microfacets (see [Cook81]) assume that the surface\nconsists of tiny specular facets pointing in different directions (Figure 4.19.1). These\nmicrofacets are so small that they cannot be discerned, but the overall distribution of\ntheir orientations governs the shape of the specular highlight. Hence, all the microfacet-\nbased shading models use the distribution of the microfacet normals 7 ,,. We denote the\nNDF with p(v ,,). What does this distribution tell us? If we look up a value with p(A), it\ngives the percentage of the surface’s microfacets that face toward direction 4.\n\nAs previously mentioned, microfacet models assume that all the microfacets are\nsmall, perfect mirrors. If the halfway vector between the view and light directions is\nthe same as the normal of a perfect mirror, we see the reflection of the light source.\n\nFIGURE 4.19.1 A surface consisting of tiny microfacets and its normal distribution\nfunction.\n\n419 Rendering with Handcrafted Shading Models 479\n\nThis is almost true for a surface consisting of tiny microfacets. If there are microfacets\nwith a normal x,, that is equal to the halfway vector 4 between the light and view\ndirections, we see light reflected trom the light source, but at the microfacct scale. he\ndistribution function p(4) tells us what percentage of the incoming light is reflected,\nsince not afl microfacets are oriented in the same direction.\n\nThe specular part of the Blinn-Phong model can be seen as a simple microfacet-\nbased shading model. [t assumes that che orientations of the microfacets have a cosine\nto the power of V distribution.\n\nNOF Shading\n\nThe shading model that we want to use is just a slight modification of the original\nBlinn-Phong model:\n\nL, = h(n L)~ bp(Bigca:)s Pieg = (b&b, bn} (4.19.2)\n\nFisecti\n\nAs you can sec, the only difference is that instead of the fixed cosine’ distribu-\ntion, we use an arbitrary normal distribution function. The surface tangent ¢, binor-\nmal 4, and the normal » define the local surface coordinace frame, which is also\nneeded for bump mapping. If the normal distribution function happens to be pix,,} =\n(n,, °°. we get the original Blinn-Phong model. However, since the normal distribu-\ntion now depends on the full local halfway vector, instead of only its z coordinate\n(simply /-»)}, we can also create anisotropic highlights.\n\nHow To Store the NDF\n\nHow can we store the normal distribution function so that it can be used with graph-\nics hardware? We store it in a 2D texture map. Assuming the microstructure of the\nsurface is a heightfield, the orientations of the microfaccts can only vary within the\nupper hemisphere: in other words, the z coordinates of the microfacets’ normals »,,\nare always positive. Therefore, it is sufficient to use the following two coordinates to\nindex into our 2D p(v,,) texture:\n\nFigure 4.19.1 ilkustrates an example of a normal distribution function that was\nstored in such a way. Imagine a hemisphere where all the values of the normal distrib-\nution function lic. Now, we project this hemisphere onto a square plane. ‘Phis is\nexactly what is shown in Figure 4.19.1 and what the mapping detailed here does.\n\nRendering/Pseudo-Code\n\nSo, how do we render an object with this new shading model? Well, it is not much\nmore complicated than the standard Blinn-Phong model. If we have already created a\n\nSection4 Graphics\n\ntexture by storing a normal distribution function, then we need to do the following to\nrender the specular highlight:\n\nGiven:\na light source at position Pgh:\n\n* a VIEWEE at POSITION Pyiewer\nBind NDF texture\nFor every vertex v, of a polygon:\n\n* Compute the normalized vector 1 from vy; to pugs\n* Compute the normalized vector v from ¥; to Pyiewer\n* Compute the halfway vector h = v+l\n\nNormalize h\nRetrieve the tangent t; and the binormal b;\n\n* Compute x, = th*t+1)/2\n* Compute x, = (h*bj+1)/2\n* Set texture coordinates (u,, ,)\n\nu\n\nRender polygon\n\nThe diffuse term can be added either later or in the same stage if multitexturing is\nsupported. An additional gloss map can also be applied, if desired.\n\nGenerating the NDF Texture\n\nSo how do we create such an NDF texture? We use a paint program to model our nor-\nmal distribution, which is equivalent to drawing the highlight itself! Figure 4.19.2\nshows a few highlights and how they look on objects.\n\nWe now will suggest how to use the diffuse term and the new specular NDF term to\ngenerate interesting shading models. If a standard highlight (as in the original Blinn-\nPhong model) is desired, then the NDF texture should probably be grayscale, so that\nyou can change its color according w the light source, The texture should not contain\na directional diffuse term. In Figure 4.19.2, two different NDFs are applied to some\ngeometry; a standard diffuse term was added as well.\n\nMore- interesting shading effects can be achieved by including a (colored) direc-\ntional diffuse term. In contrast to the normal diffuse term, the directional diffuse term\ndepends on 4-7, Therefore, we can include it in the NDF. This directional diffuse\nterm can, of course, have some color, which makes it possible to achieve interesting\neffects.\n\nIn Color Plate 16, on the left, you can sce a piece of cloth rendered with a bluish\ndirectional diffuse NDF plus a red diffuse term. The cloth looks mostly purple, but at\n\n4.19 Rendering with Handcrafted Shading Models 481\n\nFIGURE 4.19.2 NDF: applied to a piece of cloth and a teapot.\n\ngrazing angles, the red diffuse term has more influence than the blue directional term,\nmaking the cloth more reddish. In the middle, you can see an NDF that varies from\ndark red to bright red at grazing angles of the halfway vector, which is the opposite\nway an NDF usually looks like. Applying this NDF to the piece of cloth gives it a vel-\nvet-like look. On the right side, we created an anisotropic NDF, which goes from red\nto blue. Now, the cloth looks like anisotropic satin.\n\nBump Mapping with NDFs\n\nNDF shading can be easily incorporated with bump mapping, as long as you have\ndependent texture reads. It is almost equivalent to bump mapping with the Blinn-\nPhong model, only you have to compute the texture coordinates, #, and w,, with the\ntangent and the binormal for the lookup. This makes it necessary to store them in\ntexture maps as well. Here is a pixcl shader (DirectX8.1 notation) chat will do this\ncomputation:\n\nps.1.4\n\ntexld ri, tO ; Normal (tex1)\n\ntexcrd r2.rgb, ti ; Tangent Space 1 vector\n\ntexcrd r3.rgbh, t2 ; Tangent Space Halfangle vector\ntexld r4, tO ; Bainormal (tex4)\n\ntexld rS, tO ; Tangent (tex5)\n\ndp3_sat rt.xyz, ri_bx2, r2 3; r1 = max(n*1,0)\ndp3 r2.x, r4_bx2, r3 ; r2.x = bth\n\ndp3 r2.y, r5_bx2, r3 ; r2.y = t*h\nadd d2 ré.xy, r2, one ; r2 = (r2+1)/2\n\n482 Section 4 Graphics\n\nphase\ntexld r0, tS ; tex0.rgb = k_d and tex0.a = k_s\ntexld r2, r2 ; NDF is in texture unit 2\n\nmul rO.rgb, rO, rt ; Kd * {Nn*1)\nMul ri.rgh, rO.a, r2 ; k_s * NDF(}\nadd rO.rgb, rO, r1 5 kd * (Nn*1L) + k_s * NDF{)\n\nExtensions\n\nThe shading model could be extended with a Fresnel term and a (so-called) self-\nshadowing term, which refers to the self-shadowing of microfacets. This is commonly\nused in more-accurate microfacet models [Cook81]. Although these two terms do\nchange the resulting shading, in many cases they do not significantly add to the shad-\ning model, especially if point light sources are used for illumination.\n\nOne other extension is to include the area foreshorting of incident light for the\nspecular term as well:\n\nL, = kg{n-2) + k,p(Poca)(n >) (4.19.4)\n\nThis makes a big difference in the shading, especially if a directional diffuse term\nis encoded in the NDF texture. In the end, however, the use of this additional term\ndepends on the effect/material you wish to create.\n\nConclusion\n\nWe have presented a shading technique that is easy to implement and easy to use. A\nwide variety of materials can be simulated. An artist can modify the appearance of an\nobject in an intuitive way by just painting a highlight and/or a directional diffuse term\ninto a texture! See Color Plate 19 for an example of NDF shading applied to the\nStandford Buddha model combined with a diffuse color. Although there is some\nphysical explanation behind this shading technique, it does not accurately model any\nreal world surfaces. Nonetheless, the visual richness that can be achieved with this\nshading model is fascinating.\n\nReferences\n\n[Blinn77] Blinn, J., “Models of Light Reflection for Computer Synthesized Pictures,”\nComputer Graphics Proceedings (SIGGRAPH 1977), Pp. 192-198.\n\n[Cook81} Cook, R. and K. Torrance, “A Reflectance Model for Computer Graphics,”\nComputer Graphics Proceedings (SIGGRAPH 1981): pp. 307-316.\n\n[Heidrich99] Heidrich, W. and H. P. Seidel, “Realistic, Hardware-Accelerated Shad-\ning and Lighting,” Computer Graphics Proceedings (SIGGRAPH 1999): pp.\n171-178.\n\n4.19 Rendering with Handcrafted Shading Models 483\n\n[Kautz99] Kautz, J. and M. McCool, “Interactive Rendering with Arbitrary BRDFs\nUsing Separable Approximations,” Tenth Eurographics Workshop on Rendering,\npp. 281-292, June 1999.\n\n[Kautz01] Kautz, Heidrich W. and H. P. Seidel, “Real-Time Bump Map Synthesis,”\nEurographics! SIGGRAPH Workshop on Graphics Hardware, August 2001, pp.\n109-114.\n\n[Kilgard00] Kilgard, M., “A Practical and Robust Bump-Mapping ‘Technique for\noday’s GPUs,” available online at hetp://developers.nvidia.com, July 2000.\n[MitchellO1] Mitchell, J., “Advanced Vertex and Pixel Shader Techniques,” available\n\nonline at http://www.ati.com/developer, September 2001.\n\n5.1\n\nMinimizing Latency in Real-\nTime Strategy Games\n\nJim Greer, EA.com, and\nZachary Booth Simpson, Mine Controf\n\njamesfgreer2@yahoo.com,\n0ink54321@yahoo.com\n\nultiplayer real-time strategy games have different networking requirements than\n\ntwitchy action games. Rather than transmitting the millisecond-by-millisecond\nmovements of the player, they must manage hundreds of semi-autonomous units.\nThis allows their network protocol to be optimized in ways that action games cannot.\nIn this gem, we will! describe event-locking, a time-synchronized method well-suited to\nthe coordination of real-time strategy games. The technique could also be applied\nto simulation games and other nontwitch games.\n\nFrame-Locking Versus Event-Locking\n\nEarly networked games, often written for local area network (LAN) play, used a tech-\nnique called frame-locking. Under this method, the clients send out an update every\nframe; at a minimum, this includes all the user input that occurred during the frame.\nThis update might be sent to all other clients (in a peer-to-peer arrangement) or to a\ncentral server that processes it and echoes the results to all clients. In practice, some\nsuch frame-locked games render more than one frame before sending an update; but\nthe updates typically happen at some fixed interval. While this method is suitable for\nLAN play, it does not extend well to Internet play, even under low to moderate\nlatency (150-300 ms).\n\nConsider a network architecture with a central server. As long as all clients are send-\ning in their updates at the same pace, everything is fine. However, if one client’s update\nis not received due to network latency or other reasons, then the server and all other\nclients must freeze, awaiting the arrival of the update. If they were to proceed without\nwaiting for the delayed client's input, the game would immediately be out of synchro-\nnization—the player would see the results of their actions, but no one else would.\n\nFigure 5.1.1 shows an example of this arrangement as an event timeline. For the\nfirst update at time 0, Clients A and B send their updates to the server. The server\n\n5.1 Minimizing Latency in Real-Time Strategy Games 489\n\nTime ClientA Server Client B\n\n0\n\ni}\ni\nI\ni]\ni]\nJ\n|\n|\nJ\nI\nt\nt\nt\n|\n|\n|\n|\n|\n|\n|\n|\n|\n|\n|\n|\ni\nI\nl\nI\nI\n\nFIGURE 5.1.1 Freezing under frame-locking: Server and Client A are held up by Client B,\n\nreceives both updates at nearly the same instant and sends the results immediately.\nHowever, for the second update, Client B’s update takes longer in transit due to net-\nwork latency. The server waits, and so does Client A.\n\nThis behavior makes pure frame-locking suitable only for LAN games, but with\nmodifications, it can handle longer latencies. For example, Age of Empires [Bettner01]\nused a peer-to-peer architecture with adaptive communication turn lengths. Pauses\nwould occur when communications weren't received from one machine, but then the\nturn length would be increased to compensate. Instead of more pauses, players would\nexperience slightly diminished responsiveness overall. Unfortunately, the performance\nof the game was still limited by the slowest network connection among the players.\n\nEvent-Locking\n\nWhat is needed is a method that, in contrast to frame-locking, avoids slowing down\nall clients to the speed of the slowest one. We propose event-locking as an efficient\nmethod. Under this method, each client sends requests for events, which are evaluated\nby the server and, if approved, broadcast to all clients simultaneously.\n\nSection 5 Network and Muttiplayer\n\nFor example, imagine a typical real-time strategy game in which one player\ndecides that they want to move a tank. The player issues the movement command on\ntheir client, which performs preliminary legality checking. If legal, the client sends a\nRequestMoveTank packet to the server. The server then performs its own authoritative\nlegality check, and upon determining that the movement is legal, sends a MoveTank\npacket to all clients, including the one that originally made the request. (For more dis-\ncussion about selecting what actions to use as events, see [Dickinson01].)\n\nNote that not all clients will receive the event packets at the same time. Therefore,\nevents must be structured so that clients can begin execution at the appropriate time.\nFor example, a movernent event such as the MoveTank packet described above might\ncontain a series of waypoints, each encoded with an arrival time. A client that receives\nthe packet later can either warp the tank to the appropriate current position or, if the\ndifference is small, simply animate its movement slightly faster.\n\nIt might appear that this arrangement would introduce unacceptable delays for\nplayers. If it takes 300 ms or more for their tank to start moving, won't they be frus-\ntrated? The answer is to give the player immediate ‘request feedback.’ In the simplest\ncase, this feedback might be a client-side animation or sound effect. Or, for move-\nment requests, it could be safe to start ‘unofficial’ movement on the client if server\ndenial is unlikely. For example, in the MoveTank example, the tank driver can say “Yes,\nsir!” and start moving immediately, assuming that the server will confirm the move-\nment the vast majority of the time. Figure 5.1.2 illustrates this example.\n\nThere will be cases when the server rejects a client’s request or sends a path differ-\nent than the one the client generated. For example, perhaps just prior to Client A issu-\ning a RequestMoveTank, Client B requested the construction of a building near the tank.\nClient A might create a path that rolls the tank to the north and begins the movement\nin anticipation of the server's authorization. However, because the server knows that a\nbuilding now exists in the tank’s northerly path, it reroutes it to the west. When\nClient A receives the correct path, it must warp the tank from the unofficial path to\nthe correct one, and this might be extremely disconcerting to the player. However,\nunless latency is very high, significant warping will be rare; furthermore, for many\ngames, uncommon but dramatic warping is preferable to the alternative of common,\nbut less-dramatic freezing. Furthermore, the warping will only be experienced by the\nplayer with the poorer connection.\n\nThe fact that some units might be in unofficial positions on a given client means\nthat all important decisions must be handled by che server. In games that don’t have a\nsingle final authority, out-of-sync bugs can be a big problem [Bettner01]. In many\nreal-time strategy games, one of the client machines is also the server. Typically, unit\ncreation, destruction, path-finding, and targeting decisions are server-controlled and\nbroadcast. However, movement and attacks are animated independently on each\nclient, generating no network traffic.\n\nThe following code illustrates how path-finding packets might be exchanged\nbetween the client and server.\n\n6.1 Minimizing Latency in Reai-Time Strategy Games 491\n\nTime ClientA Server Client B\n|\n\n0\n4 !\nG9. ; !\nMoy, t\n\nPP |\nSy. | |\n1 i i\nI\n!\nMy !\nOp, |\nang !\n2 i\nI\n\n3\n\n|_|\n\nFIGURE 5.1.2 Zank movement example—the tank moves in boxed areas (gray is\nunofficial movement). All players see the tank arrive at the same time.\n\nvoid MoveableUnit: :moveRequest( Coord destination ) {\n// GENERATE a temporary path and\n// begin traversing it. This will\n// probably be ths same as the path the\n// server finds but not guaranteed:\nsetActivePath(generatePath({destination) );\n\n// SEND a AequestMovement the server,\n// even if this client also happens\n// to be the server:\nsendRequestMovement( destination );\n\n}\n\nvoid handleAequestMovement (\nMoveableUnit aunit,\nCoordinate destination\n\n)¢{\n// This is the handler for the destination\n// request packet. Note that all clients send\n// requests, even the client who also happens",
      "page_number": 466,
      "chapter_number": 49,
      "summary": "This chapter covers segment 49 (pages 466-476). Key topics include models, shading, and server. We propose to use a simple technique called normal distribution\nfunction (NDF) shading.",
      "keywords": [
        "Shading Models",
        "Handcrafted Shading Models",
        "NDFs NDF shading",
        "Shading",
        "NDF",
        "client",
        "Shading Models Jan",
        "model",
        "NDF texture",
        "normal distribution function",
        "diffuse term",
        "server",
        "NDF shading",
        "normal distribution",
        "term"
      ],
      "concepts": [
        "models",
        "shading",
        "server",
        "networking",
        "clients",
        "normal",
        "normalized",
        "normalize",
        "games",
        "time"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 8",
          "chapter": 5,
          "title": "Segment 5 (pages 41-49)",
          "relevance_score": 0.49,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 2",
          "chapter": 47,
          "title": "Segment 47 (pages 458-468)",
          "relevance_score": 0.47,
          "method": "api"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 25,
          "title": "Segment 25 (pages 482-502)",
          "relevance_score": 0.44,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 8,
          "title": "Segment 8 (pages 69-86)",
          "relevance_score": 0.43,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 4,
          "title": "Segment 4 (pages 31-40)",
          "relevance_score": 0.42,
          "method": "api"
        }
      ]
    },
    {
      "number": 50,
      "title": "Segment 50 (pages 477-487)",
      "start_page": 477,
      "end_page": 487,
      "detection_method": "topic_boundary",
      "content": "492\n\nSection 5 Network and Multiplayer\n\n// to be the server\n\n// This can only run on the client who\n// is also the server\nassert( thisClientIsAlsoTheServer );\n\n// €NCODE which unit is to move and compress\n\n// the path into a compact form:\nPath path = unit.generatePath{ destination };\nMovementPacket p = makeMovementPacket({unit, path};\n\n// SEND the packet to every client\n/f including the original sender\n{f/f even if that sender is also the server:\nbroadcast({ p );\n}\n\nvoid handleMovement(MoveableUnit &unit, Path &path) {\n// This function is called in response to\n// a MovementPacket.\n\n// Note: setting the path may induce warping if the new\n// path is not the same as the temporary path on\n\n// the requesting client\n\nunit.setPath{ path );\n\nTransport Layer for Event-locking—TCP\n\nAssumed in the implementation of event-locking is a reliable delivery protocol, such\nas TCP [Postel80-2]. In other game protocols—for example, those that might be used\nin a flight simulator, where units generate traffic as they move—dropped packets are\nnoncatastrophic because newer data will soon arrive to correct the loss. However, in\nevent-locking implementations, the server sends each critical event only once; and\ntherefore, the transport layer must ensure delivery. We have used and were pleased\nwith TCP for this. Some game developers have written their own reliable protocols on\ntop of UDP [Postel80-1], working under the theory that they can reduce latency by\n‘improving’ upon the TCP algorithms. We strongly advise against this approach. Not\nonly is the complexity of the task often underestimated, but so also are the ramifica-\ntions. Smooth operation of the Internet depends upon the well-defined and well-\ntested flow-control mechanisms of TCP. Attempting to override this flow-control\nwith a custom algorithm can induce catastrophic router feedback and possibly even\ntemporary denial of service. (In the case that the game developer deploys their own\ncentralized servers, this denial-of-service would most likely occur on their own\nrouters). One final point against UDP is that it is often firewalled on corporate net-\nworks because it is more difficult to secure. This implies that game developers will\nneed to consider a TCP connection as a protocol-of-last-resort, even in the case that\nthey implement a custom UDP-based system.\n\n6.1 Minimizing Latency in Real-Time Strategy Games 493\n\nTime Synchronization\n\nPerformance of event-locking is significantly improved by time-synchronizing the\nclients. For example, imagine that when a unit moves, the server broadcasts a message\nlike: “Move unit X such that it will arrive at position P at time 7 in the future.” With-\nout clock synchronization, time 7 on one client could differ from another client's by\nas much as the current packet latency (which might be much higher than the average\nlatency). In such a case, a player with lower latency will have an advantage because\nthey will see the world closer to the way the server sees it and are thus less likely to\nhave requests denied.\n\nExisting Clock Synchronization Protocols\n\nClock synchronization is a topic of major importance, and several well-developed\nprotocols already exist. The simplest technique is incorporated in the Simple Network\nTime Protocol (SNTP) [Mills96]. In this protocol, the client machine to be synchro-\nnized sends a datagram (UDP) packet to the server, which then immediately replies to\nthe receiver with the time as it is known to the server. Although simple, the SNTP\nalgorithm is not useful when accuracy is critical and latency is variable, because it does\nnot attempt to measure or compensate for latency.\n\nUnlike SNTP, the Network Time Protocol (NTP) [Mills92}] does attempt to\ncompensate for latency by sophisticated statistical methods. Unfortunately, NTP is\nvery complicated and, more importantly, slow to converge on the accurate time delta.\nThis makes NTP less than ideal for network game play where players expect games to\nstart immediately and are unwilling to allow for dedicated synchronization time.\n\nFurther complicating matters, NTP and SNTP both use UDP in place of TCP to\navoid the anomalous latency measurements induced by hidden retransmits thac TCP\nmight generate. As noted above, UDP is often firewalled by many Internet service\nproviders, especially by corporate WANs, and is therefore undesirable.\n\nA Simple Alternative: High Mode Elimination\n\nAn alternative to SNTP and NTP is required for games. Ideally, the protocol should\nbe reasonably accurate (150 ms or better), quick to converge, simple to implement,\nand able to run on stream-based protocols, such as TCE\n\nWe propose the following algorithm, which we call “stream-based time synchro-\nnization with elimination of higher order modes”:\n\n1. The client stamps the current local time on a ‘time request’ packet and\nsends it to the server.\n\n2. Upon receipt by the server, the server stamps its time and returns the packet.\n\n3. Upon receipt by the client, a time delta is calculated by delta = (current Time —\nsentTime) f 2.\n(Note that so far this algorithm is very similar to SNTP}\n\nSection 5 Network and Multiplayer\n\n4, The first received result is immediately used to update the clock, since it\nwill get the local clock at least into the right time zone.\n\n5. The client repeats Steps 1 through 3, five or more times, pausing a few sec-\nonds each time. Other traffic might be allowed in the interim, but should\nbe minimized for best results.\n\n6. The time deltas of each packet are accumulated and sorted in lowest-latency\nto highest-latency order. The median is determined by picking the mid-\npoint sample from this ordered list.\n\n7. All samples above that are approximately 1.5 times the median are dis-\ncarded, and the remaining samples are averaged using an arithmetic mean.\n\nThe only subtlety of this algorithm is the discarding of samples with a time delta\nmore than 1.5 times the median. The purpose of this is to eliminate packets that were\nretransmitted by TCP. To visualize this, imagine that a sample of 10 packets was sent\nover TCP and there happened to be no retransmission. In this case, the latency his-\ntogram will have a single mode (cluster) centered on the median latency. Now, imag-\nine that in another trial, a single packet of the 10 is retransmitted. The retransmission\nwill cause this one sample to fall far to the right on the latency histogram, typically\nmore than twice as far away as the median of the primary mode. By simply cutting\nout all samples chat fall far from the median, these stray modes are easily eliminated,\nassuming that they do not comprise the bulk of the statistics, which is likely that they\ndo not.\n\nOne very important consideration in time synchronization is that while the syn-\nchronization is running, #me might go backward! It is extremely critical that any time-\ndependent checks used during time synchronization (¢.g., animations during the\nstartup phase or startup timeouts) do not slave themselves to the clock being synchro-\nnized. Failure to heed this warning could result in odd ‘lock-up’ bugs that will not\nmanifest themselves until play-testing with players who span more than one time\nzone and are therefore likely to be mysteriously unreproducible within the developer's\nworkplace.\n\nThis basic algorithm was tested in NetStorm: Islands At War, a real-time, Internet\nstrategy game co-implemented by the authors at Titanic Entertainment (1997). The\nresults were satisfactory and usually resulted in synchronizations of less than 100 ms.\nAnecdotal evidence in large-scale trials suggested that bad synchronizations due to\nretransmission were infrequent, and when they did occur, were often symptomatic of\nan unusually bad Internet connection that would eventually cause more-catastrophic\nerrors (such as dropped connections), rendering the failure due to time-sync moot.\n\nThe following code sample demonstrates the statistical technique:\n\n// GLOBAL variables holding time samples:\n8&3\n\ntypedef double Time; // or appropriate type for platform\nTime timeSamples[MAX_TIME SAMPLES];\n\nint numTimeSamples; // Num valid samples in the timeSamples\n\n5.1 Minimizing Latency in Real-Time Strategy Games 495\n\n// CODE that calculate the time correction:\n{{——- J!\nassert({ numTimeSamples > 2 };\n\n// FIND the median:\nsort( timeSamples, numTimeSamples };\nTime median = timeSamples[ numTimeSamples/2 ];\n\n// FIND mean of samples less than 1.5 times the median:\nsum = (Time)d.0;\nint count = 0;\nfor({ int i=0; i<numTimeSamples; it+ } {\nif( timeSamples[i] - median < (Time})1.5 * median ) {\nsum += timeSamples[i};\ncount++;\n\n}\n4}\n\nTime carrectedDelta = sum / (Time}count;\n\nConclusion\n\nWe had great success using the event-locking method. Our first multiplayer RTS,\nNetStorm: Islands at War, was teleased by Activision in 1997, and despite having heavy\naction with hundreds of units animating at once over eight clients, it required only a\n9600-baud modem on the server machine and even less on the clients. Next Genera-\ntion magazine described the network play as “smooth as silk” even on terrible connec-\ntions. We hope you'll have similar results.\n\nReferences\n\n[Bettner01] Bettner, Paul and Mark Terrano, “GDC 2001: 1500 Archers on a 28.8:\nNetwork Programming in Age of Empires and Beyond,” Game Developer Con-\nference, 2001, available online at http://www.gamasutra.com/features/20010322/\nterrano_01. hem.\n\n[Dickinson01] Dickinson, Patrick, “Instant Replay: Building a Game Engine with\nReproducible Behavior,” Gamasutra.com, July 2001, available online at\nhetp://www.gamasutra.com/features/20010713/dickinson_01.htm.\n\n[Mills92] Mills, David, “Network Time Protocol (Version 3) Specification, Imple-\nmentation and Analysis,” University of Delaware, March 1992, RFC-1305, avail\nable online at hetp://www.eecis.udel.edu/-mills/ntp.hum.\n\n[Mills96] Mills, David, “Simple Network Time Protocol (Version 4),” University of\nDelaware, October 1996, RFC-2030, available online at http://www.eecis.udel\n.edu/~mills/ntp.htm.\n\n[Postel80-1] Postel, J., “User Datagram Protocol, STD 6,” USC/Information Sci-\nences Institute, August 1980, RFC-768.\n\n[Postel80-2} Postel, J., “Transmission Control Protocol, STD 6,” USC/nformation\nSciences Institute, August 1980, RFC-761.\n\n5.2\n\nReal-Time Strategy\nNetwork Protocol\n\nJan Svarovsky\n\njan@svarovsky.com\n\nhis gem aims to explain a simple and practical system for connecting up to 10\n\ncomputers over the Internet to play dynamic strategy, management, or combat\ngames. Star Topia [StarTopia01) is a real-time strategy (RT'S) game that supports four-\nplayer multiplay over the Internet. Player interaction involves placing and maintain-\ning facilities, interacting with individual characters, and ordering troops around the\nbattlefield. This gem is based on the simple network protocol we used for this game.\nAlthough this gem is primarily a description of the general principles, it includes our\nexperiences, both good and bad, in an actual commercial implementation.\n\nFirst, we will briefly discuss common protocols that we have come across, then\ncover the basic principles. Following that will be some refinements to the protocol, a\ndescription of modules we found useful, and some of the pitfalls we encountered. We\nwill also include a simplified example game. Part of the system found in Star Topia is\non the CD-ROM.\n\nOther Protocols\n\n496\n\nThe systems that concern us here are for games involving up to 10 players, rather than\nthose for massively multiplayer online games.\n\nClient/Server: First-Person Shooter\n\nThe most common protoco! for first-person action games is that each player is sitting\nin front of a ‘client’ program, which could almost be considered as a dumb terminal.\nA server runs the game, effectively remote from any client, even if in practice it resides\non the same machine as one of the clients. The server tells each client what it can see.\nEach client tells the server what it wants to happen, based on player controls. There\nare refinements to smooth out the game, based on the client’s prediction of server\nresponse.\n\nThis protocol benefits from its simplicity and its ability to avoid cheating (since\nthe server can veto some illegal acts). Clients can drop in and out, but the game on the\n\n6.2 Real-Time Strategy Network Protocol 497\n\nserver lives on. However, it does require thar the client’s visible game state is small\nenough that it can be repeatedly transmitted. This limitation eliminates this protocol\nas an option for real-time strategy games where a tremendous amount of game state is\ninvolved.\n\nPeer-to-Peer\n\nWith the peer-to-peer protocol, no computer in the game is more important than any\nother. Each computer ‘owns’ a part of the game state and has a final say on what hap-\npens to that part (typically, the game-player entity and a few AI agents).\n\nThe benefit of this protocol is that the game state owned by the computer is\ninstantly updated. In an ideal world, your computer owns the AI agents that are clos-\nest to you, since they are not as important to other players that are farther away. The\ndownside is that any interaction between two characters or objects in the game must\nhave a corresponding network packet so that different computers can establish a con-\nsistent outcome. Of course, as the size of the game state increases, the number of\npackets sent around the network communicating state increases quadratically.\n\nLockstep\n\nAs the name implies, a game using this protocol runs in lockstep with ali computers\ninvolved. They start with the same game state, and game time is split into turns. With\neach turn, each computer models the game world to advance the action by one step.\nAt the end of the turn, each machine tells every other machine what actions the user\nhas performed. Since all of the computers know what all users are doing, they can col-\nlectively model the next game turn and stay synchronized.\n\nThis is an easy protocol to implement and has a relatively low bandwidth, since\nuser input (which might be idle for many frames) is all that needs to be transmitted.\nThe bandwidth is also unrelated to the size of the game state, which is a big advantage\nfor real-time strategy games.\n\nA problem with this protocol is chat the number of game turns per second is lim-\nited by the round-trip network delay; at the end of each game curn, the machines\nmust receive at least an acknowledgement from all the other machines before model-\ning the next turn. Keeping the machines synchronized is also fairly difficult. You have\nto ensure that no user actions directly affect the game, but rather indirectly affect the\ngame via the network code. This ensures thar all machines are acting on the same\ninformation, and this discipline must be followed. Similarly, you have to keep their\nrandom-number generators synchronized.\n\nIn a similar way to the client/server system, some cheats are difficult because any\nillegal changes enacted on the game state will cause that machine to fall out of sync\nwith the other machines. On the other hand, because the entire game state is available\non each machine, other cheats become possible—for example, changing the game to\nbe able to see more of the map than usual.\n\n498 Section 5 Network and Muitiplayer\n\nOur Protocol\n\nWe based our protocol on the lockstep system, with several changes to limit its short-\ncomings. One machine is declared the server in order to keep the network traffic lin-\nearly proportional to the number of players. Otherwise, the network traffic is\nproportional to the square of the number of players. Each client only sends one\npacket per event (to the server), rather than one to each of the other clients. This\nmethod enables the server to be in charge of negotiating the game state when a\nmachine drops its connection.\n\nWith lockstep, the clients collect input from the others between each game turn.\nHowever, we can remove this round-trip network delay between turns. The server\nsimply broadcasts ‘advance the turn’ packets on a regular basis, and user input from\neach client is broadcast to all machines upon being received by the server. This means\nthat each uset-input event must make the trip to the server and back before it can be\nprocessed, but the game turns continue to occur at a steady pace in the meantime (see\nFigure 5.2.1).\n\nThe main features of this system are as follows:\n\n* At the start of play, the state of the game on all machines is identical.\n\n* The server then sends an identical stream of packets to the clients. This is a steady\nstream of ‘advance the turn’ packets, interspersed with user input.\n\n¢ The game progresses forward based solely on information received from the\nserver, which is identical for all machines. Therefore, the game stays synchronized\nacross the network.\n\n* For this reason, it is vital to decouple local user input from the local game state.\nUser input gets transmitted to the server, which in turn broadcasts them to the\nother machines so that parallel action can take place.\n\n© Game turns don’t necessarily happen absolutely simultaneously on all computers,\nbut game events occur in the same order.\n\n* There is at least one round-trip delay between a user input and its effect on-\nscreen. (This will be discussed in the next section.)\n\n* All network packets must have guaranteed delivery. You want all user actions to\nget processed, so packets to the server must arrive. Also, packets from the server\nmust arrive in order, so that all clients receive identical event streams.\n\nNumber of Game Turns per Second\n\nSeveral factors must be considered when deciding how many game turn updates\nshould be issued per second. As will be discussed in the next section, the graphics\nengine does not draw the game state as it is, but rather as an interpolated version. This\nmeans that the number of turns per second is not directly visible to the player, so we\nmust look elsewhere for this design decision.\n\nThere is a balance, of course. Lowering the game-turn rate has the following\nadvantages:\n\n499\n\nGame controls\nan clients...\nsend information\nto server.\n\nspa dh\nSie ania ppthedb heed spe\n22 8b edo de a Be Sr AB RE ROG ob ob iy Gir Benen we teninte aie MM HR ae mentee cee i\neis Bongo ap guage Aiansyt hs  t DDD yy BO aD ap ee tes\n\nServer clock\n\nproduces steady\nstream of\n\npagans enaee “increment\n\ngameturn\" packets\n\nUser inputs get\n\ninserted into\nstream...\nBabohheiay gf\n‘REARS Deh i pe ae ae aetna a be eae a\nSeat SAteanye gene greene oh ge A\nwhich gets\nduplicated...\n\nand broadcast...\n\nen,\nback to affect the\ngame world on\nthe clients.\n{-———————}\n\nFIGURE 5.2.1 The server/client and game turn/time relations.\n\n* Most of the time, the only network activity that occurs is the server issuing game-\nturn update packets, so a lower number of turns lowers this expected bandwidth.\n* Most game-turn processing is at a constant cost per turn, no matter how many\nturns per second there are, The simplest example is the movement of objects with\na constant velocity. Lowering the game-turn rate reduces the CPU cost of model-\n\ning the game.\nOn the other hand, there are advantages to higher turn rates:\n\n500\n\nSection 5 Network and Multiplayer\n\n* Some game processing has a constant cost per second, rather than cost per game\nturn. For example, if your robots are meant to scan the surrounding area once per\nsecond, then halving the number of turns per second will double the amount of\nscanning that has to be done per turn. In the extreme, the processing of the world\nwill be visible as a pause in the smooth rendering. In Star Topia, it was possible to\ncreate this effect by running a very low-spec computer with a higher-spec video\ncard and then filling the game area with lots of activity. The frame rate is high,\nbut the computer struggles with processing the game.\n\n* When user input arrives, its effect is only realized in the game the next time it is\nmodeled. This means that, on average, the response time of the game is lagged by\nhalf of a game turn. If game turns happen more often, this effect is reduced.\n\nIn StarTopia, we eventually settled on six turns per second. The Dungeon Keeper\nteam [Keeper01] used four turns per second. In both cases, different numbers were\nexperimented with, and in fact varied frequently during game development. A similar\nnumber of turns per second should work for most real-time strategy games.\n\nRefinements\n\nOnce the basic protocol has been implemented, there are some improvements that\nwill make the whole game much more playable.\n\ninterpolating Between Game Turns\n\nFirst, the clients anticipate when game turns will arrive from the server and try to\ninterpolate the scene smoothly between turns. In reality, all that is arriving is permis-\nsion from the server to model the next turn, possibly with some new user input.\n\nThough the world is modeled at a steady number of updates per second, what is\nshown on-screen can be updated as frequently as each client computer can handle.\nPlayers with faster machines get a much smoother view, but the game is the same for\nall players.\n\nIt is impossible to correctly anticipate the precise arrival of the next turn, of\ncourse, so any prediction system that comes close is acceptable. We found that basing\nthe prediction on the weighted average of the previous few arrival times was adequate.\n\nThis improvement needs no prediction of future game state. You just interpolate\nbetween the last two game turns you modeled. This interpolation can be linear for\nmost things, such as object position, even when there are as few as four turns per sec-\nond. Ideally, the system will correctly anticipate the moment the next game turn\noccurs, so you can continue with the interpolation. This adds up to one extra game-\nturn fag, which can be a significant time, but it allows for better gameplay.\n\nHiding the Lag\n\nThe main issue that remains is the very noticeable delay between player actions and\ntheir effects on the game world. User input only affects the game after the event has\n\n5.2 Real-Time Strategy Network Protocol 501\n\nmade the trip to the server and back, adding a game-turn delay plus an extra turn for\nthe interpolation.\n\nYou can effectively conceal this lag in a management-style game by separating the\ngame into the interface, the network code, and the game state. The game state is the\nonly thing that must stay synchronized. The ‘interface’ is expanded to include as\nmuch of the response of the game to the user as possible.\n\nExamples of game state that we (re)classify as interface are:\n\n* In a game where the player creates rooms or buildings, partially designed room\nlayouts are all done locally, and only the final room design is broadcast.\n\n¢ The Al’s response to commands is delayed, but the user interface response to\ncommands, such as flashing circles around targets, gets immediately processed\nlocally. The fact that your tank actually turns to fight its target a quarter of a sec-\nond later is unnoticeable to the player.\n\n* Camera movement doesn’t usually need to be transmitted if where youre looking\ndoesn’t affect the game.\n\n* Finishing touches to the GUI should happen only on the local machine. For\nexample, our characters’ heads track the mouse pointer around the screen when\n\nthey are being talked to directly.\n\nIt is, in fact, possible to use this protocol in a game that involves more-direct\ninteraction with the world, such as a first-person shooter, but it is awkward. One\nexample is player character movement. The ‘move left’ packet would change to ‘I\nwant to have moved left on game turn x.’ The image displayed to the local user would\nupdate as if the move had been allowed. Every client, on receipt of the event packet\nfrom the server, would decide whether or not the move was possible. However, the\ndecisions would be identical on all machines, leaving the local machine with the task\nof covering up any denied actions. .\n\nHost Migration\n\nSince one machine is dedicated as the server, a problem arises when that machine\nleaves the game. This is quite likely to happen, since players are unlikely to be willing\nto leave their machines connected for the sake of the others.\n\nTo handle this situation, you must first make sure that there is as little state as\npossible on the server. The system described above is ideal because the server is merely\na clock that counts game turns and acts as a short-term holding bay for user input\npackets.\n\n‘The remaining clients must decide which machine will host the new server. Dif-\nferent clients might have received different amounts of the event stream from the\nserver. The most up-to-date version must be used because the client that has received\nthe most-recent events will not be able to roll back.\n\nFor a more seamless transition, clients should check if they had sent any packets\nto the server that did not make it into the new broadcast stream. These should then\n\n502\n\nSection 5 Network and Multiplayer\n\nbe resent. Storing perhaps five seconds of network packets is not particularly expen-\nsive, due to the small nature of the packets.\n\nIn StarTopia, we supported server dropout to a lesser extent than this. Most\ngames were just one-on-one, so server dropout happened less often than expected. We\nhad a frequent autosave system {every minute or so). If for some reason, the server\nleft, the remaining machines could just restart from their latest autosave with very lit-\ntle effect on the game.\n\nHandiing a Slow Computer\n\nThe server will keep generating game turns at a steady rate, which might be too fast\nfor one of the clients, even if only for a short while. If game turn update requests are\narriving four times a second, but the client takes half a second to model a game turn,\nit will never catch up and will freeze, unable to advance the game fast enough.\n\nWe simply added an occasional extra packet that clients would send to the server,\nwhich would not be rebroadcast. This would tell the server what percentage of CPU\ntime was taken by modeling the game. The server could then slow down gameplay\nand allow the slower client to catch up by ensuring that the CPU modeling cost had\ndropped sufficiently for all the clients.\n\nNext, we will describe four other techniques that we found useful.\n\nSimulating Lag in Single Player\n\nEven in the single-player game, there should be a simulated network lag. This worked\nwonders for us, because the majority of game development and testing was done in\nthe single-player mode. When we started testing the network game, the testers were\nvery worried about the effect the network lag would have on playability. Ac this point,\nwe could smugly point out that they'd been playing with lag all along. The game was\nprogrammed and tested against network lag by incorporating it from the start.\n\nPointer-to-Unique-ID\n\nAlthough the game state might be completely synchronized, pointers won't necessar-\nily be equal across machines, so any object (in C++) chat must be referred to by net-\nwork packets, such as ‘Tm clicking on this unit’ needs a unique ID. This is relatively\neffortless; simply derive all referenced objects from a base class that contains a unique\nnumerical ID (and a pointer-to-number conversion function), and include a lookup\ntable for number-to-pointer conversion.\n\nThere are some subtle pitfalls to watch out for. For instance, when objects are\ndestroyed and new objects are assigned the same number, some network packets\nmight exist that refer to the old object. This is fixed by attaching a small extra number\nto each ID, which is incremented when the object dies and the ID is used for another",
      "page_number": 477,
      "chapter_number": 50,
      "summary": "This chapter covers segment 50 (pages 477-487). Key topics include game, time, and server. In other game protocols—for example, those that might be used\nin a flight simulator, where units generate traffic as they move—dropped packets are\nnoncatastrophic because newer data will soon arrive to correct the loss.",
      "keywords": [
        "game",
        "Network Time Protocol",
        "game state",
        "game turn",
        "server",
        "Time",
        "Network",
        "Real-Time Strategy Games",
        "protocol",
        "Strategy Network Protocol",
        "Strategy Games",
        "Time Protocol",
        "Network Protocol",
        "turns",
        "client"
      ],
      "concepts": [
        "game",
        "time",
        "server",
        "protocol",
        "client",
        "turns",
        "network",
        "packet",
        "player",
        "latency"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 8",
          "chapter": 47,
          "title": "Segment 47 (pages 448-460)",
          "relevance_score": 0.66,
          "method": "api"
        },
        {
          "book": "Release It! Design and Deploy Production-Ready Software",
          "chapter": 7,
          "title": "Segment 7 (pages 51-58)",
          "relevance_score": 0.62,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 7",
          "chapter": 54,
          "title": "Segment 54 (pages 522-529)",
          "relevance_score": 0.61,
          "method": "api"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 17,
          "title": "Segment 17 (pages 326-347)",
          "relevance_score": 0.58,
          "method": "api"
        },
        {
          "book": "Designing Data-Intensive Applications",
          "chapter": 32,
          "title": "Segment 32 (pages 299-308)",
          "relevance_score": 0.57,
          "method": "api"
        }
      ]
    },
    {
      "number": 51,
      "title": "Segment 51 (pages 488-496)",
      "start_page": 488,
      "end_page": 496,
      "detection_method": "topic_boundary",
      "content": "5.2 Real-Time Strategy Network Protocol 503\n\nobject. An alternative is to simply use a much larger number of object [Ds and never\nreuse [Ds, or reuse them in least-recently used order. This will increase the size of the\nlookup table for [D-to-pointer conversion, or it can be turned into a hash table. In\nStarTopia, a surprisingly large number of objects were created and destroyed in a typ-\nical session.\n\nDebugging Out-of-Syncs\n\nThe major part of network game debugging was tracking down reasons why clients\nwent out of sync with each other. Detecting that the game was out of sync was done\nby a simple checksum system. The checksum included the number and position of\nobjects, and little else.\n\nOnce the game is out of sync, looking at the differences in the game state tells you\nvery little. So, the best strategy is to litter the code with printts, especially around\ndecision points in the code. You then compare the output from the two machines to\nfind where they went out of sync.\n\nOf course, printfs are expensive. Hence, since most of what we printed were\nnumbers and constant strings, we kept a large queue of little structures, which could\ncontain either pointers to strings or numbers. The printf operation simply wrote\nonto the end of this queue. The pointers were then dereferenced to produce the ‘sync\ndump’ only when the game went of sync. For simplicity, the output was written out to\na shared network drive with a machine-specific filename.\n\nPacket Loss\n\nAs previously mentioned, all network messages in our system must be guaranteed to\narrive in the right order. We found it worthwhile to roll our own guaranteed messag-\ning system, which was effectively a layer under the protocol described here. There is a\nstream of messages from each client to the server, consisting of user input and some\nhousekeeping packets. There is also one stream from the server to each client, con-\ntaining game-turn increments and user events. Though each client receives the same\ninformation, the streams were handled independently.\n\nPitfalls in StarTopia\n\nWe will describe the most common problems we had when implementing this sys-\ntem. Of course, this section is specific to StarTopia, but the lessons we learned will\nhopefully help you with your project.\n\nOut-of-Sync\n\nAs mentioned above, this was by far our biggest problem, but it was not insuperable.\nAlthough there was a huge ammount of detail in the game, we reduced the out-of-synes\nto the point that we were unable to find them during testing. At this point, we\n#defined out the ‘syncdebug’ module and put in a message suggesting that people try\n\n504\n\nSection 5 Network and Multiplayer\n\nrestarting the game from the latest autosave. This message was never found (unless we\ncheated to trigger it).\n\nOur main cause of out-of-sync bugs was that, out of necessity, we had written a\nlarge portion of the game before the network protocol was incorporated. So, legacy\ncode that was left in by accident would break the rules of the protocol. The most\ncommon out-of-sync bugs due to this were [Ireland01]:\n\n* Changing game state directly rather than making the change via a network packet\nthat would be broadcast around to all clients.\n\n* Game code referring to the player that is local to the player’s machine.\n\n* Game code referring to the camera.\n\n* Game code referring to the system clock for timing, rather than the game turn.\n\nThese problems can be avoided by keeping the interface and game state as far apart\nas possible. For example, no code that controls game state should know which player is\nsitting in front of the machine or where the player is looking. Once you have complied\nwith this principle, the remaining common reasons for out-of-sync scenarios are:\n\n* Uninitialized data.\n\n* Different versions of data files. Once the game is shipped, this is less of a prob-\nlem. But during development, when people can be running many different ver-\nsions, it is almost worth having a checksum of all data loaded into the game.\n\n© Different executables. Again, the simplest solution is to make the game insist that\nall players use identical executables, though this can get in the way of some\ntesting.\n\nEvent Packets Becoming Irrelevant\n\nThe typical instance of this pitfall or bug is that an event packet refers to some object\nthat is destroyed during the time the packet makes the trip to the server and back.\nAlternatively, a packet describes a change for an object, but the object is no longer in\nan appropriate state to receive this event. (For a while, we could hire and fire charac-\nters in our game, even if they died in the meantime!)\n\nOf course, the tests for this are simple—the unique-ID system described above\ncatches object deaths. In addition, you should always check if your object is in a fit\nstate to respond to an event. What makes this a pitfall is that it happens most often\nwhen players are sending many packets or if they are simultaneously referring to the\nsame object. These situations happen more frequently coward the end of game devel-\nopment, when the game is near enough to completion for big showdowns to be\nplayed. Hence, these bugs can go unnoticed for an inconveniently long time.\n\nExample Game\n\nOtt THE CD\n\nSync debug has been included on the CD-ROM. We encourage you to look at the\ncode and comments. More-complete modules, such as synedebug, have been\n\n3.2 Real-Time Strategy Network Protocol 505\n\nincluded, so they are a good basis for a practical implementation. We encourage you\nto leok at the code and comments.\n\nConclusion\n\nThis protocol was easy to implement and worked well for our game. It gave us great\nfreedom to write a game full of many concurrent events, without worrying about\ntheir effect on network bandwidth. We hope this gem will help you, should you wish\nto try our protocol.\n\nI would like to thank the other members of the team who built StarTopia, espe-\ncially Tom Ireland, who gave me helpful comments as I wrote this gem.\n\nReferences\n\n(Ireland01) Ireland, Tom, list compiled during game development, July 2001.\n\n[Keeper01] Bullfrog, Dungeon Keeper I, PC game, information available online at\nfittp://wwrw.dungeonkeeper.com, June 1999.\n\n[StarTopia01] Mucky Foot, Star Topas PC game, information available online at\nhttp://www.muckyfoot.com, July 2001.\n\n5.3\n\nA Flexible Simulation\nArchitecture for Massively\nMultiplayer Games\n\nThor Alexander, Hard Coded Games\nthor@hardcodedgames.com\n\nassively multiplayer (MMP) games offer fun and addictive gameplay to hun-\n\ndreds of thousands of players who meet online and battle each other or join\nforces to fight common foes. Constructing such large and persistent Internet-based\nplaygrounds is one of the most challenging aspects of game development and possibly\nsoftware development in general. An MMP consists of many components, including\nnetworking, rendering, database access, and game simulation. This gem focuses on\ngame simulation, and it presents a solution that provides for a flexible simulation\narchitecture that can be reused to create many different styles of online games.\n\nA commercial MMP game is much mote of a service than a product. A successful\nonline game service will have a lifetime of at least five years. Over this time, the code\nbase must be maintained and modified in a timely fashion into a production or five\nenvironment with hordes of pesky players critiquing every change. To survive in such an\nenvironment, a code base needs to be built on a solid engineering foundation. To\nachieve this, we will leverage techniques from both the Design Patterns tools and UML.\n\nDesign Patterns are very useful and proven software engineering tools that have\ngained favor in recent years. A pattern is a recurring solution to a standard problem.\nFor more information on patterns, see [Gamma94]. The Unified Modeling Language\n(UML) is a design process for visualizing and specifying a software system. This gem\npresents UML class and sequence diagrams. For an in-depth discussion of UML, see\n[Booch98].\n\nArchitecture Overview\n\nFirst, let us overview the architecture we wish to achieve for MMPs.\n\nClient/Server Components\n\nAt its core, an MMP is a client/server system. It provides a network layer that\nrelays message packets across the Internet between the client and server processes.\n\n506\n\n5.3 A Flexible Simulation Architecture for Massively Muitiplayer Games 507\n\nThese message packets are received and interpreted by the game-simulation layer. This\nlayer is responsible for maintaining the consistency of the game state-space on the\nclient and the server. Detailed simulation of the physical representations of the objects\nthat occupy this state-space is handled by the physics layer. Since the client rendering\nlayer presents only what the player can perceive, the number of objects simulated at\nany given time on the client need only be a subset of those on the server. This allows\nthe client to perform the physics simulation at a much higher level of detail than the\nserver physics layer. See Figure 5.3.1 for an overview of this architecture.\n\nPhysics (Detailed) Physics (Simple)\na\n\n[ Game Simulation ; Cl Game Simulation\n\nServer\n\nClient\nFIGURE 5.3.1 Client/Server game architecture.\n\nSimulation by Proxy\n\nThe game-simulation layer on the server holds the one true representation of the\nstate-space. It must serve as the arbitrator if any clients chat it serves fall out of synch.\nThe server broadcasts changes to the actors and objects in the state-space as simula-\ntion events to the client. The client uses these events to update the proxy objects that\nmake up its local copy of the state-space. The user interacts with the server simulation\nby sending action requests that the server simulation layer must validate before the\naction takes place. Figure 5.3.2 depicts the request/event flow. For security reasons, an\n\nClient Server\nSimulation Simulation\n\n+ [___Aation Requests >> +\n+ k << SimuaionBents | 77 k\n\nProxyActors Actors\n\nFIGURE 4.3.2 Chtent/Server simulation via Actors and Prexies.\n\n508 Section 5 Network and Multiplayer\n\nMMP design must never trust the client’s representation of state-space. For a detailed\ndiscussion on issues surrounding simulation by proxy, refer to the Virtual Simultane-\nity section of [Perlin96].\n\nSupport Classes\n\nBefore we jump into the core classes of our architecture, we need to define a few sup-\nport classes that we will layer to construct the core classes of the system.\n\nDictionary/Hash Tables\n\nA dictionary is an abstract data type that stores items associated with values. Basic\noperations are AddEntry, LookupEntry, and RemoveEntry. A good dictionary imple-\nmentation method is the hash table, which is an associative array in which keys are\nmapped to array positions by a hash function. Figure 5.3.3 shows the class diagram\nfor such a dictionary. This dictionary will prove to be the workhorse data structure of\nthis architecture.\n\n-HashMap\n\n-argList\n-channel\n-sourceld\n-targetid\n-type\n\n+GetargListd\n+GetChannat)\n+GetSourceldd\n+GeiTargetad\n\n+GefType\n\nFIGURE 5.3.3 Support class\ndiagrams.\n\nSimulation Events\n\nSimulation events are the transactional objects of this system. When an actor interacts\nwith the environment by performing actions, the results of these actions are broadcast\nto other actors that can perceive them as events. An event object contains the event\ntype, source-actor ID, and target-actor ID, as well as a list of arguments specific to the\nevent type. Additionally, it has a channel attribute thar is used by the receiver of\nthe event to filter out the categories of events that it is interested in.\n\nSimulationState\n\nSimulationStaie is our implementation of the state pattern. For the sake of clarity, we\npresent a simplified version of the pattern that does not include a state machine or\nstate manager. (For a detailed and more-robust implementation, see [Boer00] and\n\n5.3 A Flexibie Simulation Architecture for Massively Multiplayer Games 509\n\n[Dybsand00].) SimulationState serves as the base class for all states in our architec-\nture. Basic operations are CanTransition and Transition. The base CanTransition is\na pretest method that validates if the specified context object can make a valid cransi-\ntion to this state. Derived state classes can implement additional checks to meet their\nindividual needs. The Transition method is where all of the real work takes place.\nEach child class will need to implement this method and provide any specific behav-\niors that occur when this state is entered.\n\nActionState\n\nActionStates are the typical game-simulation operations, such as slapping an opponent\nor opening a door. Each ActionState has its own durationTime attribute that details\nhow long this action takes to execute. Typically, this attribute is used to synchronize\nthe server simulation with the animation play-back time on the client. The Action-\nState also maintains the startTime attribute. This is useful for calculating the time\nindex into an animation when a spectator enters the view of the actor sometime after\nthat actor has already transitioned into an ActionState (see Figure 5.3.4).\n\nrate\n\n-id -durationTime\n-transitions : Dictionary [“Usercortrotsiate | -startTime\n\n+AddTransitiong\n\n+CanTransttiond\n+Getdd\n\nond] | aiContratstate |\n+GefTransitions0 -AlControlData +ClearLastActionRequesi? +SetOurationTimed\n+PerformAc\n\n+ClearActionRequestQueve()\n\n+PerformActiond +SetStartTimed\n\n-QueueActionRequestd +Transitiond\n\n+RequestactionO\n\n+RemoveTransition)\n\nFIGURE 5.3.4 Simulation state class diagrams.\n\nControlState\n\nA ControlState defines from where the associated actor can accept commands. This\nallows the actor to be under player control, AI control, or in some additional mode,\nsuch as a scripted state for use with in-game cut-scenes. The ControlState can be\nswapped on the fly to transition the actor between these states. Another use for Con-\ntrolStates is for training by observation. When in such a training state, the players\ncontrol the actor as they would in the user-controlled state, with the computer eaves-\ndropping in on the actor and learning from their actions. (For more details on train-\ning by observation, refer to [Alexander02a].)\n\nUserControlState\n\nThe UserControlState maintains a queue of pending action requests that have been\nreceived on the server from the user on the client. This control state’s PerformAction\nmethod will pull requests from this queue when it is called.\n\n510\n\nSection 5 Network and Multiplayer\n\nAlControlState\n\nThe AlControlState is responsible for determining the appropriate action to perform\nwhen an actor in this state calls its Performaction method. This decision process\nshould be implemented with an AI technique that best suits a given simulation’s game\nmechanics, such as finite state machines, neural nets, or fuzzy logic. For one example\nof such a decision subsystem, refer to [Alexander02b].\n\nGore Classes\n\nNow, let us discuss the core classes for this architecture.\n\nSimulationObject\n\nA Simulation Object (SOB) forms the base for all of the core classes that the simulation\ndeals with, including actors, areas, items, and obstacles. Figure 5.3.5 shows the core-\nclass hierarchy. An SOB is assigned its own ID that designates it as a unique object.\nSimulationObjects communicate with each other by sending simulation events. They\ncan subscribe to the events that they care about with other simulation objects. Each\nSOB maintains a subscribers dictionary that it uses to publish events that it generates.\n\n=\n=\n\nHonOdject\n\nSESE\n\n=\n\nFIGURE 5.3.5 Core class hierarchy.\n\nAn SOB might contain other SimulationObjects. Each SOB maintains a con-\ntents dictionary of the objects that it contains, as well as an ownerld that refers to the\nSOB that contains it. SimulationObject containment serves as an abstract concept\nthat can facilitate many features for the child classes. Actor subclasses can use it to\nimplement inventory-item management systems. Items can become in-game con-\ntainers, like chests and bags, which contain other items. Areas, which are abstract\nspatial representations, make use of containment to track other SimulationObjects\nthat enter and exit their boundaries.\n\nSimilar to containment, SimulationObjects also maintain a dictionary of links\nto each other. Links provide an aggregation, or ‘whole/part’ relationship, between\n\n5.3 A Flexible Simulation Architecture for Massively Multiplayer Games 511\n\nSOBs. This provides for a simple, yet powerful way to enable objects to receive events\nfrom component parts on a transitory basis. Links can be used to implement portals\nor doorways between areas that can be opened and closed. Compound items can be\nconstructed from parts by linking items together.\n\nSimulationObjects also provide a property dictionary for storing game system-spe-\ncific attributes per-object in a data-driven fashion. Each simulationObject subclass\ncan add its own properties to the dictionary as needed. The contents of this dictionary\ncan be replicated down to the associated proxy object on the client in an intelligent,\njust-in-time fashion that minimizes the network-traffic overhead. Examples of prop-\nerties include attributes like the object’s location in the world space, movement speed,\nhit points, mana, and so forth.\n\nFinally, SimulationObjects provide a persistence mechanism that allows the sim-\nulation layer to interface with storage systems in a generic fashion. Each simula-\ntionObject maintains a dirty flag that is set when persistent properties and data are\nchanged. The simulation layer can call the Store method on the SOB when needed.\nStore tests the dirty flag and archives the object if it is set. The Restore method per-\nforms the converse operation and loads the object into the simulation. These methods\ncan be implemented in the target application to save the objects to flat-file formats,\nsuch as XML or relational databases such as Oracle or MS-SQL (see Figure 5.3.6).\n\n-contents : dictionary\n-diny: boolean\n\n-id\n\n-links : dictionary\n-ownerld\n\n-properties ; dictlonaty\n-subscribess : dictionary\n\n+8ubserived\n+Unlinkd\n+Unsubscribed\n\nFIGURE 5.3.6 Simulation Object class diagram.\n\nPerformer\nThe abstract Performer core class provides for the shared client/server functionality\n\nand common interface of the Actor and ActorProxy simulation object classes. The Per-\nformer class maintains a schedulePriority attribute that is used by the simulation for",
      "page_number": 488,
      "chapter_number": 51,
      "summary": "This chapter covers segment 51 (pages 488-496). Key topics include game, simulation, and simulated. An alternative is to simply use a much larger number of object [Ds and never\nreuse [Ds, or reuse them in least-recently used order.",
      "keywords": [
        "game",
        "Simulation",
        "game simulation",
        "Game Simulation Server",
        "flexible simulation architecture",
        "server",
        "server simulation",
        "client",
        "Massively Multiplayer Games",
        "game state",
        "object",
        "Simulation Server Client",
        "state",
        "Server game architecture",
        "Simulation Object"
      ],
      "concepts": [
        "game",
        "simulation",
        "simulated",
        "state",
        "object",
        "dictionary",
        "classes",
        "network",
        "events",
        "server"
      ],
      "similar_chapters": [
        {
          "book": "Game_Engine_Architecture",
          "chapter": 36,
          "title": "Segment 36 (pages 719-740)",
          "relevance_score": 0.69,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 47,
          "title": "Segment 47 (pages 448-460)",
          "relevance_score": 0.68,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 21,
          "title": "Segment 21 (pages 197-204)",
          "relevance_score": 0.63,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 1",
          "chapter": 25,
          "title": "Segment 25 (pages 227-237)",
          "relevance_score": 0.62,
          "method": "api"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 18,
          "title": "Segment 18 (pages 348-366)",
          "relevance_score": 0.62,
          "method": "api"
        }
      ]
    },
    {
      "number": 52,
      "title": "Segment 52 (pages 497-504)",
      "start_page": 497,
      "end_page": 504,
      "detection_method": "topic_boundary",
      "content": "512 Section 5 Network and Multiplayer\n\nscheduling. A performer also maintains the object’s currentActionState, which rep-\nresents the action that the object is currently performing. This attribute is determined\nand set by the PerformAction method. More-advanced simulations can be imple-\nmented by expanding the object to contain several parallel action states for mutually\nexclusive activity layers, such as movement states, posture states, conversation states,\n\nand so forth (see Figure 5.3.7).\n\n-currentActionState : ActionState\nid\n-schedulePriority\n\n+GetCurrentActionStated : ActionState\n\nFIGURE 5.3.7 Performer class diagram.\n\nActor\n\nAn Actor is defined to be a server-side simulation object that is capable of interacting\nwith the simulation environment. Actors have a ControiState that allows them to be\ncontrolled by a number of different agents, including players, Al, and scripted cut-\nscenes. The PerformAction and RequestAction methods are delegated down to the\ncurrent control state, where the controlling agent is responsible for providing the\nappropriate implementation. The Actor class also maintains an eventQueue that is\npopulated by the ReceiveEvent method (see Figure 5.3.8). This queuing of events\nallows the Actor to batch them up and defer handling them until its next scheduled\nPeformAction method.\n\nThis passive, just-in-time event-handling scheme allows the system to avoid hav-\ning to decide what it needs to do every time an Actor receives an event. In a high-\n\n+ProcessEventQueued\n+RecerveEventd\n+RequestActiong\n+ResetControlStated\n-etCurrentControlStated\n\nFIGURE 5.3.8 Actor class diagram.\n\n5.3 A Flexible Simulation Architecture for Massively Multiplayer Games 513\n\nevent simulation, like MMP games where the actors need to be aware of everything\ngoing on around them, this is a critical improvement. The ReceiveEvent method can\nalso filter out event types that require immediate attention and bypass the queue to\nperform the required handling when the event is received.\n\nActorProxy\n\nAn ActorProxy is the client-side counterpart of an Actor. It shares the same Simula-\ntionObject ID as its Actor and replicates the actor’s relevant data. The client-side sim-\nulation will route all incoming events to the appropriate actor proxy, where it will be\nhandled by the ReceiveEvent method. The proxy also provides a RequestAction\nmethod that routes outbound action requests to the associated actor on the server.\nFinally, there is a PerformAction method available to process any client-side-only\nbehavior that does not need to be replicated by the server simulation, such as dynamic\nsoundtrack selection or triggering of UI elements (see Figure 5.3.9).\n\nmAction?\n+RecelveEventd\n+Requestactiono\n\nFIGURE 5.3.9 ActorProxy class diagram.\n\nNonperformers\n\nMuch simpler than performers ate the other core classes that do not directly interact\nwith the simulation environment. These objects do not perform actions and do not\nreceive any scheduled processing time from the simulation. All events must be han-\ndled actively as these objects receive them. These objects include:\n\n* Ltems—Small game objects that can be picked up, moved, and dropped by actors.\n\n* Obstacles—Nonmoveable objects in the game that cannot be picked up.\n\n* ProxyObject—Client-side counterpart of the Item and Obstacle classes.\n\n* Avea—Abstract spatial representations used to partition the simulation space\ndown into manageable sections, Areas define the local potential visible set that is\nused to filter who can and cannot see (or if needed, hear) simulation events.\n\nManagers and Factorles\n\nManagers and factories are implemented as singletons [Gamma94]. A singleton\ncomes in handy when a single global object needs to be accessed by several different\nclasses and objects. They are created when the simulation layer is initialized, and they\nremain in service until the layer is shut down. Parallel managers are maintained inde-\npendent of each other on both the client and server.\n\n514\n\nSection 5 Network and Multiplayer\n\nSOBFactory\n\nThe SOBFactory is responsible for creating simulation objects and guaranteeing that\nthey have a unique ID number. To achieve this, the SOBFactory is the sole keeper of\nthe nextSobId. The factory provides a Create method that takes an SOB-type argu-\nment that specifies what subclass of simulationObject (Actor, Area, Item, etc.) it cre-\nates. If the client-side simulation needs to create local simulation objects, it can\nmaintain its own SOBFactory, which will need to implement a scheme to ensure that\nclient-side SOB [Ds do not conflict with those generated on the server (see Figure\n5.3.10).\n\nsobFactory\n-nextSobld\n\n+Created : simulationObject\n-GenerateSobldd\n\nFIGURE 5.3.10 SOBFactory class diagram.\n\nSOBManager\n\nAn SOBManager is responsible for maintaining a dictionary of simulation objects.\nThe main function of this manager is to resolve SOB IDs into object references via\nthe LookupById method. This manager also provides methods to Store and Restore\nall of the objects under its supervision. These two methods delegate the actual object-\npersistence implementation down to the specific simulation objects. This allows for a\nsingle call to be made transparently from the sirnulation layer to save or load all of the\nobjects within it (see Figure 5.3.11).\n\n-sobs : Olctionary\n\nFIGURE 8.3.11 SOBManager class diagram.\n\nScheduleManager\n\nThe ScheduleManager is responsible for scheduling a Performaction method callback\nfor all of the Performer simulation objects that are active in the simulation (see Figure\n5.3.12). It also provides the Processtasks method that takes a time slice argument\nand calls all of the pending scheduled callbacks that it can process within that time,\n\n5.3 A Flexible Simulation Architecture for Massively Multiplayer Games 515\n\nsorted by the Performer’s schedulePriority. Although an effective schedule can be\nimplemented with a directory, as shown here, a more optimized solution is the prior-\nity queue. (For an excellent article, on implementing priority queues refer to\n\n[Nelson 96].)\n+CancelTaskd\n+ScheduleTaskd\nFIGURE 5.3.12 Class diagram for ScheduleManager.\nLookupManager\n\nThe LookupManager provides a fast and effective mechanism for accessing static\ngame data at runtime (see Figure 5.3.13). Typically, this data is stored in relational\nor object databases and loaded on simulation startup. The data is mapped into a\nnested dictionary with a primary Zzble key and secondary Entry keys. Some exam-\nples of static game data include initial ActionState data, SimulationEvent types, and\nSimularionObject properties.\n\nLookuphtaraget\n\n-tables : dictionary\n\nFIGURE 5.3.13 Class diagram for LookupManager.\n\nPutting It All Together\n\nNow that we have defined the support, core, and manager classes, we need to wrap\nthem all up in a nice top-level interface for managing the client/server simulation lay-\nets. The BaseSimulation class provides such a common interface. It contains all of the\nobject references to our manager singletons, as well as a reference to the root simula-\ntion object. This object represents the entire simulation universe and provides a\npointer to anchor all top-level Area simulation objects to. The simulation maintains\ntwo instances of the SOBManager, an areaManager and an actorManager. This sepa-\nration of simulation objects is useful for debugging, maintenance, and archival pur-\nposes (see Figure 5.3.14).\n\n516\n\nSection 5 Network and Multiplayer\n\n+AttachUserd)\n+DetachUserQ\n\n+LogOfig\n\n*LogOnd\n+ReceiveSimulationEvent)\n\n-root : SimulationObject\n-scheduUleManager\n-sobFactory\n\n+GetActorManager()\n+GetAreaManager\n+GetLookupManager(\n\n+GetScheduleManager()\n\nFIGURE 5.3.14 Simulation class diagrams.\n\nAttaching Users to Actors\n\nThe ServerSimulation and ClientSimulation classes each implement AttachUser and\nDetachUser methods, providing a mechanism to request that the calling user be\nmapped to a specific Actor instance on the server, as well as its associated ActorProxy\non the client. Attaching a user to an Actor allows that user to send action requests and\nreceive simulation events. It is up to the current control state of the target actor to\narbitrate whether or not the actor will accept or decline the attach request. Such an\nattachment mechanism has the added benefit of supporting advanced features, such\nas allowing multiple users to attach to the same Actor. A few uses for this feature in an\nMMP are to allow customer-support personnel to take over control of a troublesome\nplayer's character, or to be able to see the game from the exact perspective of a newbie\nplayer who is having trouble and requesting help.\n\nAction Requests\n\nOnce attached to a user on the server, the client’s primary outbound communication\ncomes in the form of action requests. The SendActionRequest method on the\nClientSimulation takes an ActionStateId and an argument list representing the user's\ndesired action, and passes them to the server simulation layer. The server, in turn,\ndelegates these requests down a chain of responsibility from the attached Actor to its\ncurrentControlState, where it is processed or rejected. Figure 5.3.15 illustrates the\naction-request sequence.\n\nAction Scheduling\n\nThe ServerSimulation provides a single Tick method that can be called from outside\nthe simulation layer to trigger all processing of pending actions. This method is\nresponsible for calculating the available time slice for simulation processing and hand-\n\n5.3 A Flexible Simulation Architecture for Massively Multiplayer Games 517\n\n(suamk]  [erSimatdon)] [Sonera] [esunensome :Sanlinngee} [Artec] [ison nents\n| 1:SendActionRequest) | |\n2ReceivaActionRequest) |\n\n3:Looku\n\n4:RequesiActiond\n\n------4+\n\n|\ni\n!\nI\nFIGURE 5.3.15 Action request sequence diagram.\n\ning it over to the schedule manager via the ProcessTasks method. Since the server\nphysics layer typically requires processing at a higher frequency than the simulation\nlayer, the Tick method serves as a good callback method to be registered with the\nphysics layer that maintains the main game loop (see Figure 5.3.16).\n\nOptimized Event Broadcasting and Handling\n\nThe PerformAction method on the ControlState determines the desiredAction State for\nthe calling Actor to attempt to transition. If this actionSrate passes its CanTransition\n\ntenascateen x] [:Sanmemdeton| | [ -Scheaamaeaeas) [sata\n\n' 4-Tieko !\n\n7\n|\n|\n2:ProcessTasksQ) \\\n\n3:PerformActiond\n\ni\n|\n|\n!\n&ProcessEventQueveg |\n|\n|\n|\n|\n\n5:Performaction®\n\nU | |\n| 1 |\n| ! I\ni | '\n' | |\nI i I\n\ni\nI\n|\ni\ni\n|\n\nFIGURE 5.3.16 Action-scheduling sequence diagram.\n\n518\n\nSection 5 Network and Multiplayer\n\npretest, then its Transition method is called to do the heavy lifting. Each actionState\nneeds to provide its own specific implementation. Typically, this implementation will\nneed to inform other simulation objects of the state transition. This is accomplished\nthrough simulation events. The acting simulationObject maintains the subscribers\ndictionary of other objects that have registered an interest in its actions. These sub-\nscribers are notified by calling their ReceiveEvent method. The receiver can deter-\nmine if it needs to give the event immediate or passive attention. In the former case,\nit is handled as it is received; in the latter case, it is queued and is processed on the\nreceiver's next PerformAction tick. Figure 5.3.17 shows this sequence diagram.\n\n1:Performaction®\n\ni\n| 1\n| | |\n| |\n| |\ni]\n\n2:<¢eslredActianState>PerformAction\n\n7:For subscritier Ih supscnipars\n\n&:Recehsévent)\n9: eventType Is Imrmadiate then\n\n10:HandleEventd\n\n11:Elee\n\n12:;QueveEvent}\n\nT\n|\n| } |\n|\n|\n|\n\nFIGURE 5.3.17 Event-broadcast sequence diagram.\n\n5.3 A Flexibie Simulation Architecture for Massively Multiplayer Games 519\n\nConclusion\n\nDeveloping an MMP is a vast undertaking and presents many challenges that are\nunique. Starting with a solid and well-engineered foundation, like the one presented\nhere, will carry you far and allow you to spend more time and effort on innovative\n\ngame mechanics, rather than bug fixes and workarounds.\n\nReferences\n\n[Alexander02a] Alexander, Thor, “GoCap: Game Observation Capture,” A Game\nProgramming Wisdom, Charles River Media, Inc., 2002.\n\n[Alexander02b] Alexander, Thor, “An Optimized Fuzzy Logic Architecture for Deci-\nsion-Making,” Al Programming Wisdom, Charles River Media, Inc., 2002.\n\n[Boer00] Boer, James, “Object-Oriented Programming and Design Techniques,”\nGame Programming Gems, Charles River Media, Inc., 2000.\n\n[Booch] Booch, Grady, “The Unified Modeling Language User Guide,” Addison\nWesley, 1998.\n\n[Dybsand00] Dybsand, Eric, “A Finite-State Machine Class,” Game Programming\nGems, Charles River Media, Inc., 2000.\n\n(Gamma94} Gamma, et al., “Design Patterns,” Addison Wesley Longman, Inc.,\n1994.\n\n[Nelson96] Nelson, Mark, “Priority Queues and the STL,” Dr, Dobbs Journal. Also\navailable online at http://www.dogma.net/markn/articles/pq_stl/priority.htm,\nJanuary 1996.\n\n[Perlin96] Perlin, K. and A. Goldberg, “Improv: A System for Scripting Interactive\nActors in virtual Worlds,” Computer Graphics Proceedings (SIGGRAPH 1996),\nACM, 1996,",
      "page_number": 497,
      "chapter_number": 52,
      "summary": "The proxy also provides a RequestAction\nmethod that routes outbound action requests to the associated actor on the server Key topics include simulations, games, and method. Covers method.",
      "keywords": [
        "simulation",
        "simulation objects",
        "Massively Multiplayer Games",
        "Actor",
        "Flexible Simulation Architecture",
        "method",
        "objects",
        "Multiplayer Games",
        "Simulation Architecture",
        "Charles River Media",
        "class diagram",
        "game",
        "Performer simulation objects",
        "Actor class diagram",
        "Massively Multiplayer"
      ],
      "concepts": [
        "simulations",
        "games",
        "method",
        "actor",
        "classes",
        "object",
        "action",
        "events",
        "states",
        "diagram"
      ],
      "similar_chapters": [
        {
          "book": "More Effective C++",
          "chapter": 24,
          "title": "Segment 24 (pages 234-241)",
          "relevance_score": 0.55,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 21,
          "title": "Segment 21 (pages 197-204)",
          "relevance_score": 0.5,
          "method": "api"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 12,
          "title": "Segment 12 (pages 95-102)",
          "relevance_score": 0.49,
          "method": "api"
        },
        {
          "book": "AI Engineering Building Applications",
          "chapter": 42,
          "title": "Segment 42 (pages 853-871)",
          "relevance_score": 0.49,
          "method": "api"
        },
        {
          "book": "Building LLM Powered Applications",
          "chapter": 52,
          "title": "Segment 52 (pages 441-448)",
          "relevance_score": 0.45,
          "method": "api"
        }
      ]
    },
    {
      "number": 53,
      "title": "Segment 53 (pages 505-512)",
      "start_page": 505,
      "end_page": 512,
      "detection_method": "topic_boundary",
      "content": "5.4\n\nScaling Multiplayer Servers\n\nJustin Randall,\n\nSony Online Entertainment\nlogic@jniogic.dyndns.org\n\nears ago, multi-user dungeons (MUDs) would often see 50 to 100 players inter-\n\nacting simultaneously. Even during these humble, early stages of multiplayer\ngaming, players suffered from lag and server resource starvation. Server administra-\ntots, implementers, and wizards fought constant battles against bugs, cheaters, grief\nplayers, and ‘bots’ running on player machines. Yesterday's problems live on today,\nbut with added complications of scale. The complexity of game systems and designs\nleave servers open to more exploits, The amount of throughput required to simulate\nan interactive 3D world for thousands of players exacerbates lag. As the technology\nadvances, so do the tools used to decipher, automate, peek, cheat, crash, or otherwise\nruin a gameplay experience. We are fighting the same battles, but they are bigger and\nrequire some different tactics to win.\n\nThis gem will describe strategies to improve fair gameplay, as well as methods of\nclustering server processes and optimizing systems to reduce throughput requirements\nwhile improving process performance.\n\nategies to Improve Fair Play |\n\n520\n\nNever trust the client to send good information back to the game server. Assume\nevery packet is malformed. Players will send false packets to move faster in a game, to\ninflict more damage, or to crash servers. They might do it to exploit data duplication\nbugs, or they might do it just to inflict grief on server administrators and other play-\ners, For whatever reason, they will send garbage—-and the server must be prepared to\nthrow out the trash.\n\nExploits in a multiplayer game fall into two general areas:\n\n* Data that is sent from the client—the client lies to the server about what it is\ndoing or assaults another client on the network,\n\n¢ Data that is on the client—the player sneaks a peak at the data vo gain unfair\nadvantage.\n\n5.4 Scaling Multiplayer Servers §21\n\nIt is impossible to exploit information that is not available. Game clients usually\nuse information that is relevant to maintain the world simulation. It is helpful to have\nas much information on the client as possible to prevent objects from ‘popping’ into\nexistence or to prevenc lagging while waiting for simulation data to arrive. This\n‘potentially relevant’ information can be exploited to give a player an advantage\nbeyond the scope of normal gameplay. The client only presents portions of informa-\ntion, while the player extracts the rest through some other means (e.g., third-party\nsoftware).\n\nStrategy 1: Don’t Send the Data\n\nData sent to the client should be on a ‘need-to-know.’ basis. Less data on the client\nequates to fewer opportunities for exploitation, lower bandwidth costs, and better\nperceived performance.\n\nFor example, the health point value of a foe might be useful during combat to\nimprove client-side simulation, but sending health points for all potential foes in the\nworld will let the player pick and choose their prey without interacting directly with\nthe game. Programs like ShowEQ [ShowEq01] and proxy bots in first-person shoot-\ners are examples of how black-hat users exploit extraneous information sent to the\nclient. If the data is not available, these kinds of exploits are impossible.\n\nStrategy 2: Temporarily Lock the Data\n\nOf course, the realities of gameplay in the context of limited bandwidth require that\nsome precaching data be sent to improve the simulated experience on the client. All is\nnot lost! Another strategy is to encrypt precache data with 4 randomly generated key\nthat is not sent to the client.\n\nThe data is in ciphertext when it reaches the client. The client, not having a key\nto decrypt the data, can only resort to an attack on the cipher itself. The time required\nto make a brute-force assault on a cryptographically strong cipher like Twofish\n[Schnier98] far exceeds the relevance of the precache before it becomes interactive.\nAfter all, precaching information is sent because the client will likely be interacting\nwith it in the near future (probably within the next 60 seconds).\n\nWhen the decryption key (16 bytes is usually large enough) is sent, the data mag-\nically ‘appears’ on the client. The time required to send tens or hundreds of kilobytes\nis amortized, and the data becomes relevant in the time it takes to send those few\nbytes to decipher precaching information.\n\nSome information, such as how to draw an object, could be in the clear as a pre-\ncache message to request a background load of assets; while game information like\nexperience values, health points, object name, and so forth are ciphertext. This strikes\na balance between network-send latencies, blocking disk reads, CPU-lag loading\nassets, and fair play.\n\n522\n\nSection 5 Network and Multiplayer\n\nStrategy 3: Clients Send Commands, Not States\n\nIf the client is not authoritative for position, health points, combat results, or what-\never, then it is not possible for the player to say, “I have 65536 health,” or “Joe is\ndead.” Instead, the client should only be allowed to send commands like “walk,”\n“run,” or “attack Joe.”\n\nStrategy 4: Server Validates Client Output\n\nThe player might not be allowed to send the message “Attack Joe,” or might send a\npacket of garbage that is not valid. If the server receives an invalid command, it\n\nshould be ready to either discard the data or discard the client altogether by discon-\n\nnecting it.\n\nStrategy 5: Never, Ever Tell a Client the Network\nAddress of Another Client\n\nIf a player knows the network address of another player, any number of attacks could\nbe launched against the remote client. For example: The player is engaged in combat\nwith Joe, and Strategy 3 has already been implemented, meaning only commands\nmay be sent, However, the player might employ a denial of service (on the game net-\nwork port) against Joe during combat. Joe is effectively incapacitated and cannot issue\nany commands. He is summarily executed in a duel, the denial of service disconnects\nJoe's computer, and the black-hat player wins the batde.\n\nThe game design might require high-bandwidth services, such as voice commu-\nnications. In this case, peer-to-peer communications are attractive solutions to prob-\nlems of throughput and the cost of ownership. There will be a tradeoff, however,\nbetween lower operational expenses and customer experiences. Permitting players to\nactivate peer communications selectively, explaining the risks to them when they do\nit, and allowing them to choose who they peer with are some compromises that might\nbe acceptable.\n\nDesigning Scalable Servers\n\nIt is important to prepare the server code for the consequences of a high-throughput\napplication. Data delivery should be efficient. Using the network system in game code\nshould be simple and safe. Efficiency, simplicity, and safety are common-sense goals,\nbut these goals can often be lost in the details of implementing massively multiplayer\nservers.\n\nEfficiency—-Use Modern System Interfaces\n\nEveryone would like code to be portable. By writing a select, connect, accept, lis-\nten, send, and recy, wrapped with a few #ifdef’s to handle nuances of Winsock ver-\nsus BSD sockets, a network subsystem can be authored with very little code in a\ncouple of hours, and it can be reasonably portable.\n\n5.4 Scaling Multipiayer Servers &23\n\nThis is fine for low-volume network services handling a few dozen connections,\nbut ic does not scale well when writing services handling hundreds or thousands of\nactive sessions. Most modern operating systems provide extended APIs that are more\nefficient than basic BSD socket services.\n\npo11() and POSIX2 AIO\n\nPOSLX2 defines an asynchronous I/O system (AIO) that is better suited to high-\nthroughput applications. Unfortunately, it is not very well-supported on all plart-\nforms. As of 2001, glibc provides fallbacks for AIO, and Linux supports AIO only for\nfiles that allow 1seek(). At some point, however, AIO will be the preferred approach\nto high-volume networking.\n\nBut for today, game code has to work on real-world platforms that are tested and\nstable. An alternative to POSIX2 AIO for UN*X is the po11{) system call. poll() is\nclosely related to select(}. File descriptors (specifically, poll file descriptors) are\npassed to the call, and it returns the number of descriptors that have some events\npending.\n\nIt does not, however, tell the application which descriptors are ready. The applica-\ntion must iterate through the descriptor list to see which of them have events.\n\npoll() is better suited than select(), because the events are posted in the\ndescriptor list directly. The network system does not have to leave user space to find\ndescriptors with pending events. Finding pending sockets in a set of hundreds, or\neven thousands, now only takes a few milliseconds, without the pains associated with\nmaking system calls querying for events on each socket.\n\nThis code is an example of using the poll call:\n\nint result = poll(fds, count, 0);\nint c = 0;\nfor(i = 0; i < count, c <= result; ++i)\n\nif(fds[I]).revents == POLLIN)\n{\n\nctt;\nfi .,. receive data\n\n}\n\nWin32 I/O Completion Ports and Overiapped I/O\n\nMicrosoft introduced IOCP with Winsock2. IOCP is an asynchronous I/O API that\nefficiently presents I/O events to an application. Rather than using select ()or other\nasynchronous methods, a socket is associated with a completion port, and normal\nWinsock operations commence. When an event occurs, however, the completion port\nis queued by the operating system. The application can then query the kernel for\ncompletion ports. Microsoft indicates that this is the best way to implement high-\nvolume network server applications [MSDN00]. This code roughly demonstrates\nIOCP usage:\n\n$24\n\nvoid foo()\n{\nSOCKET s = socket{AF_INET, SOCK_STREAM, 18);\nHANDLE iocp = CreateIoCompletianPort{\n$, g_iocpGroup,\n0, 0);\n}\n\nvoid updateNetwork (]\n\nbool success = true;\n\nwhile (success)\n\n{\nint ok = GatQuevedCompletionStatus (\niocp, // completion port of interest\n&bytesfransferred, // number of bytes sent or\n\n/?/ received\n\n&completionKkey,\n&overLapped,\nO // timeout immediately if there are no\nf/ completions\n3\n\nif (ok}\n\n{\nsuccess = true;\ni/ handle event\n\n}\nelsa\n{\nsuccess = false;\n}\n}\n}\nSafety—Mossage Serialization\n\nA server written in a strongly typed language can catch message-type errors at compile\ntime, before mistakes are introduced to a running application. Enforcing type safety\nover a network is no more difficult than ensuring type safety when storing objects on\ndisk. In fact, the same design and strategies used for file-based persistence should be\nused for network-based data synchronization, with a few exceptions.\n\nWhen persisting data to disk, programs might often assume that the data will be\nreread by the same program on the same host that wrote the data. When writing data\nto the network, this is not necessarily che case, Simply chrowing a raw chunk of mem-\noty containing some structs or classes to the network will definitely break, even if two\nhosts ate of the same endian architecture. The local and remote systems might both\nbe x86 systems, but running applications compiled with different word-alignment\noptions (Dev Studio aligns at 8 bytes by default and gcc at 4 bytes). The client might\nbe a little-endian x86, and the server might be a big-endian 64-bit alpha (with little-\nendian emulation disabled). Perhaps they are of the same architecture today, but\n\n5.4 Scaling Multiplayer Servers 525\n\nservers could be upgraded next year. There are no guarantees about byte alignment or\nendianness when dealing with the network.\n\nOpt for serialization that is common to network messaging, file I/O, and data-\nbase persistence (if a database is in use). Unified serialization might be used to apply\ndeltas to object data as well as to construct whole objects. For example, a database\nprocess might receive a position update network message, interpret it as SQL, and\nwrite only the object position to the back-end database. The database could then be\ntreated like any other server receiving updates. The interface is common; the imple-\nmentation is what differs.\n\nEnforcing type safety saves time in the long run, provides a more-stable applica-\ntion, and permits better reuse of code as development progresses. One of the most\neffective uses of a typed message system is in dispatching data to server systems.\n\nSimplicity—Message Dispatch\n\nTypically, a protocol will identify messages with a short one- to four-byte header. As\nthe message is received, the header is read, and more data is extracted from a packet\nuntil the whole message has been processed. This often happens in a single function\nwith a large switch statement that forwards a network buffer to other functions for\nfurther processing.\n\nThis is a method that gets the job done, does it efficiently, and is easy to under-\nstand. It is also somewhat painful to add new messages. When enough message types are\nintroduced to the system, the switch statement can grow to a ten thousand-line behe-\nmoth that is unreadable. With each new addition to the messaging system, the switch\nimplementation induces increasingly large build times. Most importantly, the dispatch\ncode is tightly coupled with each new message. New message code cannot leverage old\ncode to implement new behavior. The old code must be updated to understand the new\nmessage data. Unused data paths might remain in the code base undetected.\n\nThe typed-message system mentioned earlier might be used to avoid some of this\npain. It would be beneficial if an application could say to the dispatching system.\n“when connection X sends message Y, invoke my member function Z to handle it.”\n\nWith this kind of dispatching system, there should be no prior knowledge of\nwhat types of objects are requesting a message or what types of messages are handled.\nOnce the dispatch system is written, it need not be touched again, and it will be far\nless than ten thousand lines of code!\n\nHow it works (see the code provided on the CD-ROM for full implementation\ndetails):\n\n* Aconnection object has a dispatch object.\n* Another object in the system registers itself with the dispatch object.\n\n* It provides a ‘connect’ method that accepts a reference to a dispatch object that\nit listens to—a ‘this’ from the object invoking ‘connect’ and a pointer to a\nmember function that is executed when the requested message is emitted.\n\n526 Section5 Network and Multiplayer\n\n* The connection object adds the requestor’s dispatch object and callback function\nto a container of recipients by type.\n\n* When the dispatch system receives a network message, it constructs the message\nand ‘emits’ the message, which was already resolved to the proper dispatch\nmethod at compile time.\n\n© Requestor objects have their member functions invoked with the message as an\n\nargument.\n\nThis requires some meta-programming magic with templates if C++ is used. It\nprovides type-safe message dispatch and compile-time errors when message types (or\nrequestor methods) are unresolved.\n\nIn the context of a network messaging system, a connection receives a network\nbuffer, constructs a new message of a specific type, and dispatches it:\n\nvoid Client::Client(Connection * connection) :\nmyCallbackObj ect ()\n\n{\nmyCallbackObject.connect{¢\n\nconnection->getEmitter({},\nthis,\n&Client: :onDisconnect});\n\n}\n\nvoid Client: :onDisconnect(DisconnectMessage & d)\n\ncleanup{)};\n\n}\n\nvoid Connection: :onReceive(const Archive: :Stream & data}\n\n{\nArchive: :Stream: :AeadIterator cr = data.begin({);\nMessage & m = MessageFactory: :create(r};\nemitMessage({m);\n\n}\n\nThis can be used for far more than network messaging. Consider a monster\nobject on the server process. When the monster dies, it should be removed from all\nclients that see the monster.\n\nvoid Client: :onCreateMonsterOnRemote(Monster * m)\n\n{\nmyCallbackObj ect .connect (\nm->getEmitter(},\nthis,\n&Client::onKilledMonster);\n}\n\nvoid Client: :onKilledMonster(KillMsssage & k)\n\nRemoveObjectMessage r({k.getMonster()->getId(}};\n\n5.4 Scaling Multiplayer Servers 527\n\nsend(r);\n}\nvoid Monster: :onKilled{Character * destroyer)\n{\nKillMessage k({this, destroyer);\nemitMessage(k};\n}\n\nLater in development, designers might decide that the character object has to\nknow if it kills a monster. In this case, the character only wants to know about mon-\nsters that are killed when it is in combat. Perhaps all characters involved in combat\nwith the monster gain experience points. Using the dispatch system, the single kill\nmessage that was emitted by the monster in the old code can trigger new code in a\nnew character object.\n\nvoid Character: :onEnterCombat{Monster * m)\n\n{\nmyCallbackObject.connect (\nm->getEmitter(),\nthis,\n&Glient: :onKilledMonster) ;\n}\nvoid Character: :onKilledMonster{KillMessage & k)\n{\nexperiencePoints +=\nk.getMonster(} ->getExperienceValue();\n}\n\nAs an additional bonus to using this particular (C++) implementation of a dis-\npatch system, function pointers that are passed as callbacks can be protected mem-\nbers, thus hiding interface details, yet exposing them selectively to individual objects\nwhen they need to handle particular messages. No one may invoke the protected\nmembers directly, unless they are exposed explicitly within implementation code of\nthe object that defines them.\n\nDistributing the Load\n\nEnsuring that server systems can scale to arbitrarily large connection counts often\nentails clustering host systems and running multiple processes. Game services span-\nning several processes introduce technical design challenges. How does a client find\nthe right service? How do services cooperate to present a unified world simulation?\nWhere does the world persist game data between process startup and shutdown? How\nare processes spawned? What happens when clients need to interact with objects on\nmultiple servers? These are just a few of the problems nearly every distributed-game\nserver will have to address.",
      "page_number": 505,
      "chapter_number": 53,
      "summary": "The client only presents portions of informa-\ntion, while the player extracts the rest through some other means (e.g., third-party\nsoftware) Key topics include data, servers, and message.",
      "keywords": [
        "Sony Online Entertainment",
        "Servers Justin Randall",
        "Multiplayer Servers Justin",
        "client",
        "Justin Randall",
        "Sony Online",
        "Online Entertainment",
        "Scaling Multiplayer Servers",
        "data",
        "server",
        "message",
        "network",
        "Multiplayer Servers",
        "system",
        "Servers Justin"
      ],
      "concepts": [
        "data",
        "servers",
        "message",
        "messaging",
        "players",
        "gaming",
        "client",
        "connect",
        "connections",
        "connection"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 8",
          "chapter": 47,
          "title": "Segment 47 (pages 448-460)",
          "relevance_score": 0.57,
          "method": "api"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 22,
          "title": "Segment 22 (pages 188-196)",
          "relevance_score": 0.49,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 7",
          "chapter": 53,
          "title": "Segment 53 (pages 512-521)",
          "relevance_score": 0.49,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 46,
          "title": "Segment 46 (pages 434-447)",
          "relevance_score": 0.49,
          "method": "api"
        },
        {
          "book": "Microservice APIs Using Python Flask FastAPI",
          "chapter": 40,
          "title": "Segment 40 (pages 408-418)",
          "relevance_score": 0.49,
          "method": "api"
        }
      ]
    },
    {
      "number": 54,
      "title": "Segment 54 (pages 513-523)",
      "start_page": 513,
      "end_page": 523,
      "detection_method": "topic_boundary",
      "content": "Section 5 Network and Multiplayer\n\nOnce solutions are implemented, meeting the demands of the game ceases to be\nas much of a technical problem as an economic problem. Ideally, throwing more\nhardware at the server cluster would increase capacity.\n\nConsider Using a Front-End Process To Interact\nwith Clients\n\nSeparating client traffic from the rest of the servers is a good first step to solving prob-\nlems of location (How does a client find the right service?) and presenting a unified\nworld simulation. When a client connects to a game server, it is really interacting with\na front-end process (FEP). Several front-end processes might cooperate to increase the\ntotal connection count that a server cluster handles.\n\nHow Does a Client Find the Right Service?\n\nA common design employs a well-known login service that will validate a client, then\npresent the client with several ‘servers’ with which it may interact. Each server is one\nof several front-end processes that separate the client from back-end game processes.\nOnce the client connects to an FEP, that process will communicate with other back-\nend processes to insert a player’s character into the world simulation so that it may\nbegin gameplay (see Figure 5.4.1). How the world is presented to the client and which\nback-end process interacts with the client depends on the design of the game. If there\nis a process for each city in a role-playing game, then the city that the player was last\nin might be the target process for the new client.\n\nClient\n\nBack-end processes\n\nFEP\n\nFIGURE 5.4.1 Connection diagram using a Login Service and a Front-End\nProcess (FEP).\n\n3.4 Scaling Multiplayer Servers 529\n\nThe back-end will likely consist of other location services. Which objects are on\nwhich servers? Which players are on which servers? This relationship is abstracted\nfrom the client. It will only interact with the FEP. There is no need for a client to con-\nnect directly to a locator service or any other back-end process. Back-end locators\nneed a single connection with each FEP, which in turn can successfully redirect client\ncommunications to a world-simnulation service somewhere in the back-end.\n\nHow Do Services Cooperate To Present a Unified\nWorld Simulation?\n\nFEPs facilitate the presentation of a unified world simulation. A unified simulation is\none in which the game world appears as a single server covering a contiguous simula-\ntion through a single connection. If a client has to move from one back-end game-\nserver process to another, there is no reconnection process necessary on the client.\nThis might all be handled with interactions between the FEP and the game-server\nprocesses involved. ,\n\nThe FEP introduces a single process to filter packets. A FEP might handle com-\npression and encryption for client connections, dumping raw, uncompressed clear\ntext to back-end processes in order to save precious CPU resources for other activities\n(like AI or physics). Because the FEP is the single point of entry for client data, pack-\nets might also be validated on the FEP, without requiring protocol upgrades (e.g., ifa\nclient attempts to send a malformed packet to crash game servers).\n\nFront-end processes safeguard clients from game-service failures on the back-end.\nIf there is a recovery scenario implemented, clients need never know that the server\ndied a horrible death. The connection between the FEP and the client can remain\nactive while the back-end starts a new game service and redirects the clients to the new\nprocess. Meanwhile, the developer can browse the core files, while players happily\ncontinue abusing their servers.\n\nOf course, every design has its flaws. Introducing a FEP will induce latency as\ndata is read from the network, dispatched to the appropriate connection on the back-\nend, committed to the wire, and read on a back-end process. It is another process to\nmanage when maintaining or diagnosing server clusters.\n\nDistributing server processes does not necessitate the use of FEPs. Some game\ndesigns that involve autonomous game servers (i.e., there is no requirement for a uni-\nfied world simulation) requiring near-real-time latencies are probably not candidates\nfor using front-end processes.\n\nInterprocess Interaction\n\nThe majority of technical exploits arise when players interact across process bound-\naries. A player trading items for gold with an NPC or player on another process is a\ngreat example of a duplication exploit. If Joe (on Server A) is accepting plate mail\narmor offered by Jane (on Server B), and Joe (or anyone else) manages to crash Server\nB, he might be able to duplicate the plate mail armor. This happens if Joe's server\n\n530 Section 5 Network and Multiplayer\n\ncommits the transaction while Server B is crashing and has not committed the trans-\naction. Jane still has plare mail armor; so does Joe. There are two plate mail armors in\nthe world where before there was only one. Next time they trade 2 armors, then 4, 8,\n16, and so on, until they have an obscene amount of armor to loot.\n\nThe liberal use of UML {Larman01] sequence diagrams is indispensable when\nidentifying interprocess exploits. As diagrams are built, assume one or both servers\nwill crash at some point during an interprocess interaction, Identify what will happen\nto the state of the game if this happens.\n\nWhen building sequence diagrams, take time to consider interactions with over-\nloaded servers and how these affect gameplay. It would be unfair to keep a player\nlocked in a trade screen while it waits for a server that might never return. Messages\nsent between processes might not be processed right away. Assume that one or more\nprocesses will have a 100% CPU load and might never have an opportunity to process\nan interaction. Thinking asynchronously will help to design a system that the player\nperceives as better-performing. It will be more tolerant to unfair demands on some\nprocesses and can help to build load-balancing systems to even out the CPU load on\na server cluster.\n\nOptimization\n\nThree-dimensional clients limit the number of polygons sent to a rendering pipeline\nto what is potentially visible in the scene. This is done to save the amount of process-\ning necessary to draw a scene. Large-scale, distributed servers are under a much heav-\nier load, interacting with more objects than a client scene has polygons. N? operations\nbetween one million objects that are scattered over 20 or more processes will quickly\ndemonstrate a requirement to cull objects on the server as well!\n\nOn a client, culling happens relative to a single camera in a single scene. On a\nserver, the problem balloons out of proportion. Each object has its own perspective on\nthe world! The strategies that worked so well on a single game client are not an exact\nfit for the complications presented by the server—it cannot afford to spend most of its\nCPU in sorting and culling algorithms, leaving only a few cycles for Al, messaging,\nphysics, persistence, and the plethora of other tasks it must complete.\n\nIt is desirable, even necessary, to limit what each object can interact with to some\nvery small subset of other objects in the world. A system that could rapidly sort and\nupdate objects, independent of any perspective presented by a single object, and use\nless than 10% of the CPU would be ideal.\n\nThose systems do exist, and which one is right for a server really depends on the\nsimulation. This gem will focus on a particular subdivision system proposed in a pre-\nvious article by John Ratcliff in Game Programming Gems 2—the Sphere Tree [Rat-\ncliff]. Ic will also present a perspective strategy for objects that fit well with a\ndistance-based culling system.\n\n&.4 Scaling Multiplayer Servers 531\n\nThe Sphere Tree\n\nDistance-based culling is best suited to large worlds that cover a lot of area and have\nclusters of populations scattered throughout world space. Interactions aggregate\naround objects close to one another and cull objects that are far off in the distance.\nThe sphere tree is an ideal distance-based spatial sorting algorithm.\n\nSphere trees make speedy distance queries, quickly returning a solution set of\nobjects that are within an arbitrary sphere. They also have the property of extremely\nrapid resorting of objects in motion. These characteristics can be employed to main-\ntain a perspective-independent sorting and subdivision system to facilitate limited\ninteraction between objects in the world simulation.\n\nA sphere tree organizes objects in a hierarchy of spheres, There is a root node con-\ntaining all child spheres (see Figure 5.4.2). Children are subdivided into progressively\nsmaller spheres until suitable-size bounding spheres populate the tree. As an object\nmoves within a sphere, it checks its parent’s boundaries. If it exceeds the boundary,\nthe parent either resizes itself to accommodate the new position, or, if some maximum\nsize has been reached, the object is sorted into the parent's parent sphere, and a new\nchild sphere is created.\n\nFIGURE 5.4.2 A three-level sphere tree depicting a root node, two super spheres, and six\nchild spheres.\n\nSphere-to-sphere testing is a reasonably efficient process and compares vector dis-\ntances. This process can be further optimized by comparing square distances to avoid\na slow sqrt() call. Because objects in a sphere tree are sorted based on bounding\nspheres, when a range-based query is made to the tree, it tests the top-most nodes in\nthe tree. Those spheres that satisfy an intersection are further queried. Their child\n\n532\n\nSection 5 Network and Multiplayer\n\nspheres are tested against the query. This process repeats recursively through the tree\nuntil a set of objects thar satisfy the range query are identified.\n\nPerformance of the query depends on the size of the range requested, The smaller\nthe query, the fewer top-most nodes will be included for recursion. This is the second\nuseful property of sphere trees with distance-based culling.\n\nEach object has a bounding sphere so that it properly sorts into the tree. Addi-\ntionally, it has an ‘interest’ sphere, in which it has its own perspective on the world,\nbased on some distance. As the object moves, so does the interest sphere. That sphere\nis used to query the sphere tree. When the query returns a new object to interact with,\nthen it is ‘in view,’ relative to the object moving. The new object is placed in a set of\npotentially interactive objects.\n\nWhen the server checks for interactions between objects, it need only query the\npotentially interactive set. This is a much smaller subset (depending on the interest\nradius) than the total number of objects in the world.\n\nAs the new object is added, the server might also check to see if it is a player char-\nacter moving about in the world. If it is, chen when the object is added to the poten-\ntially interactive list, and baseline information for the new object might be sent to\nthe client. As the object moves or changes, the client can receive updates about\nthat object. The server will only have to send updates about objects that are poten-\ntially interactive with the client. Likewise, when objects are removed from the po-\ntentially interactive set, they might be unloaded from clients.\n\nIt is tempting to place an interest radius on a client’s character object. This pro-\nvides a single interactive set that the client can query for new information. It is more\nefficient, however, to have interactive sets relative to other objects. A building might\nhave a long range of interaction (it might be visible for hundreds of meters in game-\nworld space), while a shrubbery next to the building might have a visible range of\nonly a few meters.\n\nBy storing the interactive set on the viewed objects rather than the viewer,\nupdates can be ‘pushed’ to viewers by the observed object. This will prevent excessive\npolling, incurring CPU usage only as events take place.\n\nFor the most part, objects are not in motion, and so they do not query the sphere\ntree to update their interactive sets. Objects that are in motion will need to collide\nwith the interaction spheres of stationary objects. The building will want to know\nwhen a character is close enough to see it when the character walks toward the city.\n\nInteraction spheres might be bounding spheres placed into a sphere tree as well.\nCollision tests with spheres in the tree are efficient. When a collision occurs, the tar-\nget might receive notification and add the source (mover) to its interactive set. Using\nthis method, stationary objects such as buildings or idle nonplayer characters can be\nadded to a client’s world-view and update the client if their state changes.\n\nThis same approach can be used to cull server-to-server interactions. Reducing\nservet-to-server traffic is at least as important as server-to-client traffic. Servers will\nneed to perform some processing on remote objects if they interact. Forcing all server\n\n6.4 Scating Multiplayer Servers 533\n\nprocesses to spend CPU on all objects in the world will quickly bring a server cluster\nto its knees.\n\nSphere trees are not the only solution to problems of spatial sorting and culling\ninteractions, but they are a reasonable solution for large worlds where distance matters.\nQuadtrees and octrees are just as reasonable for large worlds, but these have their own\ndrawbacks. Some worlds consisting of interconnected spaces are better suited to a por-\ntal-based system to cull interaction. Portals, quadtrees, octrees, sphere trees, and many\nother algorithms are at the disposal of the developer. The hard part is not in imple-\nmenting the right solution; the hard part is to find the right solution to implement.\n\nConclusion\n\nThis gem has described several techniques that are useful in the design of scalable\nmultiplayer servers. Be sure to take advantage of the server platform’s most efficient\nnetwork API, even at the expense of portability, so that servers can handle the greatest\npossible number of connections. Architectural features like front-end processes and\nsphere trees for culling provide high server performance and isolate back-end servers\nfrom direct contact with client machines. Spending extra time early in the develop-\nment process to build simple, safe, and reusable APIs, like message dispatching and\nmessage factories, will ensure more-rapid implementation of gameplay features as the\nproject nears completion.\n\nReferences\n\n[Larman01} Larman, Craig, Applying UML and Patterns: An Introduction to Object-\nOriented Analysis and Design and the Unified Process, Prentice Hall, 2001.\n\n[MSDN00] Microsoft Corporation, “Windows Sockets 2.0: Write Scalable Winsock\nApps Using Completion Ports,” available online at hrtp://msdn.microsoft.com/\nmsdnmag/issues/1000/Winsock/Winsock.asp, MSDN, October 2000.\n\n[Ratcliff] Ratcliff, John W., “Sphere Trees for Fast Visibiliry Culling, Ray Tracing,\nand Range Searching,” Game Programming Gems 2, Charles River Media, Inc.,\n2001.\n\n[ShowEq01] HackersQuest. “HackersQuest” is available online at hrtp://www-hack-\nersquest.org/, March 2002.\n\n[Schnier98] Schnier, Bruce Twofish, “A 128-bit Block Cipher,” available online ac\nhetp://www.counterpane.com/twofish-paper.html, Counterpane Labs, 1998.\n\nTemplate-Based Object\nSerialization\n\nJason Beardsley, NCsoft Austin\njbeardsley@ncaustin.com\n\n| a networked game, either client/server or peer-to-peer, it is important to have\nan efficient method of converting objects to and from a network-friendly repre-\nsentation, most typically a stream of raw bytes. This process is known as serialization.\n\nEven for non-networked games, serialization is useful for dealing with the file\nsystem (e.g,, when loading resources from disk or saving game state). However, file-\nbased schemes often trade space efficiency for capabilities that are not usually required\nin a network environment, such as random access, in-place modification, a hier-\narchical directory structure, or versioning. This makes them unsuitable for network\ncommunication.\n\nThis gem presents a serialization method designed for network usage. It achieves\na high degree of flexibility and uniformity in handling all types of objects—built-in\ntypes, STL containers, and user-defined classes.\n\nExisting Solutions\n\nSerialization itself is nothing new. One commonly employed method is to define a\nstructure containing the data to be serialized, fill it in, and simply use memcpy(} to\nconvert it into a format suitable for network transmission. This approach is very fast\nand satisfactory for many applications, but it has some inherent limitations:\n\n* Tt only works when the bit-level representation of data is exactly what should be\nsent over the network. This is not generally true for C++ classes—in particular,\nthose that use dynamic storage or have embedded pointers, or any class with vir-\ntual methods.\n\n* Care must be taken when in laying out the structure in order to minimize\npadding by the compiler. In a cross-platform environment, any padding must be\napplied equally by all compilers.\n\n* Any byte order conversions must be done explicitly before copying.\n\n* Handling variable-length data, such as strings or arrays, is clumsy at best.\n\n5.5 Template-Based Object Serialization 535\n\nIn summary, the ‘struct/memepy()’ serialization method is only applicable when\ndealing with fixed-size structures containing plain data types. Another standard prac-\ntice involves the use of an object that has methods to store and retrieve each desired\ntype. This class might look something like the following:\n\nclass Serializer\n\n{\npublic:\n{// plain o1' data\nbool Put(int val};\nbool Get(int& valdut};\nbool Put(float val);\nbool Get(float& valOut);\n// standard classes\nbool Put(const std::string& val);\nbool Get(std::string& valOut) ;\n// STL containers\ntemplate <typename T>\nbool Put{const std::set<T>& val);\ntemplate <typename T> bool\nGet (std: :set<T>& valdut};\n// et cetera\n‘5\n\nNote that Put({} and Get() are overloaded instead of being named for the type\nthey handle (e.g., PutInt() or GetString()). This is essential for STL container sup-\nport. If the methods were not overloaded, then the code for handling an STL collec-\ntion could not be written in a generic fashion (i.e., by calling Put() and Get() on its\nrespective elements).\n\nWhen it comes to user-defined classes, we face a dilemma—should Serializer\nbe extended to directly support every class, or should the class have its own serializa-\ntion methods? The answer to the first question is a resounding “NO,” for a variety of\nreasons. First, Serializer must have access to the internals of any nontrivial class\n{requiring friendship). Second, every time support for a new type is added, there\nmight be a large amount of unnecessary recompilation. In addition, Serializer’s\ninterface could easily grow out of control. In short, this is a maintainability night-\nmare, not to mention very inelegant.\n\nTherefore, serialization support should be incorporated into each class directly.\nTypically, this involves defining an abstract interface class with pure virtual methods\nto support serialization:\n\nclass Serializable\n\n{\n\npublic:\nvirtual bool PutInto(Serializer& s} const = 0;\nvirtual bool GetFrom{Serializer& s} = 0;\n\n536 Section 5 Network and Multiplayer\n\nThen, extend Serializer to support serializable objects:\n\nbool Serializer::Put(const Serializable& obj)\n{ return obj.Putinto(*this}; }\n\nbool Serializer: :Get(Serializable& obj}\n{ return obj.GetFrom(*this); }\n\nThere is nothing wrong with this idea, but it has some drawbacks. It requires\nmodification of the class to be serialized, which is fine, if possible. However, what if\nthe class is provided by a third-party library and cannot be changed? There are per-\nformance implications, forcing what might otherwise be a very simple, standalone\nclass into an inheritance hierarchy. For a game, where speed is of the utmost impor-\ntance, introducing virtual methods into a simple class might be an unacceptable price\nto pay.\n\nAside from the requirement that user classes be detived from Serializable, and\naccepting some other minor performance problems (e.g., the header declaring Seri-\nalizer must include all STL container headers, increasing compilation times), this\nsatisfies the goal of a consistent, extensible serialization system. The question is, can it\nbe refined further to eliminate (or reduce in scope) these last few problems? The\nanswer is “Yes,” but before we can present the final method in detail, some back-\nground material is in order.\n\nPortability\n\nNetworked games, especially those of the client/server variety, are often multiplatform\napplications. The client might run on Windows, Macintosh, or PlayStation2, whereas\nthe servers might be a mixture of Linux, Solaris, and Windows, running on different\nprocessor architectures. Any serialization library must therefore be highly portable,\nwhich means it must be ported to (and tested on) each target platform.\n\nOne of the first lessons learned when writing multiplatform code is that the C++\nlanguage does not dictate the exact size (in bits) of built-in types, such as int and\nfloat. For serialization, this poses a problem, because the exact size of an object must\nbe known. Otherwise, a value could be written using 32 bits, but read out using 64\nbits, leading to undefined results. The most recent C standard addresses this by pro-\nviding the <inttypes.n> header, but it could be some time before all compiler ven-\ndors implement this. The next best thing is to define (via typedef) a group of\nfixed-size primitive types (int8, int16, int32, inté64, uinté, ..., uint64, floatsz,\nfloaté4), and use only these when serializing data. Care must be taken when dealing\nwith data that might be implicitly converted to more than one of the supported\ntypes—enumerated types and manifest constants should be explicitly cast to an\nappropriate numeric type before being stored or retrieved.\n\nThe next complication with cross-platform code is that of byte order. Different\nchip architectures store multibyte values (both integers and floating-point numbers) in\n\n5.5 Template-Based Object Serialization 537\n\nmemory using either ‘big-endian’ or ‘little-endian’ order [Kernighan99]. Thus, the\nserialization system must be able to convert to and from a standard byte order in order\nfor the low-level data format to be truly portable. Which specific byte order (big or lit-\ntle) is chosen is not extremely important, so long as it is consistent. A good rule of\nthumb is to go with the native format on the server side, since clients presumably have\nmore CPU cycles to burn. Regardless, byte swapping should never be a noticeable per-\nformance problem. Since we are using our own primitive types, we must implement\nour own set of conversion functions instead of using the standard hton1() and friends.\n\nSpeaking of primitive types, floating-point numbers might prove to be a signifi-\ncant barrier to portable code, depending on the target platform. Fortunately, almost\nevery processor manufactured today uses the standard IEEE formats, so bit-level\ncopying of floating-point data is actually portable. Keep in mind thar floats also have\na byte order, which is almost certainly the same as the integer order, so they might\nneed to be swapped. It is not difficult to write a program to test a particular architec-\nture for IEEE compliance, though what to do on a nonconforming platform is left as\nan exercise for the unlucky reader.\n\nThe Serializer Class\n\nThe goals for the serialization system are as follows:\n\n* Present a consistent interface for storing and retrieving all types of data.\n\n* Support primitive types, STL containers, and user-defined classes, with minimal\ncode changes to the latter.\n\n* Beas efficient as possible, while still remaining portable.\n\nAs the title of this gem suggests, the key to meeting these goals is the use of tem-\nplates—specifically, the use of member function templates.\nSuppose we declare Put () and Get() inside Serializer as follows:\n\nclass Serializer\n\n{\n\npublic:\ntemplate <typename T> bool Put(const T& obj);\ntemplate <typename T> bool Get(T& obj};\n\n}\n\nAll that is necessary now to support any type T is simply to define specialized ver-\nsions of each function. For example, the standard C++ string class:\n\ntemplate <>\nbool Serializer: :Put(const std::string& obj)\n{ {/* implementation */ }\n\ntemplate <>\nbool Serializer: :Get(std::string& obj)\n{ /* implementation */ }\n\nSection 5 Network and Multiplayer\n\nRegrettably, it is at this point when another lesson in cross-platform program-\nming is learned—not all compilers are created equal. While the above code is stan-\ndard C++, it is not accepted by all compilers. Microsoft Visual C++ 6.0, for example,\ndoes not support member template functions defined outside the enclosing class dec-\nlaration. Working around compiler differences is standard operating procedure for\nthe network coder, and as is the case with many programming problems, the answer\nlies in introducing another layer of indirection.\n\nIf there were auxiliary functions that handled the low-level details of storing\n(PutInto()) and retrieving (Getfrom()) the bits for any given type T, safely tucked\ninside the SerializeHelper namespace to avoid any conflicts, then we could trivially\nimplement Put() and Get() in the following manner:\n\ntemplate <typename T> bool Put(const T& obj}\n{\n\n}\n\nreturn SerializeHelper::PutInto(*this, obj);\n\ntemplate <typename T> bool Get(T& obj}\n{\n\nreturn SerializeHelper: :GetFrom(*this, obj);\n}\n\nThe task then becomes defining PutInto{) and GetFrom() for all of the requisite\ntypes: integers, floats, strings, STL containers, and so forth. Since the namespace can\nbe extended arbitrarily and in separate compilation units, user-defined types are easily\nand efficiently supported.\n\nInput and Output Storage\n\nSerializer makes use of a ‘byte-buffer’ utility class that handles the mundane details\nof reading and writing to memory, including automatically resizing itself when being\nwritten to. The partial interface for this class is as follows:\n\nclass BuTffer\n\nPublic:\nbool Write(const void* data, int len};\nbool Read(void* dataOut, int len);\nconst void* GetData(} const;\nint GetLength{} const;\n\n}5\n\nHandling Simple Fixed-Length Types\n\nIntegers, floats, and bool can be dealt with in two ways—using functions inside the\nSerializeHelper namespace or directly inside Serializer itself (i.c., by overloading\nPut(} and Get()). Since these types are so fundamental, we will employ the fatter\nmethod, as it might also speed up compile times.",
      "page_number": 513,
      "chapter_number": 54,
      "summary": "This chapter covers segment 54 (pages 513-523). Key topics include interact, interactions, and interaction.",
      "keywords": [
        "client",
        "server",
        "objects",
        "Sphere Tree",
        "Sphere",
        "Process",
        "Clients Separating client",
        "Multiplayer Servers",
        "Serializer",
        "FEP",
        "game",
        "Scaling Multiplayer Servers",
        "bool Put",
        "bool",
        "Put"
      ],
      "concepts": [
        "interact",
        "interactions",
        "interaction",
        "objects",
        "server",
        "clients",
        "serialization",
        "serialized",
        "process",
        "processes"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 8",
          "chapter": 47,
          "title": "Segment 47 (pages 448-460)",
          "relevance_score": 0.64,
          "method": "api"
        },
        {
          "book": "Designing Data-Intensive Applications",
          "chapter": 60,
          "title": "Segment 60 (pages 591-598)",
          "relevance_score": 0.62,
          "method": "api"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 36,
          "title": "Segment 36 (pages 719-740)",
          "relevance_score": 0.58,
          "method": "api"
        },
        {
          "book": "Release It! Design and Deploy Production-Ready Software",
          "chapter": 8,
          "title": "Segment 8 (pages 59-66)",
          "relevance_score": 0.58,
          "method": "api"
        },
        {
          "book": "Release It! Design and Deploy Production-Ready Software",
          "chapter": 11,
          "title": "Segment 11 (pages 83-90)",
          "relevance_score": 0.58,
          "method": "api"
        }
      ]
    },
    {
      "number": 55,
      "title": "Segment 55 (pages 524-531)",
      "start_page": 524,
      "end_page": 531,
      "detection_method": "topic_boundary",
      "content": "5.5 Template-Based Object Serialization 539\n\nThe code for each type is similar. Convert the value to network byte order (if nec-\nessary), and copy the bits, For bool, first convert to a uints (true = 1, false = 0), since\nthe underlying representation might be a larger integral type.\n\nHandling Simple Variable-Length Types\n\nTwo types fall into the simple variable-length types category: C-style strings and\nuntyped byte arrays. Since strings are null-terminated, it is possible to store the char-\nacter atray with its null terminator, without a Pascal-style lengthfield. Nonetheless,\nexplicitly storing the length (and omitting the terminator) is safer overall, even if it is\nmarginally less space-efficient. Both string objects and char* can be passed to Put ().\nHowever, there is no Get(char*) function, because the size of the output cannot be\ndetermined.\n\nWide character strings are a portability issue, because the size of wchar_t is not\nstrictly defined by the language. Even on a single platform, the exact size can vary,\ndepending on compiler options. Therefore, there is no built-in support for wide\nstrings. One workaround is to define an application-specific wide-string class (per-\nhaps based on the basic_string template), and make it serializable.\n\nRaw byte arrays also pose something of a problem. The interface to Put() takes in\na single argument, but it is necessary to know the number of items to write (as well as\nthe maximum number of items that can be read), Fortunately, we have introduced a\nclass that can act like a byte array (Buffer), and it is easily made serializable. There\nwill be times, however, when using Buffer is not possible, or when doing so might\ninvolve extra copying. Two additional methods, putRaw() and GetRaw(}, provide low-\nlevel access to the serialized stream. These take a length parameter that indicates the\n\nnumber of bytes to be written or read, respectively.\n\nHandling STL Containers\n\nStoring the contents of an STL container is straightforward. First, write out the num-\nber of elements, and then walk from the container’s begin() to end()}, writing out\neach individual item (calling Put() again). The code to implement this is virtually\nidentical for all containers, so naturally it would be nice to only have to write it once.\n\nProgrammers familiar with the STL know that the key to working with STL con-\ntainers (and the true power of the STL) is effectively using iterators [Meyers01]. The\nmany algorithms that come with the STL (e.g., find_if()}) use iterators almost exclu-\nsively. Serialization is no different, and although Put() and Get() do operate on con-\ntainers explicitly, underneath the hood are a pair of functions that only manipulate\niterators—PutRange() and GetRange{). These are in the SerializeHelper namespace\nand only rely on the public interface of Serializer.\n\nHere is the implementation of PutRange(). Note that it could compute the num-\nber of items by using the distance(} algorithm, but it is generally more efficient for\nthe caller to compute it (using size()), and pass it in as a parameter.\n\nSection 5 Network and Multiplayer\n\ntemplate <typename Iterator>\n\nbool SerializeHelper: :PutRange(Serializer& s,\nconst Iterator& begin,\nconst Iterator& end,\nuint32 size)\n\n{\nif (!s.Put(size)) return false; // store size\nfor (Iterator it = begin; it != end; ++it)\nif (!s.Put(*it)) return false; // store item\nreturn true; // Success\n}\n\nRetrieving the elements of a container is slightly more complicated. This process\nhas two extra wrinkles—first, the type of objects contained must be determined (e.g.,\nfor set<T>, figure out what T is); and second, once an element has been unserialized,\nit must be inserted back into the container. Given this, it is a matter of reading\nthe number of elements and then reading each element out one-by-one, adding to the\ncontainer. Fortunately, the designers of the STL have provided the necessary func-\ntionality in the iterator_traits class and the concept of insert iterators [Josuttis99),\n[Austern98].\n\ntemplate <typename Inserter>\nbool SerializeHelper: :GetRange(Serializer& s,\nInserter it}\n\n{\nuint32 size;\nif (‘s.Get(size}) return false;\nfor ({uint32 i = 0; i < size; ++i}\n{\niterator_traits<Inserter>: :value type obj;\nif (1s.Get(obj}} return false;\n*it = obj; // inserts into container\n}\nreturn true; // success\n}\n\nOnce again, compiler differences (or more accurately, STL differences) arise and\nmake this piece of code nonportable. The culprit here is iterator_traits, which is\nnot fully functional on all platforms, The workaround is something of a hack. What\nis needed is a way to determine the type of the contained objects. The caller of\nGetRange(} certainly knows this, and thus can pass in a null pointer of that type T,\nwhich becomes another template argument. The result (differences in bold) is:\n\ntemplate <typename T, typename Inserter>\n\nbool SerializeHelper: :GetRange(Serializeré& s,\nInserter it,\nT* /* unref */}\n\nuint32 size;\nif (!s.Get({size)} return false;\nfor (uint32 i = 0; i < size; ++i)\n\n5.5 Template-Based Object Serialization 541\n\n{\n\nTF obj;\n\nif (!s.Get(obj)) return false;\n\n*it = obj; // inserts into container\n}\n\nreturn true; // success\n\n}\n\nGiven Putfange() and GetRange(), writing the other helper routines for an STL\ncontainer is straightforward. For list, this is the code:\n\ntemplate <typename T>\n\nbool SerializeHelper: :PutInto(Serializeré s,\nconst list<T>& 1)\n\n{\n\n}\ntemplate <typename T>\n\nbool SerializeHelper: :GatFrom{Serializer& s,\nlist<T>& 1)\n\nreturn PutRange(s, 1.begin(), l.end{), 1.size(}};\n\n{\nl.clear(); // destroy any existing contents\nreturn Gethange(s, back_inserter(1}), (T*}0);\n\n}\n\nThe rest of the STL containers are handled similarly, with the only difference\nbeing in the number of template arguments (e.g., map requires two types—key and\nvalue) and the creation of the insert iterator in the call to GetRange(). Sequence-based.\ncontainers use the back_inserter adapter (which calls push_back()), while the others\nuse a plain inserter (which calls insert(}).\n\nIn order to completely support associative containers (map, hash_map, etc.), we\nmust also define serialization functions for the utility template class pair. Note that\nSTL containers of any serializable class are supported (including nested containers),\nso long as the class has a default constructor.\n\nHandling User-Defined Classes\n\nThe final piece to the system is dealing with user classes (i.e., any arbitrary class that\nyou want to serialize). Classes (or structures) whose public interface can be used to\nread and write an object's complete state, and which are not part of an inheritance\nhierarchy, are simple: define PutInto() and GetFrom(), and that's it. No changes to\nthe class are necessary!\n\nWhen a class has private data, the SerializeHelper functions will have to be\nmade friends. If these are viewed as external member functions, then this does not\nreally break encapsulation. In fact, it is similar to adding iostream support to a class.\n\nA class hierarchy makes life interesting. For example, say we have an abstract base,\nMessage class, and concrete subclasses, MoveMessage and ChatMessage. The base class\nhas members that need serialization, as do the subclasses. Since more message classes\n\n§42\n\nExtensions and Optimizations\n\nSection 5 Network and Multiplayer\n\necottA meen SAA MRU gmc aR mH cae A re ra ar RA RU Nop UM arte NMI DN ra\n\nwill probably be added in the future, the network layer (where messages are serialized\nbefore going out on the wire) only knows about Message objects. How can this layer\nproperly serialize an arbitrary Message, and how can it create an arbitrary Message out\nof a bunch of received bytes?\n\nFor serialization, the answer is to reintroduce the serializable concept. Make che\nbase class Message directly serializable {i.c., define PutInto() and GetFrom{}). Have\nthese functions call into pure virtual methods that Message subclasses must define in\norder to handle class-specific data. On the receiving end, use the factory pattern\n[Gamma95) to create the right type of Message before unserializing. In order for the\nreceiver to know which kind of Message was sent, and therefore which kind to manu-\nfacture, a header with type information (e.g., a ‘message~class id’) is also required.\n\nPointers and Arrays\n\nDealing with pointers is pretty easy—simply dereference them and call the existing\nmethods. Defining Put() and Get() that take pointer arguments does not work,\nbecause it gives the compiler a choice of which template to instantiate (Put<T>(T*) or\nPut<T*>(T*)), and this is an ambiguity error. Compilers do not fike choices, As a\nresult, this means that STL containers of pointers cannot be automatically serialized.\n\nThe interface must change to properly support arrays, because we need to know\nhow many elements are to be written in Put () and the maximum number that can be\nread in Get(}. Since one of che overriding goals is a consistent interface, this is unde-\nsirable. However, working with plain arrays is of obvious importance for efficiency, so\ntemplatized Putarray{) and GetArray{) functions (taking a length parameter) are\nincluded—-but in general, using the STL vector class is every bit as fast as arrays. Just\nlike pointers, an STL container of arrays is not going to work out-of-the-box,\nalthough this hardly sounds like a limitation.\n\nA Variable-Length Count\n\nStrings, buffers, and $TL containers store their sizes in serialized outputs. The ques-\ntion is: What kind of integer should be used for this lengthfield? To minimize output\nsize, it should be as small as possible. Requiting the length to fit inside (say) a uint16\nlimits the ability to serialize large collections, which might impact user code. Using a\nuint32 certainly provides enough space, but will waste bytes in most cases.\n\nAn idea that minimizes the output size yet allows for large lengthfields, is to\nencode the length in a variable number of bytes. Each byte contains seven data bits,\nand one ‘stop’ bit. To encode a count with N significant bits, a total of (LV - 1)/7 + 1)\nbytes are required. This format will end up using 5 bytes to encode a value with 29 or\nmore significant bits, but if there are chat many elements being stored, the extra byte\nwill hardly be noticeable.\n\nYou might be tempted to use this process for all multibyte integers. However, this\nis a bad idea if the values being stored falf into an even distribution across the type’s\n\n5.5 Template-Based Object Serialization 543\n\nentire range, because the average encoded length will actually be larger than the fixed\nlength. Encoding is beneficial only because most of the values being serialized are\nsmall.\n\nKeyed Serializor\n\nScripting languages often have a built-in ‘generic’ hash table, capable of storing a\nmapping from just about any object to any other—Perl’s associative array and\nPython's dictionary types are two examples. Using serialization, this same concept can\nbe implemented in C++. The geal is to create a class that maintains a mapping from\nsome known type T to any arbitrary type of object—like an STL map with no restric-\ntions on the value type. As might be expected, this class is a template (with member\ntemplate functions), and has the following interface:\n\ntemplate <typenama KEY>\nclass KeyedSerializer\n\n{\npublic:\ntemplate <typename T>\nbool Put{const KEY& key, const T& value};\ntemplate <typename T>\nbool Get(const KEY& key, T& value);\nI;\n\nThe implementation is actually pretty simple. It has an internal map from KEY\nto the Buffer class defined earlier. Put() first serializes value into a Buffer, and\nthen adds to the map. Get() does the reverse (leaving the map unchanged—so it\ncan be called multiple times with the same key). One interesting characteristic of\nKeyedSerializer is that it, unlike Serializer, allows random access to its stored\nobjects. If an object is never retrieved, its (potentially complicated) deserialization\ncode is never invoked. Finally, KeyedSerializer can itself be made serializable, and\nthis is where it becomes truly useful in a network context.\n\nPartial Serialization\n\nNetwork programmers know that bandwidth is money. Just about anything a net-\nwork game can do to minimize the size of messages being sent between client and\nserver (or client peers) is worth trying. In light of that, the KeyedSerializer class can\nbe quite useful for sending partial updates over the network.\n\nFor example, suppose a ‘game object’ has the following basic properties: position,\norientation, velocity, scale, color, and type. If an object update message contained\nevery one of these values, and updates were sent on a regular basis, it is pretty clear\nthat bandwidth would be wasted—an object's scale, color, and type are not likely to\nchange very frequently, if ever. Obviously, individual message types could be used for\neach property, but as the number of properties grows, the number of potential mes-\nsages (including combinations of related properties) can grow quite large. However, if\n\n544 Section 5 Network and Multiplayer\n\nan object update contained a KayedSerializer (perhaps using uints as the key type),\na single message can handle any combination of properties, use a single code path,\n\nand with minimal overhead.\n\nObject Tagging\n\nThere is a potentially serious problem with Serializer. This is type safety—or, the\nlack thereof. If two objects serialize into the same number of bytes (e.g., float32 and\nuint32), then it is possible to store one type and read the other. Of course, this is a\nbug in the application and not in the serialization library, but the fact remains that it\ncan happen without any indication of error (except for whatever odd side-effects\nresult).\n\nThe solution is to introduce a measure of safety by preceding each object with a\ntag. When reading, the tag is checked against what is expected, If the tags do not\nmatch, then an error is returned. To compute the tag for a given type, another func-\ntion inside the SerializeHelper namespace is used (and therefore must be defined for\n\nall supported types). Using a one-byte tag, this is the resulting code (changes in bold):\n\ntemplate <typename T> bool Put(const T& obj)\n\n{\nuint8 tag = SerializeHelper: :ComputeTag (obj);\nreturn WriteTag(tag) 2&\n\nSerializeHelper: :PutInto(*this, obj);\n}\n\ntemplate <typename T> bool Get(T& obj)\n\nuint& expected = SerializeHelper: :ComputeTag(cbj};\nreturn ReadAndCheckTag(expected} &&\nSerializeHelper: :GetFrom(*this, obj};\n}\n\nIt goes without saying that this will increase the size of the serialized output.\nHowever, this additional overhead can be eliminated by making the tag processing\noptional (e.g., only in debug builds or as a runtime toggle). The auxiliary functions\nWriteTag{) and ReadAndCheckTag() hide all of the details, so that is where conditional\nprocessing of tags takes place. If tags are turned off, these simply do nothing and\nreturn true.\n\nThere are a number of ways by which Serializer and its related classes can be\nextended further, Here are a few ideas:\n\n* Generalize the storage mechanism (instead of always using Buffer) to use an\nabstract interface and implement serialization to/from files, both binary and\nhuman-readable text (useful for debugging).\n\n* Integrate support for a favorite scripting language.\n\n5.5 Template-Based Object Serialization 545\n\n* Write adapters that allow che stream operators (<< and >>) to be used for some\nsyntactic sugar (be careful to consider proper error-handling).\n\n* Build a code generator that automates the creation of serializable classes, based on\na specification with types and field names.\n\n* Add encryption and/or compression at the serialization layer.\n\n* Port the code to a new compiler or platform.\n\nConclusion\n\nThis gem has presented a system for object serialization that is efficient, extensible,\nand minimally intrusive. Using the power and expressiveness of templates, it provides\na great deaf of functionality in a relatively small amount of code.\n\nReferences\n\n[Austern98] Austern, Matthew H., Generic Programming and the STL, Addison Wes-\nley, 1998.\n\n[Gamma95] Gamma, Erich, et al., Design Patterns, Addison Wesley, 1995.\n\n[Josuttis99] Josuttis, Nicolai M., The C++ Standard Library: A Tutorial and Reference,\nAddison Wesley, 1999.\n\n[Kernighan99] Kernighan, Brian W. and Rob Pike, The Practice of Programming,\nAddison Wesley, 1999.\n\n[Meyers01} Meyers, Scott, Effective STL, Addison Wesley, 2001.\n\nIPSec\n\nSecure Sockets\n\nPete Isensee, Microsoft Corporation\npkisensee@msn.com\n\nheating and hacking in multiplayer games is a common problem that can destroy\n\na gaming experience. One way to prevent cheating is by using cryptography,\nencrypting and authenticating network traffic. This gem explores the Internet Proto-\ncol Security (IPSec) standard and shows how games can leverage portions of the stan-\ndard to protect network packets and prevent spoofing, sniffing, and replay attacks.\n\nIPSec is an Internet standard developed by the Internet Engineering Task Force based\non academic and government research. It is published in [RFC2401] through\n[RFC2411], as well as [IPSec2]. IPSec provides services for authentication, integrity,\nand confidentiality, and is widely used to implement virtual private networks (VPNs).\nIPSec is designed to be implemented at the network layer (network stack) and is typ-\nically hidden from applications. Unfortunately, native [PSec is not a viable option on\nmost gaming platforms. Even when IPSec is available in a given OS (e.g., Windows\n2000), it’s neither on by default nor required that applications support it. Neverthe-\nless, game programmers can learn a lot from IPSec, and many of the features of IPSec\ncan be implemented within the context of game network code.\n\nAuthentication means verifying who sent a message; integrity means ensuring\nthat a message was not modified. IPSec implements authentication and integrity\nusing keyed cryptographic hashes like MD5 [RFC1321] and SHA-1 [RFC3174].\n“Confidentiality” is the term used to describe obscuring data, which implies encryp-\ntion. [PSec uses symmetric encryption algorithms like DES [RFC2405] and AES\n[AESDraft]. For game traffic, it usually makes sense to choose a high-performance\nalgorithm. Data requiring a higher level of encryption (e.g., player damage packets,\ntournament scores, etc.) can use stronger, slower algorithms. (For a good summary of\nalgorithm performance, see [WeiDai01).)\n\nCryptography alone cannot prevent replay attacks. An authentic, encrypted mes-\nsage that is intercepted and resent by an attacker will authenticate and decrypt just\nfine. Therefore, IPSec also includes a mechanism for preventing replay attacks by\nusing a combination of sequence numbers and a sliding replay window.",
      "page_number": 524,
      "chapter_number": 55,
      "summary": "This chapter covers segment 55 (pages 524-531). Key topics include serialization, serialized, and serialize. Handling Simple Variable-Length Types\n\nTwo types fall into the simple variable-length types category: C-style strings and\nuntyped byte arrays.",
      "keywords": [
        "STL",
        "STL Containers",
        "type",
        "Message",
        "size",
        "Object Serialization",
        "Object",
        "template",
        "Template-Based Object Serialization",
        "Put",
        "Serialization",
        "network",
        "STL Containers Storing",
        "SerializeHelper",
        "Containers"
      ],
      "concepts": [
        "serialization",
        "serialized",
        "serialize",
        "classes",
        "template",
        "type",
        "networks",
        "containers",
        "code",
        "bytes"
      ],
      "similar_chapters": [
        {
          "book": "C++ Templates_ The Complete Guide",
          "chapter": 63,
          "title": "Segment 63 (pages 2016-2049)",
          "relevance_score": 0.68,
          "method": "api"
        },
        {
          "book": "Designing Data-Intensive Applications",
          "chapter": 15,
          "title": "Segment 15 (pages 135-143)",
          "relevance_score": 0.68,
          "method": "api"
        },
        {
          "book": "More Effective C++",
          "chapter": 32,
          "title": "Segment 32 (pages 320-329)",
          "relevance_score": 0.67,
          "method": "api"
        },
        {
          "book": "C++ Templates_ The Complete Guide",
          "chapter": 76,
          "title": "Segment 76 (pages 2442-2473)",
          "relevance_score": 0.66,
          "method": "api"
        },
        {
          "book": "C++ Templates_ The Complete Guide",
          "chapter": 32,
          "title": "Segment 32 (pages 1015-1044)",
          "relevance_score": 0.64,
          "method": "api"
        }
      ]
    },
    {
      "number": 56,
      "title": "Segment 56 (pages 532-540)",
      "start_page": 532,
      "end_page": 540,
      "detection_method": "topic_boundary",
      "content": "5.6 Secure Sockets 547\n\nCaveats\n\nOne of the most critical steps in establishing a secure system is key management. This\ngem does not cover key-exchange techniques or the proper ways to generate, expire,\nand update keys. The assumption here is that both ends of a secure connection have\nthe same keys and that the keys were established and exchanged in a secure fashion.\nAnother process essential to secure systems is the proper generation of truly random\nbits for keys, shared secrets, and initialization vectors [Isensee01]. This gem assumes\nthat keys use cryptographically random values. .\n\nThe IPSec standard requires the implementer to embed a copy of the IP header\ninto the payload of the packet, which is in turn both encrypted and authenticated.\nThis allows the receiver to verify that the actual IP header wasn't altered. Implement-\ning this level of authentication is both complicated and usually unnecessary, since the\nauthentication of the payload proves that the packet came from someone who knows\nthe proper authentication key. This gem does not cover IP authentication.\n\n[IPSec implementations are closely tied to the fragmentation system of the IP pro-\ntocol. To avoid this issue altogether, this gem assumes that all packets are sent using\nunfragmented UDP packets and not via TCP, avoiding fragmentation. Most games\nuse UDP packets anyway, so this assumption is not unreasonable. This gem also\nassumes that all messages are less than the maximum transmission unit (MTU).\nApplications must implement their own sequence mechanism for messages larger\nthan the MTU.\n\nSecurity Associations\n\nA security association (SA) is a logical ‘connection’ created for security purposes. The\nSA defines how traffic is secured from one node to another. An SA includes cipher\nand authentication keys, modes, algorithms, and other data that define the packet for-\nmat. The SecurityAssociation class included with this gem contains the information\nshown in Table 5.6.1.\n\nSAs almost always occur in pairs, with an SA on the sender exactly matching an\nSA on the receiver. In a client-server game, the server might have a list of one SA per\nclient, and each client would have a single SA that matched an SA on the server. In a\npeer-to-peer game, each peer would have a list of SAs. The list of security associations\nmaintained by a host is called the “security association database” (SAD). For games,\nthis ‘database’ typically resides in the memory of the game or game server.\n\nPrior to sending or receiving secure data, the communicating pair must establish\na security association. This gem does not cover the means by which the SA data is\nexchanged by the sender and receiver. Some of the data, like the algorithms, could be\nbaked into the code. Other data, like the keys, should change on a regular basis for\nmaximum security, and should be exchanged using secure protocols like EKE, Ker-\nberos, or Diffie-Hellman [Schneier96]. Be sure to use different keys for authentica-\ntion and encryption in order to maximize security.\n\n548 Section 5 Network and Multiplayer\n\nTable 5.6.1 Security Association Data\n\nData Description\n\nAuthentication Algorithm — The exyptographic hashing algorithm used for authentication (e.g.,\nMDS, SHA-1)\n\nAuthentication Key The symmetric key data used for authentication\n\nEncryption Algorithm The symmetric encryption algorithm used when encrypting and\ndecrypting packets (e.g., DES, AES)\n\nEncryption Key The synumecric key dava used by the encryption algorithm\n\nSequence Number The next sequence number ro be used by a packet sent on this SA\n\nLast Sequence Number The highest sequence number received on this SA\n\nReplay Window A bitmask used as the sliding window for rejecting replay attacks\n\nTV Size The size of the encryption initialization vector (2-8 bytes)\n\nICV Size The size of the integrity check value (8-12 bytes)\n\nMax Padding Blocks The maximum number of additional random padding blocks (0-4\n\nblocks). The block size is based on the encryption algorithm.\n\nPacket Format\n\nImplementing secure sockets is a matter of encrypting and stamping a hash on data\nbefore sending it, and authenticating and decrypting the data when receiving it. Table\n5.6.2 shows the format of a secure packet, detailing which portions of the packet are\nauthenticated and encrypted.\n\nTable 5.6.2 Secure Packet Farmat\n\nData Size (bytes) Default Size (bytes) Authenticated Encrypted\n\nre ene\n\nSecurity Parameters Index (SPI} = 1-4 2 Yes No\nSequence Number 4 4 Yes No\nInitialization Vector (IV) 2-8 4 Yes No\nPayload Variable Variable Yes Yes\nPadding 0-255 0-255 Yes Yes\nPad length 1 1 Yes Yes\nIntegrity Check Vafue (ICV} 8-12 10 No No\n\nSecurity Parameters Index\n\nThe security parameters index (SPI) is a handle thar uniquely identifies a security\nassociation in a security association database. An SPI is transmitted in every secure\npacket so the receiver can select the SA under which the packet will be processed. The\nsize of the SPI is game-specific, and depends on the maximum number of SAs that\n\n5.6 Secure Sockets 549\n\nON THE CO\n\nwill be active at any one time. The example implementation included on the CD-\nROM generates random, unique two-byte SPIs. The SPI is not, and cannot be\nencrypted, because it is used to identify the SA thar defines the algorithms and keys.\nIf an attacker modifies the SPI, the packet validation will fail, since the SPI is always\nauthenticated.\n\nSequence Number\n\nThe ‘sequence number’ is a monotonically increasing counter value. The first packet\nsent using a given security association will have a sequence number of one, the next\npacket will be number two, and so on. The receiver uses the sequence number to\nensure that duplicate packets and ‘old’ packets are ignored. The sender must ensure\nthat if there’s a possibility of the sequence number rolling over to zero, the two end-\npoints of the connection generate a new pair of security associations and expire the\nold SAs prior to rollover. The sequence number is not encrypted so that replay attacks\ncan be detected without having to decrypt the packet. This can also reduce the effect\nof a denial-of-service attack. If an attacker modifies the sequence number, the packet\nvalidation will fail, since the sequence number is always authenticated.\n\nInitlalization Vector\n\nAn initialization vector (IV) is a binary blob of random data used to initialize a sym-\nmetric encryption algorithm. The IV ensures that even if the same plaintext data is\nsent multiple times, it will encrypt to different ciphertext. The IV is initialized by the\nsender with random data and is fed to the encryption algorithm, The receiver initial-\nizes its decryption routine using the same [V. Each encryption algorithm defines a\nstandard IV length, with most symmetric algorithms using an IV of eight bytes. To\nminimize bandwidth at the expense of less security, an implementation can transmit\nsmaller [Vs. The example implementation uses four-byte IVs as the default. The\nremainder of the IV is set to the sequence number when it is used during the encryp-\ntion or decryption phase.\n\nPayload\nPayload refers to the original plaintext data. This data is encrypted in the packet that\n\nis sent over the wire.\n\nPadding is appended to the payload before encryption. Padding is used for two rea-\nsons. First, the encryption algorithm might require a certain block size. For instance,\nmany symmetric encryption algorithms use eight-byte blocks. Second, it might be\ndesirable to add a random amount of padding to hide the true size of the payload.\nPadding bytes are initialized with a series of integer values (starting at one) that can be\n\nverified by the receiver, providing an additional level of security.\n\n550 Section 5 Network and Multiplayer\n\nPad Length\nThe pad length is a one-byte field chat stores the number of padding bytes in the\npacket.\n\nIntegrity Check Value\n\nThe integrity check value (ICV) is a truncated, hash-based message authentication\ncode (HMAC). An HMAC is a keyed hashing algorithm that uses a combination of a\nstandard cryptographic hash algorithm and a secret symmetric key [RFC2104]. Like\na thumbprint uniquely identifies a human being, an HMAC uniquely identifies a\nsecure packet. Truncating the HMAC is a well-known security practice. The example\nimplementation on the CD-ROM tuncates the hash to eight bytes by default.\n\nThe sender calculates the ICV by hashing the encrypted packet data using the\nauthentication key of the SA. The receiver performs the same calculation and com-\npares the ICV it computed with the ICV that was sent. If they match, the packet is\nvalid—it was sent by someone with a matching SA (authentic) and it was not modi-\nfied in transit (integrity intact). If not, the packet is bogus and is thrown away.\n\nae\n\nON THE CD\n\nSending Data\n\nSending data is a matter of encrypting the payload and generating a cryptographic\nhash of the data to be sent. The following sections describe the details used by the\nexample implementation.\n\nEstablishing a Security Assaciation\n\nPrior to sending secure data, the sender establishes a security association with the\nreceiver. Once the SAs and SPIs have been set up, each end of the communication\nlink has the data it needs to encrypt, decrypt, and authenticate traffic sent between\nthe two endpoints.\n\nBuilding the Header\n\nThe header includes the SPI, the sequence number, and the encryption IV. The SPI\ncorresponds to the SA used to encode and authenticate the payload. The current\nsequence number is also found in the SA. Once a sequence number has been used, it\nis incremented in the SA. The encryption IV is generated randomly. If the SA encryp-\ntion algorithm requires a larger TV than what is sent in the packet, the remaining\nbytes are set to the sequence number.\n\nGenerating Padding\n\nPadding is generated based on the size of the plaintext payload and the SA encryption\nalgorithm. Additional random padding might be added to hide the true size of the\npayload, The amount of random padding is configurable. The padding bytes are ini-\ntialized with a series of integer values, starting at one.\n\n5.6 Secure Sockets ; 551\n\nEncrypting the Payload\n\nThe encrypted portion of the packet includes the original payload, the padding, and\nthe pad-length byte. The symmetric encryption is initialized with the IV generated\nabove, and the encrypted payload is generated using the SA symmetric encryption key\nand SA symmetric encryption algorithm. The resulting ciphertext is appended to the\nheader.\n\nGenerating the Authentication Code\n\nThe last step before sending the data is to generate the ICV. The HMAC algorithm is\ninitialized with the SA cryptographic hash algorithm and authentication key. The\nhash algorithm is then applied to the packet header and encrypted payload/padding.\nThe resulting hash value is appended to the ciphertext. The hash value is not\nencrypted.\n\nSending the Secure Packet\n\nThe secure buffer is now ready to be sent using whatever UDP socket mechanism the\ngame uses, typically send().\n\nReceiving Data\n\nOn the receiving end, the order of operations is critical for security and performance.\nThe receiver must validate the packet SPI, ICV, and sequence number. The receiver\nmay then decrypt the packet and validate padding. Only after all validation checks are\ncomplete can the receiver process the packet payload. If any validation check fails, the\npacket must be thrown away. If the receiver is a game server, the server might also\nwant to audit the failure event as a way of detecting and tracking cheaters.\n\nRecelving the Secure Packet\n\nThe secure packet is received using whatever UDP socket mechanism the game uses,\ntypically recv().\n\nValldating the Packet\nThe simplest check that can be made on the packet is validating the SPI. If the SPI\n\ndoes not match a security association in the receiver’s security association database,\nthe packet is deemed invalid. Assuming an SA match, a quick check is made on the\nsize of the block, based on the minimal amount of data that must be included in the\nsecure packet.\n\nThe next step is to validate the packet against the ICV. The HMAC algorithm is\ninitialized with the SA cryptographic hash algorithm and key. The hash algorithm\nis then applied to the packet header and encrypted payload. The resulting hash\nvalue is truncated and compared with the ICV received. If it matches, we have an\nauthentic packet.\n\n552 Section 5 Network and Multiplayer\n\neeececae,\n\nThe last step prior to decrypting the packer is to check the sequence number. If\nthe packet is a replay or too ‘old,’ there’s no reason to decrypt it. The example imple-\nmentation uses a 64-bit sliding window to reject replay attacks and yet still allow\nout-of-order packets, which can occur with UDP. The ‘right’ edge of the window rep-\nresents the highest validated sequence number received on the SA. Packets that con-\ntain sequence numbers lower than the ‘left’ edge of the window are rejected (they're\ntoo old). Packets falling within the window are checked against the list of received\npackets. Ifa packet with a matching sequence number is received, it is a replay and is\nignored. New packets set the cortesponding bit in the window. Packets with a\nsequence number larger than the right edge cause the window to shift.\n\nDecrypting the Payload\n\nThe first step of decryption is to extract the IV. The IV is extended with the sequence\nnumber if necessary and then used to initialize the decryption algorithm. The payload\nand padding bytes are deciphered using the SA symmetric decryption key. The result-\ning plaintext includes the original payload, padding bytes, and padding size.\n\nValidating Padding\nThe padding size is validated to ensure that it’s reasonable. The padding bytes are then\n\nvalidated to ensure that they contain a series of integer values. Finally, all padding\ninformation is stripped from the plaintext, leaving the original payload.\n\nExample Implementation\n\nThe sample code on the CD-ROM, which is included with this gem, includes C++\nclasses that wrap cryptographic functions, security associations, and. secure buffers.\nTable 5.6.3 shows the list of classes provided.\n\nThe essential implementation details are contained in SecurityAssociation and\nSecureBuffer. The next section shows how the classes are used in a game for sending\nand receiving secure data.\n\nTable 5.6.3 Secure Socket Classes\n\nClass name Description\n\nCryptContext Win32 CryproAPl cryptographic service providers\nKey Cryptographic keys and algorithms\n\nCipher Encryption and decryption functions\n\nHash Hashing algorithms\n\nBuffer std::string<unsigned char>\nSecurityAssociation Security association data\n\nSADatabase std::map<Spitype, SecurityAssociation>\n\nSecureBuffer Functions for encrypting, decrypting, and authenticating payloads\n\n5.6 Secure Sockets 553\n\nCreating a Security Association\n\nCreate a security association and add it to the security association database (SAD):\n\n// One-time association of SAD to SecureBuffers\nSADatabase sad;\nSecureBuffer: :SetSADatabase( &sad };\n\n// Generate random keys. This example uses the\n// DES cipher for encryption and MD5 for hashing\nKey keyAuth( CALG DES );\n\nKey keyCrypt( CALG_DES );\n\n// Create a new SA using the specified keys\n// and algorithms; other values get defaults\nSecurityAssociation sa{ keyAuth, keyCrypt, CALG_MD5 });\n\n/{ Generate a new SPI and add the pair to the db\nSpiType nSPI = sad,.GenNewSPI{);\nsad.Insert( nSPI, sa );\n\n// Securely exchange nSPI and keys with other end\nf/f of connection...\n\nSending a Secure Packet\n\nGenerate and send a secure packet:\n\n{/ Associate SecureBuffer with SA via SPI\nSecureBuffer sb( nSPI );\n\n// Generate the encrypted and authenticated buffer.\n// Encryption and hashing happens here.\nsb.Create( \"payload\", 7 };\n\n// Send the secure packet\nsend( sock, sb.GetDataPtr({), sb.GetSize(), 0 };\n\nReceiving a Secure Packet\n\nReceive and process a secure packer:\n\n{/ Receive the secure packet\n\nchar pData[ 1024 ];\n\nint nm = recv({ sock, pData, 1024, 6 );\n\nif( mn == 0 || n == SOCKET_ERROA )\nreturn false;\n\n// Validate the packet\n\nSecureBuffer sb({ pData, n );\n\nif{ Isb.IsAuthentic({) )\nreturn false;\n\n// Extract the original payload\nif( Isb.GetPayload{ pData, &n ) )\n\n554 Section 5 Network and Multiplayer\n\nreturn false;\n\n// Adjust the replay window\nsb.SetAccepted({};\nreturn true;\n\nCryptoAPl\n\nThe cryptographic algorithms and key management use the Windows CryptoAPI, Alf\nof the crypto code is modularized into crypto.cpp so that you can replace the low-\nlevel crypto with other implementations (¢.g., Crypto++) [WeiDai01]. One of the\nfrustrating features of the CryptoAP! is that it doesn't provide direct access to key\ndata. There are no APIs that allow you to directly set or get a key. However, Microsoft\nKnowledgeBase article Q228786 [KB228786] discusses a method for directly access-\ning key data, and that method is used by the Key class.\n\nBecause of the way the CryptoAPI is designed—using cryptographic service\nproviders—not all potential algorithms or key lengths are available on all versions of\nWindows. Be sure to check the return codes for failure cases.\n\nPerformance\n\nThere are two major performance issues involved with using secure sockets. The first\nis additional bandwidth requirements. Using the default settings and an encryption\nalgorithm with eight-byte block requirement (e.g., DES), minimum packet overhead\nwith the sample implementation is:\n\n2 (SPI) + 4 (SeqNum) + 4 (IV) + 0-15 (Padding) + 1 (PadLen) + 10 (ICV) =\n21-36 bytes\n\nThose 21-36 bytes are in addition to the standard UDP packet overhead. You\ncan tweak the SA parameters to reduce the overhead, but only at the expense of secu-\nrity. To reduce the effects of the overhead, consider changing from small, frequent\npayloads to larger payloads sent less frequently. To avoid unnecessary padding, send\npayloads whose size+1 is evenly divisible by the block size of the SA cipher. (The +1\naccounts for the pad length byte.)\n\nThe second performance issue is encryption/decryption and authentication.\nTable 5.6.4 shows the costs of creating, authenticating, and decrypting one kilobyte\nof payload data, which indicates chat performance is not unreasonable. The most\nimportant factors at work here are the speed of the algorithms and the size of individ-\nual packets. Choose algorithms and key lengths that provide solid security at a rea-\nsonable performance cost.\n\nThese values were generated on a Pentium III, 866 MHz, running Windows\n2000, and using the default SA settings with DES encryption (64-bit keys) and MD5\nhashing. The “Create” column is the time in milliseconds required to repeatedly call\nSecureBuffer::Create on total payload data using the given payload size. The\n\n5.6 Secure Sockets 555\n\nTable 5.6.4 Performance\n\nTime to process one kilobyte of payload data\nPayload Size (bytes) Create (ms) Authenticate (ms) Decrypt (ms}\n\ntee ere tevarvaneomranramarvarere NOHO ta rrarrarrerre eta Ee LT rg eiietasiaarammesrenran me remrerhrg;iAijarvaiininianaremnmey tema nzn\n\n64 2.07 0,90 1.07\n128 1.06 0.45 0.57\n256 0.59 0.24 0.34\n512 0.35 0.14 0.23\n1024 0.23 0.09 0.16\n\n“Authenticate” column shows the time spent in SecureBuffer : : IsAuthentic, and the\n“Decrypt” column shows the time in SecureBuffer;:GetPayload. Performance\nincreases as the payload size increases, since relative packet overhead decreases for\nlarger packets.\n\nSecurity\n\nThe intent of this gem is to present an implementation that strikes a balance between\nextremely robust security with huge packer overhead and reasonable security with\nminimal packet overhead. The quality of security provided is primarily dependent on\nthe strength of the algorithms used. Don’t use XOR as an encryption or authentica-\ntion algorithm and expect to have packets that are never cracked. Choose well-known,\nstandard algorithms with solid implementations, like DES, Triple-DES, Blowfish,\nand AES for encryption, MD5 and SHA-1 for hashing. Understand the security lev-\nels and performance trade-offs between the algorithms. Use large keys (128-bits)\nwhen they're supported by the algorithm. Change keys regularly. Don't reduce the IV\nsize to less than four bytes or the ICV size to less chan eight bytes, or security will be\nsubstantially diminished.\n\nAlthough it’s technically possible to turn off encryption and only use authentica-\ntion, be aware that an authenticated packet without encryption exposes your game to\nsniffing attacks, which can result in cheating that’s just as bad as spoofing attacks (and\nharder to detect).\n\nConclusion\n\nAs more games support features like tournaments and prize competitions, secure\ncommunication not only reduces cheating, but also becomes an essential requirement\nof the game. The IPSec specification includes security elements that can directly ben-\nefit networked games. Although the packet overhead is not insignificant, performance\nis good, and the benefits of secure traffic are considerable.",
      "page_number": 532,
      "chapter_number": 56,
      "summary": "This chapter covers segment 56 (pages 532-540). Key topics include secure, security, and packet.",
      "keywords": [
        "secure packet",
        "packet",
        "Sequence Number",
        "security association",
        "Secure",
        "Security",
        "Encryption Algorithm",
        "data",
        "encryption",
        "payload",
        "Number",
        "Algorithm",
        "Secure Sockets",
        "Security Association Data",
        "Padding"
      ],
      "concepts": [
        "secure",
        "security",
        "packet",
        "key",
        "keys",
        "authenticated",
        "authentication",
        "authenticate",
        "encrypted",
        "encryption"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 7",
          "chapter": 54,
          "title": "Segment 54 (pages 522-529)",
          "relevance_score": 0.78,
          "method": "api"
        },
        {
          "book": "AI Engineering Building Applications",
          "chapter": 23,
          "title": "Segment 23 (pages 457-476)",
          "relevance_score": 0.6,
          "method": "api"
        },
        {
          "book": "Building Microservices",
          "chapter": 9,
          "title": "Security",
          "relevance_score": 0.6,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 1",
          "chapter": 11,
          "title": "Segment 11 (pages 99-106)",
          "relevance_score": 0.6,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 7",
          "chapter": 53,
          "title": "Segment 53 (pages 512-521)",
          "relevance_score": 0.6,
          "method": "api"
        }
      ]
    },
    {
      "number": 57,
      "title": "Segment 57 (pages 541-549)",
      "start_page": 541,
      "end_page": 549,
      "detection_method": "topic_boundary",
      "content": "556 Section 5 Network and Multiplayer\n\nReferences\n\n[AESDraft] “The AES Cipher Algorithm and Its Use With IPSec,” draft available\nonline at http://www.ietf.org/10.html, November 2001.\n\n[Howard02] Howard, Michae! and David LeBlanc, Writing Secure Code, Microsoft\nPress, 2002.\n\n[IPSec2] “IP Encapsulating Security Payload (ESP),” updated draft available online at\nhetp://www.ietf.org/ID. html, November 2001.\n\n[Isensee0 1} Isensee, Pete, “Genuine Random Number Generation,” Game Program-\nming Gems 2, Charles River Media, Inc., 2001.\n\n[KB228786] “How to Export/Import Plain Text Session Key Using CryptoAPI,”\navailable online at hetp://support.microsoft.com; q228786, July 2001.\n\n[RFC1321] “The MD5 Message-Digest Algorithm,” available online at herp://\nwww.iecf.org/rfc/rfcl321.txt, April 1992.\n\n{RFC2104] “HMAC: Keyed-Hashing for Message Authentication,” available online\nat http://www. ietf.org/rfc/rfc2104.rxt, February 1997.\n\n[RFC2401] “Security Architecture for the Internet Protocol,” available online at\nhttp://www. ietf. org/rfc/rfc240 1.x, November 1998.\n\n[RFC2403] “The Use of HMAC-MD5-96 within ESP and AH,” available online at\nhetp://www.ierf.org/rfc/rfc2403.mt, November 1998.\n\n[RFC2404] “The Use of HMAC-SHA-1-96 within ESP and AH,” available online at\nhttp://www. iecf.org/rfc/rfc2404.txt, November 1998.\n\n{RFC2405] “The ESP DES-CBC Cipher Algorithm with Explicit IV,” available\nonline at http:/Awww.ietforg/rfc/rfc2405.ct, November 1998.\n\n[RFC2406] “IP Encapsulating Security Payload {ESP),” available online at http://\nwww.ietf.org/rfc/rfc2406.txt, November 1998.\n\n[RFC3174] “US Secure Hash Algorithm (SHAI),” available online at http://\nwow iethorg/rfc/ rfc3174.cxt, September 2001.\n\n[Schneier96] Schneier, Bruce, Applied Cryptography, Second Edition, John Wiley &\nSons, 1996.\n\n[Schneier99] Ferguson, Neils and Bruce Schneier, “A Cryptographic Evaluation of\n[PSec,” available online at http://www.counterpane.com/ipsec.huml, February\n1999.\n\n[WeiDai01] Dai, Wei, “Crypto++ Cryptographic Class Library,” available online at\nhetp://www.eskimo.com/~weidai/cryptlib.html, November 2001.\n\n5.7\n\nON THE CD\n\nA Network Monitoring and\nSimulation Tool\n\nAndrew Kirmse, LucasArts\n\nEntertainment Company\nark@alum.mit.edu\n\nost online games are developed under ideal conditions on a high-bandwidth,\n\nlocal network with extremely low latency. In contrast, online games are typically\nplayed in low-bandwidth, high-latency environments with unpredictable network\nbehavior between machines. This gem describes a Windows-based simulation tool\ncalled “NetTool” that you can use to make a LAN behave more like the Internet.\nComplete source code and Win32 binaries are on the CD-ROM.\n\ninterface\n\nFigure 5.7.1 shows a picture of the Net Tool interface. The top section defines a set of\nfilters. Each filter describes the behavior of the network between two (IP address,\nport) pairs. TCP filters, being connection-oriented, allow communication in both\ndirections, so only one filter is required between any two hosts. UDP filters are one-\nway—the ‘Add reverse’ button will take the currently selected filter and create a new\none with the endpoints reversed. This is useful in the common case where the hosts\nuse the same port to send and receive data.\n\nNetTool simulates network latency on a per-packet basis according to a Gaussian\ndistribution. The interface allows you to set the mean and variance of each filter's\nlatency distribution.\n\nThere are several other controls available on each filter. Incoming packets are only\nforwarded when the Enabled box is checked, allowing you to selectively restrict traffic\nfrom individual hosts. Checking the Listed box causes incoming packets to be dis-\nplayed in the large list box on the lower right of the screen. The UDP Options set-\ntings apply only to UDP filters, and are described later.\n\nThe title bar displays all of the IP addresses assigned to the machine running Net-\nTool.\n\n558 Section 5 Network and Multiplayer\n\n127.0.0.1:3999\n127.0.0 1:3393\n127.0.0.1:3989\n127.0,0.1:9999\n127.0.0.1:9999\n127.0.0.1:9999\n127.0.0.1:9959\n127.0.0.1:9999\n127.0.0.1:9999\n127.0.0.1:9989\n127.0.0.1:9999\n427.0.0.1:9999\n127.0.0.1:9999\n127.0.0,1:9999\n127. 0.0.1:9989\n127.0.0.1:9999\n127.00.1:9999\n127.0.0.1:9898\n127.0.0.4:9999\n127.0.0.1:9999\n127.0.0.1:3995\n127.0.0.1: 9999\n127.0.0.1:9999\n\n3\n3\na\n3\n3\n3\n3\n3\n3\n3\n3\n3\n3\n3\n3\n3\n3\n3\n3\n3\n3\n3\n9\n\nNetwork Monitoring\n\n192 1680.37777\n192.168.0.9:7777\n192.168.7777\n192.168.0777?\n192.468.0.27777\n192,168.0.5:7777\n192,168.03: 7777\n192.168.0.9; 7777\n192.188.0.3:7777\n192168.0.27777\n192. 368.0.3:7777\n192,168.0.3:7777\n192,.168.0.9:7777\n192,168.0.9:7777\n192.168.0.9:7777\n192168.0.%.7777\n\n. 192468.0.47777\n\n492,168.0.3:7777\n192,168.0.8:7777\n192.168.0.9:7777\n192 188 0.9:7777\n\nDelayed 1110 ms\nDelayed 1205 ms\nReordered\nDelayed 822 ms\nDuphested\nDelaped 10 ms\nReordered\nReordered\n\nAs packets arrive, NetTool dispatches them according to the settings of the filters thac\nthey match, If the Show packets box is checked, a summary of each packet is dis-\nplayed in the list box in the lower right on the interface. This shows the packet's\narrival time, payload size, incoming and outgoing addresses, and the action that was\ntaken by NetTool. The action will be one of the following:\n\n* Sent immediately: No extra latency is required for this packet, so it’s sent right\n\naway.\n\n* Delayed Xms: The network simulation requires that the packet be delayed before\nbeing forwarded. The amount of delay is a combination of the filter's latency set-\ntings and the host bandwidth simulation (to be addressed later in this section).\n\n* Dropped: The packet was not forwarded. This occurs only for UDP packets\n\nwhen the filter’s Packet Joss setting is nonzero.\n\n5.7 A Network Monitoring and Simulation Tool 559\n\n* Reordered: The packet was sent before another packet that arrived previously.\nThis can only occur for UDP packets when the Reordering setting is nonzero.\n\n* Duplicated: The packet was sent twice. This occurs only for UDP packets when\nthe filter’s Duplication setting is nonzero.\n\n© Wair for connect: For a TCP filter, data arrived before the remote connection\ncompleted. It will be sent as soon as the connection succeeds.\n\nIf the Log to file box is checked, the same summary information will be logged to\nthe file log.txt.\n\nTCP Simulation\n\nTCP is a reliable, stream-based protocol: Data arrives in the order it was sent, in arbi-\ntrary-size chunks. NetTool appends all incoming data on a filter to a single queue. It\nthen polls the queue, forwarding as much data as the sender’s and receiver's band-\nwidth simulations will allow.\n\nSeveral subtleties arise in NetTool because of TCP’s connection-oriented nature.\nFor example, data can arrive from the sender before the connection to the receiver has\ncompleted, or the sender can shut down the connection before previously sent data\nhas been forwarded. These cases are accounted for and should be transparent to\napplications.\n\nUDP Simulation\n\nUDP is message-oriented, meaning that data arrives in the same chunks in which it\nwas sent. UDP is also unreliable, meaning that individual messages might be lost in\ntransit, arrive out of the order in which they were sent, or even arrive multiple times.\nOn a local network, UDP packets are almost never lost; but on the Internet, packet\nloss is common,\n\nNetTool drops packets with a probability given by the Packet loss box. These\npackets are simply thrown away, much like a router on the Internet might do under a\nheavy load.\n\nIf a packet is not dropped, it might be duplicated (sent twice) with a probability\nequal to that shown in the Duplication box. The latency model is applied to the two\nduplicate packets independently. If reordering is enabled, it’s possible that the dupli-\ncated packets will not arrive one after the other.\n\nPacket reordering will only occur under certain circumstances. Suppose two UDP\npackets, A and B, arrive on the same port. The latency simulation is applied to each\npacket independently, causing A and B to be scheduled for transmission. If, as a result,\nA is scheduled before B, no reordering will occur. However, if B is scheduled before A,\nNetTool will preserve this ordering with the probability given in the Reordering set-\nting. In order to force reordering to occur for testing purposes, it’s useful to introduce\nlatency with a high variance to make this second scenario more probable.\n\n560 Section 5 Network and Multiplayer\n\nHost Bandwidth Simulation\n\nIn addition to latency arising from network delays, latency is also induced at the end-\npoints of a connection by the available bandwidth For example, on a 300-bps\nmodem connection, it takes an entire second just to send 30 bytes (assuming 8 bits\nper byte, plus a start bit and a stop bit). In the lower-left section of the interface, you\ncan set the bandwidth available at each host. The send and receive bandwidth can be\nset separately, as this is actually a common case with 56k modems (which can only\nupload at 33.6k), and with asymmetric DSL connections. Several predefined band-\nwidth settings are available on buttons below the bandwidth sliders; these values are\nonly approximate.\n\nThe Netfoo! bandwidth calculations take into account the size of the header\nattached to each packet. For UDP, this is 28 bytes (20 bytes IP header plus 8 bytes\nUDP header), though this can be reduced to a simulated 7 bytes if Uses PPP is\nchecked, as PPP compresses the IP header. For TCP, the header would normally be 40\nbytes, but most slow consumer connections use VJ header compression, which\nreduces the size to about 8 bytes. In addition, many modems have optional compres-\nsion, which can be simulated by setting a compression percentage in the lower-left\ncorner, This bandwidth simulation is somewhat simplistic, but it is sufficient to pro-\nduce the approximate behavior of a client connection.\n\nConclusion\n\nNetTool is a convenient way to simulate consumer Internet connections on a LAN. It\nis particularly useful for stress-testing under poor network conditions; an ideal use\nwould be testing an implementation of reliable communication on UDP. Please for-\nward any improvements you make to the author so that they can be shared with others.\n\nCreating Multiplayer Games\nwith DirectPlay 8.1\n\nGabriel Rohweder,\n\nMicrosoft Corporation\ngrohwed@hotmail.com\n\ndding multiplayer functionality to a game can be a daunting task. Often, develop-\nrs will write their networking engines specifically to meet the needs of one title.\nPorting this code over to another title can be more of a headache than starting a new\none from scratch. DirectPlay helps provide solutions to these problems with a generic,\nextensible network-gaming API thar is both easy to use and easy to maintain. This gem\nis meant to explain some of the more-intricate details of using DirectPlay, as well as\noffer tips for avoiding common pitfalls. If you don’t have any experience with Direct-\nPlay, review the sample code in the DirectX SDK before reading this gem. DirectPlay\nsupports two types of networking architectures—client/server and peer-to-peer.\nAlthough there are many successful games on the market today that use the peer-to-\npeer architecture, this gem will focus mainly on the client/server architecture.\n\nInside DirectPlay\n\nTo reap the greatest rewards from DirectPlay, you should be familiar with how the\nAPI is constructed. DirectPlay consists of three separate layers: core layer, protocol\nlayer, and service provider layer.\n\nYour application will interact directly with the core layer, as seen in Figure 5.8.1.\nThe core layer is responsible for various tasks, such as initialization and maintaining\nthe player list. DirectPlay 8.1 utilizes a push model of information exchange. This\nmeans that your application will need to register a reentrant callback function with\nthe core layer, which will be called by the core layer when relevant messages are\nreceived from the protocol layer.\n\nThe protocol layer is responsible for the construction and interpretation of pack-\nets. DirectPlay adds 4 bytes to each packet—this is called the “packet header.” Direct-\nPlay is built on the UDP protocol, so these 4 bytes are in addition to the 28 bytes\nrequired for the UDP and IP headers. The header contains information that the\nreceiving side needs to know in order to process the packet correctly. This protocol is\n\n561\n\n562 Section 5 Network and Multiplayer\n\nnad\n\nApplication\n\nFIGURE 5.6.1 The DirectPlay message flow.\n\nalso responsible for throttling data (which will be explained later) and verifying that\nincoming packets are formed correctly.\n\nThe service provider layer provides the transport for your session. It allows you to\nsupport many different methods of networking, such as TCP/IP, serial, and IPX.\n\nAnother element of DirectPlay that is worth mentioning here is DPNSVR.\nDPNSVFR is an optional service that maintains a list of all the current hosts on your\nmachine. Doing this helps to ensure that your application doesn’t try to host a session\non a conflicting port and allows your client applications to enumerate all of the avail-\nable sessions hosted on a particular machine by querying port 6073. DPNSVR sup-\nports only the IPX and IP service providers at this time.\n\nTransmitting Data\n\nIt was mentioned earlier that DirectPlay is a generic API. By ‘generic,’ it is meant that\nDirectPlay was not designed around a specific game genre. One of the most popular\n\n5.8 Creating Multiplayer Games with DirectPlay 8.1 563\n\ntypes of games on the shelves today is the first-person shooter (FPS). The FPS gener-\nally requires very frequent transmission of smal! amounts of data. The fast action asso-\nciated with the FPS dictates the use of nonguaranteed messaging for most of your\ngame data. If a packet is lost on the wire, it could be irrelevant by the time it was suc-\ncessfully resent by the client. For this reason, most FPS network layers are built on\nUDP. UDP offers fast transmissions of data, with no guarantee that the packets will\natrive in the correct order or even arrive at all. There are times, however, when you\nwill want to make sure a packet gets to its intended recipient, and in the order sent.\nPlayer deaths and level changes are examples of when you would want to do this.\nDirectPlay will handle all of these scenarios for you, because it allows the programmer\nto specify if an individual packer is to be sent guaranteed, nonguaranteed, sequentially,\nor nonsequentially. A typical client-side send in DirectPlay is implemented as follows:\n\nMYMSG_OBJECT msgShoot;\nDPN_BUFFEA_DESC buffDesc;\nDPNHANDLE hAsync;\n\nmsgShoot .dwiype = MYMSGTYPE_SHOOT;\nbuffDesc.dwBufferSize = sizeof (MYMSG_OBJECT);\nbuffDesc,pBufferData = (BYTE*}&msgShoot;\npClient->Send(&buffDesc,1,0, NULL,&hAsync,0);\n\nBy default, DirectPlay sends messages nonguaranteed and sequential. The last\nparameter in the call to send()} is the dwFlags parameter. This parameter is used to\nspecify your send characteristics. For example, if you wanted to send your data guar-\nanteed and nonsequential, you would use the following call:\n\nDWORD dwFlags = DPNSEND_ GUARANTEED |\nDPNSEND_NONSEQUENTIAL;\npClient ->Send(&buffDesc,1,0,NULL, &hAsync , dwFlags) ;\n\nAfter a call to Send(} or SendTo{), your message is placed into the DirectPlay\ninternal send queue for that player. The reason for this is that DirectPlay throttles\ndata, a process whereby the protocol layer will increase or decrease the frequency of\nsends, depending on link conditions and how quickly the recipient can process them.\nThere is an associated send queue with every connection in a session, This ensures\nthat one slow connection will not affect the performance of all players in that session.\nIn order to increase performance in your application, it is important to process net-\nwork traffic as efficiently as possible. (See Reentrant Callbacks for tips on how to\nprocess data more effectively in your callback function.) You can check the status of\nyour send queue by calling GetSendqueueInfo(), as shown in the following code. The\nserver interface takes an additional parameter, specifying which player's send queue\ninformation to return.\n\nDWORD dwNumMsgs; //number of msgs in the send queue\n\nDWORD dwNumBytes; //number of bytes in the send queue\npClient ->GetSendQuevelInfo(&dwNumMsgs, &dwNumBytes, 0};\n\n564 Section 5 Network and Multiplayer\n\nSone me mr Amman aA an re DER UR mero LEERY mre meh SRI ear RMN eRe SRS aaa aumrm OMe nneetORRRSSAnmrmn\n\nA message will remain in the send queue until it is either sent or a timeout occurs.\nAtimeout value can be associated with each message, dictating the maximum amount\nof time that the message should be allowed to remain queued. If the message will\nbecome invalid after a certain amount of time, as was discussed earlier, it would be\nwise to specify a timeout value for that message. The following code specifies a time-\n\nout value of 30 ms:\n\nOWORD dwTimeOut = 30; //time in milliseconds\npClient->Send{&buffDesc, 1, dwlimeOut, NULL, &hAsync,0};\n\nIf you notice that your send queue is growing too large, there are two possibilities\nto consider. One possibility is that you are blocking the receive threads on the\nreceiver, prohibiting DirectPlay from processing incoming messages. The other possi-\nbility is that you are sending data more quickly than the receiver can process it, caus-\ning dropped packets. If your message queue is growing too large, but the number of\nbytes queued is relatively small, try coalescing your data. Coalescence means combin-\ning two or more messages into one larger message. DirectPlay will not do this for you\nbecause it is a generic API, and as such has no idea how to logically group your data.\nOne thing to be wary of when grouping your data is mixing message types. For\ninstance, you probably wouldn't want to combine a message telling the server that a\nplayer is now invisible, with a message saying that the player has fired a railgun. If you\nsend the message nonguaranteed, then you run the risk of losing the invisibility mes-\nsage, because the packet might be dropped and not resent. On the other hand, if you\nsend the message guaranteed, the player might start sporadically firing their railgun at\nan inopportune moment.\n\nOnce a message is received, the recipient sends back an ACK to the sender An\nACK is a special message telling the sender that the recipient received the message. If\nno ACK is received by the sender for a particular packet, then it is considered unde-\nlivered. The difference between a guaranteed send and a nonguaranteed send is how\nthe sender will handle an undelivered packet. With a nonguaranteed message, the\nsender will simply continue sending data from the message queue, ignoring the\ndropped packet. With a guaranteed message, the sender will retry sending the dropped\npacket until it is received, or until a timeout occurs. It is important to note here that\nthis timeout value is different from the one mentioned earlier, When a guaranteed\nmessage times out in this manner, DirectPlay determines that the connection has\nbeen Jost, and issues DPN_MSGID_TERMINATE_SESSION and DPN_MSGID_DESTROY_PLAYER\nmessages as appropriate. In DirectPlay, an ACK rides piggyback on a normal data\npacket to maximize throughput. In the event that there are no data packets to piggy-\nback, DirectPlay will create a special ACK packet and attempt to deliver it to the\nsender, Although it is optimized for bidirectional traffic, the frequency at which\nDirectPlay will create these special ACK packets is high enough (around 100 ms) to\navoid causing throttling issues on the sender in the event that your data stream is uni-\ndirectional.",
      "page_number": 541,
      "chapter_number": 57,
      "summary": "This chapter covers segment 57 (pages 541-549). Key topics include message, messaging, and packet. and David LeBlanc, Writing Secure Code, Microsoft\nPress, 2002.",
      "keywords": [
        "UDP packets",
        "packet",
        "AES Cipher Algorithm",
        "UDP",
        "send",
        "data",
        "DirectPlay",
        "Message",
        "Network",
        "send queue",
        "online",
        "Multiplayer References",
        "November",
        "AES Cipher",
        "online at http"
      ],
      "concepts": [
        "message",
        "messaging",
        "packet",
        "data",
        "network",
        "available",
        "send",
        "latency",
        "connection",
        "connect"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 7",
          "chapter": 54,
          "title": "Segment 54 (pages 522-529)",
          "relevance_score": 0.71,
          "method": "api"
        },
        {
          "book": "Python Essential Reference 4th",
          "chapter": 21,
          "title": "Network Programming and Sockets",
          "relevance_score": 0.58,
          "method": "api"
        },
        {
          "book": "Release It! Design and Deploy Production-Ready Software",
          "chapter": 7,
          "title": "Segment 7 (pages 51-58)",
          "relevance_score": 0.55,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 1",
          "chapter": 11,
          "title": "Segment 11 (pages 99-106)",
          "relevance_score": 0.54,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 47,
          "title": "Segment 47 (pages 448-460)",
          "relevance_score": 0.52,
          "method": "api"
        }
      ]
    },
    {
      "number": 58,
      "title": "Segment 58 (pages 550-557)",
      "start_page": 550,
      "end_page": 557,
      "detection_method": "topic_boundary",
      "content": "5.8 Creating Multiplayer Games with DirectPtay 8.1 665\n\nOne other popular type of game today is the massively multiplayer, online role-\nplaying game (MMORPG). While this genre of game shares some similarities with\nthe FPS networking model, there are many differences. An MMORPG tends to cater\nto thousands of players, simultaneously interacting in an expansive virtual environ-\nment. Current implementations of this model tend not to send network traffic for\nevery key press a player makes; instead, it sends state information across the wire. If\nyouve ever played an MMORPG, you will probably have noticed that while engaged\nin combat, the results are not governed by your keyboard or mouse dexterity as they\nare in an FPS, but rather by your character's attributes and abilities. You send a mes-\nsage to the server that you are entering combat mode and what your current target\nis—the server handles the rest. State information can also be used to communicate\nother data to the server, such as movement. When sending this kind of information\nacross the wire, you want your messages to be guaranteed. If the player's client is\ntelling them that they are in combat mode and fighting a mountain troll, but the\nserver is recognizing them as standing idle while being beaten to a pulp by a mountain\ntroll, you will have some angry players. Managing thousands of simultaneous connec-\ntions is another big issue with the MMORPG. DirectPlay scales well when properly\nimplemented and offers the programmer some handy tricks to help things go\nsmoothly. One such trick is grouping.\n\nGrouping allows the application developer to perform fewer sends, because they can\ntransmit to a group of players, rather than transmitting the same data to all of them\nseparately. In the MMORPG, the landscape is usually broken into zones or sectors.\nThis is an excellent way to group players. You can create a group of all the players in a\ncertain sector and send out your data to that one group. There is an overhead to\nadding and deleting players from groups, so you must be careful how you partition\nthem. In an FPS, it probably would not be beneficial to group players geographically.\nDue to the size of the average FPS map, a player could be switching from one sector\nto another every few seconds. Instead, you could use teams or some similar method to\ngroup players. The following code shows how to create a group in DirectPlay:\n\nDPN_GROUP_INFO dpnGrpInfo;\n\nDPNHANDLE hAsync;\n\nZeroMemory{&dpnGrpInfo, sizeof (DPN_GROUP_INFO)) ;\ndpnGrpInfo.dwSize = sizeof ({DPN_GROUP_INFO) ;\ndpnGrpinfo.dwiInfoFlags = DPNINFO_NAME;\n\nwescpy (dpnGrpInfo.pwszName, \"ThievesGuild\"};\n\npServer ->CreateGroup (&dpnGrpInfo, NULL ,NULL&hAsync , 0) ;\n\nOnce this code has been executed, your server interface’s callback function will be\ninvoked with a message of type DPN_MSGID_CREATE_GROUP, containing a DPNID. A\nDPNID is a unique identifier assigned to each player or group in a session. Once the\nDPN_MSGID_CREATE_GROUP message is received, it is safe to start adding players to the\n\n566\n\nSection 5 Network and Multiplayer\n\ngroup. To send a message to the group, you would need to supply the returned\nDPNID to the SendTo({) method of the server interface. You can also send a message\nto all players in your session by setting the DPNID_ALL_PLAYERS_GROUP constant in\nplace of the DPNID.\n\nWhen you send a message, DirectPlay creates an internal copy of that message.\nThis copying process carries an overhead. To optimize performance, there is a\nDPNSEND_NOCOPY flag that you can specify in your call to Send() or SendTo() that will\nprevent DirectPlay from making that internal copy. The down side to this is that the\nbuffer being sent must remain valid until the send completes. If you allocate your\nmessage on the local stack, you should not use asynchronous Send({) operations\nbecause the memory containing your message will go out of scope when your func-\ntion returns. Instead, allocate the buffer from the heap, and free it when the asyn-\nchronous send completes. For best results, you should use a pool of buffers to avoid\nthe cost of allocating and freeing each message. Sending a message synchronously will\nnot encounter this condition, since the Send() call will not return until the message\nhas been sent.\n\nReentrant Callbacks\n\nOne of the hardest issues to tackle in any application is multithreading. This is not\nonly because it can be tricky to program, but because it can be tricky to debug as well.\nLikewise, multithreading issues tend to be one of the biggest problems faced by devel-\nopers because DirectPlay relies heavily on reentrant callback functions. You must be\ncareful when writing your code, as an unexpected context switch could crash your\napplication. When designing your data structures, such as linked lists, keep in mind\nthat they could be accessed by two separate threads. Add reference counters to them\nto avoid resource conflicts. Use critical sections whenever accessing a global variable\nor other shared resource in your callback function. Besides the obvious need to avoid\ndeadlocks, be aware that waiting for locks or performing other lengthy operations in\nyour callback function prevents DirectPlay from using that thread to process other\ndata. This might cause the sender to throttle back, artificially limiting your through-\nput.\n\nOne way to avoid holding DirectPlay threads is to queue up your incoming mes-\nsages, and have a separate thread process them, thus freeing up the DirectPlay threads\nto do more work. Returning DPNSUCCESS_PENDING from the DPN_MSGID_RECEIVE mes-\nsage event will allow you to avoid the overhead of copying the buffer to your queue\nbecause DirectPlay will temporarily hand ownership of this buffer over to your appli-\ncation. If you choose to do this, you must call ReturnBuffer() when you are finished\nprocessing the message so that DirectPlay can free those resources.\n\ncase DPN_MSGID_ RECEIVE:\n\nPDPNMSG_ RECEIVE pRevMsg;\npAcvMsg = (PDPNMSG_RECEIVE)pMessage;\n\n5.8 Creating Multiplayer Games with DirectPlay 8.1 567\n\n//lock the queue to avoid race condition\n\nLockMyQueus{);\n\n//pass the hBufferHandle to the queue because\n\n/fyou will need that in your\n\n//call to ReturnBuffer()\n\nAddToMyQueue ( pRevMsg->pReceiveData,\npRevMsg->hButferHandle );\n\nUnlockMyGQueue {} ;\n\nreturn OPNSUCCESS PENDING;\n\n}\nOnce the queue has processed the message, make the call to ReturnBuffer():\n\npClient->ReturnBuffer (hBufferHandle , 0) ;\n\nIf your application needs to scale to a larger number of connections, a single\nqueue could hamper your performance. In this case, you might wish to devise a more\nsophisticated way of offloading message processing from your callback function.\n\nAsa side note, it is not always a bad thing to hold DirectPlay receive threads. It is\npossible that the network is able to handle more data than a CPU-bound receiver can\nprocess. If the receiver continues to queue these messages, the queue will grow with-\nout bounds. One solution is to queue received data until a limit is reached, and then\nbegin blocking new DPN_MSGID_RECEIVE callbacks. If and when all threads are blocked,\nthe senders will be forced to ‘back off.’\n\nDirectPlay lets you specify the size of your thread pool by calling setspPcaps(). By\ndefault, DirectPlay spins up 2” + 2 threads, where » is the number of processors in your\nsystem. If your CPU is not being utilized to its fullest and message queues are starting\nto back up, you could consider increasing your threadpooi size. Most likely, many of\nyour threads are busy waiting for disk I/O or critical sections. Therefore, you won't\ncause the CPU to thrash if you spin up more threads to handle DirectPlay messages.\nOn the other hand, if your application seems to be CPU bound, then you might want\nto decrease the number of threads DirectPlay can use. When setting the number of\nthreads in your DirectPlay application, remember that the threadpool can only be\nincreased, not decreased, once a call to Host(}, Connect(), or EnumHosts() is made.\nPrior to these function calls, the threadpool can be set to whatever size you deem\nappropriate. The threadpool is shared among all interfaces in a process. You can\nretrieve the thread count available by DirectPlay to process incoming messages by\ncalling GetSPCaps().\n\nDPN_SP_CAPS dpnCaps;\npClient ->GetSPCaps{&CLSID_DP&SP_TCPIP, &dpnCaps ,Q) ;\ng@pnCaps.dwSize = sizeof (DPN_SP_CAPS};\nif (dpnCaps.dwNumThreads < 16)\ndpnCaps.dwNumThreads = 16;\n\n}\npClient->SetSPCaps (&CLSID_DPSSP_TCPIP, &dpnCaps ,0) ;\n\nSection 5 Network and Multiplayer\n\nRefer back to Figure 5.8.1. When a message arrives, the service provider directly\ninvokes the protocol layer, the protocol layer invokes the core, and the core invokes\nyour callback function, all in the same thread from the service provider. This reduces\nthe amount of context-switching between the time a message is received on the wire\nand when it is passed to your application.\n\nDirectPlay gives you a few tools to help you with multithreading and perfor-\nmance issues in your callback function, one of them being the context value. A user\ncontext is a value that you pass to DirectPlay, and DirectPlay will pass that value back\nto you in related calls to your callback function. Why is this helpful? Imagine that you\nhave an application with two client interfaces, one for data and one for voice (as you'll\nsee later in this gem, a DirectPlay voice connection requires a DirectPlay client or peer\ninterface). Although you have two client interfaces, you might only want to code one\ncallback function for them both, When the core layer calls into your callback func-\ntion, you have no idea which interface the new message belongs to. Specifying a user\ncontext value in the call to Initialize() allows you to determine for which client\nobject the newly arrived message is relevant. A context value can also be associated\nwith every player in the sesston. This player context value can play a large part in opti-\nmizing the time you spend inside of your callback function. When a client connects\nto a session, you can associate its context value during the DPNMSG_INDICATE_CONNECT\not DPNMSG_CREATE_PLAYER messages. All subsequent messages arriving from that client\nwill contain a pointer to the relevant player. Notice in the following code that once a\nplayer joins the session, its context value is set. Later, when a message is received from\nthat same player implying that it now has a damage modifier, the server can use the\nplayer context as an index into the player list. This quickly adds up to a lot of saved\nprocessing time.\n\nHAESULT WINAPI DPClientMsgProc(PVOID pvUserContext,\n\nDWORD dwMessageType,\nPYOID pMessage}\n\nHRESULT hr = S_OK;\nswitch(dwMessageType)\n{\ncase DPN_MSGID_CREATE_PLAYER:\n{\n//add player to your list and\n//set their user context value\nPDPNMSG_CREATE_PLAYER pMsg;\npMsg = (PDPNMSG_CREATE_PLAYER)pMessage;\nMYPLAYER mpPlayer;\nmpPlayer.dpnid = pMsg->dpnidPlayer;\nLockMyPlayerList{)} ;\npAddress = AddPlayarToList (&mpPlayer) ;\nUnlockMyPlayerList ();\npMsg->pVUserContext = pAddress;\nbreak;\n}\ncase DPN_MSGID_RECEIVE:\n\n5.8 Creating Multiplayer Games with DirectPlay 3.1 569\n\nPDPNMSG_RECEIVE pRevMsg;\npRevMsg = (PDPNMSG_RECEIVE) pMessage;\nMYPLAYER * pPlayer = NULL;\nLockMyPlayerList{);\npPlayer = GetPlayerFromlist (\npRevMsg->pvPlayerContext };\nif({pPlayer == NULL)\n{\nhr = OPNERR_GENERIC;\nUnlockMyPlayerList (};\nbreak;\n\n}\n\nMYMSGTYPE * pMsg = NULL;\npMsg = (MYMSGTYPE*}\npRcevMsg-> pReceiveData;\nswitch( p¥sg->dwType }\n\n{\ncase MYMSG_QUADDAMAGE:\n\n{\npPlayer->DamageFactor *= 4;\nbreak;\n\n}\n\n}\nUnlockMyPlayerList();\nbreak ;\n}\n}\nreturn hr;\n}\n\nAnother benefit that DirectPlay provides you is the serialization of callbacks. Seri-\nalization means that you are guaranteed that any two messages involving a particular\nplayer will not be handled on separate threads at the same time. A good example here\nwould be a server receiving a message from a client to join a session. Immediately after\njoining the session, however, the client decides to disconnect. If a DPN_MSGID_\nDESTROY_PLAYER message were to arrive before the server has had time to complete its\nplayer initialization code, the server could be left trying to access an invalid object in\nits player list. The DirectPlay callback serialization guarantees us that this will never\nhappen.\n\nSending Voice with DirectPlay\n\nWhether it is to discuss tactics, taunt your enemies, or just chat with a friend, com-\nmunication is an important part of any multiplayer game. Unfortunately, text-based\nchat interfaces can be distracting when you are trying to play a game, and canned\naudio can become monotonous after you've heard the same words repeated for the\nhundredth time. Luckily, there is another option. If you're using DirectPlay for your\nnetworking layer, you can easily add voice communications to your game, and it only\n\ntakes a little extra work.\n\n570 Section 5 Network and Multiplayer\n\nThe DirectPlayVoice interface allows you to send voice data over your network\nconnection, using a DirectPlayClient or DirectPlayPeer connection as a transport.\nYou will need to register a callback function in your call to Initialize(), just as you\ndid for your client interface. Assuming that you already have your client/server\nDirectPlay session setup for your voice data to use as a transport session, getting\nDirectPlay Voice up and running is simple. The following code is all you need to get a\nVoice server to host a session:\n\n/ipServer is your iDirectPlay8Server interface pointer\n\n//and must be currently hosting a session\npVoiceSrvr ->Initialize({pServer, SrvrProc, NULL, NULL, 0};\n\nDVSESSIONDESC dvSesDesc;\nZeroMemory (&dvSesDesc, sizeof (DVSESSIONDESC) ) ;\n\ndvSesDesc.dwSize = sizeof (DVSESSIONDESC) ;\ndvSesDesc.dwFlags = DVSESSION_NOHOSTMIGRATION;\nif (fMixingServer == TAUE)\n\n{\n\ndvSesDesc.dwSessionType\nDVSESSIONTYPE_MIXING;\n\nelse {/Forwarding server\n\ndvSesDesc .dwSessionType\nDVSESSIONTYPE_FORWARDING;\n}\n//this value must be retrieved by a call to\n// GetCompressionTypes()\ndvSesDesc,guidCT = MyCodecGuid;\ndvSesDesc. dwBufferQuality =\nDVBUFFERQUAL ITY_DEFAULT ;\ndvSesDesc .dwBufferAggressivensss =\nDVBUFFERAGGRESSIVENESS DEFAULT;\npVoiceSrvr ->StartSession(&dvSesPesc, 0);\n\nInitializing and connecting a voice client to a hosting session is similarly easy. The\nfollowing code will initialize, connect, and set transmit targets for your voice client:\n\n/fpClient is your IDirectPlay8Client interface pointer\nf/and must currently be joined to a session\npVoiceClient->Initialize(pClient , VoiceProc ,NULL,0,0) ;\nDVCLIENTGONFIG dvClientConfig;\nZeroMemory (&dvGlientConfig, sizeof (DVCLIENTCONFIG }};\ndvClientConfig.dwSize = sizeof (DVCLIENTCONFIG );\ndvClientConfig.dwFlags =\nDYCLIENTCONFIG_AUTOVOICEACTIVATED |\nOVCLIENTCONFIG_AUTORECORDVOLUME ;\névClientConfig.1PlaybackVolume =\nDVPLAYBACKVOLUME_DEFAULT;\ndvClientConfig. dwBufferdguality\nBYBUFFERQUALITY_DEFAULT;\n\n6.8 Creating Multiplayer Games with DirectPtay 8.1 571\n\ndvGlientContig.dwaufferAggressiveness =\nDVBUFFERAGGRESSIVENESS DEFAULT;\n\ndvGlientGonfig .dwThreshold = DVTHRESHOLD_UNUSED;\n\ndvClientConfig.1lRecordVolume = DVAECORDVOLUME_LAST;\n\nOVSOUNDDEVICECONFIG dvSDConfig;\n\nZeroMencry (&dvS0Config, sizeof (DVSOUNDDEVICECONFIG) );\n\ndvSbContig.dwSize = sizeof (DVSOQUNDDEVICECONFIG);\n\ndvSDContig.guidPlaybackDevice =\nDSDEVID_BDefaultVoicePlayback;\n\ndvSDConfig.guidCaptureDevice =\nDSDEVID_DefaultVoiceCapture;\n\ndvSDConfig .hwndAppWindow = hDl1g;\n\np¥oiceClient ->Connect (&dvSO0Config, &dvGlientConfig,0};\n\nDVID dvid = DVID_ALLPLAYERS;\n\np¥oiceCGlient->SetTransmitTargets(advid, 1, 9);\n\nDirectPlay Voice manipulates audio using DirectSound, allowing the developer to\ndo effects processing, such as voice warping or lip synching, on the receiving end of an\naudio stream. DirectPlay Voice also supports 3D positional audio, which can greatly\nenhance the realism of voice transmissions in 3D games.\n\nDirectPlay Voice can be set up in one of three different configurations:\n\n* A peer-to-peer configuration allows all players to send their voice data directly to\ntheir intended target. The advantage to this is that a dedicated server is not\nneeded to process the voice data. This method is great for games with a limited\namount of players, but it does not scale well at all.\n\n* A forwarding configuration sends the voice data to a central server, where it is for-\nwarded to the receiving players. With this configuration, a client only needs to\nsend one voice message out with a list of intended recipients, cutting down band-\nwidth requirements. Bandwidth requirements on the server, however, are much\nhigher, as it must send out several voice messages to different players.\n\n¢ The third configuration is the mixing server. This is the best choice if you have a\ndedicated piece of hardware available to perform mixing operations on incoming\nvoice data. A mixing server, like the forwarding server, allows clients to send one\nvoice stream out with a list of intended recipients; but where they differ is that a\nmixing server will combine all of the audio destined for one target together and\nsend it out as a single audio stream. This reduces the bandwidth requirements on\nthe client and server, but it requires more processing power.\n\nIf you want to use a peer-to-peer configuration with your voice data, you must\nhave a peer-to-peer DirectPlay session hosted. However, it is not required that it be\nthe same session that you are using to transport game data. Thus, Figure 5.8.2 shows\ntwo valid networking models for a client/server game with voice: one with a peer-to-\npeer voice configuration and the other with a separate voice-forwarding or voice-\nmixing configuration.\n\n572 ion 5 Network and Multiplayer\n\nx\n\nGame Server\n\nGame Server Voice Server\n\n———s\n\n=\n\nFIGURE 5.8.2 Left: Peer-to-peer voice configuration. Right: Client/Server voice\nconfiguration.\n\nResources\n\nIf you are having trouble with some aspect of DirectPlay, there’s a likely chance that\nsomeone else has, too, There are many resources on the Internet that can provide help\nwith your DirectPlay networking layer, most notably the Web networking news-\ngroups at microsoft. public.directx.networking and microsoft.public.win32.program-\nmer.directx.networking. These newsgroups are frequently monitored by members of\nthe DirectPlay team and experienced users of the API, and can be an invaluable\nresource during the development of your game.",
      "page_number": 550,
      "chapter_number": 58,
      "summary": "This chapter covers segment 58 (pages 550-557). Key topics include players, messages, and voice. State information can also be used to communicate\nother data to the server, such as movement.",
      "keywords": [
        "DirectPlay",
        "voice",
        "Creating Multiplayer Games",
        "server",
        "player",
        "message",
        "group",
        "DPN",
        "send",
        "DirectPlay voice",
        "voice data",
        "callback function",
        "group players",
        "client",
        "Multiplayer Games"
      ],
      "concepts": [
        "players",
        "messages",
        "voice",
        "server",
        "networking",
        "process",
        "processing",
        "received",
        "receive",
        "games"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 8",
          "chapter": 47,
          "title": "Segment 47 (pages 448-460)",
          "relevance_score": 0.61,
          "method": "api"
        },
        {
          "book": "Generative AI with LangChain_2e",
          "chapter": 32,
          "title": "Segment 32 (pages 270-277)",
          "relevance_score": 0.6,
          "method": "api"
        },
        {
          "book": "AI Agents In Action",
          "chapter": 22,
          "title": "Segment 22 (pages 188-196)",
          "relevance_score": 0.56,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 2",
          "chapter": 12,
          "title": "Segment 12 (pages 101-108)",
          "relevance_score": 0.55,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 7",
          "chapter": 32,
          "title": "Segment 32 (pages 301-308)",
          "relevance_score": 0.55,
          "method": "api"
        }
      ]
    },
    {
      "number": 59,
      "title": "Segment 59 (pages 558-566)",
      "start_page": 558,
      "end_page": 566,
      "detection_method": "topic_boundary",
      "content": "Wireless Gaming Using the\nJava Micro Edition\n\nDavid Fox, Next Game\ndavidfox@ureach.com\n\nn an era of supercharged consoles, photo-realistic monsters, and rich 3D universes,\n\nwriting games for a wireless device can feel lackluster. The screen is miniscule—less\nthan 100 X 100 on most mobile phones. You have little dynamic memory to play\naround with—only a 32-KB heap on many phones. And there’s limited network con-\nnectivity; most second-generation wireless networks send data at 9.6 kbps (kilobits\nper second). The processors on wireless devices are also hundreds of times slower than\nan average desktop computer.\n\nOn the plus side, i’s becoming harder to find people who don't carry network-\nenabled devices with them. At the end of 2001, there were more than 600 million\nmobile phone users worldwide. If a compelling wireless game caught fire, it would\nfind a massive audience.\n\nWhile it might seem silly to try to achieve a rich, meaningful immersion on a tiny\nscreen, there's one thing mobile phone games offer chat even the best consoles can't\nprovide: They're always with you and can be played anywhere you go. Furthermore,\nmany wireless networks implement some form of mobile positioning. As this feature\nbecomes more accessible, a game can track exactly where a player is in the real world.\nWireless games are not only portable and convenient to play, but with some clever\ndesign, wholly new types of experiences can seamlessly meld virtual space with reality.\n\nAnother burgeoning field is in creating wireless extensions to existing games. For\nexample, a mobile interface can tap into a persistent multiplayer game world that is\nusually played in full visual splendor on a console. A mobile gamer could be instantly\nnotified of attacks and surreptitiously logon during meetings to tweak settings or\nmake important decisions.\n\nThe difficulty lies in achieving meaningful network interaction given extreme\nlimitations.\n\nNetwork Characteristics\n\nLatency is the time it takes for a packet of data to travel from one point to another,\nand is usually based on distance and number of hops between the two points.\n\n573\n\n574\n\n_ | $eetion 5 Network and Multiplayer\n\n|\nBandwidth is the amount of data that can be sent per second, and is usually based on\nthe physical hardware being used to transfer data.\n\nMultiplayer game programmers struggle with the Internet's high latency and the\naverage home user's low bandwidth. Second-generation (2G) wireless networks, how-\never, make the Internet seem downright speedy.\n\nEuropean mobile phones primarily operate on the Global System for Mobile\nCommunication (GSM), which sends data at 9.6 kbps. Most networks in North and\nSouth America, Russia, Israel, Eastern Asia, and Centra! Africa transfer data based on\na standard called Code Division Multiple Access (CDMA), which runs at a peppier\n14.4 kbps. Some networks tise Time Division Multiple Access (TDMA), which is\nsimilar to GSM and has the same 9.6-kbps limit,\n\nProviders in Japan, Hong Kong, South Korea, and Singapore use what can be\nthought of as a 2.5-generation (2.5G) network. This is achieved using a vatiant of\nCDMA (IS-95B), which achieves a 64-kbps data transfer rate. In the United States,\nCDMA 2000 has been deployed in select markets, eventually hoping to offer speeds\nof up to 144 kbps. Furthermore, most GSM networks are being upgraded to use Gen-\neral Packet Radio Services (GPRS), which can theoretically reach speeds of 170 kbps.\n\nThird-generation (3G) networks are slowly being rolled out. Most 3G standards\nare built on top of Internet Protocol (IP) services, allowing for high-speed mobile\naccess. The plan is for networks to scale up gradually, starting with 2.5G technologies\nand ramping up to speeds of around 300 kbps, and finally reaching 2400 kbps (2.4\nMbps), which is even faster than today’s home DSL connections. Deployment of 3G,\nhowever, is extremely expensive and fraught with all sorts of challenges. We should\nnot expect to see widespread 3G networks anytime soon.\n\nWide area wireless networks are also high latency because of the inherent inter-\nference and noise of radio wave communications. Most wireless networks force data\npackets to hop over many high-latency routers. Satellite-based wireless networks gen-\nerally add even more latency. It is not rare to experience network delays of one or even\ntwo seconds.\n\nFor the time being, then, wireless game designers should assume that they are\nworking with a thoroughly high-latency, low-bandwidth connection.\n\nJava Micro Edition\n\nJava (Sun Microsystems) is emerging as a standard language for wireless devices. Java\nruns in a virtual machine, which means that as long as developers follow the right pro-\ncedures, the same Java byte code can run on any supporting platform. Java is also\nextremely easy to use. It is object-oriented with no pointers, no complicated memory\noperations, and automatic garbage collection. Most importantly, Java applets cannot\naccess functions or memory outside of their secure ‘sandbox,’ which means that it is\nvirtually impossible to write malicious code or viruses.\n\nJava 2 Micro Edition (J2ME) [{J2ME01) is an attempt to take the best aspects of\nstandard Java and pare them down for smaller devices, such as mobile phones, pagers,\n\n5.9 Wireless Gaming Using the Java Micro Edition 575\n\nand handheld organizers. Most major mobile phone manufacturers have joined with\nSun to create the CLDC (Connected, Limited Device Configuration} [CLDC01],\nalong with the MIDP (Mobile Information Device Profile) [MIDP01]. A Java applet\nwritten for a mobile phone, therefore, is called a “MIDlet.”\n\nVarious device manufacturers have released extension APIs for J2ME. For exam-\nple, Siemens has an extensive game API that sits atop MIDP. NTT DoCoMo does\nnot use MIDP, but has a separate Java profile known as “I-Appli.”\n\nQualcomm has created a virtual machine and language called the Binary Run-\ntime Environment for Wireless (BREW), which is based on C++. Qualcomm has\nembedded BREW right onto the chipset for CDMA phones. While BREW is a J2ME\ncompetitor in some sense, a Java Virtual Machine can be written in BREW.\n\nMobile phone manufacturers have embraced Java in a way that not even PC man-\nufacturers have. Java is emerging as the platform of choice for mobile devices.\n\nJ2ME Networking Nutshell\n\nIn the world of Java Standard Edition, the large and intricate java.io.* and\njava.net .* packages are used to great effect. These packages contain most any type of\nnetworking class you want, such as Socket, DatagramSocket or ServerSocket. Each\nclass has different methods and different ways of being used.\n\nIn the world of J2ME, however, we don’t have the luxury of being so complete.\nFor starters, we have no idea what type of network transport protocol a phone is\nusing. Devices that work over circuit-switched networks can use streaming always-on\nconnections, such as the Transport Control Protocol (TCP). However, packet-\nswitched networks might only be able to handle its network data in discrete, nonguar-\nanteed packets using a protocol such as the User Datagram Protocol (UDP).\n\nThe CLDC’s Connection interface was created to be as general as possible. The\nConnection class is a catch-all that can, in theory, handle any kind of network con-\nnection. A special class known as the “Connector* can tap into any CLDC class that\nextends from the Connection interface.\n\nEvery Cennector’s open method accepts a string with the familiar syntax:\n“protocol:address: parameters”. For example, to open a typical HTTP connection:\n\nConnector .open{ “http: //java.sun.com/developer\");\nTo open a socket:\n\nConnector. open( \"socket: //123.123.111.000:9000\"} ;\nAnd to open a datagram connection:\n\nConnector.open(\"datagram: / /waw.myserver.com:9000\");\nYou can then create a datagram and send it as follows:\n\nDatagram dgram = dc.newDatagram({message, msglength,\n\n576 Section 5 Network and Multiplayer\n“datagram: / /waw.myserver .com:;9000\") ;\ndc.send(dgram) ;\ndc.close();\n\nThe remote ‘server’ could, of course, be another mobile device. Most wireless\ndevices can easily communicate in a peer-to-peer fashion with each other. Peer-to-\npeer latencies ate lower—there’s no need to use a middleman. However, in peer-\nto-peer games, one of the peers generally acts as a server, and the other acts as a client.\nThe size of this extra server code could make such a scheme infeasible. To have a\nMiDlet deal with incoming traffic, just create an endless loop that listens to a port\nand waits for some data:\n\nDatagramConnection dc = (DatagramConnection) Connector. open\n(\"datagram: //:\"+receiveport} ;\nwhile (true)\ndgram = dc.newDatagram(dc.getMaximumLength{));\ndc. receive (dgram} ;\nreply = new String(dgram.getData(), 0,\ndgram.getLength());\n}\n\nSince the Datagram protocol is standard, we could write an extremely simple\nserver component in Java Standard Edition (or any other language), running on any\nPC. For instance:\n\nDatagramSocket receiveSocket = null;\n\nDatagramPacket receivePacket = new DatagramPacket (bytesReceived,\nbytesReceived. length};\n\nreceiveSocket .receive(receivePacket};\n\nAs you can see, the MIDP specification makes it extremely easy to pass data back\nand forth. Unfortunately, many wireless devices do not support datagrams. A Connec-\ntionNotFoundException will be returned if the device you are using does not support\nthe protocol you requested.\n\nThe only protocol that MIDP devices must support is HTTP. As such, it is rec-\nommended that you design wireless games for the lowest common denominator—\nusing HTTP.\n\nHTTP Limitations\n\nHTTP is a widely supported protocol. It is exceptionally easy to design Java servlets or\nother Web technologies to be able to deal with HTTP [Fox01]. Additionally, HTTP\nrides atop TCP, so there will be no out-of-order or missing packets. You will not need\nto bulk up your MIDlet with extra networking code.\n\nHowever, HTTP’s simplicity is also its downfall. HTTP is a request-response\nprotocol designed to deliver static content. A TCP connection is made, a browser asks\nfor a document (request), a Web server delivers it (response), and the connection is\n\n5.9 Wireless Gaming Using the Java Micro Edition 577\n\nclosed. HTTP Version 1.1 is a little more advanced, allowing for arbitrary amounts of\nchunked data and for connections that stay alive. But HTTP is still very much a half-\nduplex protocol—you cannot transmit in two directions at the same time.\n\nIf your game is a simple turn-based game, you might not need full-duplex con-\nnections at all. Latency and bandwidth will not be much of a problem, either. Only\none player may make a move at a time. A player moves, the new game state is sent\ndown to all players, and then the next player can make a move.\n\nHowever, if your game is more advanced and has unpredictable data packets com-\ning in constantly, you're in trouble. And what if you want to tap into a complicated,\nfull-featured game server that uses UDP?\n\nUse Multiple Connections\n\nOne way to achieve full-duplex communication is by having your MIDlet client cre-\nate multiple connections—one that sends data to the server and one that stays alive,\nretrieving server data. The first connection should use chunked transfer encoding.\nThe server creates an open connection and assigns it some sort of unique ID. This ID\nis then sent down to the client.\n\nThe client can now create one client-to-server connection with an incredibly\nlarge “Content-length” heading, passing in the proper ID. The server can then handie\nrequest data as it flows in from the client and channel an appropriate response to the\nopen server-to-client connection.\n\nSome servers and proxies might not be able to handle a request with a long con-\ntent length, and might buffer the request and wait for it to be completed. In this case,\nthe client can break each message into a chunk and send it as an individual request.\nThe client should send the ID along with each request, either as a custom header ele-\nment or as part of the payload. The server can then parse this ID number and send\nthe appropriate response back to the client.\n\nProxy Power\n\nAnother way of creating robust wireless communications is to write your game server\nusing any protocol you wish. You can then tap into the game server via an HTTP\nproxy. This is a simple enough system——the MIDlet communicates with a proxy\ninstead of a game server. It will, of course, add extra latency. However, it will also\nallow you to create a better experience for devices that support better network proto-\ncols. For example, devices that support datagrams can try communicating directly\nwith your game server. If a GonnectionNotFoundexception is thrown, the game can\nrevert to using HTTP via a proxy instead.\n\nOptimizing Packets\n\nSo how do we create meaningful game traffic using HTTP over a high-latency, low-\nbandwidth network? In effect, the challenge of creating a wireless game is similar to\n\n6738\n\nSection 5 Network and Multiplayer\n\nthat of any other multiplayer game: Packets must be as small as possible, and design-\ning the game around network limitations is tantamount.\n\nThere are many network programming subtleties and rules of thumb to deal with\nthe design of TCP/IP. For better or worse, a lot of these subtleties do not have to be\ndealt with in wireless games—tlatency and bandwidth are too limited to warrant being\nbothered.\n\nBetter Latency\n\nThe following game scenario illustrates a basic problem involving latency. Rat A and\nRat B spot a piece of cheese at the same time, and both make a mad dash for it.\nBecause it takes a second or more for each player to be notified of the other’s location,\nboth rats see themselves as the first one to grab the snack.\n\nThere are many techniques for dealing with this. Dead reckoning [Aronson01] is\na method to extrapolate and predict a game character’s movement. Latency can also\nbe dealt with by locking the game frames in step [Bettner01]. Both of these tech-\nniques, however, involve every client keeping a detailed simulation of every entity in\nthe game. This might require more memory than a witeless device offers.\n\nIt might also be wise to have your game server measure the latency of packets it\nreceives and deal accordingly. A typical multiplayer shooter-game server sends data at\na rate of 10 frames per second (fps). This will most likely be unfeasible for a wireless\ngame. Since animation rates for wireless devices are slower (often only 10 fps), net-\nwork rates of 2 fps to 3 fps are acceptable, given the general slowness.\n\nBetter Bandwidth\n\nBandwidth is usually not as much of an issue as latency, since game packets can often\nbe made quite small. The most important rule of thumb is that, like never before,\nevery bit adds up.\n\nRather than send the game state every frame, you should delta-compress your\ninformation, only transmitting the data that has changed. Additionally, MIDP does\nnot support floating-point operations. Most games that involve graphics will simulate\nfloating-point math using a long integer. Try to reduce and simplify such values to 8\nbits or 16 bits whenever possible. The simplest form of data compression is byte-\npacking—don’t waste a whole byte to send a boolean value. Instead, tweak individual\nbits to send eight flags at once.\n\nThere are more-advanced forms of data compression that can take large packets\nand reduce their size by 30% or more. These include gzip. The downside to com-\npressed packets, however, is that already-high latency will become even higher because\nof the time it cakes to compress and decompress. The code to handle compressing\nmight also take up too much room in the MIDlet. In most cases, simply packing your\ndata into bytes will be sufficient.\n\nThe game server should prioritize messages. Some messages are necessary for the\ngame to function properly. Others, such as a chat message or score update, are not as\n\n5.9 Wireless Gaming Using the Java Micro Edition 579\n\nessential. If a message is not immediately relevant to a game scene, you should avoid\nsending it altogether.\n\nTry to tokenize messages as much as humanly possible. In other words, try not to\nsend the phrase “Your tank was hit!” Instead, send a single byte macro that is mapped\non the client to a hard-coded list of phrases.\n\nRetrieving Images from the Server\n\nVersion 1 MIDlets can only display graphics using the PNG file format. Unfortu-\nnately, there is no method to directly grab an image from the network, Rather, the\ncreateImage method accepts only two types of parameters: a string (for filenames) or\na byte array:\n\ncreateImage(byte[] imageData, int imageOffset, int imageLength) ;\n\nThe way to retrieve images using MIDP is to download the binary contents of an\nimage, and then feed that array directly into the createImage method:\n\npublic Image grabImge(String url}\n{\nInputStream is = null;\nHttpConnection he = null;\nImage img = null;\ntry {\nhe = (HttpConnection)Connector.open(url);\n// If we've got a connection...\nif (he .getResponseCade({) ==\nHttpConnection.HTTP_OK) {\n// Open the stream\nis = hc.openinputStream(};\n// How big is the file?\nint len = {int)hc.getLength();\n// Create a byte array that size\nbyte[} data = new byteflen];\n{/ Read in the file\nint actual = is.read(data};\n// Create an image from the raw data\nimg = Image.createImage(data, 0, len};\n}\n} catch (Exception e) {\nSystem.out.println(\"Id Exception+\"+e) ;\n} finally {\nif (is != null} {\ntry f\nis.clase{);\n\ncatch (Exception e} { }\n\n}\nif (c != null)\n{\n\ntry {\nc.close();\n\n580 , Section6 Network and Multiplayer\n\n}\ncatch (Exception e}) { }\n}\n\nreturn img;\n\n}\n\nIf you want images to look as good as possible on various mobile devices, it is rec-\nommended that you create an image server. That way, your game can send the device's\nscreen size, color abilities, and other parameters. The image server can then take large,\ncolorful images and convert them on-the-fly into tiny, grayscale PNGs. The Java\nAdvanced Imaging API [Javalmage01} and other such packages can do most of this\nwork for you.\n\nConclusion\n\nThe biggest challenge in wireless networking, other than the limitations of the net-\nwork itself, is to balance limited device space, speed, and memory with advanced net-\nworking techniques. While using dead reckoning, frame locking, compressed packets,\nand other tricks might be effective in theory, many mobile devices only allow 10 KB\nto 50 KB of space for your byte code. Fitting both the game code and the networking\ncode into this box is often a harrowing experience.\n\nDesigning games cleverly in order to make the most of limitations is always the\nbest bet. For example, you might opt to use tanks instead of soldiers in a war game.\nTanks move slowly, can only fire a round occasionally, and take a long time to change\ntheir direction. Of course, there’s only so far this approach can take you. Ultimately,\nsome types of games will simply not be possible until better wireless networks and\ndevices are rolled out.\n\nBut if these challenges are faced, the results can be worth it. Wireless devices offer\nalways-on networking and in-pocket interactivity. Given the pervasiveness of hand-\nheld devices and the potential for reaching a wider audience than ever before, a truly\noriginal wireless game concept can revolutionize the face of entertainment.\n\n[Aronson01] Aronson, Jesse, “Dead Reckoning: Latency Hiding for Networked\nGames,” Gamasutra. Available online at hetp://www.gamasutra.com/fea-\ntures/19970919/aronson_01.htm, September 19, 1997.\n\n[Bettner01] Bettner, Paul and Mark Terrano, “1500 Archers on a 28.8: Network Pro-\ngramming in Age of Empires and Beyond,” Game Developer's Conference Pro-\nceedings, 2001. Available online at hetp://www.gdconference.com/archives/\nproceedings/2001/terrano_1500arch.doc.\n\n[CLDC01} Sun.com, “CLDC Information Page,” available online at hetp://java.\nsun.com/products/cldc/.\n\n[Fox01] Fox, David, “Creating Games Using J2ME,” Gamasutra. Available online at\nhep://www.gamasutra.com/resource_guide/20010917/fox_0O1.htm, September\n17, 2001.\n\n&.9 Wireless Gaming Using the Java Micro Edition 581\n\n(J2ME01] Sun.com, “J2ME Information Page,” available online at herp://java.sun\n.com/j2me/.\n\n[Javalmage01] Sun.com, “Java Advanced Imaging API,” available online at hetp://\njava.sun.com/products/java-media/jai/.\n\n[MIDPOI] Sun.com, “MIDP Information Page,” available online at hetp://\njava.sun.com/products/midp/.",
      "page_number": 558,
      "chapter_number": 59,
      "summary": "This chapter covers segment 59 (pages 558-566). Key topics include gaming, game, and networking. And there’s limited network con-\nnectivity; most second-generation wireless networks send data at 9.6 kbps (kilobits\nper second).",
      "keywords": [
        "Java Micro Edition",
        "Game",
        "Wireless",
        "Java",
        "wireless networks",
        "Java Micro",
        "wireless game",
        "Micro Edition",
        "wireless devices",
        "network",
        "game server",
        "data",
        "Java Standard Edition",
        "Wireless Gaming",
        "server"
      ],
      "concepts": [
        "gaming",
        "game",
        "networking",
        "java",
        "wireless",
        "device",
        "server",
        "mobile",
        "latency",
        "latencies"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 8",
          "chapter": 47,
          "title": "Segment 47 (pages 448-460)",
          "relevance_score": 0.58,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 7",
          "chapter": 54,
          "title": "Segment 54 (pages 522-529)",
          "relevance_score": 0.46,
          "method": "api"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 17,
          "title": "Segment 17 (pages 326-347)",
          "relevance_score": 0.46,
          "method": "api"
        },
        {
          "book": "Game_Engine_Architecture",
          "chapter": 18,
          "title": "Segment 18 (pages 348-366)",
          "relevance_score": 0.45,
          "method": "api"
        },
        {
          "book": "Designing Data-Intensive Applications",
          "chapter": 33,
          "title": "Segment 33 (pages 309-318)",
          "relevance_score": 0.44,
          "method": "api"
        }
      ]
    },
    {
      "number": 60,
      "title": "Segment 60 (pages 567-574)",
      "start_page": 567,
      "end_page": 574,
      "detection_method": "topic_boundary",
      "content": "6.1\n\nAudio Compression with\n\nOgg Vorbis\n\nJack Moffitt, Xiph.org Foundation\njack@xiph.org\n\nver since computers could produce sound, audio has been a part of games in\n\nsome form or another. Originally, beeps and bloops were all that were possible.\nMIDI was later used, as it contained a lot of information about the sound in a small\namount of space. Then, as sound cards became prevalent, MOD-type files became\nmore popular, offering a combination of sampled sounds with sequencing and limited\neffects. Once the CD-ROM became the standard media on which games shipped,\nRedbook audio (normal CD audio) started to become popular, and finally games\nused high-quality music.\n\nUnfortunately, as the music became better, music files also became larger. While\nCDs can easily hold an hour’s worth of great-quality audio, not much else will share\nthe same disc. ADPCM is one compression standard that has been used in commer-\ncial games to try and alleviate the size of music files while retaining the quality, but its\nsize savings are not fantastic. High-quality music is now a must for any game, and\nsince game developers are going to continue to push the envelope with respect to\naudio and music in games, music files will have to get smaller.\n\nEnter psychoacoustic compression.\n\nPsychoacoustic Compression\n\nPsychoacoustic compression works by eliminating all the parts of the sound that the\near can't hear or considers unimportant. Unlike some other forms of compression,\npsychoacoustic compressors are lossy. The original signal is irreversibly modified, even\nthough to most ears the sound remains the same.\n\nThe compression ratios for psychoacoustic compressors are generally between\n10:1 and 20:1. This is far better than the ratios offered by the other sound compres-\n\nsion alternatives.\n\nMow It Works\n\nThere are a few basic principles behind psychoacoustics. First, there is the absolute\nthreshold of hearing. This is represented by the graph in Figure 6.1.1.\n\n588 Section 6 Audio\n\nBH\n1 HTS ME EH\nTON\niS\naoe HHVHVUE ARID asS800) THAT TAU\nsui att Hine est GEL HIN\nBH TH GY Noe aC TB\nBNbanE avesee et TT\nae 2 HHH BREAEEY AUANUEY EERERGE GASHEHY THEEEAY Unvscee cofltit UHI\n\na6\n\nFIGURE 6.1.1 The absolute threshold of hearing. The x-axis represents frequency, the y-axis\nrepresents loudness.\n\nThe absolute threshold of hearing represents how loud a sound has to be at a cer-\ntain frequency range in order for the human ear to perceive it. Any sounds that are\nbelow the curve can't be heard. If you take away all the sounds that fall under the\ncurve from the original sound, the resulting sound should be perceived identically.\n\nAnother basic concept of psychoacoustics is masking, Just as bright background\nlight sources will mask foreground objects, loud sounds will mask quieter ones. A\nstrong tone will mask weaker tones at higher and lower frequencies. Even after a\nstrong tone is gone, it will still mask some sounds, due to temporal masking. Since a\nfair amount of the sound is masked, psychoacoustic encodets won't include them, and\nthe human ear is none the wiser.\n\nHow Do Sound-Compression Techniques Compare?\n\nNow that we have a basic understanding of how psychoacoustic compression works,\nlet's take a look at how it compares to the other forms of audio compression that\nmight be more familiar. Audio is normally transmitted as raw PCM samples. These\nare uncompressed, so each stereo 16-bit sample takes 4 bytes. For CD-quality audio,\nthere are 44,100 of these every second, or around 10 MB of audio a minute.\n\nTypical ways of reducing the bulk of audio data include downmixing and resam-\npling. Downmixing reduces the stereo channels into one channel, cutting the total\nsize by half. Resampling uses fewer samples per second to represent the sound. Usual\nresampling rates are 22,050 Hz and 11,025 Hz. Both of these methods result in\ngreatly reduced file sizes, but they come at the cost of quality and the loss of stereo.\n\n6.1 Audio Compression with Ogg Vorbis 589\n\nADPCM is a 4:1 compression format that encodes the differences between suc-\ncessive samples. It is sometimes used in games to shrink audio without the unaccept-\nable loss of quality that downmixing or resampling creates. ADPCM is also lossy,\nthough, and does degrade audio quality. It also only compresses audio to one quarter\nof the size, meaning that an hour’s worth of audio can still be almost 200 MB.\n\nThere are several lossless methods available as well. While these do not sacrifice\nany quality, their compression ratios are not very good. Typical lossless compressors\nget between 1.5:1 and 2:1 in the general case. Many of them can be quite slow, but\ntheir compression ratios alone make them unusable for most situations.\n\nWhy Ogg Vorbis\n\nPsychoacoustic compression seems to be the clear choice for music compression. High\ncompression ratios and almost no discernable quality loss makes it appealing, but che\nquestion still remains-—-which codec to use of the ones that are widely available?\n\nOgg Vorbis [Ogg Vorbis02] stands above the rest as the perfect fit for games and\nother applications. Its royalty-free licensing makes it a much cheaper alternative than\nthe rest of the codecs. Its open-source implementation gives developers the freedom\nto customize and tweak it if necessary. Also, its broad platform support ensures that\nthe same code will work on Windows, Macintosh (Classic and OS X), Linux, BeOS,\nand even console platforms.\n\nIn addition to these advantages, Ogg also has several unique features that make it\nspecifically appealing to game developers. It supports multiplexing the audio data\nwith other kinds of information. There are already implementations that intertwine\nMIDI with CD-quality audio for synchronized device control. It also supports multi-\nple channels, meaning that you can encode and play back in surround sound or even\nsomething more ambitious.\n\nFor example, using Ogg, a game developer could add synchronized mouth move-\n\n_ Ments to compressed vocals, to give a much more-realistic sense of talking or singing.\nWith other formats, this is more difficult and not directly supported.\n\nIf game developers want to keep advancing the current state of the art, the audio\nand sound will not only have to be compact, but also quite flexible. This is where a lot\nof the other codec options fall short, and this is where Ogg Vorbis shines,\n\nCompression Scenarios\n\nUsing Ogg Vorbis as the implementation choice, we can now cover how best to fit\ncompressed music into a game, considering several possibilities about speed require-\nments and the type of audio being used. Although Ogg Vorbis will be specifically dis-\ncussed, most of the ideas presented here should work with other codecs.\n\nThere are several things to consider when using a codec with a game. Most games\nhave tight speed requirements, so the amount of processor time necessary to decode\naudio is an important factor. Desktop computers can generally decode psychoacoustically\n\n590\n\n/\n\ncompressed audio in about 2% to 5% of the total processor time on Pentium III-class\nmachines.\n\nAlso, the type of sound being decoded is important as well. For instance, back-\nground music generally only consists of one stereo track and switches between differ-\nent tracks. More-compiex music might layer tracks together, requiring the decoding\nof several files at once. Sound effects are generally short sounds and are keyed to\nevents. The latency between the time the event happens and the sound is played is\nvery important. Many sound effects might be playing simultaneously.\n\nWith these situations in mind, let’s outline some ways that compressed audio can\nbe effectively integrated into games.\n\nSection 6 Audio\n\nScenario 1; Decoding On-the-Fly\n\nThe most common method of using Ogg in a game would be to decode audio on-the-\nfly. This uses a lictle CPU time, but it allows the files to remain on a mass storage\ndevice, such as a hard drive.\n\nIn this scenario, an audio stream has been completely encoded in Ogg format and\nis decoded and played in real-time while the game is running. There is no need to\nmake the user wait for entire files to be decompressed before playback, and there's no\nlarge, uncompressed audio files sitting around on the player’s hard drive. In addition,\nallowing the player to add his or her own music to a game is simple with this method\nof integration.\n\nScenario 2: Decoding to Cache\n\nIn some situations, decoding to cache is a better fit. If there are many pieces of audio\nto be played at once, decoding all of them in real-time might not be possible or might\nuse up too much of the processor time. In this case, decoding the files to a cache on\nlevel changes or on startup might be the right solution. This allows a game imple-\nmentation to keep all audio data compressed that is not needed to be immediately\navailable by gameplay.\n\nThis is also a nice way to produce sound effects, The game could decode them\non-the-fly the first time they were used, and play the already decoded audio on subse-\nquent requests. If latency is a problem with decoding, the sound effects could be\ndecoded on level changes or at startup, as previously described, and then played back\nwith no decoding latency ar all.\n\nScenario 3: Compressed Transport\n\nIn cases where none of the previous scenarios make sense, compression can still be\nused for end-to-end transport. The game distribution CD-ROM and/or download-\nable packages can use Ogg to make the download smaller and leave more room for\ngraphics and code. When the game or demo is installed, all of the music can be\ndecompressed to the hard drive. This scenario would also apply well to game patches\nor additional packages to go along with the game.\n\n6.1 Audio Compression with Ogg Vorbis 591\n\nCode Examples Using Ogg\n\nA few code examples will illustrate how easy it is to use Ogg Vorbis. To use the vorb-\nisfile library, the code will need to include the API headers:\n\n#include <vorbis/vorbisfile.h>\n\nand link against the vorbisfile, verbis, and ogg libraries. Under Windows, these can be\nstatically linked or dynamically linked, depending on personal preference (see the\nSDK files and API reference on the CD-ROM for details).\n\nUncompressing Files to Momory\n\nUncompressing files to memory is easy with the vorbisfile API. First, we declare the\nOggVorbis_File variable:\n\nOggVorbis File vf;\n\nThen, we must open the Ogg Vorbis file with an already open FILE*. Note that you\nmust open a file in binary mode for vorbisfile. On some platforms, binary files are\ndefault for calls like fopen(), but on Windows, this is not the case, and you must\nspecify binary mode explicitly.\n\nint err;\nerr = ov_open({fp, &vf, NULL, 0);\n\nThe fp is our FILE* to an already open file. The vf is the OggVorbis_File struct,\nand the other two parameters are typically set to NULL and zero, as in our example. (If\nyoure curious as to what these mean and when you should use them, please consult\nthe API reference.)\n\nThe ov_open will return zero on success or less than zero on failure. On failure,\nthe return value will map to one of the standard error codes of the API (which you can\nfind explained in the API reference).\n\nNow that the Ogg file has been opened by the vorbisfile library, the library owns\nthe file. It will close the file when it’s done, and you should no longer use that file\npointer in external file operations. Once the file is opened, the file info must be read:\n\nvorbis_info *vi;\nVi = ov_info(avf, -1);\n\nThe vorbis_info struct will contain information about the opened Ogg file, such\nas its sampling rate, the nominal bit rate, and its number of channels. The second\nparameter specifies which logical bitstream to return information for (-1 means the\ncurrent logical bitstream). Optionally, you can read the comments from the file with\nthe ov_comment() function.\n\nBefore we can decompress the Ogg to memory, we must first allocate some space\nfor it. To find out the total space required, we must call ov_pem_total() to find the\n\ntotal number of PEM samples, and multiply this by the number of channels and che\nnumber of bytes per sample (usually 2 bytes for 16-bit audio).\n\nint $ize;\nchar *buffer;\n\nsize = vi->channels * 2 * ov_pem_total(avf, -+);\nbuffer = (char *)malloc(size);\n\nNow that we have a buffer allocated for the entire decoded output, ov_read() is\ncalled in a loop to retrieve PCM samples into the buffer.\n\nint eof = 0;\nchar *buf = buffer;\nint current_section;\n\nwhile (!eof) {\nlong ret = ov_read(&vf, buf, 1024, 0, 2, 1,\n&current_section} ;\n\nif (ret == 0) {\n/* 0 return value means end of file */\neof = 1;\n\n} else if (ret < 0) {\n/* <0 return value indicates an error */\n\n} else {\n/* advance the buffer pointer on success */\nbuf += ret;\n\n}\n\n}\n\nThe code is fairly simple. It doesn’t do any error checking (although when work-\ning with Ogg, most errors are normally benign and can be ignored) or overflow\nchecking, but all the hard work is done for you in the vorbisfile library.\n\nOnce a file is finished, you must cleanup with ov_clear():\n\nov_clear(avf);\n\nDecoding in Real-Time\n\nDecoding in real-time is very similar to the previous situation of decoding to a mem-\nory buffer, except that instead of decoding all at once, real-time decoding takes place\na piece at a time. After reading each block from ov_read{), the code then sends it to\nthe next stage of the pipeline. In the most common case, this is an audio output\ndevice.\n\nFor the sake of simplicity, system specifics of audio output won't be covered here.\nInstead, the code assumes that there is an audio_output() function that takes a buffer\nof samples and a size, and does the right thing.\n\nUsing the previous example as a base, the only thing that needs to be modified is\nthe decode loop. Ac the top of the loop, there is still the call to ov_read{):\n\n6.1 Audio Compression with Ogg Vorbis 593\n\nchar pcmout[4096] ;\n\nwhile (leof) {\nlong ret = ov_read{&vf, pemout, sizeof (pemout),\n0, 2, 1, &current_section);\ni* a a]\n}\n\nNotice that the buffer is now a fixed size, since the code only processes output in\nsmall blocks.\n\nIn the success clause of the previous example’s if blocks, we advanced a buffer\npointer. Since we only process a block at a time for real-time decode, we just need to\nsend the current block to the audio_out:\n\naudio_out(pcmout, ret};\n\nOn success, ret will be the number of bytes placed into the buffer.\n\nEncoding\n\nThe last part to a fairly comprehensive understanding of using psychoacoustic com-\npression in your game is encoding and production. There are several knobs to tweak\nwhen making compressed Ogg files, and understanding these will lead to better-\nsounding music and sound effects in your game.\n\nQuality and size are integrally related in Ogg, and both are controlled by a single\nknob. In most codecs, you adjust the ‘size’ knob, which implicitly changes the quality.\nIn Ogg, you adjust the ‘quality’ knob, which implicitly changes the size. In general,\nthe bigger you're willing to make the file, the better it will sound; and conversely, the\nless quality you need, the smaller the file can be. There are some practical limits to this\nrelationship, though.\n\nThe size of compressed audio is measured by bit rate: the amount of bits used to\nstore one second of audio. The average gamer is not going to be able to hear subtle\nquality loss, so pushing the bic rate past a certain point will have diminishing returns.\nOgg files should sound quite good at 64 kbps (kilobits per second) and should hardly\nbe discernable from the original, which is around 128 kbps.\n\nSince, with most games, the music is not the primary focus of the gamer’s atten-\ntion; lower-bit-rate Ogg files should be more than enough to give gamers an excellent-\nquality experience.\n\nTwo other knobs are the number of channels and the sample rate of the audio.\nWhile these affect quality (e.g., mono sound is not as good as stereo), the rate of qual-\nity change to size change is not linear. If you halve the size by going from stereo sound\nto mono sound, the quality is only slightly diminished in most cases. Similarly, if you\nhalve the sample rate, the audio sounds worse, but possibly not much worse. If space\nis at a premium, you can downmix and resample before compressing with Ogg. This\n\nleads to smaller files with an acceptable loss of audio quality.\n\n594 Section 6 Audio\n\nConclusion\n\nAs game audio grows in importance, it seems obvious that better forms of compres-\nsion must be utilized to reduce audio’s bulk. Since many games are developed on a\ntight financial budget, an open and royalty-free solution is the natural choice. So, on\n\nyour next project, consider psychoacoustic compression with Ogg Vorbis.\n\nReferences\n\n[Oge Vorbis02] Ogg Vorbis, available online at http://www.vorbis.com, June 2001.\n\n{XiphHome02] Xiphophorus, http://www.xiph.org, June 2001.\n\n[XiphName02] Xiphophorus names and logos, available online at http://www.xiph\n.org/xiphname.html, June 2001.",
      "page_number": 567,
      "chapter_number": 60,
      "summary": "The x-axis represents frequency, the y-axis\nrepresents loudness Key topics include audio, files, and sound.",
      "keywords": [
        "Vorbis Jack Moffitt",
        "Ogg Vorbis Jack",
        "Ogg Vorbis",
        "Audio",
        "Ogg",
        "Xiph.org Foundation",
        "Jack Moffitt",
        "Ogg Vorbis file",
        "Audio Compression",
        "file",
        "Ogg files",
        "sound",
        "Compression",
        "Ogg Vorbis Psychoacoustic",
        "Vorbis"
      ],
      "concepts": [
        "audio",
        "files",
        "sound",
        "compression",
        "compresses",
        "compressed",
        "quality",
        "games",
        "decode",
        "decoded"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 8",
          "chapter": 51,
          "title": "Segment 51 (pages 490-498)",
          "relevance_score": 0.49,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 52,
          "title": "Segment 52 (pages 499-510)",
          "relevance_score": 0.49,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 50,
          "title": "Segment 50 (pages 481-489)",
          "relevance_score": 0.46,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 2",
          "chapter": 55,
          "title": "Segment 55 (pages 536-543)",
          "relevance_score": 0.43,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 7",
          "chapter": 38,
          "title": "Segment 38 (pages 353-360)",
          "relevance_score": 0.43,
          "method": "api"
        }
      ]
    },
    {
      "number": 61,
      "title": "Segment 61 (pages 575-584)",
      "start_page": 575,
      "end_page": 584,
      "detection_method": "topic_boundary",
      "content": "Creating a Compelling 3D\nAudio Environment\n\nGarin Hiebert, Creative Labs, inc.\ngarinh@hibyte.com\n\nhis gem will provide you with techniques for creating compelling 3D audio in\n\nyour games by applying a few simple rules to your audio engine design and the\nsamples used. We will introduce some basic concepts of 3D audio rendering, provide\ntips on how to maximize the effectiveness of your audio engine, and offer examples of\nhow to apply these tips. DirectSound 3D and OpenAL are used as examples of promi-\nnent 3D audio APIs, but the concepts should be transferable if you are using another\nAPI. Complete sample code is included on the CD-ROM.\n\n3D Audio Core Concepts\n\nMany modern games are designed to take place in a 3D world, even in genres that\nin the past would have used two-dimensional representations of their world. The\nfundamental idea of a 3D audio engine is to provide a way to use the same three-\ndimensional world representation for all aspects of the game, with the same data\nbeing used for audio and video components. The following subjects are fundamental\nto 3D positional audio rendering and are critical to your audio engine design.\n\nSingle Listener\n\nThere is a single ‘listener’ object representing where the sound is heard in the 3D\nenvironment. The listener has a position and orientation in the game-world space,\n\nwhich is used to calculate the appropriate speaker output.\n\nMultiple Sources\n\nEach sound-producing object in the environment is represented by a source. All the\nsources are mixed and represented at the listener’s position, and each corresponds to a\nvoice on the sound card.\n\nMultiple Buffers\n\nA buffer object contains the actual audio data. In DirectSound 3D, a buffer and a\nsource are combined into one object. In OpenAL, the audio data is separated from\n\n596 Section6 Audio\n\nthe sources, in which case there ate commonly more buffers allocated than there are\nsources.\n\nVoice Management\n\nThere must be a scheme implemented to allocate the audio data (in buffers) among\nthe available voices on the sound card. The game often needs to play more sounds\nconcurrently than the system can play. Voice management solves this problem by\ninvoking a method, based on distance and/or priority, to decide which sounds will be\nplayed at any given time. In DirectSound 3D, a buffer and a source are the same\nthing, and a voice-management scheme is used internally to determine which buffers\nate audible using the current hardware. In OpenAL, a source object directly corte-\nsponds with a voice on the audio hardware, and there can be a much latger number of\nbuffers that can be played on the limited number of sources. Voice allocation in this\ncase is done by any scheme the programmer decides to use.\n\nDetermination of Speaker Output\n\nThe end user might have any of a variety of speaker output configurations, any of\nwhich should convincingly portray the 3D audio world. To do this, the audio-render-\ning system (e.g., DirectSound, OpenAL) must minimally figure out what the panning\nand attenuation characteristics are for each source at the listener's position. The rela-\ntive positions and orientations of the listener, and each source can be used to figure\nout the panning of the speakers. The distance between each source and the listener\ndetermines the attenuation of each source, and the resulting audio is then mixed and\nplayed. For an even more compelling audio experience, reverberation and filtering can\nalso be applied (either globally or on a per-source basis) before the final mix.\n\nUsing Your Audio Engine Effectively\n\nThe following tips {in order of their application to the audio-processing chain) will\nhelp you maximize the quality of a 3D audio engine.\n\nTip #1: Use Normalized Samples\n\nBefore importing a sample into your engine, make sure it is taking full advantage of\nthe amplitude range of your sample bit depth by normalizing it. Otherwise, you\nmight find that a particular sample is always too soft, and then you might have to\nadjust the levels of everything else. This hassle is avoided by normalizing the sample\nto begin with.\n\nTip #2: Use ‘Dry’ Samples\n\nIf you intend to apply effects to your audio, make sure there are no effects applied to\nthe original sample. (Samples without effects are called “dry.”) Applying reverberation\n\n6.2 Creating a Compoliing 3D Audio Environment 507\n\nor filtering at an early stage makes it impossible to recover from the effect during run-\ntime processing.\n\nTip #3: Deckie on Your Units\n\nMake sure you know what units are used in the design of the game world. It is critical\nto provide the correct information to the low-level API so that it can render the audio\nproperly, This means that the audio API needs to understand the physical parameters\nof the game world. If the audio world units are in meters, but the game world is in\nfeet, then certain audio effects (e.g., Doppler effects or air absorption) might not\nwork as intended, forcing you to recalibrate the effects for another set of units. Using\nconsistent units throughout the engine will allow the API to work the way it was\ndesigned.\n\nTip #4: Understand and Use the Capabilities of the\nLow-Level API\n\nDecide on a low-level API and plan to take advantage of its features. In addition to\n3D position, the low-level API {e.g., DirectSound 3D, OpenAL) will have global and\nper-source properties, such as roil-off factor or per-source gain. Plan on providing this\ndata to the low-level API. For example, if you followed Tip #1 and normalized your\naudio, then you will need to set per-source reference distance appropriately. Both\nOpenAL and DirectSound 3D have a notion of directional audio as well—an under-\nutilized feature of both APIs.\n\nTables 6.2.1 and 6.2.2 show a few of the global and per-source properties that can\nbe applied using OpenAL or DirectSound 3D.\n\nTable 6.2.1 Examples of Gichal Properties In OpenAL and DirectSound 3D\n\nDescription OpenAL Property DirectSound 3D Property\n\nMaster gain AL_GAIN Master Volume, set using mixer AP]\nSpeed of sound AL_ DOPPLER VELOCITY DistanceFactor, applied to listener\nDoppler effect AL_DOPPLER_FACTOR DopplerFactor, applied to listener\n\nTable 6.2.2 Examples of Per-Source Properties in OpenAL and DirectSound 3D\n\nDescription OpenAL Property DirectSound 3D Property\nPitch multiplier AL_PITCH Frequency\n\nGain AL_GAIN Volume\n\nPosition AL_POSITION Position\n\nVelocity AL_VELOCITY Velocity\n\nDirection AL_DIRECTION ConeOrientation\n\nHead relative/Absolute modes AL_SOURCE_RELATIVE Mode\n\nReference distance AL_REFERENCE_DISTANCE MinDistance\n\n598 fo Section6 Audio\n\nTip #5: Add Effects\n\nProcess the audio to accommodate the game environment. Using an API such as\nEAX, occlusion, obstruction, reverberation panning, and other effects can be added\nto enhance the player's experience. A fallback scheme for lack of hardware-accelerated\neffects does not need to be limited to dry audio, either—filtering and additional\nattenuation can be applied. For example, in a first-person shooter, intervening walls\nshould muffle sounds. Applying occlusion via EAX or using a low-pass filter function\nwith additional attenuation can make this situation sound much more realistic and at\nthe same time provide the player with information about the environment.\n\nA demo program is provided on the CD-ROM with an audio engine incorporating\nthe above tips. The demo program is simple in many regards, but ir stil] illustrates\ntypical audio engine flow with four high-level events:\n\n1} Loading Audio Data\n\nAll the audio data is loaded once when the program starts. In most games, the audio\ndata is loaded for each level as part of the loading of that level’s other data (e.g., geom-\netry, textures, etc.). But in general, the loading of audio data is an infrequent event.\nTips #1 and #2 apply to this event. The audio data should be normalized and dry.\n\n2) Apply Global Parameters\n\nThe global parameters are all applied only once, and after the audio data is loaded. A\ngame might not be able to get away with only a single setting of the global parameters,\nbut this will normally be a very infrequent event compared to other audio events. For\nexample, the physical parameters of the game world, such as the Doppler factor and\nmaster volume, shouldn’t require constant adjusting.\n\nTips #3 and #4 apply to this event. The setting of any parameter should use the\ncorrect units, and the selection of parameters should make use of the APT's capabilities.\n\n3) Adjust Per-Source Parameters\n\nPer-source parameters are set once for every frame of graphics displayed, which is sim-\nilar to how most games will operate. Some games set the audio parameters less fre-\nquently than the video updates occur, but this event is still part of the main loop of\nthe program.\n\nTips #3 and #4 apply to this event. The setting of any parameter should use the\ncorrect units, and the selection of parameters should make use of the API's capabilities.\n\n6.2 Creating a Compeiling 3D Audio Environment 599\n\n4} Adjust Effects Parameters\n\nBoth global and per-source effects are being used in the demo program. If EAX capa-\nbility is detected, the global EAX preset can be changed while the demo runs. In addi-\ntion, the demo program is also constantly looking for the opportunity to apply\nper-source EAX effects. Any game will need to apply both global and per-source\neffects, depending on the effects available. This event is part of the main loop of the\nprogram and takes place concurrently with the per-source parameter changes.\n\nTips #3 and #5 apply to this event. Some effects rely on the physical properties of\nthe game world being set correctly, and an appropriate level of effects should be used\nwhen available.\n\nConclusion\n\nCreating a compelling 3D audio environment for your game is a difficult job with\nmany subtleties. Using the five tips in this gem, the job will be less stressful, take less\ntime, and provide your players more compelling audio.\n\n[Creative02] Creative Technology, Ltd., “Creative Labs—Developer Central,” avail-\nable online at http://developer.creative.com, March 2002. The “Games” section\nhas information on EAX as well as OpenAL, including documentation and\nSDKs.\n\n[Loki01] Loki Entertainment Software, “OpenAL | Open Source Audio Library,”\navailable online at http://www.openal.org, March 2002. The OpenAL source -\ncode and a mailing list are hosted.\n\n6.3\n\nObstruction Using Axis-\nAligned Bounding Boxes\n\nCarlo Vogelsang, Creative Labs inc.\ncvogelsang@creativelabs.com\n\nhis gem will describe how axis-aligned bounding boxes can be used to simplify\n\nthe calculations for proper sound obstruction caused by arbitrary objects in your\ngame. It will demonstrate actual techniques used by EAGLE™ and EAX-Manager,\ndeveloped. by Keith Charley at Creative Labs. The result is a good audio experience\nwith low calculation cost and enough flexibility for general usability.\n\nThe Problem\n\nWhen sound is heard indirectly, this means that the sound waves cannot travel\ndirectly from source to listener. We call this obstruction [Jot99] since the direct path is\nbeing obstructed, Figure 6.3.1 shows the unobstructed and obstructed sound source.\n\nWe want to obtain a value that represents the amount of this obstruction. It turns\nout that sounds waves with a bigger wavelength (or lower frequency) diffract around\nsolid objects berrer than sound waves with a smaller wavelength (or higher fre-\nquency). So once we have obtained a value that represents the amount of obstruction,\nwe can use that value to determine the gain of a low-pass filter applied to our sound\nsource [I3DL2]. This filter is used to simulate the attenuation of higher frequency\nsounds diffracting around solid objects.\n\nSource Source\n5\n\nListener\n\nFIGURE 6.3.1 An unobstructed (left) versus obstructed (right) sound source.\n\n6.3 Obstruction Using Axis-Aligned Bounding Boxes 601\n\nIn the following section, an algorithm is explained that determines a value from 0\n(silent, the sound is completely obstructed) to 1 (full level, the sound is completely\nunobstructed).\n\nThe Solution\n\nThe solution proposed in this gem involves finding an approximation for the path\nthat sound must take to ‘bend’ around the corner of an obstruction. The corner we\nchoose to evaluate is the edge closest to the sound source. To calculate this bend, we\nbuild an angle, o, from the vectors that go from source to corner to listener. When\nthis angle is at a maximum (180°), there is no obstruction. The smaller the angle cal-\nculated, the more the sound is being obstructed [Kutt00}. You can see in Figure 6.3.2\nthat this results in a vector that intersects the obstruction object. An accurate path\naround the obstruction would not intersect, but we are trading accuracy for speed.\n\nTo speed up the process even further, we can use axis-aligned bounding boxes\n(AABB). A small error is still introduced, but the computational time is drastically\nreduced. You can see the error introduced by comparing Figure 6.3.2 and Figure\n6.3.3. Any object chat is not cubical and axis-aligned will accrue some error in &. Fig-\nure 6.3.3 shows the resulting & when using AABBs.\n\nTo calculate this angle given our source position, listener position, and obstruc-\ntion bounding box, we start by computing two bit vectors, one for the source and one\n\nListener\n\nFIGURE 6.3.2 Biggest angle/shortest path algorithm.\n\nSection6 Audio\n\nSource\n\nBounding box\n\nListener\n\nFIGURE 6.3.3 Obstruction covered by axis-aligned bounding box.\n\nfor the listener. Six bits are used to represent each of the six planes of the 3D bound-\ning box. A set bit indicates that the source or listener is in front of that plane; this code\nexample computes the listener bits corresponding to the front and back (xy-) plane:\n\nif (ListenerPosition.Z < BoundingBox.vMin.Z)\nlListenerFlags |= 0x02;\n\nelse if (ListenerPosition.Z > BoundingBox.vMax.Z)\nlListenerFlags |= 0x01;\n\nUsing these two bit vectors, we can quickly determine if an obstruction is possi-\nble. If both bit fields share any true bits, then there cannot be an obstruction, because\nthe source and the listener are in front of the same plane. The check can be performed.\nby:\n\nif {lListenerFlags & 1SourceFlags}\ncontinue;\n\nIf we have determined that an obstruction is possible, we create a list of the bound-\ning-box planes closest to the source. This is accomplished by using the bit vector to\ndetermine the zone that the source is in (26 possible zones outside of the bounding box\nand 38 zones inside of the bounding box, adding up to a total of 2° = 64 zones). One of\n\n6.3 Obstruction Using Axis-Aillgned Bounding Boxes 603\n\nthe valid 26 outside cases is shown in the switch statement code presented here. The 38\ninside cases are invalid and are handled by the default case statement.\n\nswitch (1SourceFlags & Ox3f)}\n\n{\n\ncase 0x01:// Behind bounding box\nvPlanePoint[0O] = BoundingBox. vMax\nvPlaneNormal[0] = {0, 6, 1};\n1PlaneType = BACK;\n1NumPlanes = 1;\nbreak;\n\ndefault: /7/ Invalid combination (inside)\n1NumPianes = 0G;\nbreak;\n\n}\n\nAfter this switch statement, we may have up to three bounding box planes speci-\nfied. For each plane, we check to see if it intersects the source/listener vector. If an\nintersection is found, we compute the intersection point:\n\nfor (i = 0; i < LNumPlanes; itt)\n\n{\nSVector svIntersection;\nFindPlaneIntersectionPoint{..,&svIntersection) ;\nif (PointInPlane(svIntersection, ..})}\n{\n}\n\n}\n\nNow that we know there is an intersection somewhere on the bounding box’s\nhull, we need to find and move the intersection point to the closest edge. The follow-\ning code block performs this.\n\nswitch (1PlaneType)\n{\ncase FRONT:\ncase BACK:\nif (Listener->fY < Box.vMin->fY¥ &&\nListener->fY¥ > Box.vMax->fY)\n\n{\nfMidPoint = Box.vMin->fX — Box. vMax->fX;\nfMidPoint /= 2;\nfMidPoint += Box. vMax->fX;\nif (svIntersection.fX < fMidPoint }\nsvintersection.fX = Box. vMax->fX;\nelse\nsvIntersection.fX = Box, vMin->fX;\n}\nelse\n\n604 Section6 Audio\n\nfMidPoint = Box.vMin->TY — Box.vMax->TY;\nfMidPoint /= 2;\nfMidPoint += Box. vMax->TY;\nif (svIntersection.fY < fMidPoint }\nsvIntersection.fY = Box.vMax->TfY;\nelse\nsvintersection.f¥ = 80x.vMin->fY;\n\n}\n\nbreak;\ndefault:\n\nbreak;\n}\n\nWith the intersection point now on an edge of the bounding box, we can com-\npute the angle, a&, between the intersection point-to-source vector and the intersec-\ntion point-to-listener vector.\n\nlong lLevel = MAX_OBSTRUCTION;\n\nCVector cvListener(*psvListener) ;\ncvListener -= sviIntersection;\n\nCVector cvSource(*psvSource) ;\n¢vSource -= svIntersection;\n\ncvSource.Normalize();\ncvListener .Normalize();\n\nfloat fAngle = cvListaner.DotProduct (cvSource) ;\nif ( fAngle >= 0 )\nreturn ILeval;\n\nfAngle += 1;\n\nfloat fMaxAngle = {float}m_10ifAngle;\nfMaxAngle /= 90.0f;\n\nif ( fAngle >= fMaxAngle }\nraturn lLevel;\n\nHevel = (long) (((float)lLevel * fAngle) / fMaxAngle);\n\nNow that we know o: and, thus, the amount of obstruction imposed by the edge,\nwe will take the biggest value (meaning the /east amount of obstruction) found. Note\nthat this algorithm will only consider the closest edge to the source; if the bounding\nbox is fairly thin (¢.g., walls, crates, etc.), this will work fine. For larger bounding\n\nboxes, the influence of the edge closest to the listener can cause greater inaccuracies.",
      "page_number": 575,
      "chapter_number": 61,
      "summary": "We will introduce some basic concepts of 3D audio rendering, provide\ntips on how to maximize the effectiveness of your audio engine, and offer examples of\nhow to apply these tips Key topics include audio, sources, and obstruction.",
      "keywords": [
        "Audio",
        "audio data",
        "audio engine",
        "source",
        "bounding box",
        "Listener",
        "Audio Source Bounding",
        "obstruction",
        "Audio Environment Garin",
        "Audio Environment",
        "Bounding",
        "box",
        "sound",
        "effects",
        "sound source"
      ],
      "concepts": [
        "audio",
        "sources",
        "obstruction",
        "obstructed",
        "sound",
        "tips",
        "tip",
        "effectiveness",
        "object",
        "boxes"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 7",
          "chapter": 39,
          "title": "Segment 39 (pages 361-371)",
          "relevance_score": 0.56,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 7",
          "chapter": 38,
          "title": "Segment 38 (pages 353-360)",
          "relevance_score": 0.55,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 50,
          "title": "Segment 50 (pages 481-489)",
          "relevance_score": 0.54,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 51,
          "title": "Segment 51 (pages 490-498)",
          "relevance_score": 0.54,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 2",
          "chapter": 50,
          "title": "Segment 50 (pages 490-497)",
          "relevance_score": 0.53,
          "method": "api"
        }
      ]
    },
    {
      "number": 62,
      "title": "Segment 62 (pages 585-592)",
      "start_page": 585,
      "end_page": 592,
      "detection_method": "topic_boundary",
      "content": "6.3 Obstruction Using Axis-Aligned Bounding Boxes 606\n\nimplementation\n\nA sample implementation that handles all the calculations needed for a single bound-\nZe ing box is on the CD-ROM. This is actual code from EAXMan, by Keith Charley at\nome Creative Labs, Inc.\n\nrhe\n\nConclusion\n\nIn this gem, we have shown how to simplify the obstruction calculations by using\naxis-aligned bounding boxes, This dramatically reduces the amount of computations\nrequired, yet the overall result is very convincing and adds an important audio cue to\ngive players a definite advantage.\n\nReferences\n\n[I3DL2] LASIG, “Interactive 3D Audio Rendering Guidelines Level 2.0,” available\nonline at hetp://www.iasig.org, Los es, CA, 1999.\n\n[Jor99] Jot, J. M., “EAX 4.0 Specification,” Creative Labs, Inc., Milpitas, CA, 2001.\n\n[Kutt00] Kurtruff, H., Room Acoustics, Fourth Edition, Spon Press, London, U.K.\n2000.\n\n6.4\n\nUsing the Biquad\nResonant Filter\n\nPhil Burk, SoftSynth.com\nphilburk@softsynth.com\n\nhis gem will discuss the biquad infinite impulse response (IIR) filter, which is a\n\nmultipurpose resonant filter. By changing the filter coefficients, it can perform\nvarious filter-pass operations, such as low pass, band pass, high pass, band stop, and\nothers. We will describe how digital filters work, how to implement an efficient\nbiquad filter, and how to calculate coefficients for various functions. Several examples\nof the sound-filtering techniques and synthesis tricks will be provided.\n\nYou can use a filter to change the character of a sound. Sounds can be thought of\nas being composed of sine waves at various frequencies. Filters change the amplitude\nof those sine waves, depending on their frequency. You can emphasize the high fre-\nquencies or the low frequencies to make something sound brighter or have more\nboom.\n\nThis is particularly handy when playing samples because they tend to always\nsound the same. However, if you pass a sample through a filter while changing para-\nmeters, you can vary the sound every time the sample is played. You can dynamically\nchange these filter parameters to track the state of the game. Changing a sound to\nappropriately match the current game state will make your game more realistic.\n(Examples of using a biquad filter to create complex sound effects are also given in\nGem 6.6, The Stochastic Synthesis of Complex Sounds, by Phil Burk.)\n\nHow Digital Filters Work\n\nWhen you add sine waves of the same frequency together, they can cancel each other\nout or reinforce each other, depending on their relative phase. Delaying a complex\nsignal by a fixed amount, say one sample period, will change the phase of all its fre-\nquency components by differing amounts. A one-sample period delay might cause a\nvery small phase change for a low frequency because it has a long period, while\na higher frequency sound will have a greater phase change because the time delay is a\nlarger fraction of the waveforms period. This gives us a mechanism by which we can\naffect different frequencies in different ways.\n\n6.4 Using the Biquad Resonant Filter 607\n\nA typical digital filter contains a delay line made up of successive, one-sample\ndelays, or saps. The original input signal is called x,. So the taps are labeled x,.;, x2\nand so on. The taps are scaled and added or subtracted to cause cancellation or rein-\nforcement of various frequencies.\n\nAn averaging filter, for example, produces an output, y,, that is an average of the\ncurrent input sample and the previous input sample. The equation for a simple low-\npass filter is:\n\nIn = 0.5 * (Ky + X__ 1) (6.4.1)\n\nBecause low frequencies are not phase-shifted very much by this one-sample\ndelay, they remain relatively unaffected by this filter. However, high frequencies are\nshifted significantly in phase and can undergo cancellation. In fact, the higher the fre-\nquency, the greater the cancellation. Because this filter passes low frequencies more\nthan high frequencies, we call this simple averaging filter a /ow-pass filter.\n\nA high-pass filter can be constructed by changing the plus (+) sign in the equa-\ntion for the low-pass filter to a minus (—) sign. Then, low frequencies that are not\nshifted very much in phase cance! themselves out. The simple high-pass filter equa-\n\ntion is:\n\nIn = 9.5 * (x, 7 X_—1)- (6.4.2)\n\nliR Versus FIR Filters\n\nFinite impulse response (FIR) filters only process the incoming sound. So, when the\ninput goes to zero, the output goes to zero within a few samples, depending on how\nmany taps there are,\n\nInfinite impulse response (IIR) filters use delayed versions of both the incoming\nsound, and the resulting output. This feedback allows the filter to wiggle forever, even\nwhen the input goes to zero. The characteristic ringing filters of electronic music are\nIIR filters.\n\nThe Biquad Filter Implementation\n\nThe biquad filter has three taps on the input side and two on the output side\n[Dodge97, p. 214]. The equation for this filter is:\n\nIn = Ay” Xq_t Oy\" Xq_ 4 + Oy * x, 2 - by* yn, 1 - 82* Jn—2. (6.4.3)\n\nBy changing the coefficients, a, 2), 42, 6, and &, you can make the filter behave\nas a low-pass, high-pass, band-pass, band stop, peaking EQ, or other type of filter.\n\nThere are several things we can do to optimize the filter. The most optimal place\n\nfor the filter operation is in a loop. Most compilers will load the values into the regis-\nters once and then perform the loop calculations without having to reload them. The\n\n608 Section6 Audio\n\nfollowing listing is an implementation of the biquad excerpted from the file\nUnit_BiquadFilter.cpp available on the CD-ROM.\n\nfor( i=0; i<GGSYNTH_FRAMES_PER_BLOCK; i++)\n{\n{/ Generate outputs by filtering inputs.\nxn = inputs[i];\nyn (aO * xn) + (at * xnt) + (a2 * xn2)\n- (b1 * ynt} - (b2 * yn2);\noutputs[i] = yn;\n\n// Delay input and output values.\n\nxn2 = xn1;\nxni = xn;\nyn2 = yni;\nyni = yn;\n\n}\n\nPermuting the Variables\n\nAnother optimization to the biquad filter is to reduce the data movement associated\nwith the delay lines by permuting the algorithm. First, we modify the loop so that we\nperform two filters per loop. Instead of moving data, we can just leave the data in\nplace and change the equation to use the right values. The following code is a per-\nmuted version of the previous code. To make this clearer, look at the second IIR equa-\ntion in the following code, where we multiply (a2 * xn1). We would normally have\nset xn2=xn1 to implement the delay line, and then done (a2 * xn2). However, we can\ntake a shortcut and just multiply (a2 * xn1), and get the same result. Some optimiz-\ning compilers will do this trick by themselves, but it doesn’t hurt to give the compiler\na hint.\n\nfor( i=0; i<GGSYNTH_FRAMES PER_BLOCK; 1+=2)\n{\n// Generate outputs by filtering inputs.\nxn = inputs[i];\nyn2 = (a0 * xn) + (ai * xni) + {a2 * xn2)\n- (bt * yn1) - (b2 * yn2);\noutputs[i}] = yn2;\n\n// Permute filter operations to reduce data movement.\n// Just substitute variables instead of xn1=xn, etc.\nxn2 = inputs[i+1];\nyni {a0 * xn2} + (a1 * xn} + (a2 * xnt}\n- {bi * yn2) - (b2 * yni};\noutputs[iti] = yn1;\n\n// Only move a little data.\nxnt = xn2;\nxn2 = xn;\n\n6.4 Using the Biquad Resonant Filter 609\n\nAlso, many of the filter types have coefficients that are the same or zero; so, you\ncould eliminate one of the multiplications. If, for example, a0 equals a2, then the\nterm (a0 * xn2) + {a1 * xn) + (a2 * xn1) becomes (ad * xn2} + (a1 * xn) +\n(a0 * xnt), which can be shortened to (a0 * (xn2 + xn1)) + (at * xn).\n\nAvoiding Denormalization\n\nRecursive algorithms that operate on their previous output are subject to a vexing\nproblem. Imagine performing this calculation many times:\n\nx = 0,99 * x;\n\nThe value x will continue to get smaller and smaller, and will eventually become\ntoo small to represent as a valid floating-point number. This can happen in a game if\nyou leave it paused for a long time. When this happens, some FPUs will interrupt the\nCPU and ask for a fix, which could render a computer sluggish.\n\nLuckily, there is a simple solution. Just inject a little bit of energy into the filter to\nprevent it from decaying to such a small value. You can pulse it with a number so\nsmall that you will never hear the effect, but it is enough to prevent the interrupts.\nAfter you calculate a block of samples using the aforementioned loop, just add a very\nsmall number to one of the delayed values. The tiny spike will prevent the filter from\ndecaying too close to zero. The following is an example solution.\n\nyn += 1.0E-26; /* prevent denormalization */\n\nControlling the Filter\n\nThere are two parameters that control the behavior of the filter: the cutoff frequency\nand the resonance (Q). For a low-pass filter, frequencies above the cutoff frequency will\ngradually fall off. For a high-pass filter, frequencies below the cutoff frequency will\ngradually fall off. The resonance value (a) can be used to increase the amount of feed-\nback in the filter. This can cause frequencies near the cutoff to be emphasized. The fil-\nter can even be made to oscillate at a sufficiently high value of @. A Q value of 1.0 is\nconsidered normal resonance.\n\nCalculating Coefficients for the Filter\n\nThe coefficients that we are using for the various filter types are based on a cookbook\npublished by Robert Bristow-Johnston on the music-dsp mailing list [RBJ]. Note that\nthe A and B coefficient names are reversed relative to his document in order to be\nconsistent with many textbooks. Calculation of coefficients involves trigonometric\ncalculations, which are expensive and should only be performed when the input para-\nmeters change.\n\nDigital filters simply operate on a stream of numbers or samples. For a given set\nof coefficients and input samples, the output samples will be the same regardless of\n\n610\n\nSection6 Audio\n\nthe actual sample rate. So before calculating the filter, we convert the cutoff frequency\n(in hertz) to a radial velocity, omega, that is proportional to the sample rate. The sine\nand cosine of omega are used several times in the calculations, so we only calculate\nthem once (sin_omega and cos_omega).\n\nomega = (2.0 * PI * frequency) / samplefate;\n\nsin_omega = sin{ omega );\ncos_omega = cos{ omega );\n\nAll of the coefficients are scaled by a common factor. We fold thar factor into the\ncoefficients instead of doing an extra multiply.\n\nalpha = sin_omega / (2.0 * Q);\nscalar = 1.0 / (1.0 + alpha);\n\nLow-Pass Fliters\n\nLow-pass filters reduce the high frequency content of a sound and pass the low-\nfrequency content.\n\n{* Coefficients for LowPass Filters */\nAO = 0.5 * (1,0 — cos_omega) * scalar;\n\nAil = (1.0 -— cos_omega) * scalar;\nA2 = AO;\n\nBi = -2.0 * cos_omaga * scalar;\nB2 = (1.0 - alpha) * scalar;\n\nLow-pass filters, when combined with reverberation, can make a sound seem\nmore distant. They can be used to make a sound seem muffled when it is behind a\nwall or inside a box or tunnel. Ringing low-pass filters can be use to create unusual |\nalien vocal chirps or synthetic-sounding weapon noises. A whistling wind sound can\nbe produced by passing white noise through a filter and slowly, randomly varying the\ncutoff frequency and @.\n\nHigh-pass filters reduce the low frequency content of a sound and pass the high-\nfrequency content.\n\n/* Goefficients for HighPass Filters */\n\nAQ = 0.5 * (1.0 + cos_omega) * scalar;\nAl = -(1.0 + cos_omega} * scalar;\nA2 = AQ;\n\nB1 = -2.0 * cos_omega * scalar;\n\nB2 = {1.0 - alpha} * scalar;\n\nHigh-pass filters can be used to make a voice sound tinny, like it is on a telephone\nor radio. It can also be used to brighten a sound.\n\n6.4 Using the Biquad Resonant Filter 611\n\nBand-Pass Filters\n\nBand-pass filters reduce the frequencies on either side of a center frequency. We call it\na center frequency instead of a cutoff frequency because if you look at the frequency\nresponse curve of a band-pass filter, this frequency will be at the center of the peak.\n\n/* Coefficients for BandPass Filters */\nAO = alpha * scalar;\n\nAt = 0.0;\n\nA2 = -A0;\n\nBi = -2.0 * cos_omega * scalar;\nB2 = {1.0 - alpha) * scalar;\n\nCombining Filters in Serles\n\nYou can combine low-pass and high-pass filters in series by passing the output of one\nfilter to the input of another. Each filter will subtract from the previous filter. You can\nalso combine low-pass and high-pass filters to create custom band-pass filters with a\nbroad pass band.\n\nCombining Filters in Parailel\n\nSeveral filters can be placed in parallel by mixing or adding their outputs together.\nThis collection of filters is called a filter bank. An example is the set of band-pass fil-\nters in a graphical EQ that you might have on your stereo.\n\nCombining three or more band-pass filters can create formats that create vocal\nsounds. These may be useful for creating alien creature sounds.\n\nSoftware\n\nA keyboard-driven C++ program is provided on the CD-ROM thar enables you\nexperiment with all three of the filter types described in this gem. You can pass white\nnoise or an impulse train through the filters to hear how they sound, You can also\nchange the resonance of the filter. The filter frequency is slowly swept up and down\nusing a sine wave. Updates to this software will be posted on the Web at:\nhttp://www.softsynth.com/gamegems/.\n\nThe example program uses PortAudio, which is a simple, cross-platform audio\nAPI. The program should be abie to run on Win32, Macintosh, Unix with OSS, SGI,\nand other platforms. To check for updates to PortAudio for your platform, visit them\non the Web at: http://www.portaudio.com/,\n\nConclusion\n\nA biquad filter gives us a simple way to modify the character of a sound without using\na large amount of memory. It allows us to get more use out of a smaller number of\nsamples, or to generate interesting sounds without the use of any samples. This gem\n\n612 Section 6 Audio\n\nshows us how to implement a filter efficiently, and the example software shows us\nhow to filter sounds and play the result.\n\nReferences\n\n[Dodge97] Dodge, Jerse, Computer Music Synthesis, Composition and Performance,\nSimon & Schuster, 1997.\n\n[Moore90] Moore, F. Richard, Elements of Computer Music, Prentice Hall, 1990.\n\n[RBJ] Bristow-Johnson, Robert, “Cookbook Formulae for Audio EQ Biquad Filter\nCoefficients,” available online at http:// http://www.musicdsp.org/.",
      "page_number": 585,
      "chapter_number": 62,
      "summary": "We will describe how digital filters work, how to implement an efficient\nbiquad filter, and how to calculate coefficients for various functions Key topics include filter, filtering, and sound.",
      "keywords": [
        "Filter",
        "biquad filter",
        "Biquad Resonant Filter",
        "Resonant Filter",
        "sound",
        "frequency",
        "Biquad",
        "High-pass filters",
        "Band-Pass Filters",
        "Low-pass filters",
        "coefficients",
        "omega",
        "digital filters",
        "frequencies",
        "Biquad Filter Implementation"
      ],
      "concepts": [
        "filter",
        "filtering",
        "sound",
        "frequencies",
        "frequency",
        "audio",
        "passes",
        "passing",
        "delaying",
        "input"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 8",
          "chapter": 51,
          "title": "Segment 51 (pages 490-498)",
          "relevance_score": 0.45,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 2",
          "chapter": 55,
          "title": "Segment 55 (pages 536-543)",
          "relevance_score": 0.42,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 7",
          "chapter": 37,
          "title": "Segment 37 (pages 345-352)",
          "relevance_score": 0.41,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 52,
          "title": "Segment 52 (pages 499-510)",
          "relevance_score": 0.41,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 2",
          "chapter": 51,
          "title": "Segment 51 (pages 498-505)",
          "relevance_score": 0.39,
          "method": "api"
        }
      ]
    },
    {
      "number": 63,
      "title": "Segment 63 (pages 593-601)",
      "start_page": 593,
      "end_page": 601,
      "detection_method": "topic_boundary",
      "content": "Linear Predictive Coding for\nVoice Compression and\nEffects\n\nEddie Edwards\neddie@tinyted.net\n\nvocoder is a device for altering speech, now made famous by that Cher song,\n\nLieve [Cher98]. Vocoders are best known for the robot voices they produce,\n\nfrom daleks in the Dr. Who series [Nation63] to the battle droids in Star Wars\n\n[Lucas99], but they can also produce bizarre alien voices, as well as “singing” guitars\n\nand similar effects. In addition, vocoders are used as the basis for several voice-com-\npression methods, including the GSM digital mobile phone standard [ETSIOO}.\n\nAlthough voice effects and voice compression seem like different problems, the\nsame approach can apply to both. The program on the CD-ROM demonstrates voice\neffects, but a side effect of the approach is that only 500 bytes of data are required per\nsecond—this is 350 times fess data than CD audio, which would allow us to store\nalmost three weeks of speech on one CD-ROM! The full GSM algorithm is available\nin the public domain [Degener00} and achieves about 200:1 compression over CD\naudio.\n\nThis sort of magic can happen because of the way a vocoder works. There are sev-\neral different types of vocoders, but they all work on the same basic principle: Split\nthe sound up into constituent parts (analysis), manipulate the parts, and then put\nthem back together again (resynthesis). We can then either play around with the data\nin the middle to create effects, or we can compress it. Clearly, we can also store and\nretrieve it, so the analysis and synthesis parts do not have to happen together—or\neven on the same machine. A vocoder is like any codec in this respect, with logically\ndistinct encoding and decoding phases (see Figure 6.5.1).\n\nConsider comparing this arrangement with the familiar set up of JPEG compres-\nsion. There, each block of pixels is transformed into the frequency domain (analysis),\nwhere it can be more easily compressed. The pixels are transformed back again (resyn-\nthesis) when the JPEG is decompressed.\n\nA vocoder is ultimately defined by which algorithm it uses for analysis and resyn-\nthesis. When that algorithm is the Fast Fourier Transform (FFT), we get a phase\n\n613\n\n614 Section6 Audio\n‘eneoder | yr  hr7TC~<—~;<3OCU”; Decoder!\nFIGURE 6.5.1 A vocoder.\nvocoder. The algorithm we present here is called linear predictive coding (LPC) and\ngives us an LPC vocoder.\n\nModeling the Voice\n\nLPC attempts to model the way speech is produced in the human body, but in such a\ngeneral way that it can also model sound production under different circumstances.\nThe basic model has only two parts, which are usually termed the oscillator and the\n\nresonator (see Figure 6.5.2).\n\nOscillator Voice Signal\n\nFigure6.5.2 The LPC model.\n\nYou can't produce a sound without an oscillator—this is the physical object that\nvibrates, producing sound waves. Anything that makes a sound contains some kind of\noscillator, from a played violin (the strings) to a pencil dropped on a desk (the pencil\nvibrates). The human voice is no exception; the person's vocal chords is che oscillator.\n\n6.6 Linear Predictive Coding for Volce Compression and Effects 615\n\nOscillators are well understood, and simulating them on a computer provides little\nchallenge.\n\nMany systems make a sound of one form or another, but some are designed to do\nso (either by evolution or ingenuity). These systems are distinguished by the presence\nof a resonator. A resonator acts as a natural amplifier for the sound produced by the\noscillator. All musical instruments have them—for instance, an acoustic guitar has a\nhollow body that amplifies the strings (an electric guitar has a solid body, and its\nstrings are virtually inaudible until you plug the guitar into an amplifier). However,\nthe resonator isn’t a simple amplifier, by any means. It amplifies different frequencies\nby different amounts, depending on the characteristics of the resonator. In violins, the\nresonance helps to actually reduce inharmonic sounds from the strings. It is the qual-\nity of the resonator in a violin that distinguishes a Stradivarius from a Yamaha. In\nbrass instruments, the only way to produce different notes is to change the configura-\ntion of the resonator, since the oscillator (mouthpiece) is incapable of changing pitch.\nBy pressing a key, the player opens an air vent in the side of the resonator, changing its\ncharacteristics and producing a new note.\n\nThe resonator in the human voice is formed by the human head—-specifically, the\ninterior cavities of the head, through which the sound from the vocal chords travels\nbefore it reaches the mouth. This resonator is certainly not fixed, and by moving the\ntongue, jaw, and lips, the speaker can change the resonator’s characteristics quite\nquickly. If you hum with your vocal chords and make your mouth larger and smaller\nyou can hear the effect—clearly, most word sounds come from this mechanism and\nnot the vocal chords. (There are other mechanisms at work too, which we discuss\nlater.)\n\nSince the resonator can change its characteristics over time, we break the model-\ning process up into frames of around 20 ms each. The resonator is assumed to have\nfixed characteristics over a single frame. The size of each frame is a parameter to the\nLPC algorithm.\n\nA Software Simulation\n\nSimulating this model in software is actually fairly straightforward. The oscillator can\nbe simulated with a sample player, and the resonator is modeled with a digital filter.\nThe oscillator feeds samples to the filter, and speech is produced.\n\nThe digital filter is quite simple in principle. It takes a sequence of input samples\nand produces a sequence of filtered output samples. The filter works by calculating\neach output sample as a weighted sum of the previous NV input samples. The weights\ndetermine the filter’s characteristics. This is usually implemented as a function that\ntakes a single parameter (the most recent sample) and remembers the last N samples\nin an internal state vector.\n\nIn LPC, we use a slightly different formulation, which is more physical than\nmathematical in nature. We model the resonator as a long pipe made up of segments\nof different widths. When a sound wave travels between two segments, some is\n\n616\n\nSection 6 Audio\n\nreflected. The amount that is reflected at each point is given by a reflection coefficient.\nA set of these coefficients describes the whole tube, and the number of coefficients is\na parameter of the LPC algorithm. The filter keeps a state vector corresponding to the\npressure in each segment. This allows reflected waves to actually travel back down\nthe simulated tube. The function given below does the work.\n\nff s = input sample\n\n// FFSE] = forward filter state\n\n// re[] = reflection coefficients\n\nfor {int ii = order; ii-;)\n\n{\n/{ s -= FFS[ii] * rcfii]\n// FFS'[ii + 1] = FFS[ii] + s * re[ii]\ns -= FFS[ii] * re[ii];\nFFS[ii + 1] = FFS{ii] + s * re[ii];\n}\nreturn 5;\n\nAn interesting note is that this function is invertible, and this is the key to LPC\n(see Figure 6.5.3). If we invert that filter and run the speech through it, we will get the\noscillator output signal. (When we run the filter this way, the oscillator signal is called\nthe residual.) The inverse of this function is listed here.\n\n// s = input sample\n/}/ IFS[] = inverse filter state\n// re{] = reflection coefficients\n\nfloat ifsp = s;\n\nfor (int ii = 0; ii < order; iit+)\n\n{\n// IFS'{ii + 1] = IFS[ii] + s * re[iil]\n// s += IFS{ii] * re[ii]\nfloat tmp = IFS[{ii] + s * rc[ii];\ns += IFS[ii] * re[ii];\nIFS[ii] = ifsp;\nifsp = tmp;\n}\nreturn s;\n\nThis is exactly what we need. In our analysis phase, we have the speech signal, but\nnot the oscillator signal. Now we can extract the oscillator signal (residual) to be used\nfor resynthesis. All we need are the reflection coefficients. The problem is that any set\nof coefficients will do. Each will produce some kind of “oscillator signal” when run\nthrough the code above. We need to choose the set of coefficients that gives us the\n“best” oscillator signal in some sense.\n\nLPC defines the best residual to be the one that has the least energy in it. This is\nreasonable, since it means that the inverse filter has removed the highest-energy parts\n\n6.5 Linear Predictive Coding for Volce Compression and Effects 617\n\n| Sonia\n\nVoice Signal\n\nOscillator Signal\n\nFIGURE 6.5.3 Reversing the filter.\n\nof the signal—that is, che most important ones. The forward filter will then re-\nemphasize those parts of the signal.\n\nSolving this then becomes a matter of constructing a large, simultaneous linear\nequation and finding the least-squares solution to it. Describing this in detail is\nbeyond the scope of this gem, but the basics might be found in a suitable linear alge-\nbra text. The code on the CD-ROM uses Schur’s algorithm [Degener94], which is\nhighly optimized for this specific case. This is reproduced as follows:\n\n// G{), HI] = working arrays\n// AC{] = autocorrelation vector for input signal\n\nfi refi (output} reflection coefficients\nfor (ii = 0; ii < order; iit+)\n{\n\nG[ii] = H[ii) = AC[ii + 1];\n\n// one iteration per coefficient\n\nfor (ii = 0; ii < order; ii++}\n\nf\n// calculate re and update error\nfloat r = -H[O] / error;\n\nre[ii] = r;\nerror t= H[O] * Fr;\n\n// update G&H\nfor (int m = 0; m < order - ii; mtt+)\n\nH[m] = H{m + 1} + r * Gm];\nG[m] = H[m + 1] * r + G[m];\n\nSection 6 Audio\n\nThe code in linearpredictor.cpp performs all these tasks and provides a black-box\nsolution for LPC coding. We are left with a two-step process—analysis plus synthe-\nsis—which (barring rounding errors) reproduces the original speech sample precisely.\nThe only parameters are frame time (in samples) and filter complexity (number of\nreflection coefficients). The test code uses frames of 20 ms (160 samples at 8 kHz)\nand eight reflection coefficients.\n\nReplacing the Vocal Chords\n\nOnce the LPC encoder has done its magic, we will want to play around a lictle to cre-\nate our robot or alien voices. The easiest thing to do is to replace the oscillator signal\nwith a synthesized sound. This synthesized sound is then filtered, and the end result is\nas if the synthesizer were in the speaker's throat instead of his own!\n\nThe important thing to remember here is that the synthesized sound is merely\nbeing filtered, so any frequencies that are not in the sound to begin with will not be in\nit afterwards. If we use a simple sine wave, it only contains a single frequency and will\nnot generate interesting sounds. It would be like illuminating a multicolored mural\nwith monochromatic laser light—only the single color is reflected back. So we must\ntry to use a sound that is rich in frequency content.\n\nThe best choices are a pulse waveform or a sawtooth waveform, since these con-\ntain all the harmonics, A square waveform contains all odd-numbered harmonics.\nThese choices all give relatively intelligible “robotic” speech, and they are all very\nquick to generate in code.\n\nAlternatively, a bass-heavy waveform will give a bass-heavy voice; and one with\nonly certain frequencies will remain tuned to those frequencies, which will be modu-\nlated. These choices give more alien-sounding voices, with weirder input waveforms\ngiving weirder speech sounds—although you can no longer hear what is being said!\nSlightly more complex waveforms can be obtained through FM synthesis.\n\nA sample can simply be played back as well. If that sample is the residual, we get\nexcellent-quality results (perfect, allowing for rounding errors). If it is something else,\nlike a guitar riff, we get a bizarre, “speaking-guitar” effect: an “all your base are belong\nto us” pedal instead of just a “wah” pedal!\n\nAnother interesting choice is simple white noise. When we whisper, we do not\nactivate our vocal chords at all, and the oscillator signal is just a hiss. We also seem to\ntone down our intonation. Using noise with a line spoken loudly produces a strange\nkind of hybrid “whisper” that sounds quite evil.\n\nControlling the Resynthesizer\n\nThe only difficult part of generating the new oscillator signal is getting the pitch and\nvolume right. These can be extracted (with some difficulty) from the residual.\n\nThe volume is the most important factor, since you need silence in the right\nplaces. It is also the easiest to calculate, by performing a root-mean-square calculation\n\n6.5 Linear Predictive Coding for Voice Compression and Effects 619\n\nover the residual for each frame of the sound. In output, it is a good idea to interpo-\nlate this volume so the sound doesn't click or pop.\n\nPitch is more difficult. The method used on the CD-ROM works as follows.\nFirst, assume the pitch is less than 1 kHz, and filter the residual using a low-pass filter\nto remove any frequencies higher than this. Then, normalize the waveform and cen-\nter-clip it. This distorts the waveform so that it looks like a series of spikes. Next,\ncompare this waveform with a set of pulse waveforms of different frequencies, and\nchoose the best match (by a least-squares comparison). Finally, for each frame, choose\nthe median pitch calculated for the last three frames (this helps smooth the results\nout). The method is by no means perfect—it is just as much of a hack as it sounds!\nNevertheless, it gives reasonable results—the oscillator seems to follow the lilt of the\ninput speech quite well, and some amount of unrealism is actually desirable!\n\nThe production of each frame now progresses according to the diagram shown in\nFigure 6.5.4. The pitch and volume for each frame control the synthesizer, which is\ncreating a waveform according to the parameters chosen for a specific speaker. This\nwaveform then passes through the filter to give the resultant resynthesized speech.\nNote that another possibility is not shown on the diagram—the frame size on output\ncan be different to the frame size on the input. By doing this, the speech can be sped\nup or slowed down relative to the input speech.\n\nNote that the parameters of the speech (pitch, volume, and reflection coefficients)\nare separate from the parameters of the speaker (they control the synthesizer parame-\n\nDigital Filter Voice Signal\n\nSynthesizer\n\nSpeaker Parms\n\nFIGURE 6.5.4 The speech resynthesizer.\n\nSection 6 Audio\n\nters and the speed). So, the same speech data can in principle be used with a variety of\nspeakers. For instance, every robot might have a different pitch so that the player can\ntell them apart, or some robots might speak more slowly than others. Damage might\neven affect this, so a broken robot might speak very fast!\n\nIncreasing the Depth of the Speaker\n\nSince our reflection coefficients reflect a physical model of a resonator, we can change\nthe resonator by changing the coefficients. The easiest thing to do is to make it longer,\nand hence deeper. If we begin with 8 reflection coefficients, we could generate 16\ncoefficients by inserting zeroes between the numbers. The result is a deeper resonance\n(one octave lower), which sounds more evil.\n\nAlternatively, by cropping reflection coefficients off, the filter becomes more\n‘shallow-—the speech becomes indistinct and sounds as if the speaker has just been to\nthe dentist. Processing the reflection coefficients is much less intuitive than processing\nthe residual, but many effects are possible in theory.\n\nEncoding the Data\n\nGiven the pitch, volume, and eight reflection coefficients, we now have 10 numbers\nper frame describing everything we need to generate a robotic or alien voice. If we\nquantize each number into a single byte, that translates to only 500 bytes per second,\nor 30 KB per minute, as quoted earlier.\n\nFor some games, this is as far as we need to go. Other games might require\nhigher-quality speech, or more natural, human-like speech. Perhaps we could try to\ngenerate a variety of male voices from a single source sample. It is the encoding that\nmust be addressed in these cases.\n\nThe residual signal is quite hard to encode, because it does contain a lot of\n“missed” information. For instance, most speech sounds use the vocal chords, but\nsome ate unvoiced, which means the vocal chords are relaxed, and just a hiss of air is\nreleased into the vocal cavity. The letter “s” is a good example. In these cases, the resid-\nual is like white noise. We could improve the encoding by trying to detect white noise\nin this case.\n\nOther sounds, like a “p”, are made by a different process altogether-—in this case,\nthe air “explodes” through the lips making the p-sound. These sounds are called\nplosives. The plosive is not well modeled by the vocal-chord-plus-filter model, so most\nof the information ends up in the residual. We might be able to model these sounds\ntoo, if we spent enough time on it.\n\nTo capture all these nuances simply, we should encode the entire residual. Then,\nthe recreated speech will be as near as possible to the real thing. There are many ways\nwe might do this—vector quantization, peak detection, or ADPCM coding for\ninstance. We might even happily store the entire residual as a PCM waveform. We\nwont have saved space (quite the opposite), but the cost might be worth it if we can\n\n6.5 Linear Predictive Coding for Volce Compression and Effects 621\n\nperform special effects very cheaply. [Degener94] describes how GSM [ETSI00]\nencodes the residual into about 1.5 kbps (kilobits per second).\n\nSpeed\n\nNot only does the algorithm bless us with low data rates, it also performs admirably\n(even on consoles from two generations ago). While encoding is difficult to get into\nreal-time, decoding is very fast indeed.\n\nThe core of the replay algorithm is the filter. This performs two loads, two adds\nand two multiplies per coefficient per sample. Assuming eight reflection coefficients,\nthis is about 50 cycles per sample, or 400,000 cycles per second at eight kilohertz. An\nunoptimized version would, of course, be slower; while a vectorized version could be\na lot faster (if the hardware supports it).\n\nIn an optimized implementation, the waveform generator would be combined\nwith the filter in the inner loop, alongside the envelope generator, using only a few\ncycles per sample. The creation of speech therefore takes around 500,000 cycles per\nsecond—only 3% of a 16-MHz processor.\n\nEncoding is less critical for game purposes, unless you want to use LPC to transmit\nspeech across the Internet. In this case, some work would have to be done on the encod-\ning end, but a current-generation machine should be able to handle this fairly easily.\n\nExperiments\n\nThe program on the CD-ROM demonstrates almost everything this gem has\ndescribed, so please play with it for a while. You can load speech samples into the pro-\ngram (an example is supplied), which converts them using the LPC algorithm. These\ncan be played back using either the residual or a voice defined in the program. Several\nexample voices are supplied. The program includes full source code (Microsoft Visual\nC++), and full instructions are provided in the ReadMe.xxt file.\n\nReferences\n\n[Cher98] Cher, Befeve, WEA/Warner Bros., 1998.\n\n[Degener94] Degener, Jutta, “Digital Speech Compression,” Dr. Dobbs Journal\n(Wecember 1994), available online at http://www.ddj.com/documents/s=1012/\n\nj9412b/.\n\n[Degener00] Degener, Jutta, “GSM 06.10 Lossy Speech Compression,” available\nonline at hrep://kbs.cs.tu-berlin.de/~jutta/toast.html, July 2000.\n\n[ETSIOO] “Digital Cellular Telecommunications System (Phase 2+); Full Rate\nSpeech; Transcoding,” (GSM 06.10 version 5.2.1 Release 1996), Third Edition,\nEuropean Telecommunications Standards Institute, 2000. Available online (free\nregistration required) at heep:/ webapp <tsi.org/pday.\n\n[Lucas99] Lucas, George, The Phantom Menace, 20th Century Fox, 1999.\n\n[Nation63] Nation, Terry, Dr. Who: The Dead Planet, British Broadcasting Corpora-\ntion, 1963.",
      "page_number": 593,
      "chapter_number": 63,
      "summary": "The program on the CD-ROM demonstrates voice\neffects, but a side effect of the approach is that only 500 bytes of data are required per\nsecond—this is 350 times fess data than CD audio, which would allow us to store\nalmost three weeks of speech on one CD-ROM Key topics include speech, voice, and sound.",
      "keywords": [
        "Linear Predictive Coding",
        "oscillator signal",
        "reflection coefficients",
        "speech",
        "oscillator",
        "filter",
        "Signal",
        "coefficients",
        "LPC",
        "sound",
        "resonator",
        "Voice",
        "Predictive Coding",
        "Voice Signal Oscillator",
        "Linear Predictive"
      ],
      "concepts": [
        "speech",
        "voice",
        "sound",
        "sample",
        "waveform",
        "filter",
        "filtered",
        "effects",
        "oscillator",
        "linear"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 7",
          "chapter": 39,
          "title": "Segment 39 (pages 361-371)",
          "relevance_score": 0.51,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 2",
          "chapter": 51,
          "title": "Segment 51 (pages 498-505)",
          "relevance_score": 0.48,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 7",
          "chapter": 37,
          "title": "Segment 37 (pages 345-352)",
          "relevance_score": 0.45,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 7",
          "chapter": 61,
          "title": "Segment 61 (pages 593-600)",
          "relevance_score": 0.42,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 7",
          "chapter": 38,
          "title": "Segment 38 (pages 353-360)",
          "relevance_score": 0.39,
          "method": "api"
        }
      ]
    },
    {
      "number": 64,
      "title": "Segment 64 (pages 602-609)",
      "start_page": 602,
      "end_page": 609,
      "detection_method": "topic_boundary",
      "content": "The Stochastic Synthesis of\nComplex Sounds\n\nPhil Burk, SoftSynth.com\nphilburk@softsynth.com\n\ntochastic synthesis is a type of audio synthesis that uses random numbers. You\n\ncan use random numbers at a low level to generate noise. This noise can be used\nas a sound source or a modulation source. You can also use random numbers at a\nhigher level to control sounds or to trigger sounds. These randomly controlled and\ntriggered sounds can then be used to create soundscapes.\n\nMost games use digital audio samples to create sounds. One advantage of using\nsamples is that they accurately reproduce the original sound. However, a disadvantage\nof using samples is that they can be repetitive. You can change the sample's playback\nrate and its amplitude, but that doesn’t eliminate the repetitiveness. Real-world\nsounds do not sound the same every time. Take, for example, a dog’s barking. Each\nbark is a little different. A dog that barked exactly the same every time would be\nsuspect.\n\nSamples are sometimes used to create continuous sounds, such as wind. However,\nthis method eventually requires samples to loop, and the repetition can be audible. A\nsolution to this problem is to synthesize the sounds directly. An advantage of using\nsynthesis is that the sound designer has control over many more parameters. You can\nchange the character of the synthesized wind by making it whistle, or you can make it\nfluctuate more rapidly. You are not limited to just amplitude and pitch changes.\n\nWe will provide examples including wind, sonar pings, rain, rocket engines, and\nhelicopter rotors. The examples will be constructed out of simple, atomic units called\nunit generators. These will include filters, noise generators, oscillators or tone genera-\ntors, and effects processors, such as reverbs.\n\nLinear Congruential Algorithm\n\nYou cannot generate truly random numbers using software. This is because comput-\ners generate reproducible, deterministic results, Like most game programmers, how-\never, we ate not above cheating. We can generate sequences of numbers, which will\nsound random, even if they aren't really random.\n\n6.6 The Stochastic Synthesis of Comptex Sounds 623\n\nThe most common and cheapest pseudo-random number generator is the linear\ncongruential algorithm (LCA). It is based on doing multiplications and additions,\nand producing a numerical result that is so large that it overflows the word size of the\ncomputer. By carefully selecting the coefficients of the equation, we can generate a\nsequence of 2°? numbers before repeating the sequence [Chamberlin80]. If we gener-\nate a stream of samples at 44,100 Hz, then it would only repeat after 27 hours.\n\nTo use the LCA function described here, pass a starting value co the function,\nthen feed the result back into the function to generate a sequence of random\nnumbers.\n\n/* Calculate pseudo-random 32 bit number using\n* the linear congruential method. */\nstatic unsigned long GenerateRandomNumber (\nunsigned long previous }\n\nreturn ((previous * 196314165) + 907633515};\n}\n\nThe most significant bits of this function are more random than the lower bits.\nSo, if you want to generate 16-bit random numbers, shift right and use the top 16 bits\ninstead of masking off the lower 16 bits.\n\nTypes of Noise\n\nThe direct result of the Linear Congruential Algorithm is white noise, which sounds\nlike static (“shshshsh”). White noise contains equal energy across the entire frequency\nspectrum. By modifying the algorithm, you can generate noise with different spectra.\n\nYou can generate red noise by calculating a new random number every few sam-\nples and interpolating between them for the intervening samples. This method,\nwhich is demonstrated by the following code and Figure 6.6.1, gives you some very\nsimple control over the frequency content.\n\n// phase ranges from 0.0 to 1.0\nphase += phaseInc;\nif( phase >= 1.0 }\n{\n// grab a new random target whenever the phase wraps\nsource = target;\ntarget = randomFloat(};\ndelta = target - source;\nphase -= 1.0f;\n\n// linear interpolation between random values\noutputs[O) = source + {phase * delta);\n\nYou can also generate noisy signals using fractal mathematics {feedback on non-\nlinear functions). An example is a simple sine wave with feedback [Roads96]. Iterate\nover the following code to generate samples or a control signal.\n\nSection 6 Audio\n\nFIGURE 6.8.1 (Left) White noise with new random values for every sample. (Right) Red\nnoise with samples interpolated between random values.\n\nPhase += phaseIncrement + (feedback * x );\nif( phase > 1.0 } phase -= 2.0;\n\nelse if( phase < -1.0 } phase t= 2.0;\n\nx = sin{ PI * phase );\n\nIn this example, phase ranges from —1.0 to 1.0. As you raise the feedback coeffi-\ncient, you will start to get a noisy, chaotic signal.\n\nSoftware Examples\n\nThe following sections describe actual examples using the techniques described. The\nsource code to the various components described is on the CD-ROM.\n\nGenerating a Wind Sound\n\nA wind sound can be generated using a white noise generator (WhiteNoise) as the\nsound source. The noise signal passes through a low-pass filter (LowPassFilter) with\na frequency of 1000 Hz. By increasing the @ of the filter to around 16, you can make\na good whistling wind sound.\n\nSee Figure 6.6.2 for an overview of the wind example. A red noise generator (Red -\nNoise) controls the cutoff frequency of the filter and mimics the random rising and\nfalling of the wind, The modRate parameter controls how rapidly the wind fluctuates.\nThe modDepth controls the size of the fluctuation. You then multiply the RedNoise\noutput by the modDepth and add the result to the frequency value to generate the\nactual cutoff frequency value for the filter, Mixing (or adding) together several of\nthese generators will create a more realistic sound. Try setting mo¢Rate to 0.6, and\nmodDepth to 350.\n\nGenerating a Sonar Ping\n\nA sonar ping sound consists of a short sine wave burst that echoes off various objects\nunderwater. The sound slowly fades away over time. We can generate the sine burst\nby hitting a resonant LowPass filter with an impulse spike, similar to hitting 2 bell\n\n6.6 The Stochastic Synthesis of Complex Sounds 625\n\nFIGURE 6.6.2 A wind sound example.\n\nwith a hammer. To implement this, you want to set the filter cutoff frequency to\nabout 700 Hz. To make the filter ring for a longer time, set the @ to larger values, like\n1000. To increase the sound of the ‘ping’ try setting the Impulse amplitude to seven.\n\nThe sound we have so far is just a pure sound wave. To make it sound like it is\nreflecting off of submerged objects, we need to roughen it up a bit. We could add\nlarge amounts of reverb, but there is a cheaper trick, which should appeal to game\ndevelopers. We can modulate the LowPassFilter cutoff frequency by using a RedNoise\ngenerator. Set the RedNoise frequency to about 180 Hz and its amplitude to about 80\nfor the desired result.\n\nThe circuit is identical to the wind sound example shown in Figure 6.6.1, except\nthat an ImpulseOscillator replaces the WhiteNoise generator.\n\nGenerating the Sound of Rain\n\nThe sound of rain is composed of the sounds produced by millions of raindrops hit-\nting cars, trees, windows, dogs, etc. We cannot generate the sound of each individual\nraindrop, but we can come close. When each raindrop hits, it generates a little ‘plop’\nsound. We could. assign an oscillator to each plop sound, but we would need too\nmany oscillators. So, instead we use the familiar ringing filter to generate the plop. An\nadvantage to using a ringing filter is that we can hit one filter with lots of little\nimpulses and get the same result as if we had a filter per impulse. We set the filter fre-\nquency to 250 and the 0 to 2.\n\nThe ringing filter will always generate the same pitch every time we hit it unless\nwe modulate the frequency. We can frequency modulate the filter using a fast Red-\n\nSection& Audio\n\nNoise generator, as we have in the previous examples. We set the modrate to 10 and\nthe modDepth to 90 to achieve the desired resule.\n\nThe next trick is to generate lots of randomly distributed impulses to feed the fil-\nter. We can use a comparator to look at a random signal, Whenever the signal exceeds\nthe threshold, we can output a random value, as in the code shown here. Otherwise,\nwe output zero. This will give us occasional random pulses that we can use to excite,\nor ping the filter (see Figure 6.6.3).\n\nthreshold = 1.0 — rates;\nexcitation = (nextRandom(} > threshold) 7\nNextRandom {) : 0.0;\n\nPoissonTrigger Lowpass Filter\n\nFIGURE 6.6.3 A rain example. Two raindrop generators share a reverb.\n\nWe can use the rate value above to adjust how hard it is raining.\n\nThe ringing filter will give us the sound of individual raindrops that are near to\nus. Now, we need to generate the millions of drops in the surrounding area that make\nup the dull roar of rain. We can use a reverb effects processor to echo the sound of a\nfew raindrops and create the sound of many raindrops. The reverb is constructed\nfrom six comb filters and an all-pass filter. [Moore90]. The comb filters include a low-\npass filter that muffles the sound of the other raindrops and makes them seem farther\naway. The reverb also uses a much longer delay than normal, between 200 ms and\n350 ms, so that the echo effect is less noticeable. We then mix the close raindrop\nsound with the reverberated sound to get a complete rain sound, as shown above in\nFigure 6.6.3.\n\n6.6 The Stochastic Synthesis of Compiex Sounds 627\n\nYou could add different resonators to this patch to simulate the sound of rain hit-\nting a tin roof or a glass skylight. Just replace the low-pass filter with a more-complex\nformant filter bank or cross-coupled modal filters.\n\nGenerating a Rocket Engine Sound\n\nA decent rocket engine sound can be generated using just two RedNoise generators. A\nsingle RedNoise generator has a discernable pitch and doesn't have the crackle of a\ngood rocket sound. So we can use one RedNoise generator to medulate the frequency\nof another. You want to set the center frequency of the carrier, the RedNoise that you\nhear, to 1300 Hz, and set che modulator’s frequency to a value around 731 Hz. Avoid\nhaving the modulator frequencies be a simple ratio of the carrier, and set the modula-\ntor amplitude to about 600 Hz.\n\nWe also need a way to quickly ramp the sound’s amplitude up and down as we\nturn the rocket on and off. Imagine a thruster firing under a pilot’s control. We can do\nthis with a slew rate limiter. The limiter tracks its input but won't move faster than a\ngiven rate, as shown in the code that follows. This allows us to suddenly set the ampli-\ntude to zero, but the actual level will drop more slowly.\n\nif{ input > value )\n{\nvalue += increment;\nif{ value > input } value = input;\n\nelse if( input < value }\n\n{\n\nvalue -= increment;\n\nif( value < input ) value = input;\n\n}\n\nWe then control the output amplitude of the circuit by multiplying the RedNoise\nsignal by the SlewRateLimiter value. Figure 6.6.4 illustrates the rocket engine sound\nlogic.\n\nGenerating a Helicopter Rotor Sound\n\nThe noise from a helicopter has two main components, the engine noise and the rotor\nnoise. The rotors cut through the air, causing a whooshing sound. Because the rotors\nare spinning, they are sometimes going away from us and sometimes coming toward\nus. This causes a Doppler shift that raises and lowers the pitch of the whoosh. Imag-\nine a car driving past you on a road. It sounds higher pitched when it is approaching\nyou and lower pitched as it goes away. This is because the sound waves are compressed\nas the car moves toward you, and shorter wavelengths have a higher frequency.\n\nThis sound uses filtered white noise as the source sound as in the wind example.\nIt then passes the sound through two variable delays. The two delays are swept back\nand forth using a sine wave modulator, Set the sine waves 180° out of phase to model\n\nFIGURE 6.6.4 Rocket engine sound using red noise pair and an envelope generated by a\nslew rate limiter.\n\ntwo blades opposite each other. So, as one delay is increasing, the other is decreasing.\nThis is illustrated in Figure 6.6.5.\n\nNext, we can tune the delay times to match the diameter of the rotor blades, The\nminimum delay time is when the blade is closest to us, and vice versa.\n\ndelayRange = rotorDiameter / speedOfSound;\nmodDepth = delayRange / 2.0;\n\nA UH-1 Huey helicopter has a rotor diameter of 48 feet. The speed of sound is\napproximately 1100 feet per second, so the modDepth for the Doppler shift is about\n0.022 seconds. The previous code example generates the proper modDepth.\n\nmodDepth\n\nFIGURE 6.6.5 Helicopter rotor sound created using Doppler shifts 180° out of phase.\n\n6.6 The Stochastic Synthesis of Complex Sounds 629\n\nSoftware\n\nA keyboard-driven C++ program is provided on the CD-ROM that enables you to\nexperiment with these sounds. You can turn sounds on and off, and change parame-\nters interactively. Look in the index.html file for more information on the software\ndesign. To check for updates to this software, visit [Softsynth02].\n\nThe example program uses PortAudio, which is a simple, cross-platform audio\nAPI. So, the program should be able to run on Win32, Macintosh, Unix with OSS,\nSGI, and other platforms. To check for updates to PortAudio or to get source code for\nyour platform, visit [PortAudio01).\n\nOM THE CD\n\nConclusion\n\nUsing just a few simple unit generators, you can synthesize a wide variety of sounds\nwithout the use of samples. This gives you more control over the sound parameters\nand helps you avoid the artifacts associated with sample loops. Stochastic functions\nare particularly useful because they can add a lot of complexity without adding a sig-\nnificant computational load. The technique of modulating a single filter with Red-\nNoise is particularly handy and can be used to replace multiple unmodulated filters.\nStochastic processes are also useful at a higher level to trigger short sound events, such\nas raindrops. Reverberation can be used to make it sound like there are many more\nsound generators than are actually present in the circuit. Hopefully, these techniques\ncan be used to add some sonic spice in your next game.\n\nReferences\n\n[Chamberlin80] Chamberlin, Hal, Musical Applications of Microprocessors, Hayden,\n1980.\n\n[Dodge97] Dodge, Jerse, Computer Music Synthesis, Composition and Performance,\nSimon & Schuster, 1997.\n\n[Moore90] Moore, FE. Richard, Elements of Computer Music, Prentice Hall, 1990.\n\n[PortAudio01] Bencina, Ross, “PortAudio—an Open-Source Cross-Platform Audio\nAPI,” available online at http://www.portaudio.com/, 2001.\n\n[Roads96] Roads, Curtis, The Computer Music Tutorial, MIT Press, 1996.\n\n[SoftsynthO2] Burk, Phil, “Biquad Filters and Stochastic Synthesis,” available online\nat http://www.softsynth.com/gamegems/, 2002.",
      "page_number": 602,
      "chapter_number": 64,
      "summary": "We will provide examples including wind, sonar pings, rain, rocket engines, and\nhelicopter rotors Key topics include sounds, generate, and generators.",
      "keywords": [
        "sound",
        "filter",
        "noise",
        "Wind Sound",
        "Stochastic Synthesis",
        "generate",
        "Rocket Engine Sound",
        "random",
        "frequency",
        "Engine Sound",
        "Synthesis",
        "random numbers",
        "phase",
        "red noise",
        "Complex Sounds"
      ],
      "concepts": [
        "sounds",
        "generate",
        "generators",
        "generating",
        "filters",
        "filtered",
        "value",
        "examples",
        "phase",
        "noise"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 2",
          "chapter": 55,
          "title": "Segment 55 (pages 536-543)",
          "relevance_score": 0.55,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 7",
          "chapter": 38,
          "title": "Segment 38 (pages 353-360)",
          "relevance_score": 0.53,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 52,
          "title": "Segment 52 (pages 499-510)",
          "relevance_score": 0.53,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 2",
          "chapter": 46,
          "title": "Segment 46 (pages 450-457)",
          "relevance_score": 0.48,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 7",
          "chapter": 63,
          "title": "Segment 63 (pages 609-616)",
          "relevance_score": 0.48,
          "method": "api"
        }
      ]
    },
    {
      "number": 65,
      "title": "Segment 65 (pages 610-617)",
      "start_page": 610,
      "end_page": 617,
      "detection_method": "topic_boundary",
      "content": "6.7\n\nReal-Time Modular Audio\nProcessing for Games\n\nFrank Luchs, Visiomedia Software\n\nCorporation\ngemsaudio@visiomedia.com\n\nhis gem will describe how to incorporate modular audio processing into your\n\ngame to procedurally generate sounds in real-time, Often games use one-shot or\nlooped samples to play game sounds. While this can frequently be effective, these sta-\ntic one-shot or looped samples are limited in how they can change in response to user\nactions, Procedural sound generation with modular audio processing provides many\nmore controls and variations that offer greater realism of sound interaction through a\ngreater interaction berween gameplay and audio.\n\nSound can shape the picture as much as the picture can shape the sound. Real-\ntime procedural audio should become part of a continuum, changing dynamically\nover time—sometimes subliminal and sometimes impressive. It should resonate with\nthe game's environment and flow with the player's interaction.\n\nModular Audio Processing\n\nModular audio processing systems can be created in software using virtual modules\nand cables that are quite similar to those of vintage modular synthesizer systems. Both\nsystems have no fixed signal path. You create a sound by connecting units like oscilla-\ntors, filters, and envelope generators—building an audio chain. Using units makes it\npossible to synthesize various sounds with maximum flexibility, without the need for\nhard-coding all the countless possible connections.\n\nThe data flow of audio processing is determined by the connections that are cho-\nsen between the units. The units are encapsulated entities that perform specific opet-\nations on the data stream.\n\nForty years ago, synthesizers were so large that they filled up an entire room, and.\nthe only way to save a patch with all its connections was by shooting a Polaroid.\nToday pure-software systems allow you to create and save millions of patches on your\nhard disk. Patches are created by appending DSP units to a processing chain. Com-\nplex components can be built on top of simpler patches, using units that represent\nfamiliar mathematical operations,\n\n6.7 Real-Time Modular Audio Processing for Games 631\n\nAs with the vintage hardware monsters, a deep knowledge of digital signal pro-\ncessing is not required, since you can learn by ear while experimenting with connec-\ntions between modules.\n\nProcedural Sound Generation\n\nThere is a great variety of procedural sound-generation methods, and many have a\nlong history in electronic synthesis. Here, we mention some of the common tech-\nniques used by many synthesizers that are both effective and practical for current real-\ntime software synthesis.\n\nClassical synthesizers are based on the idea of subtractive synthesis. The typical\nsubtractive synthesizer has an oscillator that generates the basic audio tone, mostly a\nharmonically rich waveform. This sound goes through a low-pass filter, truncating\nthe upper harmonics, and finally through an amplifier. Each stage can have its own\nmodulators; so over time, the sound changes dynamically in pitch, timbre, and\nloudness.\n\n‘Two types of modulators are common. One is the low-frequency oscillator\n(LFO), which is an oscillator running in the subaudio range (below 20 Hz). It pro-\nduces cyclic modulations. Connected to an audio oscillator, you will get vibrato. Con-\nnected to a filter, you get a kind of “wah-wah.” Connected to the amplifier, the result\nis a tremolo effect. The other modulator is the envelope generator (EG) for one-shot\nmodulations, often triggered by the keyboard. The EG gives the sound a shape.\n\nAnother important synthesis method is FM modulation, a frequency (or phase)\nmodulation in audio range. This is perfect for creating a rich spectrum from of a few\noscillators. Of course, oscillators can also provide simple linear-interpolated wavetable\nplayback. (For additional information on historical applications of synthesis, see\n[Smith91].}\n\nThe Sphinx MMOS System\n\nIn the following sections, we introduce a system called “Sphinx MMOS,” which can\nbe used to generate procedural sounds in your games. Source code and executables for\nthis system can be found on the CD-ROM.\n\nSphinx MMOS builds on the ideas of PD [PDRef}, MAX [MAXRef], and Gen-\nerator [GENRef], with an extensible object-oriented model that allows users to create\ninstruments at different levels. It simplifies development of audio applications using\nthe well-known patch model.\n\nDifferent terms are used for the individual elements of such a system. Table 6.7.1\ncompares the terminology used in Sphinx MMOS with other common terms.\n\nSphinx MMOS is a data flow-oriented system. In such a system, you build a data-\nprocessing network by connecting primitive units together. Each unit (here called a\n“processor”) has input pins that accept data from processors connected upstream and\none or more output pins that send processed results to the following downstream\nprocessor. For efficiency, all the data is processed blockwise, and the blocksize in\n\n632 Section 6 Audio\n\nTable 6.7.1 Terminology Used In Sphinx MMOS\n\nName in Sphinx MMOS Other Names\n\nProcessor Unit, Filter, Block, Node, (DSP} Module\n\nPin Input/Output, Inlet/Oudet, Slot, Port\n\nSignal Data, Media, Stream, Samples, Payioad, Information\nPatch Graph, Chain, Network\n\nSphinx MMOS defaults to 256 samples. Having a sample rate of 44,100 Hz makes a\nbuffer duration of -6 ms, which corresponds to a frame rate of ~172 Hz.\n\nProcessors\n\nThere are many kinds of processors available in Sphinx MMOS. The most common\ntypes are oscillators, noise generators, envelopes, filters, and mixers. In order to con-\ntrol triggering of sounds, there are processors for impulse generation, sequencing, and\nselection. Each processor defines the particular connections that are available.\n\nTable 6.7.2 shows a list of some of the processors in the Sphinx MMOS system.\nWe will discuss how to connect these processors together in the next section.\n\nTable 6.7.2 Some of the Processors in Sphinx MMOS\n\nOscillators Noise Generators\nCGASineOscillator CGARandomGenerator\nCGATriangleOscillator CGANoiseGenerator\nCGASquareOscillator Miscellaneous\nCGASawtoothOscillator CGAAverager\nCGASinCosO0scillator CGAGlLide\nCGASinexOscillator CGAInterleaver\nCGASawtoothOscDSF CGAThreshold\nCGASawtoothOscBLit Trigger & Selection\nCGAWaveTableOscillator CGAImpulseGenerator\nEnvelopes CGASequencer16\nCGATriangleEnvelope CGASelector\nCGAHalfCosineEnvelope Mixers\nCGAGaussEnvelope CGAMixer2,3,4,6\nCGARampEnvelope CGABalance\n\nFilters\n\nCGAButterworthLPF\n\nCGAResonator\n\n6.7 Real-Time Modular Audio Processing for Games 633\n\nPatch File introduction\n\nSphinx patch files are simple text files that you can edit with any text file editor. Let’s\nlook at a simple patch. It’s an oscillator with a base frequency of 200 Hz, modulated\nby an LFO at 3.5 Hz. FMAttenuation is set to 0.1, which limits the modulation depth\nto +/— one octave. All processors of the audio chain are listed inside the patch. Also,\nall parameters are contained inside the object's brackets.\n\nCGAPatch “Sine Oscillator with LFO Modulation\"\n\n{\nCGASineOscillator LFO\n{\nFrequency = 3.5;\n}\nCGASawtoothOscillator OSC\n{\nFrequency = 200;\nFMAttenuation = 0.1;\n}\nConnection = LFO, OSC, SampleOQut, FM;\n}\n\nThe last line of the patch connects the sample output of the LFO with the (bipo-\nlar) frequency modulation input of the VCO. This is what it looks like to hardcode\nthat patch right into your game:\n\nvoid SamplePatch()\n{\nIGAPatch* pPatch = CreatePatch(\n“Sine Oscillator with LFO Modulation\");\n\n// O modulator\n\n1GASineOscillator* pLFO =\nPCREATE (pPatch,SineOscillator);\npLFO ->SetFrequency(3.5T);\n\n/{ t oscillator\nIGASawtoothOscillator* pSaw2 =\nPCREATE (pPatch, SawtoothOscillator)} ;\npSaw2 ->SetFrequency (200. 0f};\npSaw2->SatFMAttenuation(0.1f};\n\n// connections\npPatch->Connect(0,1, SampleOut, FM);\n\n}\n\nThe first line creates a new patch and appends it to the application's patch list.\nWith the two PCREATE lines, we create the two processors. PCREATE is a convenient\nmacro that casts to the type of processor specified by the CID, creates the object, and\n\nSection 6 Audio\n\nappends it to the list of processors in our patch. The order of creation is important,\nbecause it defines the order of processing in the chain. The last line connects the two\nprocessors, The arguments are the processor indices in the chain and their pins. Here\nwe connect the pin Samp1e0ut of oscillator zero with the input pin FM of oscillator one.\n\nShown next are the steps needed to initialize Sphinx MMOS, create and play the\npatch, and clean up.\n\ng_pGASystem->Initialize(}\n\nSamplePatch(};\n\ng_pGASystem->Start();\n\n// run application loop here and handle\n\n// start/stop and parameter setting somewhere\nff in your event handling\n\nRunLoop{);\n\ng_pGASystem->Terminate()\n\nThe g_pGaSystem is a global that represents the singleton audio object in our\napplication. If not specified otherwise, all rendering is done to the default stream. For\naudio rendering, the current version of Sphinx MMOS uses its own set of wrapper\nclasses that encapsulate the excellent PortAudio system [Burk01].\n\nPatch File Applications\n\nON THE CO\n\nNow that we have described the basic patch-definition language, we have the power\nto create complex sounds. Because any signal path can be formed by describing\nprocessors and their connections, an infinite variety of patches are possible. Also,\nthese patches can be controlled by games because we can choose game variables to\ntake the place of certain processors in a given patch, thus giving us organic control\nover digital sound generation and signal processing. We even can connect any\ndynamic value from our game data or user interface to a CGAController to modify the\naudio stream at the sample rate.\n\nTo show how we can apply this patch system to games, we will now describe how\npatch configurations can be designed to simulate engine sounds. Rather than covering\nall of the specific details of the patches, we will highlight some of the important fea-\ntures. We will also show how the complexity of patches can be incrementally\nincreased to improve the quality of engine simulation.\n\nThe patches described in the following subsections can be found in the patches\nprovided on the CD-ROM.\n\nMotor Vehicles\nA vehicle sound is a complex signal produced by several sources. Many deterministic\n\nand stochastic components occur simultaneously. The deterministic components are\n\n6.7 Real-Time Modular Audio Processing for Games 635\n\ncorrelated to the revolutions per minute (RPM) of the engine. The stochastic compo-\nnents are primarily due to turbulent airflow from the air intake and exhaust systems.\nAt low speed, the sound signature is dominated by these deterministic components,\nwhile at high speed, the signature is dominated by the stochastic components,\n\nThe basic idea behind an engine patch is to simulate the alternating phases of a\nsound. In order to generate sophisticated and less-predictable sounds, we combine\nlooped and simple one-shot samples with synthesized sounds, We will use a sequencer\nto control the timing of the sounds. An impulse generator ttiggers a selector switch.\nEach impulse at the inpur of the selector selects che next sound source input, and it\nalso resets the sample start. This is somewhat like programming a drumbox. The dif-\nference lies in speed. We accelerate the cycle up into the audio range. While a drum\nsequence might groove at 120 beats per minute, our engine will climb to 4000-RPM\ncruising speed and higher.\n\n¢ The PowerStroke patch simulates the generic, four-cylinder, four-stroke engine.\nThese four repeating strokes are referred to as Intake, Compression, Power, and\nExhaust. We can simulate three of the engine phases with samples. At the begin-\nning of the patch file, we load the samples into the CGASignal objects and give\nthem appropriate names (Intake, Impulse, Exhaust). These names (not the file-\nnames) are used as a reference value for the WaveTable parameter of a\nCGAWavetableOQscillator.\n\nThe wavetable oscillator can play loops or one-shots. We want to trigger the\nwaves from a CGAImpulseGenerator, so we set the Repeat parameter to one. The\nspeed of the impulse generator, the RPM, is controlled by a low-frequency oscil-\nlator. Each impulse selects the next input at the CGASelector. To activate four\ninputs, we set the Selection parameter to 15 (1 + 2 + 4 + 8). We have no input\nfor the compression phase, which means this phase will be silent and the selector\nwill just fill in zeros.\n\n* The PowerStroke with Muffler patch has two additional filters of type CGARes-\nonator to simulate the muffler resonances. The original signal and the signals of\nthe resonators are mixed in a CGAMixer3 object. In order to get a roaring sound at\nhigher speed, we set the input gain of the resonances high, but control the AM by\nthe speed controller.\n\n¢ The PowerStroke 2 Cylinders with Muffler patch adds cross-fading between\nsounds over the range of RPMs. Across the RPM range, the sound components\nshould vary slightly to produce a convincing timbre change.\n\nHelicopters\n\n* The Turbine patch plays a turbine sample loop. The sample contains both\npitched and noisy components. In contrast to the common sample editing phi-\nlosophy, the loop points here are chosen to not suppress the cyclic character.\n\nThe cGAWavetableOscillator is frequency modulated by a smoothed LFO\nsource, In order to get a complex and bright sound with varying overtones, we\n\nSection 6 Audio\n\nnow add a bit of audio FM to the CGAWavetableOscillator. We need a CGAMixer\nhere to combine the modulation signals from the LFO and the VCO. The result\nis the Turbine AudioFM1 patch. We can change the character in a more interest-\ning way if we add some FM modulation to the VCO that modulates the sample.\nIn lower ranges, this results in amplitude modulations, which enhance the slow\nrotating effect (Turbine AudioFM2).\n\n* The Rotor—Enveloped Sample patch demonstrates a looping sample that is\namplitude modulated by a CGAGaussEnve lope to give soft attack and release. The\nsample m_propeller01.wav consists of a strong noise component and a low-fre-\nquency distorted sine wave. The envelope is triggered by 2 CGAImpulseGenera-\ntor. The trigger points are independent of the loop start point, which results in\nlittle sound variations.\n\n* Turbine +-Rotor is a combination of the AudioFM2 Turbine and the enveloped\nrotor. The turbine’s frequency and the trigger speed of the envelope are controlled\n\n- by the same LFO.\n\n¢ The Helicopter with Turbine, Rotor and Flap Fx patch uses sequenced waveta-\nbies and feedback FM techniques to simulate engine and air chop. Exactly as with\nthe car engine, we use the balance parameter of the CGAMixer to cross-fade\nbetween its inputs. Components of this patch are the Jet/Turbine Engine with its\nIntake and Exhaust sounds, the basic main and tail rotor sounds with the blade\nparameters, an additional generator to intensify air noise at greater speeds, and\nthe flanging impulse for the characteristic flap effect.\n\nFar away, the helicopter sound has strong amplitude fluctuations and an indi-\nrect muffling effect caused by air turbulence. For short bursts, the sound some-\ntimes disappears completely or is just a single but strong impulse. In our patch,\nwe simulate this characteristic interference effect by adding a four-millisecond\ndelayed version to the original flap sample. The delay time is slowly modulated by\nan LFO. This results in moving notches in the audio spectrum and gives a nice\nflanging effect.\n¢ Turbine Controlled by Keypad is an interaction demo that shows how to\ncontrol the turbine sample by the keypad. The frequency of the loop is controlled\nby a value assigned to a key of the numpad. Play with the numbers one to nine in\norder to glide to different turbine speeds. For the gliding effect, we connect a\nCGAGLide between the CGANumPadController and the CGAWavetableOscillator.\n\nSubmarines\n\nThe tonal components of a submarine are machinery and equipment noise, hull reso-\nnances, and propeller-radiated noise. The broadband components are flow noise, cav-\nitation, and the background of the ocean's natural noises. In order to generate the\nsound signature of a submarine, we use two special oscillators to generate pink noise-\nmodulated sine waves. These simulate the combination of irregular and. stochastic\n\n6.7 Real-Time Modular Audio Processing for Games 637\n\nprocesses of turbulent noisy bubbles and the tonal noise that contains the discrete res-\nonance frequencies of the ship’s hull. The continuous part of the spectrum is charac-\nterized by a maximum in the area of 50 Hz to 100 Hz, but convincing frequency\nvalues might have a range of up to 1000 Hz.\n\nThe propeller sound is simulated by a looped sample containing higher frequen-\ncies. When the propeller’s excitation frequency corresponds to the hull’s natural fre-\nquency, we get strong tonals from the huil. Also, singing can occur when the\nvortex-shedding frequency matches the blade’s natural frequency. This is a speed-\ndependent feedback effect in a narrow speed range and can happen at different\ns .\nAs the boat passes through the water, turbulent flow noise is generated along the\nhull. This hydrodynamic noise increases significantly as the speed rises. Cavitation\nand flow noise extend well beyond 10 kHz.\n\n* The Sonar—Noise Modulated Sine Patch is a sine wave of 2000 Hz, with\namplitude modulated by a descending ramp and frequency modulated by noise.\nThe noise modulation is shaped by an envelope to get a fade-in effect, thus the\ntone is clear at the beginning, but gets more and more distorted.\n\n* The Submarine—Engine Only is just an amplitude-modulated sample with an\nengine loop. A CGASinCosOscillator is used for fading. The next turbulence\npatches introduce two special oscillators for tonal noise generation, the\nCGANoiseMSineOsc with default settings and the CGASineXOscillator with a fre-\nquency setting of 860 Hz for turbulences in a higher range.\n\n* Submarine—Engine, Turbulences is a mix between the engine sample, the\nlower noise generated by the CGANoiseMSineOsc, and the higher noise generated\nby the CGASineXOscillator. We use a three-channel mixer, the CGAMixer3, and set\nthe gain of the higher part very low to get a convincing, filtered, underwater\neffect. No additional filter is used for this patch.\n\n¢ In the patch Submarine—Engine, Turbulences, Sonar, we include the elements\nof the above sonar patch and add frequency modulation on the engine sample to\nsimulate a Doppler effect. In conjunction with a low-pass filter at 400 Hz, this\nmakes the flow-by effect more convincing.\n\nSource Code\n\nOn the CD-ROM, you will find the Sphinx MMOS system source code, executables,\npatch files, and samples. Some patch files demonstrate the various processors, and\nsome contain the engine simulations discussed in the previous section. Updates are\navailable at the Visiomedia Web site [Visiomedia].\n\nThere are three methods for incorporating this audio system into your application:\n\n1. Write new C++ classes to handle audio processing and management, and\nbuild your own version of the library with customized source code.",
      "page_number": 610,
      "chapter_number": 65,
      "summary": "This chapter covers segment 65 (pages 610-617). Key topics include patch, patches, and modules. The data flow of audio processing is determined by the connections that are cho-\nsen between the units.",
      "keywords": [
        "modular audio processing",
        "Sphinx MMOS",
        "Sphinx MMOS System",
        "Modular Audio",
        "audio processing",
        "Real-Time Modular Audio",
        "Audio",
        "patch",
        "sound",
        "Sphinx MMOS Oscillators",
        "Sphinx",
        "MMOS",
        "Games Frank Luchs",
        "sample",
        "Processing"
      ],
      "concepts": [
        "patch",
        "patches",
        "modules",
        "modulations",
        "modulation",
        "modulated",
        "modulates",
        "noise",
        "audio",
        "frequency"
      ],
      "similar_chapters": [
        {
          "book": "Game Programming Gems 2",
          "chapter": 55,
          "title": "Segment 55 (pages 536-543)",
          "relevance_score": 0.62,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 7",
          "chapter": 61,
          "title": "Segment 61 (pages 593-600)",
          "relevance_score": 0.56,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 2",
          "chapter": 52,
          "title": "Segment 52 (pages 506-515)",
          "relevance_score": 0.53,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 7",
          "chapter": 40,
          "title": "Segment 40 (pages 372-380)",
          "relevance_score": 0.52,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 8",
          "chapter": 53,
          "title": "Segment 53 (pages 511-519)",
          "relevance_score": 0.52,
          "method": "api"
        }
      ]
    },
    {
      "number": 66,
      "title": "Segment 66 (pages 618-618)",
      "start_page": 618,
      "end_page": 618,
      "detection_method": "topic_boundary",
      "content": "638 Section 6 Audio\n\n2. Write a plug-in containing C++ classes using the Sphinx base interface,\nIGAProcessor, and load your plug-in along with the original Sphinx\nMMOS plug-in.\n\n3. Use the system as is, and only create new patch files.\n\nConclusion\n\nThis gem has provided insight into how to combine modular audio processing and\nprocedural generation of sounds to procedurally generate various vehicle sounds for\ngames. The main difference between real-time procedural audio and conventional\nplayback systems is the complexity management and the responsiveness of the\nprocessed sounds to the game context. The combination of samples sequenced at\naudio rate in conjunction with traditional synthesis techniques lets you build spectac-\nular sound transformations for your interactive applications.\n\nReferences\n\n[Ackermann94] Ackermann, Philipp, “Design and Implementation of an Object-ori-\nented Media Composition Framework.” available online at hwtp://citeseer.nj.\nnec.com/ackermann94design.html, 1994.\n\n[Burk01) Burk, Phil and Ross Bencina, “PortAudio - An Open-Source Cross-Plat-\nform Audio API,” available online at http://www.portaudio.com, 2001.\n\n[GENRef] Generator by Native Instruments, available online at hetp://www.native-\ninstruments.net/.\n\n[MAXRef] MAX / MSP by Cycling 74, available online at hitp://www.cycling74.\ncom/index.html.\n\n[PD Ref] Puckette, Miller, “Pure Data Dot Org,” available online at http://www.pure-\n\nta.org/,.\n\n[Rabin0O] Rabin, Steve, “Classic Super Mario 64 Third-Person Control and Anima-\ntion,” Game Programming Gems 2, Charles River Media, Inc., 2001.\n\n[Sim-Schmitz99] Sim, Ben and Fredric Schmitz, “Acoustic Phasing and Amplifica-\ntion Effects of Single-Rotor Helicopter Blade-Vortex,” Proceedings of the 55th\nAnnual National Forum American Helicopter Society, 1999.\n\n[Smith91] Smith, Julius O., “Viewpoints on the History of Digital Synthesis,” Pro-\nceedings of the International Computer Music Conference, October 1991: pp. 1-10.\n\n[Visiomedia] Updates to the Sphinx MMOS system, available online at hetp://\nwew.visiomedia.com/rooms/labor!/stc/sphinxmmos/index hem.\n\n[Wang99] Wang, Geng, “Prediction of Rotorcraft Noise with a Low-Dispersion\nFinite Volume Scheme,” available online at http://www.ae.gatech.edu/-Isankar/\n\nERT/ 1999.",
      "page_number": 618,
      "chapter_number": 66,
      "summary": "This chapter covers segment 66 (pages 618-618). Key topics include audio, available, and sounds. Write a plug-in containing C++ classes using the Sphinx base interface,\nIGAProcessor, and load your plug-in along with the original Sphinx\nMMOS plug-in.",
      "keywords": [
        "online",
        "Sphinx base interface",
        "Sphinx MMOS system",
        "Section",
        "Sphinx",
        "online at http",
        "Audio",
        "Sphinx MMOS",
        "Media Composition Framework",
        "Sphinx base",
        "original Sphinx",
        "Charles River Media",
        "plug-in",
        "American Helicopter Society",
        "Classic Super Mario"
      ],
      "concepts": [
        "audio",
        "available",
        "sounds",
        "helicopter",
        "games",
        "pure",
        "playback",
        "media",
        "procedural",
        "files"
      ],
      "similar_chapters": [
        {
          "book": "Python Microservices Development",
          "chapter": 12,
          "title": "Segment 12 (pages 90-98)",
          "relevance_score": 0.54,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 2",
          "chapter": 55,
          "title": "Segment 55 (pages 536-543)",
          "relevance_score": 0.51,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 7",
          "chapter": 61,
          "title": "Segment 61 (pages 593-600)",
          "relevance_score": 0.49,
          "method": "api"
        },
        {
          "book": "Building LLM Powered Applications",
          "chapter": 26,
          "title": "Segment 26 (pages 211-218)",
          "relevance_score": 0.47,
          "method": "api"
        },
        {
          "book": "Game Programming Gems 7",
          "chapter": 50,
          "title": "Segment 50 (pages 487-494)",
          "relevance_score": 0.47,
          "method": "api"
        }
      ]
    }
  ],
  "pages": [
    {
      "page_number": 1,
      "chapter": null,
      "content": "Contents\n\nForeword... cc ccc cee eee eee ees xi\nPreface... ccc cece een eee ee ee ee ae xv\nAcknowledgments. ....0cc0cuscuneeneeneeeeueee en eeeneeeee xix\nAbout the Cover Image ........000c0unues vem eee eee eee xxi\nContributor Bios .......... ee ee ee ee xxiii\n\nSECTION 1 GENERAL PROGRAMMING .......0.ccen eens nenenaee f\n\n1.1\n\n1.2\n\n1.3\n\n1.4\n\n1.5\n\n1.6\n\n1.7\n\n1.8\n\nIntroduction 2... cee eee eee eee eee eee\n\nKim Pallister\n\nScheduling Game Events ........000 cence eee eee e eee eee 5\nMichael Harvey and Carl Marshall\n\nAn Object-Composition Game Framework .........:0ceccuauaen 15\nScott Patterson\n\nFinding Redeeming Value in C-Style Macros ..... ween eee e eee 26\nSteve Rabin\n\nPlatform-Independent, Function-Binding Code Generator ........ 38\nAllen Pouratian\n\nHandle-Based Smart Pointers .......000ccceeasneuewereneneee 44\nBrian Hawkins\n\nCustom STL Allocators ......0cccceecnauen Cane e ce eeeneee ». 49\nPete Isensee\n\nSave Me Now! ........000: eee w eee tenes vuwnuas seueneeat ss SO\nMartin Brownlow\n\nAutolists Design Pattern...... wee eee eee 64\nBen Board",
      "content_length": 1053,
      "extraction_method": "OCR"
    },
    {
      "page_number": 2,
      "chapter": null,
      "content": "1.9\n\nContents\n\nFloating-Point Exception Handling ........00000e0ncnunen ents s 69\nSoren Hannibal\n\nProgramming a Game Design-Compliant Engine Using UML .......73\n\nThomas Demachy\n\nUsing Lex and Yacc To Parse Custom Data Files ....... 2.0005 122283\nPaul Kelly\n\nDeveloping Games for a World Market ........0.0.0:: eee neeneas 92\nAaron Nicholls\n\nReal-Time Input and Ulin 3D Games .......00000esneneneuuen 109\nGreg Seegert\n\nNatural Seiection: The Evolution of Pie Menus .....-..00e00005 117\nDon Hopkins\n\nLightweight, Policy-Based Logging ........00::020008 saeeneans 129\nBrian Hawkins\n\nJournaling Services .......00s0een0neee re ee e212 136\nEric Robert\n\nReal-Time Hierarchical Profiling ........0000eceneeuneuaue ents 146\n\nGreg Hyjelstrom and Byon Garrabrant\n\nSECTION 2 MATHEMATICS ..... ccc eee cee eee ees 1G\n\n2.1\n\n2.2\n\n2.3\n\n2.4\n\n2.5\n\nIntroduction ........ seen eee eee eee wean a2. 155\nJohn Byrd\n\nFast Base-2 Functions for Logarithms and\n\nRandom Number Generation ...... seen eee eee eee ... 157\nJames McNeill\n\nUsing Vector Fractions for Exact Geometry ........ seen een aaee 160\nThomas Young\n\nMore Approximations to Trigonometric Functions ..... aunenenaentZO\nRobin Green\n\nQuaternion Compression ......000sn0ecnennaens ee seeen tees 187\nMark Zarb-Adami\n\nConstrained Inverse Kinematics ......000neccenerenncncenaee 192\nJason Weber",
      "content_length": 1327,
      "extraction_method": "OCR"
    },
    {
      "page_number": 3,
      "chapter": null,
      "content": "2.6\n\n2.7\n\nCellular Automata for Physical Modeling ............000n00008 200\nTom Forsyth\n\nCoping with Friction in Dynamic Simulations ........... nese 215\nMiguel Gomez\n\nSECTION 3 ARTIFICIAL INTELLIGENCE .......0ccnennewe nen eel\n\n3.1\n\n3.2\n\n3.3\n\n3.4\n\n3.5\n\n3.6\n\n3.7\n\n3.8\n\nIntroduction .......:. cane eee Se ee sna 229\nSteven Woodcock\n\nOptimized Machine Learming with GoCap .......e000seeaneuun 231\nThor Alexander\n\nArea Navigation: Expanding the Path-Finding Paradigm ......... 240\nBen Board and Mike Ducker\n\nFunction Pointer-Based, Embedded Finite-State Machines ....... 256\nCharles Farris\n\nTerrain Analysis in an RTS—The Hidden Giant ........ ee ean anes 268\nDaniel Higgins\n\nAn Extensible Trigger System for Al Agents,\n\nObjects, and Quests .......0.0008 vanes Cee eee ee 22 285\nSteve Rabin\n\nTactical Path-Finding with A* ........0..0055 wenaeae eeu eenees 294\n\nWilliam van der Sterren\n\nA Fast Approach to Navigation Meshes .........::5 wesnenas »..307\nStephen White and Christopher Christensen\n\nChoosing a Relationship Between Path-Finding and Collision ..... 321\nThomas Young\n\n4.1\n\n4.2\n\nIntroduction ....ccc cen n eee ee eneesens rr 2. 335\nJeff Lander\n\nT-Junction Elimination and Retriangulation ......... ee eanaas .. 338\nEric Lengyel\n\nFast Heightfield Normal Caiculation ........0.0000ncevunnunae 344\n\nJason Shankel",
      "content_length": 1316,
      "extraction_method": "OCR"
    },
    {
      "page_number": 4,
      "chapter": null,
      "content": "viii\n\n4.4\n\n4.5\n\n4.6\n\n4.7\n\n4.8\n\n4.9\n\n4.12\n\n4.13\n\n4.14\n\n4.15\n\nContents\n\nFast Patch Normals ......00ccn en enee nnn e eens 349\nMartin Brownlow\n\nFast and Simple Occlusion Culling ..... 2.002000 eseeseeeraeras Bod\nWagner T.: Corréa, James T. Klosowski, and Claudio T. Silva\n\nTriangle Strip Creation, Optimizations, and Rendering .......... 359\nCarl S. Marshall\n\nComputing Optimized Shadow Volumes for Complex Data Sets ...367\n\nAlex Vlachos and Drew Card\n\nSubdivision Surfaces for Character Animation ........000000008 372\nWilliam Leeson\n\nImproved Deformation of Bones ......0ccceerseennenenanesees OOF\nJason Weber\n\nA Framework for Realistic Character Locomotion ........: veae s 394\n\nThomas Young\n\nA Programmable Vertex Shader Compiler .......ccn0ecunaunae 404\nAdam Lake\n\nBillboard Beams ........0000000:8 Pr ee 413\nBrian Hawkins\n\n3D Tricks for Isometric Engines .......000c0nnnennennneennes 417\nGreg Snook\n\nCurvature Simulation Using Normal Maps .......:2022202202022 424\nOscar Blasco\n\nMethods for Dynamic, Photorealistic Terrain Lighting ........... 433\nNaty Hoffman and Kenny Mitchell\n\nCube Map Lighting Techniques .........0ccnneucennnnananen 444\nKenneth L. Hurley\n\nProcedural Texturing ..... eee eee eee eenee seve censneneeas 452\nMike Milliger\n\nUnique Textures .....00000008 er re 459\nTom Forsyth\n\nTextures as Lookup Tables for Per-Pixel Lighting Computations . . . 467\nAlex Vlachos, John Isidoro, and Chris Oat\n\nRendering with Handcrafted Shading Models .........:..: want 477\nJan Kautz",
      "content_length": 1488,
      "extraction_method": "OCR"
    },
    {
      "page_number": 5,
      "chapter": null,
      "content": "SECTION 5 NETWORK AND MULTIPLAYER .....nc scene nnn nnnee 485\n\n5.1\n\n5.2\n\n5.3\n\n5.4\n\n5.5\n\n5.6\n\n5.7\n\n5.8\n\n5.9\n\nIntroduction ........; eneneenee eee wen eee e nee s 487\nAndrew Kirmse\n\nMinimizing Latency in Real-Time Strategy Games ...... ee neneee 488\nJim Greer and Zachary Booth Simpson\n\nReal-Time Strategy Network Protocol ....... ee eee eee eee 496\nJan Svarovsky\n\nA Flexible Simulation Architecture for\n\nMassively Multiplayer Games .........05e0005 ene e eens 506\nThor Alexander\n\nScaling Multiplayer Servers ...... enna ene e tees eae s O20\nJustin Randall\n\nTemplate-Based Object Serialization ..... enneae een ewer eee 534\nJason Beardsley\n\nSecure SocketS ..... 2c cece eee eee eee eee 546\nPete Isensee\n\nA Network Monitoring and Simulation Tool ..... ene enee 2... 557\nAndrew Kirmse\n\nCreating Multiplayer Games with DirectPlay 8.1 .........+:++.:561\nGabriel Rohweder\n\nWireless Gaming Using the Java Micro Edition .......2:0.000008 573\nDavid Fox\n\nSECTION 6 AUDIO eee weet DOS\n\n6.1\n\n6.2\n\n6.3\n\nIntroduction .......00.05 se neeene ee »... 585\nScott Patterson\n\nAudio Compression with Ogg Vorbis .......... ee ee 587\nJack Moffitt\n\nCreating a Compelling 3D Audio Environment ..........:5 enna 595\nGarin Hiebert\n\nObstruction Using Axis-Aligned Bounding Boxes ....... see eeae es 600\n\nCarlo Vogelsang",
      "content_length": 1289,
      "extraction_method": "OCR"
    },
    {
      "page_number": 6,
      "chapter": null,
      "content": "6.4\n\n6.5\n\n6.6\n\n6.7\n\nContents\n\nUsing the Biquad Resonant Filter ........ weneas ween e eee 606\nPhil Burk\n\nLinear Predictive Coding for Voice Compression and Effects ..... 613\nEddie Edwards\n\nThe Stochastic Synthesis of Complex Sounds .......0200000085 622\nPhil Burk\n\nReal-Time Modular Audio Processing for Games .......0.:00008: 630\nFrank Luchs\n\nAppendix: About the CD-ROM ........c00ceeeennewnuueewenee 639",
      "content_length": 405,
      "extraction_method": "OCR"
    },
    {
      "page_number": 7,
      "chapter": null,
      "content": "ON THE CD\n\nScheduling Game Events\n\nMichael Harvey and Carl S. Marshall,\n\nIntel Labs\n\nmichael.harvey@intel.com,\ncarl.s.marshall@intel.com\n\nMets events in a game—animation updates, object collisions, and so forth—\ncan be a daunting task if there is no clear understanding of how the events are\norganized and executed. This gem will explain how a scheduler can provide both\norganization and flexibility to your game framework.\n\nWe will begin by describing what a scheduler is and why it is useful, and end with\nadvanced topics on scheduler development. A simple scheduler is provided as source\ncode on the CD-ROM.\n\nWith the growing sophistication of computer games, real-time events and simu-\nlations are virtually a standard in today’s game architectures. What is needed is a way\nto manage and execute multiple events per frame, or many times within a frame's\ntimestep. A scheduler can manage game events in a very flexible fashion, as well as\nfacilitate a modular approach for extensibility.\n\nA few examples of game technologies that can effectively utilize a scheduler are\nphysics simulations, character animation, collision detection, game AI, and render-\ning. A key aspect in all of these technologies is time. Many of these simulation tech-\nnologies can become enormously complex, with hundreds of independent objects and\nprocesses being updated at various time intervals. For instance, a physics simulation\nwill break down time into small, discrete intervals for each object in order to update\nthe object’s motion [Bourg01]. By providing a finer resolution of time, the simulation\nwill have a much higher degree of accuracy. In this case, many objects and time inter-\nvals are managed by the same scheduling code, so efficiency is a vital concern in pre-\nventing scheduling bottlenecks.\n\nAnother important aspect of the scheduler is its ability to add and remove objects\non the fly. This allows for new entities to come into a game and participate in the sim-\nulations along with the rest of the game’s entities without missing a beat, and then be\nremoved from scheduling when they are no longer needed.",
      "content_length": 2107,
      "extraction_method": "OCR"
    },
    {
      "page_number": 8,
      "chapter": null,
      "content": "Scheduler Concepts\n\ntime = 10\n\nSection 1 General Programming\n\nThe basic components of the scheduler are a task manager, an event manager, and a\nclock (see Figure 1.1.1). With these components, the scheduler can generate time- or\nframe-based events and execute event handlers. Throughout this gem, we will refer to\n\nevent handlers as tasks.\n1) Event Manager ( Task Manager q\n\nFIGURE 1.1.1. Basic scheduler architecture.\n\nTask Manager\n\nThe task manager handles the registration and organization of tasks. Each task has a\nstandardized interface that contains a callback function for the manger to execute. The\ntask manager maintains a list of tasks, along with scheduling information about each\none—such as start time, execution frequency, duration, priority, and other required\nproperties. It might also contain a user-data pointer or performance statistics.\n\nEvent Manager\n\nThe event manager is the heart of the scheduler. Each task in the task manager defines\none or more events that it handles. An event is a moment in time when a task is to be\nexecuted. For example, in Figure 1.1.2, Task1 defines events at times 10 and 15. The\nevent manager generates events as needed to trigger the execution of tasks.\n\nReal-Time Versus Virtual Time\n\nA real-time scheduler is fairly simple in concept—the event manager sits in a loop.\nwatches a real-time clock, and as soon as a target time is reached, it fires an event. In\na real-time system, latency is critical. If a task takes too long, then it might interfere\n\nwee newer est wwwene\n\nTask1\nnext_time = 10\nperiod = 5\n\nGet Next Task = Task1\n\n@ Task1 next_time = 10\npdate Clock\n\n@ clock time = task time = 10\nExecute Task\n\nUpdate Task next time\n\n@ new_time = 15\n\nExecute(t = 10)\n\nTask2\nnext_time = 12\n\nperiod = 20\n\neee ee ee ens\n\nFIGURE 1.1.2 Event processing.",
      "content_length": 1800,
      "extraction_method": "OCR"
    },
    {
      "page_number": 9,
      "chapter": null,
      "content": "with the start of the next task. Since each task occurs exactly at its scheduled time, the\ntime between tasks is essentially wasted from the scheduler’s frame of reference.\n\nFrom the task’s point of view, time is only a number. Times can be compared, and\nelapsed time can be computed, based on this comparison number. The scheduler can\nsimulate a given time or the passage of time by manipulating this number, indepen-\ndent of real-time—hours can pass in the blink of an eye, or time can be halted. This\nis the basis of virtual time.\n\nVirtual time is extremely useful because it allows the scheduler to execute tasks\nwhen it is most convenient to do so, instead of when real-time dictates. It allows a\nsequence of events to be run quickly forward, stopped, recorded, and replayed. It also\nmakes it possible to debug a ‘real-time’ application by stepping one interval at a time.\n\nA virtual time scheduler divides time into frames. Tasks are executed in batches\nbetween frames, running in ‘virtual time,’ and then are synchronized with real-time\nwhen each frame is rendered. If the frame rate is high enough, the illusion of real-time\nis achieved. However, a few dozen milliseconds between frames is a lot of time for the\ncomputer, especially if it is managed efficiently. By batching all tasks together into a\nsingle block, the remaining time can be used for something else (see Scalability).\nLatency issues can be almost eliminated.\n\nWe'll refer to virtual time as simulation time in this gem, since all objects within\nthe simulation use it as a reference. If simulation time is stopped, then simulation\npauses as well. When it resumes, objects in the simulation do not detect any break in\ncontinuity. Simulation time starts at zero at the beginning of the simulation.\n\nTasks are executed sequentially while simulation time is updated between tasks.\nAs an example, assume each frame has a length of 20 ms (see Figure 1.1.3). If we have\nevents that occur at 51 ms and 54 ms, then they will be processed during Frame 2.\nThe event manager does not know how long Frame 2 is until it has ended; so at the\nbeginning of Frame 3, it looks at real-time and sees 60 ms. It can now process the\ntasks scheduled for Frame 2. Task] is the first, at 51 ms; but the simulation clock is\nstill at the beginning of Frame 2. The clock is advanced to 51 ms and Task] is exe-\n\nFrame 2 - Real-Time Frame 3 - Real-Time\n\n40ms 51ms 54ms 60ms\n\nStart Frame End Frame Start Frame\n\n<Task’ ‘<Task2> kRender> een eee ee eee\n\n40ms 51ms 54ms 60ms\n\nFrame 2 - Simulation Time Frame 3 - Simulation Time\nFIGURE 1.1.3 The difference between real-time and simulation time in Frame 2.",
      "content_length": 2643,
      "extraction_method": "OCR"
    },
    {
      "page_number": 10,
      "chapter": null,
      "content": "Section 1 General Programming\n\ncuted. Once Task1 is done, the clock is advanced to the next event at 54 ms and Task2\nis executed. No more events are scheduled for this frame, so the clock is set to the end\nof the frame (60 ms) and the frame is rendered. (If you are using an offscreen buffer,\nthe frame was probably already rendered, and this is merely copying the image to the\ndisplay.) Any unused time can be used for additional processing (see Scalability on\nhow to use those extra processing cycles).\n\nIn this model, task execution and frame rendering always lag slightly behind real-\ntime. But this is not perceptible to the viewer, and it allows us to work with a variable\nframe rate. If the frame rate slows down, the scheduler can compensate so that the\nsimulation appears to run at a constant rate. If the frame rate is fixed, the scheduler\ncan predict the start and end times, and perform event processing in advance. How-\never, if the machine becomes significantly overloaded, the scheduler cannot compen-\nsate, and the game will become slower.\n\nEvent Types\n\nFrame events are the simplest types of events and occur once per NV frames, or every\nframe (N = 1). They can also occur before or after the render event. Time events, on\nthe other hand, occur in simulation time and are not specifically synchronized with\nframes. For example, a time event can occur every 10 ms, regardless of the rendering\nframe rate. It is also possible to combine time events and frame events. For example,\nan event could be scheduled to occur 10 ms after the start of every frame, or it could\nexecute five times per frame, evenly distributed in simulation time.\n\nClock\n\nThe clock component of the scheduler keeps track of real-time, the current simulation\ntime, and the frame count. The accuracy of the clock will determine the accuracy of\nthe simulation—a 1-ns resolution clock will be much more accurate than a 1-ms res-\nolution clock. For most purposes, 1-ms resolution is adequate. If greater resolution is\nrequired, one could use the 1-ms hardware clock and subdivide the real-time ticks as\nneeded to increase the resolution. A floating-point clock could be used as well.\nalthough careful attention would have to be paid to dealing with rounding errors.\n\nSequencing\n\nThe event manager handles the sequencing and generation of events. Since tasks are\ntriggered by events, proper ordering occurs naturally. For example, let’s define two\n\ntasks:\n\nTaskI: | Run every 5 ms from 5 to 15, normal priority.\n\nTask2: Run every 4 ms from 11 to 19, high priority (see Table 1.1.1).In some\ncases, tasks might be set to execute at the same time. In the example,\nboth Task1 and Task2 execute at time 15. Since Task2 has higher\npriority than Task], it is executed first. If priorities are equal, or no",
      "content_length": 2779,
      "extraction_method": "OCR"
    },
    {
      "page_number": 11,
      "chapter": null,
      "content": "1.1 Scheduling Game Events 9\n\nTable 1.1.1 Task Execution Order\n\nTime Task\n\n5 ms Task1\n10 ms Task1\n11 ms Task2\n15 ms Task2\n15 ms Task1\n19 ms Task2\n\npriority system is implemented, they are handled round-robin. Priority is also\nuseful for ordering frame-based tasks.\n\nTask Manager Details\n\nWith hundreds of potential tasks, the task manager must manage things intelligently.\nA brute-force search for the next task is clearly not very efficient. While many meth-\nods are possible, the example programs on the CD-ROM make use of an ordered list.\nThe tasks are stored in a list according to their next execution time—the head of the\nlist is always the next task to be executed. The event manager only needs to look at the\nfirst task to determine when the next event should occur. When an event occurs, the\nforemost task is ‘popped’ off the list and executed, its next time is updated, and it is\nre-inserted into the list according to its updated execution time.\n\nBesides avoiding lengthy searches, this approach also has the advantage that fre-\nquent tasks stay close to the front of the list (almost like a cache). Infrequent tasks stay\nout of the way and ‘bubble up’ automatically at the proper time.\n\nIt is often the case that a registered task must be modified on the fly, which might\ninvolve adjusting its priority, period, duration, or even deleting it before it is finished.\nIn order to update a task, there must be some external means to locate it. A unique\nregistration ID can be assigned to locate the task in the list.\n\nwill demonstrate how a simple scheduler can be built and utilized. Code for the exam-\nples provided can be found on the CD-ROM. The provided sample scheduler\n(Scheduler, Clock, and ITask) can also be used as a library. Two sample clients are pro-\n\nvided (sample.exe and win.exe).\n\nThe scheduler’s design hinges on two components—the scheduler engine itself and\nthe ITask plug-in interface (see Figure 1.1.4).",
      "content_length": 1934,
      "extraction_method": "OCR"
    },
    {
      "page_number": 12,
      "chapter": null,
      "content": "10 Section 1 General Programming\n\nClock\n\nEvent Manager\n\nFIGURE 1.1.4 Relationship between scheduler components and client application.\n\nIn order for the scheduler to run, someone needs to call it. In a non-GUI pro-\ngram, this is as simple as coding a loop and executing:\n\nwhile (running)\nscheduler.ExecuteFrame();\n\nThere are two ways to integrate a scheduler into a message-pump GUI, such as\nWindows. The first is by modifying the message loop to process messages and then\nexecute the scheduler. This is the most obvious approach, but it suffers from sched-\nuler ‘freezes’ while a window is being resized.\n\nThe second approach is to create a Windows timer, and use that to call the sched-\nuler. Since timers are not interrupted by window dragging, the scheduler runs contin-\n\n_ uously in the background. A sample application (Win) has been provided on the\n© 5 CD-ROM that shows how to use a scheduler in a Windows application. Let’s look at\nonmie co this application more closely.\n\nThe core Windows code is quite simple. The scheduler is run off a WM_TIMER mes-\nsage and has two types of scheduled events. One updates the position of each ball\nevery 15 ms, while the render event writes all the balls to an offscreen buffer. Win-\ndows can then paint the screen from this offscreen buffer on an as-needed basis. The\nsimulation and rendering occur without any special Windows programming. This\nexample demonstrates the use of multiple simulation tasks and adding/removing tasks\non the fly.\n\nOften, games have frame rates that vary, depending on system capacity and load.\nyet the velocity of moving objects remains constant. While both sample applications\nhave a fixed frame rate, the provided scheduler does support this constant velocity\ntechnique. The key is in the Clock.Update() method that samples the actual real-time\nand advances the simulation by the elapsed time. If an object moves N units in 60 ms.\nit does not matter whether the system renders two 30-ms frames or three 20-m:\nframes—the object moves the same distance in the same real-time, so the velocity is",
      "content_length": 2069,
      "extraction_method": "OCR"
    },
    {
      "page_number": 13,
      "chapter": null,
      "content": "1.1 Scheduling Game Events 11\n\nconstant. If you wish to have the velocity of simulated objects increase or decrease\nwith the frame rate, change the Clock.Update() method so that it advances in fixed\nintervals, instead of reading the real-time clock.\n\nSo, how does the scheduler manage time, anyway? We need to register some\nevents and see how it works.\n\nScheduling\n\nThe first step in scheduling a task is to specify it as a time event, a frame event, or a\nrender event. This code will schedule a frame event that starts on Frame 200, runs\nevery third frame, and ends before Frame 210 (start 200 + duration 10):\n\nscheduler.Schedule(TASK_FRAME, 200, 3, 10,\npSomeHandler, pUserPointer, &id);\n\nThis task would run on Frames 200, 203, 206, and 209. After executing the final\niteration, the task expires and is deleted by the task manager. Tasks with duration 0\nare perpetual and never expire. In certain cases, you might want to remove a task\nbefore it is complete, or you might want to manually end a perpetual task. To do this,\nyou Terminate() it using the task ID.\n\nHow does the frame get updated? Each time the scheduler ExecuteFrame()\nmethod is called, it first calls Clock. BeginFrame(), which starts a new frame by updat-\ning the frame count and computing new frame start and end times. After updating\nthe frame count, it executes all time events, advances the simulation time to the end\nof the frame, executes all frame events, and then finally executes the render task. (In\nthe sample scheduler, the render task is a special frame task that does not have a start,\nperiod, or duration—It always executes once per frame.)\n\nThe entire simulation can be stopped or restarted using the Run() and Stop()\nmethods. When the scheduler is stopped and then restarted, it computes the elapsed\ntime and subtracts it from the total simulation time. While stopped, the scheduler\nstill performs renders and frame events, but time events are suspended.\n\nAdvanced Concepts\n\nenn RRA LSE SERIES SEE PO OT ET LER ee\n\nThere are a number of ways in which the scheduler can be improved or better utilized.\nScalability, simulation and multithreading are a few of these methods.\n\nScalability\n\nA common problem in game development is scalability. The game should take advan-\ntage of all the available processing power to provide a richer experience, but it still\nneeds to function well on less-powerful systems. Computationally expensive features\nneed to be throttled down or turned off completely. The game should also ‘play well’\nin a multitasking environment—a game that utilizes most of the CPU might prevent\nthe OS from responding to user input in a timely manner. In addition, if the OS",
      "content_length": 2669,
      "extraction_method": "OCR"
    },
    {
      "page_number": 14,
      "chapter": null,
      "content": "Section 1 General Programming\n\nlaunches any housekeeping tasks in the background, it could slow the game down.\nIdeally, the game should adjust dynamically to the conditions of the system.\n\nCollecting the performance data is half the battle. Since the scheduler can\nbecome a bottleneck by handling all processes, it is a perfect place to put performance\nmonitors.\n\nAs described earlier, the clock takes a snapshot of the current time and compares\nit to the last frame to determine elapsed time. The scheduler can also determine the\nelapsed time of each task by comparing the start time to the end time. This informa-\ntion can either be communicated to the task, or it can be used to determine whether\nor not to run the task and/or how often.\n\nOne way to provide scalability is to require time budgets—the more power, the\nmore time allowed. A task might have a ‘time budget’ per frame. The scheduler tracks\nthe accumulated budget and the accumulated running time, and only executes the\ntask if the current budget exceeds the actual time. For example, a task might have a\ntime budget of 2 ms per frame, but it runs in 3 ms on a slow CPU. The scheduler will\nskip every third frame in order to keep the task within its budget (see Table 1.1.2).\n\nTable 1.1.2 Time Budget Per Task\n\nFrame # Budget Actual\nFrame 1 2 3\nFrame 2 4 6\nFrame 3 6 —\nFrame 4 8 9\n\nSome tasks might have a time budget ‘threshold’—if they exceed their budget.\ninstead of running part of the time, they do not run at all. The scheduler can also\ndetermine the time needed to perform the entire simulation by summing all of the\ntasks. The difference between processing time and frame length is idle time. Ideally, the\ngame should use all the available time to improve gameplay, but should not use mor\nthan what is available, or the frame rate will slow down. The scheduler can add tasks tc\nfill idle time or remove tasks to reduce the load. (There must, of course, be some way\nto specify which tasks can safely be added or removed.) By supplying overall systerr\nusage statistics to tasks, the tasks can then scale themselves to use more or less time\nbased on the data received. It is probably best to have a 5% to 10% idle target to allow\nfor minor fluctuations in actual processing time without slowing things down.\n\nOther options that provide scalability include increasing or decreasing of time\nbudgets, scheduling of idle tasks (which only run during idle time), garbage collectioz\nor other housework, graphics enhancements, or improvement of the AI. When doing\nthis type of management, it is important to avoid oscillation between extremes. Thr\ncan be done by limiting adjustments to small incremental changes rather than larg:",
      "content_length": 2692,
      "extraction_method": "OCR"
    },
    {
      "page_number": 15,
      "chapter": null,
      "content": "1.1 Scheduling Game Events 13\n\njumps, or by statistical analysis of the effect of previous adjustments in order to\nimprove prediction.\n\nSimulation\n\nThe scheduler can be used to drive a simulation system. Most simulation engines\nbreak time down into discrete steps for purposes of animation and collision detection.\nThe scheduler described in this gem is perfect for this type of simulation system.\n\nIn a simple example of a lunar lander, the lander has a vertical velocity and a for-\nward velocity. Each timestep adds gravity. If we use AI to control the vertical thruster\nof the lander, then at each timestep, the AI samples velocity and adjusts thrust to\ncompensate, allowing for a controlled descent. The timesteps need to be small enough\nto give the AI time to react—otherwise the lander will hit the ground before it can\nrespond effectively. For collision detection, again, you want small timesteps so that\nthe lander will intersect the surface rather than passing completely through it.\n\nMultithreading\n\nIt is possible for the scheduler to manage the execution of subthreads [Carter01, Daw-\nson01]. There are many reasons why you might wish to do this. For example, some\ntasks might work better as a continuous process rather than a series of discrete events\n[Otaegui01]. Such tasks can be written as a thread, and the scheduler can control how\nmuch time the thread is allowed for processing. This approach allows true preemptive\nmultitasking while actually enforcing a time budget.\n\nMultiprocessing systems are slowly becoming more common, and it is likely that\nmultiprocessing will become a standard feature in the near future. Games that are able\nto take advantage of multiple processors will be able to outperform games written for a\nsingle CPU. An easy way for a game to utilize multiple CPUs is to make it mulkti-\nthreaded and let the OS do the work of distributing the threads on available processors.\n\nA multi-CPU scheduler could activate several threads at once so that they could\nrun concurrently. It could also spawn event handlers into specific threads so that mul-\ntiple events can be handled concurrently.\n\nof simulations. A quality scheduler needs to be flexible and efficient. This gem has\ncovered some of the basic scheduler concepts, has provided a sample scheduler, and\nhas shown how to integrate it into conventional and GUI-based applications. Help\norganize your events by using a scheduler in your next game.\n\nReferences .\n[Bourg01] Bourg, David M., Physics for Game Developers, O'Reilly, 2001.\n[Carter01] Carter, Simon, “Managing AI with Micro-Threads,” Game Programming\nGems 2, Charles River Media, Inc., 2001.",
      "content_length": 2640,
      "extraction_method": "OCR"
    },
    {
      "page_number": 16,
      "chapter": null,
      "content": "Section 1 General Programming\n\n[Dawson01] Dawson, Bruce “Micro-Threads for Game Object AI,” Game Program-\nming Gems 2, Charles River Media, Inc., 2001.\n\n[Llopis01] Llopis, Noel, “Programming with Abstract Interfaces,” Game Program-\nming Gems 2, Charles River Media, Inc., 2001.\n\n[Mirtich00] Mirtich, Brian, “Timewarp Rigid Body Simulation,” Computer Graph-\nics Proceedings, SIGGRAPH 2000: pp. 193-200.\n\n[Otaegui01] Otaegui, Javier, “Linear Programming Model for Windows-Based\nGames,” Game Programming Gems 2, Charles River Media, Inc., 2001.",
      "content_length": 541,
      "extraction_method": "OCR"
    },
    {
      "page_number": 17,
      "chapter": null,
      "content": "1.2\n\nAn Object-Composition\nGame Framework\n\nScott Patterson, Next Generation\n\nEntertainment\n\nscottp@tonebyte.com\nscott@gameframework.com\n\nhis gem will present a design for a game framework based on object composition\n\nand explain its advantages and design philosophy. We will present reasons why\nthis kind of framework can be useful for implementing the work required for games.\n\nThis game framework can serve as a reference for your own game systems. You\ncan create new systems with the capabilities that you need and create new tasks that\nperform the actions that you need.\n\nWhen we talk about a programming framework, we are referring to a system of\nobjects that work together to provide certain services. An application framework is a\ncollection of classes that provide the services necessary for creating applications. Our\ngoal in this gem is to find out what kind of framework we can build to help create\ngame.applications.\n\nThere are good reasons to use a framework to build an application. Getting some-\nthing running quickly is a primary reason. Time is money, after all. Frameworks typ-\nically contain built-in features, consistent behavior and structure, and well-known\nrules for object access, object ownership, and object lifetimes.\n\nIn this gem, we first summarize game development stages to get an overview of\nthe work that is required. We then discuss the game framework design issues. Finally,\nwe present an overview of the game framework implementation provided on the\n\nCD-ROM.\n\nshows a listing of typical game development stages and identifies the typical goals at\neach stage.\n\n15",
      "content_length": 1598,
      "extraction_method": "OCR"
    },
    {
      "page_number": 18,
      "chapter": null,
      "content": "16\n\nSection 1 General Programming\n\nTable 1.2.1 Typical Goals During Game Development\n\nStage Goal\n\nConcept Design of functionality and aesthetics. Creation of character, story, and mission\nconcepts.\n\nPrototype Demonstration of key gameplay elements through proof-of-concept demos.\nDemonstration of technology.\n\nPlayable Demonstration of at least one mission or level being played from start to finish.\n\nProduction Completion of designs and implementation for all missions and levels.\n\nWrapping Integration of various game modes and screens. Includes stoty segments, training,\nmission/level selection, win/lose, status/scores, save/load, pause/restart, options/\nconfiguration.\n\nTesting Solving design and implementation problems. Solving compatibility issues.\nIntegration of alternate drivers.\n\nRelease Shipping the game on its first platform. Party!\n\nConversion Alternate language versions. Alternate platforms.\n\nDuring the early stages (concept, prototype, playable), the choice of framework\nmight be focused on getting the program running quickly. At this time, it is quite pos-\nsible that the framework does not seem as important as creating the demonstration of\nconcepts. However, if the framework is not also designed to be useful for the other\nstages of game development, then you might find yourself losing time to refactoring.\n\nDuring the production stage, tools such as viewers and editors become essential.\nViewers are necessary for developers to see how their content looks “in the game.”\nEditors are required for developers to make adjustments to any aspect of the game.\nWhile these kinds of tools can be separate from the game application, it is often\nrequired for viewer and editor capabilities to be incorporated into the game. To do\nthis, there must be code for the “consumer” aspect as well as for the “developer”\naspect. The goal is to build a framework that leverages the shared components of these\nfeatures, yet allows them to be developed independently.\n\nDuring the wrapping stage, we must integrate the various game modes and\nscreens into one seamless product. This integration sometimes suffers from schedul-\ning delays or restructuring of the original design. Having a framework to help manage\nthese game modes and screens, and even the transitions between them, will help this\nprocess go more smoothly.\n\nDuring the testing stage, we might need the ability to start the game in various\nmodes or at certain points within the game. We want our framework to provide this\nkind of flexibility to make it easy to define these various modes and entry points. We\nmight also want to include the ability to switch between drivers while inside the\ngame. If our framework binds a particular type of video technology to our applica-\ntion, switching video drivers would not be possible. Whether we provide driver-\nswitching or not, we can add logging capabilities to our framework to aid the process\nof compatibility testing.",
      "content_length": 2934,
      "extraction_method": "OCR"
    },
    {
      "page_number": 19,
      "chapter": null,
      "content": "1.2 An Object-Composition Game Framework 17\n\nAfter we reach the release stage, the game team might go on to do conversions of\nthe game, or it might be shipped off to other developers to do the conversions. Either\nway, if our framework is hard to port to another platform, it will cause delays. We\nwould rather have the conversion team spend their time putting in new features and\nenhancements for each platform, rather than spend their time struggling to get it\nworking.\n\nGame Framework Design\n\nNow that we have an idea of the kind of work required to make games, we can look at\nthe design issues in creating a framework. We will cover platform dependence, game\ndependence, object composition, inheritance, frame-based code, function-based\ncode, operation order, object lifetimes, and task integration.\n\nPlatform-Independent Versus Platform-Dependent\n\nGames are usually filled with many concepts that transcend operating systems and\nplatform technologies. These concepts determine the player's enjoyment through\n“gameplay” and “depth.” Conversely, games are also commonly written to take advan-\ntage of specific hardware features that help identify the presentation quality. This pre-\nsentation quality is often responsible for extending a game's feeling of “immersion.”\n\nFrameworks need not be bound to operating systems and technologies. We can\ndefine platform-independent system interfaces for our framework rather than plat-\nform-dependent system interfaces. Even though these interfaces are platform-inde-\npendent, we can use a factory system to create the concrete implementations for\nspecific platforms.\n\nThe more we can separate the game's conceptual work from platform specifics,\nthe easier it will be to replace only the platform-specific code for conversions. So, part\nof our goal in creating a game framework is making it easy to keep game concepts\nindependent of the operating system and platform technology details whenever possi-\nble or practical.\n\nGame-independent Versus Game-Dependent\n\nIf we want to use a framework for many games, it makes sense to have the framework\nbe game independent. However, if we are going to use a framework for a single game\non several platforms, it might be acceptable to have portions of the framework be\ngame dependent.\n\nFor example, if our game controls a specific type of character that has many\ndynamic visual details that depend on the character's state, we might want the render-\ning code to access game-specific states and decide how the object should be rendered.\nThis kind of situation can reduce the number of system interface calls, which simpli-\nfies and speeds up the code.",
      "content_length": 2633,
      "extraction_method": "OCR"
    },
    {
      "page_number": 20,
      "chapter": null,
      "content": "18 Section 1 General Programming\n\nObject Composition Versus Inheritance\n\nOne way to make an application framework intuitive is to use the template method\ndesign pattern, and create objects that are a subclass of an application class. When we\ndo this, we treat application initialization and destruction as algorithms that sub-\nclasses can redefine. This kind of design pattern is called “class behavioral” because it\nuses inheritance to distribute behavior between classes.\n\nAnother way to define the steps of application initialization and destruction\n(without inheritance) is to define these steps as a list of tasks to process. A task system\nclass can coordinate task execution, and a resource system can reference and manage\nthe task lists and task objects. Now we are “object behavioral” because we are using\nobject composition and our resource system as our mediator for these objects.\n\nUsing a task system like this means that we can now build a framework based on\nobject composition rather than inheritance. Our task system controls task objects\nthrough their interfaces, and our tasks perform work by calling object interfaces. This\nalso means that our framework will not have the typical inverted control structure\nthat is a result of the template method. Instead, our task objects control the software.\nPerhaps this is an object framework rather than a class framework, but it is a frame-\nwork nonetheless.\n\nThe Design Patterns book [GoF94] discusses many advantages of object composi-\ntion. It also highlights two principles of object-oriented design:\n\n¢ Program to an interface, not an implementation.\n¢ Favor object composition over class inheritance.\n\nFrame-Based Versus Function-Based Operation\n\nThere are many types of software that are not concerned with frame timing, where\nfunctions may take seconds, minutes, or even longer to complete. This function-\nbased operation can be much easier to program than frame-based operation.\n\nMost games must be visually and aurally responsive, with many animations and\ndetails being calculated every frame. Each time a visual image and/or audio buffer is ren-\ndered, we have created a frame. Games may be rendered at speeds up to 50 or 60 frames\nper second. This kind of frame-based operation requires game software to execute in\nshort spurts of time. Ifa lengthy operation (over 1/60th of a second) is to be performed,\nit must be broken into shorter pieces or be performed as a background task.\n\nFor our framework, frame-based operation will require a frame system class that\ncan tell our task system class when to call frame-synchronized tasks. Our task system\nwill also be able to process tasks that are not frame-synchronized, which we will call\n“asynchronous tasks.”\n\nSince the frame system controls when to call frame-synchronized tasks, we can\nalso offer the ability to manually step through frames and choose particular frame\nrates. This can be useful for checking animation playback details as well as for other\ndebugging and testing purposes.",
      "content_length": 3008,
      "extraction_method": "OCR"
    },
    {
      "page_number": 21,
      "chapter": null,
      "content": "1.2 An Object-Composition Game Framework 19\n\nDynamic Versus Static Operation Order\n\nThere are many types of software operations that need to be done in a specific order.\nFor these operations, we must call functions in a particular order or submit tasks in a\nspecific order to our task system. This is an example of static operation order.\n\nGames are normally filled with various screens and transitions that are not typi-\ncally connected in a specific order. Instead, the player's actions determine what hap-\npens next. This is an example of dynamic operation order.\n\nFor our framework, we can provide dynamic operation order by enabling task\nobjects to access the task system interface and submit new tasks.\n\nDynamic Versus Static Object Lifetimes (and\nOwnership Issues)\n\nIn hierarchical systems, we might find that base objects own certain objects that are\nused by inherited objects, while inherited objects can create objects that the base\nobjects know nothing about. Often the lifetimes of such objects are built into the\nhierarchy, and inherited objects cannot dynamically create and delete them. The life-\ntimes of these objects are static in this sense.\n\nIn an object-composition framework, it could be confusing to know when a par-\nticular object owns another object. To resolve this, we can assign object ownership to\nour resource system. This way, any task can connect with system resources as needed\nand not be given management responsibilities. We give our resource system the power\nof object ownership and our tasks the power of object access, which limits the confu-\nsion over ownership issues.\n\nWe can make the lifetimes of these objects dynamic by having tasks issue com-\nmands to our resource system. We can direct the resource system to load and dump\nobjects in collections. For example, a load collection command can be issued before\ntasks that need the loaded objects are started. A dump collection command can be\nissued after those tasks are finished. Alternatively, we can have objects around for the\nentire lifetime of the application.\n\nHorizontal Versus Vertical Integration of Tasks\n\nIn hierarchical systems, it might seem like we are always “under” other objects that\ncontrol us and that our relationship with those objects is “fixed.” Tasks feel vertically\narranged, and changes to higher parts of the system can have far-reaching effects on\nthe operation of lower parts of the system.\n\nIn object-composition framework, it might seem like our programming environ-\nment is “flat” and our relationships with certain objects is more “dynamic.” Tasks feel\nhorizontally arranged, and changes to certain tasks in the system will have little or no\neffect on other tasks in the system.",
      "content_length": 2704,
      "extraction_method": "OCR"
    },
    {
      "page_number": 22,
      "chapter": null,
      "content": "Game Framework Implementation\n\nie a SR NR RE SER CHS PRR MPA SS SA ARTA IH NAG AG RNMTR BRR SISSON SE HOM IS BEN ATTEN BARRONS SINTRA\n\nNow we present an overview of the implementation of our framework that meets\nthese challenges. The framework is composed of systems and tasks. A special kind of\ntask called the “frame player” provides high-level control of audio-visual rendering\nand logic.\n\nSystems\n\nThe Systems_t class contains pointers to the pure interfaces [Stroustrup97] of the sys-\ntems that our game will use. We choose to provide access to these systems through\npure interfaces so that dynamic system switching is possible and platform-dependent\nsystem code is separated from the platform-independent code that accesses the sys-\ntems. The interfaces available in the Systems_t class are summarized in Table 1.2.2.\n\nTable 1.2.2 The Interfaces Available in the Systems_t Class\n\nSummary\n\nLogSys_t Handles all message logging from the game. Optional output types include\ntext boxes or files.\n\nErrorsys_t Handles error information and states.\nTimeSys_t Reports timing information.\nFactorySys_t Creates objects using Factory IDs.\nResourceSys_t Manages object instances using Instance IDs.\nTaskSys_t Manages task execution and control.\nWindowSys_t Provides window system management and control.\nFrameSys_t Provides frame synchronization services and control.\nInputSys_t Provides input device management and control.\nVisualSys_t Provides visual system management and control.\nAudioSys_t Provides audio system management and control.\nNetworkSys_t Provides network system management and control.\n\nEach system has an Init (Systems_t *pSystems) and a Shutdown() method. Pass-\ning the Systems_t pointer to the objects allows them to access any of the system inter-\nfaces. Including the Systems_t class does not create compiler dependencies on the\nsystems code because the systems are accessed through pointers that only require for-\nward references. This is important, as Systems_t pointers are used in many of the\nframework’s classes. Reducing physical dependencies is an important goal of good\nphysical design {Lakos96].\n\nBecause each of these systems is defined as a pure interface that hides all imple-\nmentation details, we can dynamically switch system implementations as long as\nthose implementations do not have static link dependencies. The break-up of depen-\ndent implementations into dynamically loadable components is an example of the\n\npackages pattern [Noble01].",
      "content_length": 2473,
      "extraction_method": "OCR"
    },
    {
      "page_number": 23,
      "chapter": null,
      "content": "1.2 An Object-Composition Game Framework\n\n21\n\neitieninnemnnimsintcmeaa mate IIE Lai eNrmaseninmeatteniny Ace et Sckcatrn tn SNC Neen in ih nnn ne LONER NO a IEEE HE\n\nThe source code on the CD-ROM demonstrates how to dynamically switch\nvisual systems. This is done using dynamic link libraries, each of which provides dif-\nferent implementations of the VisualSys_t interface. Here is an example of how to\ncontrol the switch of visual systems:\n\nFactorySys t *pFS = m_pSystems->GetFactorySys();\n\npFS->DeleteVisualSys( m_pSystems->GetVisualSys() );\npFS->SetVisualSysDriver1ID( m_nVisualSysDriverID );\nm_pSystems->SetVisualSys( pFS->CreateVisualSys() );\n\nTasks\n\nThe TaskSys_t class provides an interface to the task system. Using the\nPost_TaskCommand function, we can post a task as either a frame-synchronized task or\nan asynchronous task. The only difference is when the tasks are called. Frame-syn-\nchronized tasks are called when the frame system reports that it is time to run the next\nframe. Asynchronous tasks are called in each loop of the task system.\n\nPost_TaskCommand allows us to add and remove tasks at any time. Here is an\nexample of how to post task commands to stop the current asynchronous task and\nstart a frame-synchronized task:\n\n// get the task system\n\nTaskSys_t *pTaskSys = m_pSystems->GetTaskSys();\n\n// get the resource system\n\nResourceSys_t *pResSys = m_pSystems->GetResourceSys();\n\n// remove the current asynchronous task\npTaskSys->Post_TaskCommand( ASYNC_REMOVE, this );\n\n// get the new task to start\n\nTask_t *pTask = pResSys->GetTask( INSTANCE_ID_TASK_INTRO );\n// push back the new frame-synchronized task\npTaskSys->Post_TaskCommand( FRAMESYNC_PUSH_BACK, pTask );\n\nHere we see that we can access any task using its instance ID by calling\nthe resource system’s GetTask function. Tasks are passed to the Systems_t pointer\nwhen they are connected to the system via the task’s Connect (Systems_t *pSystems)\nfunction.\n\nLayers\n\nThroughout the game development process, there is typically a great amount of work\nassociated to visual rendering design. Rendering can be managed in a high-level man-\nner using a layer system. The importance of a layer system comes into play when the\ngame screen is rendered in a layered fashion. For example, during a 3D game, we\nmight have the world rendered as one layer and perhaps game objects as another layer,\nand then a “heads-up display” as a third layer. We want the ability to push new layers\nonto the scene and have them appropriately affect visuals, audio, and input-handling\nlogic.\n\nTo control layers of visual screens, audio data, and input-handling logic, we intro-",
      "content_length": 2626,
      "extraction_method": "OCR"
    },
    {
      "page_number": 24,
      "chapter": null,
      "content": "22 Section 1 General Programming\n\nduce a special kind of task called the FramePlayer_t. This task is intended to be\nframe-synchronized and manages audio-visual-layer (AVLayer_t) objects and logic-\nlayer (LogicLayer_t) objects.\n\nAudio-visual-layer objects are called each frame as follows:\n\n// Update AV Layers\nfor( each audio-visual layer (forward-order) )\n{\nAVLayer_t *pAVL = contents of iterator;\npAVL ->Update() ;\n}\n\n// Begin Render Visual\nif( m_pSystems->GetVisualSys()->BeginRender() )\n\n{\nfor( each audio-visual layer (forward-order) )\n{\nAVLayer_t *pAVL = contents of iterator;\npAVL->RenderVisual{) ;\n}\nm_pSystems ->GetVisualSys() ->EndRender();\n}\n\n// End Render Visual\n\n// Begin Render Audio\nif ( m_pSystems->GetAudioSys()->BeginRender() )\n\n{\nfor( each audio-visual layer (forward-order) )\n{\nAVLayer_t *pAVL = contents of iterator;\npAVL ->RenderAudio();\n}\n\nm_pSystems ->GetAudioSys() ->EndRender () ;\n\n}\n// End Render Audio\n\nWe can see that each audio-visual layer is updated first with an Update() call.\nThis is when the audio-visual objects are updated, depending on their state of anima-\ntion. Following this update call, we render the visuals and audio.\n\nLogic-layer objects are called each frame as follows:\n\n// Update Logic Layers\nfor( each logic layer (reverse-order) )\n\n{\nLogicLayer_t *pLL = contents of iterator;\npLL->Update();\nif( pLL->IsExclusive() ) break;\n\n}\n\nWe can see that each logic layer is simply updated with an Update() call. While\naudio-visual-layer updates are meant to handle animation, logic-layer updates are\nused to handle game logic and player input.",
      "content_length": 1584,
      "extraction_method": "OCR"
    },
    {
      "page_number": 25,
      "chapter": null,
      "content": "work\n\n1.2 An Object-Composition\n\nSince the logic layers are processed in reverse, and since they stop processing if\nthey're marked exclusive, the last logic layer in the m_LogicLayerPtrList can “over-\nride” previous logic layers. So, pushing back a logic layer can exclusively change the\nway player input is handled, such as is required for game menus, viewers, and editors.\nIn contrast, if we push forward a new audio-visual layer, we only add a new set of\nitems to display and hear.\n\nJust as the task system has task commands, the FramePlayer_t class has layer\ncommands. Here is an example of how to post layer commands:\n\nAVLayer_t *pAVL;\n\nLogicLayer_t *pLL;\n\n// get the resource system\n\nResourceSys _t *pResSys = m_pSystems->GetResourceSys() ;\n\n// get the task to modify\n\nTask_t *pTask = pResSys->GetTask( INSTANCE_ID_TASK_INTRO) ;\n// we know it is a frame player\n\nFramePlayer_t *pFP = (FramePlayer_t *)pTask;\n\n// push back an audio-visual layer\n\npAVL = pResSys->GetAVLayer (INSTANCE_ID_AVLAYER_INTRO) ;\npFP->Post_AVLayerCommand(PUSH_BACK, pAVL);\n\n// push back a logic layer\n\npLL = pResSys->GetLogicLayer (INSTANCE_ID_LOGICLAYER_INTRO) ;\npFP->Post_LogicLayerCommand(PUSH_BACK, pLL) ;\n\nHere we see that we can get any audio-visual layer using its instance ID by calling\nthe resource system’s GetAVLayer function. Similarly, we can get any logic layer using\nits instance ID by calling the resource system’s GetLogicLayer function. Layers are\npassed to the Systems_t pointer when they are connected to the system via the layer’s\nConnect (Systems_t *pSystems) function.\n\nWith this layer system, we can now change audio-visual layering dynamically. All\nof the various game modes and screens mentioned in the wrapping stage can be\nimplemented using layer and task commands. For example, we can push back\nan audio-visual layer for a “heads-up display” when needed. Similarly, we can push\nback audio-visual and logic layers for floating menus. When creating new modes and\nscreens, we have the option of editing the layering of our frame-player task using the\nlayer commands, or we can switch between frame-player tasks using the task com-\nmands mentioned earlier.\n\nFinally, a sophisticated use of layer and task manipulation is in transitions. Items\non one game screen (the first audio-visual layer) can be gradually covered by items of\nanother game screen (the second audio-visual layer). When the transition is complete\nand only the second layer is visible, the first layer can be removed from audio-visual\nprocessing.\n\nSource Code\n\nPec 8 REET\n\nThe CD-ROM includes source code to the game framework implementation and\nsome additional documentation. The code with this book is meant to highlight game\n\nON THE CD",
      "content_length": 2707,
      "extraction_method": "OCR"
    },
    {
      "page_number": 26,
      "chapter": null,
      "content": "Section 1 General Programming\n\nframework concepts and not game technology concepts. Code updates will be avail-\nable at http://www.gamefgramework.com. Figure 1.2.1 illustrates the modes, tasks,\nand layers that are implemented in the source.\n\nMode Task Audio-Visual Layers Logic Layers\n\nInfo\n‘o) Intro Enter ——+(2)\nNew Game—>{:3\nIntro Intro\n(Start Menu}\n\nLoad Game —>{ 5 )\nRestore Game +6)\nGame\nConfiguration\n\nSystem\nConfiguration\n\n©) Game Game\n(Pause Menu}\n\nEscape —€)\nD307, D3D8, OpenGL —-@\n\nFIGURE 1.2.1 Using the game framework: An example of how game modes can be\nimplemented using tasks, audio-visual layers, and logic layers.",
      "content_length": 631,
      "extraction_method": "OCR"
    },
    {
      "page_number": 27,
      "chapter": null,
      "content": "1.2 An Object-Composition Game Framework 25\n\nReference 7\n\n[Boer00] Boer, James, “Object-Oriented Programming and Design Techniques,”\nGame Programming Gems, Charles River Media, Inc., 2000: pp. 8-19.\n\n[Boer00] Boer, James, “Using the STL in Game Programming,” Game Programming\nGems, Charles River Media, Inc., 2000: pp. 41-55.\n\n[GoF94] Gamma, E., et al., Design Patterns: Elements of Reusable Object-Oriented\nSoftware, Addison Wesley Longman, Inc., 1994.\n\n[Lakos96] Lakos, John, Large-Scale C++ Software Design, Addison Wesley Longman,\nInc., 1996.\n\n[LlopisO1] Llopis, Noel, “Programming with Abstract Interfaces,” Game Program-\nming Gems 2, Charles River Media, Inc., 2001: pp. 20-27.\n\n[Meyers96] Meyers, Scott, More Effective C++, Addison Wesley Longman, Inc., 1996.\n\n[Meyers98] Meyers, Scott, Effective C++, Second Edition, Addison Wesley Longman,\nInc., 1998.\n\n[Meyers01] Meyers, Scott, Effective STL, Addison Wesley Longman, Inc., 2001.\n\n[Noble01] Noble, James, Small Memory Software: Patterns for Systems with Limited\nMemory, Addison Wesley Longman, Inc., 2001.\n\n[Stroustrup97] Stroustrup, Bjarne, The C++ Programming Language, Third Edition,\nAddison Wesley Longman, Inc., 1997.\n\n[Vlissides98] Vlissides, John, Pattern Hatching: Design Patterns Applied, Addison Wes-\n\nley Longman, Inc., 1998.",
      "content_length": 1295,
      "extraction_method": "OCR"
    },
    {
      "page_number": 28,
      "chapter": null,
      "content": "1.3\n\nON THE CD\n\nFinding Redeeming Value in\nC-Style Macros\n\nSteve Rabin, Nintendo of America, Inc.\nsteve@aiwisdom.com\n\nhe lowly C-style macro (#define) is a powerful construct that is severely misun-\n\nderstood. Many people and books characterize it as evil and outdated, replaced by\nthe inline functionality in C++. Unfortunately, that’s a simplistic view that doesn’t\ntake into account the unique functionality that the macro possesses. Shamefully,\nmany C++ books fail to explain the basic properties of macros or even acknowledge\ntheir existence. However, solid explanations can still be found in classic C books such\nas [Kernighan88].\n\nIn a nutshell, the macro is a directive to the compiler’s preprocessor to do some\ncreative text replacement. Thus, no type-checking or other safety checks take place,\nand this is where many programmers get into trouble. As a simple rule, macros\nshouldn't be used to create function-like behavior or constants. For a discussion of the\npitfalls of macros, please refer to [Dalton01], [Hyman99], and [McConnell93].\n\nHowever, this gem isn’t about the problems with macros; it’s about proving that\nmacros are useful and desirable in many surprising ways. Macros allow you to per-\nform fancy text replacement before actual compilation, and that’s exactly what the fol-\nlowing tricks exploit. Note that the source code that appears in each example can also\nbe found on the CD-ROM.\n\nDisclaimer\n\nRR ae eRe eR cRNA ee ASG ARR RP NE IEA MA SN HERE HT\n\n26\n\nWith macros, it’s easy to be carried away into a world o\nHowever, that’s not the intention of this gem. While individuals have their own\nboundaries as to what is acceptable, it is generally understood that making new\ndialects of C/C++ by using macros is undesirable. Anyone coming onto a project\nshould be able to read your code with a minimal amount of effort. So, as you read\nthese tricks, understand that each one must be carefully weighed for its benefit versus\nthe possibility of obfuscation. Confined use of these examples is probably the most\nreasonable way to benefit from this gem.",
      "content_length": 2073,
      "extraction_method": "OCR"
    },
    {
      "page_number": 29,
      "chapter": null,
      "content": "1.3 Finding Redeeming Value in C-Style Macros 27\n\nof a macro. The first operator is #, and it will instruct the macro to put quotes around\nthe argument that follows it. For example:\n\n#define CaseEnum(a) case(a): LogMsgToFile(#a, id, time)\n\nswitch( msg_passed_in )\n\n{\nCaseEnum( MSG_YouWereHit );\n\nReactToHit();\nbreak;\n\nCaseEnum( MSG_GameReset );\nResetLogic();\nbreak;\n}\n\nAfter the compiler’s preprocessing step, the previous code becomes:\n\nswitch( msg_passed_in )\n{\ncase( MSG_YouWereHit ):\nLogMsgToFile( “MSG_YouWereHit”, id, time );\nReactToHit();\nbreak;\n\ncase( MSG_GameReset ):\nLogMsgToFile( “MSG_GameReset\", id, time );\nResetLogic();\nbreak;\n}\n\nWith this macro scheme, you can easily dump enum names in a reliable and\nmeaningful way, as actual strings, to a log file or the screen. Without this trick, you\nwould need to have a lookup table of all enums-to-strings. Unfortunately, lookup\ntables are often poorly maintained and, thus, not reliable. The other solution is to use\nstrings in the first place, instead of enums, but it’s doubtful you would want to per-\nform routine string compares inside your game. Therefore, the macro trick is a sound\nsolution that is both fast and reliable.\n\nAnother variant is to read in the enumeration from a header file and interpret the\nsingle list into both an enumeration and an array of string names. The following\nshows how this can be done:\n\n// data.h\nDATA(MSG_YouWereHit )\n\nDATA(MSG_GameReset )\nDATA(MSG_HealthRestored)",
      "content_length": 1460,
      "extraction_method": "OCR"
    },
    {
      "page_number": 30,
      "chapter": null,
      "content": "28 Section 1 General Programming\n\n// data.cpp\n#define DATA(Xx) x,\nenum GameMessages\n\n#include \"“data.n\"\n35\n\n#undef DATA\n#define DATA(x) #x, // make enums into strings\n\nstatic const char* GameMessageNames[] =\n\n{\n#include \"data.h\"\n\n}3\n\n#undef DATA\n\nMacro Trick #2: Compile-Time Constants from\nBinary Representations\n\nThe other special macro operator is ##. This operator lets you paste two arguments\ntogether. For example:\n\n#define cat(a,b) a ## b\nvalue = cat( 1, 2 );\n\nThe preprocessor will turn the previous line into:\nvalue = 12;\n\nWhile this simple example is useless (shown just to illustrate the concept), the ##\noperator can be exploited in very interesting ways. The following trick allows you to\ncreate compile-time constants using binary representations. What is especially inter-\nesting is that this runs completely in the preprocessor with no runtime code gener-\nated. (Special thanks to Jeff Grills who provided this implementation.)\n\nHere's the usage:\n\nBINARY1 (0101); // 0x5\nBINARY2(1010,0101); // Oxa5d\n\nconst int nibble\nconst int byte\n\n// Oxa5a5a5a5\nconst int dword = BINARY8(1010,0101,1010,0101, 1010,0101,1010,0101);\n\nMacro source:\n\n#define HEX_DIGIT_0000 0\n#define HEX_DIGIT_0001 1",
      "content_length": 1198,
      "extraction_method": "OCR"
    },
    {
      "page_number": 31,
      "chapter": null,
      "content": "1.3 Finding Redeeming Value in C-Style Macros 29\n\n#define HEX_DIGIT_0010\n#define HEX_DIGIT_0011\n#define HEX_DIGIT 0100\n#define HEX DIGIT_0101\n#define HEX_DIGIT_0110\n#define HEX_DIGIT_0111\n#define HEX_DIGIT_1000\n#define HEX_DIGIT_1001\n#define HEX DIGIT_1010\n#define HEX _DIGIT_1011\n#define HEX_DIGIT 1100\n#define HEX DIGIT 1101\n#define HEX_DIGIT_ 1110\n#define HEX DIGIT 1111\n\n>ADADOTMOONAARAN\n\n#define HEX_DIGIT(a) HEX_DIGIT_ ## a\n\n#define BINARY1H(a) (Ox ## a)\n#define BINARY1I(a) BINARY1H(a)\n#define BINARY1 (a) BINARY11 (HEX_DIGIT(a) )\n\n#define BINARY2H(a,b) (Ox ## a ## b)\n#define BINARY2I(a,b) BINARY2H (a,b)\n#define BINARY2(a,b) BINARY2I (HEX_DIGIT(a), HEX_DIGIT(b))\n\n#define BINARY6H(a,b,c,d,e,f,g,h) (Ox##a##b##cH#Hd##eH#THHg#HHh)\n\n#define BINARY8I(a,b,c,d,e,f,g,h) BINARY8H(a,b,c,d,e,f,g,h)\n\n#define BINARY8(a,b,c,d,e,f,g,h) BINARY8I(HEX_DIGIT(a), \\\nHEX_DIGIT(b), HEX DIGIT(c), HEX_DIGIT(d), HEX_DIGIT(e), \\\nHEX_DIGIT(f), HEX _DIGIT(g), HEX DIGIT(h))\n\nMacro Trick #3: Adding a Descriptive Comment to\nStandard Assert\n\nThe standard Windows assert (found in assert.h) is already a macro. It’s extremely\nhelpful, even indispensable to good software engineering—but it can be improved.\nThe biggest improvement is to add a descriptive string so that a meaningful message\nis displayed when an assert is triggered.\n\nWith the following macro, you can easily expand the standard assert to include a\ndescriptive string:\n\nSERCH,\n\n#define assertmsg(a,b) assert( a && b )\n\nExample use:\nassertmsg( time > 0, \"Trigger::Set - The arg time must be > 0\" );\nWhen time is less than or equal to zero, the assert will be raised and the embed-\n\nded message is displayed as part of the failed assertion. You can read more about this\ntrick, as well as other assert tricks, in [Rabin00O].",
      "content_length": 1769,
      "extraction_method": "OCR"
    },
    {
      "page_number": 32,
      "chapter": null,
      "content": "30 Section 1 General Programming\n\nMacro Trick #4: Compile-Time Assert ;\n\nease saridanreeennnnn ata mao ane ire bee REE TR OMI aR Bae ae eR te mee\n\nOccasionally, you'll have a situation where y you want a a build to immediately fail if\na particular condition isn’t satisfied at compile time. Depending on the size of your\nproject, this can save a lot of time and trouble. The following macro allows you to ver-\nify a statement at compile time, which in effect is a compile-time assert.\n\n#define cassert(expn) typedef char __C_ASSERT__[(expn)?1:-1\n\nFor example, if you're working on cross-platform code, you might want to check\nat compile time that enumerations are the same size as an unsigned integer. Given an\nenumeration such as MyEnum, you can check this by writing:\n\ncassert( sizeof(MyEnum) == sizeof(unsigned int) );\n\nIf a false statement is passed into cassert, it will fail at compile time because it\nattempts to define an array with a negative size. Defining a negative-size array is a bla-\ntant compile error that will immediately stop the build.\n\nMacro Trick #5: Determining the Number of\nElements in an Array\n\nisan: Aitkkvabiton stu NNN aM ta RNAse ANNAN een ER RAM a pH TRR EE HERE ASR AROS ABER EN\n\nSometimes it’s useful to know the number of elements in an array. However, there is\nno obvious way to query this, since it is not stored explicitly—only defined at initial-\nization time.\n\nThe trick to computing the number of elements in an array is to divide the over-\nall size of an array by the size of a given element. For example, if the total size of an\narray is 120 bytes and each element takes up 12 bytes, there must be 10 elements in\nthe array. The size of each element, in bytes, is known at compile time, and the fol-\nlowing macro neatly returns the number of elements.\n\nce\n\n#define NumElm(array) (sizeof(array) / sizeof((array)[0]))\n\nMacro Trick #6: Making _ _LINE__\n\n‘SAAR gaa\n\ninto a String\n\nSeveral very useful macros exist by default. These include:\n\n__LINE__ //an integer of the line number where it appears\n\n__FILE__ //a string containing the file name where it appears\n__DATE__ //a string containing the date when it was compiled\n__TIME__ //a string containing the time when it was compiled\n\nThe main use for these macros is to record information that is useful in debug-\nging. For example, when an assert macro is placed in your code, it takes advantage of\nthe _ FILE__ and __LINE__ macros. Should the assert be triggered, these values are\ndisplayed; thus, you know the exact filename and line number where the problem\noccurred.",
      "content_length": 2560,
      "extraction_method": "OCR"
    },
    {
      "page_number": 33,
      "chapter": null,
      "content": "1.3 Finding Redeeming Value in C-Style Macros 31\n\nSince these values are normally used for printing out debugging information as\nstrings, here are several macros to turn the __FILE__ string and the __LINE__ integer\ninto a single string containing both:\n\n#define _QUOTE(x) # x\n#define QUOTE(x) _QUOTE(x)\n#define _FILELINE___FILE__ \"(\" QUOTE(__LINE_) \")\"\n\nThis trick doesn’t work with Microsoft Visual C++, since it replaces __LINE__ dif-\nferently than other compilers. Instead of replacing the macro __LINE__ with a simple\ninteger, it is replaced by (__LINE__Var+offset), where __LINE__Var is an internal vari-\nable that represents the line number where the function starts, and offset is an actual\ninteger representing the offset from the start of the function. Therefore, with\nMicrosoft Visual C++, the macro trick might produce a result like:\n\n\"C:\\project\\main.cpp((__LINE_ _Var+5))\"\n\nHowever, this macro trick produces the desired result with both Metrowerks\nCodeWarrior and SN Systems ProDG (a gcc-based compiler).\n\nMacro Trick #7: Protecting Against Infinite Loops _\n\nThe possibility of an infinite loop often looms over particular parts of your code,\nespecially parts that depend on outside data or scripts. A practical safeguard is to cre-\nate a counter that increments every time through the loop and, if it should get too\nhigh, asserts. That is exactly what this next trick will do, except that it will be done in\na transparent manner that can be optionally compiled out for release builds.\n\nThis trick creates a macro called “while limit,” which behaves similar to the\nwhile keyword; however, it takes a second argument that defines the number of itera-\ntions at which it will raise an assert. For example, consider the following code:\n\nwhile limit( node != 0, 1000 ) {\n//some work\nnode = node->next;\n\n}\n\nThe previous example will assert if the loop spins more than 1,000 times. By rais-\ning an assert instead of hanging, testers can more easily diagnose bugs. As an added\nbonus, if the tester chooses to ignore the assert, the while_limit will exit the infinite\nloop and continue normal program execution.\n\nHere’s the macro source:\n\nstatic bool while_assert( bool a )\n{\n\nassert( a && \"while_limit: exceeded iteration limit\" );\nreturn( a );",
      "content_length": 2250,
      "extraction_method": "OCR"
    },
    {
      "page_number": 34,
      "chapter": null,
      "content": "32\n\nMacro Trick #8: Small, Specialized Languages\n\nSection 1 Generai Programming\n\n#define UNIQUE_VAR(x) safety_limit ## x\n\n#define while_limit(a,b,c) \\\nassert(b>0O && \"while_limit: limit is zero or negative\");\\\nint UNIQUE_VAR(c) = b; \\\nwhile(a && while_assert (--UNIQUE_VAR(c)>=0) )\n\n#define while_limit(a,b) _while_limit(a,b, COUNTER_)\n\nNote that a new default macro, __COUNTER__, is used in the previous code. The\nmacro __COUNTER__ expands to an integer, starting with zero, and increments by one\nevery time it is used. This allows us to create a unique variable each time we use\nwhile_limit. This unique variable is used to keep track of loop iterations. The first\ntime a while limit occurs, the variable’s name will be safety_limito. (The second\ntime, the variable’s name will be safety_limit1.) This unique-naming trick is neces-\nsary so that multiple while_limit macros could be used without their loop-iteration\nvariable names clashing (causing compile errors due to multiple definitions).\n\nThe macro __COUNTER__ is not a standard ANSI C macro and is not implemented\nin all compilers. However, it is implemented in Microsoft Visual C++ and Metrow-\nerks CodeWarrior. For SN Systems ProDG and other gcc compilers, an alternative\ntrick exists by using the __LINE__ macro to help create the unique variable name. The\nfollowing code will work with both SN Systems ProDG and Metrowerks CodeWar-\nrior. (Both variations of while_limit work with Metrowerks CodeWarrior.)\n\nAlternate while_limit macro:\n\nstatic bool while_assert( bool a )\n\n{\nassert( a && \"while_limit: exceeded iteration limit\" );\nreturn( a );\n\n}\n\n#define _UNIQUE_VAR(x) safety_limit ## x\n\n#define UNIQUE_VAR(x) _UNIQUE_VAR(x)\n\n#define while_limit(a,b) \\\nassert(b>0 && \"while limit: limit is zero or negative\"); \\\nint UNIQUE_VAR(__LINE_) = b; \\\nwhile(a && while_assert(--UNIQUE_VAR(__LINE__)>=0))\n\nRN A LR RS IR IR NHN a\n\nMacros can be quite powerful, and this trick probably demonstrates this best. Using\nthe text-replacement property of macros, you can create your own small, specialized\nlanguage that compiles directly into C/C++. Before you jump to conclusions, remem-\nber that we're still striving for readable, maintainable, and debuggable code.\n\nIn the article “Implementing a State Machine Language” (AJ Game Programming\nWisdom (Rabin02)), there is an example of a macro language that standardizes the\nconstruction of state machines and enforces some good programming practices. Con-\nsequently, it makes the state machine easier to build and easier to read. Here is an\nexample of a state machine using the macro language:",
      "content_length": 2591,
      "extraction_method": "OCR"
    },
    {
      "page_number": 35,
      "chapter": null,
      "content": "1.3 Finding Redeeming Value in C-Style Macros 33\n\nBeginStateMachine\n\nState( STATE_Wander )\nOnEnter\n// C++ code for state entry\nOnUpdate\n// C++ code executed every tick\nOnExit\n// C++ code for state clean-up\n\nState( STATE_Attack )\nOnEnter\n// C++ code for state entry\n\nEndStateMachine\n\nWhile the previous code looks like a completely new scripting language, it com-\npiles into C/C++ using only six macro keywords. The benefit is that native C/C++\ncode can be freely inserted, and it is trivial to debug, since the full power of the debug-\nger is still available. Once you understand the behavior of the state machine, the\nmacro language actually hides the unnecessary details and lets you code the internals\nin a simple and natural way.\n\nThe six macro keywords are as follows (OnEvent is a helper—it’s not used\n\ndirectly):\n#define BeginStateMachine if(state < 0){if(0){\n#define EndStateMachine return(true);}}else{assert(0); \\\nreturn(false) ;}return(false) ;\n#define State(a) return(true);}} \\\nelse if(a == state) {if(0){\n#define OnEvent(a) return(true);}else if(a == event){\n#define OnEnter OnEvent (EVENT_Enter)\n#define OnUpdate OnEvent (EVENT_Update)\n#define OnExit OnEvent (EVENT_Exit)\n\nIf you want to explore this macro-scripting language further, please see [Rabin02]\nfor an in-depth explanation.\n\nMacro Trick #9: lifying Cl s Interfaces\n\nOne of the goals of C++ is to separate the declaration of a class from its definition.\nThis is very useful; it allows you to see the interface that a given class exposes—its dec-\nlaration, usually placed in a header file—without having to understand its actual\nimplementation of that functionality (the class definition, usually placed in a .CPP\nfile).\n\nUnfortunately, the way C++ implements the separation of class declaration and\ndefinition ends up causing a fair amount of extra work. Namely, the signature (func-\ntion name and parameters) of every non-inline function must be stated twice, once in\nthe class declaration and once in the definition.",
      "content_length": 1993,
      "extraction_method": "OCR"
    },
    {
      "page_number": 36,
      "chapter": null,
      "content": "34\n\nSection 1 General Programming\n\n// class declaration in Elmo.h\nclass Elmo\n\n{\n};\n\nvoid TickleMe(int x, int y = 0);\n\n// class definition in Elmo.cpp\nvoid Elmo::TickleMe(int x, int y)\n\n{\n}\n\n// actual implementation of Elmo::TickleMe() goes here\n\nBecause the signature of Elmo::TickleMe() exists in two places, every time we\nwish to change the parameters of the method—or change the function’s name, or\nchange it to be const, perhaps—we need to change it in two places.\n\nUsually, this isn’t a big deal. In most cases, a method will belong only to one class,\nand it’s not problematic to change it in only two places. However, there are some cases\nwhere this aspect of the C++ language can cause you a lot of work. And in some situ-\nations it can become very easy to incur subtle bugs when you change a function's sig-\nnature—bugs that your compiler won't be able to warn you about.\n\nFor example, imagine we have a base class named BaseClass. There are three\nclasses derived from BaseClass—D1, D2, and D3. BaseClass declares a virtual function\nFoo(). BaseClass: :Foo() comes with a default implementation in BaseClass; it’s not\na pure virtual function. Further, let’s assume that the derived class D3 overrides Foo(),\nso that D3::Foo() does something different than BaseClass: :Foo().\n\nNow, let’s say we add a parameter to BaseClass: :Foo(), and we forget to update\nD3::Foo() at the same time. Sadly, our compiler will now lose the connection\nbetween BaseClass: :Foo() and D3: :Foo()—it will assume that they are two entirely\ndifferent functions, and that D3::Foo() is an entirely separate function from Base-\nClass::Foo(). When we try to call Foo() as a virtual function on objects of class\nBaseClass, D3::Foo() will not get called on objects of type D3, as we originally\nintended.\n\nIdeally, we want a method’s signature to exist in only one place. It would be nice\nto be able to declare BaseClass::Foo() and provide implementations in both Base -\nClass and D3 without also having to provide an additional declaration of D3: :Foo0().\n\nThere's also an argument in support of productivity: With inheritance in C++, we\noften end up making many shallow class hierarchies with a single parent and many\nchildren. These generally tend to be much more useful than deep, everything-includ-\ning-the-kitchen-sink hierarchies, which attempt to artificially conglomerate many\nunrelated pieces of functionality into a single, massively extended family.\n\nWith shallow hierarchies, we begin with a base class that exists primarily to\ndeclare an interface—that is, it declares some number of virtual functions, most of\nwhich will be pure virtuals. Quite often, we end up with a large number of classes in\nsuch a family, with a single base class and perhaps a dozen other classes derived from\nthat base class. The problem is that we need to redeclare all of the methods we want",
      "content_length": 2857,
      "extraction_method": "OCR"
    },
    {
      "page_number": 37,
      "chapter": null,
      "content": "1.3 Finding Redeeming Value in C-Style Macros 35\n\nto override in all of the derived classes we implement. If we have a base class with 10\nfunctions, and we derive 10 classes from that base class, that’s 100 extra function dec-\nlarations, all of which essentially exist only to say, “I, too, implement the functional-\nity declared in the base class.” All of this extra text can make header files difficult to\nmaintain and hard to read.\n\nLet’s imagine we have a class called Creature, and we intend to derive various dif-\nferent classes of creatures from this base class. Creature defines three pure virtual\nfunctions, as shown:\n\nclass Creature\n\n{\npublic:\nvirtual std::string GetName() const = 0;\nvirtual int GetHitPoints() const = 0;\nvirtual float GetMaxVelocity() const = 0;\n}5\n\nFurthermore, assume we derive several different classes of creature (SnowCrab,\nNordicYeti, and SnowshoeBandit) from this base Creature class. Each of our three\nmethods—GetName(), GetHitPoints(), and GetMaxVelocity()—-now exists in seven\nplaces: once in the declaration of Creature, and once each in the declaration and def-\ninition of SnowCrab, NordicYeti, and SnowshoeBandit.\n\nSo now let's assume we make a minor change and modify GetHitPoints() to\nreturn a float instead of an int. We now have to go and modify GetHitPoints() in\nseven different files—Creature.h, SnowCrab.h, SnowCrab.cpp, NordicYeti.h, Nordi-\ncYeti.cpp, SnowshoeBandit.h, and SnowshoeBandit.cpp.\n\nOne good way to handle this is to wrap the methods into what can be called\nan interface macro. This is a macro that simply declares all of the Creature methods,\nlike so:\n\n#define INTERFACE _Creature(terminal) \\\npublic: \\\nvirtual std::string GetName() const ##terminal \\\n\nvirtual int GetHitPoints() const ##terminal \\\n\nvirtual float GetMaxVelocity() const ##terminal\n\n#define BASE_Creature INTERFACE_Creature(=0; )\n#define DERIVED Creature INTERFACE_Creature(;)\n\nThe beauty of this is that we can now vastly simplify the class declarations of\nCreature and all of the classes derived from it:\n\n// Creature.h\nclass Creature\n{\n\n};\n\n// Skeleton.h\n\nBASE_Creature;",
      "content_length": 2102,
      "extraction_method": "OCR"
    },
    {
      "page_number": 38,
      "chapter": null,
      "content": "36 Section 1 General Programming\n\nSe ee a ke ee ec a es\n\nclass SnowCrab\n: public Creature\n\n{\nhs\n\nDERIVED Creature;\n\n// NordicYeti.h\nclass NordicYeti\n: public Creature\n\n{\n\nDERIVED_Creature;\n}3\n// etc.\n\nNow, whenever we want to change one of the methods in Creature, we no longer\nhave to touch SnowCrab.h, NordicYeti.h, or SnowshoeBandit.h—all we need to\nchange is the interface macro (INTERFACE_Creature in Creature.h). We still need\nto modify the implementations in the various .cpp files; but given that the function is\nchanging, we'd need to do that anyway.\n\nFurthermore, our class declarations have become much more readable. When we\nlook at the class declaration of NordicYeti in NordicYeti.h, we see DERIVED Creature\nplus some number of other methods specific to a NordicYeti and not shared with\nother creatures. This immediately tells us what functionality belongs specifically to\nNordicYeti, and that if we want to see the declaration of the creature-level function-\nality, we should look for it in Creature.h, since that’s where it properly belongs.\n\nIt’s important to note that this interface macro is entirely different from the con-\ncept of an ‘interface’ in a language such as Java or C#. In these sorts of languages, you\ncan treat an interface as an object—you can pass it around as a reference and call any\nof its methods. An interface macro, however, is just a way of encapsulating a set of\nrelated function declarations to hide some of the unnecessary duplication that the\nstructure of the C++ language forces you to maintain.\n\nVery special thanks to Paul Tozour for supplying this macro trick.\n\nConclusion\n\neee\n\nREN REE REY DE REIN ROR UIA\n\nHopefilly, these examples have given you some renewed hope in macros and have\nexpanded your personal toolbox of solutions. Just remember to carefully weigh the\ncost versus the benefit; always strive to make your code easier to understand and more\nrobust. Used judiciously, these macros should make your programming tasks just a lit-\ntle easier and the results a little less prone to error.\n\nReferences\n\n[Dalton01] Dalton, ‘Peter, “Inline Functions Versus Macros,” Game Programming\nGems 2, Charles River Media, Inc., 2001.",
      "content_length": 2179,
      "extraction_method": "OCR"
    },
    {
      "page_number": 39,
      "chapter": null,
      "content": "1.3 Finding Redeeming Value in C-Style Macros 37\n\n{Hyman99] Hyman, Michael, and Phani Vaddadi, Mike and Phani’s Essential C++\nTechniques, APress, 1999.\n\n[Kernighan88] Kernighan, Brian, and Dennis Ritchie, The C Programming Language,\nPrentice Hall, 1988.\n\n[McConnell93] McConnell, Steve, Code Complete: A Practical Handbook of Software\nConstruction, Microsoft Press, 1993.\n\n[RabinOO] Rabin, Steve, “Squeezing More Out of Assert,” Game Programming Gems,\nCharles River Media, Inc., 2000.\n\n[Rabin02] Rabin, Steve, “Implementing a State Machine Language,” AJ Game Pro-\ngramming Wisdom, Charles River Media, Inc., 2002.",
      "content_length": 613,
      "extraction_method": "OCR"
    },
    {
      "page_number": 40,
      "chapter": null,
      "content": "1.4\n\nPlatform-Independent,\nFunction-Binding Code\nGenerator\n\nAllen Pouratian, Sony Computer\nEntertainment RTime\nallenp@csua.berkeley.edu\n\nAree function binding tool scans your C code for function prototypes,\nsigns unique integers to each function, writes out code that hashes the proto-\ntype text names to the integers, and then writes out code for a ‘switch’ to bind these\nintegers to the code that calls the functions.\n\nOnce the code generated by the binding tool is compiled into your program, such\nan interface forms the core of a scripting engine or a network RPC executor without\nthe usual tedious and error-prone maintenance programming.\n\nThis gem is an extension of [Bilas00], from the original Game Programming Gems\n(2000).\n\nYouth and Wisdom\n\nanuassiebineiD\n\n38\n\ni NE area\n\nBack when we were young punks hacking on our first machines, we lacked the wis-\ndom to tweak our software without a rebuild. Later, we wised up a tad and started\nusing command line arguments. Later still, we used option files. Those of you who\nare in-crowd material wrote a tool to make your option files [Rabin00].\n\nNow that we're older punks, we'll design a tool to write the code that handles the\ninternals of calling any function in our programs by text name. For example, it sure\nwould be nice to avoid hard-coding the loading of a level, and script it instead. Also,\nif the design guy orders a new class of enemy bots for your shoot-em-up, wouldn't it\nbe great if the code needed to send the new function calls to the other client machines\nwrote itself automatically?\n\nCygwin\n\nBefore the fine souls at Red Hat published their Cygwin [Cygwin01] package, such a\ncoding stunt was not cheap. The Cygwin libraries allow most POSIX code to build\nand run in Windows 9x/NT/2000/XP environments. Thus, the ancient and venera-",
      "content_length": 1804,
      "extraction_method": "OCR"
    },
    {
      "page_number": 41,
      "chapter": null,
      "content": "ble compiler-generation tools Lex and Yacc, along with grammars and specifications\nfound for free on the Internet [Degener95], mean that everything necessary for pars-\ning C structures, typedefs, and function prototypes is mostly already complete on all\nGNU-supported platforms—complete, that is, on platforms where sufficient clue has\nbeen scraped together to complete the porting task. Since GNU support strengthens\nby the week, genuine versions of Lex and Yacc are there for downloading.\n\nGhost of Gems Past\n\nThe prequel to this gem, ([Bilas00]), thoroughly discussed the issues surrounding var-\nious function-binding mechanisms. Gradually, we were led through the simple yet\nimpractical and painful first and second design attempts. Through the lessons grew\nthe design for an automated and elegant Windows-, x86-, Visual C++ 6.0-specific\nsolution. Specifically, functions tagged for compile-time DLL export were parsed\nfrom compiler-generated export files into a table at runtime. This table then allowed\nthe look-up of function text names for associated IDs and their subsequent execution.\n\nAs we peruse the Lex specification for C [Degener95], we notice #define and\n#include are missing. The C preprocessor handles these and forwards the results to\nthe compiler. Fortunately, the writers of gcc have broken out the preprocessor into a\nseparate utility, called “cpp.”\n\nHere is what we will do. First, take a C module whose functionality you want\nexported, and run it through cpp. Then, for ‘Phase 1’ of this tool, take the product\ngenerated by cpp and extract function prototypes with the tool you will write with\nLex and Yacc. Next, in ‘Phase 2’ of this tool, take these extracted function prototypes,\nassign integer IDs to each of them, and generate C code for a table that associates the\nIDs with the prototypes. In ‘Phase 3,’ we must write out yet more C code for a func-\ntion that resolves function names into IDs, preferably with a ‘move-to-front,’ chain-\ning hash table. Finally, our tool generates a switch statement on said ID, which serves\nup the hard-coded function call with properly cast arguments. Thus, tool-generated\nC code leaves the platform specifics of calling functions to the compiler. Just compile\nand link in the tool-generated C code, and youre ready to go.\n\nOnce we have Lex'd and Yacc'd together our function prototype-reading tool, we\nneed it to shove out some fast C code to bind function text names to IDs. Surpris-\ningly, using a clever ‘move-to-front’ hash-table chaining mechanism [Zobel01] beats\nall trees, including self-adjusting splay trees [Sleator85] by at least threefold! Follow-\ning the Paredo principle, which states that 20% of the data is needed 80% of the time,\nthe most commonly accessed elements are kept at the chain's top.\n\nAfter compiling and linking our tool-generated C code into our games, we are\nready to reap the rewards! We can call our script-execution function on any script file,\nor we can write a new function for our server, and execute it on the server from any\nclient with no coding effort for translation and invocation.",
      "content_length": 3090,
      "extraction_method": "OCR"
    },
    {
      "page_number": 42,
      "chapter": null,
      "content": "40 Section 1 General Programming\n\nKeep in mind that if all you desire is a way to call your C, C++, or Objective-C\nfunctions from scripts written in Perl, Python, or Tcl/TK, then visit www.swig.org.\nSupport for binding yet more languages to C/C++/objective-C code is in the works.\n\nThe Details\n\nse TR td ne aR RINNE 2 SIERRA RIC\n\nThe task of writing tokenizers for compilers surfaces so often that Mike Lesk and Eric\nSchmidt (Bell Labs) decided to write a tool to simplify the task. Review Chapter 1 of\nthe respective O’Reilly book [Levine95] if you need convincing that Lex will cut your\nworkload drastically.\n\nWe use regular expressions [Borsodi01] to express the tokens, and slam out C\ncode to handle each respective expression. Lex handles the dirty work of writing\nC code to extract the token and calls your C code when it’s found. The following Lex\ncode identifies some famous scientists and mathematicians of history:\n\n%{\n\n/* Put any C code here. It need not be a comment. */\n%}\n\n%% [\\t ]+ /* ignore white space */ ;\n\nNewton | newton { printf(\"Issac Newton\\n\") ; }\nPascal | pascal { printf(\"Blaise Pascal\\n\") ; }\nPasteur | pasteur { printf(\"Louis Pasteur\\n\") ; }\n\n[a-zA-Z]+ {printf({\"%s: don't recognize \\n\", yytext); }\n\n\\&.|\\n { ECHO; /* normal default anyway */ }\n\n56%\nmain{)\n{\nyylex()\n}\n\n/* Again, any C code of yours can go here */\n\nBetween the opening %{ and %}, we insert any C code we want at the top of the\ngenerated C code for this Lexer. Then, we nest the tokens we seek to extract between\nthe two %% groupings, followed by bracketed C code that we want executed when the\ndesired Lexeme is found. After the trailing %%, we again insert any C code we need.\n\nFear not, for you can also call functions and declare/assign variables from the C\ncode that follows each regular expression. Just make sure you link the Lex library into\nyour applications. If you use the Unix make utility, this is most commonly done by\nadding -11 to the line that summons the linker.",
      "content_length": 1974,
      "extraction_method": "OCR"
    },
    {
      "page_number": 43,
      "chapter": null,
      "content": "1.4 Platform-iIndependent, Function-Binding Code Generator 41\n\noreo mn nuaireres na eerste tem\n\nYacc in Two\n\nThe engineers of the 1970's Bell Labs were an industrious bunch, so Yacc was written\nto ease the task of writing parsers. Just as English grammar specifies the syntax of Eng-\nlish sentences, we write a grammar for C so Yacc can distinguish a line of C from a\nline of Ada. Here is a simple Yacc grammar that will parse the simplest of English\nsentences:\n\n%{\n\n/* Put any C code here. It need not be a comment. */\n#include <stdio.h>\n\n%}\n\n%stoken NOUN VERB PRONOUN\n\n96%5\nsentence: subject VERB {printf(\"Baby talk!\\n\"); }\n\n5\nsubject: NOUN | PRONOUN ;\n56%\n\n#define ERROR_RETURN( intReturnValue, expression,\nstringExplanation ) \\\nif( expression ) \\\n{ \\\nprintf (\"Function Failure: %s in %s at line\n%d\\n\", stringExplanation, \\\n__FILE_, _LINE_ ) ; \\\nreturn intReturnValue ; \\\n+ \\\n\nextern FILE *yyin;\n\nmain(int argc, char* argv[])\n\n{\n\nFILE *fp ;\n\nERROR_RETURN( 1, argc != 2 , “main-->wrong number of arguments\")\n;\n\nfp = fopen(argv[1], “r\" ) ;\n\nERROR_RETURN( 2, !fp , \"main-->Invalid input\nfile\") ;\n\nyyin = fp ;\nwhile(!feof(yyin) )\n\n{\nyyparse();\n\nfclose( fp ) ;",
      "content_length": 1158,
      "extraction_method": "OCR"
    },
    {
      "page_number": 44,
      "chapter": null,
      "content": "42 Section 1 General Programming\n\n}\n\nyyerror(s)\nchar *s;\n\nfprintf(stderr, “%s\\n\", s);\n}\n\nLike cousin Lex, Yacc allows direct insertion of any C code between %{ and %}\ninto the generated C file. This time, in addition to a C-style comment, we have\narranged for the loading of stdio.h. The words that follow %token designate tokens\nthat the grammar will recognize. Should you choose to use Lex with Yacc, these macro\ndefinitions will be common between your Lex and Yacc specifications.\n\nBetween %% groupings, we describe what are called productions of the grammar,\nwhere the grammar’s syntax is described to Yacc unambiguously. Typically, a pro-\ngrammer will include C code they want executed after a desired production. Follow-\ning the trailing %%, we again include all C code we want to include with the C code\ngenerated by Yacc. There is no need to link in a Yacc library the way we must with\nLex.\n\nduring development. Imagine changing a triggered sound with the change of a named\nWAV file, or any attribute of anything, without a rebuild. Visualize your producer\ndoing this instead, so that you can take time to hunt down another memory leak. If, a\nweek before shipping, someone deems that a game level is too dark—feel your sched-\nule pressure lessen as they adjust one variable at the top of your level-loading script.\n\nAl Directives\n\nIn a Gamasutra article, Charles Guy discussed modeling AI (Artificial Intelligence)\nbiologically with procedural directives [Guy99]. Again, the exported functionality\nallows tweaking by the nontechnical personnel working on the project. AI needs AI\n(Artificial Intervention—Yours!) to function acceptably, and scripts defining such\nbehavior will speed the process and lessen headaches in the long run.\n\nNetworkin\n\nOnce you have function binding integrated into your RPC system, you need\nnot worry about extending functionality when you expand your API. Say we're\nplanning a four-person, peer-to-peer network game, where in order for Player\nA to fire a missile, fire_missile() must be called on computers A, B, C, and D.\nIf the foundation for the calling mechanism on Machine A is laid once in a\ngeneric way using ANSI C variable-length argument lists (which refer to the\naforementioned tool-generated, function prototype table of IDs and encoded",
      "content_length": 2284,
      "extraction_method": "OCR"
    },
    {
      "page_number": 45,
      "chapter": null,
      "content": "1.4 Platform-Independent, Function-Binding Code Generator 43\n\nConclusion _\n\ncern nnn cterreacemoaeenn Himsa:\n\nargument lists), no extra coding effort will be needed to translate and execute\neach new function at the other end of the network pipe.\n\nExporting and binding functions with tool-generated C code can save us lots of work\nin manually binding functions for scripting and RPC engines. Converting tasks that\ntraditionally required programmer modification over to the hands of designers and\nartists helps speed the iterative design cycle significantly.\n\nrete — SER RNR MnemEmRES\n\nReferences\n\n[BilasO0] Bilas, Scott, “A Generic Function-Binding Interface,” Game Programming\nGems, Charles River Media, Inc., 2000.\n\n[Borsodi01] Borsodi, Jan, “Regular Expressions Explained,” available online at\nhetp://www.zez.org/article/articleprint/11/, 2000.\n\n[Cygwin01] http://www.cygwin.com.\n\n[Degener95] Degener, Jutta, “ANSI C Grammar, Lex Specification,” available online\nat http://www.lysator.liu.se/c/ANSI-C-grammar-l.huml, 1995.\n\n[Degener95] Degener, Jutta, “ANSI C Yacc Grammar,” available online at hetp://\nvww.lysator fu se/c/AN SI-C-grammar-y.html, 1995.\n\n[Guy99] Guy, Charles, “A Modular Framework for Artificial Intelligence Based on\nStimulus Response Directives,” available online at http://www.gamasutra.com/\nfeatures/19991110/guy_01.htm.\n\n[Levine95] Levine, Mason, Brown, Lex & Yacc, O’Reilly & Associates, 1995.\n\n[Rabin00] Rabin, Steve, “The Magic of Data-Driven Design,” Game Programming\nGems, Charles River Media, Inc., 2000.\n\n[Sleator85] Sleator, Tarjan, “Self-adjusting Binary Search Trees,” JACM, Vol. 32, No.\n3, July 1985: pp 652-686.\n\n[Zobel01] Zobel, Heinz, Williams, “In-Memory Hash Tables for Accumulating Text\nVocabularies,” available online at http://goanna.cs.rmit.edu.au/-hugh/zhw- ipl.\n\nheml.",
      "content_length": 1814,
      "extraction_method": "OCR"
    },
    {
      "page_number": 46,
      "chapter": null,
      "content": "1.5\n\nHandle-Based Smart Pointers\n\nBrian Hawkins, Seven Studios\nwinterdark@sprynet.com\n\nt any time, an object in a game can die and leave any pointers to that object dan-\n\nling with dangerous consequences. Handles are a common method for prevent-\n\ning these invalid pointers from being used, but handles incur a substantial overhead if\n\nused for every action to be performed on an object. To reduce this overhead, there is\n\noften a conversion provided from a handle to a pointer, but this can lead to accidental\n\nstorage of the raw pointer without any method of tracking its use. A better solution is\n\nto wrap the handle inside a smart pointer. This provides familiar syntax as well as\ngreater safety and debugging options.\n\nA smart pointer is a C++ class that uses syntax similar to a regular pointer, but it\nprovides added functionality that is not normally available to a regular pointer. One\nof the most common jobs performed by a smart pointer is ownership management of\nthe object data. There are many smart pointer implementations available with differ-\nent ownership strategies for each (deep copy, copy on write, reference counting, and\ndestructive copy), and it is important to consider which type is necessary for the task\nat hand. Andrei Alexandrescu provides a good overview of many smart-pointer fea-\ntures in Modern C++ Design [Alexandrescu01].\n\nLet’s consider when to use handle-based smart pointers. First, the object should\nhave a distinct owner that controls when it is destroyed—for example, if the scene\nmanager is the only one allowed to destroy a game object. If there is no distinct owner\nto determine when the object is destroyed, reference counting might be a better\noption. Second, the object’s destruction time should be unknown. A game object that\nis killed by the player is an example of an unpredictable destruction time. If the time\nan object is deleted is certain, it is usually not necessary to incur the overhead of han-\ndles. Finally, handle-based smart pointers are only necessary when several objects need\nto store pointers to the same object, such as four players that each require a reference\nto the same vehicle object. Otherwise, there is most likely a better solution with\nsmaller overhead.\n\nNow that you know when and why to use handle-based smart pointers, we can move\n\non to the details of implementing them safely and efficiently. But first, a description",
      "content_length": 2401,
      "extraction_method": "OCR"
    },
    {
      "page_number": 47,
      "chapter": null,
      "content": "1.5 Handle-Based Smart Pointers 45\n\nof how handlc-bascd smart pointers are used will help in understanding what the\nimplementation is designed to accomplish.\n\nThe first step is to create the object instance and assign the resulting dumb\npointer (the term “dumb pointer” is often used to refer to a built-in pointer type) to a\nsmart pointer. There is no reason to keep the dumb pointer around, so this operation\ncan be performed in one line:\n\nt_HandlePointer<class> 1 _handle(new class);\n\nThe designated owner of the object instance can then assign this handle to any-\none that requires a reference to that instance:\n\nt_HandlePointer<class> 1 handleCopy = 1l_handle;\n\nWhen the object’s lifetime is over, the instance’s owner destroys the object.\nBecause the owner stores a smart pointer, a function is required rather than the delete\noperator (operator delete):\n\ng Destroy(l_handle) ;\n\nUsing a handle pointer is as close to using a dumb pointer as possible. For exam-\nple, the handle pointer can be dereferenced using operator -> or operator*. The han-\ndle pointer can also be checked to determine its validity using the same conditional\nthat would be used to check for a null dumb pointer:\n\nif(l_handle) {\n1_handle->m_Member () ;\n(*1_handle) .m_Member () ;\n}\n\nThis check should always be done if there is a possibility that the object has been\ndestroyed, thus invalidating the handle pointer.\n\nsb ENR RG RN ROR ROHN\n\nThe handle is at the heart of a handle-based smart pointer and therefore must be\nimplemented efficiently. The primary operations that are performed on the handle are\nconversion to a pointer and tests for validity. A very efficient way to convert from\nhandle to pointer is to store the pointer in an array and include the array index as part\nof the handle. The conversion then takes two simple operations to complete: First,\nobtain the index from the handle; and then, look up the pointer in the array using the\nindex.\n\nThe preceding conversion is only valid if the handle is still valid. There must there-\nfore be a method of determining that the contents at the index match the handle used\nfor the conversion. To accomplish this, a unique identifier can be assigned to each han-\ndle and stored with the associated pointer in the array. When the handle is invalidated,",
      "content_length": 2285,
      "extraction_method": "OCR"
    },
    {
      "page_number": 48,
      "chapter": null,
      "content": "46\n\nSmart Pointer\n\nON THE CD\n\nSection 1 General Programming\n\nboth the pointer and unique identifier are removed from the array. Future attempts to\nuse the handle can be detected as invalid because the unique identifier is no longer at\nthat location in the array. Figure 1.5.1 shows a possible layout using this method.\n\nArray of Handle/Pointer Pairs\n\n0 1 2 3\n——O ere) CO eee\n\nHandle | Pointer\n\nUnique ID Array Index\nFIGURE 1.5.1 Example layout for resolving handles to pointers.\n\nWhile there are several methods for generating a unique identifier, a simple\nmethod usually suffices for handles. Simply start with one as the first unique identi-\nfier, and increment by two every time a new unique identifier is requested. The added\nadvantage of this method lies in the fact that zero is never a unique identifier because\nthe one bit is always set. Notice that no mention is made about checking for a dupli-\ncate unique identifier. As long as the bit count of the unique identifier is reasonably\nlarge compared to the number of objects in existence at any one time, the chances\nthat the same identifier will occur at the same location in the array is small enough to\nignore. Preventing the unique identifier from wrapping around will eliminate this\nminute possibility, although it will also limit the total number of objects.\n\nThe smart pointer wraps the handle to provide familiar syntax when using the handle.\nSince there are several good books and articles on all the details of making smart\npointers, we will concentrate on the issues that are specific to handle-based\nsmart pointers. These issues can be broken down into construction, destruction,\ndereferencing, and validation. The sample implementation provided on the CD-ROM\nprovides a fully working example.\n\nConstruction and Destruction\n\nConstructing a smart pointer from a dumb pointer requires the creation of a handle.\nThe constructor passes the dumb pointer to a handle manager in order to create this",
      "content_length": 1962,
      "extraction_method": "OCR"
    },
    {
      "page_number": 49,
      "chapter": null,
      "content": "1.5 Handle-Based Smart Pointers 47\n\netnnsnncoo see eeerlssenestseeoneb A eeaeb OMS NENA eo ANN\n\nhandle. The handle and the dumb pointer, which will be used for validation and\ndereferencing, are then stored in the smart pointer.\n\nThe handle manager is typically a Singleton class [GoF95]—a class with one\nglobal instance. This is necessary to provide a central location for handle/pointer pairs\nfor later handle lookups. The manager also ensures there is only one handle per\npointer, but this comes with a performance penalty. This check can be avoided if a\ndumb pointer is assigned to a single handle-based smart pointer immediately on\nobject creation, and all subsequent use is through the smart pointer or copies of the\nsmart pointer.\n\nNormally, an object is destroyed using the delete keyword; but that is not possi-\nble with smart pointers. One option is to add a member function to the smart pointer\nthat will call delete on the dumb pointer. This can lead to confusing code, however,\nwhen the same variable has operator-> and operator. applied to it. A better alterna-\ntive is to use a friend function that deletes the dumb pointer when given a smart\npointer as an argument. Once the object is deleted, the handle manager must be\ninformed that the handle is now invalid.\n\nValidation\n\nIf there is the possibility that the object was destroyed, the smart pointer must be\nchecked for validity before it is dereferenced. There are two important conditionals\nthat are used when checking a handle-based smart pointer: equality and inequality.\nInternally, both tests must query the handle manager to determine if the handle is still\nvalid.\n\nThe inequality test is a simple matter of overriding operator!, but the equality\ntest requires a little bit more work to prevent strange behavior on the part of the smart\npointer. A simple class must be created that disables operator delete by declaring,\nbut not defining the operator, and then returning a pointer to a global instance of the\nclass from a conversion operator if the handle is valid. Otherwise, the conversion\nfunction can return a null pointer. More information on why this is the preferred\nmethod can be found in Modern C++ Design [Alexandrescu01].\n\nDereferencing\n\nThe most useful feature of a smart pointer comes from the dereferencing operators\noperator-> and operator*. These operators are the reason for keeping a copy of the\ndumb pointer in each smart pointer; this way, we can quickly return the pointer or a\nreference to the object. These operators should be extremely simple and efficient\nbecause they will be the most-frequently used handle-based smart pointer features.\nDebugging versions of these functions can also perform validation of the handle as an\nadded protection against the mistake of the caller not testing the smart pointer before\ndereferencing it.",
      "content_length": 2829,
      "extraction_method": "OCR"
    },
    {
      "page_number": 50,
      "chapter": null,
      "content": "48 Section 1 General Programming\n\nenn AR AAA AAR NAR eR RR cman ea\n\nConclusion\n\nHandle-based smart pointers can be an efficient and powerful technique when used\nwith the right types of objects. The combination of handles and smart pointers sim-\nplifies object management and retains syntax familiar to all programmers.\n\nWe've covered the specific issues relating to smart pointers using handles, but\nthere is a lot more information available on smart pointers. Modern C++ Design\n[Alexandrescu01] and More Effective C++ [Meyers96] both contain a wealth of use-\n\nful information on smart-pointer implementation and uses.\n\n] Alexandrescu, drei, Modern C++ Design, Addison Wesley, 2001.\n[GoF95] Gamma, Erich, et al., Design Patterns, Addison Wesley, 1995.\n[Meyers96] Meyers, Scott, More Effective C++, Addison Wesley, 1996.",
      "content_length": 819,
      "extraction_method": "OCR"
    },
    {
      "page_number": 51,
      "chapter": null,
      "content": "1.6\n\nCustom STL Allocators\n\nPete Isensee, Microsoft Corporation\npkisensee@msn.com\n\nany games use custom memory allocation strategies, providing their own mal-\n\nloc and free functions or overriding the global operator new and delete. The\nC++ STL (Standard Template Library) provides a powerful extension that allows you\nto use your own allocation and deallocation methods with all standard C++ container\nobjects, including strings. This gem shows how to create custom allocators and inte-\ngrate them into game code.\n\nAs an example, suppose your game creates a list, manipu\nthrows the list away—all within a single function:\n\nstd::list<int> MyList;\n\nfor( int i = 0; i < 100; ++i ) // build the list\nMyList.push_back( i );\n\nMyList.reverse(); // manipulate the list\n\nIf this function is called once per game loop, the penalty you would pay for allo-\ncating and freeing list nodes could easily convince you not to use STL lists. Suppose\nyou could customize the list so that all memory allocations came from the stack rather\nthan the heap. Deallocations would be free, because stack memory is automatically\nreclaimed when the stack object goes out of scope. Here’s how the stack-based list\ncode might look using a custom allocator:\n\n// Create custom allocator object\n\nconst size_t nStackSize = 100 * 12;\nunsigned char Stack[ nStackSize };\nStackAlloc<int> sa( Stack, nStackSize );\n\n// Tell the list about the custom allocator\nstd::list<int, StackAlloc<int> > MyList( sa );\n\n// This code is the same\n\nfor( int i = 0; i < 100; ++i ) // build the list\nMyList.push_back( i );\n\nMyList.reverse(); // manipulate the list\n\n49",
      "content_length": 1610,
      "extraction_method": "OCR"
    },
    {
      "page_number": 52,
      "chapter": null,
      "content": "ON THE CD\n\nSection 1 General Programming\n\nStackAlloc is a custom STL allocator. The StackAlloc type is specified as a tem-\nplate parameter in the list declaration, and the StackAlloc object is passed to the list\nconstructor. In this example, the stack is specified as just large enough to allocate 100\nnodes. In most STL implementations, a list node consists of the object and two point-\ners. The full implementation of StackAlloc is available on the CD-ROM.\n\nPerformance-wise, this particular optimization produces code that runs two to\nthree orders of magnitude faster than the first version, depending on the compiler and\nplatform. Clearly, custom allocators offer huge performance benefits, and the beauty\nof allocators is that you can write your own implementations that use whatever allo-\ncation techniques make sense for your game.\n\nSTL containers include vector, deque, list, map, set, multimap, and multiset. The\nbasic_string object also meets the qualifications for a container. All STL containers\nallocate memory to store objects in the container. These containers allow you to pro-\nvide custom allocators that define how memory will be managed. For example, list\nis defined as the following:\n\ntemplate <typename T, class Allocator = allocator<T> >\nclass list { ... }j\n\nThe Allocator parameter is a default template parameter. In normal usage, it’s\nnot specified, and the default allocator, allocator<T>, is used. The default allocator\nwill be covered in more detail later.\n\nstd::list<int> IntList; // uses default allocator<int>\n\nAllocator Requirements\n\nAny allocator object must meet the minimum requirements set forth by the C++\nStandard in Section 20.1.5 of [Cpp98]. These requirements are not difficult to follow\nand involve writing mostly boilerplate code. However, it’s beneficial to understand all\nportions of the allocator class.\n\nTypedefs\n\nAll allocator objects must include the typedef names shown here. These typedefs are\nalmost always defined as listed in this section. However, the C++ Standard allows\nimplementations to provide alternative definitions. For instance, the pointer typedef\nmight refer to far pointers, or some other pointer type particular to the platform. In\npractice, the freedom to define alternate types is limited, especially since C++ has no\nway of defining a reference type other than good old T&. The moral of the story: Don’t\nalter these typedefs without fully understanding the ramifications.\n\ntypedef size t size_type;\ntypedef ptrdiff_t difference_type;",
      "content_length": 2504,
      "extraction_method": "OCR"
    },
    {
      "page_number": 53,
      "chapter": null,
      "content": "1.6 Custom STL Allocators 51\n\ntypedef T* pointer;\n\ntypedef const T* const_pointer;\ntypedef T& reference;\ntypedef const T& const_reference;\ntypedef T value_type;\n\nConstruction and Copying\n\nAllocators are regular C++ objects, so there must be a way to construct them, copy\nthem, and destroy them. Here are the declarations for the constructors and destructor:\n\nallocator() throw();\nallocator( const allocator& ) throw();\ntemplate <typename U>\n\nallocator( const allocator<U>& ) throw();\n~allocator() throw();\n\nNotice the unusual template member constructor, which allows an allocator to be\nconstructed given an allocator of another type. Some compilers do not support tem-\nplate members yet, so this constructor may not exist in your implementation. Note\nalso that the C++ Standard explicitly requires that neither the constructors nor\ndestructor throw an exception.\n\nUtility Functions\n\nAllocator objects must provide a small set of utility functions. The most interesting\nutilicy function is max_size, which returns the maximum number of objects that could\nbe conceivably allocated via allocate.\n\npointer address( reference r ) const\n\n{\nreturn &r;\n}\nconst_pointer address( const_reference c ) const\n{\nreturn &c;\n}\nsize type max_size() const\n{\nreturn numeric_limits<size_t>::max() / sizeof(T);\n}\nAllocation\n\nThe allocate function is one of the two critical functions in the allocator object,\nand is the focus of custom allocation strategies. The C++ Standard says that allo-\ncate must return a pointer to raw memory of sufficient size to hold N objects of size\nT, where n is always greater than zero. The function does not construct the objects.",
      "content_length": 1642,
      "extraction_method": "OCR"
    },
    {
      "page_number": 54,
      "chapter": null,
      "content": "52\n\nSection 1 General Programming\n\nThe second parameter is an allocation “hint,” commonly a pointer to another mem-\nory block used to improve locality of reference. The hint parameter is generally not\nused.\n\npointer allocate( size_type n, const void* pHint );\n\nHere's just one example of how this function could be written to conform to the\n\nStandard:\n\npointer allocate( size_type n, const void* )\n\n{\nassert( n> 0);\nreturn pointer( malloc( n * sizeof(T) ) );\n}\nDeallocation\n\nThe deallocate function is the second critical function of the allocator object. The\nC++ Standard states that this function must free storage for N objects of size T, where\nthe raw memory of those objects begins at a non-null storage location p. The pointer\np must have been previously returned by allocate from an equivalent allocator\nobject, and the function must not throw an exception.\n\nvoid deallocate( pointer p, size_type n );\n\nHere’s an example of how this function could be written to conform to the Stan-\n\ndard:\n\nvoid deallocate( pointer p, size_type )\n\n{\nassert( p != NULL );\n\nfree( p );\n\nIn-Place Construction and Destruction\n\nNotice that unlike new and delete, allocate and deallocate don’t construct or\ndestroy objects—they only deal with raw memory. For performance reasons, alloca-\ntors specifically separate out these operations. For instance, vector: :reserve() allo-\ncates raw memory, but only constructs vector::size() objects. Only if and when\nvector: :resize() is called would uninitialized objects actually be constructed.\n\nThe allocator construct function allows existing memory to be used for con-\nstructing an object in place. You cannot call a constructor directly in C++, but the\nplacement new operator provides the functionality needed. Placement new doesn’t\nactually allocate memory—it calls an object’s constructor using existing memory.\n\nvoid construct( pointer p, const_reference c )\n\n{\n\n// placement new operator",
      "content_length": 1921,
      "extraction_method": "OCR"
    },
    {
      "page_number": 55,
      "chapter": null,
      "content": "1.6 Custom STL Allocators 53\n\nnew( reinterpret_cast<void*>(p) ) T(c);\n\n}\n\nThe destroy function allows an object to be explicitly destroyed without releas-\ning the memory. You can call a destructor directly in C++, which is exactly what\ndestroy does.\n\nvoid destroy( pointer p )\n\n//{ call destructor directly\n(p)->-T();\n}\n\nThe C++ Standard defines these functions very precisely. They must always\nbehave as shown here. The real purpose of these functions is to hide the notational\ncomplexity from containers.\n\nSuppose you've defined your own allocator object for a list of integers.\nlist<int, MyAlloc<int> > IntList;\n\nYou might be inclined to believe that MyAlloc<int>::allocate would be called\nwhenever a new item was added to the list. You would be mistaken. Most containers\n(vector being an exception) don’t actually allocate the objects they store. They allo-\ncate nodes. Each node contains an object plus one or more pointers. That means that\nallocators must have some way of converting from type T to type node, whatever type\nnode may be. The solution is called rebind.\n\ntemplate <typename U>\nstruct rebind\n{\n\n};\n\ntypedef allocator<U> other;\n\nRebind simply allows allocator<T> to allocate objects of another type, U. For\nexample, given allocator @ of type T, you can allocate an object of type U with the\nexpression:\n\nT::rebind<U>: :other(a).allocate( 1, NULL );\n\nDon’t worry if you don’t understand the gory template details. The important\nthing to remember is that the allocator you define for a given type has a way to allo-\ncate objects of different types (and sizes). The other important thing to know about\nrebind is that it requires a compiler with support for member templates in order to\nwork properly. STL implementations that work with nonconforming compilers must\nprovide their own mechanism for allocating nodes. For instance, older versions of the",
      "content_length": 1865,
      "extraction_method": "OCR"
    },
    {
      "page_number": 56,
      "chapter": null,
      "content": "54\n\nSection 1 General Programming\n\nDinkumware STL library [Dinkum] provide the function _Charalloc to support\nnonconforming versions of Microsoft Visual C++.\n\nComparing\n\nThe C++ Standard says two things about comparing allocators. First, it states that\nallocators are considered equivalent if and only if storage allocated by one can be de-\nallocated via the other. Then, it says that STL implementations are permitted to\nassume that allocators “be interchangeable and a/ways compare equal to each other.”\nIf these statements sound contradictory, that’s because they are. What the Standard is\nsaying is that allocator comparison is implementation-dependent. Some STL imple-\nmentations allow allocator comparison. Other implementations always compare allo-\ncators as equivalent.\n\ntemplate <typename T1, typename T2>\nbool operator==( const allocator<T1>&,\nconst allocator<T2>& ) throw();\ntemplate <typename T1, typename T2>\nbool operator!=( const allocator<T1>&,\nconst allocator<T2>& ) throw();\n\nIn many cases, it’s perfectly fine to assume that allocators are interchangeable.\nThe classic case is when the allocator has no data members. In other cases, you might\nreally want to compare allocators (for more detail on this issue, see Allocator State\n\nData, below).\n\nThe Default Allooator Object\n\nThe C++ Standard requires that all STL implementations include a default allocator\nobject called “allocator<T>.” This is the allocator that’s used if a custom allocator is\nnot specified. In other words, this is the allocator that your code is probably using at\nthe moment, so it makes sense to know what it is doing.\n\nThe default allocator object is defined in the C++ Standard in Section 20.4.1\n[Cpp98]. You can find the default allocator for your version of the STL in the <memory>\nheader file (or one of the headers included by <memory>).\n\nThe standard says the default allocator must call operator new to allocate storage.\nIf not enough memory is available, it throws the bad_alloc exception. A typical\nimplementation of the default allocate function looks like this:\n\npointer allocate( size_type n, const void* )\n\n{\nassert( n>0O );\nreturn pointer( operator new( n * sizeof(T) ) );\n\n}\n\nThe Standard says the default deallocate function must call operator\ndelete(p). A typical implementation of the default deallocate is:",
      "content_length": 2318,
      "extraction_method": "OCR"
    },
    {
      "page_number": 57,
      "chapter": null,
      "content": "1.6 Custom STL Allocators 55\n\nWritin Your Own Allocator\n\nvoid deallocate( pointer p, size_type )\n{\n\nassert( p != NULL );\n\noperator delete( p );\n\n}\n\nAs you might expect, the default allocator object simply wraps new and delete.\nImplementations are free to provide additional optimizations in the default allocator\nif they wish. You can examine your version of the STL to see how the default alloca-\ntor is implemented.\n\nAs mentioned above, every allocator object must meet the minimum requirements set\nforth by the C++ Standard. To be useful, it also has to function within any compiler-\nspecific limitations. The best way for you to meet these requirements (and limitations)\nis by copying the default allocator from <memory> and then customizing the allocate\nand deallocate functions, and potentially the constructors, destructors, and compar-\nison operators as well.\n\nHere’s the partial implementation of the StackAl1oc allocator shown at the intro-\nduction of the gem. Full source code is included on the CD-ROM. The allocate\nfunction simply returns a pointer to the next unused portion of stack memory, then\nupdates the number of bytes that have been allocated. If it runs out of stack space, it\nthrows bad_alloc(). The deallocate function doesn’t need to do anything, because\nstack space is automatically reclaimed. All of these functions are inlined template\nfunctions, so deallocate is a no-op in a release build.\n\ntemplate <typename T>\nclass StackAlloc\n\n{\npublic:\n\n// boilerplate typedefs here .\n\n// critical ctor\n\nStackAlloc( unsigned char* pStack,\nsize_t nMaxBytes ) throw()\nmpStack( pStack ),\nmBytesAllocated( 0 ),\nmMaxBytes({ nMaxBytes )\n\n{\n}\n\n// other ctors, dtor .\n// utility functions .\n\n// construct, destroy, rebind .",
      "content_length": 1733,
      "extraction_method": "OCR"
    },
    {
      "page_number": 58,
      "chapter": null,
      "content": "56 Section 1 General Programming\n\npointer allocate( size type n, const void* )\n\n{\nvoid* pRaw = mpStack + mBytesALLocated;\nmBytesAllocated += ( n * sizeof(T) );\nif( mBytesAllocated+1 > mMaxBytes )\n\nthrow std::bad_alloc();\n\nreturn pointer (pRaw) ;\n\n}\n\nvoid deallocate( pointer p, size_type }\n\n{\nassert( p != NULL );\n\n}\n\n// member data .\n};\n\nPotenti I Uses\n\nWhen should you write your own allocator? If after profiling your game, you’ve deter-\nmined that the default allocator is a bottleneck, consider providing a custom allocator.\nIf your entire game uses a custom solution and you don’t want operator new being\ncalled at all, but you do want to use STL containers, consider writing a custom\nallocator.\n\nThere are far too many allocation strategies to possibly list them all, but Table\n1.6.1 lists a selected number of strategies to consider when creating a custom\nallocator.\n\nTable 1.6.1 Allocation Strategies\n\nType Description\n\nFixed-Size Pools All allocations are the same size; reduces memory overhead per allocation.\n\nShared Memory Allocations use shared memory. See [Stroustrup97] for an example.\n\nMultiple Heaps Allocations come from different heaps, depending on the allocation size or type.\n\nSingle Threaded Allocations and deallocations are not thread-safe; useful within single-threaded code,\n\nGarbage Collected Deallocations don’t free memory; garbage collector function is called to free memory.\n\nStack Based All memory resides on the stack. Useful for containers with short lifetimes.\n\nStatic Memory Allocations come from program data space (static memory).\n\nNever Delete Deallocations never free memory; memory is reclaimed when application exits.\n\nOne-Time Delete Deallocations never free memory; memory is reclaimed by custom function.\n\nAligned Memory is aligned to meet certain requirements. Examples include page-aligned\nmemory or SSE instruction-aligned memory.\n\nDebugging Allocation logging, pinpointing leaks, checking for memory overwrites, peak allocation\n\nsize, and so forth.",
      "content_length": 1999,
      "extraction_method": "OCR"
    },
    {
      "page_number": 59,
      "chapter": null,
      "content": "1.6 Custom STL Allocators 57\n\nAllocator State Data\n\nCd\n\nAs mentioned above, STL implementations might allow any allocator to be equiva-\nlent to any other. That implies that unless your particular implementation supports\ncomparable allocators, it’s dangerous for allocators to hold per-object data/state of any\nkind. If you're writing an allocator that must work across multiple implementations,\nthe only safe path is writing allocators with no per-object data. The nice thing about\nthis restriction is that allocators in such implementations generally have no space\noverhead. The drawback is that it might be more difficult to accomplish your task\nwith a custom allocator.\n\nOne of the easiest ways to see if your STL implementation supports allocators\nwith per-object data is to examine the implementation of list: :splice. In the nom-\ninal case, the splice function splices one list to another by shifting pointers, which is\nvery fast. Now, consider the case where the allocators for the lists are truly different—\nusing different heaps, for example. Splice cannot simply change pointers, because the\nresulting list would contain some nodes allocated on one heap and some on another.\nThe resulting list wouldn’t “know” how to delete some of its nodes!\n\nIn the list splice function, if there are two code paths based on the comparison\nof allocators, it’s likely you have an implementation that supports allocators with per-\nobject data. If not, it’s likely your implementation assumes that allocators are all\nequivalent.\n\nRecommendations\n\nBelow is a list of recommendations for writing a custom allocator.\n\n* Copy the default allocator from <memory> and replace allocate and deallocate.\nIf your allocator has state data, update the constructors and destructor. Don't for-\nget to include the global comparison functions.\n\n* Be aware that using allocator<T> does not necessarily mean that only blocks of\nsizeof (T) will be allocated. The rebind function allows other types—and there-\nfore other sizes—to be allocated.\n\n* Typedefs are your friends, especially when dealing with template code. Use type-\ndefs for allocators and containers that use custom allocators. If you need to make\na change, only the typedef will need to be altered.\n\n* Be wary of creating allocators that hold per-object data or that contain “state.”\nYour STL implementation might not support such allocators. Examine the list\nsplice function to determine if your implementation supports allocators with\nper-object data.\n\n* Due to current compiler technology, not all allocator implementations conform\nto the C++ Standard. When in doubt, examine the default allocator in <memory>\nto determine how your implementation works around compiler limitations.\n\n* Don’t add custom allocators until you need to. The great thing about the alloca-\ntor architecture is that allocators can be replaced with very few code changes.",
      "content_length": 2884,
      "extraction_method": "OCR"
    },
    {
      "page_number": 60,
      "chapter": null,
      "content": "58 _ Section 1 _General Programming\n\nThe code included on ‘the CD- ROM i is ; designed t to > work with Microsoft Visual Stu-\ndio Version 6 and Visual Studio .NET. It was tested with STL implementation Ver-\nsions 3.08 and 3.10 from Dinkumware. These versions do support allocators with\nper-object data and allow nontrivial comparison functions.\n\nExample allocators are provided for a number of strategies, including multiple\nheaps, stack-based allocators, and static allocators. There’s also an allocator that sim-\nply wraps malloc and free.\n\nConclusion\n\nPine LE LRN NRE RARE\n\nWriting a custom 1 allocator is is a matter © of c copying some boilerplate code and cus-\ntomizing a handful of key member functions. Allocators have some curious features,\nand a working knowledge of these features is critical to understanding how allocators\nwork. It’s also important to note that different STL implementations might not sup-\nport allocators with per-object data and might provide custom member functions to\navoid compiler issues. Regardless of the complexities, custom allocators can signifi-\ncantly improve performance and are definitely worth understanding.\n\nReferences\n\n[Alexandrescu0 1] Alexandrescu, Andrei, Modern Ce. ++ , Design, Addison Wesley, 2001.\n[Austern98] Austern, Matt, “What are Allocators Good For?,” C/C++ Users Journal,\navailable online at http://www.cuj.com/experts/1812/austern.htm, May 1998.\n[Austern99] Austern, Matt, Generic Programming and the STL, Addison Wesley,\n1999.\n\n[Cpp98]} ISO/IEC 14882, ANSI C++ Standard, August 1998.\n\n[Dinkum] Plauger, P J., et. al., “Dinkumware Standard Template Library,” available\nonline at http://www. dinkumware.com.\n\n[osuttis99] Josuttis, Nicolai, The C++ Standard Library: A Tutorial and Reference,\nAddison Wesley, 1999.\n\n[Meyers01] Meyers, Scott, Effective STL, Addison Wesley, 2001.\n\n[Plauger01] Plauger, P. J., et. al., The C++ Standard Template Library, Prentice Hall,\n2001.\n\n[Stroustrup97] Stroustrup, Bjarne, The C++ Programming Language, Third Edition,\nAddison Wesley, 1997.",
      "content_length": 2037,
      "extraction_method": "OCR"
    },
    {
      "page_number": 61,
      "chapter": null,
      "content": "1.7\n\nSave Me Now!\n\nMartin Brownlow, Shiny Entertainment\nmbrownlow@shiny.com\n\nany recent games have been released with one vital feature missing, and this one\n\nfeature has probably generated more user complaints than any other element of\na game. What could possible cause so much commotion? It is none other than the\nability to save the game at any point. Saving your game on demand is generally taken\nfor granted by the game-playing public; and if this functionality is missing, the public\nwill complain loudly and often.\n\nHowever, some categories of games can get away without it. Several game types\nwould actually almost be ruined if you could save at any point. Could you imagine\nBubble Bobble if you could save the game whenever you wanted? Unfortunately, most\nmodern PC games do not realistically have the luxury of excluding a save game feature.\n\nIt is possible to argue that the ability to save at any point can significantly\ndecrease the difficulty of a game, hence adversely affecting or severely curtailing the\nlongevity of a game. This is reason enough for not implementing it. Most games\ninstead support saving only at specific points where certain things can be taken for\ngranted, simplifying the implementation. Unfortunately, this approach usually has a\ndetrimental effect on the whole gameplay experience. Players feel cheated and often\nthink that the feature was omitted to artificially inflate the playing time by making\nthem replay the same 20 minutes over and over again. A better approach would be to\nallow saving the game at any point, but revoking that ability during crucial gameplay\nareas, such as the ubiquitous boss encounter.\n\nSaving a game at an arbitrary position is one of those annoying tasks—to the layper-\nson it seems remarkably simple, but when you get right down to the nuts and bolts,\nyou discover that hard work is involved.\n\nDuring the course of a game, even with clever object reuse, memory gets frag-\nmented and object lists get jumbled. So, at any given time, it is nearly impossible to\nsay where in memory a new object will be generated. A solution to this is to replace all\npointers in the game with handles, which are then de-referenced through a lookup\ntable. However, if you are not using handles, another solution is to change all point-\ners to handles as they are written to disk, and then de-reference the handles back into",
      "content_length": 2374,
      "extraction_method": "OCR"
    },
    {
      "page_number": 62,
      "chapter": null,
      "content": "60 ; Section 1 General Programming\n\npointers after loading. Note that this will require several passes through the ‘save data’\nprior to saving and after loading.\n\nAnother large hurdle is deciding exactly what to save for each object. Once this\ndecision is made, it is necessary to write functions that read and write the data for\neach object type. Since most games have many types of objects, this can become an\nonerous task. Also, whenever any data structures change, all saved games are invali-\ndated and new code must be written. This is often why the task of writing the save\ncode is postponed until the end of the project. In the worst cases, the code is either\nnot properly tested or it is omitted altogether as pressure mounts to finish the game\nwithin the time constraints.\n\nWhat we need is a little automation. Ideally, we should only have to specify what\ndata elements and types to save for each object class, pass a list of object instances to\n\ney save, and let the save-game manager handle the rest. In this gem, we will be discussing\nowmeco a SAVENGR class framework that manages game saves with this automation. The class\nfiles are available on the CD-ROM.\n\nThe\n\nAfter implementation, the process of saving a game becomes trivial. Simply specify all\nobjects that should be saved with calls to AddSaveObject(), and then call save() to\nsave the game. Loading a game is simpler still—just call Load() and the game is\nloaded.\n\nSAVEMGR builds a list of all the objects that are to be saved with each call to\nAddSaveObject(). When the Save() function is invoked, SAVEMGR goes through this\nlist and calls the Save() member function for each object. When a pointer to an object\nneeds to be saved, SAVEMGR searches through this list to find the referenced object. The\nposition in the list (beginning from one; zero is reserved for NULL pointers) becomes\nthe object’s ID, which is then saved in place of the pointer. Note that if the object\nbeing referenced by the pointer is not in the list, then the game cannot be properly\nsaved.\n\nWhen reading a file, SAVEMGR first reads the number of objects in the file. Then,\nfor each object, it reads its class [D and calls the SAVEMGR: :MakeObject() function to\ninstantiate an empty object of the correct type. Next, SAVEMGR calls the object's Load()\nfunction, which reads the object’s data. When all objects have been loaded in this\nmanner, SAVEMGR makes a final call to each object’s PostLoad() function, which de-ref-\nerences object pointers from object [Ds back into usable pointers.\n\nThe SAVEOBJ Class _\n\nEvery savable class should be derived from the SAVEOBU class and must implement the\npure virtual functions GetSaveID() and GetSaveData(). Optionally, a class can over-\nride the Save(), Load(), and PostLoad() virtual functions, but it must be careful to\ncall the base class version of the functions before returning.",
      "content_length": 2871,
      "extraction_method": "OCR"
    },
    {
      "page_number": 63,
      "chapter": null,
      "content": "1.7 Save Me Now! 61\n\nHow does it know what data to save for each object? That is where the\nGetSaveData() function comes in. For each class, a static array should be defined that\nspecifies the data elements to write into the save file. This array defines the offset,\ntype, and length of each piece of data. The GetSaveData() function should return a\npointer to the correct array for the class. To retain simplicity, the SAVEMGR class defines\nseveral macros for common types, including pointers, allocated data, and contiguous\ndata blocks. Also, for class hierarchies, there is a macro allowing the class to refer to its\nparent’s save data description.\n\nThe GetSaveID() member function must return a unique ID for each type of\nclass. This ID is then used by the user-defined SAVEMGR: :MakeObject() factory func-\ntion to create a class of the correct type during loading.\n\nData es and Extensions\n\nThe SAVEMGR class natively supports the saving of several different data types through\nmacros that create the save table. These macros automatically fill out the SAVERECORD\nstructure by calculating the offset and length of the given data. The default types sup-\nported are contiguous generic data, pointers, allocated memory, and the save table of\nthe base class. These are listed in the save table through the macros SAVEDATA,\nSAVEPTR, SAVEALLOC, and SAVEBASE, respectively.\n\nThe SAVEDATA macro has two parameters; the first is the type of the class, and the\nsecond is the member variable name. For example, the mat member variable in\nthe PLAYER class would be declared with the macro SAVEDATA(PLAYER,mat) . Similarly,\nthe SAVEPTR macro takes the type of the class and the member variable name.\n\nThe SAVEALLOC macro takes three parameters—the type of the class, the member\nvariable for the memory pointer, and a member variable containing the length of the\nallocation.\n\nFinally, the SAVEBASE macro takes a single parameter—a pointer to the save data\ntable for the base class. For instance, for a class PLAYER derived from the class OBJECT,\nthe save table could contain an entry SAVEBASE (OBJECT: :obj_savetable). If the\nOBJECT class was derived from another class, say MASTEROBJ, then the OBJECT save table\ncould contain an entry SAVEBASE(MASTEROBJ: :mobj_savetable). Then, the PLAYER\nclass would automatically save the data elements for its base OBJECT class and also its\nbase MASTEROBJECT class.\n\nThese macros work by finding the offset of the given data element and its size,\nthen writing this into the save table. The SAVEALLOC function is slightly different,\nhowever. This macro saves not only the offset of the pointer to the allocated data, but\nalso the offset of a variable containing the size of the data that has been allocated. It is\noften necessary to save data types that are specific to the current game state. For\ninstance, we might need to save a pointer to a resource that has been changed from\nthe default. To do this, extra macros need to be defined, and the code to handle these\nmacros must be placed in the SAVEMGR member functions WriteData(), ReadData(),\nand CorrectData(). For our example, the code in WriteData() must translate the",
      "content_length": 3151,
      "extraction_method": "OCR"
    },
    {
      "page_number": 64,
      "chapter": null,
      "content": "62 Section 1 General Programming\n\nresource pointer into some recoverable form (like the resource ID), and ReadData()\nmust translate it back.\n\nOverriding the Default Functions\n\nRCE\n\nIn some cases, it is desirable not to save certain data to the file, since it is derivable\nfrom other elements in the object. This is where the overridable Save(), Load(), and\nPostLoad() functions come in.\n\nWhen an object is saved, the save manager calls SAVEOBJECT: :Save(). This in\nturn calls SAVEMGR: :SaveData(), which actually writes the data out. If there is work to\nbe done before saving (for instance, deriving Euler angles from a matrix) then we\nmust override the Save() function. Note that the base Save() function must be called\nto perform the actual write.\n\nSimilarly, the Load() function can be overridden. However, there will be no data\nin the class until you have called the base class’s Load() function. Finally, the PostLoad()\nfunction can be overridden and called for each object after all the objects have been\nloaded. Its primary purpose is to restore all the pointers in the object, but it should\nalso be used to restore any data not saved in raw form (for instance, converting Euler\nangles to a matrix).\n\nSimple Example\n\nThe following code demonstrates saving a simple class.\n\nClass PLAYER : public SAVEOBJ\n\n{\npublic:\n/* constructors/members omitted */\nint GetSaveID();\nSAVERECORD *GetSaveData();\nprotected:\n/* This is the table returned by GetSaveData() */\nStatic SAVERECORD player_savedata[];\n/* This is the data for the PLAYER class */\nMATRIX mat;\nNTT *targetNTT;\n}3\n\n/* The data saved for class PLAYER */\nSAVERECORD PLAYER: :player_savedata[] =\n\n{\nSAVEDATA( PLAYER, mat) ,\nSAVEPTR(PLAYER, targetNTT),\nSAVEDONE ()\n\n}3\n\nSAVERECORD *PLAYER: :GetSaveData()\n{ /* return the data table for PLAYER */",
      "content_length": 1800,
      "extraction_method": "OCR"
    },
    {
      "page_number": 65,
      "chapter": null,
      "content": "1.7 Save Me Now! 63\n\nreturn player_savedata;\n\n}\n\nint PLAYER: :GetSaveID()\n{ /* return a unique ID for this class */\nreturn PLAY_ID;\n\n}\n\n[RR RRRRERERERRERRER RRR EERERERERREREREREERK\n\nThis is the class factory function.\nIt takes a classID and makes an\nobject of the correct type\n\nRRRKKEEKERKKREKREEREREEEREEREKERERERERREEERER |\n\nSAVEOBJ *SAVEMGR: :MakeObject( int classID )\n\n{\nswitch( classID )\n{\ncase PLAY_ID:\nreturn new PLAYER();\n}\nreturn NULL;\n}\n\nThe PLAYER class is derived from the SAVEOBJECT base class and defines the inher-\nited pure virtual functions GetSaveID() and GetSaveData(). GetSaveID() returns\nthe value PLAY_ID, which is then used later in the class factory function,\nSAVEMGR: :MakeObject(), to create a class of the correct type. The GetSaveData()\nfunction returns a pointer to the save table for the PLAYER class, which defines the data\nthat will be saved and loaded. The save table defines just two member variables that\nneed saving—the mat variable and the targetNTT pointer.\n\nConclusion\n\nON THE CD\n\nSaving and loading games is arduous and requires careful data conversion and man-\nagement. With care and a little automation, however, this task can be transformed\ninto a simple task of maintaining one table of data for each type of class. The code\nprovided on the CD-ROM is a skeleton for a save/load manager. Many enhancements\nare possible. For example, the output stream could be passed through a compressor\nlayer or a cryptographic layer. You might want to add a header to the file to enable\nquicker parsing, or include a miniscreenshot to display in the file manger. It is even\npossible to extend the SAVERECORD entry to enable backward compatibility.",
      "content_length": 1677,
      "extraction_method": "OCR"
    },
    {
      "page_number": 66,
      "chapter": null,
      "content": "1.8\n\nAutolists Design Pattern\n\nBen Board, Dogfish Entertainment, Ltd.\nben_board@yahoo.com\n\nC++ game programmer frequently finds it necessary to gain selective access to\n\nthe set of all objects of a type T (e.g., CAIPedestrian), where T is a leaf type of\nthe hierarchy derived from a base type B (e.g., CAIObject). Since there is often a list in\nthe game containing pointers to all objects derived from B, identifying the relatively\nfew entries of type T requires a wasteful search.\n\nA sensible alternative is to create a separate list containing just those objects of\ntype T, enabling immediate access to those objects in isolation. However, this method\nhas some problems:\n\n¢ We must decide where the list itself should be stored.\n¢ We must ensure objects are added to the list on creation and removed on dele-\ntion.\n\n* Rogue additions or deletions must be guarded against.\n\nCreating each list requires several lines of code in a number of places, and it is\neasy to introduce bugs, particularly by using copy and paste, or forgetting a step in the\nprocess. An ideal solution would be if the programmer could somehow mark the class\nas “to be listed,” and, with no further programmer effort, the class itself would create\nthe list, store it intelligently, and guarantee that it contained just the existing instances\nof itself. This gem provides just such a solution with a design pattern called autolists\nthat achieves all these features, removes much of the potential for bugs, and only\nrequires half a line of code for each class to be listed.\n\nimplementation\n\n64\n\nConsider a class, CListMe. We would like each instance of CListMe to be added to a\nspecial new list on construction and removed on destruction, and we would like to be\nable access this list simply, but in a suitably object-oriented manner.\n\nAutolists achieve this by way of a single C++ template class, TAutolists<T>.\nTAutolists<T> has these crucial features:\n\n¢ It has a static, private member variable of type list-of-pointers-to-Ts.\n* On construction, it casts its this pointer to type T* and adds itself to that list.",
      "content_length": 2086,
      "extraction_method": "OCR"
    },
    {
      "page_number": 67,
      "chapter": null,
      "content": "1.8 Autolists Design Pattern 65\n\n¢ On destruction, it finds its entry in the list and removes it.\n* TAutolists exposes a read-only interface, allowing useful query functions with-\nout allowing the list to be altered directly.\n\nTo mark a CListMe as “to be listed,” simply derive it publicly from TAutolists\n<CListMe>:\n\nclass CListMe : public TAutolists<CListMe>\n{\n\n// no further references to TAutolists required\n}5\n\nSince the constructor for CListMe must call the parent constructor (that of\nTAutolists<CListMe>), the class's this pointer (cast to a CListMe pointer) is added to\nthe list. When the object is destroyed, the reverse process happens, and the pointer is\nremoved from the list, which is hidden in the parent class’ private scope. In both cases,\nthe derived class has nothing further to do to make this happen.\n\nAccess to the resulting list is via the TAutolists interface—no direct access is\nallowed to the list object itself. The following is a typical example of autolist usage:\n\nCListMe* pLM = TAutolists<CListMe>: :GetAutolistFirst()\n\nwhile (pLM)\n\n{\n\n// use pLM here\n\n// finally:\n\npLM = TAutolists<CListMe>: :GetAutolistNext();\n}\n\nGetAutolistFirst() and GetAutolistNext() both return a T*, which will point\nto either a valid existing T object or NULL if the end of the list has been reached. There\nis almost no danger that a returned non-NULL T* pointer refers to a nonexistent\nobject, given the restrictions on removals from the list. There is nothing for the pro-\ngrammer to forget to do!\n\nNote the explicit scope qualifications of GetAutolistFirst() and GetAutolist-\nNext() by use of the prefix TAutolists<CListMe>::. This is not strictly necessary in\nthe case where only one function of that name is visible (more on this shortly).\n\nIt is difficult to use this implementation incorrectly—there are two interface\nfunctions, which do not take any arguments. We could use an iterator system, but by\nexposing an extra type, requiring the declaration of another variable in the autolist\nloops, adding parameters to the list lookups, and essentially replicating a tiny subset\nof the regular list functionality without all the other useful stuff you can do with iter-\nators—it would be taking a step backward from the no-brainer, no-bugs purity of this\npattern.",
      "content_length": 2274,
      "extraction_method": "OCR"
    },
    {
      "page_number": 68,
      "chapter": null,
      "content": "66 Section 1 General Programming\n\nComments on the implementation\n\nNow, let us discuss some of the details of this implementation.\n\nCost\n\nThe cost of autolisting a class is trivial: one static list object containing one list ele-\nment per object listed (as it would be with any list), one static iterator per list, and the\nvirtual function table entry for the TAutolists virtual destructor.\n\nNested Iterations\n\nIn the implementation presented, nested iterations of the list are not allowed. If\nGetAutolistFirst() for a list is called while another iteration is in progress further\nup the call stack, the iterator would become corrupted. This is addressed by asserting\nthat the iterator is NULL on starting a new iteration, but if nested accesses are likely\nto be useful, it is simple to replace the single static iterator in the TAutolists\nclass with an array (or list) of iterators to manage an iterator ‘stack’ within\nGetAutolistFirst/Next().\n\nAutolists Without Constructors\n\nA second point to make is that some games avoid using constructors and destructors\nin favor of Initialize and Shutdown methods that are explicitly called shortly after\nconstruction and before deletion in order to gain more control over these important\nphases of an object's life. In this case, it might be necessary to dilute the automation of\nthe pattern by moving the addition to and deletion from the list to separate functions,\nsay InitializeAutolists() and ShutdownAutolists(), and require that the autolisted\ntype call these explicitly—a step that must be remembered by the programmer, but at\na very small cost when considering the benefit.\n\nDownward Casting\n\nOne might raise an eyebrow at the cast down the inheritance tree that takes place in\nthe TAutolist constructor. We recognize this issue, but can see no practical cause for\nconcern, since there is little theoretical doubt about the type safety of the cast. The\ncompilers used do not complain, and problems have yet to be seen while adding to,\nremoving from, or querying a list. It might ease the programmer’s conscience if a\ndynamic cast is performed rather than a static one by enabling run-time type identifi-\ncation (RTTI). However, no such problems should occur.\n\nOther Storage Methods\n\nThe name of this pattern implies that lists are the only (or the preferred) method of\nstoring the instances of a certain class. This is not necessarily the case. A sister class to\nTAutolists might be TAutomaps, for example, which stores each new object in an STL",
      "content_length": 2495,
      "extraction_method": "OCR"
    },
    {
      "page_number": 69,
      "chapter": null,
      "content": "1.8 Autolists Design Pattern 67\n\nmap. Indeed, one might create a suite of classes covering a range of aggregate methods\nto suit the expected populations of classes and to optimize their accesses. We have\n\nchosen the (STL) list example merely for simplicity.\n\nUse of Multiple Inheritance\n\nIt is also worth discussing the potentially controversial use of multiple inheritance (MI)\nimplied by this pattern. In order to mark a class with one existing parent as “to be\nlisted,” it must add TAutolists, a second parent. This is only a cause of limited con-\ncern; the problems associated with MI are dealt with in the natural use of the pattern.\n\nThe principal problem raised by the use of MI is name clashing—a type in a hier-\narchy ends up inheriting two or more functions with the same name from its parents.\nThis problem might be mitigated by carefully naming the public interface by includ-\ning the word “Autolist” in the Get*() functions. The chances of finding that name\nelsewhere in a hierarchy are slim. Of course, a name can always clash with itself: Con-\nsider the perfectly sensible and useful situation in which class CBase is a parent to class\nCDerived, and both are autolist clients:\n\nclass CBase : public TAutolists<CBase>\n\n{\n\n}\n\nclass CDerived : public CBase, public\nTAutolists<CDerived>\n\n{\n\n}\n\nWithin member functions of Chase, it is possible to access other members of your\nown type by referring to the autolist interface without the usual explicit scope qualifi-\ncation:\n\nvoid CBase::ExamineOtherCBases { )\n\n{\nCBase *pBase = GetAutolistFirst();\n// not strictly necessary to write\n// TAutolists<CBase>::GetFirst(), because this\n// way is unambiguous\n}\n\nHowever, this is not the case within CDerived, which inherits two functions called\nGetAutolistFirst() (one from its own TAutolists inheritance, and one via the\ninheritance from CBase). In this instance, it is necessary to fully resolve the scope:\n\nvoid CDerived: :ExamineOtherDerived ()\n\n{\nCDerived *pDerived = GetAutolistFirst();\n\n// syntax error — ambiguous call",
      "content_length": 2029,
      "extraction_method": "OCR"
    },
    {
      "page_number": 70,
      "chapter": null,
      "content": "68 Section 1 General Programming\n\nCDerived *pDerived =\nTAutoLists<CDerived>: :GetAutolistFirst();\n// no error, and arguably clearer syntax\n\n}\n\nIn our project, we have imposed the rule chat all uses of autolists, whether or not\nthe scope is ambiguous, should explicitly state the scope in question, partly for read-\nability and partly to maintain good habits.\n\nConclusion\n\nAutolists are a design pattern intended to ease the common game-programming task\nof tracking all instances of a particular class type, without the programmer manually\nmaintaining a list per type (a bug-prone operation requiring several steps).\n\nThis is achieved by a single template class, TAutolists, which, when used as a parent\nclass for a class J; creates a new list of pointers-to- 7, hides its implementation behind\na simple interface, and causes each new instance of T to be added to the list on cre-\nation and removed from the list on deletion—all in half a line’s worth of additional\ncode. Autolists list your objects so you don't have to. The TAutolists<> class defini-\ntion can be found on the CD-ROM.\n\nON THE CD",
      "content_length": 1095,
      "extraction_method": "OCR"
    },
    {
      "page_number": 71,
      "chapter": null,
      "content": "1.9\n\nFloating-Point Exception\nHandling\n\nSeren Hannibal, Shiny Entertainment\nsorenhan@yahoo.com\n\nMi: programming packages for creating Windows applications create applica-\ntions in which floating-point exceptions are often handled automatically, caus-\ning the processor to keep quiet about any floating-point errors that might occur. This\ngem will show you how to make your program crash when one of these errors occurs,\nby only adding three lines of code. It will also give you a few hints on how to locate\n\nthe bugs.\n\nWhy should these errors be exposed in the first place? There are at least three good\n\nreasons:\n\n¢ Cross-Platform Compatibility: Since other processors and other operating sys-\ntems might be much less forgiving, any code that could potentially cause floating-\npoint exceptions might crash on some platforms and run on others.\n\n* Performance: Depending on the design of the processor, an instruction causing\nan exception might be slower than a well-executed instruction. Furthermore,\nsince many operations work differently with illegal or infinite floating-point val-\nues, the code might run much slower or even lock up. For example, the following\nloop will lock up if x is an infinite number, as half infinite is still infinite:\n\nint counter=0;\nwhile (x>1.0f)\n{\nx=x/2.0F;\ncounter++;\n\n}\n\n* To Avoid Sloppiness: Although most floating-point errors are very innocent,\nthey can easily hide bigger problems that typically surface at 2:00 a.m. the night\nbefore a major deadline.\n\n69",
      "content_length": 1494,
      "extraction_method": "OCR"
    },
    {
      "page_number": 72,
      "chapter": null,
      "content": "70\n\nener ONAN ENR AHL HN\n\nIt is important not to think of this gem as introducing bugs into programmers’\n\ncode; our goal is only to expose the bugs that are already there. Therefore, it is in the\nbest interest of every programmer to use the method in this gem to find and fix any\ncode that causes floating-point exceptions.\n\nDoes Your Program Handle\n\nFloating-Point Exceptions? 7\nSome compilers (e.g., Microsoft Visual Studio 6) disable floating-point exceptions by\n\ndefault; and therefore, you should always perform a test when switching program-\nming environments. Here is a short piece of test code that, when put into a program,\nshould generate a division-by-zero error. You should be careful to put the test some-\nwhere in the core of your program and not in the very beginning, as some library calls,\nsuch as in the DirectX8 IDirect3DDevices: :Reset(), might disable the floating-point\nexceptions every time it is called.\n\nvolatile float x=1.0f;\nvolatile float y=0.0f;\nfor(int i=0;i<10;i++)\n\n{\n}\n\nX=x/Yy;\n\nThe code uses volatile to prevent the compiler from optimizing the division by\n\nzero out. When put into a project, it should be easy to see if your program ignores\nfloating-point exceptions or crashes it.\n\nException Types\n\nRAL NE\n\nos\n\naaron\n\nThe biggest consideration when enabling the floating-point exceptions is which types\nof exceptions to use. The Windows system routines allow access to six different types:\n\n_EM_INVALID—Invalid Exception. This should always be enabled.\n_EM_ZERODIVIDE—Division by Zero Exception. This should also be enabled.\n_EM_OVERFLOW—Overflow Exception. This should probably be enabled, except if\nthe application is written to work with infinite numbers.\n_EM_INEXACT—Exception for an Inexact Result. This exception should definitely\nnot be enabled, as most floating-point operations are slightly imprecise and\nwould set the flag.\n\n_EM_UNDERFLOW—Underflow Exception. This occurs when an operation gives a\nsmaller result than the floating-point register can contain, and it is rounded to\nzero. This exception should not be enabled, since, for example, the dot-product\nof two perpendicular vectors, with slight imprecision, would result in very small\nnumbers.\n\n_EM_DENORMAL—Denormal Exception. Denormals are slightly specialized cases of\nfloating-point numbers and are the smallest floating-point numbers available in",
      "content_length": 2354,
      "extraction_method": "OCR"
    },
    {
      "page_number": 73,
      "chapter": null,
      "content": "1.9 Floating-Point Exception Handling 71\n\nthe IEEE754 standard. A very small number would become denormal before\nbecoming zero. Denormals can therefore be unavoidable; and as a general rule,\nthis exception should not be enabled. However, denormals are expensive com-\npared to normal floating-point values, and by testing your code with this flag on,\nyou might discover areas that can be modified to avoid denormals.\n\nThe Code\n\nThe code for enabling the floating-point exceptions is really simple. It reads the old\ncontrol register values, modifies them, and writes them down again. The code is:\n\n#include <float.h>\nvoid enableFPExceptions()\n\n{\nint i = _controlfp (0,0);\ni &= ~(EM_ZERODIVIDE|EM_OVERFLOW|EM_INVALID) ;\n_controlfp (i,MCW_EM);\n\n}\n\nThe tricky part is where to place it within the program. As mentioned above,\nsome libraries overwrite the floating-point exception flags. Therefore, after incorpo-\nrating this function into your code, it is very important that you test it. Again, the test\ncode should be at the core of the program, not just immediately after enabling the\nexceptions. Note that changing the floating-point exception flags can be expensive, so\nit should not be done for every frame. If you know which library functions overwrite\nthe control register, it would perhaps be a good idea to reset the flag before the library\ncall and set it again afterward.\n\nException Handling in Released Projects\n\nYou should also consider whether to enable floating-point exceptions in your released\nprograms or not. There are arguments for and against this, and the answer depends\non the type of program. For a game, it might make sense to disable all exceptions; a\nbug probably will not have any long-term effects when the program is closed down.\nOn the other hand, there is an argument for enabling them in programs such as level\neditors, since a level might get corrupted in memory and then saved to disk.\n\ning Floatin\n\n-Point Exceptions\n\nOk, so you enabled the exceptions and your program crashes. But the code next to the\ncrash looks fine. What is wrong, then?\n\nUnfortunately, the crash does not occur right away. Because today’s processors\nhave multistage pipelines, the floating-point error occurs at the earliest stage during\nthe next floating-point instruction, which might not even be in the same function.\nTherefore, it is very useful to switch to disassembly mode and look at the actual float-\ning-point registers instead of looking at source-level debugging output. Remember\nthis when you are trying to locate bugs that make no sense (at first).",
      "content_length": 2566,
      "extraction_method": "OCR"
    },
    {
      "page_number": 74,
      "chapter": null,
      "content": "72 Section 1 General Programming\n\ncompatibility, performance, and avoidance of sloppiness. The code to check for float-\ning-point exceptions is simple, but care has to be taken to put it in at the right place\nand to test it carefully. Debugging can be confusing because of the delayed multistage\npipeline, but looking at disassembly instead of source-level output makes it easier.\n\nThere is no reason not to check for floating-point errors, and doing so offers the\npotential for more stability and higher performance. By using the information pre-\nsented in this gem, you will be on your way to writing better code in minutes.",
      "content_length": 626,
      "extraction_method": "OCR"
    },
    {
      "page_number": 75,
      "chapter": null,
      "content": "1.10\n\nProgramming a Game Design-\nCompliant Engine Using UML\n\nThomas Demachy,\nTitus Interactive Studio\ntdemachy@titus.fr\n\nL* admit it—as programmers, we are sometimes compelled to turn down great\ngame-design ideas because the game engine cannot cope with them. On the other\nhand, we might be disappointed when the game designer frowns at a brand new\nweather-control system, just because the game takes place underground.\n\nWe have all faced these situations, usually due to the fact that game design and\nengine programming are parallel tasks. Even if there are frequent interactions between\ndesigners and programmers, both have their own ideas of what the game should be.\n\nThis gem will explore collaborative work between the game-design team and the\nprogramming team, using a common graphic language—Universal Modeling Lan-\nguage (UML). By working together on the same model, designers and programmers\nwill focus on the game, and only the game, and thus reduce both delays and develop-\nment costs.\n\nThe Object Is in the Game_\n\nHANA NARA RARER\n\nObject-oriented programming (OOP) was modeled after the real world. Consider an\nobject—it is unique and identifiable, and therefore can be described with properties,\nsuch as its shape or color. In addition, any object interacts with the world and thus has\na specific behavior.\n\nThese two observations are the foundations for object-oriented methods. These\nmethods have been successfully applied to the software industry for more than 20\nyears, and many language implementations are available—Smalltalk, Java, and Visual\nBASIC, to name a few.\n\nFor several reasons, OOP just recently came to our industry with the growing use\nof C++ as a game programming language. For instance, [GPGO1] presents many con-\ntributions concerning the benefits of using C++. However, there is more to C++ than\na ‘plus’ added to C. It is a completely different paradigm, with a strong motto:\n“Think Object!”.\n\n73",
      "content_length": 1932,
      "extraction_method": "OCR"
    },
    {
      "page_number": 76,
      "chapter": null,
      "content": "Section 1 General Programming\n\nSoftware and Game Design Share History\n\nRecently, one of the most difficult challenges faced in game design is how to break\naway from linear or multilinear storytelling. Too often, situations are described with\neach and every interaction specifically defined. It becomes impossible for the player to\nfreely choose their own unique path.\n\nIn a lecture entitled “The Future of Game Design” [Smith01], Harvey Smith (Ion\nStorm) promotes object-oriented game design in order to gain ‘global consistency’\n(among other benefits). He demonstrates that by using object classes that inherit\nproperties from one another, a more credible game universe can be achieved. Sound\nfamiliar? It probably does.\n\nA Solution for Collaborative Work\n\nSince game design is becoming more object-oriented, now is the time to work\ntogether and use a common language. The Universal Modeling Language was first\nintroduced in the mid-90s and enables this collaborative opportunity. UML is a\ngraphic-modeling toolbox, mainly used for software design; but it was intended from\nthe start to be applied to any kind of design. This gem is not intended to be a UML\ntutorial. There are plenty of resources available in books or on the Web, several of\nwhich are listed in the References section.\n\nAll the World’s a Stage\n\nWhen considering design tools, it’s important to take the dynamic aspect of game’s\ndesign into account. If the world were really a stage, then a modeling language would\nhave its own actors. This is the case for UML. From the game scenario, you can iden-\ntify characters and actions. For UML, an actor is an entity with a role, such as the\nplayer, a nonplaying character, a vehicle, ... even a weather-control system. It intro-\nduces actors, use cases, sequences, and collaborative diagrams.\n\nIntroducing Groody\n\nBoth the game designer and the programmer use the game scenario as the starting\npoint. Imagine you are working on a 2D platform game called Groody. The fairly\nbasic scenario would go something like: Groody features a hero running through a\nscrolling background. He can jump from one white cloud to another, but must blow\nstormy clouds away by using his wind blower. If a stormy cloud hits Groody, he might catch\na cold.\n\nDefining Which Case to Use\n\nThe first step is to identify the actions and actors. For Groody, we identify three actors\nthat can initiate an action—the game player, Groody, and the stormy cloud. Note\nthat the game player and its virtual avatar are two different actors—you don’t run in",
      "content_length": 2531,
      "extraction_method": "OCR"
    },
    {
      "page_number": 77,
      "chapter": null,
      "content": "1.10 Programming a Game Design-Compliant Engine Using UML 75\n\nfront of your screen like the hero does in the level. We then need to define the ‘main\nactions’ of the scenario. For UML, these actions are formalized as use cases. Use cases\nare very important because they define how the system will be built. In Figure 1.10.1,\nactors are drawn as stick figures, and use cases are drawn as ovals. The lines between\nthe objects symbolize communication. The supported actions can be stereotyped as\n“uses” or “extends,” linking several cases together. In this diagram, the Run Through\nLevel case uses the Jump over white clouds case. Each use case must also be described\nin plain language, including normal control flow, alternative operation, special cases,\n\nand so on.\nRun Through <<uses>>\nLevel\nUse Wind\nGroody Blower\n| a Fly after to hit\nHuman Stormy\n\nFIGURE 1.10.1 Use case diagram for Groody.\n\nUnwrapping the Action\n\nUse cases are wonderful for creating a quick draft of the design concepts, but they can\nbe far too abstract and can be misinterpreted as more-detailed concepts. In an actor\nuse-case relationship, each time that an instance of an actor is created, it will execute\nan instance of the use case, also called the “scenario.” This scenario is unwrapped\nalong a timeline and represented in the sequence diagram (see Figure 1.10.2).\n\nA sequence diagram features the dynamic interactions between objects. If we\nfocus on the Use Wind Blower use case, a typical scenario would be:\n\n* Groody checks to see if he has energy cells left for the wind blower.\n¢ For each cloud in the level, check if there is a clear line of sight (LOS).\n¢ The first cloud with a clear LOS is hit and blown into thin air.\n\nSeveral sequences are defined for each use case. It is the sum of all these scenarios\nthat describes a use case.",
      "content_length": 1817,
      "extraction_method": "OCR"
    },
    {
      "page_number": 78,
      "chapter": null,
      "content": "76\n\nClasses Move .\n\nRESP ARAN Ra\n\nSection 1 General Programming\n\n| WindBlower CloudsCollection | aCloud:StormyCloud [ Background |\n\nI\n\nGroody\nquery energy level\n\n[energy level Ok]\n\n|\n|\n|\nI\n|\n|\nfind target cloud |\n\n*[for each cloud]\nquery position\n\n*[for each cloud]\ntest visibility\n\n[target visible\nblown away\n\nFIGURE 1.10.2 Sequence diagram for the Use Wind Blower use case (time goes\ndownward).\n\nFrom Sequence to Collaboration\n\nSequence and collaboration diagrams are two sides of the same mirror—they convey\nexactly the same information. The only difference is that the sequence is time-based,\nwhereas the collaboration is object-based (see Figure 1.10.3). The magic of UML\nresides in this simple translation, which is the link between the dynamic and the sta-\ntic parts of the model.\n\nLike Stones Do\n\nea RENT\n\nThe game e of Go is paradoxical in a way. Opponents attack one another and gain ter-\nritories, essentially by laying down stones that will never be physically moved. The\ndynamic is born from the static. We have, until now, focused on the dynamic nature\nof objects and their relationships. In the game engine, however, the dynamic—the\nbehavior—is based on the object properties.\n\nNext, we will focus on the static representation for the game world and on the\n\nmost popular diagram for UML, the class diagram.",
      "content_length": 1321,
      "extraction_method": "OCR"
    },
    {
      "page_number": 79,
      "chapter": null,
      "content": "1.10 Programming a Game Design-Compliant Engine Using UML 77\n\nWindBlower\n\n4: *[for each cloud]\ntest visibility\n\n3 : *[for each cloud]\nquery position\n\nFIGURE 1.10.3 Collaboration diagram for the Use Wind Blower use case.\n\nTwo Ways To Talk About Classes\n\nLeaning toward ever-more realistic simulations, modern games have to manage sev-\neral thousands of objects, each interacting with a subset of the domain. Class general-\nization (or inheritance) is one of the most powerful object-oriented mechanisms. By\nclassifying objects and creating hierarchies, it drastically downsizes the system’s com-\nplexity.\n\nUsually, inheritance cannot be identified from the dynamic analysis, since it\nmainly links object properties. During the class design, the secret to efficient collabo-\nration between the programmer and the game designer is ‘vocabulary’ (see Figure\n1.10.4). Both domains share the same object-oriented paradigm, but where the\n\nClass A Class A\n\n¢\n—_\n7\n‘\n\nAssociation :\n\"uses\", Aggregation :\n\nGeneralization :\n\"is a kind of\"\n\n\"sends a \"belongs\"\nmessage\", ...\n\nFIGURE 1.10.4 A word for each association.",
      "content_length": 1104,
      "extraction_method": "OCR"
    },
    {
      "page_number": 80,
      "chapter": null,
      "content": "78\n\nCollaborate and iterate\n\nSection 1 General Programming\n\nar Rac EYED RE RDN NNT RE SN aS ae SEE ah ESS nr ta ISA Leen orees\n\nprogrammer uses the terms “association,” “aggregation,” or “generalization,” the game\ndesigner will refer to “uses,” “possesses,” or simply “is a kind of.” The words are dif-\nferent, but the graphical representations for these concepts are the same.\n\nCreating an Object Hierarchy\n\nThe collaboration diagram usually makes a good starting point. The messages become\nclass operations to be transferred in the class initiating the message. Communicat-\ning classes are in an association relationship, except when the link is asymmetrical. In\nthis case, we have an aggregation. There is aggregation when you can say that one\nobject is part of another, and when the destruction of the owner will force the destruc-\ntion of the owned.\n\nFrom the collaboration diagram (Figure 1.10.3), we define the messages as the\noperation from the calling class. Figure 1.10.5 shows a representation of a class dia-\ngram after one use-case analysis.\n\nWindBlower\nL EnergyLevel:integer\n\nQueryAmmo:integer\nFindTarget:StormyCloud*\nDestroyTarget\n\n(...)\n\n(...) Background\n\nGetEntityPosition:vector2D\nTestVisibility: Boolean\n(..-)\n\nFIGURE 1.10.5 Class diagram (incomplete), after one use case analysis.\n\nUML has more advantages than just simplifying communication between game\ndesigners and programmers. The main idea behind UML is the iterative modeling",
      "content_length": 1452,
      "extraction_method": "OCR"
    },
    {
      "page_number": 81,
      "chapter": null,
      "content": "1.10 Programming a Game Design-Compliant Engine Using UML 79\n\nprocess. It means that it is not necessary (and not even desirable) to develop the whole\ngame design in UML before beginning the engine implementation. The process is\nincremental, back and forth between game designer and programmer. The use of case\ntools, such as those listed in the References, below, will smooth the entire process. In\nfact, several of these tools have code-generation and reverse-engineering features.\nThus, a programmer can code the game engine and go back to the design when\nneeded.\n\nBecause of its graphical nature, a UML model can be modified at very low cost.\nFor instance, when introducing a new enemy, say a snake, you might want to create\nan abstract enemy class and specialize the cloud class from this new one. This modifi-\ncation implies a minor modification to the class diagram (see Figure 1.10.6). We must\nintroduce the enemy abstract class, create the snake subclass, and then inherit the\nstormy cloud from the enemy class with the generalization link.\n\n| stormycious | | Snake ]\n\nFIGURE 1.10.6 Jncremental class diagram modifications.\n\nWhile implementing source, it implies inheritance modifications, just as with\nother design techniques. However, if you use a UML case tool, the code modifications\nwill be automatically rebuilt.\n\nModifications are not restricted to class hierarchy and can be done at any level. In\nthe sequence diagram (Figure 1.20.2), the Groody actor is responsible for polling\nthe level to find StormyCloud targets. For implementation reasons or to increase the\nreusability of the code, it might be preferable to introduce a combat resolver, estab-\nlishing the interface between the shooter and the target (see Figure 1.10.7). The new\nscenario would be:",
      "content_length": 1772,
      "extraction_method": "OCR"
    },
    {
      "page_number": 82,
      "chapter": null,
      "content": "80\n\nSection 1 _General Programming\n\n1. Groody informs the combat resolver that he is shooting.\n\n2. The combat resolver determines if there is enough energy left in the wind\nblower.\n\n3. The combat resolver finds a stormy cloud in Groody’s line of sight.\n\n4. When a cloud is targeted, the combat resolver informs it that it is being\nblown into thin air.\n\nThis new scenario results in a new sequence diagram (Figure 1.10.7), which in\nturn produces a new collaboration diagram. The new class, CombatResolver, is simply\ninserted into the class diagram. Implementation constraints do have consequences on\nthe game design, however. Using a case tool, the whole process might take a few\n\nminutes.\nCombat Clouds aCloud:\nResolver WindBlower Collection StormyCloud packground\nT T ! |\nroody | |\nattack query | | | |\nenergy level , | (\n*[for each |\nquery [energy ; cloud} |\nweapon level Ok] ; | query I |\n| findtarget | position \\ |\ncloud |\n|\n|\n|\n|\n[target |\n\na\n\n, Visible] |\n\n| blown |\n\nj away |\n{\n{\n|\n|\n\nFIGURE 1.10.7 Modified version of sequence diagram from Figure 1.10.2.\n\nt tion I\n\nThroughout this gem, we have 1 not written one line of code. This demonstrates the\ncapacity of UML to be completely language-independent. However, implementation\ncan be done from the class diagram at any time. If you are using a UML tool, it can\nusually build the source code from the design automatically.",
      "content_length": 1381,
      "extraction_method": "OCR"
    },
    {
      "page_number": 83,
      "chapter": null,
      "content": "1.10 Programming a Game Design-Compliant Engine Using UML 81\n\nHard Coding vs. Scripting\n\nSince UML can be translated into many languages, you can choose what will be hard-\ncoded and what will be described with a script. Usually, this decision is made very\nearly in the development process. Using a UML design, functions and classes can be\nincluded in the hard-coded areas or in the scripts.\n\nIf you choose an object-oriented script language, such as embedded Python\n[Python02], you can also use UML to code these game scripts. In fact, there is\nanother UML diagram perfectly adapted for behaviors and Al—the state diagram, as\nshown in Figure 1.10.8. The state diagram has been widely covered for AI state\nmachines [Dybsand00]. It unrolls all the different states that an object can encounter,\nalong with the conditional transitions.\n\nWandering Hit by wind blower\n\nDestroyed\n\nAttack done Touch hero\n\nAttacking\n\nFIGURE 1.10.8 State diagram for the StormyCloud class.\n\nHit by wind blower\n\nApplying UML to Your Project\nSeveral books, like [Muller97], describe the rules for widely used languages when\n\ntranslating the class diagram into plain code. However, the best option is to use a case\ntool that supports the whole iterative process, can generate the code in a chosen lan-\nguage, and can even reverse-engineer your code. This way, you have all the latitude\n\nnecessary to keep both the UML model and the code consistent.",
      "content_length": 1420,
      "extraction_method": "OCR"
    },
    {
      "page_number": 84,
      "chapter": null,
      "content": "Section 1 General al Programming\n\nCurrently, the most popular UML tools are Together ControlCenter\n[Together02] and Rational Rose [Rational02]. The latter has been reviewed in Game\nDeveloper Magazine [Sari01], a sign that it is making its way into the game-develop-\nment community. There is also an open-source case modeler, ArgoUML [Argo02];\nbut since it is Java based, it does not implement complete code generation yet.\n\nREIL ROB ERE EINND\n\nThis gem proposed techniques for using UML for g game programming. It demon-\nstrated that using a modeling language can help game designers create object-oriented\ndesigns and emphasize the collaborative work between the programmer and the\ndesigner. The most recent version of UML (1.3) has many more features to offer that\ncan be adapted for your team collaboration.\n\nUsing a case tool gives you the ability to work incrementally with object-oriented\nmethods, while keeping complete control over the code and increasing maintainabil-\nity, documentation, and reusability of the game engine.\n\nReferences\n\nBeen Oe AR MING MENS AR ORIEN IO EERE\n\n[Argo02] ArgoUML Project, available online at t http: /Iwrwe. argouml. .org.\n\n[Dybsand00] Dybsand, Eric, “A Finite-State Machine Class,” Game Programming\nGems, Charles River Media, Inc., 2000: pp. 237-248.\n\n[GPG01] DeLoura, Mark, Game Programming Gems 2, Charles River Media, Inc.,\n2001.\n\n[Muller97] Muller, Pierre-Alain, Jnstant UML, Wrox Press, Inc., 1997.\n\n[Python02] Python 2.2 Script Language, available online at http: //www.python.org.\n\n[Rational02] Rational Software Corporation, http://www.rational.com.\n\n[Sari01] Sari, Jonathan, “Product Review: Rational Rose,” Game Developer Magazine,\nJuly 2001: pp. 10-11.\n\n[Smith01] Smith, Harvey, “The Future of Game Design: Moving Beyond Deus Ex\nand Other Dated Paradigms,” available online at http: ://www. ipa. org/Endeav-\nors/Articles/hsmith_intro.htm.\n\n[Together02] TogetherSoft Corporation, http://www.togethersoft.com.",
      "content_length": 1959,
      "extraction_method": "OCR"
    },
    {
      "page_number": 85,
      "chapter": null,
      "content": "1.11\n\nUsing Lex and Yacc To Parse\nCustom Data Files\n\nPaul Kelly\npaul_kelly2000@yahoo.com\n\nNM: game engine subsystems have reached quite a state of complexity—they\nrequire a great deal of data to configure the behavior of that subsystem. It is\nbeneficial to have that data specified outside of code and loaded at game initialization.\nData should be in a format that is easy to modify, which can be done with a custom\ndata file. Briefly, the format of the custom data file will contain the data and descrip-\ntions of the data. The separation of data from the code by using a custom data file has\nseveral benefits:\n\n* Creating a custom data file for the subsystem helps organize the data so that it is\neasy to modify with a text editor [Boer01].\n\n* Artists and game designers can change behaviors of the subsystem to balance\ngameplay.\n\n¢ Data is managed outside of source code. If data is stored within code, then it is\nusually the programmer's responsibility to make data tweaks, which would be a\ntremendous bottleneck to a project.\n\nThe custom data file is input to a tool. The tool takes the text description of the\ndata as input and transforms the textual data into a binary form. The binary file can\nthen be loaded directly into memory at game initialization. This data transformation\nby the tool will require a parser. However, writing custom parsers for all game subsys-\ntems would require a great deal of work. Why reinvent the wheel?! Lex and Yacc, an\napplication toolset that allows programmers to create a ‘programming language’ for a\ngame subsystem, can do most of the work for you. Lex and Yacc can extract data from\na text file and pass the data along to a tool for further processing. This gem presents\nmethods for using Lex and Yacc within a tool for processing custom data files that can\nbe compiled into binary data for a game subsystem.\n\nThe different sections of this gem break down the process of how to build a lexer\nand parser for a custom data file, as well as how to build a simple data file format. The\nfirst two sections provide a brief description of the basic functionality of Lex and Yacc.\nThe third section covers how both work together to parse custom data files. Refer to\n[Levine92] for a more complete reference for Lex and Yacc.\n\n83",
      "content_length": 2264,
      "extraction_method": "OCR"
    },
    {
      "page_number": 86,
      "chapter": null,
      "content": "84 Section 1 General Programming\n\nThe last two sections cover methods of using Lex and Yacc to generate game data.\nThe first method will discuss generating game data from a custom data file for a game\nsubsystem. The second method will cover creating loadable game data from interme-\ndiate export data files. Finally, an example will be given. The examples in this gem\nwere tested using the non-GNU Flex and GNU Bison (instead of Lex and Yacc). See\nAvailability of Flex and Bison, at the end of this gem, for instructions on how to obtain\nthese applications.\n\nLex generates a source code file that specifies a lexical analyzer (also know as a lexer or\na scanner). In general, a lexer takes an input text file and combines the characters of\nthe text into individual pieces called tokens, which are assigned a meaning by the\nlexer. The tokens can then be passed to the parser [Aho86]. In our case, the parser\nwould be created by Yacc.\n\nThere are three sections to every Lex file: a C code section and the lexer specifica-\ntion, which is followed by another C code section. The first is used for inserting\ninclude files and the declaration of constants, macros, global variables, function proto-\ntypes, and other data types that are used by the lexer and the last (C code) section.\nThe second section defines the lexer. A lexer is defined by regular expressions that will\nbe used to tokenize the input. The last section is where code, such as utility functions\nfor processing input, will be located.\n\nYacc\n\nsna\n\nsah esse et tence se\n\nYacc is a parser generator. Yacc generates a source code file that specifies a parser (and\nan optional header file to be used by the Lex-generated code that contains token\ndefines). In general, a parser takes the tokens produced by the lexer and combines\nthem into phrases that have a particular meaning. Actions can be associated with the\nphrases. In our case of using custom data files, these actions are used to determine\nhow the text file should be interpreted into binary data.\n\nA Yacc specification has a similar setup as a Lex specification. The first section\ncontains C code and is usually used for inserting include files and the declaration of\nconstants, macros, global variables, function prototypes, and other data types that are\nused by the parser and the second C code section. The second section contains the\nparser definition. The parser definition consists of production rules and the associated\naction when a production rule is matched. The last section contains another C code\nsection that contains code used within the parser specification. Functions for error\nreporting and other input processing functions are located in this section.\n\ndvantages and Disadvantages\n\nSo, what is the advantage of using Lex to write lexers and Yacc to write parsers?\n[Levine92] points out that even a small lexer written in C that handles a simple com-",
      "content_length": 2884,
      "extraction_method": "OCR"
    },
    {
      "page_number": 87,
      "chapter": null,
      "content": "1.11 Using Lex and Yace To Parse Custom Data Files 85\n\nmand language is three times as long as the equivalent Lex program. This could mean\nthat the C version could take three times as long to debug. When using Lex, there is\nonly a need to debug the regular expression or other code that determines string\nmatches for tokenizing the text. The same argument can be made for using Yacc.\nNevertheless, there are disadvantages to using a lexer created by Lex and parser cre-\nated by Yacc. The disadvantages are the same for both. The generated code is often\nmuch larger than it would be if you wrote it yourself. This is due to the necessary code\nthat handles all the functionality of Lex and Yacc—wasted space if that functionality is\nnot used. Also, the execution time of code generated by Lex and Yacc tends to be slower.\nThis because optimizations that could be performed in the coding of a lexer or a parser\ncannot be performed within a Lex lexer and a Yacc parser with as much relative ease.\n\nse RNS\n\ne anding of how Lex and Yacc work independently. How do\nthey work together to construct a parser for a tool? As shown in Figure 1.11.1, source\nfiles generated by Lex and Yacc are compiled and linked into a tool that uses them.\nThe tool will assign the Yacc global variable, yyin, to be a pointer to the custom data\nfile. Next, the tool will call yyparse() to start the parsing of the input text file. (See\nListing 1.11.4 for an example main() for a tool.) The source code that Yacc generates\nhas calls to the lexer functions created by Lex to grab the tokens of the input (the custom\n\nLex specification Lex generated C lexer code\n\nYacc specification Yacc generated C parser code\n\nC compiler generated object files\n\ntool's C source\n\ntool's executable file\n\nLinker\n\nFIGURE 1.11.1 Overview of the creation of a tool that uses a Lex and Yacc specification.",
      "content_length": 1854,
      "extraction_method": "OCR"
    },
    {
      "page_number": 88,
      "chapter": null,
      "content": "86 Section 1 General Programming\n\ndata file), Data is passed from Lex to Yacc by using the Yacc sunion and another Yacc\nglobal variable, yyival. Data is passed to the tool from Lex and Yacc through global\nvariables. The values of the global variables are assigned within the actions of the\nparser specification (see Figure 1.11.2). The introduction to Lex and Yacc given above\nis a very basic one. For more information about Lex and Yacc, see [Levine92].\n\ncustom data file\n\nget next token\n\ndata file\n\nFIGURE 1.11.2 Interaction of lexer, parser, and a tool that uses them.\n\ndata extracted from\n\nA custom data file can be used to specify data for a game subsystem. The structure of\n\nthe custom data file can be difficult to define. However, most game data has some\nkind of structure that can be exploited to form a data file format that is both sensible\nin design and intuitive to the user. It is best to start simple and build on working cus-\ntom data file formats. For example, take a game that has a weapon system. A weapon\ncan have static and dynamic data. Static weapon data would include things like max-\nimum ammo ina clip, ammo type, and firing rate, to name a few. The static data can\n\ndata file, and the Yacc specification for the custom data file.\n\nListing 1.11.1 Weapon dat\n\nSTART_AMMO\nAMMO 9NM\nDAMAGE 5\nEND\nAMMO. 50CAL\nDAMAGE 15\nEND\nEND\n\nSTART_WEAPON\n\nbe configured using a custom data file. Listing 1.11.1 (on the CD-ROM) is an exam-\nple of a custom data file for a weapon system, the Lex specification for the custom",
      "content_length": 1529,
      "extraction_method": "OCR"
    },
    {
      "page_number": 89,
      "chapter": null,
      "content": "1.11 Using Lex and Yacc To Parse Custom Data Files 87\n\nWEAPON MP5\nAMMO_CLIP) 30 /* num bullets in clip */\nAMMO_TYPE 9MM /* in millimeters *]\nFIRE_RATE 60 /* in rounds per second */\nEND\n\nWEAPON DESERT_EAGLE\nAMMO_CLIP 10\nAMMO_TYPE 50CAL\nFIRE_RATE 150\n\nEND\n\nEND\n\nThe custom data file must have enough structure so that a Yacc specification can\nbe made to uniquely identify all the elements of the file. This is mostly achieved in the\nabove example by delimiting sections with start and end symbols. Listing 1.11.1 can\nbe used as a template for most simple data-file formats. More-complicated formats\nwill use a similar structure, but will probably embed more nested substructures (areas\nsurrounded by a start symbol and an end symbol).\n\nA similar custom data file, Lex specification, and Yacc specification can be used\nfor power-up data, AI attributes, inventory data, player attributes, vehicle properties,\nand any other data for which a custom data file can be created. These systems would\nhave a similar data file to the weapon system’s data file.\n\nA custom data file can be created for menu or HUD system data, where data\nwithin those items might be dynamic, but the items themselves usually don’t change. A\nwhole specification can be created for menus within a data file that can be used to\nbuild all the screens of the game. For those of you familiar with Windows program-\nming, the resulting file would be similar to a Windows resource file. The specification\nwould tell the location of elements of the menu screen and the possible range of values.\n\nA Complete\n\nON THE CD\n\nLex and Yacc can also be used to parse text data exported from tools like 3D Max. It is\n\nsometimes easier to spot errors in model, terrain, and animation data exports if it is\nexported first to a text file for visual inspection. A parser can be written to convert the\ntext data to a binary file that can be loaded at game initialization. The parser could\nalso do error checking on the data if that is desired. An example of this kind of parser\ncan be found on the CD-ROM. The Packer program takes a text description of a\n.md3 Quake III model file and converts it to its binary representation. Unpacker is\nalso included on the CD-ROM. It converts a .md3 in binary form to its text form.\n\namp\nWe will now present an example (on the CD-ROM) using the custom data file format\nof the weapon system presented in Listing 1.11.1. We'll start by looking at the Lex\nspecification in Listing 1.11.2 (on the CD-ROM). The lexer code (generated by Lex)\nis called from the parser (generated by Yacc) whenever a new token is needed. As you",
      "content_length": 2600,
      "extraction_method": "OCR"
    },
    {
      "page_number": 90,
      "chapter": null,
      "content": "88\n\ncan see, the lexer simply returns the next token it encounters. If the input text is\n“START_WEAPON,” the token constant TKN_START_WEAPON is returned to the Yacc\nfunction that called for the token. The Yacc functions retrieve tokens until a parse\nmatch is obtained. In addition to the type of token, values used in the parser actions\ncan be returned to the Yacc function via yylval.\n\nListing 1.11.2 Lex specification for weapon data\n\nan\n\n/* C code section for Lex specification */\n\n/*** INCLUDES ***/\n\n#include “weapon_y.h\" /* include token macros\ngenerated by yacc */\n\n#include <stdlib.h>\n#include <string.h>\n\n/*** PROTOTYPES ***/\nvoid RemoveComment (void);\n\nreturn TKN_FIRE_RATE; }\nreturn TKN_DAMAGE; }\n\nFIRE_RATE\nDAMAGE\n\n%}\n/*** LEXER SPECIFICATION ***/\n56%\nSTART_WEAPON { return TKN_START_WEAPON; }\nSTART_AMMO { return TKN_START_AMMO; }\nEND { return TKN_END; }\nWEAPON { return TKN_WEAPON; }\nAMMO { return TKN_AMMO; }\nAMMO_CLIP { return TKN_AMMO CLIP; }\nAMMO_TYPE { return TKN_AMMO_TYPE; }\n{\n{\n\n[0-9]+ { yylval.integer = atoi (yytext);\nreturn TKN_INTEGER; }\n\nu yee { RemoveComment (); }\n\n[a-2A-Z0-9]*[a-zA-Z}][_a-zA-Z0-9]*\n{ strepy (yylval.string, yytext);\nreturn TKN_IDENTIFIER; }\n\n56%\n/* C code section for Lex specification */\n\n/* function to remove a comment from the input data file. */\nvoid RemoveComment (void)\n\n{\nint ct =0, c2 = input();\n\nfor (33)\n{\n\nSection 1 General Programming",
      "content_length": 1394,
      "extraction_method": "OCR"
    },
    {
      "page_number": 91,
      "chapter": null,
      "content": "1.11 Using Lex and Yacc To Parse Custom Data Files 89\n\nif (c2 == EOF)\n\n{\nbreak;\n}\nif (c1 == '*' && c2 == '/')\n{\nbreak;\n}\nc1 = c2;\nc2 = input();\n\n}\n\nNext, we'll inspect the Yacc specification in Listing 1.11.3. The Yacc specification is\na Backus-Navr Form (BNF) grammar [Aho86] with embedded actions. This Yacc speci-\nfication starts with the values that can be returned from the lexer, designated with the\nxsunion{} group. Next are the token types the lexer can return. These constants will\nbe placed in a header file. (A command-line argument to Yacc is necessary to generate the\nheader file and that header filename will need to be included in the Lex specification file.)\nThe second section of the Yacc specification is the parser definition. When a parser match\noccurs, any action associated with the match is executed. For instance, when “WEAPON\nMP3” is parsed, the action strcpy(weapon_tbl[weapon_cnt], $2->string); is executed,\nand then the parse continues until the whole input file is processed (assuming no errors\nhave occurred). This action specifies copying the production rule’s second token’s string\nvalue (returned by Lex) into the weapon table. The $2 denotes the token and the field\nspecifies what data is expected to be returned from Lex. These are unioned fields so be\ncareful! In this case, $2->string will be the string “MPS.”\n\nListing 1.11.3 Yace specification for weapon data\n_ custom data file.\n\naeRO aM a Oana eS RR GE NTS RR RSME\n\n/*** INCLUDES ***/\n#include \"weapon.h\"\n#include <string.h>\n#include <stdio.h>\n\n/*** GLOBAL VARIABLES ***/\nextern char *yytext;\n56}\n\n/*** TOKENS ***/\n// return types for tokens\n\nS%union\n{\nint integer; // for INTEGER token\nchar string[80]; // for IDENTIFIER token\n}\n\n// used by the lexer as return values so that the",
      "content_length": 1771,
      "extraction_method": "OCR"
    },
    {
      "page_number": 92,
      "chapter": null,
      "content": "90\n\nSection 1 General Programming\n\n// parser knows which tokens have been found\n%stoken TKN_START_WEAPON TKN_START_AMMO TKN_END\n%stoken TKN_WEAPON TKN_AMMO\n\nS%stoken TKN_AMMO_CLIP TKN_AMMO_TYPE TKN_FIRE_RATE\n%stoken TKN _DAMAGE\n\n// tokens that can return a value from Lex to Yacc via // yylval\n%token <integer> TKN_INTEGER\n\n%stoken <string> TKN_IDENTIFIER\n\n%%\n\n/*** YACC SPECIFICATION ***/\n\n// weapon_data is the start symbol\n\nweapon_data: /* lamda rule - empty rule */\n| weapon_data weapon_section\n| weapon_data ammo_section\n\nweapon_section: | TKN_START_WEAPON weapon TKN_END\nweapon:\n/* lamda rule - empty rule */\n| weapon TKN_WEAPON TKN IDENTIFIER\n{ strcpy (weapon_tbl[weapon_cnt], $3); }\nweapon_attribute TKN_END\n{ weapon_cnt++; }\nweapon_attribute:\n/* lamda rule - empty rule */\n| weapon_attribute ammo_clip\n| weapon_attribute ammo_type\n| weapon_attribute fire_rate\n\nammo_clip:\nTKN_AMMO_CLIP TKN_INTEGER\n{weapon [weapon_cnt].ammo_clip = $2;}\nammo_type:\nTKN_AMMO_TYPE TKN_IDENTIFIER\n{strcpy (weapon [weapon_cnt].ammo_type, $2) ;}\nfire_rate:\nTKN_FIRE_RATE TKN_INTEGER\n{weapon [weapon_cnt].fire_rate = $2;}\n\nammo_section: TKN_START_AMMO ammo TKN_END\nammo:\n/* lamda rule - empty rule */\n| ammo TKN_AMMO TKN_IDENTIFIER\n{ strcepy (ammo_tbl[ammo_cnt], $3) ;}\nammo_attribute TKN_END\n{ ammo_cnt++;}\nammo_attribute:\n/* lamda rule - empty rule */\n| ammo_attribute TKN_DAMAGE TKN_INTEGER\n{ammo [ammo_cnt].damage = $3;}\n%6%\nint yyerror (const char *msg)\n{\nprintf (“%s at '%s'\\n\", msg, yytext);\nreturn 0;",
      "content_length": 1493,
      "extraction_method": "OCR"
    },
    {
      "page_number": 93,
      "chapter": null,
      "content": "1.11. Using Lex and Yacc To Parse Custom Data Files 91\n\n}\n\nListing 1.11.4 shows the general shell of a main() function from a tool that would\nuse the lexer and parser generated by Lex and Yacc.\n\ne code.\n\n#include \"“y.tab.h\nWEAPON_DATA weapon;\nint main (void)\n{\nFILE *in;\nin = fopen (\"weapon.data\", \"r\");\nyyin = in;\nyyparse() ;\n\n/* process data in weapon and write out as binary\ndata */\n\nreturn 0;\n\nConclusion\n\nThis gem shows how Lex and Yacc can be used to create parsers for custom data files.\nWith Lex and Yacc, you are given access to tools that can generate a very powerful\nparser. Take the time to get to know and become familiar with these tools; your time\nspent will be repaid tenfold in future time savings.\n\nAvailability of Flex and Bison\n\nFlex, a version of Lex that can be found on the GNU Website, and Bison, GNU’s ver-\nsion of Yacc, are available for free at the GNU Website [GNU02]. See [Flex02] and\n[Bison02] for FTP download information.\n\nReferences\n\n[Aho86] Aho, Alfred, et al., Compilers: Principles, Techniques, and Tools, Addison\nWesley, 1986.\n\n[Bison02] Free Software Foundation, March 2002. Bison Flex is available for down-\nload at ftp://ftp.gnu.org/gnu/bison/.\n\n[Boer01] Boer, James, “A Flexible Text Parsing System,” Game Programming Gems 2,\nCharles River Media, Inc., 2001.\n\n[Flex02] Free Software Foundation, March 2002. Flex is available for download at\nftp://ftp.gnu.org/gnu/non-gnu/flex/.\n\n[GNU02] Free Software Foundation, “GNU’s Not Unix!—the GNU Project and the\nFree Software Foundation (FSF),” available online at http://www.gnu.org/,\nMarch 2002.\n\n[Levine92] Levine, John, et al., Lex & Yace, O'Reilly 8& Associates, Inc., 1992.",
      "content_length": 1662,
      "extraction_method": "OCR"
    },
    {
      "page_number": 94,
      "chapter": null,
      "content": "1.12\n\nMarket Potential\n\n92\n\nDeveloping Games for\na World Market\n\nAaron Nicholls, Microsoft Corporation\naaron_feedback@hotmail.com\n\nUh recently, developing games for multiple language markets was often done as\nan afterthought. Once the product was ready (or nearly so) for release in its core\nlanguage market, the coding work to support other languages would begin, with test\nand localization soon following. The resulting products were often delayed and very\nlimited in terms of language support. However, in recent years, many companies have\nreleased games in multiple language markets simultaneously, and titles such as Star-\ncraft and Diablo 2 have enjoyed phenomenal sales worldwide.\n\nIn order to capitalize upon the full market for a game, it is important to under-\nstand the technical obstacles and processes related to globalization. In addition, inte-\ngration of globalization techniques into the entire developmental process is essential.\nIn this gem, we will present the main issues related to the design, development, and\ntesting of world-ready games, as well as some solutions to the inherent problems.\n\nc.neceoraanonmnsianaantandrmniati ‘AOS ANNSAAALAN ANNA AARNE I CNR NORA RRTAN\n\n‘Traditionally, many games companies have had a tendency to focus on their local\nmarket, ignoring the global potential of a quality title. Many titles have received uni-\nversal praise and strong sales in the U.S., but no attempts were made to introduce the\ntitles to new markets. In other cases, a title is released worldwide, but the game is\nentirely in English—only the manual is translated. Fans of a specific genre and avid\ngamers in the know might be willing to put forth the effort to tackle a game that is\nnot in their native tongue. However, as a wider audience embraces PCs and game\nconsoles, it is important to appeal not only to the hardcore gamer, but to casual\ngamers as well.\n\nIn the past few years, there have been several game releases that have identified\nthe size of the international game market. For example, in 2000 and 2001, South\nKorea proved to be a very promising market. Both Starcraft and Diablo 2 were big\nhits, each selling more than 3 million copies worldwide. Of that total, approximately\none third of the sales were in South Korea alone, with over a million copies of each",
      "content_length": 2299,
      "extraction_method": "OCR"
    },
    {
      "page_number": 95,
      "chapter": null,
      "content": "1.12 Developing Games for a World Market - 93\n\ngame sold there. The games became cultural phenomena of a sort, with the game\ncharacters featured in toys and on potato chip bags.\n\nSuch success stories have not only been the case with American games selling out-\nside of the U.S. As of January 2002, the best-selling, massively multiplayer, online\nrole-playing game was not Ultima Online, Asheron’s Call, or Everquest, but the Korean\ngame Lineage with over 4 million copies sold—and it hadn't even launched in the U.S.\nand Europe yet! With such examples of success, it is easy to understand the impor-\ntance of designing a game from the ground up to appeal to a world market of gamers.\n\ndisplaying the desired language(s). In addition, you might choose to provide input\noptions and customizations particular to each language version of your game.\n\nFonts\n\nFirst of all, you need fonts that contain all of the characters that must be displayed.\nWhile bitmap fonts are still used in some games, many have moved to TrueType and\nOpenType fonts for ANSI and Unicode character display, respectively. Unicode fonts\ncan contain characters for multiple languages, but they can result in much larger file\nsizes, also.\n\nFortunately, the latest versions of Windows and MacOS support input and dis-\nplay of a wide variety of languages, including the necessary fonts. However, games\ntypically use their own fonts (with the possible exception of install/uninstall), and it is\nimportant to consider a game’s target markets when obtaining or developing fonts. In\naddition, keep in mind that while English text may look perfectly clear in an 8-point\nfont, applying the same size to a traditional Chinese font might produce illegible text.\nYour game should be designed with enough flexibility to take such issues into\naccount.\n\nLine Breaks and Sorting\n\nIf your game supports multiline text input or display, one of the problems that can\narise is that of breaking multiple lines of text. The rules for line-breaking are relatively\nsimple for English and other European languages, but things are not as simple for\nmany other languages. For example, in Chinese and Japanese, spaces typically are not\nused to distinguish individual words in a sentence. Instead, sentences consist of char-\nacters with no spacing, although similar (but double-byte) punctuation is still used.\nAs such, it may be necessary to use more-advanced guidelines for determining where\nto break lines and wrap words. When dealing with multi-byte text, you can adopt the\nfollowing rule: Lines may be broken before, after, or between double-byte characters.\nHowever, when a line break is needed within single-byte characters, you should break\nat the last space or double-byte character.",
      "content_length": 2730,
      "extraction_method": "OCR"
    },
    {
      "page_number": 96,
      "chapter": null,
      "content": "1.12 Developing Games for a World Market 93\n\ngame sold there. The games became cultural phenomena of a sort, with the game\ncharacters featured in toys and on potato chip bags.\n\nSuch success stories have not only been the case with American games selling out-\nside of the U.S. As of January 2002, the best-selling, massively multiplayer, online\nrole-playing game was not Ultima Online, Asheron’s Call, or Everquest, but the Korean\ngame Lineage with over 4 million copies sold—and it hadn't even launched in the U.S.\nand Europe yet! With such examples of success, it is easy to understand the impor-\ntance of designing a game from the ground up to appeal to a world market of gamers.\n\nFirst Things First—Display and Input\n\nceo RUAN\n\nWhen dealing with international game development, o1 one e of the first challenges is in\ndisplaying the desired language(s). In addition, you might choose to provide input\noptions and customizations particular to each language version of your game.\n\nFonts\n\nFirst of all, you need fonts that contain all of the characters that must be displayed.\nWhile bitmap fonts are still used in some games, many have moved to TrueType and\nOpenType fonts for ANSI and Unicode character display, respectively. Unicode fonts\ncan contain characters for multiple languages, but they can result in much larger file\nsizes, also.\n\nFortunately, the latest versions of Windows and MacOS support input and dis-\nplay of a wide variety of languages, including the necessary fonts. However, games\ntypically use their own fonts (with the possible exception of install/uninstall), and it is\nimportant to consider a game's target markets when obtaining or developing fonts. In\naddition, keep in mind that while English text may look perfectly clear in an 8-point\nfont, applying the same size to a traditional Chinese font might produce illegible text.\nYour game should be designed with enough flexibility to take such issues into\naccount.\n\nLine Breaks and Sorting\n\nIf your game supports multiline text input or display, one of the problems that can\narise is that of breaking multiple lines of text. The rules for line-breaking are relatively\nsimple for English and other European languages, but things are not as simple for\nmany other languages. For example, in Chinese and Japanese, spaces typically are not\nused to distinguish individual words in a sentence. Instead, sentences consist of char-\nacters with no spacing, although similar (but double-byte) punctuation is still used.\nAs such, it may be necessary to use more-advanced guidelines for determining where\nto break lines and wrap words. When dealing with multi-byte text, you can adopt the\nfollowing rule: Lines may be broken before, after, or between double-byte characters.\nHowever, when a line break is needed within single-byte characters, you should break\nat the last space or double-byte character.",
      "content_length": 2865,
      "extraction_method": "OCR"
    },
    {
      "page_number": 97,
      "chapter": null,
      "content": "94\n\nSection 1 General Programming\n\nIn addition to line/word breaking, sorting rules also vary from language to lan-\nguage, and sorting by character code is usually insufficient. Fortunately, these rules are\nusually defined in the operating system and are typically exposed to you as the devel-\noper through system APIs.\n\nInput Method Editors (IMEs)\n\nOnce you have your characters displaying properly, you need to deal with input as\nwell. While some games allow input only in English, this can be very limiting when\ndealing with saving games, chatting with other players, or jotting down in-game notes\n(for those games with such features). Many users do not speak English as a first lan-\nguage, and limiting input to English can distract gamers and reduce immersion into a\ngame. Although supporting input of European characters requires few changes from\nan English-based product, other languages, such as Korean, Chinese, and Japanese,\nmight require more work to support.\n\nThe first problem with implementing support for input of these languages is that\neach of them has thousands of characters—far too many to fit on a keyboard. When\ndeveloping computer-based games, it might be possible to implement or use existing\ninput method editors (IMEs). An IME is a program that converts keyboard scan\ncodes (and, more recently, pen- or mouse-driven input) into character codes.\n\nFor example, for a user to input the word “sushi” in Japanese, they will first acti-\nvate the IME (usually with a user-defined keystroke or a dedicated key on a Japanese\nkeyboard). The IME then activates, and it intercepts the English letters “s-u-s-h-i” or\na Japanese phonetic equivalent as they are typed by the user. The IME then gives the\nuser a choice of candidate words corresponding to the phonetic spelling input by\nthe author. Once the user selects the desired word (or string), the actual character\ncodes representing the desired Japanese input are sent to the target application. If you\nchoose to support IME input in your game, you should familiarize yourself with the\nIME message codes and architecture for your platform (see References for Web links\nto IME information).\n\nInput Options Without IMEs\n\nUnfortunately, IME support is not always an option. Due to UI design or develop-\nment constraints, it may be impractical to implement or use an existing IME. This is\nusually the case when the target platform is a game console. However, with basic\nknowledge of the target language(s) for a game, it might still be possible to provide\nthe user with some level of input support.\n\nFor example, in a Japanese game, it is possible to allow users to input player\nnames in Japanese by providing an onscreen virtual keyboard containing only the\nkatakana or hiragana (collectively referred to as Kana) characters. These are two sets of\nphonetic characters, either of which can be used to represent any word in the Japan-\nese language. Although either alphabet is sufficient to represent any Japanese word",
      "content_length": 2980,
      "extraction_method": "OCR"
    },
    {
      "page_number": 98,
      "chapter": null,
      "content": "1.12 Developing Games for a World Market 95\n\nphonetically, each has its own use, somewhat like upper- and lowercase letters in\nEnglish. A hiragana or katakana keyboard to allow input in Japanese can be imple-\nmented in approximately the same amount of screen space required for an English\nupper/lowercase keyboard. An example of such an interface can be seen in Figure\n1.12.1, taken from Microsoft’s Japanese Xbox user interface. However, it is of course\nnecessary to weigh the benefits of such a solution with the impact of such a feature\non testing and development.\n\nSY IOS\n\nFIGURE 1.12.1 On-screen keyboard for input of (A) Japanese hiragana characters, (B) Japanese\nkatakana characters, and (C) English characters, from Microsoft Xbox. Screen shots reprinted by\npermission from Microsoft Corporation.",
      "content_length": 804,
      "extraction_method": "OCR"
    },
    {
      "page_number": 99,
      "chapter": null,
      "content": "Character Sets\n\nSection 1 General Programming\n\nUnits and Display Formatting\n\nWhen developing a game, it is important that the interface not interfere with immer-\nsion into the game itself. One way in which you can provide the user with a familiar\ninterface is to default to the date, time, and number formats that the user is likely to\nprefer. It can be disorienting to go through savegame files as DD/MM/YY when you\nexpect dates to be displayed in YY/MM/DD format. Similar problems can occur\nwhen dealing with numeric and time formats (is it 1,234.56 or 1.234,562), as well as\nunits for speed, weight, or distance.\n\nWhile it might be appropriate in many cases to choose the most common default\nformat for the target market, keep in mind that some operating systems (especially\nWindows and MacOS) allow users to specify these preferences in great detail. In addi-\ntion, some console makers hard-code these formats differently, depending on the tar-\nget market for the console. If your game retrieves these settings from the system, you\ncan provide the user with their preferred display formats automatically.\n\nWhen implementing support for various languages into a game, there are several dif-\nferent character encoding schemes that can be used. While there seems to be a gradual\nmove toward Unicode on some platforms, there are advantages and disadvantages to\neach character encoding scheme. Typically, the scheme you choose will depend on\nyour platform, target languages, and any dependencies you might have on legacy or\nother code that is not world-ready.\n\nSingle-Byte Character Sets (SBCS)\n\nIn addition to character display, another issue that has to be dealt with is character\nencoding. When dealing with traditional ASCII text, one byte is required to store one\ncharacter. This is called a “single-byte character set” (SBCS) and is often used to\nencode data from English and other European languages.\n\nHowever, even within SBCS, there are multiple systems for encoding. The ASCII\nstandard uses 7 bits to store characters, with the 8th bit (originally) used for parity\nchecking. This allows 128 characters (0-127) to be stored, which is sufficient for\nEnglish text, punctuation, and a few control characters. Unfortunately, this is not suf-\nficient for many other European languages, which need to represent accented charac-\nters, additional letters, and symbols that are not typically used in the English\nlanguage.\n\nIn order to represent these additional languages, several extensions to the ASCII\nstandard were proposed. Since the parity bit is no longer needed, the full 8-bit range\nis utilized, with characters 0-127 typically kept identical to ASCII specifications and\ncharacters 128-255 used to store additional characters, punctuation, and symbols. In\nWindows, for example, these are represented by a form of the ANSI character set",
      "content_length": 2843,
      "extraction_method": "OCR"
    },
    {
      "page_number": 100,
      "chapter": null,
      "content": "1.12 Developing Games for a World Market 97\n\nknown as ISO-8859. However, in order to represent various languages, multiple code\npages (or encodings of characters to numerical values) have been developed. Typically,\nSBCS code pages differ only in the definition of the upper-range characters 128-255.\nHowever, since single-byte character sets can only represent 256 symbols, it is still not\npossible to represent even the full range of European languages, much less languages\nsuch as Chinese, Japanese, or Korean (often referred to collectively as CJK).\n\nDouble and Multi-byte Character Sets (DBCS/MBCS)\n\nTo represent a wider range of characters, larger character sets were developed. As the\nname implies, a double-byte character set (DBCS) uses two bytes per character, and a\nmultibyte character set (MBCS) contains characters of varying length. One example\nof this is the Japanese Shift-JIS encoding scheme, which uses characters of one or two\nbytes.\n\nIn the Shift-JIS system, single-byte characters fall from 0x00 to 0x7F for ASCII\ncharacters and 0xA0 to OxDF for Japanese single-byte kana. Double-byte characters\nconsist of lead bytes and trail bytes, and lead bytes fall in the range excluded by the\nsingle-byte characters, namely 0x81 to 0x9F and OxEO to OxFC. Such systems can\nencode tens of thousands of characters through this extended encoding; but they are\ntrickier to develop for because character-counting, word-wrapping, and cursor-move-\nment algorithms have to compensate for varying character sizes. In addition, since the\nlead-byte ranges vary for different MBCS encodings, your code might need to provide\ndifferent cases for different Asian languages. Although the term DBCS is often used\nfor encodings such as Shift-JIS, MBCS is a more appropriate definition and is the\nnotation used in the C/C++ standards.\n\nProgramming for Various Byte-Size Character Sets\n\nWhen working with SBCS data, while code pages might be a concern, characters and\nbytes are always one-to-one, requiring few code changes. Memory allocation, cursor\nmovement, searching, editing, and word breaking remain relatively trivial. However,\nwhen coding for DBCS or MBCS data, it is necessary to take into account the fact\nthat a character does not necessarily correspond to a byte, and vice-versa.\n\nTo begin with, when allocating memory for DBCS/MBCS strings, confusing\nbytes with characters can lead to disastrous results. For example, if a player's name is\nallocated as a 16-byte string, and the input algorithm counts user input by characters\ninstead of bytes, a buffer overflow can occur, leading to instability and/or security\nproblems. In addition, the interface needs to handle cursor movement, editing, and\nsearches in terms of characters, rather than bytes.\n\nIn particular, searches are another area that can be problematic. For example,\nwhen parsing a file path, it is essential to distinguish between a forward or backslash\nand the same character code used as a nonlead byte of a double- or multibyte charac-\nter. Failure to do so can lead to file-loading problems, savegame corruption, and other",
      "content_length": 3091,
      "extraction_method": "OCR"
    },
    {
      "page_number": 101,
      "chapter": null,
      "content": "98\n\nInterface and Design Considerations\n\nSection 1 General Programming\n\nserious bugs that are only reproducible when specific characters in certain languages\nare used.\n\nSince such problems are so difficult to identify (and often discovered by isolated\ncustomers after release), it is necessary that your test team understands and tests for\nthese types of issues in order to prevent them from reaching the finished product.\nFirst of all, care must be taken in development to ensure that all string search and\nparsing algorithms are DBCS/MBCS-aware. In addition, identifying a core set of\nsuch ‘danger characters’ and including them in all string-algorithm testing can be\neffective in detecting problems before the production stage.\n\nMBCS-Specific Problems\n\nIn MBCS systems, editing can be even more complicated. For example, merely hit-\nting the backspace key while editing can trigger a full string parse, required to deter-\nmine the number of bytes to delete. First of all, we don’t immediately know if the byte\nimmediately before the cursor represents a single byte or part of a multibyte character.\nWe can determine that by stepping backward one character at a time until we reach\neither the beginning of the string or a character sequence that is definitively a single-\nor multibyte character. From that point, we can determine the number of bytes in the\ncharacter to be deleted.\n\nIn the worst case, it might require parsing back to the beginning of the string. As\nsuch, it might actually be more efficient to parse the string from the beginning, espe-\ncially when dealing with short strings. However, there is an alternative. Many systems\ncontain MBCS-aware APIs for solving such problems. In Windows, for instance, the\nCharPrev, CharNext, and IsDBCSLeadByte APIs make this process easier by encap-\nsulating this functionality into a simple system call.\n\nUnicode\n\nFortunately, there is a way to support a variety of languages with a single codebase and\nwithout having to deal with code pages and characters of varying lengths. The Uni-\ncode standard defines approximately 40,000 characters in a constant two-byte format,\nsupporting characters, symbols, and codes necessary to display the majority of major\nlanguages in a single code page. Although the standard also specifies extensions for\nsupporting millions of characters and a plethora of languages (even Klingon!), the\ndouble-byte Unicode standard is typically sufficient for most games, and its flexibility\nand universal nature has made it the encoding system of choice for many serious,\nworld-ready games. For more information on Unicode, please see [Unicode02] or the\nlatest published version of the standard. At the time of this writing, the latest version\nis Unicode Standard 3.0.\n\nDENRA AAANSDAE RASTER DPMS EWE HERE H EES NEGA s Oe goer AN RR RRNA sae\n\nIn addition to the character input, encoding, and display issues that were described\nabove, there are several other areas of the game interface and design that must be",
      "content_length": 2987,
      "extraction_method": "OCR"
    },
    {
      "page_number": 102,
      "chapter": null,
      "content": "1.1 2 Developing Games for a World Market 99\n\ntaken into account when developing a game for multiple markets. These include\ndevice input and video output, as well as UI design and game content.\n\nVideo Output\n\nWhen developing for game consoles, it is important to keep video standards in mind.\nWhile televisions in the United States, Canada, Mexico, and Japan use the NTSC\nstandard at 30 (60 interlaced) frames per second, most other countries use PAL/\nSECAM, which runs at 25 (50 interlaced) frames per second. As such, be aware that\npre-rendered video for your game might need to be provided in both formats. In addi-\ntion, it is a good idea to ensure that your game does not synchronize rendering or ani-\nmation to a particular standard.\n\nKeyboard Input\n\nA common problem encountered when producing a PC game for a world market is\nthat of keyboard input. While joysticks and gamepads are for the most part standard-\nized, keyboards can vary from region to region. Some games anticipate a predefined\nset of expected scan codes (representing the physical position of a key on the key-\nboard) or virtual key codes or vkeys (typically representing the actual character on the\nkey). If your game is to have appeal in multiple language markets, it is important to\nensure that it works equally well with various keyboard layouts.\n\nThe problem arises when gamers use different keyboard layouts to play the game.\nIn the best case, they find that certain keys just aren't available for mapping. In the\nworst case, keys are misnamed or don't work in the game, a very frustrating experi-\nence. For example, the scan code for the right square bracket “]” on a U.S. English\nkeyboard maps to “+” on the German keyboard and “$” on the French. In addition,\nthe upper range of vkeys contains several values that vary from language to language,\nspecifically Oxba-Oxbf, Oxc0, Oxdb-Oxde, and Oxe2. For more details on scan codes,\nvirtual keys, and ASCII character codes, please refer to Table 1.12.1. Fortunately,\nusing a more-advanced input API, such as Windows DirectInput, can insulate your\ngame from some of these implementation details; it provides a layer of abstraction and\nincludes APIs for mapping codes to keys.\n\nTable 1.12.1 Virtual Keys, Glyphs, and ASCII Codes for Scan Codes\n\nEnglish © ; ; German — French a\nVkey Glyph ASCII\n\n0x29\n0x3d\n\nScancode _Vkey Glyph ASCII\n0x0c Oxbd Ox2d\n\nOxdf\nOxb4\n\n(Continues)",
      "content_length": 2397,
      "extraction_method": "OCR"
    },
    {
      "page_number": 103,
      "chapter": null,
      "content": "100\n\nSection 1 General Programming\n\nTable 1.12.1 Virtual Keys, Glyphs, and ASCII Codes for Scan Codes (Continued)\n\n0x27\n\n0x28\n0x29!\n0x2b\n0x32\n0x33\n0x34\n0x35\n0x56?\n\nEnglish German French\nOxba ; 0x3b OxcO 6 Oxf6 Ox4d m Ox6d\nOxde ‘ 0x27 Oxde 4 Oxe4 Oxc0 u Oxf9\nOxc0 . 0x60 Oxdc A OxSe Oxde ? Oxb2\nOxdc \\ Ox5c Oxbf # 0x23 Oxdc * Ox2a\n\n0x4d m Ox6d Ox4d mm Ox6d Oxbc ; Ox2c\n\nOxbc , Ox2c Oxbe Ox2c Oxbe ; 0x3b\nOxbe . Ox2e Oxbf : 0x3a\nOxbf / Ox2f Oxbd - 0x2d Oxdf ! 0x21\nOxe2 \\ Ox5c Oxe2 < 0x3c Oxe2 < Ox3c\n\n1 Not available on German keyboard\n2 Not available on French keyboard\n3 Not available on U.S. keyboard\n\nLanguage-Neutral UI Design\n\nRegardless of the character encoding and input method systems used in a game, one\nof the universal problems encountered is with UI design and text layout. This is par-\nticularly problematic in the localization process, when resources from various lan-\nguages are brought into the game. Even if your game’s engine and UI is designed to\nhandle a wide range of character types, it is practically guaranteed that you will\nencounter resizing and/or overlapping issues when you first localize your game.\n\nWhen developing a user interface, it is good practice to leave additional space in\nboth the UI and the necessary data storage to take into account languages that might\nuse longer strings or different fonts. For example, strings translated from English to\nGerman can grow considerably in size. If a UI is built with the English product in\nmind, with graphical buttons or UI components just large enough for the English\nstrings, it might be impossible to produce the same interface for German without\neither modification or excessive abbreviation.\n\nOne often-quoted guideline is that when using English as your source language,\nyou should leave enough room in the UI for strings to grow 30% to 50%. In addi-\ntion, shorter strings might require even more room for growth, especially when a Ger-\nman product is to be produced from an English product. This way, your UI will be\nless likely to require changes when you begin localizing to languages that might\nrequire longer strings.\n\nIn addition, it might be necessary to accommodate a taller font in order for\ndetailed Chinese or Japanese characters to be legible, especially on a console where the\ntarget display device is typically a low-resolution television without sharp pixel render-\ning. If the UI does not provide sufficient leeway for such a change, users might be faced\nwith an interface that is unfriendly or difficult to read. Another problem that can occur",
      "content_length": 2546,
      "extraction_method": "OCR"
    },
    {
      "page_number": 104,
      "chapter": null,
      "content": "1.12 Developing Games for a World Market\n\n101\n\nis overlapping; strings of text overlap improperly due to size and formatting differences\nbetween languages. Although overlapping and truncated strings might be found\nthrough manual testing of the in-game UI, it is also possible to automate this process\nand programmatically detect potential string problems before they reach the product.\n\nCulture-Neutral Game Design\n\nIn addition to making sure that the interface is designed for its target language, it is\nimportant to ensure that your game does not make any invalid assumptions regarding\ncultural associations or expectations. For example, if your game expects the character\nto drive on the left-hand side of the road, American gamers might be surprised to see\ntraffic coming at them in the right-hand lane unless you make a point of telling them\notherwise. In addition, if you have a ‘call’ button in the UI with an image represent-\ning its function, it might be best to use an icon that is relatively universal, rather than\na picture of an old-fashioned rotary dial or a traditional British phone booth.\n\nCultural and Political Sensitivity Issues\n\nOne final issue is that of cultural and political sensitivity. While many games might be\nset in a fantasy or science-fiction setting, your game will need to sell in the real world,\nand it probably won't do that by violating cultural norms or governmental standards.\nFor example, if you choose to develop a game that has strong adult themes, Nazism,\nor violent material, you might need to consider toning it down or providing a filter\nfor potentially offensive content, depending on your target market.\n\nIn addition, keep in mind the political environments of the markets where you\nanticipate selling your game. For example, if your game shows a map that contains\ndisputed regions (such as Kashmir, the western Sahara, or the Falkland Islands), take\ncare not to offend gamers or officials in your target market. This might mean modify-\ning the detail of the map or shipping different maps for different markets. In addition,\nwhen dealing with disputed territories, such as Taiwan, it might be best to avoid refer-\nring to them with the term “country.” Flags are another touchy issue, as they might\nchange frequently and exist for regions that are not recognized countries. Lastly, you\nshould take care not to offend if your game refers to existing governments, places, or\npeople. When making a game for a world market, it is important to consider the\npolitical ramifications of your content. Otherwise, you might risk alienating gamers\nin your target market or even having your game banned.\n\ntion\n\nRNSIRRR SBS BR MERUNNRT SL HEBBEN RENO EINE IR ORE NNT MOSES ESE SN RANT OIA RRR I\n\nOnce you've developed your game to display, input, and handle data in your target\nlanguage, you still have a problem—your game isn’t actually in the target language\nyet. Localization is the process of translating content and adapting interface/internal\nconfigurations to prepare a software product for another language market. Ideally, it\nshould not involve any changes to the code. Proper care should be taken during the\n\nare\n\nLocali",
      "content_length": 3165,
      "extraction_method": "OCR"
    },
    {
      "page_number": 105,
      "chapter": null,
      "content": "102\n\ndesign and development process in order to ensure that the localization process goes\nsmoothly.\n\nHard-Coded Strings\n\nQuite possibly, the biggest impediment to the localization process is that of hard-coded\nstrings and resources. When developing software, it is standard practice to store all\nstrings in a resource file outside of the source code. This allows for easy access to and\nmodification of in-game text. If such strings are actually embedded in the code rather\nthan the resources, it can be difficult to find or modify them, although this might not\nbe a problem if the strings don’t need to be changed during the life of the product.\n\nThis problem escalates when localizing a product, as having text in the wrong lan-\nguage is unacceptable. In Windows, for example, many system paths are localized in\nmany of the products, but not all. As such, any reference to system paths (and mem-\nory allocation for such strings) should query the system rather than hard-coding\nthem. In order to prevent localization problems due to hard-coded strings, it is impor-\ntant to establish and follow proper coding standards.\n\nOver-Localization\n\nAs important as localization is for a successful product, it is important to prevent what\nis called “over-localization.” This is where the localization process goes to far, localiz-\ning resources that should not be modified. For example, names of in-game objects\nshould not be localized because they are not exposed to the user, and changing their\nnames might break code that depends upon them. In order to prevent over-localization,\nall resources and strings should be marked with flags that indicate whether or not they\nshould be localized. In addition, when localizing dialogue and media, you might wish\nto document your content before it is sent to localization to ensure that the gamer\nreceives the same experience regardless of the language. For example, if a character\nspeaks broken English in the U.S. version, then the script and voice for that character\nin the localized French version should similarly portray the character as less than flu-\nent in French.\n\nLocalizing Media\n\nLocalization becomes more complicated when applied to nontextual resources. For\nexample, if your game contains graphical resources with embedded text, it is unrea-\nsonable to expect localizers to possess the proper software and skills to edit the image\nand localize it. Instead, all text embedded in graphics should be stored in a separate\nlayer and coordinated with external string tables for ease of localization. This also\nmakes it easier to modify the text in the core language product. In addition, the\ngraphic should be large enough to allow string wrapping or font changes necessary in\nthe localization process.\n\nIn addition, when producing audio or video, remember that the localized version",
      "content_length": 2826,
      "extraction_method": "OCR"
    },
    {
      "page_number": 106,
      "chapter": null,
      "content": "1.12 Developing Games for a Worid Market 103\n\nmay run longer, especially if the original version contains quickly spoken text. As\nsuch, it is best to ensure that in-game audio/video clips are long enough to accommo-\ndate various-length localized versions, and that gameplay is not affected by these dif-\nferences. In addition, if you are targeting multiple language markets, please keep in\nmind that it can be much more expensive to localize full-motion video (FMV) than\nvideo sequences using the game’s engine. The balance of FMV versus in-game\nsequences is something that must be determined early on in the project. One alterna-\ntive that may help you avoid some of these problems is to localize only subtitles for\nvideo sequences. This significantly reduces problems with media synchronization; but\nyou need to balance those advantages with the potential impact on the user experi-\nence and immersion that it might have on your game.\n\nAnother concern in localization is ensuring that the game has the same feel in\nmultiple target languages. For example, if you choose to localize audio or video in\nyour game, it is a good idea to ensure that the character and tone of the original is\ntaken into account. If a character is to sound paranoid and edgy, it is important that\nthe message gets across in all languages. In addition, if your game has a character that\nis a New York mobster, for a Japanese version, you might choose a voice actor that can\nspeak with a stereotypical, modern Osaka Yakuza accent if that is appropriate to your\ngenre. Lastly, keep in mind that if you use a celebrity in your game, he or she might\nnot be as well recognized in much of your international market.\n\nString and Audio/Video Concatenation\n\nOne final concern is that of concatenation of strings and media. Due to variations in\ngrammar and overall sentence structure, concatenating multiple strings to make a sin-\ngle sentence can be very problematic. As such, if your game must use string concate-\nnation, it is important to involve localization at an early stage to ensure later\nlocalizability. Concatenation is an even greater problem when dealing with audio and\nvideo, and extra care should be taken with a product that will be localized.\n\nDesign and Planning Considerations\n\nOnce you understand the core issues involved in developing games for a world mar-\nket, it is important to integrate this knowledge into the design and development\nprocess. There are several ways to plan multiple language releases of the same game.\nTo begin with, some teams choose to focus on the core language product initially,\nwith consideration for localized versions later in the project. This method has several\nproblems.\n\nTo begin with, the localized versions might be considerably delayed, missing the\nhalo of excitement that can follow a successful release. In addition, this approach\ntends to increase the work for localization and testing, and might significantly hamper\nfunctionality in other languages. However, this could be the only choice if a game is\nreleased for a certain market, but strong interest is shown in other language markets.",
      "content_length": 3117,
      "extraction_method": "OCR"
    },
    {
      "page_number": 107,
      "chapter": null,
      "content": "104\n\nTesting\n\nSection ai _General Programming\n\nModifying a Game After the Fact\n\nIf you are trying to add multiple language support for a game that is already shipped or\nthat is late in the development process, your choices are limited. First of all, trying to\nconvert the entire game to Unicode late in the project is expensive, time-consuming,\nand error prone. As such, it is usually not even an option. However, it is possible to\nprovide a moderate level of support for various languages at a reasonable development\nand test cost.\n\nTo begin with, it is possible to reduce support for various languages while still\nproviding desired functionality. For example, you might choose to support only Euro-\npean languages in the game UI itself, but implement wider support in the install\nengine and file system. As an alternative, it might be acceptable to allow input only in\nEnglish, but modify the game engine to support storage and display of a wider range\nof languages. Finally, you can modify the game to support MBCS (such as Shift-JIS),\nbut this can incur a large development hit and bug risk. In addition, cross-language\nfunctionality might be limited, such as chat. The determining factors should be a bal-\nance of the cost/time involved and the user experience you wish to provide.\n\nDoing it Right the First Time\n\nAlthough the above options are valid and have been used many times, successful glob-\nalization should be designed from scratch. To begin with, it is much cheaper to\ndevelop a product the right way from the onset, as opposed to tacking on desired fea-\ntures after the fact. In addition, if all versions of the game run off the same code base,\ndevelopment is less complicated and support issues are reduced because only a single\nplatform must be supported and maintained.\n\nIn the long run, it is also cheaper and faster to incorporate globalization and\nlocalization into the core design process. While this integration may incur a small\ndelay the first time around, it can greatly improve the speed with which multiple lan-\nguage versions of your game can ship. In addition, you'll be able to ship these versions\nsimultaneously, and if you choose to release multiple languages in a single media, you\ncan reduce manufacturing and support costs further.\n\nEE BRG EUSA NPAT RR NEE RI INR RAN IR ASO eS RR NNT\n\nSo far, the focus of this gem has been primarily on design and implementation. How-\never, it is important that the same standards of internationalization be applied to testing\nas to development. Testing of different localized versions of a product need not be\nredundant. If your game is single-code base and world-ready, a full test pass needs be\nperformed on only one language version. Testing on other language versions of the\ngame can focus on localization and functionality specific to those versions, although\nsanity testing should be performed across the product. The following are several areas of\ntesting that might require specific attention when dealing with an international game.",
      "content_length": 3014,
      "extraction_method": "OCR"
    },
    {
      "page_number": 108,
      "chapter": null,
      "content": "1.12 Developing Games fora World Market 105\n\nI Can’t Read It—How Do | Test It?\n\nOne of the first obstacles to testing a localized game is the language barrier. If you're\nlike most companies, you picked your test team because of their technical skills and\ntesting ability in a number of languages seemed a low priority. However, a good test\nteam can test for the majority of functionality bugs without having to learn another\nlanguage.\n\nTo begin with, your testers should know your game inside and out. If they have\nbeen testing the original-language version long enough, they should be able to walk\nthrough the UI with their eyes shut. As long as everything functions as planned,\ntesters should be in familiar territory. One exception might be warning and error mes-\nsages. If they are localized in the test builds, it might be necessary to provide testers\nwith a list of common error/warning messages and phrases (“not found,” “not enough\nspace available,” etc.) and their localized counterparts.\n\nIn addition, if you have someone on staff that speaks the language and can be on\ncall, they can help to quickly identify problems when they occur. With some experi-\nence, testers should become familiar with common messages and known problems in\nthe localized product, so only new or infrequent issues will require attention. How-\never, in-game verification and other testing might require someone fluent in your tar-\nget language. Many technical recruiting, staffing, and contracting companies have\nexperience finding and providing testers with native language experience. You could\nfind it worthwhile to contract one or more testers who are fluent in your target lan-\nguage once localized builds are available. In addition, there are several international\ncompanies to which you can outsource localized testing.\n\nDanger Characters\n\nOnce your team is ready to tackle the testing of a world-ready product, you need to\nidentify your highest-risk areas and integrate this knowledge into your test process.\nOne place to start is with so-called “danger characters.” These are characters that, due\nto their usage or their position in a codepage, tend to cause a disproportionate num-\nber of problems in applications. In particular, danger-character testing is important\nwhen dealing with originally SBCS code that has been modified to be MBCS/DBCS\ncompliant. When dealing with such code, it is not unusual to find search or parsing\nalgorithms that treat strings as being strictly single-byte.\n\nMost operating systems reserve certain characters in their file paths, such as the\nforward/back slashes and the pipe character. A common problem occurs when the\nfilename/path-parsing algorithm is single-byte, generating errors for filenames that\nare perfectly valid. For example, if a user enters a Chinese filename with a double-byte\ncharacter whose code happens to be 0x5C (the ASCII code for the backspace charac-\nter) in the second byte, a single-byte algorithm will likely detect this as a backslash\nand improperly parse the file path.",
      "content_length": 3027,
      "extraction_method": "OCR"
    },
    {
      "page_number": 109,
      "chapter": null,
      "content": "106\n\nSection 1 General Programming\n\nIn addition, off-by-one errors are not uncommon when dealing with MBCS\ncodepages. These occur when comparisons leave out or include one too many charac-\nters, such as a greater-than instead of a greater-than-or-equals. For example, in Shift-\nJIS, the character value 0xDF represents the highest of the single-byte kana codes,\nwhile 0xE0O marks the beginning of the second DBCS range for leading bytes. In such\na case, it may be useful to test your boundary values (0xDF and 0xE0 in this case) to\nensure that your code does not contain off-by-one bugs.\n\nIn order to produce a list of danger characters, you should evaluate your target\nlanguage/codepage and identify the following characters:\n\n* Any values that the filename/path parser might search for or consider invalid,\nsuch as the pipe, backslash, brackets, file delete marker, and so forth.\n\n* The beginning and ending values for each character range if you are using an\nMBCS character set.\n\n* The lowest and highest possible character values, and also one character beyond\nthose in each direction (these should be noted as invalid characters).\n\nYou should first test these values to ensure that valid and invalid values are treated\nproperly. In addition, for any SBCS values, you should find an MBCS character that\nincludes those values as trailing bytes to ensure that your filename/path parsing will\nnot fail on these values. To be most effective, you should create a universal test string\nthat includes one each of the invalid characters and enter it everywhere possible. If\nyou cannot read the target language, you can have a native speaker write down what\nthe string looks like and how to enter it. In addition, if your game is Unicode and\nallows multiple-language input, a good test string should include text (preferably dan-\nger characters) from multiple languages as well.\n\nBuffer Allocation\n\nAnother common programming bug that can occur when developing world-ready\ngames is in buffer allocation. This type of error is common when a distinction is not\nmade between characters and bytes. For example, if a string is allocated to be 16 bytes,\nit will only hold eight characters if they are double-byte. Testers should know the\nbuffer limits for different strings (they should be detailed in the game specification,\nincluding whether the limits are in characters or in bytes), and perform boundary\ntesting on them with both single- and double-, or multibyte characters if possible.\n\nHardware Configuration\n\nAnother issue that can arise in testing localized games is that of hardware configura-\ntion and input. To begin with, internationally, a wide variety of keyboards are used,\nand certain market areas (such as Korea and Japan) might have their own, language-\nspecific keys on their keyboards. In addition, there can be other variations in hard-\nware worldwide, such as localized drivers on the PC and different default hardware\nconfiguration/controllers on consoles. When testing for these markets, it is important",
      "content_length": 3017,
      "extraction_method": "OCR"
    },
    {
      "page_number": 110,
      "chapter": null,
      "content": "1.12 Developing Games for a World Market 107\n\nto consider the most-popular configurations (which may affect your supported hard-\nware configurations) and test with these devices to ensure compatibility with your\ntarget market.\n\nSystem Configuration\n\nWorld-ready system configurations comprise their own kettle of fish. With regards to\ntesting, the two things you should look out for are system incompatibilities and user\nsettings. While system incompatibilities are typically spotted early in the development\ncycle due to their severity, user settings are often overlooked. These include, but are\nnot limited to, time, date, and unit formats. PCs and some consoles allow a certain\ndegree of customization in this area, and you should test to ensure that your game\nrespects the users’ preferences.\n\nInput Testing\n\nOne more area that should be given special testing in a world-ready product is that of\nediting and input. Two functions in particular that should be tested (if available in\nyour game) are cursor movement and text editing. Cursor-movement testing typically\ncovers selection and movement of the cursor through text, while editing includes such\nfunctionality as delete, backspace, copy, cut, and paste. To test for problems in these\nareas, you can create a string composed of a mixture of different double-byte (and sin-\ngle-byte if available) characters, and make sure that cursor movement, selection, and\nediting are character-based. In no case should you ever be able to move the cursor to\nthe middle of a character or cut off the leading or trailing byte of a multibyte character.\n\nUl and Localization Testing\n\nWhen performing localization and UJ testing, a sanity check can be performed by a\nnon-native speaker who will look for truncation, resizing, and other obvious visual\nproblems. However, many other problems require the eye of a native speaker, notably\ncontext, string order, and translation testing. Context and string order testing refers to\nverifying the UI content (mostly text) and ensuring that strings are in the right places,\nand that all text is comprehensible and translated properly for the appropriate con-\ntext. String order problems can occur when a string has to be broken into two or more\nparts to accommodate a variable component. Since sentence structures and order are\ndifferent in various languages, care must be taken in both localization and testing to\nverify that all resources are properly presented and in context.\n\nTranslation testing focuses on the validity of the translation itself and can be\nsomewhat vague due to the difficulties of communicating the same message in multi-\nple languages. If your company performs in- house localization, you might be able to\ninvolve the localization team in the testing process, since they are familiar with both\nthe content and the target language. In addition, proper checks in the localization\nprocess can identify mistakes in the original text prior to translation, thus correcting\nproblems before they reach the test team.",
      "content_length": 3014,
      "extraction_method": "OCR"
    },
    {
      "page_number": 111,
      "chapter": null,
      "content": "108 Section 1 General Programmin\n\na world-ready game. In this gem, we have tried to list the major issues that concern\nthis process, along with ways of anticipating and resolving them as they relate to game\ndevelopment. Although it can be a complex process, integrating globalization and\nlocalization into your design process allows you to capitalize on a larger market and\nproduce a better design as well as a better gaming experience.\n\nndard, Version 3. 0, Addison Wesley\n\nPp iprand, Joan, The\nPublishing Co., 2000.\n\n{[Dmoz02] Open Directory Project, “Open Directory - Help Central,” available\nonline at http://www.dmoz.org/Computers/Software/Globalization/. The Open\nDirectory Project’s software alobalization page has links to almost any related\ntopic. March 2002.\n\n{DrIntl02] Dr. International, Developing International Software, Microsoft Press,\n2002.\n\n[Kano95] Kano, Nadine, Developing International Software, Microsoft Press, 1995.\nThe entire book is accessible online at http://www.microsoft.com/globaldev/\ndis_v1/disv1.asp.\n\n[Lunde98] Lunde, Ken, and Gigi Estabrook, C/KV Information Processing, OReilly,\n1998.\n\n[MicrosoftGlobalDev02] Microsoft Corporation, “Microsoft: Global Software Devel-\nopment!,” available online at http://www.microsoft.com/globaldev. Microsoft's\nglobal software development page includes step-by-step globalization guidelines,\nsolutions to common problems, and links to other resources. March 2002.\n\n[MicrosoftIME02] Microsoft Corporation, “Microsoft Global Input Method Editors\n(IMEs) Further Enhance East Asian Text Input,” available online at http://www.\nmicrosoft.com/Windows/ie/downloads/recommended/ime/, Microsoft IME\ndownload page for pre- Windows 2000 systems, March 2002.\n\n[Shmitt00] Shmitt, David, Jnternational Programming for Microsoft Windows,\nMicrosoft Press, 2000.\n\n[Unicode02] Unicode Consortium. The Unicode home page, available online at\nhttp://www.unicode.org, contains general information, standards documenta-\ntion, code charts, and conference proceedings. March 2002.",
      "content_length": 2025,
      "extraction_method": "OCR"
    },
    {
      "page_number": 112,
      "chapter": null,
      "content": "1.13\n\nReal-Time Input and Ul\nin 3D Games\n\nGreg Seegert, Stainless Steel Studios\ngseegert@alum.wpi.edu\n\neveloping a safe, fast, and responsive user interface and input system for your\n\ngame remains an often-overlooked programming task, but it is one of the most\nvital components in a successful title. In this gem, we will explore various implemen-\ntation details, tricks, and optimizations that will assist you in creating the best UI and\ninput system possible. We will also examine the important role that a user interface\nand input system fulfill in eliminating perceived network latency. This gem assumes a\nbasic familiarity with DirectX, and the code samples and accompanying code are\nimplemented with DirectX8, although the concepts could be applied to any 3D API.\n\nimplementing the User interfac\n\nWhen creating a 3D game, it is helpful to utilize the power of the available 3D hard-\nware to render 2D elements as well. To draw our UI elements, we will simply render\nflat polygons to the screen after setting up our world, view, and projection matrices.\nThe following code sample illustrates setting up Direct3D to render polygons two-\ndimensionally:\n\n// an LPDIRECT3DDEVICE8 variable named “d3dDevice\"\n// has been previously instantiated.\n\nD3DXMATAIX tempMatrix;\n\n// make an identity matrix\nD3DXMatrixIdentity (&tempMatrix) ;\n\n// set dx8's world and view matrices\nd3dDevice->SetTransform(D3DTS_WORLD, &tempMatrix) ;\nd3dDevice->SetTransform(D3DTS_VIEW, &tempMatrix) ;\n\n// set the projection matrix using\n\n// the width and height of the viewport\ntempMatrix. 11 2.0f / width;\ntempMatrix. 41 -1.0f;\n\ntempMatrix. 22 -2.0f / height;\n\n109",
      "content_length": 1637,
      "extraction_method": "OCR"
    },
    {
      "page_number": 113,
      "chapter": null,
      "content": "ion 1 General Programming\n\n110\n\ntempMatrix._42 = 1.0f;\n\nd3dDevice->SetTransform(D3DTS_ PROJECTION, &tempMatrix) ;\n\nAfter we have set up our world, view, and projection matrices, we must simply\nrender two triangles to the screen. The two triangles will form our polygon, which we\ncan color or texture to use as a background, button, or any other 2D component of a\nuser interface. First, after the corresponding UI object is instantiated, create a vertex\nbuffer consisting of the vertices used to specify the two triangles. Set the position of\neach vertex to be the location you want in screen pixel coordinates. Then, for each\nframe call, DrawPrimitive() to render the vertex buffer as a triangle list [(MSDN101].\nThe method of using screen coordinates simplifies the encapsulation of any 2D user\ninterface elements you choose to develop. It is also important to point out that\nDirectX8 offers a method for rendering a sprite in screen coordinates that may be use-\nful [MSDN201]}. An excellent resource to accomplish this goal using OpenGL is the\ngem “Using 3D Hardware for 2D Sprite Effects” [McCuskey00].\n\nUser interfaces have grown increasingly complex over the years. The end user\nexpects a high level of functionality, and it is the programmer’s job to supply these\nfeatures. Table 1.13.1 lists common controls that should be implemented in any\nrobust UI.\n\nTable 1.13.1 Suggested Ul Elements For Implementation\n\n¢ Backgrounds ¢ Edit Box * Sliders\n\n¢ Button ¢ List Box ¢ Static Text\n\n¢ Check Box ¢ Radio Button * Tool Tips\n\n* Combo Box ¢ Scroll Bar * Pages or Forms\n\nSpecifying User Interface Elements\n\nBROCE AEN 8 SEH Be BOR HE EBLE RRS ESE LIES ELISE ES se\n\nTe SOC DALI Sis OR ILE,\n\nOnce the code is written and the various UI elements are tested, it is time to put them\ninto the game. There are many ways to accomplish this goal. Each and every screen\nand element could be hard-coded into the game. However, this method requires pro-\ngrammer intervention to change even the simplest aspect of how the UI is displayed.\nIdeally, we would like to be able to specify the UI in an external file, allowing design-\ners to create and modify the interface as they see fit with virtually no programmer\nintervention.\n\nXML: It’s Not Just for Microsoft Anymore\n\nXML is an acronym for eXtensible Markup Language. Anyone vaguely familiar with\nthe syntax of HTML will most likely be comfortable with XML. In fact, HTML is",
      "content_length": 2411,
      "extraction_method": "OCR"
    },
    {
      "page_number": 114,
      "chapter": null,
      "content": "1.13 Real-Time Input and Ul in 3D Games\n\nea\n\nON THE CD\n\nexe\n\n111\n\nbeen asec eR err eet ACEP Sh NE ED SST CRA\n\nitself an ‘older cousin’ of XML. XML’ true power is its extensibility—it essentially\nallows the creation of a unique markup language. The backbone of XML is the DTD\n(Document Type Definition). The DTD specifies the constructs and syntax used in\nthe particular instance of XML. The DTD can then be used to ensure that a corre-\nsponding XML file adheres to the correct syntax. The XML standard is well defined,\nand there are numerous resources available to assist in writing and parsing XML\n[W3C102]. Because of the object-oriented and data-driven nature of XML, it is an\nideal candidate for specifying not only a user interface but also virtually all data-dri-\nven elements of the game engine.\n\nThe following code segment is a sample taken from an imaginary XML file used\nto specify a user interface screen. As you can see, the XML file logically outlines the\nuser interface elements in a manner that is easy to parse as well as to read and edit.\n\n<!-- This will create a UI screen with a background,\na title, list box, and an ok button. These are\nall user-defined tags -->\n<UISCREEN NAME=\"screen0\" BACKGROUND=\"screen0_bg.tga\">\n<UITEXT NAME=\"textO\" LEFT=\"10%\" RIGHT=\"90%\"\nTOP=\"10%\" BOTTOM=\"25%\">\n<UITEXTITEM>This is the title.</UITEXTITEM>\n</UITEXT>\n<UILISTBOX NAME=\"listO\" LEFT=\"30%\" RIGHT=\"70%\"\nTOP=\"40%\" BOTTOM=\"70%\">\n<UITEXTITEM>This is item 1.</UITEXTITEM>\n<UITEXTITEM>This is item 2.</UITEXTITEM>\n<UITEXTITEM>%1001%</UITEXTITEM>\n</UILISTBOX>\n<UIBUTTON NAME=\"button0O\" LEFT=\"40%\" RIGHT=\"60%\"\nTOP=\"80%\" BOTTOM=\"90%\">\n<UITEXTITEM>OK</UITEXTITEM>\n<UIEVENT ONCLICK=\"PushScreen\"\nPARAMETER1=\"screen1\"/>\n</UIBUTTON>\n</UISCREEN>\n\nThe DTD for the above segment contains the allowable tags, their parameters,\nand the tags that can be nested under them. One DTD can be used to verify any\nnumber of XML data files. The sample shown here and corresponding DTD can be\nfound on the CD-ROM.\n\nIn this example, the occurrences of <UITEXTITEM> specify text, with %value% indi-\ncating a string table entry. Positions for each UI entity are specified in percentages.\nUsing percentages helps to ensure the UI is displayed as expected in a variety of screen\nresolutions. The <UIEVENT> tags specify what events are valid for a specific UI entity\nand what actions to take when those events are fired. For example, when button “but-\nton0” is clicked, the UI code will execute the PushScreen action with screeni as a\nparameter. Implementing the actions to fire could be accomplished through the use of\nfunction pointers or through a C++ class that is derived from an abstract base class",
      "content_length": 2673,
      "extraction_method": "OCR"
    },
    {
      "page_number": 115,
      "chapter": null,
      "content": "Section 1 General Programming\n\nrequiring a string name. The action could then be mapped to the appropriately\nnamed object, and code would be executed with the specified parameters.\n\nTo parse an XML file, you can write or reuse a custom parsing routine. Alterna-\ntively, there are a number of free SDKs available that support XML parsing on a vari-\nety of platforms [W3C202]. For Windows developers, Microsoft offers the Microsoft\nXML Core Services (MSXML) 4.0 SDK, which includes full-featured XML parsing\naccessible through C and C++ interfaces [MSDN301].\n\nLocalization Considerations\n\nAs games continually increase in both size and scope, so do their target audiences. In\norder to maximize market penetration, it is imperative to design a game to be easily\nlocalizable to any other language. The user interface is on the forefront of this effort,\nas translated text will eventually be displayed on the screen. The following guidelines\nshould always be considered throughout the development of the user interface and\nthe game engine itself.\n\n¢ Never hard-code any text that might eventually be translated; use a string table\ninstead.\n\n* Use MBCS or Unicode strings.\n\n* Be wary of string concatenation.\n\n* Process WM_CHAR messages for all text displayed to the user.\n\n* Design UI controls to accommodate potentially large strings.\n\n* Use fonts that support multibyte languages.\n\nThe most obvious tenet is to never hard-code any text. Instead, use a string table\nfor all text (excluding debug text, of course). It is also important to use MBCS (multi-\nbyte character strings) or Unicode (wide character) strings throughout the game. If\nyou do not, certain languages will appear to have garbled text. The Standard Template\nLibrary (STL) offers a wide character version of the string class, appropriately named\nwstring. Use caution when concatenating strings. Sentences are formed differently in\nother languages, so it is important to store sentence format in the string table as well.\nAlso, never use DirectInput to process keyboard inputs that will be directly displayed\nto the user as text. Instead, use WM_CHAR messages. When processing WM_CHAR messages,\nWindows will perform the translation based on local information. An equally impor-\ntant task is to design UI controls to accommodate large strings or to expand to fit the\ndisplayed string. A short English phrase could easily become twice as long when trans-\nlated to another language. Lastly, the font used must be carefully chosen and able to\ndisplay multibyte languages. Some system fonts support multibyte languages, making\nthem good selections. If you absolutely must use a custom font, however, a clever\nsolution is to specify the font to use in the string table itself. Then, the localization\nteam could choose the appropriate font for the language they are translating to if\nnecessary.",
      "content_length": 2848,
      "extraction_method": "OCR"
    },
    {
      "page_number": 116,
      "chapter": null,
      "content": "1.13 Real-Time Input and Ul in 3D Games 113\n\nThe Input System\n\nThe user’s game experience incorporates more than simply the textures used for back-\ngrounds and buttons. Your primary goals should include ensuring that all user input\nis responsive and performs as the user expects it to. We will now cxplore several useful\ntricks to achieve this for the keyboard, mouse, and joystick.\n\nThe Keyboard\n\nDirectInput allows two methods of retrieving data from various input systems:\nimmediate and buffered. Immediate data returns a snapshot of the current state of the\ndevice, while buffered data consists of a sequence of events that have occurred since\nthe last buffered data call. When used for the keyboard, immediate mode returns an\narray of 256 bytes representing the state of the keyboard keys. If the high bit is set for\na particular key index, the key is down. Immediate mode appeals to many Windows\nprogrammers due to its simplicity, its similarity to the Win32 GetKeyboardState()\ncall, and the desire to know exactly what the state of the keyboard is at any given\nmoment. Although this approach is effective, it seems to perform best when the game\nis only processing a small amount of keyboard commands, such as left, right, up,\ndown, and shoot. What about a flight simulator, RTS game, or another game with\npotentially hundreds of hotkey combinations? It could be rather inefficient to loop\nthrough every hotkey that might or might not have been pressed, checking against the\narray returned by GetDeviceState() at every update. Handling events when a key is\nreleased will also require maintaining a copy of the keyboard state as of the previous\nupdate. Additionally, this approach does not handle the case where a user manages to\npress and release one or more keys between updates to the input system.\n\nHow To Never Miss an Input\n\nFortunately, DirectInput’s buffered data mode offers a viable alternative. Rather than\ncalling GetDeviceState(), we will call GetDeviceData(). This will return a list of key-\nboard events that have occurred since the last call to GetDeviceData(). Each keyboard\nevent specifies whether the key was pressed or released, which key it was, and provides\na high-resolution time of when the event occurred. No matter how frequently or\ninfrequently the input system is refreshed, we will know exactly what events occurred\nand in what order.\n\nThe next step is to package up the input event, and put it on a queue of inputs to\nbe processed by the game engine. We will maintain three queues: “just pressed,”\n“pressed,” and “just released.” Storing our inputs in these three queues allows us to\nfire actions depending on the state of the key. For example, holding down the for-\nward-arrow key could accelerate a car in a racing game, while tapping the “A” key\ncould shift gears. The other items to consider are the ‘modifier’ keys. These keys,\nwhich include CTRL, SHIFT, and ALT, are no different than any other key as far as\n\nDirect Input is concerned. This is the desired behavior, as we might wish to fire events",
      "content_length": 3039,
      "extraction_method": "OCR"
    },
    {
      "page_number": 117,
      "chapter": null,
      "content": "114\n\nON THE CD\n\nThe Mouse and Joystick\n\nSection 1 General Programming\n\nwhen those particular keys are pressed. However, we will also use these keys as modi-\nfiers. For example, CTRL-A will be considered a unique key separate from CTRL and\nA. For this reason, the input system will maintain a current modifier state consisting\nof bit flags that will be updated as the appropriate modifiers are pressed and released.\nTherefore, each packaged input event will consist of the key for that event as well as\nthe current modifier state. Packing the combination of key and modifier state into a\nsingle 16-bit value will allow us to identify a unique key combination for sorting and\ncomparison purposes.\n\nOn each occasion that the input system is refreshed, we will add any input events\nto the appropriate queue. When we are ready to process these inputs, the game engine\nwill iterate through the queues. Each hotkey that we will be checking for can be stored\nas a map of input events to hotkey pointers. This way, look-up is considerably fast for\nlocating the corresponding hotkey (if it exists) and executing the game engine code.\n\nWe now know exactly what keys the user pressed, no matter how often the input\nsystem is refreshed. Furthermore, this method for processing input can serve as an\nimportant optimization, since we are quickly processing a much smaller list of what\nthe user actually did, rather than checking against every possible key combination.\nRefer to the CD-ROM for further implementation details.\n\n=r URED SR A LEALETB LLNS ARLEN ESL P NS SEE ERIE B EEE LSAT NA SELL IM SEEPS IR NTT\n\nThe mouse and joystick can benefit from buffered input in precisely the same manner\nas the keyboard. Instead of key presses, we will package and process mouse and button\nclicks. However, buffered input should not necessarily be used to interpret the axis\nmovement of either the mouse or joystick. During pauses in the execution of the\ngame engine, the mouse cursor or joystick controls might appear to jump around the\nscreen as the buffered axis inputs are processed. The simple solution is to use buffered\nand immediate input. The buffered input is used to process buttons and clicks, while\nthe immediate data modifies the axes.\n\nA Smooth and Responsive Cursor\n\nOne fairly common implementation of the mouse in games is to run the mouse in its\nown thread. This remains a good approach, as the mouse can be updated and ren-\ndered independently of other processing being performed by the game engine. How-\never, the mouse thread might be capped to yield away time, allowing more processor\ncycles for physics, AI, and graphics. Although this makes perfect sense, capping pro-\ncessing of the mouse thread can exhibit undesirable behavior on certain machine con-\nfigurations. If the game is running at over 60 fps (frames per second), a mouse pointer\nupdating only 10 times per second will appear jerky and unresponsive. In this case,\nthe solution is to separate the updating of the mouse axes from the processing of the\nbuttons. Then, the position of the mouse can be updated and the mouse pointer ren-\ndered every single frame, achieving the smoothest possible movement.",
      "content_length": 3165,
      "extraction_method": "OCR"
    },
    {
      "page_number": 118,
      "chapter": null,
      "content": "1.13 Real-Time Input and UI in 3D Games 115\n\nThe Role of the UI in the Fight Against Lag\n\n‘senoEReRRRIY\n\nSERN\n\nAs the popularity of network games increases, so does users’ expectations of as fast and\nenjoyable online experiences as possible. At times, the user’s expectations can be rather\nunrealistic. A user running a complex network game on a 28.8k-baud modem will\nexpect gameplay as smooth as those users connected directly on a LAN. There is only\na certain degree of optimization and tuning that can be applied to the network\ncode—given the unpredictability of network connections; if the user is not transmit-\nting data fast enough, there is not much more that can be done to accomplish this\nfeat.\n\nThe best way to attack this problem is to simply hide the network latency from\nthe user. Some of the most successful online games, like Quake and Half-Life, use a\nmethod known as client-side prediction. Essentially, the simulation is run on the\nclient’s machine as fast as possible, with the client predicting the position and actions\nof other entities in the game. When network updates are received from the server, the\nclient is corrected if it is not synchronized with the server.\n\nA similar methodology can be applied to all aspects of the user interface and\ninput. Any and all feedback of the game, including updating UI buttons or selecting\nunits, should be performed instantly on the client. For example, if the user presses the\ntrigger button, the gun should fire immediately as the network message is sent to the\nserver. If the user sends a chat message, it should be displayed on the screen instanta-\nneously. If the user clicks a button to build another unit, the onscreen counter should\nincrement without delay. What happens, however, if the command is not allowed,\nrejected by the server, or the network packet is lost?\n\nThere are a number of potential solutions to this problem. It is possible to occa-\nsionally compare the UI with the state of the game world, making corrections when\nnecessary. To help prevent these errors in the first place, the same server-side valida-\ntion of commands and actions can be performed on the client, although this could\nduplicate code and increase processing demands. Lastly, a method of guaranteed mes-\nsage delivery could be implemented for the game. This will allow the client to update\nthe user interface, knowing that eventually the server will receive the command.\nHowever, the drawback to this approach should be fairly obvious. In a high network\nloss situation, the client could potentially be forced to resend a message many times.\nCombined with lag, this method could aggravate, rather than relieve the problem.\n\nConclusion\n\nHopefully, you have found the ideas and tips presented in this gem useful. Though we\nhave only scratched the surface, keeping these points in mind will help you build a\nfast, safe, and robust user interface and input system for your game. The CD-ROM\ncontains a complete keyboard input system that is easily adaptable for any game. The\ninput system implements the fast, buffered-input method mentioned previously.\nAdditionally, the input system is localization friendly and can read hotkey assign-",
      "content_length": 3185,
      "extraction_method": "OCR"
    },
    {
      "page_number": 119,
      "chapter": null,
      "content": "116 Section 1 General Programming\n\nments from an external file, allowing completely customizable hotkeys. Also available\n\non the CD-ROM is a simple C++ XML parser, as well as the XML samples used here.\n\nReferences\n\n[McCuskey00] McCuskey, Mason, “Using 3D Hardware for 2D Sprite Effects,”\nGame Programming Gems, Charles River Media, Inc., 2000.\n\n[MSDN101] msdn.microsoft.com, “IDirect3DDevice8::DrawPrimitive,” available\nonline at hetp://www.msdn.microsoft.com/library/en-us/dx8_c/directx_cpp/\nGraphics/Reference/CPP/D3D/Interfaces/IDirect3 DDevice8/DrawPrimitive.as\n\n, 2002.\n\n[MSDN201] msdn.microsoft.com, “ID3DXSprite::Draw,” available online at http://\nwww.msdn.microsoft.com/library/en-us/dx8_c/directx_cpp/Graphics/Refer-\nence/CPP/D3DX/Interfaces/ID3DXSprite/Draw.asp, 2002.\n\n[MSDN301] msdn.microsoft.com, “MSXML 4.0 RTM,” available online at\nhttp://www.msdn.microsoft.com/downloads/sample.asp?url=/MSDN-\nFILES/027/001/766/m sdncompositedoc.xml, 2001.\n\n[W3C102] World Wide Web Consortium, “Extensible Markup Language,” available\nonline at http://www.w3c.org/XML/, 2002.\n\n[W3C202] World Wide Web Consortium, “Extensible Markup Language (Soft-\nware),” available online at http://www.w3c.org/XML, 2002.",
      "content_length": 1203,
      "extraction_method": "OCR"
    },
    {
      "page_number": 120,
      "chapter": null,
      "content": "1.14\n\nNatural Selection: The\nEvolution of Pie Menus\n\nDon Hopkins\ndon@DonHopkins.com\n\nPp menus are a naturally efficient user-interface technique—directional selection\nof pie slice-shaped targets. The cursor starts out in the inactive center region of a\npie, and all target slices are large, nearby, and in different directions. Pie menus are\nquite easy for new users. You simply follow the pop-up directions to use them. They\nare also extremely efficient for experienced users. Once you know the directions, you\ncan quickly and reliably ‘mouse ahead’ without looking. Fitts’ Law [Fitts54] explains\nthe pie menu advantage—their fast selection speed and low error rate is due to their\nlarge target size and the small distance between each item.\n\nThe evolution of user interface design is driven not only by theory, but also by\npractice. We'll examine the successes and failures of a few real-world examples, not\nonly to avoid re-inventing the square wheel, but also to encourage further creativity.\nThe examples presented here are intended to inspire you to think outside the box and\ndesign new kinds of fun, efficient, and reliable user interfaces.\n\nThe Feng GUI of Pie Menus\n\nUser interface design is not just a process of raw artistic creation nor a legalistic appli-\ncation of interface guidelines and theories. It’s the exploration and discovery of natu-\nrally efficient ways of solving problems, given competing sets of constraints. The\noutcome is always different, because the trade-offs and constraints always vary, but\nmany of the underlying principles are universal.\n\n‘Feng GUD seeks to understand the dynamic flow of mental and physical energy.\nIt orchestrates the flow of attention and gesture throughout the interface as a whole.\nFitts’ Law is useful for scientifically analyzing performance speed and error rate, but it\ndoesn’t capture the human side of the equation. Feng GUI tries to prevent unfortu-\nnate accidents (like the 2000 Florida presidential election ‘Butterfly Ballot’) before\nthey happen.\n\nWhen designing a pie menu, think of Martha Stewart arranging a bunch of flow-\ners into a beautiful bouquet. You must work with what you're given, try to play off the",
      "content_length": 2181,
      "extraction_method": "OCR"
    },
    {
      "page_number": 121,
      "chapter": null,
      "content": "118\n\nSection 1 General Programming\n\nvisual and semantic symmetries and relationships, and arrive at a pleasing pattern\nthat’s both enjoyable and easy to remember.\n\nTo construct a memorable pie menu tree of submenus, you should emulate\nAlexander Calder’s creating a hanging mobile sculpture. The task not only requires a\nsound understanding of scientific engineering principles, but also aesthetic judgment\ncalls and acrobatic balancing acts.\n\nDoug Engelbart, who invented the mouse and pioneered interactive user inter-\nfaces, strongly believes that the human-tool co-evolution should be based on rigorous\nexploratory use in a wide variety of real-world applications. So don’t just talk about\npie menus—use them, evaluate their performance, and improve upon them!\n\nResearching and Evaluating Pie Menus\n\nThe essential idea of directional menu selection has been around for a long time in\nvarious forms and with different names. Many examples of implementations exist,\nand a detailed history can be found at [PieMenu02].\n\nMany studies have also been done on their effectiveness compared to other UI\napproaches. Gordon Kurtenbach and Bill Buxton (University of Toronto) have\ndemonstrated many interesting results with their empirical research and controlled\nexperiments with marking menus and various input devices. At Alias| Wavefront, they\nhave successfully applied them to Maya, a high-end 3D animation environment, so\nusers can design their own marking menus to customize their environment. In their\nresearch, they studied the learning curve from novice to expert user. They found that\nthere are three stages of behavior along the learning curve:\n\n1. Novice users click up the menu, wait for it to display, look for the desired\nlabel, move the mouse, and click to select the highlighted item.\n\n2. Intermediate users remember the direction, click up the menu, move in a\ndesired direction, wait for the menu to pop up and highlight the desired\nitem, and release the button to confirm the selection.\n\n3. Expert users simply press down the button, move in a desired direction, and\nrelease the button without hesitating.\n\nBecause the physical motions of novice, intermediate, and expert users are the\nsame, pie menus transparently train you to become an expert. Each time you make a\nselection, you're rehearsing the expert mouse-ahead gesture. The intermediate stage is\nlike an escalator along the learning curve. It helps novice users become experts by\nexercising their skills and increasing their confidence to mouse-ahead. Your muscles\nquickly and unconsciously learn to mouse-ahead without looking.\n\nJaron Lanier (VPL Research) put it well: “The mind may forget, but the body\nremembers.” Pie menus exploit your body’s ability to remember muscle motion\nand direction, even when your mind has forgotten the names of the corresponding\nitems.",
      "content_length": 2838,
      "extraction_method": "OCR"
    },
    {
      "page_number": 122,
      "chapter": null,
      "content": "1.14 Natural Selection: The Evolution of Pie Menus 119\n\nThe nature of the input device used has a significant effect on the selection speed\nand error rate. Mice have been found to be faster and more accurate than trackballs,\nand pens are faster and more accurate than mice.\n\nThe maximum usable breadth (number of items) and depth (submenu nesting\nlevel) is limited by the maximum error rate the application can tolerate. Nuclear\npower-plant interfaces should stick to single level-two and four-item pie menus,\nwhich are extremely reliable. A game like SimCity or an editor like Maya can get away\nwith using deeper menus with more items because it’s easier to recover from selecting\nthe wrong item.\n\nExperienced users perceive single-level pie menus with two, four, and six items to\nbe error-free, and eight items to be very reliable. Kurtenbach and Buxton measured\nthe error rate at less than 10% with four items four levels deep as well as with eight\nitems two levels deep.\n\nIncreasing the number of items in a pie menu has an obvious detrimental effect\non the selection speed and error rate, but the relationship is not simply linear. Even\nnumbers of items are easier to use and remember because more of the items are on-\naxis and symmetrical. On-axis items are easier to select than off-axis items, so it’s good\nto put commonly used items to the North, South, East, and West, and less-common\nitems along the diagonals.\n\nThis even/odd effect is most pronounced when comparing 7 versus 8 items, and\n11 versus 12 items. Eight and 12 items are especially easy to use, because the directions\nare mentally more familiar and physically more on-axis. As the number of items\nincreases, the negative effect of adding another item decreases. So, it’s often helpful to\nadd an extra item to 11-, 7-, and even 3-item menus, just to make them nice and even.\n\nWhen designing nested pie menus, the depth versus breadth trade-off seems to be\nabout even. So, it’s best to let the semantics of the items determine how they should\nbe arranged: shallow menus with many items, or deep menus with few items.\n\nIt’s worth noting that some menus still work better as linear menus. Most linear\nmenus and submenus aren't arranged to take advantage of the pie menu directions,\nand pie menus with too many items are huge and unwieldy. To solve those problems,\nmodifiable pie menus have been developed that the user could customize, and\nscrolling and paging pie menus can handle any numbers of items.\n\nComponent technologies, like ActiveX and Dynamic HTML behaviors, make it pos-\nsible to implement general-purpose, easily reusable plug-in user-interface compo-\nnents. Pie menus can provide configuration languages, property sheets, and\nspecial-purpose editors, which enable designers and users to create and customize\ntheir own menus without programming.\n\nActiveX (also known as COM and OLE) is a component technology developed\n\nby Microsoft. We developed an open-source ActiveX pie menu component that can",
      "content_length": 2978,
      "extraction_method": "OCR"
    },
    {
      "page_number": 123,
      "chapter": null,
      "content": "120 Section 1 General Programming\n\nbe plugged into any OLE control container, including those used by Internet\nExplorer, Visual BASIC, Visual C++, and many other tools and applications. They're\neasily created and customized through scripting languages like Visual BASIC or\nJavaScript, and they have property sheets to configure their many options, for editing,\nand to preview the pie menus (see Figure 1.14.1).\n\nFIGURE 1.14.1 (A-D) Editing control properties using an example program.\n\nActiveX pie menus support many properties and methods to control their appear-\nance and behavior. You can customize pie menus by writing scripts that manipulate\ntheir properties, call methods, and handle callback events signaled during tracking.\nHowever, their graphical abilities are quite limited when compared to Dynamic\nHTML (see Figure 1.14.2).\n\nThe open-source JavaScript pie menus for Internet Explorer solve this problem\nnicely [JavaScript02]. They're tightly integrated with the Web browser and can take\nadvantage of all of its features. They're easily and completely configured in XML as\nwell as being extremely flexible, because you define their appearance with Dynamic",
      "content_length": 1166,
      "extraction_method": "OCR"
    },
    {
      "page_number": 124,
      "chapter": null,
      "content": "1.14 Natural Selection: The Evolution of Pie Menus 121\n\nrman ah pH pg Nk ee a oR mon tire ne ea D A MCR at HE ALANINE ASAE EI\n\nFIGURE 1.14.2 (A-I) Pie menus implemented using Dynamic HTML.",
      "content_length": 188,
      "extraction_method": "OCR"
    },
    {
      "page_number": 125,
      "chapter": null,
      "content": "122 Section 1 General Programming\n\nscenes Sana Sta A I mn rm AN ERM MAP AANA RHEE natant nt A RNR aC\n\nHTML. These menus a easy for Web page designers to use for static pages and for\nWeb server programmers to use for dynamic online services because they're imple-\nmented as modular ‘Dynamic HTML Behavior Components.’\n\nJavaScript pie menus are specified in XML, so it’s possible for people to manually\nwrite them with a text editor. It is also possible for programs to dynamically generate\nthem from a database. The JavaScript pie-menu component code is cleanly distinct\nfrom the Web page and XML pie-menu specification. You can customize their be-\nhavior by writing event handlers on the Web page in JavaScript, VBScript, or other\nlanguages. They can provide rich, dynamic graphical feedback, because scripts can\nreach into the pie menus and Web pages, and actually modify the Dynamic HTML\non the fly.\n\nUsing XML to specify pie menus has many advantages. The format is indepen-\ndent of the implementation, so the same pie menus can be used across many different\nplatforms. Web servers and browsers can automatically transform application-specific\nXML formats into pie menus by using standard XML-processing tools, like XSTL\nand distributed XML databases. For example, an XSLT style sheet can dynamically\ngenerate a Web page with ‘Punkemon’ pie menus, based on an XML database of trad-\ning-card attributes and links to animations [Punkemon02] (see Figure 1.14.3).\n\nPunkemon Pie Menus! Punkemon Pie Menus!\n\nFIGURE 1.14.3 (A-C) The ‘Punkemon’ example.\n\nThe XML pie menu schema enables editors to automatically validate, construct,\nand edit pie menus. The pie menu schema is on the CD-ROM as well as\n[PieSchema02]. An example editor can be seen in Figure 1.14.4, which is available\nonline [PieEditor02].\n\nFasteroids {Fasteroids01] is both a real-time video game and an empirical user\ninterface experiment; it enables you to compare linear menus and pie menus. The\nJavaScript pie menus also support the old-fashioned linear menu style, and they can\nbe instrumented to record the selection time for experimental purposes. Fasteroids\nalternates between pie menus and linear menus (as shown in Figure 1.14.5), and\nprompts you to select a certain item to blow up the asteroids. It records and displays\n\nON THE CD",
      "content_length": 2303,
      "extraction_method": "OCR"
    },
    {
      "page_number": 126,
      "chapter": null,
      "content": "1.14 Natural Selection: The Evolution of Pie Menus 123\n\n“Bait Pieblena Preperyy View\n‘Dexeripnam, Pie Mets Va,\n\n<icem name=\"Five\"/>\ncam neem 31>\n<item nemen\"Seyen\"/>\nitem Ammen Lge).\n\n</piemen>\nL </1tem>\n\nite,\nFo nemes*Sourbeaat >\n\n<piemenu\nweoue=\"'switenns\n<item nease=\"On\"/ >\nteem name\" On2\"/> Dee :\n\n</piemenur + Rit Pre bYemm Broperty.-Cemner Background Color\n\nDescraption: Pie Menu Center Backaround Color\n\n</ tiem,\n\ni <item\newes \"Snuch >\n\n<pienene\nfixedredius=\"40%>\n\n‘btanl>\nING ‘sro=\"bieb.jpg\"/>\n</btinl>\n\ns<?eml_version=\"1.0\"2>\n\n<achema\nsmlng*\"het p://va¥. ¥3 .otg/ 1999/TELScheme”\ntargetNemespace=\"httpi//sws. pienent.cci/ piemmeuimiachers~1.0.4947\nsoelns: pie \"http i//wrw.piemecu.con/ piemenwarlschem-1.0.%sa\"\nelement FormDefaaic=\"qualitied”\n\nE versions \"uly 8 2001\">\n\n| <npnptet san> |\nthw : “Baa item Property: [HTML -\n<documentat dom> HIML Bement Content in Pie E h\nA Schesa for Pie Benus.~ by Dori Bopkins cca in Pie Menu Bera E cnpty, the bw Name is chown xwte wd.\n¢</Socummacetion> Element\n\n:fe@y Tie Biebs <8) <ea/ ><img sca~\"bleb-dpg\"7>\n\n<documenceat ion sources \"nt tp: //wws. pismeny.com”>\n\nA B\nFIGURE 1.14.4 (A-B) ie menu schema and editor.\n\nFasteroids Fasteroids\nCopyright (C) 2001 By Yr: Copyright (C) 2001 B:\nRound ? Round 8\nPre Menna Linear Mems\nConstant Itemax Comstant Ite\n\ne Stensoce\n\n‘Mem! Menu ‘Selection ‘Correct Total Average Erret Error\n‘Type Items.' Count Conmt Time Tume Count Rate\nPie Random 3036500 12166672 6%\n: “95620 15675416 9%\n48340 525.435 4\n\nA B\nFIGURE 1.14.5 (A-B) The Fasteroids game and experiment.",
      "content_length": 1546,
      "extraction_method": "OCR"
    },
    {
      "page_number": 127,
      "chapter": null,
      "content": "124 Section 1 _General Programming\n\naunt RRA RRR eh A ROA OO EOE MNO reese\n\nthe average selection time and error rate, so you can compare pie menus and linear\nmenus for yourself.\n\nFuture Directions\n\npommanierteracenmnnnuneenst\n\nPie menus work well with touchscreens on » handheld devices like the Palm Pilot and\nthe Pocket PC. ‘Finger Pies’ are easy enough to use with your finger, so no pen is\nrequired. A product we have developed called ConnectedTV makes your handheld\ninto a customizable entertainment guide and remote control that’s designed to be\nheld in one hand and operated with the thumb and finger. ConnectedTV lets you use\nfinger pies to make your own personalized television schedule, filter, and program-\nsearch guide; you can flip back and forth through show descriptions and movie\nreviews, and send infrared remote-control commands to change the TV channel and\noperate other equipment.\n\nFast, inexpensive motion detectors that are sensitive enough to detect the direc-\ntion of gravity will soon be built into consumer electronic equipment like cell phones,\nhandheld computers, remote controls, and games. Motion detectors will enable con-\nvenient one-handed scrolling, dialing, panning maps, tilting pie menus, continuous\ngesture recognition, and many other exciting interaction techniques.\n\nGoing to Town with SimCity .\n\nIn 1991, we first ported Sim Ci to , Unix. Ie featured p pie mer menus (see Figure 1.14.6) for\nquickly selecting SimCity editing tools, which was a useful shortcut for the original\nSimCity command palette.\n\nStatic pie menus whose items don’t change can be carefully designed for ease of\nuse and nicely illustrated for aesthetic appeal. We translated the SimCity tool palette\ninto a convenient set of static pie menus. Icons in the pie menus are arranged in the\nsame pattern as the palette, so they’re easy to learn and quick to use.\n\nPop-up pie menus let you quickly switch tools without moving back and forth\nbetween the map and the tool palette. You soon learn to mouse-ahead through the pie\nmenus and submenus just by flicking in the appropriate directions. Thanks to\nMoore’s Law, you can now run Sim City so fast, it’s a strategy twitch game, running at\ndecades per second. Thanks to Fitts’ Law, pie menus help you keep up with acceler-\nated SimCity time by mousing-ahead without looking, and without wasting centuries\ndragging though linear menus.\n\nThe icons of the SimCity tool palette and pie menus are different sizes and shapes\nthan the original, square SimCity tool icons. Their sizes and shapes are related to the\nprices and functions of the tools. Small icons stand for inexpensive tools, like parks or\nbulldozers. Large icons stand for expensive tools, like power plants or airports. Long\nicons suggest linear tools, like roads or railroads. And square icons are for square\nbuildings, like residential zones or fire stations. The purpose behind this oddball icon\ndesign is to make remembering and differentiating between them easier (see Figure\n\n1.14.6).",
      "content_length": 3005,
      "extraction_method": "OCR"
    },
    {
      "page_number": 128,
      "chapter": null,
      "content": "125\n\n1.14 Natural Selection: The Evolution of Pie Menus\n\n‘nua ad sMarjuty  (9-w) 9*v bk FHNDId",
      "content_length": 94,
      "extraction_method": "OCR"
    },
    {
      "page_number": 129,
      "chapter": null,
      "content": "126 Section 1 General Programming\n\n‘CE EC MEIER NE NOE hESC ERC SET OH EEE TOTO EOE I CO Be OOOO AOE 1 nosateievnetercnmmleit MeltenininisieBONlteaRNSAOAEENINEEY\n\nLiving at Home with The Sims\n\nRSS ISSR ES TERESA.\n\nThe pie menus in The Sims use a combination of desaturation, darkening, and alpha\nblending to feather the edges of the menu (see Figure 1.14.7 and Color Plate 1). This\nwas done because we didn’t want the pie menus to obscure too much of the scene\nbehind them. You can see through the pie menu as the animation continues on in\nreal-time behind it. The head of the currently selected person is drawn in the center of\nthe pie menu and follows the cursor by looking at the currently selected item.\n\nIt was necessary to somehow separate the head from the rest of the scene. Other-\nwise, it looked like a giant head was floating in a room of the house, which was some-\nwhat disconcerting and violated the ‘Principle of Least Astonishment.’ Simply\ndrawing a solid menu background would obscure too much of the scene behind the\nmenu. Using a partially transparent menu background still did not visually separate\nthe head from the background scene enough. It looked muddy and cluttered, instead\nof crisp and bright.\n\nInstead of simply alpha-blending the menu background, we actually lowered the\ncontrast, which darkens the image and desaturates the background. The effect was to\ncast a colorless shadow with soft, feathered edges over the animated background,\nagainst which you can easily see the head and menu item labels.\n\n(Give Gift Entertain\n‘tg Give Back Rub\n\nFIGURE 1.14.7 Pie menus in The Sims.",
      "content_length": 1606,
      "extraction_method": "OCR"
    },
    {
      "page_number": 130,
      "chapter": null,
      "content": "1.14 Natural Selection: The Evolution of Pie Menus\n\n127\n\nInstead of drawing a circular edge around the pie menu, the gray shadow gradu-\nally tapers off, suggesting that the active pie menu target area is not confined to a\nsmall circle. The labels are drawn around the pie menu center with high-contrast drop\nshadows, so they're easy to read.\n\nThe animated head in the center needed to look sharp and bright against the pie\nmenu background. So, the shadow effect looks at the Z buffer to clip around the head\nin the menu center, keeping it crisp and bright. That gives it visual ‘pop,’ which\nclearly separates the user interface from the world, without drawing dividing lines or\nunnecessary visual clutter.\n\nConclusion\n\nRA EE AR EE Nk ORR NR IT SSAA NERS AAS EES\n\nPie menus benefit from the natural consequences of Fitts’ Law. They're neither the\nonly nor the best user interface technique to take advantage of this effect. However,\nthey're a great improvement over today’s standard linear menus and a stepping stone\nto developing even better user-interface techniques.\n\nThe proven advantages that pie menus have over linear menus are their higher\nspeed and lower error rate. They also have the potential to be carefully designed and\nconveniently automated in many different ways, which increases their usefulness for\nmany applications.\n\nComputer games and handheld consumer electronic devices are reshaping the\nway user interfaces are designed because of their new and unusual demands. Real-\ntime games require quick, responsive, engaging user interfaces. Handheld computers\nand phones must be useful for a wide range of people in real-world conditions, so they\ndemand high reliability and ease-of-use.\n\nDesigning a good user interface requires balancing many competing demands\nand guidelines. It’s extremely important not to squander the user’s time or atten-\ntion—consider it your most rare and precious resource. Don’t get tripped up on\nmetaphors—take a step back and look at what’s really going on. Think in terms of the\nuser’s goals, mental models, and physical actions.\n\nBe prepared to throw away your first design. Use your own system on an everyday\nbasis. Continuously iterate the design, based on feedback from empirical testing and\nthe users themselves. Every application and user has different requirements that\ndemand different trade-offs at different times.\n\nDesigning good pie menus takes thought and effort, like writing Haiku. Limit\nthe number of items in each menu, and group them together into memorable, bal-\nanced submenus. Arrange the items in natural directions to exploit their semantic\nrelationships and physical associations. Don’t exclusively use pie menus when other\ntechniques are more appropriate, like sliders, scrolling lists, keyboards, or handwriting\nrecognition. It’s a good idea to provide multiple ways of accomplishing the same task\nwhen it makes the application easier to use.\n\nFeng GUI seeks to integrate the lessons of real life, empirical research, and theo-\nretical principles, and apply them to the enlightened design of efficient, reliable user",
      "content_length": 3088,
      "extraction_method": "OCR"
    },
    {
      "page_number": 131,
      "chapter": null,
      "content": "128 . Section 1 General Programming\ninterfaces. The “Butterfly Ballot” debacle demonstrated how badly designed user\ninterfaces can have enormously consequential effects on the real world. By striving to\ndesign user interfaces with good Feng GUI, you can improve people’s lives and affect\nthe world in many positive ways.\n\nReferences\n\n[Fasteroids01] Hopkins, Don, Fasteroids, available online at http://www.PieMenu\n.com/fasteroids.html, March 2002.\n\n[Fineman01] Fineman, Howard, “Unsettled Scores,” Newsweek, September 17, 2001.\n\n[Firts54] Fitts, PR M., “The Information Capacity of the Human Motor System in\nControlling the Amplitude of Movement,” Journal of Experimental Psychology,\n1954: Vol. 47, pp. 381-391.\n\n[JavaScript02] Hopkins, Don, “Open Source JavaScript Pie Menus,” available online\nat http://www.PieMenu.com/JavaScriptPieMenus.html, March 2002.\n\n[PieEditor02] Hopkins, Don, “Pie Menu Schema Editor,” available online at\nhttp://www. PieMenu.com/ piemenuschemaeditor.html, March 2002.\n\n[PieMenu02] Hopkins, Don, “Pie Menu Central,” available online at http://www\n.piemenus.com/, March 2002.\n\n[PieSchema02] Hopkins, Don, “Pie Menu XML Schema,” available online at\nhttp://www.PieMenu.com/piemenuxmlschema-1.0.xsd, March 2002.\n\n[Punkemon02) Hopkins, Don, “Punkemon Pie Menus,” available online at http://\nwww. PieMenu.com/punkemon.xml, March 2002.",
      "content_length": 1355,
      "extraction_method": "OCR"
    },
    {
      "page_number": 132,
      "chapter": null,
      "content": "1.15\n\nLightweight, Policy-Based\nLogging\n\nBrian Hawkins, Seven Studios\nwinterdark@sprynet.com\n\nMo debuggers are powerful and very useful, but there are still places they can-\nnot reach. This is where a simple, lightweight logging system is of great value.\nLogging can be used when a debugger is not available, which is often the case for\ngame designers and testers. Logging also allows the examination of the current game\nstate and similar information, while the game continues running under normal\noperation.\n\nTo accomplish this end, an efficient logging system that is configurable at both\ncompile time and runtime is introduced in this gem. The entire system can be placed\ninto a library, thus maintaining compile time flexibility through the use of policies\n[Alexandrescu01], and includes the ability to remove the logging calls from the final\ngame. Runtime configuration allows the modification of logging data without the\nneed to recompile. This also allows developers to share the same code, but only log\nthe information they want to see. Thus, code can be entered into a source control sys-\ntem without the need to remove logging calls that might be useful later. We will also\nconcentrate on performance throughout the gem.\n\nPolicies define a class interface that is compile-time bound as a template parameter.\nPolicies are similar to the ‘traits’, used by the Standard Template Library (STL) and\nthe Strategy Design Pattern [GoF95]. The end user of a policy-based class can then\ncreate a class that conforms to the specified interface. This class is passed as a template\nparameter to configure an instance of a policy-based class without the need to change\nthe original class code. This makes policies useful in creating robust libraries, a con-\ncept that will be used throughout the design of the logging system. More information\non policies and policy design can be found in Modern C++ Design [Alexandrescu0 1].\n\nDebugging flags\n\nboolean type for determining whether to perform various debugging operations.\n\n129",
      "content_length": 2022,
      "extraction_method": "OCR"
    },
    {
      "page_number": 133,
      "chapter": null,
      "content": "130\n\nSection 1 General Programming\n\nWhen designing a flag, there are several decisions that need to be made. These deci-\nsions can be grouped into three main choices—initialization, assignment, and storage\ntype— that can be turned into policies, allowing the final decision to be made by the\nflag user. We can then provide implementations of these choices that are useful for\n\nlogging.\n\nInitialization\nThe most important decision is the method of initialization. The policy interface for\ninitialization is:\n\nclass t_InitializationPolicy\n\n{\ntypedef /*type*/ t_Type;\nStatic bool m_Convert(t_Type i_value) ;\n\n3\n\nThe first part of the interface defines the argument type used for initialization.\nThis is the type that will be passed to the flag’s constructor. The debug flag has access\nto this type because it is defined as t_Type. The second part of the interface is a func-\ntion that takes an argument of t_Type and converts it to a boolean value. This func-\ntion must be declared as static, so that it can be accessed without the need to\ninstantiate an instance of the class. With these two pieces, the constructor for the\ndebug flag can be implemented to take an argument, convert it to boolean, and then\nstore the boolean value.\n\nAssignment\n\nThe interface for the assignment policy is identical to the initialization interface. The\ntwo interfaces are separate in order to allow different types for initialization and\nassignment. Thus, the primary difference is only that the assignment policy is used\nto implement operator=, while the initialization policy is used to implement the\nconstructor.\n\nBoolean Storage Type\n\nThe final decision is the boolean storage type. The primary use of this policy is to\nmake the flag either a constant or a mutable boolean flag. By defining the type of the\nflag as constant, assignment is disabled. By defining the type as a normal boolean,\nassignment is made possible. It is also possible to provide more-complex types, as long\nas they support assignment from boolean and conversion to boolean. The policy\ninterface for this is:\n\nclass t_BooleanPolicy\n\n{\n}5\n\ntypedef /*type*/ t_Boolean;",
      "content_length": 2121,
      "extraction_method": "OCR"
    },
    {
      "page_number": 134,
      "chapter": null,
      "content": "1.15 Lightweight, Policy-Based Logging 131\n\nThe debugging flags greatly benefit from the ability to be initialized using a configu-\nration file, since debugging information can then be enabled without recompiling.\nFor this purpose, a Singleton class [GuF95] is created that provides initialization from\na single configuration file.\n\nInitialization\n\nThe first step is to initialize the configuration Singleton class by parsing the configu-\nration file. A sorted string array, using std::vector or a similar array class, is created\nbased on the contents of the configuration file. Once an array of available strings is\nsorted, we can use a binary search, such as std: :binary_search [Meyers01], to find a\nparticular string. Because most debugging flags are initialized at the start of an appli-\ncation, there is not as much of a concern for performance. Even so, the binary search\nshould be efficient.\n\nUse PIMPL\n\nThe public interface for the configuration file is simple and should not change,\nwhereas the private implementation has several options that might change for various\nreasons. The PIMPL, or Private Implementation, design pattern [Sutter00] is ideal\nfor separating the public interface from the private implementation. The public class\ncontains a pointer to a private implementation class, and the public class passes all\nfunction calls along to the private implementation. The private implementation can\nthen be created in a separate header or in the source file. If private changes are\nrequired later, there will be no effect on users of the public interface. This paradigm\nalso discourages the user of the public interface from relying on private implementa-\ntion details.\n\ninto a single configuration flag. The best approach for this is to provide an initializa-\ntion policy for the debug flag that uses a Singleton configuration class. The definition\nof t_Type, above, would become a string, and the conversion function would call the\nconfiguration Singleton class to convert the string to a boolean.\n\nThe log class brings all the components together with several policy interfaces to form\nthe workhorse of the logging system.\n\nFlag Policy\n\nEnabling and disabling of a log instance is based on the flag policy provided. The flag\npolicy interface is:",
      "content_length": 2264,
      "extraction_method": "OCR"
    },
    {
      "page_number": 135,
      "chapter": null,
      "content": "132\n\nclass t_FlagPolicy\n\n{\ntypedef /*type*/ t_InitializationType;\ntypedef /*type*/ t_AssignmentType;\nt_FlagPolicy(t_InitializationType i_value);\nt_FlagPolicy& operator=(t_AssignmentType i_value) ;\noperator bool() const;\n\n3\n\nThe first two parts of the interface are type definitions for the constructor and\noperator=. The flag policy must also support a constructor that takes the initializa-\ntion type and an assignment operator chat takes the assignment type. Note that this\npolicy differs from the others described previously because an instance of the flag is\ncreated within the log class, causing the need for a constructor. Finally, the flag policy\nmust support conversion to a boolean value. The debugging flag described earlier fits\nthe required interface.\n\nOperator<<\n\nThere are two primary methods for logging messages: variable-length argument lists\nor operator<<. While variable-length argument lists are a traditional method for log-\nging operations, this method introduces potential problems:\n\n¢ Lack of argument checking.\n\n¢ Lack of type safety.\n\n¢ Lack of extensibility.\n\n* No support for user class types.\n\nIn the best case, these problems could lead to garbage information in the logging\nsystem. In the worst case, logging could end up corrupting or crashing the game. For\nexample, if a string is specified in che output format, but is not included in the argu-\nment list, an invalid memory address is likely to be referenced. On many platforms,\ncertain memory addresses throw an exception even when the data is only being read,\ncausing the game to crash if the invalid memory address happens to land within one\nof these ranges.\n\nThe operator<< solves all of the problems previously listed, but it introduces a new\none. Variable argument list syntax would invoke only one function call, whereas opera-\ntor<< could invoke an unspecified number of functions calls. A buffer is needed to store\nthe result of each subsequent call until the entire log is collected and ready for dispatch.\n\nGiven the tradeoffs, operator<< is the still the best approach, so we deal with the\nbuffer issue by defining a buffer policy.\n\nDefining a Buffer Policy\n\nA buffer implementation, which determines how the log string is stored until being\n\ndispatched, is specified by the buffer policy:",
      "content_length": 2285,
      "extraction_method": "OCR"
    },
    {
      "page_number": 136,
      "chapter": null,
      "content": "1.15 Lightweight, Policy-Based Logging ; 133\n\nclass t_BufferPolicy\n\n{\ntypedef /*type*/ t_Type;\nstatic const string m ToString(const t_Type &i_buffer) ;\nstatic void m_Clear(t_Type &o_buffer) ;\n\n}5\n\nThe first part of the interface is the buffer class type, an instance of which will be\ncreated with each log class. Note that the buffer type must support all instances of\noperator<< that are to be logged. This allows the log class to pass on all operator<<\ncalls to the buffer policy with a template member function:\n\ntemplate <typename t_Type>\nt_LogImplementation& operator<<(t_Type i_value)\n{ m_buffer << i_value; return(*this); }\n\nAlthough a new class could be implemented, in most cases, the STL\nstd::stringstream is the best choice. The standard string stream also supports the\nother two buffer policy functions.\n\nThe m_ToString function converts the contents of the buffer to a standard string.\nThe standard string will then be passed to the dispatch policy (described later). The\n\nm_Clear function is used to clear the buffer once it has been dispatched.\n\nPerformance\n\nThe most important performance issue to address is log instances that have been dis-\nabled. Enabled logs are not as much of a concern because they are already bottle-\nnecked by the performance of I/O. For disabled logs, a boolean test and a branch\nshould be all that is performed. This prevents the use of a single function for the pur-\nposes of logging, which would require the evaluation of all function arguments. Since\noverloaded operators are really just functions with convenient calling syntax, they are\nnot useful, either.\n\nInstead, it is necessary to fall back to a trusted C paradigm—logical AND, &&. By\nplacing the boolean test before && and the logging function after, the entire logging\ncall is short-circuited when the boolean test is false. There are two steps to accom-\nplishing this result. First, for simplicity, define a macro:\n\n#define LOG(type) (type) && (type)\n\nNote that a macro must be used to ensure the logical AND behavior is preserved.\nA template function would result in a function call that would defeat the purpose of\nusing logical AND. Second, define an inline implementation of operator bool for the\nlog class that only calls the dispatch function when the internal flag is true:\n\nOperator bool() { return(m_flag && m_Dispatch()); }",
      "content_length": 2339,
      "extraction_method": "OCR"
    },
    {
      "page_number": 137,
      "chapter": null,
      "content": "134 Section 1 General Programming\n\nThis will expand to result in only one test and one branch for disabled flags. You\nmight be wondering about the dispatch call, which appears to be called twice due to\nthe two boolean conversions in the LoG macro. It is called twice for each log, but the\nfirst call performs no dispatch because the buffer is empty.\n\nDispatch Policy\n\nOnce the buffer is full and operator bool is called on the log class, the string is\nextracted, then the buffer cleared. The string is then passed to the dispatch function\ndefined by the dispatch policy:\n\nclass t_DispatchPolicy\n\nstatic void m_Dispatch(const string &i_string);\nhs\n\nThis function can be defined to do any number of things, including writing to\nthe console, writing to a file, displaying the message onscreen, or all of the above.\n\nThe first step in using the logging class is to create an instance of the class. Because\ntemplates are used, it is often helpful to define a shorthand type for various sets of\ntemplate arguments. For example:\n\ntypedef t_FlagImplementation<\nt_FlagConfigurationPolicy,\nt_FlagBooleanMutatorPolicy,\nt_FlagMutablePolicy> t_ConfigurationFlag;\n\ntypedef t_LogImplementation<\nt_ConfigurationFlag,\nt_StandardOutDispatchPolicy,\nt_StringStreamBufferPolicy> t_Log;\n\nFrom this, instances can be created that are initialized from the configuration file:\n\nt_Log LOG_MEMORY( \"MEMORY\") ;\nt_Log LOG_SCRIPT(\"SCRIPT“);\n\nLogging information is very similar to using the standard I/O streaming library.\nThe following is an example of a log:\n\nLOG(LOG_MEMORY) << \"Memory used is \" << 1_memoryUsage\n<< \"\\n\";\n\nThere is also the option to change the state of the logging instance later, for\nexample:\n\nLOG_SCRIPT = false;",
      "content_length": 1705,
      "extraction_method": "OCR"
    },
    {
      "page_number": 138,
      "chapter": null,
      "content": "1.15 Lightweight, Policy-Based Logging 135\n\nWith the information presented in this gem, a logging library can be created that is\nboth flexible and efficient. Extensions can be made without the need to change the\nlibrary code through the use of policies. Several basic policies are provided here and\non the CD-ROM, but there is still a wealth of new policies that can be written for\nspecific implementations. We encourage you to explore them.\n\n[Alexandrescu01} Alexandrescu, Andrei, Modern C++ Design, Addison-Wesley, 2001.\n\n[GoF95] Gamma, Erich, et al. Richard Helm, Ralph Richard, Johnson, Ralph, and\nJohn Vlissides, John, Design Patterns, Addison -Wesley, 1995.\n\n[Meyers01] Meyers, Scott, Effective STL, Addison -Wesley, 2001.\n\n[Sutter00] Sutter, Herb, Exceptional C++, Addison -Wesley, 2000.",
      "content_length": 794,
      "extraction_method": "OCR"
    },
    {
      "page_number": 139,
      "chapter": null,
      "content": "1.16\n\nManaging the Information _\n\n136\n\nJournaling Services\n\nEric Robert,\n\nUbi Soft Entertainment, inc.\neric.robert@videotron.ca\n\nebugging interactive applications is not a trivial task. Lots of things can go wrong\n\nwithout leading to a crash or without getting caught by proofing code. Also, tim-\ning issues, which are often involved, just make matters worse.\n\nIt is not uncommon to have some sort of state machine with unexpected behav-\nior under specific conditions. The faulty logic that triggered this condition could be\nvery far from the experienced problem in terms of both time and code. Many inter-\nmediate states could get executed before reaching the point where the error is finally\nnoticed. This occludes the real problem from the programmer and significantly\nincreases debugging time. Without any kind of execution history, the problem must\nbe reproduced over and over until the iterative process narrows down and gives a clear\npicture of what is really happening.\n\nProgrammers typically try to trace the code using their debugger. If this is not\npossible, they will start adding some debugging code to generate primitive tracing\ninformation where it might be needed. This is a long and arduous task. On the other\nhand, breaking into the code only reveals the current state of the application. What\nwent wrong could be light-years away and might not be retraced. Since debuggers\ntypically provide many effective ways to stop execution and to monitor memory, they\nare of limited help when it comes to interactive applications. What is needed is some\nway to trace the program’s flow without breaking it.\n\nTherefore, a solution could be to provide real-time information about what is\ngoing on under the hood in a flexible and efficient way. This is what this gem will\nfocus on.\n\nAn important consideration about real-time debugging is the amount of information\npresented to the user. It must be understood that having too much information is just\nas bad as not having enough. A monstrous amount of information will slow down the\nsystem and overwhelm the user. Needless to say, too little information is also quite\nuseless.",
      "content_length": 2132,
      "extraction_method": "OCR"
    },
    {
      "page_number": 140,
      "chapter": null,
      "content": "1. 16 Journaling Services © 137\n\nThe ideal balance must be reached by presenting the right debugging information\nat the right time. Therefore, the user should be actively involved in the selection of\nthe source of that information. Being able to focus reporting precisely on a specific\nsystem or subsystem can be a very precious tool. This way, journaling services can be\nused to mimic the debugging process and provide support for a divide-and-conquer\napproach known to help find and correct bugs.\n\nThus, the system should consist of a logical state (on/off) associated with each\nsystem or subsystem to support the activation or deactivation of reporting functions.\nIt should be built so that it can provide easier control over groups of states. For exam-\nple, the journaling of a complete system could be disabled without having to specify\neach and every associated subsystem:\n\nJournaling: :setDisable(\"/Core/Loading/...\");\n\nAnother consideration is the location where reports will be written. The user\nmight want data to be presented directly on-screen, sent directly to a file, or maybe\neven across the network if the monitored application is remote. This kind of flexibil-\nity is most welcome in console projects, since debugging is often somehow limited.\n\nBy providing an extensible framework from which alternative output locations\ncan be developed and integrated, the system’s usability will increase substantially.\n\nThe System Hierarchy\n\nUR HN TE HLL I EO A Sat ses nao\n\nOur journaling services are - built around three classes: the § Switch, the SwitchBox and\nthe Journal. Many concrete services can then be built using these basic components.\n\nThe switch is the primary interface that users interact with. It contains a logical\nstate and the associated output location wrapped in a Journal. Each Switch is owned\n\nSwitchBoxX\n\nSwitch A\n\n- On\n- Debugger\n\nYA &Z/A\n\nSwitchBox Y SwitchBoxZ\n\nSwitch A f} Switchc Switch A\n\n- On -On\n- Debugger | | - Log - Debugger\n\nFIGURE 1.16.1 Architectural overview.",
      "content_length": 2005,
      "extraction_method": "OCR"
    },
    {
      "page_number": 141,
      "chapter": null,
      "content": "Section 1 General Programming\n\nby a SwitchBox, which is part of the SwitchBox tree. By naming each element with\nstrings, the user can refer to them using the path notation.\n\nmySwitch = Journaling: :getSwitch(\"/Core/Loading/Trace\");\n\nIn the hierarchy, each SwitchBox is an internal node, and each Switch is a leaf. So,\nin this example, both “Core” and “Loading” are SwitchBoxes and “Trace” is a Switch.\n\nThe goal here is to have a Switch associated with a particular reporting facility for\na particular system or subsystem. Thus, a complete area of the program could control\nits reporting facilities with a simple query on the current state of its Switch.\n\nif (mySwitch->getState()) {\nmySwitch->getJournal() << \"Some Trace\";\n\n}\n\nBefore presenting some code, it is worth mentioning that while designing this\nsystem, we considered the journaling services to be basic services. Thus, we didn't use\nany kind of dynamic memory allocation (since the memory manager could eventually\nuse those services, creating a dependency loop). We also decided that the whole sys-\ntem should be available before the program entrance (main), since the service might be\nuseful for tracking construction of global objects. Because the initialization order of\nglobal objects cannot be controlled in a portable manner, we aimed for objects that\nwill be initialized on demand.\n\nFirst, users must declare their own SwitchBox and Switch singleton objects in\norder to use them in services. The initialization procedure for both classes is done\nusing the same method. The singleton instance is constructed on its first access using\na static factory method that will insert the object into its owner’s singly linked list.\nNote that macros are available for these tasks, but the generated code for a Switch is\npresented here.\n\n// Header file\nclass SwitchSample : public Switch\n\n{\ntypedef Root OwnerType;\nStatic Switch * ourInstance;\nstatic Switch * staticFactory();\npublic:\n\nSwitchSample() ;\n\nstatic Switch * getInstance() {\nif(ourInstance) {\nreturn ourInstance;\n\n}\n\nreturn staticFactory();",
      "content_length": 2057,
      "extraction_method": "OCR"
    },
    {
      "page_number": 142,
      "chapter": null,
      "content": "1.16 Journaling Services _ ; 139\n\n}5\n\n// Source file\nSwitchSample: : SwitchSample()\nSwitch (OwnerType: :getInstance(),\n\"My name\",\n“My description\") {}\n\nSwitch * SwitchSample::staticFactory() {\nstatic SwitchSample instance;\nourInstance = &instance;\nreturn ourInstance;\n\n}\n\nSwitch * SwitchSample::ourInstance =\nSwitchSample: :getInstance();\n\nUsing the helper macros usually make more sense.\n\nDECLARE_SWITCH(SwitchSample, Root);\nIMPLEMENT_SWITCH(SwitchSample,\n\n\"My name\",\n\n\"My description\");\n\nThe singly linked list is implemented without memory allocation by considering\neach inserted item as a node of the list. Thus, both classes supply a link to the next list\nitem (called the brother), allowing insertion.\n\nvoid SwitchBox: :addSwitch(Switch * item) {\nif(mySwitches) {\nitem->myBrothers = mySwitches;\n\n}\n\nmySwitches = item;\n\n}\n\nThis kind of structure will enable the implementation of a hierarchical propaga-\ntion of settings. This could be useful to enable (or disable) a Switch for a system and\nall its subsystems at once. Since everything is related somehow to the Root node, it\nalso provides a way to list and manage everything in the system.\n\nIt also gives the opportunity to provide a number of operations on the whole\nSwitchBox tree at once. A class named Journaling implements many of these operations.\n\n// Disable everything at once.\nJournaling: :disableAll();\n\n// Print the whole tree.\nstd::cout << Journaling: : getRoot();\n\nDue to the way instances are defined, the initialization of some branches in the\nSwitchBox tree will be forced if they are used before main. It is only after this process",
      "content_length": 1605,
      "extraction_method": "OCR"
    },
    {
      "page_number": 143,
      "chapter": null,
      "content": "140\n\nthat the whole tree is really available for operations. Hence, even if the system works\nfor global objects, it is somewhat limited.\n\nEach SwitchBox supplies two singly linked lists that use forward iterators. One is\nfor Switch and the second one is for SwitchBox children. They support both incre-\nment operators and the indirection operator that returns a reference to the associated\nlist item. Thus, in the previous example, if a Switch named “Trace” is added to the\nexisting SwitchBox named “Core”, changing the state of the “Core/Trace” could prop-\nagate at the lower level and update the “Core/Loading/Trace” accordingly.\n\nvoid Switch::setState(bool state, bool recursive) {\nmyState = state;\n\nif(recursive) {\nmyOwner ->propagateState(this) ;\n\n}\n}\n\nvoid SwitchBox: :propagateState(Switch * source) {\nSwitchBox:: Iterator i = getChildrenBegin() ;\n\nwhile(i != getChildrenEnd()) {\nSwitchBox * node = &(*it++);\nnode->setState(source) ;\n\n}\n\nvoid SwitchBox::setState(Switch * source) {\nSwitch: :Iterator i = getSwitchesBegin();\n\nwhile(i != getSwitchesEnd()) {\nSwitch * leaf = &(*i+t+);\n\nif(!strcomp(leaf->myName, source->myName)) {\nleaf->myState = source->myState;\n\n}\n}\n\npropagateState(source) ;\n\n}\n\nOther mechanisms could also be built around the hierarchical system already in\nplace. These might include some sort of extended name-matching using wildcards or\nregular expressions. However, the basic functionality presented here should be enough\nto efficiently use the system and control the flow of information.\n\nThe supplied code sample also implements the Journal propagation and some\nsearching facilities in the SwitchBox tree using path notation. A more elaborate imple-\nmentation could provide (at least) a console command so that the user could modify\nthe system’s Switch states in real-time. Maybe a stand-alone user interface would be\nuseful for remote debugging on systems that do not support a keyboard.",
      "content_length": 1918,
      "extraction_method": "OCR"
    },
    {
      "page_number": 144,
      "chapter": null,
      "content": "1.16 Journaling Services 141\n\nThe Journal Interface\n\nSSiRRISATRERRRTIN ARRAN TARO ANIMAS TEENAGE LISLE LIER OT VG EAGT RE, AMR RTE MRE TELE ELE EGET\n\nAn output location is associated with a Switch instance using the Journal abstraction.\nIt simply provides a way to output formatted text to different devices. Since instances\nof Journal will be shared, this resource is reference counted.\n\nOne way to implement this is by using the standard libraries with the\nstd: :iostream. Since the design is extensible, we can build our own streams fairly eas-\nily. As an example, a debug stream (specific to Win32) is presented here.\n\nFor those not familiar with the std: : iostream design, it can be divided into two\nlayers. The first implements all formatting concepts with manipulators and operators.\nThe other provides the underlying buffering mechanism. This separation will enable\nus to build our own buffering system and support alternate output locations while\nbenefiting from standard formatting operations. Our debugger stream is built around\na simple deviation from the std::streambuf. Since we only need an output stream,\nthe input part of the buffering is disabled (by default).\n\nThe first step is to build a std::streambuf. A fixed-size buffer is provided for\nbuffering, and only two virtual methods need to be implemented. The first one trans-\nfers the data within the buffer to the debugger with a Win32 call. Note that one char-\nacter is reserved for the null termination. The second function deals with overflow\nsituations.\n\nclass DebuggerStreamBuf : public std::streambuf\n\n{\nchar myBuf [512];\npublic:\nDebuggerStreamBuf() {\nsetp(myBuf, myBuf + sizeof(myBuf) - 1);\n}\nprotected:\n\nvirtual int sync() {\nsize_t len = pptr() - pbase();\n\nif(len > 0) {\nmyBuf[len] = 0;\nOutputDebugString (myBuf ) ;\nsetp(myBuf, myBuf + sizeof(myBuf) - 1);\n}\n\nreturn 0;\n\n}\n\nvirtual int_type overflow(int_type c) {\nsync();\n\nif(c != traits_type::eof()) {\nmyBuf [0] = c;",
      "content_length": 1946,
      "extraction_method": "OCR"
    },
    {
      "page_number": 145,
      "chapter": null,
      "content": "142 Section 1 General Programming\n\npbump (1);\nreturn c;\n\n}\nreturn traits_type: :not_eof(c);\n};\n\nThe journal provides two additional virtual functions used to delimit the begin-\nning and the end of a reporting event. For the debugger journal, only the end is used,\nwhich provides synchronization with the debugger. So, to implement this journal, the\nstd: :ostream subsystem must simply be initialized with the above std::streambuf.\n\nclass DebuggerJournal : public Journal\n\n{\nDebuggerStreamBuf myStreamBuf ;\npublic:\nDebuggerJournal() {\ninit (&myStreamBuf ) ;\n}\nvirtual char endReport() {\n*this << std::endl << std::flush;\nreturn 0;\n}\n}5\n\nMore-elaborate journals can be built using this method. In the supplied code\nsample, we added a journal that uses a Win32 message box. This way, we can retrieve\nthe user’s answer and act accordingly.\n\nOther implementations can be used to extend the system and add more types of\njournals. For example, it would be useful to have multiple output locations for a\nunique reporting event. However, since the Switch class only contains a single Jour-\nnal reference, a new type of Journal that can handle this case needs to be designed. A\nquick way to resolve this problem is to forward the formatted data string to all other\ninstances of Journal that could be kept in a std: : vector.\n\nvirtual int sync() {\nsize_t len = pptr() - pbase();\nif(len > 0) {\nmyBuf{len] = 0;\nfor(int i = 0; i < myJournals.size(); ++i) {\n*(myJournals[i]) << myBuf;\n}\n\nsetp(myBuf, myBuf + sizeof(myBuf) - 1);",
      "content_length": 1512,
      "extraction_method": "OCR"
    },
    {
      "page_number": 146,
      "chapter": null,
      "content": "1.16 Journaling Services 143\n\nreturn 0;\n\nBuilding Journaling Services\n\nSHERRATT RRR AAA NA ROSIE RE ONO GS SBOE R ANIONS S SOS TRINA TERRE NANA\n\nSome typical journaling services are presented here that use the system presented in\nthe previous section to control the flow of information.\n\nInformation Reports\n\nThe first service only reports data to the associated journal. It provides the very basic\nfunctionality needed to use the system.\n\n#define REPORT(Leaf, Expression)\ndo {\nSwitch * leaf = Leaf::getInstance();\n\nif (leaf->getState()) {\nJournal& journal = *leaf->getJournal();\njournal. beginReport();\njournal << Expression;\njournal.endReport();\n} \\\n} while(0)\n\nee ee ee ead\n\nNote that all services are designed as macros to enable conditional compilation\nand remove some or all reporting facilities on specific builds.\n\nTracing Information\n\nAnother useful idea is the stack trace. Knowing what portion of the program is cur-\nrently executing (without stopping it) can be valuable. This is especially true when\ndebugging optimized releases or if associated debugging information is not available.\n\nThe method presented here simply keeps track of the whole call stack at all times.\nEach method must contain some code that will update the stack as the program runs.\nIf one of the methods is missing this piece of code, it will simply not be shown. The\njournaling will report (when enabled) the Enter and Leave events. Nevertheless,\nbecause the stack must be valid even when not reporting, the housekeeping code will\nalways get executed.\n\nvoid foo() {\nTRACE (TraceSwitch); // Add the stack trace here.\n\n}\n\nThis implementation simply pushes the current function name and the associated\nSwitch on the stack. Since many compilers now support a predefined macro describ-\ning the current function name, it will be used here. To differentiate between functions",
      "content_length": 1853,
      "extraction_method": "OCR"
    },
    {
      "page_number": 147,
      "chapter": null,
      "content": "144 Section 1 General Programming\n\nhaving the same name, we chose to use the function's signature. Note that a pointer to\nthe parent is kept to enable us to walk back up the stack to its top.\n\nclass StackTracer\n\n{\n\nStackTracer * myParent;\n\nSwitch * myLeat;\n\nconst char * myName;\n\npublic:\n\nStackTracer(Switch * leaf, const char * name)\nmyLeaft(leaf), myName(name) {\nmyParent = ourParent;\nreportEvent(\"Enter -- \");\nourParent = this;\n\n}\n\n~StackTracer() {\nreportEvent(\"“Leave -- \");\nourParent = myParent;\n\n}\n\nprotected:\n\nvoid reportEvent(const char * prefix) {\n\n}\n\nstatic StackTracer * ourParent;\n\nhs\n\nThe helper macro can then be easily defined with the compiler-specific definition\nof the function's signature. Note that we are using a predefined compiler macro that\nwas not available in any version prior to Microsoft Visual Studio .NET. Thus, some\ncompilers might not support this feature. Some other compilers, like Metrowerks\nCodeWarrior, support this with the GCC extension __PRETTY_FUNCTION_, which\ndoes the same thing.\n\n#define TRACE(Leaf) \\\nStackTracer \\\nstackTop(Leaf::getInstance(), _ FUNCSIG_)\n\nAt any moment, this ‘virtual’ call stack can be used to report the current position\nof the program. For example, the next service reports the call stack when an unex-\npected condition occurs. This way, the user has more-valuable information than just\nthe traditional filename and line number.",
      "content_length": 1396,
      "extraction_method": "OCR"
    },
    {
      "page_number": 148,
      "chapter": null,
      "content": "1.16 Journaling Services 145\n\nInteractive Reports\n\nFinally, to give an overview of interactive reports, the common assertion macro will be\npresented. Normally, if the assertion fails, a message box is displayed to prompt the\nuser to choose between aborting the application, debugging it, or simply ignoring\nthe error. The assertion’s logic should not be associated with the Journal, since it\ncould be used with any other interactive services. Therefore, the behavior of this\nreport differs with the above trace service in handling the endReport event. It should\nonly communicate the user’s answer so that it can be dealt with appropriately. All sup-\nported values are enumerated in the Journal interface.\n\n#define ASSERT(Leaf, Condition)\ndo {\nSwitch * leaf = Leaf: :getInstance();\nif (leaf->getState() && !(Condition)) {\nchar result =\ndisplayAssert(leaf->getJournal(),\n\n#Condition,\n_ FILE_,\n__LINE__);\n\nif(result == Journal::ABORT) {\nSystem: : Terminate();\n\n}\nif(result == Journal::BREAK) {\n\nSystem: :Break();\n}\n\n}\n} while(0)\n\nCe MM MM MM MM MM MM Nr ne\n\nNote that this opens the door to something interesting. By using another Jour -\nnal, it is possible to run the application unattended. Assertions will still get caught\nand reported, but no message box will wait on the user.\n\nConclusion\n\nTo summarize, we presented a simple and extensible system built to control the flow\nof real-time information, along with some basic tools to report it. However, it should\nbe clear that the quality of that information and its adequate separation into usable\ntopics are definitively up to the programmer. Remember that time invested in pro-\nducing information reports will pay off when it’s time to debug.\n\nReferences\n\n[Reeves01] Reeves, Jack, “The (B)Leading Edge: Using IOStreams, Part I,” The\nC/C++ User’s Journal Experts Forum, available online at hetp://www.cuj.com/\nexperts/1901/reeves.htm, January 2001.\n\n[Stroustrup00] Stroustrup, Bjarne, The C++ Programming Language Special Edition,\nAddison Wesley, 2000.",
      "content_length": 2004,
      "extraction_method": "OCR"
    },
    {
      "page_number": 149,
      "chapter": null,
      "content": "1.17\n\n146\n\nReal-Time Hierarchical\nProfiling\n\nGreg Hjelstrom and Byon Garrabrant,\n\nWestwood Studios\n\ngreg@westwood.com\nbyon@byon.com\n\nWr developing most games, a primary goal is to get maximum performance\nout of your code. Knowing where to spend your optimization effort is key to\nattaining this goal. We've all heard variations on the old adage: “A program spends\n90% of its time in 10% of the code.” Profiling is an invaluable tool for finding that\n10% of the code that needs to be optimized.\n\nTwo types of profiling strategies are often employed—sampling and explicit tim-\ning. A sampling profiler works by frequently sampling the position of the instruction\npointer while the program runs. This generates a huge amount of raw data that is\nthen processed to generate profiling data. Sampling profilers can often tell you exactly\nin which line of code most of the time is being spent. Many commercial profilers\nwork this way because modifications to the application code are unnecessary. Unfor-\ntunately, it isn't always practical to use sampling in real-time, due to the amount of\noverhead involved in gathering and processing the sampled data.\n\nThe other profiling method that is commonly used is to explicitly time blocks of\ncode. These measurements can then be displayed in real-time and can aid in finding\ntransient performance problems. This is important because bottlenecks in games are\noften dependent on many factors. It is useful to see how the profiling data changes as\nthe user plays the game and triggers various events. Also, these profiling samples will\ntypically be logically organized. For example, one might log how much time the code\nspends processing AI, rendering, and physics. Then, at any point in time, you can see\nwhich subsystem in the code is taking the most time. The only drawback to this type\nof profiling is that it only gives a general idea of where the code-processing time is\nbeing spent. For example, once you know the AI is running extremely slow, you typi-\ncally have to use a sampling profiler or temporarily add more timing measurements to\nfind out why the AI is running slowly.\n\nIdeally, we would like to have the best of both worlds—real-time profiling with as\nmuch detail as a sampling profiler. This gem will describe a system that, while not",
      "content_length": 2286,
      "extraction_method": "OCR"
    },
    {
      "page_number": 150,
      "chapter": null,
      "content": "1.17 Real-Time Hierarchical Profiling ; 147\n\nattaining the resolution of a sampling profiler, can efficiently support thousands of\nprofiling samples that are logically and hierarchically organized. A ‘profile tree’ is con-\nstantly updated and can be browsed in real-time, and we can find out where the CPU\nis spending its time.\n\nThe Profile Tree\n\neS RE RENARD IDI BM LER BREE RIL OOS FREE IE OSLO ILE YD LTS\" IE LEST LEE LET LR EERE\n\nThe profile tree is an V-ary tree made of profile nodes. An N-ary tree is a tree where each\nnode of the tree can have any number of child nodes. The topology of this tree is deter-\nmined by the placement of profiling macros in the application’s code. Since each node\nin the tree typically has only a few children, searching and data presentation is efficient.\n\nEach profile node corresponds to a single explicit timing sample of a block of\ncode. Each node tracks the total amount of time spent within that block of code and\nthe total number of times that code has been executed. Samples, which are taken\nwithin the scope of another sample, correspond to a child node of that sample.\nWhenever a new profiling call is made, a new child node is added to or reused in the\ncurrent node.\n\nFor a real-world example, we can examine how this profiling system was used in\nCommand & Conquer Renegade. Renegade had a total of over 1,000 profile nodes(see\nColor Plate 1). However, the profiler was efficient because there were only an average\nof 2 children for any given node, and the worst-case node only had 15 children. As we\nwill show later, the cost of this algorithm is proportional to the number of children in\na node.\n\nRL HRN PRIN ATER ANE TSO NESE NAT RSIS NAN AR GL PRORAL Kaen HNO ATR OID RNAI ARS TAUNNE SRE IITA\n\nTo use this profiling system, PROFILE macros must be placed at key points in the code.\nAs will be described later, placing a PROFILE macro in the code will cause a profile\nnode to be generated. This node will be responsible for timing the scope of the corre-\nsponding code. A good strategy is to place a PROFILE macro at the top of each subsys-\ntem in the application, and refine it as needed.\n\nvoid My_Function(void)\nPROFILE (\"My_Function\")\n}\n\nIt can be helpful to break large routines into several independent profile samples.\nThis is easily accomplished by adding additional scoping brackets to the function,\neach with their own PROFILE macro. Here is an example:\n\nvoid BigFunction(void)\n\n{\n\nPROFILE(\"BigFunction Part 1\")",
      "content_length": 2471,
      "extraction_method": "OCR"
    },
    {
      "page_number": 151,
      "chapter": null,
      "content": "148 Section 1 General Programming\n\noo\n\nUW\n\nFIGURE 1.17.1 his is a screenshot the real-time hierarchical profiler running inside of Command\n& Conquer Renegade. Only one node of the tree is shown, but the user can navigate the tree in real-\ntime.\n\nPROFILE(\"BigFunction Part 2\")\n\nIt can also be useful to ‘flatten’ the profile structure of a member function in a\nclass hierarchy. The following example shows how you can combine time spent in a\nparticular layer of an overridden function, even when it is called through many differ-\nent derived classes. In this example, time spent in BasePhysics::Timestep() is not\nincluded in CarPhysics: :Timestep(), and all time spent in BasePhysics: :Timestep()\nwill be combined into a single profile sample, even when called from other derived\nclasses (assuming they use this profiling strategy).\n\nvoid CarPhysics: :Timestep(void)",
      "content_length": 865,
      "extraction_method": "OCR"
    },
    {
      "page_number": 152,
      "chapter": null,
      "content": "1.17 Real-Time Hierarchical Pr\n\n149\n\n{\n{\nPROFILE(\"CarPhysics::Timestep\") ;\n}\nBasePhyics: :Timestep();\n\n}\n\nBrowsing the Profiling Data\n\nThis profiling system generates a lot of data, so the user must have a way to navigate\nit easily. An iterator is provided that can be used to navigate through the tree and dis-\nplay statistics for the children of the current node. Using this system, a user can chase\ndown a bottleneck in real-time by walking up and down the profile tree, and focus on\nareas of code that are taking a lot of time. For example, a representative profile sample\nfor the main loop of Renegade is listed in Table 1.17.1.\n\nTable 1.17.1 Profile Data for Main Loop\n\nName %Parent %Total Ms/Frame Ms/Call Calls/Frame\n0-Audio 2.01 2.00 0.35 0.35 1\n\n1-Render 51.64 51.40 8.95 8.99 1\n2-Network 1.70 1.69 0.30 0.30 1\n\n3-Think 43.19 42.99 7.49 7A9 1\n4-Pathfind 0.04 0.04 0.01 0.01 1\n\nUnlogged 1.42 1.42\n\nIn this case, the time is mostly split becween Render and Think. Navigating the\ntree is achieved by assigning a numerical index to each child of the current node. The\nuser is allowed to enter either the parent of the current node or any of its children.\nAssume the user wanted to investigate the Render child. They would get a new dis-\nplay, as shown in Table 1.17.2.\n\nTable 1.17.2 Profile Data for Render\n\nName %Parent %Total Ms/Frame Ms/Call Calls/Frame\n0-Switch_Thread 16.39 8.58 1.47 1.47 1\n1-Post_Render 0.28 0.14 0.02 0.02 1\n2-End_Render 8.04 4.21 0.72 0.72 1\n3-DialogMgr 0.09 0.01 0.01 0.01 1\n4-Render_Game 49.55 25.95 4.44 4.44 1\n5-Begin_Render 1.70 0.89 0.15 0.15 1\n6-Shadow_Gen 22.83 11.96 2.05 2.05 1\n\nUnlogged 1.12 0.09",
      "content_length": 1638,
      "extraction_method": "OCR"
    },
    {
      "page_number": 153,
      "chapter": null,
      "content": "150 Section 1 General Programming\n\nSince Render_Game takes a large portion of this node’s time, the user could then\ndescend the tree to get a breakdown of that node. This process can continue as long as\nthere are children of the node you are interested in.\n\nAll of the statistics in the profiling system represent running totals and averages.\nIt can be useful to use the reset feature to throw out historical data. For example,\nwhen the frame rate drops, we often reset the profiler to get a more accurate measure-\nment of what the code is doing at that time. When the profile system is reset, the tree\nis not actually destroyed; only the timing data contained in the nodes are zeroed out.\n\nimplementation\n\nThe implementation relies on an accurate way to sample time. We used the 64-bit\ncycle counter feature of Pentium CPUs. This counter is incremented every time the\nCPU executes an instruction. By saving the state of the counter at the start of a pro-\nfiling sample and subtracting that value from the state of the counter at the end of a\nprofiling sample, you can very accurately compute the amount of time elapsed. We\nthen divide the number of instructions by the CPU clock speed to determine the\namount of time spent. Our profile nodes accumulate the amount of time in a float-\ning-point variable.\n\nCProfileSample\n\nThis is a small C++ class whose only task is to call the start_Profile() method of\nCProfileManager in its constructor and the Stop_Profile() method in its destructor.\nThis automates the task of starting and stopping a profile sample during the scope of\nthis object. To further simplify the usage, the PROFILE macro is used to automatically\ncreate a CProfileSample object and to easily remove profiling code from release builds.\n\nclass CProfileSample {\n\npublic:\nCProfileSample(const char * name)\n‘ cProfileManager: :Start_Profile(name) ;\n pprofilesample(void)\n‘ CProfileManager: :Stop_Profile();\n}3\n\n#define PROFILE(name) CProfileSample _ profile(name)\n\nCProfileManager\n\nThe profile manager is the external interface to the profiling system. It maintains the\nCurrentNode pointer into the profile tree that corresponds to the scope of the cur-\nrently executing code. It also contains methods for accessing the profile tree for dis-\n\nplay purposes.",
      "content_length": 2267,
      "extraction_method": "OCR"
    },
    {
      "page_number": 154,
      "chapter": null,
      "content": "1.17 Real-Time Hierarchical Profiling 151\n\nThe Start_Profile() method is used to start a profile sample. It detects recur-\nsion by comparing the name of the requested profile with the name of the current\nnode. When the subnode that matches the given name is found, it becomes the cur-\nrent node. The overhead incurred in this search will be proportional to the number of\nimmediate children linked to the current node. Typically, this is a small number,\nrarely as large as 10. In addition, since we use static strings for all of our profile sam-\nple names, pointer compares are used rather than slower string compares when look-\ning for a particular profile sample.\n\nIn the case that a child with the given name does not exist, a new node will be cre-\nated and linked to the tree. Note that node creation will only occur on the first pass\nthrough a particular code path. In any case, the node’s Cal1() method is then called to\nbegin timing.\n\nvoid CProfileManager: :Start_Profile(const char * name)\n\n{\nif (name != CurrentNode->Get_Name()) {\nCurrentNode=CurrentNode->Get_Sub_Node(name) ;\n}\nCurrentNode->Call();\n}\n\nThe Stop_Profile() method is used to end a profile sample. The first task is to\ncall the Return() method on the current node to complete and record the timing.\nSince the profile manager has maintained the current node being sampled, no search-\ning overhead is incurred in this operation. Assuming we are not in a recursive func-\ntion, the parent node becomes the current node.\n\nvoid CProfileManager::Stop Profile( void )\n\n{\n// go to parent unless recursed\nif (CurrentNode->Return()) {\nCurrentNode = CurrentNode->Get_Parent();\n}\n}\n\nThe remaining methods in the profile manager are either accessors or perform\nsimple administrative functions. For example, the application calls the Increment_\nFrame_Counter() method once per frame in order to support calculation of the num-\nber of calls per frame for any profile sample. The Get_Iterator() and Release_Iter-\nator() methods provide and destroy an iterator that is used to access the profile tree.\n\nCProfileNode\n\nThe CProfileNode is a C++ class that is private to the profiling system; it stores the\ntotal time spent in a block of code and the number of calls of that block of code.\nWhen the CPU is in the scope of a node, the node also stores the starting time.",
      "content_length": 2320,
      "extraction_method": "OCR"
    },
    {
      "page_number": 155,
      "chapter": null,
      "content": "152 Section 1 General Programming\nTo start a profiling sample, the profile manager calls the Cal1()method on the\nnode. This method simply increments the call counter and, if we are not recursing,\nrecords the starting time.\nvoid CProfileNode::Call( void )\n{\nTotalCalls++;\nif (RecursionCounter++ == 0) {\nProfile_Get_Ticks(&StartTime) ;\n}\n}\n\nAt the end of a profiling sample, the Return() method is called. After checking if\nwe are not recursing, the elapsed time is computed and added to the TotalTime vari-\nable. This function also returns whether or not the code is recursing, so the profile\nmanager knows if the node is completed, in which case it would return to the parent\nnode.\n\nbool CProfileNode::Return( void )\n{\nif (--RecursionCounter== 0 && TotalCalls !=0 ) {\n__inte4 time;\nProfile_Get_Ticks (&time) ;\ntime-=StartTime;\nTotalTime += (float)time / Tick_Rate();\n}\nreturn ( RecursionCounter == 0 );\n}\nCProfilelterator\nThis object provides an easy way to browse the profile tree. It contains methods for\nnavigating the tree and displaying the contents of a particular node. Typically, a node\nalong with its immediate children are displayed to the user. For each child, several sta-\ntistics are available: total time spent, total number of calls, calls per frame, and time\nper frame.\nConclusion\n\n<A SSRN 850 AOE RNR SRO SEE RMHRESS MoS 80 SRA IE ARRAN AS ae\n\nWith the ability to hierarchically profile code in real-time and sample thousands of\nblocks of code efficiently, we’ve found this to be a useful tool for code optimization. It\nis our hope that readers will find this system useful in improving their own code. You\noNTHECD will find an implementation of these classes on the CD-ROM.\n\nReferences\n\nRRR eer NR ARB 2 a sR eS EIST ee\n\n[GPGO00] Rabin, Steve, Game Programming Gems, Charles River Media, Inc., 2000.",
      "content_length": 1817,
      "extraction_method": "OCR"
    },
    {
      "page_number": 156,
      "chapter": null,
      "content": "2.1\n\nON THE CD\n\nFast Base-2 Functions for\nLogarithms and Random\nNumber Generation\n\nJames McNeill\njames_mcneill@ameritech.net\n\nn this gem, three utility functions are presented for computing values associated\nwith the base-2 logarithms of integers. They are simple, efficient, and correct for\nany 32-bit input value, in contrast to their floating-point alternatives.\n\nes occasionally during the game-\ndevelopment process. The integral logarithm is the real logarithm, rounded up or\ndown to the nearest integer as required. This logarithm is useful when rounding tex-\nture image dimensions up to the nearest power of two, padding data to the nearest\npower of two before using the Fast Fourier Transform, or determining the number of\nlevels a quadtree needs in order to subdivide a grid.\n\nAlthough the logarithm can be calculated using an expression such as\nint(floor(log(n)/1og(2))) or int(ceil(log(n)/1og(2))), the floating-point divi-\nsion can underflow and give incorrect results. A simple test program of the above\nexpressions using 32-bit floating-point arithmetic on an Intel processor showed the\nproblem occurring as low as n = 65536. There are also some environments that are\ndevoid of floating-point functionality, but a mechanism for computing the integral\nlogarithm is still desired.\n\nTo avoid these issues, we use the two integer-only routines described in this gem.\nThey provide correct results over the entire 32-bit input range and are also more effi-\ncient than the corresponding floating-point methods. The expression log2le(n) ,\nwhich stands for “log, less-than-or-equal-to n”, finds the largest non-negative integer\nx such that 2* < n. The expression log2ge(n), which stands for “log, greater-than-or-\nequal-to 7,” finds the smallest non-negative integer x such that 2* 2 n. The code for\nboth of these functions can be found on the CD-ROM.\n\n157",
      "content_length": 1861,
      "extraction_method": "OCR"
    },
    {
      "page_number": 157,
      "chapter": null,
      "content": "158\n\nSection 2 Mathematics\n\nBit Masks and Random Number Generation\n\nern NER  enoom RR RIES : SSSR\n\nYEE BESS SEAN AROSE NILES OSI S ECORI BBB ANRONM\n\nThe third utility function provided in this gem, bitmask(n), computes a mask in\nwhich all bits used by numbers from one up to, and including, 7 are set to one.\n\nOne use for bitmask() is in generating uniformly-distributed random integers\nthat fall within a specified range. As an example, suppose a random number generator\nrand()generates uniformly-distributed random integers in the range 0 to 32767, but\nwe need a sequence of random numbers in the range [0, 2]. A common approach is to\nuse the modulus operator to map the source range to the target range:\n\nint randomNum = rand() % 3;\n\nAs described in [Booth97], there are a couple of problems with this method. The\nmodulus operator is typically fairly slow, and the results are slightly biased away from\na uniform distribution. Because the target range [0, 2] does not evenly partition the\nsource range of [0, 32767], values of randomNum are not evenly distributed. Zero and 1\neach have 10,923 values of rand() that map to them, while 2 has only 10,922 values\nthat map to it. This is admittedly a small difference, but the disparity can be larger.\nFor instance, if we used this technique to generate numbers in the range [0, 32766},\nzero would be ewice as likely as any other number.\n\nOne way to get evenly distributed results is to generate random numbers and\nthrow them away until we get one within our desired range:\n\ndo { randomNum = rand() } while ( randomNum > 2 );\n\nNow, with our example, this would take a very long time, since values of rand()\nare far more likely to be out of the desired range than in it. However, the above pro-\ncedure can be modified to be quite fast. First, use the modulus operator with an inte-\ngral divisor in the range of rand() to get to an intermediate range of random numbers\nas close as possible to the target range. Then, reject any values from the intermediate\nrange that fall outside the target range:\n\ndo { randomNum = rand() % 4 } while ( randomNum > 2 );\n\nSince most random number generators have a range that is a power of two, we\ncan use bit masking instead of the modulus operator to speed things up:\n\ndo { randomNum = rand() & 3 } while ( randomNum > 2 );\n\nThis is where our function bitmask() comes in. It computes the necessary bit\nmask for use in the previous algorithm, so we can write a general function for getting\nrandom numbers over an arbitrary range:\n\nunsigned random( unsigned range )\n{\nif ( range < 2 )\nreturn 0;",
      "content_length": 2574,
      "extraction_method": "OCR"
    },
    {
      "page_number": 158,
      "chapter": null,
      "content": "2. 1 Fast Base-2 Functions for Logarithms anc and Random Number Generation — 159\n\nunsigned mask = bitmask(range-1);\n\nunsigned n;\n\ndo { n = rand() & mask; } while (n >= range);\nreturn n;\n\n}\n\nAssuming the values of rand() are evenly distributed, the expected number of\nloop iterations is less than two and approaches one as the intermediate range’s size\napproaches that of the target range. This is substantially faster and more reliable than\nthe alternatives.\n\nHow the Functions Work\n\nRAREST SED GAC IE\n\nThe functions are specialized for 32-bit i integers. This limits the number of distinct\nreturn values to 32 or 33, depending on the function. The function log21e() returns\na value ranging from 0 to 31, log2ge() returns a value ranging from 0 to 32, and\nbitmask() returns a bit mask ranging from 0 to OxFFFFFFFE\n\nOne possible algorithm would be to simply store the 32 or 33 return values in an\narray and do a binary search through it to find the correct result. The functions here\nfollow this approach, but do so without the stored array, since the array entries are eas-\nily computed as needed. Only a few registers are used as a result. Finally, the loops\nhave been unrolled for speed.\n\nThe implementations of each function can be found on the CD-ROM.\n\nON THE CD\n\nei re a te\n\n~ [Booth97) Booth, Rick, Inner Loops: A Sourcebook For Fast 32-Bit Software Devel-\nopment, Addison-Wesley Developers Press, 1997: pp. 223-224.\n\nAOI NORE Re",
      "content_length": 1435,
      "extraction_method": "OCR"
    },
    {
      "page_number": 159,
      "chapter": null,
      "content": "2.2\n\nUsing Vector Fractions for\nExact Geometry\n\nThomas Young, PathEngine\nthomas@pathengine.com\n\ni tends to happen near the end of the project. A particularly ingenious tester figures\nout that there is a certain corner on a certain level where path-finding fails, leaving\nenemies stuck. Someone else notices that jumping into another corner lets you wan-\nder off the edge of the world. After days of nerve-racking debugging, you figure out\nthe source of the problem—error due to approximation.\n\nIn game programming, fewer problems are more subtle or insidious than round-\noff errors. Perhaps you try to add code to the system to catch these errors. You check\nfor tolerances and write a lot of special-case code. Unfortunately, this merely converts\nthe precision problem into a set of other nasty problems. What error tolerances are\nacceptable? How can we guarantee that the code will work? Lastly, who will ever be\nable to figure out our code when the sequel comes out?\n\nThis gem considers examples in constructive solid geometry and in path-finding\nwhere approximation at points of intersections can cause the algorithms to fail. Tech-\nniques are offered for representing these intersection points without approximation.\nThis enables us to eliminate errors without adding complexity to our algorithms.\n\nThe Problem\n\nSvea\n\n160\n\nSAAN NS RPP PRE EAP RRO LEE\n\nWhen a polygon is rendered to screen pixels, the user won't notice if the least signifi-\ncant bit of the green value is incorrect. Even if screen coordinates are off by a pixel or\ntwo, it’s probably okay as long as there are no visual artifacts, such as cracks between\npolygons.\n\nOn the other hand, there are some key algorithms in game programming that are\nsensitive to even small round-off errors in mathematical calculations. In particular, a\nproblem arises when an algorithm needs to reuse the results of calculations with\nimplicit round-off errors. With a complex algorithm, we often depend on constraints\nholding true for our data structures as the algorithm proceeds. Perhaps we depend on\nthis to have the algorithm terminate.\n\nWhen we try to represent fractional values as floating-point or fixed-point num-\nbers, we often introduce round-off errors that can affect the results of our algorithms.",
      "content_length": 2260,
      "extraction_method": "OCR"
    },
    {
      "page_number": 160,
      "chapter": null,
      "content": "2.2 Using Vector Fractions for Exact Geometry 161\n\nWe can’t represent 1/3 exactly using a fixed-point or floating-point number of finite\nprecision. Examples of this kind of problem arise in constructive solid geometry\n\n(CSG) and points-of-visibility path-finding.\n\nConstructive Solid Geometry\n\nConsider the problem of Boolean operations between meshes in two dimensions. In\norder to process the mesh efficiently, we will want to specify certain validation condi-\ntions for that mesh. For example, we can require all faces to be convex. We then\ndepend on this validation condition for the algorithm to work.\n\nAs part of the Boolean process, we might detect an overlap between two faces and\nresolve this by introducing extra vertices where edges intersect (see Figure 2.2.1).\n\nFIGURE 2.2.1 Boolean subtraction in two dimensions.\n\nApproximation at these intersections can lead to nonconvex geometry (see Figure\n2.2.2).\n\nFIGURE 2.2.2 Approximation results in a nonconvex face.",
      "content_length": 972,
      "extraction_method": "OCR"
    },
    {
      "page_number": 161,
      "chapter": null,
      "content": "162\n\nSection 2 Mathematics\n\nThe same problem exists in three-dimensional constructive solid geometry for\nedges created at the intersection of faces and for vertices created at the intersection of\nan edge with a face.\n\nPath-finding\n\n[Young01] demonstrates how silhouette regions can be used to optimize points-of-\nvisibility path-finding. Each point of visibility corresponds to a corner in the environ-\nment. A point is considered for connection if it appears as a silhouette from the\nperspective of the source point.\n\nFigure 2.2.3 shows how approximation at an intersection can cause path-finding\nto fail. The boundary of a silhouette region intersects with another line, which might\nbe an expanded external edge, another region boundary, or a portal. Approximation at\nthe intersection means that our source point is incorrectly determined to be outside of\nthe silhouette region, so a connection to the associated point of visibility is not gener-\nated. The line from the source point to the target point just clips the edge of the\nobstacle and is, therefore, blocked by collision. The result is that the path-finder fails\nto generate a path to the target area.\n\n. —— Source point\nPoint of visibifity\n\nTarget point\n\nSilhouette region\n\nTarget area\n\nFIGURE 2.2.3 Path-finding fails because the source point is incorrectly determined to be\noutside a silhouette region.\n\nOne solution to this problem is to treat the lines bounding our silhouette regions\nas infinite lines. To test if the source point is in a given region, we test inside of each\nbounding line. However, it is a lot quicker to keep track of which region a point is in\nby detecting which edges are traversed as a point is moved. If our path-finder has to\ndeal with overlapping geometry, then this traversal also serves to delineate between\ndifferent levels of geometry.\n\nIn order to perform our traversal, we need to be able to determine which side of\nour traversal an intersection is on. In Figure 2.2.4, the traversal ends inside the sil-\nhouette region because the intersection is to the right of the line of traversal.",
      "content_length": 2084,
      "extraction_method": "OCR"
    },
    {
      "page_number": 162,
      "chapter": null,
      "content": "2.2 Using Vector Fractions for Exact Geometry 163\n\nTraversal\n\nFIGURE 2.2.4 Traversal into a silhouette region.\n\nWhy Not Just Use Floats?\n\nFloating-point representation only gives us greater precision near zero. At the edges of\nthe number range, we actually get less precision than with an integer representation\nbecause of the bits required to store the exponent. Floating-point representation\nimplies a grid that looks something like Figure 2.2.5, but with many more gradua-\ntions. Thus, the problem still occurs, since results are still approximated to a grid.\n\nFIGURE 2.2.5 A floating-point grid.",
      "content_length": 599,
      "extraction_method": "OCR"
    },
    {
      "page_number": 163,
      "chapter": null,
      "content": "164 —\n\nEven adding arbitrary precision doesn’t solve the problem. For example, we can-\nnot represent 1/3 exactly no matter how many decimal places we use. Some errors will\noccur with a similar frequency no matter how small our grid is. Unless error probabil-\nity becomes infinitely small, reducing the frequency of that error just serves to make\nlife harder for our testers.\n\nimation. We propose vector fractions as one way of achieving this.\n\nIntersection of 2D Lines\n\nConsider two infinite lines in two dimensions, represented with start points and axes\nS, A, and S, A). As long as the lines are not parallel, they will intersect, allowing us to\nrepresent the intersection I as a fractional distance along the axis of one of the lines\n(see Figure 2.2.6 and Equation 2.2.1).\n\nFIGURE 2.2.6 Representing the point of intersection as a vector fraction.\n\nnA\nI=S,+—+ 2.2.1\nit (2.2.1)\nThe numerator and denominator elements n and d are determined by taking dot\nproducts with N,, a vector normal to the axis of the second line (Equation 2.2.2 and\nEquation 2.2.3). These values will be proportional to the lengths of the arrows shown\nin Figure 2.2.6.",
      "content_length": 1143,
      "extraction_method": "OCR"
    },
    {
      "page_number": 164,
      "chapter": null,
      "content": "2.2 Using Vector Fractions for Exact Geometry 165\n\nn=(S, -S,)-N, (2.2.2)\n\n1=A,-N, (2.2.3)\n\nintersection of a 3D Line with a Plane\n\nThe method extends easily to the intersection of a three-dimensional line with a\nplane. In this case, we can take dot products with the plane normal to obtain a frac-\ntional distance along the three-dimensional line for the intersection.\n\nWorking with Vector Fractions _\n\nWe can apply the same kinds of techniques for working with vector fractions that we\nuse with normal fractions. Most importantly, when we work with vector fractions,\ncross-multiplication enables us to perform certain operations without explicit divi-\nsion. By eliminating division, we can perform the required geometric operations\nwithout approximation. Operations involving addition, subtraction, and multiplica-\ntion of integer values will yield integer values.\n\nTesting Side of Line for an Intersection\n\n‘To determine if a point P is on the right of an infinite line defined by start S and axis\nA, we can test for the inequality in Equation 2.2.4. This equation assumes that the\ndirection of increasing x is to the right of the direction of increasing y:\n\nJ\n\n(2.2.4)\n\nx\n\nTo apply this to a point represented as a vector fraction, we simply substitute a\nfractional representation for P (Equation 2.2.5) and then multiply everything by 4, to\navoid division, giving us the inequality in Equation 2.2.6. This gives us one way to\nimplement the traversal we require through path-finding regions.\n\np=B+L (2.2.5)\nd\nP\n\n(B,4, +C, -8,4,)A, < (Bd, + C, -S,d,)A, \" (2.2.6)\n\nGeneralizing to Other Operations\n\nIt is easy to extend this approach to more-general operations on vector fractions.\nTo perform comparisons between P and a second point Q (also represented as a vec-\ntor fraction, as shown in Equation 2.2.7), we transform the points to a common\ndenominator by multiplying both points by 4,d,. Addition of P and Q yields a vector\nfraction result, as shown in Equation 2.2.8.",
      "content_length": 1972,
      "extraction_method": "OCR"
    },
    {
      "page_number": 165,
      "chapter": null,
      "content": "166 Section 2 Mathematics\n\nE\nQ =D+— 2.2.\n; (2.2.7)\n\nq\nad Ct+daFE\nP+Q =B+D+—4+_*-\n44,\n\nAnother Way To Traverse—Using Order\nof Intersection\n\nAnother way to solve our traversal problem is by comparing the distances for two\nintersections along a common axis. Figure 2.2.7 depicts the traversal problem. We\nneed to determine the side of our traversal line (S, A3) for an intersection of region\nboundaries (S, A, and S, A,). If we know that the traversal line crosses the boundary\nline S, A, from right to left, then we can compare fractional distances for intersections\nalong the axis A, The inequality in Equation 2.2.9 is true when the boundary vertex\nis to the right of traversal.\n\na\n\nd’\n\nFIGURE 2.2.7 Determining order of intersection.\n\nnd’ >n'd (2.2.9)",
      "content_length": 752,
      "extraction_method": "OCR"
    },
    {
      "page_number": 166,
      "chapter": null,
      "content": "2.2 Using Vector Fractions for Exact Geometry 167\n\nBy using integer coordinates and eliminating division, we can perform geometric\noperations without approximation and without requiring any extra precision. How-\never, we have to think carefully about number ranges to avoid the possibility of over-\nflow. The ranges that must be supported will depend on the coordinate range allowed\nfor our geometry, together with the exact operations performed on this geometry.\n\nDeriving Ranges\nLet us assume that the coordinates of all points in our geometry are in the range [0, 7].\nLet us also assume that axis vectors are always formed by subtracting a start point\nfrom an end point.\n\nThe range of vectors formed by subtraction of points will be from [-r, 7]. Both\nthe numerator and denominator in Equation 2.2.1 were determined by dot products\nof these vectors and therefore will have a range [—2r?, 2r?] for the two-dimensional\ncase. For the three-dimensional case, the range is [-3r?, 3r7] for dot products of\nthree-dimensional vectors. Extending the two-dimensional analysis to Equation 2.2.6\ngives us a range [—6r', 6r'] for each side of the inequality. For Equation 2.2.9, we get\n[-874, 874].\n\nFitting the Ranges into Integer Data Types\n\nSay we allow 128 bits to represent —874 to 874. This gives us Equation 2.2.10 for r.\nSolving and rounding to integer coordinates yields a value for r.\n\n8rt = 2'77 -] (2.2.10)\n\nr= DI] (2.2.11)\n\nPoints and vectors can be stored in 32 bits, the results of dot products in 64 bits,\nand products of dot products in 128 bits. For different constraints or if different com-\nputations are required, a different set of ranges and, therefore, a different set of data\ntypes might need to be chosen.\n\nManaging Range Constraints\n\nDefining different data types for different stages of computation can help with man-\naging the different ranges. For example, points and vectors could be implemented as\ndifferent types, as well as dot products and multiplied dot products. With this method,\nwe can use the compiler to check that the correct types are used for a computation.\n\nIt is a good idea to include range checking in the debug build. The impact on per-\nformance can be limited by only checking ranges when data types are constructed\nfrom other data types that do not have a defined range. We would then make sure to\navoid this kind of construction as often as possible.\n\nAt compile time, it might not be possible to know what ranges will be required\nfor complex operations. In this case, or simply as an alternative to working out ranges",
      "content_length": 2560,
      "extraction_method": "OCR"
    },
    {
      "page_number": 167,
      "chapter": null,
      "content": "168 Section 2 Mathematics\n\nseamanrctuscnttn atten SNE MARRIAGE eA SAE ASE OSE 8 an NRE SE IY HEIR AN POE OR AEA ETS\n\nin advance, it is possible to use an integer class that dynamically allocates storage as\nrequired to represent arbitrarily sized integers. There are a number of packages avail-\nable that can do this. See, for example, [GMP02] and [Haible02].\n\nImplementation Details\n\nSt CA BSS RE BIRD IRS ERO OS ETE ELE SIERO CELLET BOLE NEL ELE\n\nWorking with Big Integers\n\nFor platforms with a register size of 64 bits, working with big integers need not be a\nproblem. For these platforms, multiplication of two 64-bit values will be performed\nin the silicon and yield a 128-bit result across two registers. Addition, subtraction,\nand comparison of 128-bit register pairs is also not a problem.\n\nFor platforms with a 32-bit register size, multiplication of 64-bit integers is a lit-\ntle more expensive; but if done correctly in assembly, it might not be too costly. Be\ncareful with the standard 64-bit extensions provided by your compiler, as the code\ngenerated by these can be slower than you would expect. If multiplication of 64-bit\nintegers is too costly, then an alternative is to reduce the ranges so that only 32-bit\nmultiplication is required.\n\nWhich Kind of Traversal Should We Use?\n\nWe have a choice between Equation 2.2.6 and Equation 2.2.9 for implementing our\ntraversal. Let’s consider these equations in terms of the operations required for imple-\nmenting them.\n\nFor Equation 2.2.6, we can precalculate Bd, and store the result together with\nour fractional representation. Now, testing the inequality only requires four multi-\nplies. However, our intermediate results are obtained by multiplication of a dot prod-\nuct and a point coordinate. So given r as derived in Equation 2.2.11, two of these\nmultiplies must be performed with 128-bit sources. Ideally, we need to avoid multi-\nplying numbers this large because of the resulting performance hit.\n\nOne solution is to reduce the range permitted so that the two final multiplica-\ntions for Equation 2.2.6 can be performed with 64-bit sources. This is the fastest\noption. Alternatively, we can use Equation 2.2.9 with six multiplies that all can be\nperformed with a 64-bit source.\n\nOptimizations\n\nThe ranges derived above are theoretical limits that will rarely be reached in practice.\nIf you are a gambler, you can use fewer bits than are theoretically required for inter-\nmediate values, and perhaps overflow will never occur. Another alternative is to check\nfor overflow and use a separate code path when the overflow occurs. Branch predic-\ntion on the target processor can help improve code performance in this situation. The\nvast majority of the time there will be no overflow, so we need to set up our code so\nthat the branch is predicted correctly for this case.",
      "content_length": 2834,
      "extraction_method": "OCR"
    },
    {
      "page_number": 168,
      "chapter": null,
      "content": "2.2 Using Vector Fractions for Exact Geometry 169\n\nVector fractions based on a dynamic integer class can result in some very large\nnumbers and a very slow program. In this case, it might be worthwhile to reduce the\nsize of the numbers involved. We can do this by finding the greatest common denom-\ninator of the numerator and denominator of the fraction. Then, we divide both\nnumerator and denominator by this value.\n\nA simpler optimization is to detect when an intersection falls exactly on the coor-\ndinate grid and proceed as if it were a normal point. This is only worthwhile if the\nsavings offset the cost of the test.\n\nConclusion\n\nRIROROROBN\n\nERRERURERIE RR eH RTI\n\nThe mathematical basis for vector fractions is not complicated, but they provide an\nelegant solution for dealing with points at intersections without introducing the error\nof approximation. The elimination of artifacts from approximation removes a major\nheadache when implementing geometric algorithms.\n\nIt’s important to avoid overflow when using vector fractions. The compiler can\nhelp us with this if we use different types for different stages of computation. If we\nknow what geometric queries we need, we can abstract the notion of a vector fraction\nas either a class or as a set of functions.\n\nThe cost of the change can be as little as a few extra multiplies and some extra bits\nto manipulate. Adding these extra calculations means that you'll no longer need\nspecial-case checks for the results of an approximation.\n\nReferences\n\nsree NANRRRTERR RRR ARRRRRARORET\n\n[GMP02] GMP, “GMP,” available oneline at http://www.swox.com/gmp/, January\n2002.\n\n[Haible02] Haible, Bruno, “CLN - Class Library for Numbers,” available online at\nhetp://www.ginac.de/CLN/, January 2002.\n\n[Young01] Young, Thomas, “Optimizing Points-of-Visibility Pathfinding,” Game\nProgramming Gems 2, Charles River Media, Inc., 2001.\n\nHR en RR aE LE RN RR ORR ROR?",
      "content_length": 1906,
      "extraction_method": "OCR"
    },
    {
      "page_number": 169,
      "chapter": null,
      "content": "2.3\n\n170\n\nuring Error\n\nMore Approximations to\nTrigonometric Functions\n\nRobin Green,\nSony Computer Entertainment America\nrobin_green@playstation.sony.com\n\nhe art and science of writing mathematical libraries has been consistent over the\n\npast 10 years. Many computer science reference books that were written in\nthe 1970s and 1980s are still in common use, and, as mathematics is the universal\ndenominator, these books are usually considered as the last word on the subject. In\nthe meantime, hardware has evolved, instruction pipelines have grown in length,\nmemory accesses are slower than ever, multiplies and square-root units are cheaper\nthan ever before, and more specialized hardware is using single-precision floats. It is\ntime to go back to basics and review implementations of the mathematical functions\nthat we rely on every day. With a bit of training and insight, we can optimize them for\nour specific game-related purposes, sometimes even outperforming general-purpose\nhardware implementations.\n\nBefore we look at implementing functions, we need a standard set of tools for mea-\nsuring how good our implementation is. The obvious way to measure error is to sub-\ntract our approximation from a high-accuracy version of the same function (usually\nimplemented as a slow and cumbersome, infinite series calculation). This is called the\nabsolute error metric:\n\nerror», = Fecal - Spree (2.3.1)\n\nThis is a good measure of accuracy, but it tells us nothing about the importance of\nany error. An error of 3 is acceptable if the function should return 38,000, but an\nerror of 3 would be catastrophic if the function should return 0.008. We will also\nneed to graph the relative error.\n\nF coprox\n\nerror, =1-—*= when fia * 9 (2.3.2)\n\nactual",
      "content_length": 1738,
      "extraction_method": "OCR"
    },
    {
      "page_number": 170,
      "chapter": null,
      "content": "2.3 More Approximations to Trigonometric Functions 171\n\nWhen reading relative error graphs, an error of zero means there is no error; the\napproximation is exact. With functions like sin() and cos(), where the range is\n[-1.0, 1.0]. the relative error is not that interesting. But functions like tan() have a\nwider range, and relative error will be an important metric of success.\n\nSine and Cosine\n\nFor most of the examples, implementations\nconsidered, but many of the polynomial techniques, with a little tweaking, are applic-\nable to other functions, such as exponent, logarithm, and arctangent.\n\nResonant Filter\n\nWhen someone asks you what is the fastest way to calculate the sine and cosine of an\nangle, tell them you can do it in two instructions. The method, called a resonant filter,\nrelies on having previous results of an angle calculation and assumes that you are tak-\ning regular steps through the series (see Figure 2.3.1).\n\nint N= 64;\nfloat PI = 3.14159265;\n\nfloat a = 2.0f*sin(PI*N);\nfloat c = 1.0f;\nfloat s = 0.0f;\n\nfor(i=0; i<N; ++i) {\nOutput_sine =\noutput_cosine =\nc =c — s*a;\nSs =s + C*a;\n\nS;\nCc;\n\nFIGURE 2.3.1 Resonant filter sine and cosine—eight iterations over 37/2.",
      "content_length": 1186,
      "extraction_method": "OCR"
    },
    {
      "page_number": 171,
      "chapter": null,
      "content": "172\n\nSection 2 Mathematics\n\nNote that the value of ¢, used to calculate s, is the newly updated version from the\nprevious line. This formula is also readily converted into a fixed-point version, where\nthe multiplication by a can be modeled as a shift (e.g., a multiply by 1/8 converts to a\nshift right by three places).\n\nIf you plan to use this technique to fill look-up tables for later use, you must pay\nclose attention to a (the step size) and to the initial values of c and s. The technique\nrelies on the previous value feeding back into the system, so the initial values of s and\nc affect the final amplitude of the waves (e.g., starting with s = 0.5 and c = 0.5 gives a\npeak value of 0.7). As fast as this technique is for generating sine wave-like signals,\nyou cannot rely on samples at fractions of a cycle returning accurate values. For exam-\nple, say we were looking to take seven steps around a quarter of a circle:\n\nN\na\n\n73\n0.5*sin(PI*N) ;\n\nThe values for iterations seven and eight (counting from zero) are listed in Table 2.3.1.\n\nTable 2.3.1 Testing the Accuracy of the Resonant Filter\n\nIteration Sine Cosine\n7 1.004717676 0.158172209\n8 0.9917460469 -0.0597931103\n27 1.000000000 -0.000000002\n\nThe end points of this function miss the correct values of 1.0 and 0.0 by quite\nlarge amounts (see Table 2.3.1 and Figure 2.3.2). If, however, we extend the table to\ngenerate the whole cycle using 27 samples, we find that the final values for s and ¢ are\ncorrect to nine decimal places. Adding more iterations will reduce this error, but won't\nmake it disappear. Clearly, this approximation is useful for generating long sequences\nof sine-like waves, especially over entire cycles; but it is not well suited to accurate,\nsmall-angle work.\n\nGoertzels Algorithm\n\nA more accurate approach to the same problem is Goertzels algorithm, which uses and\nupdates the two previous values (i.e., it’s a second order filter). With it, we can calculate\na series of sine and cosine values in the series x, = sin(a + *b) for integer values of n:\n\nfloat cb = 2 * cos(b);\nfloat s2 = sin(a + b);\nfloat s1 = sin({a + 2*b);\nfloat c2 = cos(a + b);\nfloat c1 = cos({a + 2*b);",
      "content_length": 2158,
      "extraction_method": "OCR"
    },
    {
      "page_number": 172,
      "chapter": null,
      "content": "2,3 More Approximations to Trigonometric Functions 173\n\n°\n©\n\n9\nfon)\n\n°\nip\n\n2\nho\n\n0\n\n1 2 3 4 5 6 7\n\nFIGURE 2.3.2 Resonant filter quarter-circle test, seven iterations over 1/2.\n\nfloat s,c;\n\nfor(i=0; i<N; ++i) {\ns =cb * si — s2;\nc = cb * cl — C2;\n\ns2 = $1;\nc2 = cl;\n$1 = §;\ncl =c;\noutput_sine = §$;\noutput_cosine = c;\n\n}\n\nThe technique is only slightly more expensive to run than the previous method,\nbut it has greater setup costs. However, if the setup can be done at compile time, the\nalgorithm is still very efficient (see Figure 2.3.3).\n\nThere are some pitfalls associated with this algorithm, as it is a second-order filter.\nBecause the values of s and c are constructed from the two previous samples, the algo-\nrithm actually outputs a result three iterations later than you might expect. To com-\npensate for this, we need to initialize the sequence carefully, subtracting three steps\nfrom the initial value of a:\n\n// step = N steps over 2*PI radians\nfloat b = 2.0f*PI/N;\n\n// minus three steps from origin\nfloat a = 0.0f -— 3.0f * b;",
      "content_length": 1038,
      "extraction_method": "OCR"
    },
    {
      "page_number": 173,
      "chapter": null,
      "content": "174\n\nSection 2 Mathematics\n\nFIGURE 2.3.3 Goertzels algorithm: sine and cosine, eight iterations over 3m/2.\n\nAdding in these alterations and putting Goertzels to the quarter-circle test, we find that it\npasses the test well, producing more-accurate results than the resonant filter for fractions of\ncomplete cycles (see Figure 2.3.4).\n\no\nih\n\n1 2 3 4 5 6 7\n\nFIGURE 2.3.4 Goertzels quarter-circle test, seven iterations over 1/2.",
      "content_length": 426,
      "extraction_method": "OCR"
    },
    {
      "page_number": 174,
      "chapter": null,
      "content": "2.3 More Approximations to Trigonometric Functions a 175\n\nTable-Based Solutions\n\nAs clock speeds rise and memory-access latencies become longer and longer, sine and\ncosine tables fall out of favor and are no longer the fastest method in all situations.\nNew architectures that provide vector units with closely coupled, fast RAM can still\ngive single-cycle access time for small tables, so the technique must not be discounted\nand will be with us for some time to come.\n\nThe idea is to precalculate a table of samples from a function at regular intervals\nand use the input value to the function to hash into the table, look up the two closest\nvalues and linearly interpolate between them (see Figure 2.3.5). In effect, we are trad-\ning off storage space against speed.\n\n0.5\n\nat\n\nFIGURE 2.3.5 Zable-based sine(16 samples) with and without linear interpolation.\n\nIn order to speed linear interpolation (erp) between samples, we can precalculate\nthe difference between adjacent samples, saving a subtract per look-up, especially on\nSIMD machines where a look-up usually loads a four-vector of floats at a time.\n\nsin(x) ~ table[i] + A * (cable +1]- table|\n= table{;] + A * gradient[Z] (2.3.3)\n\nPrecalculating these differences turns the lerp operation into a single multiply-\nadd.\n\nUsing a table poses the question: How many samples do we need to get N digits\nof accuracy? The table-based sine with 16 samples is shown in Figure 2.3.5, and the\nabsolute error graph is shown in Figure 2.3.6.\n\nThe largest error (or maximal error) occurs where the curvature of the function is\nhighest—in fact, when two samples straddle the top of the curve. The size of the max-\nimal error where the step size is Ax = x, , , — x,, can be shown to be:",
      "content_length": 1727,
      "extraction_method": "OCR"
    },
    {
      "page_number": 175,
      "chapter": null,
      "content": "176\n\nSection 2 Mathematics\n\n0.015\n0.01\n0.005\n0\n-0.005\n-0.01\n\n-0.015\n\nFIGURE 2.3.6 Absolute error of 16 sample, linearly interpolated sine table.\n\nE=1- cof | (2.3.4)\n\nSo, for a table of 16 samples covering one whole cycle, the maximum relative\nerror will be 1 — cos(m/16) = 0.0192147, giving us just under two decimal places of\naccuracy in the worst case. Turning the problem around, given a known accuracy,\nhow many entries will we need in the table? We just reverse the inequality. For exam-\nple, to approximate sin(x) to 1% error we only need 23 entries:\n\nE=1%\n1-cos(z / N) <1%\ncos(z / N) > 0.99\nN> n/arccos(0.99)\n= 22.19 (2.3.5)\n\nUsing a process called range reduction, we can reconstruct the whole cycle from\njust 45° of samples, meaning that we only need a table of 23/8 = 3 entries. Equation\n2.3.4 will give you the hard upper bound on the error, an error that almost never\noccurs. For a slightly lower bound, you can use a small-angle approximation to the\narccos(), as 1/N should hopefully be a very small angle, giving you a bound of:\n\nN=— (2.3.6)\n\n\\2E",
      "content_length": 1060,
      "extraction_method": "OCR"
    },
    {
      "page_number": 176,
      "chapter": null,
      "content": "2.3 More Approximations to Trigonometric Functions 177\n\nApplying Equation 2.3.6 to various error factors gives us a feel for situations\nwhere tables would be well used and where more-accurate methods must be used. See\nTable 2.3.2 for some example values.\n\nTable 2.3.2 Size of Table Needed To Approximate Sin(X) to a Given Level of Accuracy\n\nE 360° Range 45° Range\n1% accurate 0.01 23 3\n0.1% accurate 0.001 71 9\n0.01% accurate 0.0001 223 28\n1.0° 0.01745 17 3\n0.1° 0.001745 54 7\n8-bit int. 2? 26 4\n16-bit int. 215 403 51\n24-bit float 105 703 88\n32-bit float 107 7025 880\n64-bit float 10°17 ~infinite 8.7e+8\n\nRange Reduction and Reconstruction\n\nThe sine and cosine functions have an infinite domain. Every input value has a corre-\nsponding output value in the range [0, 1] and the pattern repeats every 27 units. To\nproperly implement the sine function, we need to take any input angle and find out\nwhere inside the [0, 27] range it maps to. This process, for sine and cosine at least, is\ncalled additive range reduction, and is shown in Figure 2.3.7.\n\nTo do this, we need to find out how many times we need to subtract 27 from the\ncurrent value to reduce it to the target range. We divide the input value by 27, trun-\ncate the result toward zero (i-e., convert it to an integer), and subtract that many\ncopies of 27 from it.\n\nVVVN eVV VV VV VV VV VV\ni. =) é 2 4 6\n% %\n\n% 75 % .\n& ’ & é\n% * ?\nso” 1 Sa\n\nFIGURE 2.3.7 Additive range reduction where C=20/16.",
      "content_length": 1452,
      "extraction_method": "OCR"
    },
    {
      "page_number": 177,
      "chapter": null,
      "content": "178 Section 2 Mathematics\n\nLRA I NR A NSE REREAD ASA RE BH SRS MO ESIC Ca A EH AIC 2 et Ee EN INA\n\nconst float C = 2*PI;\nconst float invC = 1/C;\n\nint k = (int) (x*invC);\ny = x -— (float)k * C;\n\nIn this example, the value of & only tells us how many full cycles we need to sub-\ntract, but if we were to range-reduce using fractions of a cycle then the lower digits of\nk would tell us which ‘quadrant’ the remainder belongs to. Why is this useful? Because\nof these well known relationships:\n\nsin(A + B) = sin(A) cos(B) + cos(A) sin(B)\ncos(A + B) = cos(A) cos(B) + sin(A) sin(B) (2.3.7)\n\nIf we range-reduce to y €[0..1/2], that means we have four segments to our cycle,\nand k mod 4 will tell us which segment to use. If we multiply Equation 2.3.7 through,\nwe find that sin(B) and cos(B) collapse into the constants zero and one, and we get\nfour special cases:\n\nsin( y +0*2/ 2) = sin(y)\nsin( y +1*2/ 2) = cos(y)\nsin(y +2* n | 2) = —cos(y)\n\nsin(y +3*a2/ 2) = —sin(y) (2.3.8)\nleading to code like:\n\nfloat table _sin(float x) {\nconst float CONVERT = (2.0f * TABLE_SIZE) / PI;\nconst float PI_OVER_TWO = PI/2.0f;\nconst float TWO_OVER_PI = 2.0f/PI;\n\nint k = int(x * TWO_OVER_PI);\n\nfloat y = x — float(k)*PI_OVER_TWO;\n\nfloat index = y * CONVERT;\n\nswitch(k&3) {\ncase 0: return sin_table(index);\ncase 1: return sin_table(TABLE_SIZE-index) ;\ncase 2: return -sin_table(TABLE_SIZE-index) ;\ndefault: return -sin_table(index);\n\n}\n\nreturn(0) ;\n\n}\n\nWhy stop at just four quadrants? To add more quadrants, we need to reconstruct\nthe final result by evaluating Equation 2.3.7 more carefully, using either in-lined con-\nstants or a table of values:",
      "content_length": 1625,
      "extraction_method": "OCR"
    },
    {
      "page_number": 178,
      "chapter": null,
      "content": "2.3 More Approximations to Trigonometric Functions 179\n\ns = sin_table(y);\nc = cos_table(y);\nswitch(k&15) {\n\ncase 0: return s;\ncase 1: return s * 0.923880f + c * 0.382685f;\ncase 2: return s * 0.707105f + c * 0.707105f;\ncase 3: return s * 0.382685f + c * 0.923880f;\ncase 4: return c;\ncase 5: return s * -0.382685f + c * 0.923880f;\n\n}\n\nNote how we have had to approximate both the sine and cosine in order to pro-\nduce just the sine as a result. For very little extra effort, we can easily reconstruct the\ncosine at the same time, and the function that returns them both for an input angle,\ntraditionally present in FORTRAN mathematical libraries, is usually called sincos().\n\nYou will find that most libraries use the range reduction, approximation, and recon-\nstruction phases in the design of their mathematical functions, and that this program-\nming pattern turns up over and over again. In the next section, we will generate an\noptimized polynomial that replaces the table look-up and lerp.\n\nPolynomial Approximations\n\nA person’s first introduction to approximating functions usually comes from learning\nabout the 7aylor Series in high school. Using a series of differentials, we can show that\nthe transcendental functions break down into an infinite series of expressions—for\nexample:\n\n3 5 17 V9\nsin(x) = x — ~ 4% _~% 4* _ (2.3.9)\n3 OSE OD\nIf we had an infinite amount of time and infinite storage, then this would be the\nlast word on the subject. As we have a very finite amount of time and even less stor-\nage, let’s start by truncating the series at the ninth power and multiply through to five\nsignificant digits:\n13,15 1 wy) 9\n\nx-- —_\n\n-— x +——*«\n6 120 5040 362880\n\nX\n\nsin(x)\n\nx — 0.16667x + 0.0083333x° — 0.00019841x” + 0.0000027557x°\n(2.3.10)\nThis is one of the classic infinite series—it exhibits alternating signs and drasti-\ncally reducing factors (1/x! plummets toward zero), two signals that this series is going\nto converge toward the correct value fairly fast. The problems lie in the approxima-\ntion error. If you graph the absolute error of this function (shown in Figure 2.3.8),\nyou find that it is very accurate for small angles around the origin of the Taylor expan-\nsion, but the error increases almost exponentially away from x = 0. Truncating the",
      "content_length": 2271,
      "extraction_method": "OCR"
    },
    {
      "page_number": 179,
      "chapter": null,
      "content": "180 Section 2 Mathematics\n\nFIGURE 2.3.8 Absolute error of Taylor series over |-1t, 71].\n\nseries later will decrease the error; however, it is more costly, opens you up to more\ndanger of numerical error, and each additional term is another load/multiply-\naccumulate in your program. We need good accuracy across the whole range, and we\nneed it using as few terms as possible.\n\nHow about reducing the input range? If you reduce the range of the sine function\nthat we're trying to approximate, then, yes, we reduce the error because there’s less to\ngo wrong! Along with reducing the range, we could also Taylor-expand around the\ncenter of the range we want to approximate. This will halve the overall error, but at\nthe cost of doubling the number of constants we need—now we need to calculate\nevery power from zero to nine, not just every second one. We can do better than to\nuse a Taylor series as a technique for generating fast polynomial approximations,\n\nMinimax Polynomials\n\nThe Taylor expansion has a poor maximal error. If only we could find a way to take\nsome of this error and spread it out across the whole range. In fact, thanks to a theory\nby Chebychey, it can be shown that every approximation has one special polynomial\nthat has an equal amount of error everywhere—where we have ‘minimized the maxi-\nmal error,’ and it’s called the minimax polynomial. \\ts characteristics are:\n\n* Fora power N approximation, the error curve will change sign NV + 1 times.\n° The error curve will approach the maximal error V+ 2 times.\n\nThe method used to find these polynomial approximations is called the Remez\nExchange Algorithm, and it works by generating a set of linear equations. For example:\n\nsin(x) — a + bx, + cx? = 0 forasetofvalues x, € [2..2] (2.3.11)\n\nThese are solved to find the required coefficients a, 6, and c the maximal error is\nfound and fed back into x,. This highly technical optimization problem is sensitive to",
      "content_length": 1928,
      "extraction_method": "OCR"
    },
    {
      "page_number": 180,
      "chapter": null,
      "content": "2.3 More Approximations to Trigonometric Functions 181\n\nfloating-point accuracy and is difficult to program, so we call on the professionals to\ndo it for us. Numerical math packages, like Mathematica and Maple, have the neces-\nsary environments with che huge number representations and numerical tools needed\nto give accurate answers.\n\nThe arguments needed to calculate a minimax polynomial are:\n\n¢ the function to be approximated,\n\n¢ the range over which the approximation is to be done,\n\n¢ the required order of our approximation, and\n\n* a weighting function to bias the approximation into minimizing absolute (weight\n1.0) or the relative error.\n\nLet’s find a seventh-order polynomial approximation to sin(x) over the range [0,\n7/4], optimized to minimize relative error. We start by looking at the Taylor expansion of\nsin(x) about x = 0, just to get a feel for what the polynomial should look like. The result\nshows us that the series has a leading coefficient of 1.0 and uses only the odd powers:\n\nsin(x) = x — 0.166666667x°+0.00833333333x° — 0.000198412698x’ (2.3.12)\n\nA raw call to minimax will, by default, use all coefficients of all available powers\nto minimize the error, leading to some very small, odd-looking coefficients and many\nmore terms than necessary. We will transform the problem into one of finding the\npolynomial in the expression:\n\nsin(x) = x + x° P(x’) (2.3.13)\n\nFirst, we form the minimax inequality, expressing our desire to minimize the rel/-\native error of our polynomial P:\n\nsin(x) — x — x° P(x’)\n\n: < error (2.3.14)\nsin(x)\nDivide through by x?:\nsin(x) _ 4+ — P(x?)\nNS oppor (2.3.15)\nsin(x)\n~\n\nWe want the result in terms of every second power, so we substitute y = x7:\n\n51 -+- ry)\nae Pe (2.3.16)",
      "content_length": 1726,
      "extraction_method": "OCR"
    },
    {
      "page_number": 181,
      "chapter": null,
      "content": "182\n\nSection 2 Mathematics\n\nSo, we have reduced our problem to finding a minimax polynomial approxima-\n\ntion to:\nsin vy 1\nP(y) = WV -= (2.3.17)\ny J\nwith the weight function:\n3/2 .\nW(y) = (2.3.18)\n\nJ\n\nIn order to evaluate the function correctly in the arbitrary, precision environment\nof Mathematica or Maple, it is (ironically) necessary to expand the first expression\ninto a Taylor series of sufficient order to exceed our desired accuracy in order to pre-\nvent the specially written, arbitrary accuracy sine function from being evaluated:\n2 3 4 5\n\n6 120 5040 362880 39916800 6227020800\n\nOur last task is to transform the range we wish to try and approximate. As we\nhave substituted y = x”, so our range [0, 7/4] is transformed to [0, 27/16]. Running\nthese through the minimax function, looking for a second-order result gives us:\n\nPly) = — 0166666546 + 0.00833216076y — 0.000195152832y? (2.3.20)\nResubstituting this result back into Equation 2.3.12 gives us the final result:\nsin(x) = x — 0.166666546x* + 0.00833216076x° — 0.000195152832x” (2.3.21)\n\nIn order to reconstruct these coefficients as single precision floats, we need only\nrecord the first nine significant digits (see proof below), giving us Figure 2.3.9, the\nabsolute and relative error curves over our range with a maximum absolute error of\n2.59e-9 at x = 0.785.\n\nHere is a loose proof. In single precision, numbers in the range [10%, 2!°] = [1000,\n1024] have 10 bits to the right of the decimal and 14 bits to the right. There are\ntherefore (2!° — 10%)2!4 = 393,216 representable values. If we use a decimal notation\nwith eight digits, we can represent (2!°— 107)108= 240,000 values. We therefore need\nnine decimal digits to be able to reconstruct the correct binary number. Similar con-\nstructions along the number line show a need for between six and nine digits. For\n\nmore, see [Goldberg91].\n\nOptimizing for Fioating-Point\n\nThe same technique we used to remove a coefficient can be used to force numbers to\nmachine-representable values. Remember that numbers like 1/10 are not precisely\nrepresentable using a finite number of binary digits. We can adapt the technique\nabove to force coefficients to be our choice of machine-representable floats. Remem-",
      "content_length": 2222,
      "extraction_method": "OCR"
    },
    {
      "page_number": 182,
      "chapter": null,
      "content": "2.3 More Approximations to Trigonometric Functions 183\n\n3e-09\n2e-09\n1e-09\n\n-1e-09\n-2e-09\n\n-3e-09\n\nFIGURE 2.3.9 Absolute and relative error of approximation over (0, 1/4].\n\nbering that all floating-point values are rational numbers, we can take the second\ncoefficient and force it to fit in a single precision floating-point number:\n\n2796201 _\n~ 24 ~\n\nk= —0.16666656732559204101562500000 (2.3.22)\n\nNow that we have our constant value, let’s optimize our polynomial to incorpo-\nrate it. Start by defining the form of polynomial we want to end up with:\nsin(x) = x + kx? + x° P(x’) (2.3.23)\nNow we form the minimax inequality:\nsin(x) — x — kx? — k° P(x’)\nsin(x)\n\n< error (2.3.24)\n\nwhich, after dividing by &, substituting y = x’, and solving for P(y), shows us that we\nhave to calculate the minimax of:\n\nP(y) = cD - y + y (2.3.25)\nwith weight function\n5/2\nW(y) = (2.3.26)\n\nJ\nSolving this and resubstituting gives us a seventh-degree optimized polynomial\n\nover the range [0, 7/4] with a maximal error of 3.39e-8 at x = 0.557, but with better\nsingle precision floating-point accuracy:",
      "content_length": 1078,
      "extraction_method": "OCR"
    },
    {
      "page_number": 183,
      "chapter": null,
      "content": "184 Section 2 Mathematics\n\n7 — OT 2 + 0.00833220803x? — 0.000195168955x” (2.3.27)\n\nsin(x) = x\n\nThe absolute and relative error of float-optimized approximation over [0, 1/4] are\nshown in Figure 2.3.10.\n\n6e-09\n\n4e-09 f\n\n2e-09 | /\n\nFIGURE 2.3.10 Absolute and relative error of float-optimized approximation over\n[0, 7/4].\n\nA Note on Convergence\n\nTAL RNAI R A SRN\n\npra ie JRA MAREE ARNON CANE RATI RIP\n\nHow do we choose the degree of polynomial that we need to approximate a function to\na given accuracy? We can easily calculate how many bits of accuracy an approximation\nprovides. First, we calculate the maximum error within the range (this will be a small\nvalue, typically something like 5e-4) and take the base-2 logarithm of this value using\nIn(error)/In(2), giving us a negative number that tells us how many bits we will need\nafter the decimal point to be able to represent this value. Generating a table of this value\nfor several important functions shows us some interesting results (see Table 2.2.3).\n\nTable 2.3.3 Number of Significant Bits of Accuracy Versus Degree of Minimax\nPolynomial Approximating the Range [0, 1]\n\n2 3 4 5 6 7 8\n& 6.8 10.8 15.1 19.8 24.6 29.6 34.7\nsin(x) 7.8 12.7 16.1 21.6 25.5 31.3 35.7\nIn(1 + x) 8.2 11.1 14.0 16.8 19.6 22.3 25.0\narctan(x) 8.7 9.8 13.2 15.5 17.2 21.2 22.3\ntan(x) 4.8 6.9 8.9 10.9 12.9 14.9 16.9\narcsin(x) 3.4 4.0 44 4,7 4.9 5.1 5.3\n\nVx 3.9 44 4.8 5.2 5.4 5.6 5.8",
      "content_length": 1412,
      "extraction_method": "OCR"
    },
    {
      "page_number": 184,
      "chapter": null,
      "content": "2. 3 More ‘Approximations to  Trigonometric Functions 185\n\nFirstly, it shows how well we can use polynomials to approximate exp(x) and\nsin(x), as each additional power gives us pretty much four bits of accuracy. For a 24-\nbit single precision floating-point value, we will only need a sixth- or seventh-power\napproximation. The table also shows how badly Vx is approximated by polynomials;\neach additional power only adds half a bit of accuracy—this is why there are no quick\nand easy approximations to the square root; we must use range reduction with New-\ntons algorithm and good initial guesses to calculate it. Another surprise is tan(x).\nAfter all, it’s only sin(x)/cos(x) isn’t it? Rational functions like this are not well approx-\nimated by ordinary polynomials and require a different toolkit of techniques.\n\nCon lusion\n\ncemennnnnnuiimaraauamnnnnnunne: ar eo\n\nRUAN AS ARRAS PINS RESCH ROR HS RRNA NORE\n\nThe task of writing low-accuracy mathematical functions using high-accuracy tech-\nniques has not been covered in any depth in the literature. But with the widespread\nuse of programmable DSPs, vector units, high-speed yet limited hardware, and more-\nesoteric shading models, the need to write your own mathematical functions is\nincreasingly important.\n\nIntroductions to polynomial approximation always start by saying how accurate\nthey can be, and this obsession with accuracy continues through to extracting the very\nlast bit of accuracy out of every floating-point number. Why this obsession with accu-\nracy? Because if you can build high-accuracy polynomials with less coefficients, you\ncan also build tiny, low-accuracy approximations using the same techniques. The lev-\nels of accuracy you can obtain with just two constants as well as the hugely reduced\nrange can be amazing. Hopefully, this gem has given you the confidence to grab a\nmath package and generate some of your own high-speed functions.\n\nReferences\n\nNatta a RRR RONG RR RBRRTS ES GORDA RRR ARORA HORE EEE\n\n(Codye0) Cody & Waite, ‘Software Manual for the Elementary Functions, Prentice\n\nHall, 1980.\n\n[Crenshaw00] Crenshaw, Jack W., Math Toolkit for Real-Time Programming, CMP\nBooks, 2000.\n\n[DSP] The Music DSP Source Code. Archive available online at http://www.smart-\nelectronix.com .\n\n[Goldberg91] Goldberg, Steve, “What Every Computer Scientist Should Know\nAbout Floating Point Arithmetic,” ACM Computing Surveys, Vol. 23, No. 1,\nMarch 1991.\n\n(Hart68] Hart, J. E, Computer Approximations, John Wiley & Sons, 1968.\n\n[Moshier89] Moshier, Stephen L., Methods and Programs for Mathematical Functions,\nPrentice Hall, 1989.\n\n[Muller97] Muller, J. M., Elementary Functions: Algorithms and Implementations,\nBirkhaiiser, 1997.\n\n[Ng92] Ng, K. C., “Argument Reduction for Huge Arguments: Good to the Last\nBit,” SunPro Report, July 1992.\n\n[Story00] Story, S. and Tang, P. T. PR. “New Algorithms for Improved Transcendental\nFunctions on [A-64,” Intel Report, 2000.",
      "content_length": 2932,
      "extraction_method": "OCR"
    },
    {
      "page_number": 185,
      "chapter": null,
      "content": "Section 2 Mathematics\n\n[Tang89] Tang, Ping Tak Peter, “Table Driven Implementation of the Exponential\nFunction in IEEE Floating Point Arithmetic,” ACM Transactions on Mathemat-\ncal Software, Vol. 15, No. 2, June 1989.\n\n[Tang90] Tang, Ping Tak Peter, “Table Driven Implementation of the Logarithm\nFunction in IEEE Floating Point Arithmetic,” ACM Transactions on Mathemati-\ncal Software, Vol. 16, No. 2, December 1990.\n\n[Tang91] Tang, Ping Tak Peter, “Table Lookup Algorithms for Elementary Functions\nand Their Error Analysis,” Proceedings of 10th Symposium on Computer Arith-\nmetic, 1991.\n\n[Upstill90] Upstill, S., The Renderman Companion, Addison Wesley, 1990.",
      "content_length": 660,
      "extraction_method": "OCR"
    },
    {
      "page_number": 186,
      "chapter": null,
      "content": "2.4\n\nQuaternion Compression\n\nMark Zarb-Adami,\n\nMuckyfoot Productions\nmark@muckyfoot.com\n\nNic’ of today’s computer games use large amounts of animation data, and a large\nportion of the memory used for each animation frame is consumed by the rota-\ntion of the bones. Typically, the rotation data is stored as quaternions. In this gem, we\npropose and compare methods for compressing a four-float quaternion into a 32-bit\n\nquantity.\n\nQuaternions\n\nra\n\nA quaternion Q(x, y, z, w) can be used to represent a rotation matrix. If we consider\nall rotation matrices to represent a rotation of angle @ about axis A(X, ¥, Z), then the\nquaternion for the rotation would be:\n\nQ = (sX,sY,sZ,c)\n\nwhere:\n\nsin(@)\nc = cos(9)\n\nIt is important to note that quaternion Q(x, y z, w) and quaternion Q*(-x, -y, -z,\n-w) represent the same rotation. This is because a rotation of @ about axis A is equiv-\nalent to a rotation of -@ about axis —A. Also, note that all the quaternions we consider\nin this gem are normalized. This means that for every quaternion Q(x, y, z, w):\n\n$\n\netypt+e7 tw’ =1\n\nSmallest Three Method\n\nWe can compress a quaternion by quantizing each element of the quaternion down to\na byte. This is very fast, but it is \\so inaccurate. Because the quaternion is normal-\nized, we can improve the accuracy of quantization by eliminating one of the elements.\nGiven three of the elements, we can calculate the fourth one. Now, we have to decide\nwhich element to exclude. If we remove the biggest element, we will have smaller\n\n187",
      "content_length": 1515,
      "extraction_method": "OCR"
    },
    {
      "page_number": 187,
      "chapter": null,
      "content": "188\n\nSection 2 Mathematics\n\nnumbers to store! In fact, none of the three smallest elements of a quaternion can have\n\nan absolute value larger than 1 / V2. To understand why this is the case, consider the\nfollowing. The second largest element of a normalized quaternion will be Largest when\ntwo elements of the quaternion have the same value and the other two are zero, as in\n\nQt», v, 0, 0). If we normalize this quaternion, then v must equal 1/V2.\n\nWe don’t have to store the sign of the largest element, since we can make sure it is\nalways positive. If it isn’t positive already, simply negate the quaternion as described\npreviously.\n\nPolar Methods\n\nSSSR RRA ste RRO samen SSB ORS IETISIIE LN LEE TOTES\n\nSince we can store a direction vector (x, y, 2) using just two angles, yaw and pitch,\nwe can also store a quaternion as (yaw, pitch, w). Note that storing (x, y, z) with yaw\nand pitch removes information about its length, but we can restore the correct length\nwith ww, since the quaternion is normalized. If we ensure that w is always positive, then\nwe don't have to store its sign. Once again, if w is negative, we simply negate the\nquaternion.\n\nThe trouble with storing a direction vector as yaw and pitch is that the encoded\nvectors are not evenly dispersed over a sphere. They are instead concentrated at the\npoles. When the pitch of the vector is 7/2, and the vector points straight up at the\npole, we do not want to store a yaw. However, when the pitch of the vector is zero and\nthe vector lies along the equator, we want to store many yaw values. Say we wanted to\nuse 7 bits to encode a direction vector. One solution would be to spread points evenly\nacross the surface of the sphere, store (x, y, 2) or (yaw, pitch) for each point in a lookup\ntable, then store an 7-bit index into that table. While this is okay for small values of 1,\nthe size of the lookup table quickly becomes uncomfortably large!\n\nHowever, there is an effective method for encoding a direction vector without the\nuse of a lookup table. First of all, we store the signs of x, y, and z separately so that we\ncan assume that x, y, and z are all positive. This reduces the problem to an eighth of\nthe sphere. The next step is to number points inside this eighth of a sphere as in Fig-\nure 2.4.1.\n\nNotice that the square numbers appear on the left-hand side of the diagram. This\nallows us to find the row and column of an encoded number, e, like this:\n\nrow = floor(sqrt(e));\ncolumn = e — row*row;\n\nNow, if we let pitch be the row of e, and if we let yaw be the column of e, we can\nefficiently store and retrieve these values. Notice how we will not waste any yaw values\nat the pole, and that we have plenty of possible yaw values at the equator.\n\nImplementation\n\nasm NRE EE TTT eS Se ROSS NASSAR HOSTS SRSES ORS e RUTGERS RSNEHE nn a a HEN\n\nNow, let’s discuss the implementation for the methods we have discussed.",
      "content_length": 2892,
      "extraction_method": "OCR"
    },
    {
      "page_number": 188,
      "chapter": null,
      "content": "2.4 Quaternion Compression 189\n\nFIGURE 2.4.1 Numbering over an eighth of a sphere.\n\nSmallest Three\n\nThe smallest three method neatly stores a quaternion into 32 bits. We need two bits\nto store the index of the implied (largest) element, leaving 10 bits for each of the\nthree smallest elements. Since we know each of the stored elements lie in the range\n[— 1/V2, 1/V2. we can interpolate those values to [0, 1023] so that the values are rep-\nresented as integers.\n\nPolar\n\nAfter experimenting with various bit allocations, we found the best compression\nwhen we allocated 11 bits to w. We need an additional 3 bits to store the sign of x, »,\nand z, leaving 18 bits to store yaw and pitch. If we are encoding yaw and pitch as a sin-\ngle number, then we can store 2'® values in 512 rows. Alternatively, we can allocate 9\nbits for yaw and 9 bits for pitch. We know they are both in the range [0, 2/2], so we\ninterpolate these values to [0, 511] and store them as integers.\n\nConverting from yaw and pitch to a vector requires sine and cosine calculations\nfor both yaw and pitch, so we recommend using a fast polynomial approximation",
      "content_length": 1125,
      "extraction_method": "OCR"
    },
    {
      "page_number": 189,
      "chapter": null,
      "content": "Section 2 Mathematics\n\nctr ooh tt tb aOR REE\n\n[Edwards00] to calculate these values. Moreover, because yaw and pitch are always\nwithin [0, 7/2], we can tailor (no pun intended) the approximations to this particular\nrange. We can expand a Taylor series about 1/4 (instead of about 0) and use values\nbetween [0, 1/4] as sample points for a Lagrange series. A Taylor series to order five,\nor a Lagrange series to order four or five is sufficient. The order-four Lagrange series\nis slightly faster, but you lose a bit of accuracy. Also, the order-five Lagrange series\ngives a more accurate approximation than the order-five Taylor series.\n\nThe animation data for our game Blade II is stored hierarchically, hence the vast\nmajority of the quaternions have only a small angle of rotation, 0. Since w is cos(8/2),\nw is usually close to 1 for this data. Note that this would be true to a lesser extent even\nif the quaternions had random angles of rotation, simply because of the nature of the\n\ncosine function. So, to get more resolution for values near to 1, we store V1—w\ninstead of w and recover w at decompression time.\n\nPerformance\n\n{Hie SRR TE eee RRR SRR HARRIS RR AR NOR EY 8 sa?\n\nTo quantify the performance of each compression method, we used the quaternions\nfrom our Blade I] as data. We compressed and decompressed each quaternion Q to get\nanother quaternion, Q’. We converted Q and Q’to matrices, and transformed a set of\npoints with the resulting matrices. Then, for each point, we calculated the distance\nbetween the point transformed with Q and the point transformed with Q’. We repre-\nsent these distances as error for that compression method. We also measured the\ndecompression speed of each method. Figure 2.4.2 shows the relative performance of\neach compression method on our hierarchical data. The approximation method used\nfor the polar methods was an order-five Lagrange polynomial.\n\nDecompression\nTime\n\nmw Polar encoded\n\nMaximum (yaw, pitch) and w\nError @ Polar\n(yaw, pitch,w)\n0 Smallest Three\nAverage\nError\n\nFIGURE 2.4.2 Relative performance of each compression method using Blade IT\nquaternion data.",
      "content_length": 2117,
      "extraction_method": "OCR"
    },
    {
      "page_number": 190,
      "chapter": null,
      "content": "2.4 Quaternion Compression ; 191\n\nsein ttt au ia oto aaa tela ons pisncgronice Mot tt\n\nea A RR RS RI RRS USE RAR\n\nThe real t test of the compression of each algorithm comes from observing the charac-\nters in your game. The worst-case scenario for Blade I is when errors accumulate\ndown the skeleton, especially if the character is holding a long lever (like a shotgun) in\nhis hand! There is a visible improvement when using the polar methods compared to\nthe smallest three method.\n\nAcknowledgments _\n\nLAL LE ENTER RRA\n\nI want to thank Jan Svarovsky and Mike Diskett for their help j in developing the ideas\nin this gem.\n\nitRBRENINRaRN ARS RI RRE IRON IARC eI aR RN\n\nwards00] Edwards, Eddie, “Polynomial Approximations to Trigonometric Func-\ntions,” Game Programming Gems, Charles River Media, Inc., 2000.\n\n[Svarovsky00] Svarovsky, Jan, “Quaternions for Game Programming,” Game Pro-\ngramming Gems, Charles River Media, Inc., 2000.",
      "content_length": 929,
      "extraction_method": "OCR"
    },
    {
      "page_number": 191,
      "chapter": null,
      "content": "Bones Hierarchy\n\n192\n\nConstrained Inverse\nKinematics\n\nJason Weber, Intel Corporation\njason.p.weber@intel.com\n\nuch of the animation currently used in interactive applications relies on stored\n\nfragments of motion-captured or hand-authored data. Although these motions\ncan be beautifully polished, the repeated use of a limited set of actions can become\nreadily apparent. One key to holding the attention of a user is to continually provide\nnew and unique environments.\n\nTo provide unique animations at runtime, we first need an abstract means to con-\ntrol and deform a mesh, such as with an embedded skeleton. Then, we need to gener-\nate motion for that skeleton from events or items in the proximity of the mesh.\nForward kinematics allows us to simply adjust bone angles like a jointed, wooden\nartist's model. However, we also need the reverse calculation to find suitable angles\nthat will arrange terminal segments, like hands and feet, where we want them. Inverse\nkinematics (IK) provides a fast and robust method to position an arbitrary chain of\nbones so that an end bone attempts to align with a movable ‘effector.’ By providing\nsolutions in real-time, we allow characters to react spontaneously and uniquely to an\nunpredictable environment.\n\nWe describe a well-known method called “cyclic coordinate descent” and demon-\nstrate how to constrain the angular solutions based on the physical limits of the joints.\nWe specifically target the constraint format provided with 3ds max.\n\nPRIMER\n\nARLE ORS PRR RAEN I eRe REO RARER\n\nThe skeletal structure is basically a hierarchy of transforms, like a scene graph. At each\ntransform, we define a bone length, which is really a displacement along that trans-\nform’s local x-axis. By default, the origin of all child bones is positioned at the point\non the end of the parent bone. We allow for an additional arbitrary displacement, but\nin most cases it is zero, because bones usually connect end-to-end.\n\nFor clarity, we will not refer to a “model space” in which the overall character is\nplaced. We will refer to the space that the root bone moves in as the “world space,”\neven though in a real scenario, it will probably be just a node in some greater scene",
      "content_length": 2203,
      "extraction_method": "OCR"
    },
    {
      "page_number": 192,
      "chapter": null,
      "content": "2.5 Constrained Inverse Kinematics 193\n\ngraph. At each transform in the bone hierarchy, that transform, relative to its parent,\nwill be called a “local” transform.\n\nAt this stage, we represent all rotations using quaternions because of their smooth\ninterpolative qualities [Bobick98]. A quaternion is a four-dimensional extension to\ncomplex numbers. So, just as a complex number can be used for two-dimensional\nrotational computations, w + xi + yj + zk (i = j* = k? = —1, ij = k = —ji) can effectively\nrepresent three-dimensional rotations. Conversions to and from quaternions, as well\nas operations using quaternions, can include nontrivial mathematics, but small\nlibraries and clear examples are readily available [Flipcode98]. We use right-handed\nunit quaternions of the form (w, x, y, z) where (1, 0, 0, 0) represents an identity of no\nrotation. The values are similar to the angle/axis format, where a rotation of (2cos! w)\nradians occurs about a nonunit vector (x, y, Z).\n\nA reference pose for the skeleton describes the state of the hierarchy so that it\naligns with a given undeformed source mesh. (BiPed™, in 3ds max, calls this the “fig-\nure mode.”) The motion of the bones away from reference is used to deform the mesh\nto any arbitrary position. The deformation techniques are a different topic\n[Weber02], so all we have to know about here is that the IK algorithms or interpo-\nlated motion data supply a bone-indexed set of world-aligned transforms at each\nframe. After the parent-relative quaternion values have been determined for a frame,\nthe bone graph is traversed, and the world transforms are generated through simple\nquaternion-quaternion concatenation and quaternion-matrix conversion.\n\nCyclic Coordinate Descent\n\nThe IK system attempts to rotate a chain of participating bones so that the tip of the\nend bone is located at a movable control point, called an effector. There are many\ncomplex and expensive ways to generate inverse kinematic solutions, but fortunately\nthere is a reasonably simple algorithm that is quite fast and surprisingly robust, called\n“cyclic coordinate descent” (CCD), which is nicely outlined in [Lander98]. We use\nquaternions for all the rotational operations.\n\nEach iteration starts with the deepest child bone in the chain. The bone is rotated\nabout its base so that it points directly at the effector. Next, the parent of that bone is\nrotated about its base so that an imaginary line from the base of that parent to the tip\nof the newly rotated child points toward the effector. This is repeated for every bone\nin the chain so that each bone’s imaginary line from its base to that same end bone’s\nendpoint rotates toward the effector. Multiple iterations through the chain can fur-\nther refine the solution to produce a smoother distribution of angles. Even if the effec-\ntor cannot be reached, the solver can make a solid attempt without becoming shaky or\nunstable.\n\nThis method can create a tendency to make the lowest child disproportionally\ndynamic, such as using full wrist deflection just to pick up a ball. It is possible to bias\nthe solution by having some bones only rotate a fraction of the desired change for",
      "content_length": 3169,
      "extraction_method": "OCR"
    },
    {
      "page_number": 193,
      "chapter": null,
      "content": "194\n\n2 Mathematics\n\neach iteration, but this might increase the number of iterations needed to reach a sta-\ntic solution. To pick up a ball, it is probably easier just to apply the IK effector to the\nwrist instead of the fingertips, and then use a generic pick-up motion for the hand.\nFigure 2.5.1 shows the steps in a descent. The X symbol is the location of the\neffector. The dotted line represents the current base-to-tip angle. Each currently\naddressed bone is rotated to align the dotted line with the desired dashed line.\n\n™—\n\nFIGURE 2.5.1 Steps in cyclic coordinate descent. The X symbol is the location of the\n\neffector.\n\nIf a bone participates in multiple ‘effected’ end bones, the participating bone can\nfirst compute an angular change to satisfy each of the solutions, then use given\nweighting factors to work out a blended solution.\n\nThe number of iterations required to reach an acceptable solution depends on\nwhere each new frame starts the solution. In a conventional approach, you would\nreset the limb to some default state at the beginning of each frame. The solver would\nrun through 10 or so iterations to a fresh solution. However, a small change in an\neffector position can cause a sudden change in the solution. For example, if you are\nmoving an effector for the hand vertically behind the back, the solver might suddenly\ndecide that it is better to reach over the shoulder than under it. An alternative\napproach is to continue from the solution of the previous frame. Then, we can cut\nback to as little as one iteration per frame. By using this incremental method, the\nsolver also is much less likely to flip between marginally superior, but substantially\ndifferent solutions.\n\nAn important factor in generating realistic motion is limiting the angular velocity.\nTo do this, we take the world-based quaternion of the previous frame and compare\nthe new quaternion solution. We convert the delta to angle-axis form and limit the\nangle to a specified maximum. About 3 radians per second seems to be a good default\nlimit, with smaller values increasing the sluggishness. Limiting angular acceleration\nturns out to have minimal value, since it appears that most biological structures can\nachieve full velocity during the timestep of one frame.\n\nSee [Welman93] for detailed explanation of CCD and other methods of inverse\n\nkinematics.",
      "content_length": 2350,
      "extraction_method": "OCR"
    },
    {
      "page_number": 194,
      "chapter": null,
      "content": "2.5 Constrained Inverse Kinematics 195\n\nRotational Constraints __\n\nThe resulting IK solution will not st work well with physical c creatures unless we account\nfor realistic angular limits. The basis of how constraints are defined and applied is dic-\ntated by the form in which the authoring packages export them. Therefore, we will\ndefine two conventions we need to follow.\n\nEuler Angles\n\nAlthough our rotations are computed using quaternions, the limiting angles are usu-\nally supplied from the artist using Euler angles, an alternative angular representation\nusing three angles applied in succession. For example, Euler angles could represent the\norientation of an airplane by heading, pitch, and bank where pitch is applied after\nrotating by the heading, and bank is applied after rotating for the pitch. Gimbal lock\ncan occur if one of the angles is near 90°, since two of the rotation axes can align and\nbecome redundant. In that case, the third degree of freedom is lost.\n\nConverting from an Euler representation to a quaternion or matrix is as simple as\napplying the three rotational transforms in succession. However, converting back to\nan Euler representation is weakly defined and can have multiple solutions. A conver-\nsion example is in a referenced article, [Flipcode98].\n\nWorld-Aligned Constraints\n\nProgrammers would probably expect the angular limits of a particular bone to be\ndefined relative to the position of its parent. While this is partially true, 3ds max uses\nworld-aligned axes to define the angles about which these limits are to be applied.\nThis means that if the world-relative reference transform of a parent bone is not\naligned with the world axes, then an isolated constraint of a child about one of the\nparent’s local axes is not possible. Because of this, the 3ds max manuals recommend\nthat the constrained bones in the reference pose (their ‘figure mode’) should be coin-\ncidentally aligned with the world. Unfortunately, we cannot simply transform these\nlimits about world-aligned axes to the local axes of the bone. To faithfully reproduce\nthe artist’s intentions, we have to follow these conventions exactly, making conver-\nsions back and forth as necessary.\n\n‘Kine’ Each Bone, and Apply the Constraints\n\nON THE CO\n\nSN ARS AACR MERIT RE RGB RABANNE GILG RA ATOR NRO OED ME EASE ARETE ME NES\n\nThis pseudo-code will describe the entire process of applying IK to one specific bone.\nThis process is applied to the entire hierarchy in a child-first order. For reference, see\nGPGCharacter::KineBone() in the file GPGCharacter.cpp on the CD-ROM. The\nvariable world_relative is true (you may note how much simpler the code would be if\nit were false).\n\nEach bone contains a list of the effector solutions to which it participates. For\neach bone that has an effector, there are usually several bones that participate in the\nsolution to draw that one bone toward the effector. Note that we called this partici-",
      "content_length": 2936,
      "extraction_method": "OCR"
    },
    {
      "page_number": 195,
      "chapter": null,
      "content": "Section 2 Mathematics\n\npating association to an effector an “effection.” Having an effection doesn’t necessar-\nily mean that the specific bone is trying to reach the effector, but rather it may be\nhelping a descendent bone meet the effector. For example, the upper arm can help the\nhand reach for a ball.\n\nThe float scalar is used to divide influence from multiple effectors. Currently in\nour code, it is evenly divided, so if a bone has an effection to two effectors, each will\nonly have half the effect they would have had by themselves. The following block is\n\napplied once for each bone’s effection.\n\nVector3 effected = current end of effected bone in world space\ndisplaced in local X by the bone length\nVector3 effector = current position of relevant control point in\n\nworld space\nVector3 current = effected, reverse-transformed to local space\nVector3 desired = effector, reverse-transformed to local space\n\nif the difference between current and desired is small, skip to next\nbone\n\nnormalize current and desired\ncompute a quaternion delta that would rotate current to desired\n\nsum all the scaled deltas from the multiple effections and store in\nchange\n\nif velocity-limiting is on, limit change to the max per-frame angle\nallowed; this should be adjusted to the magnitude of the timestep\n\nrotate the bone by the quaternion delta\n\nQuaternion global_rot = parent's world rotation * this bone's local\nrotation (this is the bone's current world transform)\n\nQuaternion parent_delta = parent's reference rotation * inverse of\nparent's current world rotation (this is how much the parent has\ndeviated from reference with respect to the world)\n\nQuaternion global_delta = parent_delta * global_rot * inverse of\nparent reference world rotation (this is the bone rotation in world-\naligned axes adjusted for parent rotation)\n\nconvert Quaternion global_delta to Euler euler\n\nThe next block does the actual limiting of angles. It is applied to euler in each of\nthe three axes. “Active” means it is allowed to move. “Limited” means that the angle is\nconstrained. To avoid gimbal lock, we ignore new x and z angles when the y angle is\nnear + 90° (by about 5% of a radian). We retain old values of x and z until the y angle\nreturns to a safe value.\n\nNote the usage of a variable called dias. When a potential solution goes far outside\nthe constraints, this can prevent it from flipping around and constraining to the opposite",
      "content_length": 2414,
      "extraction_method": "OCR"
    },
    {
      "page_number": 196,
      "chapter": null,
      "content": "197\n\nlimit. A bias of zero means the bone is currently being limited by the minimum angle,\none indicates it is being limited by the maximum angle, and two indicates no preference.\nWhen thinking about the constraints, it can be helpful to think of a pie slice in a circle\nwhere the two radials are the minimum and maximum angles. Usually, when the result\nends up outside this region, you want to snap to the closest boundary (minimum or max-\nimum). However, if the computed solution is outside the pie slice, but is nearly equidis-\ntant from both limits, it is possible that the clamping routine will flip back and forth\nbetween the minimum and maximum. So, we insert a bias indicating that in order to flip\naround the outside of the pie, the alternate limit must be substantially closer. In our code,\nwe add 10° to the alternate distance before the magnitude comparison.\n\nif active and not limited, skip this axis (any angle is fine)\n\nif not active, set the angle to the reference value; skip to next\naxis\n\nX,Z axes only: if Y angle is near 90 degrees, set angle to last\nframe's value, and skip to next axis (gimbal lock avoidance)\n\nif current angle is within limits, reset bias to 2 (no preference),\nand skip to next axis\n\nmindiff\nmaxdi ff\n\nminimum — angle\nangle - maximum\n\nadjust mindiff and maxdiff to be in range of 0 to 2*PI\n\nif there is a bias preference, adjust angles to make flipping between\nsolutions less desirable by adding the 10 degrees to the opposite\nmin/max diff variable\n\nif maxdiff<mindiff, set angle to max and bias to 1\nif maxdiff>mindiff, set angle to min and bias to 0\n\nstore modified euler in case there is a gimbal lock next frame\nconvert euler to Quaternion global_delta\n\nQuaternion constrained = inverse of parent reference world rotation\n* global_delta * parent reference world rotation\n\nset bone rotation to constrained\n\nrecompute cached current world transform for this bone and all\ndescendents\n\nFigure 2.5.2 shows a character reaching back to an effector about 2/3 meters\nbehind his head. Without the constraints, the solver would have immediately posi-\ntioned the arm in a straight line from the shoulder toward the point. With con-\nstraints, the arm is restricted to its physical limits. Also see Color Plate 2 for an\nexample of this technique on a scorpion tank mesh.",
      "content_length": 2301,
      "extraction_method": "OCR"
    },
    {
      "page_number": 197,
      "chapter": null,
      "content": "198 Section 2 Mathematics\n\nConclusion\n\nRNR cE cere\n\nfed pe\n\nUsing inverse kinematics in skeletal motions can generate a level of spontaneity that is\ndifficult to produce with pre-authored or captured motion data. By generating the\nmotion in real-time, the characters can react uniquely to an ever-changing situation.\n\nIn our example, we use hard stops to limit the angles. By adding a springiness\nnear the limits, we should be able to reduce the mechanical-looking motions that can\nsometimes occur.\n\nReferences\n\n[Bobick98] Bobick, Nick, “Rotating Objects Using Quaternions,” Game Developer\nMagazine, February 1998: pp. 34-42. Also available online at http://www.\ngdmag.com/.\n\n[Flipcode98] Unattributed, “The Matrix and Quaternions FAQ,” available online at\nfietp: iwww.flipcode.com/documents/matrfag.html, December 1998.\n\n[Lander98] Lander, Jeff, “Making Kine More Flexible,” Game Developer Magazine,\nNovember 1998: pp. 15-22.",
      "content_length": 926,
      "extraction_method": "OCR"
    },
    {
      "page_number": 198,
      "chapter": null,
      "content": "2.5 Constrained Inverse Kinematics 199\n\n[Weber02] Weber, Jason, “Improved Bones Deformation,” Game Programming Gems\n3, Charles River Media, Inc., 2002.\n\n[Welman93] Welman, Chris, “Inverse Kinematics and Geometric Constraints for\nArticulated Figure Manipulation,” Masters Thesis, Simon Fraser University, Sep-\ntember 1993.\n\nThe author will make an effort to maintain a long-term archive and link site for some\nrelated resources at http://www.imonk.com/baboon/bones.",
      "content_length": 464,
      "extraction_method": "OCR"
    },
    {
      "page_number": 199,
      "chapter": null,
      "content": "2.6\n\nCellular Automata for\nPhysical Modeling\n\nTom Forsyth,\nMucky Foot Productions, Ltd.\ntomf@muckyfoot.com\n\nNi current game environments are mostly static. The sorts of things that move\n\nin games are restricted to either small, discrete objects, such as vehicles and peo-\n\nple, or sometimes some larger, mechanical, or prescripted objects. In some cases, the\nwater level in a container can move in scripted ways, but it is only a single horizontal\nplane that moves up or down, and there is no way for the player to directly interact\nwith it.\n\nIn the current state of the art of games, the following effects tend to be either\n\nfaked or not simulated at all:\n\nFire that spreads, ignites flammable objects, and causes damage to them.\n\nWater that can be held in containers, flow through pipes, be pumped around real-\nistically, walked through, weigh objects down, overflow containers, or spread over\nfloors and down slopes.\n\nOil that combines the fluid properties of water with the burning properties of\nflammable materials, such as wood.\n\nExplosions that have realistic damage radii, doing more damage indoors than out-\ndoors, and traveling around corners in realistic ways.\n\nHeat that causes air to rise, causes convection currents, can be pumped around by\nventilation fans, and possibly even carry scents and smells.\n\nSmoke and dust that spread with air currents, are generated by fires or smoke\ngrenades, obscure vision, and choke people.\n\nWalls and environments that can be damaged, destroyed, set on fire, moved, or\ngive limited protection from explosions and attacks.\n\nSome of these features have appeared in games, but usually in heavily scripted and\n\nconstrained ways; frequently they play little part in the actual gameplay and look arti-\nficial—which, of course, is exactly what they are. Using cellular automata (CA) to\nsimulate these ideas can lead to far more dynamic and realistic behavior, and allow\n\n200",
      "content_length": 1916,
      "extraction_method": "OCR"
    },
    {
      "page_number": 200,
      "chapter": null,
      "content": "2.6 Cellular Automata for Physical Modeling 201\n\nnew types of gameplay and new tactics within games. At the very least, they allow\nmore realism, better graphical rendering, and therefore increase player immersion.\n\nCellular automata (CA), and their close relatives, finite element analysis (FEA) and\ncomputational fluid dynamics (CFD) [CFD], are already used in plenty of applica-\ntions for modeling air and water flow, heat distribution, building stresses and strains,\nand many other aspects of the real world. However, the main emphasis of the acade-\nmic and commercial modelers is on accuracy. As game programmers, our only real\nconcern is whether something looks good enough and runs quickly enough; and in\nalmost every case, the simulation can be enormously simplified while still looking per-\nfectly correct to most people.\n\nThe basics of a CA are simple. The world is divided into a grid of fixed-size cells.\nEach cell has various numbers associated with it to represent its state. Usual values\nheld in cells are the air pressure, temperature, amount of water, which direction the\nwater or air is flowing in, and so on.\n\nEach game turn, every cell is processed, and it compares itself with its neighbor-\ning cells. Differences between them result in changes to the state of the cell and/or its\nneighbors according to various laws. In this gem, these laws will be based very loosely\non real physical laws. One of the best-known CA is called “Conway's Game of Life”\n[Conway]. This is an extremely simple CA. It has a single bit of state—whether the\ncell is full or not—and some extremely simple rules for changing state according to\nthe state of neighboring cells. Nevertheless, even this simple model can give rise to\nsome extremely complex behavior.\n\nThe CAs used in games will have rules based on various physical models to deter-\nmine the amount of heat, air, water, or smoke that is transferred between neighboring\ncells. If we run the rules quickly enough on a sufficient number of cells, water will\nflow downhill and find level ground, gently heated air will form convection currents,\nand strongly heated air will burn objects and, in turn, be heated by the burning\nobjects.\n\nIn a three-dimensional array of cubic cells, there are three possible definitions of\n‘neighbor’ cells:\n\nSREB BBN B8\n\n_ ouuTaRRERRERERARAA\n\n¢ The six cells that share a face with the central cell.\n¢ Those 6, plus another 12 that share an edge with the central cell.\n¢ Those 18, plus another 8 that share a corner with the central cell.\n\nSurprisingly, the rules that are used for physics simulations give almost the same\nresults, whichever of the three definitions we use. Of course, the first version is far\nsimpler, and there is only one type of neighbor cell, rather than three. For this reason,\nit is far easier to only consider as neighbors the six cells that share a face with the cen-\n\ntral cell.",
      "content_length": 2889,
      "extraction_method": "OCR"
    },
    {
      "page_number": 201,
      "chapter": null,
      "content": "202\n\nSection 2 Mathematics\n\nFirst, choose the physical size of a CA cell. For human-size games, we decided to\nuse cubes that are half a meter across. Any bigger, and a CA cell of air will not fit\ninside a narrow passageway. Smaller cubes give higher resolution and allow for smaller\nPipes, narrower gaps, and so on—but the extra space and processing is expensive. Dif-\nferent scales of games will naturally require a different size of CA cell; however,\nbecause most games are set on a human scale, for convenience, this gem will assume a\nscale of half-meter cube cells in its examples.\n\nAnother important consideration in a human-size game is how to model thin\nwalls. Most internal house walls and doors are only a few centimeters thick. They will\nstop water flow, slow fire down, and stop smoke and air spreading, so they must be\nmodeled in some way. Modeling them conventionally by using many small cells, and\nmarking those occupied by the wall as solid, would require using cells of no more\nthan about 10 cm across, which requires 125 times as many cells—an extremely\nexpensive option.\n\nTwo possible solutions present themselves. One method, used by the first of the\nX-Com series of games in their impressive and innovative use of CAs [XCom], is to\nmodel the faces between the cells as entities, as well as modeling the cells themselves.\nSo walls, floors, and ceilings always lie between two cells, along cell faces. This works\nquite well, but it does mean that there are now two distinct classes of objects—things\nthat fill a whole cube (e.g., rock, dirt, furniture, or tall grass) and things that sit\nbetween two cells (e.g., walls, floorboards, short grass, or doors). This creates annoy-\ning special cases in the code used to model substances and their interactions, and\ncauses code replication between the two types (spaghetti code). However, if this\nmodel fits, then it is a viable one, and it is fairly intuitive—the internal representation\nof objects matches their rendered shape fairly closely.\n\nThe other solution is one that retains its generality without resorting to many\ntiny cells. Rather than aligning cubic cells on a fixed grid, we allow the edges between\ncells to move about a bit according to the contents. This allows a thin wall to be\nchopped into half-meter squares, and each square lives in a cell. Because the walls are\nonly a few centimeters thick, we expand the neighboring cells to take up the extra\nspace. Even though the cells are no longer aligned on a grid, the CA code itself does\nnot know or care what shape the objects it represents are. As far as the CA physics are\nconcerned, everything is still half a meter thick. Most of the work in making things\nlook otherwise is in the rendering, rather than in the CA routines. It is the job of the\nrendering to ensure that water goes all the way to the wall’s mesh and not just to\nthe edge of the CA cube, which would leave a large gap. The only things that need to\nspread adaptively like this are volumetric effects, such as smoke, fire, and water. When\ndrawing a cell with one of these effects, the renderer needs to check each neighboring\ncell to see if its polygonal shape is smaller than the usual half-meter cube. If it is, it\nexpands the size of the volumetric effect to fill the space.\n\nIn this scheme, a one-meter-wide corridor with thin wooden walls is represented\nby a plane of ‘wood’ cells, a plane of ‘air’ cells, and then a plane of ‘wood’ cells. Since",
      "content_length": 3447,
      "extraction_method": "OCR"
    },
    {
      "page_number": 202,
      "chapter": null,
      "content": "2.6 Cellular Automata for Physical Modeling 203\n\nthe centers of the cells are each half a meter away from each other, the total apparent\nwidth from wall to wall is still one meter. Of course, the graphical representation of\nthe world still shows that the ‘cubes’ of wood are not cubes at all, but flat planes a few\ncentimeters thick; and this is the representation that will be used for any collision\ndetection. But the distinction makes very little difference to the things that are mod-\neled with the CA. Because these entities are fairly amorphous, the difference between\nwhat is rendered (a one-meter gap) and what is actually being modeled (a half-meter\ngap) is very hard for the player to see. Again, accuracy is sacrificed for speed wherever\nthe game can get away with it.\n\nThe next factor to consider is a gameplay decision—the difference between using\nPassive scenery and active scenery.\n\nPassive Scenery\n\nIn this system, as far as the CA is concerned, the scenery is inert—it is not affected by\nthe actions of the CA in any way. This is the simpler of the two representations, but it\nstill allows discrete objects, such as the ubiquitous oil drum and crate, to float away on\nrivers of water or to explode or burn when heated by fire.\n\nBecause the CA only knows about cells, not polygons, the scenery must be con-\nverted into a cell representation—usually as a preprocessing step. These cells are sim-\nply marked as inert volumes that confine the actions of the CAs. Of course, the\nscenery is usually a collection of arbitrary polygons and is not aligned to cell bound-\naries. But the things being modeled with CAs are so amorphous that this difference\ndoes not matter in practice. As long as each solid polygonal wall is converted into a\ncontinuous wall of CA cells, water will not flow through and break the illusion.\n\nEven in this system, special cases should be made for doors that can be opened\nand other animate or moving objects. When doors are opened, they should remove\n(sliding doors) or move (swinging doors) the solid cells that represent them so that\nwater and/or fire can move through them.\n\nActive Scenery\n\nThe far more versatile and adventurous option is to have the scenery modeled by the\nCA as well. This opens up the ‘totally destructible world’ concept that many designers\nare looking to as the next big thing in games, though this concept is not truly new in\ncomputer games [XCom].\n\nIn this system, rather than simply being cells of inert material, scenery is modeled\nby its actual properties, such as temperature, flammability, and so on. As the cells\nmodeled with CA change their state according to the physical rules of the CA, the\ngraphics engine changes how it renders the associated polygonal objects (e.g., sooty,\ndamaged, etc.)\n\nIn the latter case, the graphics engine can either be of the ‘Geo-Mod’ type [Red-\nFaction], or the object itself can simply have been specially marked as destructible and\nhave an alternative, ‘broken’ graphical representation.",
      "content_length": 2993,
      "extraction_method": "OCR"
    },
    {
      "page_number": 203,
      "chapter": null,
      "content": "204 Section 2 Mathematics\n\n\\sinieansomente iuennaciinmnataanron ooo. sek mame RAM aac Reena EAE MEERA AEDS HEA RASH EE CBI EAS A\n\nThose considering implementing these CA methods will have quickly noticed that\nstoring half-meter cells for even a modest-size level consumes a huge amount of mem-\nory, and the processing and memory bandwidth requirements become severe. The\napproach to doing this efficiently is to not store or process cells that are not partici-\npating in any interesting activities—notably inert walls and/or air at (standard) ambi-\nent temperature and pressure (STP).\n\nAn octree is ideally suited to storing this arrangement, specifically a dynamically\nallocated octree. In any implementation of the octree, remember that the most com-\nmon operation in a CA is “find the cell next to me,” so it makes sense to optimize for\nthis type of operation when implementing the octree. If this request is made and there\nis no neighboring cell in the octree, it is assumed that the neighboring cell is air at\nSTP. The physical simulations are carried out accordingly; and if they result in the\n‘missing’ cell becoming significantly different from STP, a cell with the new properties\nis created and inserted in the octree. When an air cell returns to within a certain tol-\nerance of STP, it is deleted from the octree and is no longer processed.\n\nThe octree holding CA cells can also be useful as a general-purpose octree. Many\ngames use octrees to optimize collision detection and visibility culling, and there is no\nreason the octree cannot fulfill both roles and hold objects not directly related to the\nCA. A fairly easy adaptation to the search algorithms allows the octree to become a\n‘loose octree’ [Ulrich00], which has several other advantages over a conventional\noctree. This does not change its behavior when dealing with the CA aspect of its\nbehavior, since all CA cells are aligned to regular intervals and have a fixed size.\n\nPractical Physics\n\nRATE see ERE\n\nA ne SSSR RP SRN\n\nThe main thing to remember when writing CA physics routines is to keep things sim-\nple. It is surprisingly easy to write very simple routines that take major physical short-\ncuts, yet look perfectly natural to the player. As long as the basics of conservation of\nmass and energy are retained—which is frequently optional—most of the other code\ndeals with keeping the simulations stable.\n\nThe major problem we encountered during implementation was finding good,\nsimple models of various physical features. Most of the standard references deal with the\napplication of Navier-Stokes equations for various materials and implementing them\nwith as little error as possible. This enormously complicates the code, and most of the\nacademic and commercial literature is concerned with these error reductions. For\ngames, what is required is simplicity, not accuracy. Most of the time, finding implemen-\ntations involved getting only the general feel of the behavior from the literature.\n\nCore Processing Model\n\nEB SAARI OER AH 08 RR ss - exter\n\nMost of the properties simulated by the CA work in similar ways. To illustrate these\ncommon methods, here is a very simple fluid simulation that just tries to achieve even",
      "content_length": 3201,
      "extraction_method": "OCR"
    },
    {
      "page_number": 204,
      "chapter": null,
      "content": "2.6 Cellular Automata for Physical Modeling 205\n\ndistribution of pressure throughout the available space. Even this simplified model is\nvery useful for air and fluid modeling.\n\nfor ( neigh = each neighbor cell )\n{\nif ( neigh->Material->IsInert() ) continue;\nfloat DPress = cell->Pressure — neigh->Pressure;\nfloat Flow = cell->Material->Flow * DPress;\nFlow = clamp ( Flow,\ncell->Pressure / 6.0f,\n-neigh->Pressure / 6.0f );\ncell->NewPressure -= Flow;\nneigh->NewPressure += Flow;\n\n}\n\nThe clamp() operation is performed to prevent NewPressure from going negative.\nThe division by six is because there are six neighbor cells. In practice, even more\ndamping might be needed to retain stability and prevent small oscillations, such as\nwaves on the surface of water, from becoming unrealistic oscillations.\n\nConventionally, once all the cells have been processed in this way, the NewPres-\nsure values are copied to the Pressure values. This double-buffering is necessary,\nrather than simply writing directly to Pressure at the end of the routine. Otherwise,\npressure will be transmitted extremely fast (sometimes instantly) in the direction that\nthe cells are updated, and much slower in the reverse directions. This produces obvi-\nous asymmetry in heat distribution, water flow, and other processes.\n\nThe double visit to each cell can hurt performance considerably, especially as\nthe second visit is simply a copy, and will be limited by memory bandwidth on\nmost modern CPUs. A better method is to store the last turn that a cell was\nprocessed. When subsequently processing that cell, the turn number is checked; and\nif it is earlier than the current turn, the copy is done. Although slightly odd-looking,\nthis is in fact much quicker than scanning the whole array of cells twice. The code\nbecomes:\n\nif ( cell->Turn != CurrentTurn )\n\n{\ncell->Turn = CurrentTurn;\ncell->Pressure = cell->NewPressure;\n}\nfor ({ neigh = each neighbor cell )\n{\nif ( neigh->Material->IsInert() ) continue;\nif ( neigh->Turn != CurrentTurn )\n{\n\nneigh->Turn = CurrentTurn;\nneigh->Pressure = neigh->NewPressure;\n\n}\n\n// same physics code as before",
      "content_length": 2111,
      "extraction_method": "OCR"
    },
    {
      "page_number": 205,
      "chapter": null,
      "content": "206\n\nAir\n\n“Se a ome REINER DK wis 4ST NN Ee RELA\n\nWater\n\nSMR AEHASLA Sone tc cisions\n\nMS GR aR SAU LEASED DER A ENG SET TIE BRAS\n\nThis simple model works well for uniform redistribution of air pressure. At first\nglance, this is not something that is frequently modeled in games. But in fact, it is one\nof the most common effects—explosions and their effects on things. An explosive is\nsimply a lump of material that produces a huge amount of air in a very short time.\nThey can be modeled through the following steps. First, find the nearest CA cell to\nthe center of an exploding grenade. Second, add a large number to the cell’s pressure.\nThird, let the CA propagate the pressure through the world. Damage is done to the\nsurroundings by either high absolute pressures or high pressure differences—in real-\nity, both do different kinds of damage to different objects; but that is usually unnec-\nessary complication for the purposes of a game.\n\nThe advantages of this method of modeling over conventional ones is that\nline-of-sight is handled automatically. Explosions in confined spaces are far more\ndeadly at a certain range than explosions in open spaces because there is less space for\nthe pressure to dissipate. In addition, it shows that pure line-of-sight is not protection\nenough from explosions—they do go around corners and obstructions to a certain\ndegree.\n\nBecause the simulation of the flow of air is qualitatively correct to the human eye,\ndebris and small objects can be carried along with the explosion; you don’t have to\nworry about the illusion being shattered by debris going the wrong way or through\nsolid walls.\n\nRRR RENN SRR RA 8 ARO HHA Num esRoRERNRE\n\nWater is only slightly more complex than air. The obvious distinction is that air\nexpands to fill the available space with cells changing pressure to do so, while water\nstays at the bottom of its container and is incompressible.\n\nIn fact, the easiest way to simulate the transmission of pressure through water is\nto make it slightly compressible. This means pressure can be stored as a slight excess\nmass of water in the cell, above what the cell’s volume should be able to hold. In prac-\ntice, the amount of compression needed is tiny—allowing just 1% more water per cell\nper cube height is easily enough. In a static body of water whose cells can normally\ncontain 1.00 liter of water each, the cells at the top will contain 1.00 liter, the ones\nunder them will contain 1.01 liters, the cells under those will contain 1.02 liters, and\nso on to the bottom. This tiny amount of compression will be completely unnotice-\nable to the player, but it has enough dynamic range to allow all the usual properties of\nliquids. For example, the levels of water in two containers joined by a submerged pipe\nwill be the same, even if water is poured into one of them; it will flow through the\npipe to the other container.\n\nif ( neighbor cell is above this one )\n\n{\nif ( ( cell->Mass < material->MaxMass ) ||",
      "content_length": 2967,
      "extraction_method": "OCR"
    },
    {
      "page_number": 206,
      "chapter": null,
      "content": "2.6 Cellular Automata for Physical Modeling 207\n\n( neigh->Mass < material->MaxMass ) )\n\n{\nFlow = cell->Mass - material->MaxMass;\nyelse{\nFlow = cell->Mass — neigh->Mass\n- mMaterial->MaxCompress;\nFlow *= 0.5f;\n}\n}\nelse if ( neighbor cell is below this one )\n{\nif ( ( cell->Mass < material->MaxMass ) ||\n({ neigh->Mass < material->MaxMass ) )\n{\nFlow = material->MaxMass - neigh->Mass;\n}else{\nFlow = cell->Mass — neigh->Mass\n+ material->MaxCompress;\nFlow *= 0.5f;\n}\n}\nelse // neighbor is on same level\n{\nFlow = ( cell->Mass — neigh->Mass ) * 0.5f;\n}\n\nThis Flow value is then scaled and clamped according to some measure of the\nmaximum speed that the fluid can flow, allowing some fluids to appear more viscous\nthan others, and to prevent any resulting masses from going negative.\n\nThe two cases of code for the water model deal with different situations. The first\ncase is where one of the two cells is not full of water—such as on the surface of a body\nof water or if the water is splashing or falling (e.g., in a waterfall). Here, the behavior\nis simple—water flows downward to fill the lower cell of the two to the value Max -\nMass—the mass of water that can be contained by a single cell’s volume. In the previ-\nous example, the mass is one liter of water.\n\nThe second case is where both cells are full of water, or perhaps a bit over-full,\nsuch as in the middle of the body of water. Here, the flow acts to try to make sure that\nthe upper cell has exactly MaxCompress more water than the lower cell. MaxCompress is\nthe amount of ‘extra’ water that can be fitted in because of compression. In the previ-\nous example, it would be the mass of 0.01 liters of water.\n\nFlow\n\nSo far the air and water models have ignored a fairly important property of any liquid\nor gas—its speed of flow. We have simply taken the difference in pressures between\ntwo cells and used that to move mass around. This is fine for relatively static environ-\nments that we wish to bring to a stable state, such as uniform air pressure or water\nfinding its level. Many games will only use these simple properties for all the game-\nplay and realism they need.",
      "content_length": 2127,
      "extraction_method": "OCR"
    },
    {
      "page_number": 207,
      "chapter": null,
      "content": "Section 2 Mathematics\n\nHowever, what happens in real life is that water and air have momentum (which\nequals flow times mass), and the difference in pressure only influences the flow\nbetween cells; it does not rigidly set it. Storing momentum or flow is important when\nmodeling waves, flowing rivers, and air currents. Although rivers can flow in models\nwithout momentum, they have a very visible slope of at least 10°, which looks very\nbizarre.\n\nTo model momentum or speed of flow during each processing step, the difference\nin masses determines the pressure gradient, as before. However, instead of changing\nthe masses of the cells directly, the pressure gradient only alters the flow between the\ncells. The flow then changes the masses in the cells. The code is slightly more complex\nbecause flow is a three-dimensional vector and not a scalar like mass.\n\nThere are two possible ways to think about flow. The first is to think of a flow\nvector as being the flow through the center of the cell. This is possibly the most intu-\nitive model—the flow and the mass of the cell are both measured at its center. How-\never, in this case, the flow is affected by the pressure differential between the two\nneighboring cells, which in turn determines how mass flows from one neighboring\ncell to the other. Note the slightly odd result that, for a particular cell, the flow stored\nin it is not affected by the mass in the cell itself, but only by its neighbors. Nor does it\nchange the mass of the cell, but only the mass of its neighbors’ cells. This is a slightly\nsurprising result; and in some cases, this can lead to odd behavior.\n\nIt is more useful to think of each component of the flow vector as being the flow\nbetween two adjacent nodes—from the ‘current’ node to the node in the positive rel-\nevant direction. Thus, the flow vector F stored at cell (x, y, z) is interpreted as mean-\ning that F, is the flow from cell (x, y, z) to cell (x + 1, y, z); F,is the flow from cell\n(x, y, 2) to cell (x, y + 1, z); and, similarly, for F,. The ‘meaning’ of the vector F is now\nnot as intuitive, but the physical model does seem more sensible. In practice, this is\nthe most common model; but either model can be used for simulation with appropri-\nate adjustment of the various constants.\n\nThe most important step in this model is to carefully control oscillations. Not\nonly does this model allow waves, but it also tends to encourage them to build up,\nand sufficient damping must be applied to the flow by introducing a simple friction\ncoefficient. Otherwise, waves can build up higher and higher instead of dying down,\nand the liquid or gas starts to do very odd things indeed.\n\nIt is worth mentioning that, although one of the most common applications of\nflow is in rivers, in most ‘human-size’ games, large bodies of water, such as lakes and\nrivers, are frequently far too large to participate in gameplay. Their behavior will stay\nfairly constant whatever the player does; and if they do change, they will do so in\nhighly constrained ways. They do not usually require the flexibility of a CA and are\noften far better modeled and rendered in more-conventional ways. We can use pre-\nanimated meshes, collision models, and scripted events. However, there are many\nother genres that operate on larger scales and will want to properly simulate rivers\n\nwith a CA.",
      "content_length": 3349,
      "extraction_method": "OCR"
    },
    {
      "page_number": 208,
      "chapter": null,
      "content": "2.6 Cellular Automata for Physical Modeling 209\n\ncesarean sosiececssetenenne .\n‘Transmitting heat through the environment, whether from burning objects or from\nother sources, happens through three separate mechanisms: conduction, convection,\nand radiation.\n\nConduction\n\nConduction is the simplest mechanism to simulate. Neighboring cells pass heat energy\nbetween each other so that eventually they reach the same temperature. This is com-\nplicated because different materials are heated by different amounts by the same\nenergy—called the specific heat capacity (SHC), which is usually measured in J/kg°C.\nIfa hot cell made of water (high SHC and hard to heat up) is next to a colder cell made\nof the same mass of iron (low SHC), equilibrium will be reached at somewhere very\nclose to the original temperature of the water, not at the average of the two tempera-\ntures. This is because when a given amount of energy is transferred from the water to\nthe iron, the water’s temperature drops far less than the iron’s temperature rises.\n\nNote that the above example is true for the same mass of each substance. How-\never, iron has a far greater density than water; and therefore, for the same volume, they\nhave very similar heat capacities.\n\n// Find current heat capacities.\nfloat HCCell = cell->material->SHC * cell->Mass;\nfloat HCNeigh = neigh->material->SHC * neigh->Mass;\nfloat EnergyFlow = neigh->Temp - cell->Temp;\n// Convert from heat to energy\nif ( EnergyFlow > 0.0f )\nEnergyFlow *= HCNeigh;\nelse\nEnergyFlow *= HCCell1;\n// A constant according to cell update speed.\n// Usually found by trial and error.\nEnergyFlow *= ConstantEnergyFlowFactor;\nneigh->Temp -= EnergyFlow / HCNeigh;\ncell->Temp += EnergyFlow / HCCell;\n// Detect and kill oscillations.\nif (((EnergyFlow>0.0f)&&(neigh->Temp<cell->Temp) ) | |\n( (EnergyFlow<=0.0f) &&(neigh->Temp>cell->Temp) ) )\n\n{\nfloat TotalEnergy = HCCell * cell->Temp +\nHCNeigh * neigh->Temp;\nfloat AverageTemp = TotalEnergy /\n( HCCell + HCNeigh );\ncell->Temp = AverageTemp;\nneigh->Temp = AverageTemp;\n}\n\nThe code at the end is necessary if two materials with very different SHCs are side\nby side. In this case, the temperatures of the two can oscillate violently and can grow",
      "content_length": 2209,
      "extraction_method": "OCR"
    },
    {
      "page_number": 209,
      "chapter": null,
      "content": "210\n\nSection 2 Mathematics\n\nout of control. The physically correct solution is to integrate the transfer of heat over\ntime. However, this approach simply finds the weighted average temperature, which\nis the temperature that the system would reach eventually. It is less accurate, but looks\nperfectly natural and is quite a bit quicker to execute. Importantly, it obeys the law of\nconservation of energy, so any artifacts are purely temporary. The longer-term state is\nthe same as a more realistic simulation.\n\nConvection\n\nConvection is the phenomenon of heat rising. Hot areas of fluid, such as air or water,\nare less dense than cold areas, and thus try to rise. This can be simulated by incorpo-\nrating temperature into the model of water or air. If a flow model is being used, the\nflow will be influenced by the relative temperatures of cells as well as their relative\npressures. Otherwise, convection does not work very well, though its effects can be\nfaked as described in the section on fire.\n\nRadiation\n\nHot things glow. They emit light at various wavelengths, which travels in straight\nlines, hits other surfaces, and in turn heats them up. This effect is very important\nphysically, but unfortunately it is also extremely expensive to model. Each source of\nheat must effectively shoot many rays out from itself and heat up whatever they hit.\nRadiative heat modeling is very similar to the radiosity modeling that is used\nwhen creating lightmaps for many current games. Both are extremely expensive to\nmodel in runtime, even crudely, though there are some cunning methods that use a\nheavy amount of approximation to improve the speed of radiative heat modeling.\nEven with these algorithms, modeling even a fraction of the radiative heat seems like\na prohibitive amount of work for a game. These algorithms are also extremely com-\nplex and do not involve the standard cell-to-cell interactions that model all the other\nphysical properties mentioned. For both these reasons, we won't discuss them here.\n\nThe physics of burning materials is frequently extremely complex. There are multiple\nparts that burn at different rates and heats, and there are also different phases of mate-\nrial involved in the process.\n\nTo perform the calculations in real-time, the material models used during the\nprocess need to be trimmed down to their minimum; and for each material, an appro-\npriate model must be chosen that emphasizes the main characteristic.\n\nOf the many models considered, the one that finally seems to give the best results\nfor the least amount of effort is a quadratic approximation of an exponential graph. This\ngraph shows how much heat energy is released per unit of time when a substance burns\nat a certain temperature. There is a maximum amount of energy that can be released, no\nmatter how hot the fire gets. But even at relatively cool temperatures, a lot of heat is",
      "content_length": 2879,
      "extraction_method": "OCR"
    },
    {
      "page_number": 210,
      "chapter": null,
      "content": "211\n\nreleased. This explains why open fires tend to start small, rapidly grow to a certain size,\nand then not grow any bigger, yet burn for a long time, despite ample availability of fuel.\nThey are simply not generating enough heat energy to compensate for the heat lost to\nthe environment (which is directly proportional to the temperature).\n\nfloat Temp = cell->Temp — material->Flashpoint;\n// Damage the cell.\nCellDamage = Temp * material->BurnRate;\nfloat Burn;\n// Convert to actual burning value.\nif ( Temp > material->MaxBurn * 2 )\nBurn = material ->MaxBurn;\nelse\nBurn = ( 1.0f - ( 0.25f * Temp / material->MaxBurn ) ) * Temp;\nASSERT ( Burn <= material->MaxBurn );\nASSERT ( Burn >= 0.0f );\n// And heat the cell up from the burning.\ncell->Temp += Burn * material->BurnTemp;\n\nNote that the damage done to a cell is proportional to its actual temperature, not\nhow much heat is generated by burning. This allows materials that burn at low tem-\nperatures to nevertheless be far more severely damaged if exposed to high tempera-\ntures. By varying the factors MaxBurn and BurnTemp, burning anything can be\nsimulated—paper, wood, oil, gunpowder, or high explosives.\n\nOf course, one of the major aspects of fire is that it is hot, and thus it relies heav-\nily on the modeling of heat flow by the three methods discussed previously. In real-life\nfires, convection and radiation are incredibly important to their behavior. Convection\nmakes fires spread vertically far easier than spreading horizontally, such as across\nfloors, and leads to distinctive ‘walls of fire’ in burning buildings. Radiation concen-\ntrates fire in corners of rooms, causing fire to spread up the corners of the room first.\n\nSadly, radiative heat, as mentioned above, is extremely hard to model, and con-\nvection, although slightly more straightforward, requires large numbers of air cells\naround the source of the fire to be modeled and updated, which is expensive. It would\nbe far better to find some hacks that simulate some of these features without incurring\nthe considerable expense involved.\n\nA hack for convection effects is simply to make conduction of heat far easier in an\nupward direction. In real life, a section of burning wall heats the air beside it, which\nrises and heats the section of wall higher up. This makes it far easier for the flames to\nspread upward. Using this hack, conduction of heat is made artificially asymmetrical.\nIn the model presented above, a single factor—CconstantEnergyFlowFactor—was\nused for heat conduction for all six neighbors of a cell. Instead of this, a higher figure\nis used when conducting heat upward and a lower figure when conducting heat\ndownward.\n\nA hack for radiation is more difficult, but it is possible that some precomputation\ncould be done using the same techniques as radiosity to decide which parts of a room",
      "content_length": 2838,
      "extraction_method": "OCR"
    },
    {
      "page_number": 211,
      "chapter": null,
      "content": "212\n\nSection 2 Mathematics\n\nDynamic Update Rates\n\nwould be more susceptible to fire because of the feedback effects of radiative heat.\nOne possibility is computing the hemispherical occlusion term [Hemispherical01]\nand using that to boost the heat generated by fire—generally around edges and\ncorners.\n\nA factor that might not be immediately obvious is that these hacks are far more\ncontrollable than any realistic solution. Convection in real life is a notoriously chaotic\nsystem, and small changes in conditions can cause it to adopt very different patterns\nof flow. This can make designing gameplay around the effect very tricky indeed.\nWhat game and level designers usually require is a high degree of control and pre-\ndictability to carefully create exciting set-pieces for the player to experience. The\nhacks presented above are far more predictable and linear in their behavior, which is\nusually a far more desirable quality in a game than absolute realism.\n\nThe natures of some of the physic\nupdate rates to maintain realism. The flow of any property from one cell to another\ncan only proceed at a maximum speed of one cell per update cycle. Fire might spread\nquickly—at meters per second or faster. Water spilling from a container might move\neven faster—at tens of meters per second. Explosions require extremely high update\nrates—real-life explosion shock waves spread at the speed of sound, roughly 340 m/s.\n\nSimulating all of the above implies that update rates of 680 cycles per second\ncould be required. This is an awesome speed, and it seems unlikely that any current\nplatform can sustain these sorts of update rates for a decent-size game world.\n\nAs with the optimization of not storing or processing cells at STP, it is possible to\nuse the octree to reduce the update rates for cells that do not require fast updates to\nmaintain realism.\n\nWhen a cell is processed, it decides how fast it needs to be updated to maintain a\ngood simulation, based on its current state. Cells involved in explosions require high\nupdate rates; cells holding flowing water, burning objects, or high heat need medium\nupdate rates; cells with fairly static water require lower update rates; and cells that\nhold scenery at ambient temperature require no processing at all until disturbed.\n\nThis speed of processing is then stored in the cell and is also passed up the octree\nhierarchy, each level being marked so that it is processed at the highest update rate of\nany of its children. This then allows the update routine to start at the top node of the\noctree and recurse down the tree. At each level, it decides if the current node would\nrequire processing of the all the child nodes.\n\nOne point to note is that this system only works if the update rates are quantized\nto powers of two. For example, if a child node needs to be updated every third turn,\nbut the parent node is marked as being updated every second turn, every sixth turn\nthe child node needs updating, but the parent does not. Because of the traversal algo-\nrithm’s early-out path, the child does not get updated this time, and in the end only",
      "content_length": 3102,
      "extraction_method": "OCR"
    },
    {
      "page_number": 212,
      "chapter": null,
      "content": "2.6 Cellular Automata for Physical Modeling _ 213\n\ngets updated every sixth turn. Quantizing update rates to powers of two solves this\nproblem and also allows some slight extra storage efficiency.\n\nAn obvious consequence of this variable update rate is that the physics routines\nneed to be able to handle variable update rates as well. So far, all the code has assumed\nthat it will be run at a set speed, and that the physical constants will be adjusted to\ngive good results for that speed. With variable update rates, the physically correct\nbehavior is to integrate the various equations over the given period. However, one of\nthe purposes of the variable update rate is to choose an update rate that ensures the\ncells have a fairly constant behavior over the update interval.\n\nThis assumption makes integration simple. We just multiply the given behavior\nflow or rate by the time period since the last update. This slight extra complication is\nmore than offset by the savings in processing time and memory bandwidth because of\nthe huge reduction in the number of cells updated per second.\n\nIn many cases where the mathematics are simple, it might be more efficient to\nactually perform the integration. The extra accuracy of the simulation will then allow\nthe use of an even lower update rate, further improving speed overall.\n\nAn unexpected artifact of using a variable update rate can occur when neighbor-\ning cells have very different update rates. Since one cell is being updated much more\nfrequently than its neighbor, it can change rapidly before the other cell has time to\nreact. The solution is to limit the maximum difference in update rates of adjacent\ncells. Every time a cell is processed, as well as exchanging temperature, heat, and sim-\nilar information with neighboring cells, it also ensures that those cells are being\nupdated at least a quarter as fast as itself. We found this factor purely by experimenta-\ntion. Using a factor of two causes too many cells to have their update rates raised\npointlessly by nearby events, when in fact nothing exciting is happening to them.\nUsing a factor of eight or more allows more possible artifacts, but does not reduce the\nprocessing load appreciably. As with the many arbitrary factors that are found by pure\nexperimentation, others should experiment to find what works best.\n\nsituations rarely seen in games today. They allow the player to interact with them\nfully, flexibly, and logically, without the limitations of prescripting. This opens the\nway for more inventive puzzles, more lateral thinking by the player, more freedom to\nexperiment, more realistic rendering, and overall better immersion in the game world\nas a real place, rather than as a collection of polygonal entities.\n\n[CFD] There are innumerable references to the field computational fluid dynam-\nics. Unfortunately, most assume graduate physics knowledge or an extremely firm",
      "content_length": 2904,
      "extraction_method": "OCR"
    },
    {
      "page_number": 213,
      "chapter": null,
      "content": "214\n\nSection 2 Mathematics\n\nrasp of 3D calculus. One of the more comprehensible of these can be found at\nFeepy/ /www.efunda.com/formulae/fluids/overview.cfm.\n\n[Conway] http://www.dmoz.org/Computers/Artificial_Life/Cellular_Automata/\nConway’s_Game_of_Life/.\n\n{Hemispherical01] “Advanced Shading and Lighting,” presentation at Meltown\n2001: pp. 22-35. Available online at Attp://www.microsoft.com/mscorp/corpevents!\nmeltdown2001/ppt/DXGLighting ppt.\n\n[LorensenCline87] Lorensen, W. E. and Cline, H. E., “Marching Cubes: A High Res-\nolution 3D Surface Reconstruction Algorithm,” Computer Graphics Proceedings\n(SIGGRAPH 1987), Vol. 21, No. 4: pp. 163-169.\n\n[RedFaction] Red Faction, developed by Volicion, Inc. Published by THQ, Inc., 2000.\n\n[Ulrich00] Ulrich, Thatcher, “Loose Octrees,” Game Programming Gems, Charles\nRiver Media, Inc., 2000.\n\n[XCom] X-Com: UFO Defense (U.S.) or X-Com: Enemy Unknown (U.K.), Micro-\nprose, 1994, http://www.codogames.com/UFOUnknownDefense.htm.",
      "content_length": 973,
      "extraction_method": "OCR"
    },
    {
      "page_number": 214,
      "chapter": null,
      "content": "2.7\n\nCoping with Friction in\nDynamic Simulations\n\nMiguel Gomez\nkikomu@seanet.com\n\nYur at a playground, holding a block of wood. You stand at the base of a slide\nand shove the block of wood up the ramp. The block slides to the middle of the\nramp, reverses direction, and slides back down to the bottom of the ramp.\n\nYou place the block at the fulcrum of a balanced seesaw and grab one of the ends.\nAs you slowly tilt the seesaw, the block remains stationary at first, but then begins to\nslide down the seesaw. As you increase the tilt, the block slides faster, and eventually\nends up at your feet again.\n\nCan your physics model for friction handle all these cases correctly? For extra\ncredit, can it do all this work without resorting to strange magic numbers and toler-\nance checking?\n\nModeling dry frictional forces is an important aspect of simulating mechanical\nsystems. However, standard numerical integration schemes can fail, since friction is\ndiscontinuous with respect to velocity. This gem uses some simple one-dimensional\nexamples to provide an intuitive understanding of the Coulomb model of friction and\nto illustrate numerical problems that arise when simulating frictional systems. A\nthree-dimensional formulation is given, and a simple numerical method for comput-\ning the trajectory of an irrotational object, sliding and sticking under friction over a\nsurface of constant incline, is presented. Important issues in extending this method to\ncurved surfaces and polygonal surfaces are also discussed.\n\nto existing relative motion between two objects at their region of contact, and static\nfriction (also known as stiction), which equalizes forces tangent to the surface that\nwould otherwise initiate relative motion at a stationary region of contact. The fol-\nlowing examples illustrate the essential differences between static and dynamic\nfriction.\n\n215",
      "content_length": 1869,
      "extraction_method": "OCR"
    },
    {
      "page_number": 215,
      "chapter": null,
      "content": "216\n\nSection 2 Mathematics\n\n(peat mt Sta HON AE I 2A: AS Cae OSCE\n\nA System with Dynamic Friction\n\nFor our first example, suppose a block is placed on a flat surface. At time ¢ = 0, it\nis given an initial velocity v) > 0 in the x* (positive x) direction, as in Figure 2.7.1.\n(Note that in general, velocity is a vector. Since we are working in one dimension,\nscalar values suffice.) Experiments show that this block will decelerate at a constant\nrate until it comes to rest at some time ¢, after which it remains stationary. Further-\nmore, the rate of deceleration is independent of the block’s mass, m, and is propor-\ntional to the gravitational acceleration, g. If instead we had given the block an initial\nspeed v < 0 in the x direction, friction would have again decelerated the block until\nit had stopped. We can conclude that friction always acts opposite the velocity, v, of\nthe block and that friction exerts no force on the block when v = 0. This implies that\na correct formulation of dynamic friction for this one-dimensional system is:\n\n—sgn(v)u,N when v # 0\n= (2.7.1)\n\n0 when v = 0,\n\nwhere |, is the coefficient of dynamic friction and N is the magnitude of the normal\nforce; that is, the force exerted on the object by the surface in the normal direction (z*\nin this example). Equation 2.7.1 constitutes a one-dimensional formulation of\ndynamic Coulomb friction [Stewart00]. Even though our block exists in the x and z\n\nN= -Fg=mg\n\nFIGURE 2.7.1 A block set in motion on a flat surface will decelerate at a constant rate\nuntil it comes to rest. This rate of deceleration is proportional to gravitational\nacceleration by the coefficient of dynamic friction Ly.",
      "content_length": 1670,
      "extraction_method": "OCR"
    },
    {
      "page_number": 216,
      "chapter": null,
      "content": "2.7 Coping with Friction in Dynamic Simulations 217\n\naxes, friction is represented as a scalar value, so it’s okay in this simple example to\nthink of friction as a one-dimensional force.\n\nIn this example we assume the block has no motion along the z direction; there-\nfore, the net force in this direction is zero, and N must be exactly equal and opposite\nthe gravitational force mg. By Newton's second law we know that x(z), the x position\nof the block as a function of time ¢, satisfies the system of differential equations:\n\na) = ot) (2.7.2a)\nL\nd’x(t)  do{t\n\nSuppose again that vy > 0. Since v will not change sign before the block stops, the\nsgn(v) term can be omitted, and Equation 2.7.2b can be integrated directly to yield an\nexplicit formula for v(2):\n\nv{t) t\ndv = -{ Ljgat => v(z) = vy — Mgt. (2.7.3)\nC7) 0\nIf the initial x-position of the block is xp = 0, integrating Equation 3 gives\nx(t) t\n[ dx = [ vy — Hygtat = x(z) = Uot — + Ma&t- (2.7.4)\nThe exact time and position at which the block comes to rest are:\n= % (2.7.5a)\nHig\nand\n2\nx, = x(z,) = +20 (2.7.5b)\n2 Hig\nrespectively. For all times ¢ 2 ¢,, the block has stopped; in other words, the solution is\nsimply:\nx(¢) = x,,and o(z) = 0. (2.7.6a, b)\n\nThe position, velocity, and acceleration of the block over time are plotted in Fig-\nure 2.7.2. Notice that the acceleration of the block has a jump discontinuity (an\ninstantaneous change in value) at ¢,. This discontinuity must be taken into account when\nwe develop a numerical method for computing the trajectory of the block.\n\nCoefficients of friction depend on both the apes of surfaces and on the condition\nof the surfaces in contact. See [Beer62] for a table of static friction coefficients for\nsome common surfaces.",
      "content_length": 1732,
      "extraction_method": "OCR"
    },
    {
      "page_number": 217,
      "chapter": null,
      "content": "218 Section 2 Mathematics\n\nserena vnc re yer RLSM: MA RNA A SRD HRN REE RT ER\n\n4 xv\n\n(b) t\n\n“h a9 ——e\n\n(c)\n\nFIGURE 2.7.2 Plots of (a) position, (b) velocity, and (c) acceleration of a block sliding along a\nflat surface subject to friction. Acceleration goes to 0 instantaneously when v = 0 at time t,,\n\nA System with Static Friction\n\nSuppose now that our block is placed on a platform at an incline @ > 0; and for\nsimplicity, let the x-axis be aligned with the platform and the z-axis point in the nor-\nmal direction. Assume that the block is initially stationary, as in Figure 2.7.3. For\nmost, if not all dry surfaces, there exists some angle @, > 0 below which the block\nremains stationary and above which the block begins to slide. Static friction can there-\nfore be thought of as a constraint force that must satisfy:\n\nFf. <u; (2.7.7)\nwhere is the coefficient of static friction.\n\nFirst, suppose that the incline of the platform is at an angle @ < @, so that the\nblock is stationary. This implies that the frictional force is equal and opposite the x\ncomponent of the gravitational force. When @ = @,, static friction is at its maximum\npossible value (the authors of [Pfeiffer92] refer to this state as “friction saturation”) so\n\nthat\nfi = UN. (2.7.8)\n\nThis implies the relationship",
      "content_length": 1286,
      "extraction_method": "OCR"
    },
    {
      "page_number": 218,
      "chapter": null,
      "content": "220\n\nSection 2 Mathematics\n\nIt might seem that the explicit formula for x(z) derived above could be used to cal-\nculate the exact position at the times we want to display the particle. Unfortunately,\nthis approach only works for flat surfaces. For a general curved surface, an explicit for-\nmula cannot be found, so we are forced to find a time-stepping scheme that gives the\nposition at subsequent times.\n\nWe'll start by implementing friction naively and see why discontinuity of acceler-\nation is a real problem when implementing game code. Then, we'll change our fric-\ntion model slightly to try to work around the acceleration problem. Last, we'll\npropose an altogether better mathematical model that takes care of these problems\nfor us.\n\nFirst Approach: Euler’s Method\n\nConsider the first example: a block sliding on a flat surface. Given the position x(2)\nand velocity v(¢) at time ¢, we might try to calculate the position and velocity of the\nblock at a later time, ¢ + 4, in the following way:\n\nx(t +h) = x(t) + hor) (2.7.10a)\n\n)\n\no(t +h) = oft) - A sgn(o(e))u ag (2.7.10b)\n\nThis intuitive approach is called Euler's method [Gerald97]. Due to its simplicity\nand speed, this is the integration method of choice for many game programmers.\n\nLet x = 0, u% = 1, m= 1, By= 1, g= 9.81, and 4 = 0.02. The exact solution indi-\ncates the block will come to rest after ¢, = 0.10194 seconds at a position x, = 0.05097\nmeters. Table 2.7.1 gives the numerical output of Euler’s method for this initial value\nproblem.\n\nTable 2.7.1 Positions and Velocities Resulting from Euler's Method for a Block Slid-\ning on a Flat Surface\n\nt x(t) v(t)\n\n0.00 0.00000 1.0000\n0.02 0.02000 0.8038\n0.04 0.03608 0.6076\n0.06 0.04823 0.4114\n0.08 0.05646 0.2152\n0.10 0.06076 0.0190\n0.12 0.06114 0.1772\n0.14 0.05760 0.0190\n0.16 0.05798 0.1772\n0.18 0.05443 0.0190\n\nNote: The numerical values never converge due to the discontinuity of acceleration at v = 0.",
      "content_length": 1926,
      "extraction_method": "OCR"
    },
    {
      "page_number": 219,
      "chapter": null,
      "content": "2.7 Coping with Friction in Dynamic Simulations (221\n\nNumerical calculations nearly stop the block after about 0.1 seconds at 0.061\nmeters. Since Euler’s method is only first-order accurate, some error should be\nexpected. What is alarming, however, is that not only does v never converge to zero,\nbut it oscillates about zero asymmetrically so that x actually decreases at a constant rate\nfor times ¢ > ¢. An animation would show the block turning around and moving back\ntoward the origin! .\n\nIt might seem practical to solve this problem by simply setting v to zero when its\nmagnitude falls below some threshold v, > 0. Unfortunately, tuning these types of\n‘magic numbers’ so that a particular system looks intuitively correct is an art. Finding\nvelocity thresholds that work for simulations involving several objects of different\nmasses and friction coefficients requires a lot of time and testing. In essence, it’s nec-\nessary to test each object affected by friction against every surface type on which it\nmight possibly rest. We've simply traded one problem for another, less-tractable one.\nAs we shall see later, velocity thresholds cause more serious problems when evaluating\ntransitions between dynamic and static friction.\n\nSecond Approach: Reformulating Friction\n\nIn retrospect, it now seems obvious that Euler's method would fail for this problem.\nWhen 1 is ‘small,’ our integration method will cause v to overshoot zero and change\nsign. On the following step, acceleration is in the opposite direction, which causes v\nto change sign again. Since v oscillates asymmetrically about zero, the position gets a\nnet translation every two steps.\n\nInstead of fixing the numerical method, we might be tempted to modify our for-\nmulation so that friction is continuous at v = 0. One option is to replace the Coulomb\nformula with viscous damping:\n\nf =-m,N. (2.7.11)\n\nUnfortunately, this formula will cause the block to decelerate too quickly at high\nspeeds and not quickly enough at low speeds. Animations using this formula simply\n\nlook unnatural.\nAnother possibility is to regularize friction (see [Abadie00] or [Stewart00]) so that\n\n-~u,N , when | Sv,\nfai % (2.7.12)\n\n—sgn(v)u,N , when b| >v,,\n\nfor some velocity threshold v, > 0. This formulation resolves the counterintuitive\nbehavior observed at high speeds but has the same problems as viscous damping at\nlow speeds. Furthermore, v, is just another magic number that must be tuned to the\nparticular system. More importantly, these alternate formulations cause problems\nwhen transitioning (either way) between dynamic and static friction.",
      "content_length": 2595,
      "extraction_method": "OCR"
    },
    {
      "page_number": 220,
      "chapter": null,
      "content": "222\n\nSection 2 Mathematics\n\ncee rN ASE aR BR NE No sesame canes Et ah EES I NRE HABE\n\nThird Approach: Dealing with Nonsmoocthness\n\nIt is possible to find a numerical method that works well, provided we understand\nwhat is going wrong. The trajectory x(t) of our sample problem has two smooth\ndomains (a function x(2) is smooth if its first derivative is continuous and exists every-\nwhere):\n\n—t1 2\nx2) _ Jot — 3 sgn(v)u, gt , whent <¢, (2.7.13)\nx , when 2 ¢,\n\ns\n\nThe function x(z) and its derivative v(t) are both continuous at ¢, but acceleration\na(t), the first derivative of v(2), is not. Euler's method, along with higher-order meth-\nods, assumes that the function x(¢) has a Taylor series on the interval over which we\nare integrating [Gerald97]. This system, however, does not satisfy this property in a\nneighborhood of t, where v goes to zero and the discontinuity occurs. Therefore, any\nmethod that assumes a valid Taylor series for x(¢) will not converge to the correct\nsolution.\n\nSuppose that our current time is ¢ < ¢, and that we want to calculate the position\nat some later time ¢ + 4 < ¢. Over this interval, x(¢) does have a valid Taylor series, so\nwe can expand x(t + 4) in 4 about ¢ to get\n\ndx(t d’x(t\nx(z + h) = x(t) +h at) + ip 4) = x(t) + ho(t) - 1p? sgn(v) yg. (2.7.14)\n\nThe Taylor series for v(t + 4) is\n\nmG + h) = v(t) +h a) = (+) - hsgn(v) zg . (2.7.15)\n\nTogether, these two equations form a Taylor method [Gerald97]. Provided we\nintegrate over time intervals [¢, ¢ + A] that satisfy ¢+ 4 < 4, this method is exact for our\nblock on a flat surface at any incline.\n\nDuring any interval, we know that v will go to zero if the quantity\n\nh, = v (2.7.16)\nsgn(v) 4g\nsatisfies\n0<h <h, (2.7.17)\n\nIf 4, satisfies this inequality at any particular step, we must set v = 0, and consider\nx(t + A,) the position of rest. In general, if the block has acceleration a(t), our method\n\nhas the form\nx(t + h) = x(t) + holt) + 1 ha) (2.7.18a)\n\nv(t +h) = o(r) + ha(z) . (2.7.18b)",
      "content_length": 1980,
      "extraction_method": "OCR"
    },
    {
      "page_number": 221,
      "chapter": null,
      "content": "2.7 Coping with Friction in Dynamic Simulations\n\n223\n\nAt every step, we check to see if 4, satisfies\nt\n0<h/ = _ ot) <h. (2.7.19)\n\nWhen applied to our test system, this approach gives much better results. In fact,\nTable 2.7.2 shows that ¢, and x, are exact, but more importantly, v(t) = 0 for ¢2 ¢,.\n\nTable 2.7.2. Positions and Velocities Calculated with a Taylor Method\n\n0.00000 0.00000 1.0000\n0.02000 0.01804 0.8038\n0.04000 0.03215 0.6076\n0.06000 0.04234 0.4114\n0.08000 0.04861 0.2152\n0.10000 0.05095 0.0190\n0.10194 0.05097 0.0000\n0.12194 0.05097 0.0000\n\nNote: Positions and velocities calculated with a Taylor method are exact for our test system. Calculating\nan intermediate time step /, ensures that velocity goes to zero and stays there.\n\nTransitioning Between Static and Dynamic Friction\n\nThe previous approach handles only dynamic friction. On slopes, we must evaluate\nwhether or not a transition between static and dynamic friction will occur. When v #\n0, friction is dynamic by definition, so we only need to consider these transitions\nwhen v = 0.\n\nRecall the example of Figure 2.7.3. For inclines @ > @, the block will decelerate to\nan apex, then slide back down. But for 0 < @,, it will stop at its apex and remain sta-\ntionary. If the block is stationary and the forces on the block are changing over time,\nthen we must periodically check to see if static friction can equalize tangential forces\nso that the block remains stationary. In other words, if the net tangential force does\nnot satisfy the inequality\n\n—uN<E< MN; (2.7.20)\nthen the block begins to slide.\n\nThere is an important subtlety, however, that must not be overlooked. When the\nblock transitions from static to dynamic friction, its velocity is zero; so the direction\nof dynamic friction cannot be determined. Since the impending motion willbe in the\ndirection of F,, dynamic friction must therefore act opposite to F..\n\nIt is now easy to see why velocity thresholds cause problems when transitioning\nfrom static to dynamic friction. Upon the first application of dynamic friction, veloc-",
      "content_length": 2065,
      "extraction_method": "OCR"
    },
    {
      "page_number": 222,
      "chapter": null,
      "content": "224\n\nSection 2 Mathematics\n\nsere\n\nity goes from zero to some value v(t + 4). If |v(t + 4)| < v,, our minimum allowable\nvelocity, then v is set back to zero. However, since a(t) # 0, x(t+ 4) will advance some-\nwhat. If velocity consistently fails to rise above v,, then the block will slowly creep\ndown the slope at a constant speed. For any configuration of 0, 4 and v,, there exists\nsome minimum time step /,,;, below which creep will occur.\n\nWe can now formulate dynamic friction in three dimensions:\n\n—u,Nv whenv #0\nf, = (2.7.21)\n\n—,NE, when v = 0,\n\nwhere E, is the direction of the tangential component of the net force on the object.\nThis formulation is consistent for transitions from static to dynamic friction. Friction\nf, is now a vector. We assume that velocity has no normal component so that the unit\nvector V is tangent to the contact surface. The normal force is the vector N = Nan,\nwhere n is the unit normal direction.\n\nWhen v = 0, static friction tries to counter tangential forces, and its magnitude\nmust satisfy\n\nf=\n\nThe interpolated Taylor method derived above will still work, provided we can\naccurately predict whether or not v goes to zero during the integration interval.\n\nDue to the nonlinearity of the three-dimensional problem, we cannot solve for 4,\nexactly, so we must find some way of estimating its value. The time rate of change of\nthe square of the magnitude of velocity is\n\nad 2 ad ay\n\nial =“f{y-.v)=2v-—=2a- 2.7.23\na | v(2) | a (v v) 2v a 2a-v. (2.7.23)\nIf we assume that the acceleration a and the direction of velocity is constant over\n\nthe interval [z, ¢ + 4], then only the magnitude of velocity changes over time. We can\nintegrate Equation 2.7.23 to find 4;\n\n< u,N. (2.7.22)\n\ni 2a-vdt=2a a vat=2a -(x(¢ + h) - x(+)) =2a- Ax, (2.7.24)\n\nSince we are assuming the direction of v is constant and its magnitude decreases\nat a constant rate, we get\n\n2a: Ax =2a- 3 vA, =a-vh., (2.7.25)\nIf this rate of change is negative, then we get\nhb, =-—— (2.7.26)\n\nso .\na:v",
      "content_length": 1994,
      "extraction_method": "OCR"
    },
    {
      "page_number": 223,
      "chapter": null,
      "content": "2.7 Coping with Friction in Dynamic Simulations 225\n\nThis reduces to the one-dimensional formula when v and a are in the same\ndirection.\n\nGeometric issues\n\nSmoothness\n\nOne common way to represent a two-dimensional surface is as a polygonal mesh.\nAnother common representation is the heightfield, in which elevations of a surface are\nstored over a regularly spaced grid. Unfortunately, both of these representations can\nlead to convergence problems if discontinuities in slope are not properly dealt with.\n\nConsider the example illustrated in Figure 2.7.4. When the block hits the slope,\ngravity will instantaneously change from acting solely along the normal direction to\nhaving a component opposite friction, and the net acceleration will experience a jump\ndiscontinuity. If this is not dealt with properly, it can lead to the same convergence\nproblems described here.\n\nFIGURE 2.7.4 A block sliding along a flat surface will experience a discontinuity in tts\nacceleration when the slope suddenly changes.\n\nOne possible remedy is to interpolate the position and velocity to the point at\nwhich the change in slope occurs. For a heightfield, this might be practical; but it\ncould be inefficient for arbitrary polygonal meshes. This approach might also cause\nproblems for an implementation that treats impacts (which involve instantaneous\nchanges in velocity) generally.\n\nAnother possibility is to smooth the surface so that its directional derivative (see\n[Davis91]) is continuous. For a heightfield, this would require quadratic spline inter-\npolation (see [Watt00]) along the x and y directions. For arbitrary polygonal meshes,\na subdivision scheme might be required.\n\nThe best approach must be decided by the application developer, but the effects\nof discontinuities in acceleration on the convergence of the method should be kept in\nmind.",
      "content_length": 1840,
      "extraction_method": "OCR"
    },
    {
      "page_number": 224,
      "chapter": null,
      "content": "226\n\nSection 2 Mathematics\n\nCurvature\n\nThough we now have a good model for representing frictional forces operating on flat\nsurfaces, extending this model onto curved surfaces is nontrivial. If you want to try to\nextend it, note the following: When the surface curves upward, integration will push\nthe object into the slope and give v a component normal to the surface. This can be\ndealt with by simply resetting the position of the object and removing the normal\ncomponent of velocity following the integration step.\n\nWhen a surface curves downward, however, it must be decided whether or not\nthe object should leave the surface. Although not very robust, using a velocity thresh-\nold on the normal component of velocity seems to be the most common approach.\nWhen using this approach, these thresholds must be adjusted to get the desired\n\nbehavior.\n\nConclusion\n\ni BTR 0 aA RA NN BN AOE SIT SB AME RR\n\nReferences\n\nWe have used some simple one-dimensional examples to illustrate the Coulomb\nmodel of friction. We have also explored reasons why certain numerical methods are\ninsufficient, and we have developed a simple but effective numerical method for com-\nputing the three-dimensional trajectory of an object sliding over a surface of constant\nincline. Now, go build yourself a playground!\n\n[Abadie00] Abadie, Michel, “Dynamic Simulation of Rigid Bodies: Modeling of\n\nFrictional Contact,” Impacts in Mechanical Systems: Analysis and Modeling, Springer-\nVerlag, 2000.\n\n[Beer62] Beer, F. P. and Johnston, E. R., Jr., Mechanics for Engineers: Statics and\n\nDynamics, McGraw-Hill, 1962.\n\n[Davis91] Davis, H. E and Snider, A. D, Introduction to Vector Analysis, 6th\n\nEdition, Wm. C. Brown Publishers, 1991.\n\n[Gerald97] Gerald, C. E and Wheatley, P. O., Applied Numerical Analysis, 6th\n\nEdition, Addison Wesley, 1997.\n\n[Pfeiffer92] Pfeiffer, F and Hajek, M., “Stick-Slip Motion of Turbine Blade-\nDampers,” Philosophical Transactions: Physical Sciences and Engineering, Nonlin-\near Dynamics of Engineering Systems, 1992: Vol. 338, No. 1651, pp. 503-517.\n\n[Stewart00] Stewart, D., “Rigid-Body Dynamics with Friction and Impact,” SIAM\nReview, 2000: Vol. 42, No. 1, pp.3-39.\n\n[Watt00] Watt, A., 3D Computer Graphics, 3rd Edition. Addison Wesley, 2000.\n\nSOREN ARTES EE TTT ON IRIAN",
      "content_length": 2271,
      "extraction_method": "OCR"
    },
    {
      "page_number": 225,
      "chapter": null,
      "content": "3.1\n\nOptimized Machine Learning\nwith GoCap\n\nThor Alexander, Hard Coded Games\nthor@hardcodedgames.com\n\nachine learning is an emerging technology that will make a big impact on the\n\nway games are made in the future. From a production standpoint, machine\nlearning will bypass need for the thousands of lines of brittle, special-case AI logic that\nis used in many of today’s games. Training a computer-controlled character by observ-\ning a human, expert player will bring great advances in the level of intelligence that\ncan be displayed. Game designers will be able to role-play the personalities of a wide\narray of characters, which can be stored in libraries and then later imported into their\ngames like traditional content assets.\n\nThis gem presents an optimized version of GoCap, a method we developed to\ntrain Al characters by observation [Alexander02]. Think of it as ‘motion-capture for\nAI.’ Some figures contained in this gem are shown using UML (Unified Modeling\nLanguage) notation. For an in-depth discussion of UML, see [Booch98].\n\nGoCap Architectural Overview\n\nTo employ GoCap, we need to engineer our system to record the inputs to the system\nas a human plays the game, and then map them to the action that the player chooses\nto execute, and under the current simulation conditions. To make this useful, we will\nhave to build the game in such a way that a human trainer can play all of the game\nactors, including the enemies. To do this, we must first define a few classes to support\n\ntraining.\n\nActionState\n\nAn ActionState is an atomic element of a finite-state graph. It stores the legal transi-\ntions that it can make to other action states in a transitionList. The ActionState\nalso maintains an ActionRuleSet that enumerates all of the rules under which the\nstate should be used. Each ActionRule has its own Evaluate() method that computes\nand returns some game-related value that defines the rule (see Figure 3.1.1).\n\n231",
      "content_length": 1937,
      "extraction_method": "OCR"
    },
    {
      "page_number": 226,
      "chapter": null,
      "content": "Section 3 Artificial Intelligence\n\nL ActionState actionRuleSet\n\ntransaction List\n+AllRulsFired() : boolean\n+GetReleventTangent Set()\n+GetRuleSet() :actionRuleSet\n+Transistion() +RemoveRule() : boolean\n\nFIGURE 3.1.1 Class diagrams for ActionState with actionRuleSet and actionfule.\n\nActor Class\n\nAn actor is a simulation object that is capable of interacting with the game environ-\nment. Each actor has a control state that defines if the actor is currently under player\ncontrol, AI control, or is in the training state. The control state can be swapped on the\nfly to transition the actor between one of these states. The actor’s PerformAction()\nmethod will delegate processing to the current control state, which will determine the\ndesired ActionState to transition to.\n\nContro(State\n\nA Controlstate defines from where the associated actor can accept commands. When\nin a training state, the player controls the actor, as in the user-controlled state; except\nnow, the computer can observe and learn from the actor's actions.\n\n[Actor ControlState\n+PerformAction() +PerformAction()\n+RequestAction() +RequestAction()\n+SwapControlState()\n\noo\n[ UserControlState AlControlState TrainingState\n-ActionRequestQueue -ControlStateAuto : AlControlState\n+ClearActionRequestQueue() -ControlStateUser : UserControlState\n-DequeueActionRequest() +PerformAction()\n\n+PerformAction() +RequestAction()\n-QueueActionRequest() -Train() : boolean\n\n+RequestAction()\n\n—\n\nFIGURE 3.1.2 Controlstate class hierarchy.\n\nUserControlState\n\nFor use in client/server environments, the UserControlState maintains a queue of\npending action requests that have been received from the player. This control state’s\nPerformAction() method will pull requests from this queue when it is called. The",
      "content_length": 1752,
      "extraction_method": "OCR"
    },
    {
      "page_number": 227,
      "chapter": null,
      "content": "3.1 Optimized Machine Learning with GoCap 233\n\nqueue can be replaced with an immediate request-handling method if the training\nenvironment runs locally, without need of a server.\n\nAlControiState\n\nThe AlControlState is responsible for determining the appropriate action to perform\nwhen an actor in this state calls its PerformAction() method. The example presented\nin here implements a rule-based AI decision system encoded with hash maps.\n\nTrainingControlState\n\nThe TrainingControlstate adds a private Train() method that it will use to learn\nunder which conditions to transition to a given ActionState.\n\nCar To Drive\n\nose\n\nMURR ERNLINRENBR RR\n\nTo illustrate how GoCap works, we present the example of driving a toy car around\nsome obstacles and the car’s learning when to turn to avoid the obstacles. This exam-\nple will also illustrate the process of mapping action states to the rules that detail\nwhen to use them.\n\nDefining Action States\n\nOur toy car has five basic action states that define the operations that it can perform\nand limit the transitions between them. Table 3.1.1 enumerates the states, and Figure\n3.1.3 depicts the transitions between them, shown as arrows.\n\nTable 3.1.1 Action States for Driving a Car\n\nAction State Description\n\nStop Stop the car from moving (default state).\nMoveFwd Move the car forward in the direction it is facing.\nTurnRight Steer the car to the right.\n\nTurnLeft Steer the car to the left.\n\nMoveBwd Back the car up.\n\nOnce we have defined the states, we will need the transitions between them so\nthat we can build the classes to implement them. Figure 3.1.4 shows the class diagram\nfor these action states. Each state can be encapsulated in its own instance of an\nActionState. Note that this implementation yields a state graph containing the legal\ntransitions between states, but it does not embed any knowledge of when to make\nthose transitions.",
      "content_length": 1888,
      "extraction_method": "OCR"
    },
    {
      "page_number": 228,
      "chapter": null,
      "content": "234\n\nSection 3 Artificial Intelligence\n\nTurnRight\n\nTurnLeft\n\nFIGURE 3.1.3 Action states for driving and the transitions between them.\n\nActionState\n| Cid\n[ t—“C;i‘“CC*dzC\n\nMoveFwd MoveBwd\n\nTurnRight\n\n|\nLd\n\nFIGURE 3.1.4 Class diagram for movement action states.\n\nDefining Rules\n\nNow we need to determine the rules that will detail when our car can transition to\nthese action states. Each ActionState is associated with an ActionRuleSet that con-\ntains the rules under which we can use the state (see Figure 3.1.1). Each ActionRule\nhas its own Evaluate() method that computes and returns some game-related value.\nFor our car, we will define six sensors that will detect proximity to possible collisions.\nEach of these sensors will be implemented with an Evaluate() method. These methods\nwill cast a ray from the car’s origin, out in the sensor direction. If the sensor collides\nwith an obstacle, then the method will compute distance to the obstacle and return the",
      "content_length": 961,
      "extraction_method": "OCR"
    },
    {
      "page_number": 229,
      "chapter": null,
      "content": "3.1. Optimized Machine Learning with GoCap\n\n235\n\nproximity as 1/distance, ensuring that the distance is always greater than or equal to 1.\nThis yields a floating-point proximity value from 0.0 to 1.0. Table 3.1.2 details the\n\nsensors we will use. Figure 3.1.5 illustrates how these probes will be attached to our car.\n\nTable 3.1.2 Sensors for detecting collisions.\n\nSensor Description\nFWD Probe forward directly in front of the car.\n\nFWD-L Probe forward to the left of the car.\nFWD-R Probe forward to the right of the car.\n\nLEFT Probe left of the car.\nRIGHT Probe right of the car.\nBWD Probe directly behind the car.\n\nFIGURE 3.1.5 Attaching sensors probes to a car.",
      "content_length": 665,
      "extraction_method": "OCR"
    },
    {
      "page_number": 230,
      "chapter": null,
      "content": "236 Section 3 Artificial Intelligence\n\nTurnLeft\n\ncic\n\nFIGURE 3.1.6 Rules for the TurnLeft behavior.\n\nWith our Evaluate() methods encapsulated in each rule, we can now build the\nActionRuleSet for each ActionState. Figure 3.1.6 depicts the TurnLeft action state\nwith its associated six sensor rules. Figure 3.1.7 shows the class diagram for the Turn-\nLeft state and rules.\n\nLearning the Rules\n\nSARA RO ERNE RETRACING\n\nNow, we are ready to train our car’s rules. We do this by swapping the car’s actor to the\ntraining control state with a human player in the driver's seat, as described here.\nPseudo code is provided to illustrate the process.\n\nHRM OR RRR ANB RB HEIST ANAS RATERS TORSO LACES TENANT ERE ERNE\n\nActor. SwapControlState( TrainingControlState )",
      "content_length": 754,
      "extraction_method": "OCR"
    },
    {
      "page_number": 231,
      "chapter": null,
      "content": "3.1 Optimized Machine Learning with GoCap 237\n\nActionRuleSet\n\nStop | MoveFwd TurnLeft TurnRight\nLe\nLd PT LT\n\nFIGURE 3.1.7 Class diagram for TurnLeft ActionState rules.\n\nWhen the player steers to avoid obstacles, the training actor is informed of the\naction requests. The TrainingControlState will allow the user control state to per-\nform the requested steering action as normal, but it will grab the resulting Action-\nState and pass it to the Train() method.\n\nTrainingControlState:PerformAction( Actor )\n\n{\nActionState = UserControlState.PerformAction()\n\nTrainingControlState.Train( ActionState )\n\nCluster Maps for Floating-Point Valued Rules\n\nTo allow us to dynamically train the rules, each rule has a ClusterMap associated with\nit. A cluster map is a one-dimensional, spatial-partitioning data structure. This struc-\nture can be partitioned into a number of cells that provide coverage appropriate to the\ndomain of the associated rule. To cover our Evaluate() method’s domain of 0.0 to\n1.0, we will use a 10-cell cluster map. If we required greater precision to cover the rule\ndomain, we could increase the number of cells. A 10-cell cluster map can be imple-\nmented as a hash map that is indexed by an integer key value between zero and nine.\nFigure 3.1.8 shows the related classes.\n\nThe ClusterMap class provides a CalculateIndex() method that can perform an\nindex calculation on the floating-point value returned by the Evaluate() method to\ntransform it into an integer representation. This gives us the hash map key that corre-\nsponds to the evaluation value. We can feed this key to the Lookup() method on the\nClusterMap class to get the individual Cluster object that represents the cell. The\ncluster map serves to round off or quantize the floating-point input value so it fits into\nthe nearest cell.\n\nTrainingControlState:Train( ActionState )\n{",
      "content_length": 1856,
      "extraction_method": "OCR"
    },
    {
      "page_number": 232,
      "chapter": null,
      "content": "Section 3 Artificial Intelligence\n\nActionRule [ ClusterMap Cluster\n[>———-hashMap -firingThreshold\n-Evaluate() +CalculateIndex():int -trainingMarkerCount\n+Fire() +Hashindex() +Fire()\n+Reinforce() +Lookup() +Reinforce()\n\nFIGURE 3.1.8 Class diagram for ClusterMap.\n\nFor Rule in ActionState.GetRuleSet {)\nClusterMap = Rule.GetClusterMap()\nValue = Rule.fEvaluate( Actor )\nIndex = ClusterMap.CalculateIndex( Value )\n\nKey = ClusterMap.HashIndex{ Index )\n\nCluster = ClusterMap.Lookup( Key )\nCluster.Reinforce()\n\nEnd For\n\n}\n\nThe Reinforce() method is where the actual training occurs. Each Cluster\nmaintains a trainingMarkerCount that is incremented during training. This marker\nindicates that the player activated this action rule with this evaluation value. As the\nplayer feeds more input into the training system, we will get more values that fall into\nthis cluster. Every time we get a hit in the cluster, we increment the marker count\nuntil it reaches some preset firing threshold. We add this threshold to account for\nnoise or error in the input data. In practice, you might need to set this threshold sig-\nnificantly high if your training data is prone to noise or error.\n\nCluster: Reinforce({)\n\n{\ntrainingMarkerCount ++\nIf trainingMarkerCount > firingThreshold then\ntrainingMarkerCount = firingThreshold\nEnd If\n}\n\nEarly in our training, the cluster maps will only contain a few training markers.\nAs training goes on, more data flows into the system, and more rules are learned.\nEventually, we will tend to reach a point of equilibrium where we have learned all of\nthe rules that match the input action choices. We can detect this equilibrium by com-\nparing the player’s input against the action that the AIControlstate would pick itself.\nWhen they match on a continuing basis, we can signal the player to stop training.\n\nSwapping Control to the Al\n\nNow that we have a fully trained rule set, we can detach our human trainer and swap\nto AI control. When the actor performs its next action, it calls on its decision process\nand newly trained rules to determine its course of action.",
      "content_length": 2079,
      "extraction_method": "OCR"
    },
    {
      "page_number": 233,
      "chapter": null,
      "content": "3.1 Optimized Machine Learning with GoCap 239\n\nActor .SwapControlState( AIControlState )\nActionState = Actor.PerformAction( )\nIf ActionState Is Not None Then\nCurrentState = Actor.GetCurrentActionState()\nCurrentState.Transition( ActionState )\nEnd If\n\nThe cluster's Fire() method can now test the evaluation values against the train-\ning markers in the cluster map. If a rule evaluates to a value that falls into a cluster\nthat has enough markers to reach the threshold, then that rule fires. If all of the rules\n\nin the rule set fire, then the associated ActionState is returned for activation.\n\nAIControlState:PerformAction( Actor )\n\n{\nfired = 0\nActionState = Actor.GetCurrentActionState()\nFor Action in ActionState.GetTransitions()\nFor Rule in Action.GetRuleSet()\nClusterMap = Rule.GetClusterMap()\nValue = Rule.Evaluate( Actor)\nIndex = ClusterMap.CalculateIndex(Value)\nKey = ClusterMap.HashIndex( Index )\nCluster = ClusterMap.Lookup( Key )\nIf Cluster.Fire() Then\nfired++\nEnd If\nEnd For Rule\nIf fired = Action.GetRuleSet().Count() Then\nReturn Action\nEnd If\nEnd For Action\nReturn None\n}\n\nConclusion\n\ned\n\nAE sk NOUR RRO A ATER AER ATS SEER\n\nThis gem outlined an implementation of GoCap using hash maps for the dynamic\nlearning of rule clusters. This enhancement provides a significant performance\nincrease over the previous version, which used sparse arrays. The nested structure of\nthe AI decision loop makes it a good candidate for further optimization with SIMD\ntechniques, but that is a story for another day.\n\nan SARE ORR REAR ROSEN Ti FSR RS RENT SCE\n\n[Alexander02] Alexander, Thor, “GoCap: Game Observation Capture,” Al Game\nProgramming Wisdom, Charles River Media, Inc., 2002.\n\n[Booch98] Booch, Grady, The Unified Modeling Language User Guide, Addison Wes-\nley, 1998.\n\nAe RN",
      "content_length": 1780,
      "extraction_method": "OCR"
    },
    {
      "page_number": 234,
      "chapter": null,
      "content": "3.2\n\n240\n\nArea Navigation: Expanding\nthe Path-Finding Paradigm\n\nBen Board and Mike Ducker,\nDogfish Entertainment\nben_board@yahoo.com, mike@ducker.org.uk\n\nPah indne constitutes one of the primary areas of game AI and is a major con-\ncern in almost all modern computer games. The simple act of producing a route\nfrom A to B could introduce a significant CPU hit, depending on the complexity of\nthe world and the manner in which the task is broken down. The traditional\napproach to solving the path-finding problem involves placing nodes across the game\nworld and connecting them by edges, where the direct route linking any two points is\nfree from obstruction.\n\nThe placement of these nodes can be achieved in many ways: by the level designer\nas part of the design process, by a procedural method as part of an export process, or\nby the nature of the game world in which the environment might be split into some\nset of formalized shapes, such as a tile map.\n\nOnce the world is deconstructed into nodes and connections, path-finding is nor-\nmally carried out by some form of heuristic search to discover the list of connections that\nwould provide a route from a character's start point to their goal. Arguably, the most pop-\nular form of heuristic search in computer games today is A*, an explanation of which can\nbe found in [Stout00] or on various gaming Web sites throughout the Net. This algo-\nrithm simply expands the best node in the current list until the goal node is reached or no\nvalid nodes remain to be expanded (i.e., the attempted path-finding has failed).\n\nThis gem presents a paradigm shift in the way a given world is deconstructed for\npath-finding. Rather than using nodes as the fundamental components of path-finding,\nit is suggested that regions of the environment be segregated into areas, each represented\nby one node in the search space, and that these areas be connected to one another if nav-\nigation between them is possible. Upon implementation of this paradigm in our game,\nwe will have profited from significant improvements in the following areas:\n\n¢ Speed and storage efficiency due to a huge decrease in nodes used in the search\nalgorithm.\n\n¢ Realistic movement—by moving from area to area, individuals are not restricted\nby unnecessarily precise waypoints.",
      "content_length": 2287,
      "extraction_method": "OCR"
    },
    {
      "page_number": 235,
      "chapter": null,
      "content": "3.2 Area Navigation: Expanding the Path-Finding Paradigm 241\n\nTraditionally, path-finding has used the waypoint as its fundamental component for\nthe traversal of a simulated environment. By deconstructing the world into a series of\nconnected nodes (connections exist between a pair of nodes if those nodes can be nav-\nigated without obstruction), the world can be viewed as a graph of vertices and edges,\nthus allowing state-space searches and graph theory to be directly applied. An intro-\nduction to graph theory can be found in [Sedgewick89].\n\nThis abstraction from a complex environment, possibly containing detailed 3D\nmodels obstructing much of the landscape, allows simple, yet powerful algorithms to\nconnect two geographically dispersed points by the shortest possible route.\n\nWhile the node is a sensible choice for performing state-space searches, given its\nsimilarity to the vertex in graph theory, it lends itself rather easily to certain common\nscenarios where its straightforward use can lead to inefficiency. Imagine the simplest\nform of environment—a 2D tile map. Figure 3.2.1 shows a simple tile map contain-\n\nFIGURE 3.2.1 A simple tile map for a 2D world. Light areas are walkable,\ndark areas are unwalkable.",
      "content_length": 1226,
      "extraction_method": "OCR"
    },
    {
      "page_number": 236,
      "chapter": null,
      "content": "242\n\nSection 3 Artificial Intelligence\n\ning two types of terrain: walkable (light) terrain and unwalkable (dark) terrain. The\nsimplest procedural method of producing nodes for this map is to place a single node\nat the center of each tile, and then connect each one to its horizontal and vertical\nwalkable neighbors, as shown in Figure 3.2.2.\n\nrt yf oe\n\nFIGURE 3.2.2 Procedurally placed nodes and connections.\n\nOf course, using this procedure generates seemingly redundant nodes on the\nunwalkable tiles. They are only truly redundant if their type (the particular aspect that\ndetermines their navigability) is guaranteed not to change, and there are no characters\nin the game world that are able to use them.\n\nSuch a complete system of nodes ensures that an obstacle-free path can be found\nfrom any walkable tile to any other walkable tile (if such a path exists), but at the sig-\nnificant cost of time and storage per node (for every tile). A preferred solution would",
      "content_length": 967,
      "extraction_method": "OCR"
    },
    {
      "page_number": 237,
      "chapter": null,
      "content": "3.2 Area Navigation: Expanding the Path-Finding Paradigm 243\n\nrequire fewer nodes, carefully chosen to encode the same accessibility information in\nless space.\n\nAny algorithm for node application must function under the following con-\nstraints to ensure that the path it generates is free of static obstacles:\n\n¢ Each node must represent a group of tiles that share the property that any pair of\ntiles in that group can be navigated between (without obstruction).\n\n¢ Each potentially navigable tile on the map must be represented by exactly one\nnode.\n\nThe method above recognizes those constraints only by applying a high degree of\nredundancy. If we could address that redundancy by identifying the minimal set of\nnodes necessary to encode walkable versus unwalkable regions, we could still enjoy\nthe benefits of the graph-search approach, but in optimal space and time.\n\nThe following section explains the paradigm shift in which each node represents\na nonuniform area of tiles.\n\nwith the New\n\nWhen approaching the problem of path-finding, the form of the environment should\nbe considered so that the path-finding algorithm can be optimally written for the\ngame in question. There are two underlying considerations for deconstructing the\n\nTR RRB AES EN A A ABB 2 OHA RN MORRIS ESOT EE EM INE RIE\n\nworld:\n\n© The number of nodes it 1s deconstructed into: The fewer the better; the fewer nodes\nthere are, the quicker the heuristic search.\n\n© The usefulness of the resulting nodes for path traversal: \\t is preferable that the nodes\nallow characters to walk the path within the maximal limits set by the walkable\nenvironment.\n\nThe use of areas rather than points is beneficial in both cases.\n\nThe world is broken into areas, each being of uniform navigability and internally\ntraversable in a straight line without having to avoid static obstacles. If one can navi-\ngate between two areas, then the areas are connected by a ‘portal’ that is in the shape\nof the contact region between the two areas. In the tile-world example, the tiles can be\nsplit into areas as shown in Figure 3.2.3. Note that our tile-world example is rectan-\ngular, but the new approach is extendable to convex polygonal regions for the general\ncase.\n\nAs seen in Figure 3.2.3, no points are arbitrarily used in path-finding. This mir-\nrors the common-sense approach used by the majority of people when solving the\nsame problem in real life. When attempting to plan a path from one position to\nanother, you would normally only use two points: the start point and the end point.\nAll other sections of the path are generalized areas, split up by the way you perceive\nthe world. When walking from your bedroom to your bathroom in the morning (or\nearly afternoon), you might consider stairs, landings, corridors, or even other rooms",
      "content_length": 2794,
      "extraction_method": "OCR"
    },
    {
      "page_number": 238,
      "chapter": null,
      "content": "Section 3 Artificial Intelligence\n\n244\n\neo S sees\nIe:\n\nbs.\n\nlkable areas connected by porta\n\ning the world into wa\n\n3 Break\n\n2\n\nFIGURE 3\n\nin these\n\nth\nthere are no\n\nally no moti-\n\nints Wi\n\nhowever, consider particular po\nfic reason to (once at the top of the stairs,\n\n>\n\nYou don’t,\n\ning your path\n\nwhile plann\n\nis some speci\nions to be made unt\n\nareas, unless there\n\nmore dec\n\nil you reach the bottom!). There is norm\n\n1s\n\nalk\nAny path\night |\n\nyou just w\n\nit;\nion\n\nir shared portals until you reach your destinat\n\nk to any specific spot within a corridor before you leave\n\n4\nis\n3\n>\nfs]\nuv\n; aT\na\ng 2\no §\n-~\naq 8\n2s\na oO\n>\n\nbar-\n\nine,\n\nwithin a single area is always a stra\n\nos\n5\nvu\ns\nge\n£3\ng 2\nSg\nnr\n\nomen)\nAG\ng\nvw Ss\na &\neS\noe PN\na5\nsp\nae\n\nIt should be noted that the use of areas does not overly affect the basic heuristic\n\n68s\naaqs\nge yx\nwu\nSYeE\na\noes\n33%\na) 3\ngf\nase\n) =\novo\ns35\nfo}\n@a@ezt\nvod\nn=\neye\no © &\ngo yg\nBES 8\nwa B\n£2 5\nsex\num -\nBo ¢\nSee\n$25\np oo\nee&e\non 6\nve g\nco\n\nRR\ng § =\n£0 §\nmod\noP u\now V\na Ya\na & go\n2&2\no 2 8\nao\n\n-traversal\n\nic path\n\n1st\n\nistances actually traveled, given a real\n\nher values than the d\n\nhig\n\ngive",
      "content_length": 1133,
      "extraction_method": "OCR"
    },
    {
      "page_number": 239,
      "chapter": null,
      "content": "3.2 Area Navigation: Expanding the Path-Finding Paradigm 245\n\nFIGURE 3.2.4 A simple metric for movement cost between areas.\n\nalgorithm. A better solution would be to use the distance from the central point of the\n\nportal used to enter an area to the central point of the portal used to exit that area. For\n\ninstance, if your path took you from area A to B to C during your path-finding\n\nprocess, the distance cost of traveling from B to C would be the distance from the\n\nportal connecting A to B to the portal connecting B to C, shown here in Figure 3.2.5.\nTo summarize the path-generation algorithm:\n\n¢ The world is split into an optimal set of areas, where each area is uniformly navi-\ngable, and any two points within the area can be traversed in a straight line with-\nout impediment.\n\n¢ Each of these areas is represented by a node in a graph, and two nodes are connected\nby an edge if their associated areas have a common navigable interface (a portal).",
      "content_length": 958,
      "extraction_method": "OCR"
    },
    {
      "page_number": 240,
      "chapter": null,
      "content": "246 Section 3 Artificial Intelligence\n\nroe ornare ee eer a BASU Ua ate annonce EEN EASA ENERO Cn i ene tI SCH ANe teNERNEENE 2 seinonseeseeatentenAGunOH mE ne ORDER NEPEAN\n\nFIGURE 3.2.5 A more realistic metric for movement cost between areas.\n\n* Basic paths are generated by determining the containing areas for the start and\nend points of the journey, finding the associated nodes, and then searching the\ngraph to find the best route between the two points.\n\n* Once this area-wise route is found, a specific path is created by moving between\nthe portals linking successive pairs of areas. This is path traversal, which shall be\ndiscussed shortly.\n\nNow that the basic concepts have been introduced, the next section will continue\nwith the tile-world example and explain a method of producing optimal areas from\nthe environment.",
      "content_length": 827,
      "extraction_method": "OCR"
    },
    {
      "page_number": 241,
      "chapter": null,
      "content": "3.2 Area Navigation: Expanding the Path-Finding Paradigm 247\n\nDivide and Conquer\n\nConstructing areas from raw terrain data is a very game-specific problem. It is possi-\nble you will have to extract the processed areas from polygons flagged for terrain type,\nor even from open spaces in a fully 3D game. This section will focus on the simplest\ncase as an example and show a method of rectangularizing a tile world to produce\nresults as seen in Figure 3.2.3.\n\nWhile there are many possible ways of producing a set of rectangles from a given\ntile set (each having its own merits and flaws), for the purposes of producing rectan-\ngles for path-finding, the following aspects are important to consider:\n\n° The rectangles produced should be as large as possible. The larger the rectangles, the\nquicker the path-finding process will occur, since fewer rectangles are necessary.\n\n° The rectangles should be as square as possible. For the purposes of path-finding, the\nrectangles will produce better paths if the ratio of width to height is close to one.\nThis helps avoid the problem outlined in Figure 3.2.4 and leads toward more-\nrealistic looking paths.\n\n© The rectangularization algorithm should be fast. In games where the type of land-\nscape can be changed dynamically and rectangularization must be performed in\nreal-time, the algorithm for rectangularization should be as fast as possible.\n\nThe following pseudo-code rectangularizes the world with reasonable speed, pro-\nducing more-evenly sided rectangles with an adjustable level of performance between\noptimized rectangles for path traversal and optimized speed. Where offline processing\nis possible, speed optimization is not a key issue and can be ignored in favor of better\noptimized rectangularization. The algorithm is presented as pseudo-code here due to\nthe length of the full code, which can be found on the CD-ROM.\n\nThe rectangularization function is defined as:\n\nRectangularizeWorld( MapCellTypes cellType, int\ninitialTestSize)\n\nwhere the parameter cellType defines the type of environment the function will rec-\ntangularize (walkable, unwalkable, or some other defined type), and the parameter\ninitialTestSize defines the size of the largest square tested, and is used to trade opti-\nmal rectangularization for optimal speed.\n\nThe first step in the function is to count the number of cells of the required type.\nThis is used to abort out of the function if that cell type is lacking in the current envi-\nronment. Only cells that are not already contained within an area are considered.\n\nint CellCount = number of free cells of type cellType\nif CellCount = 0 then exit\n\nThe next step is to ensure that the size of the square used for the comparisons\nis smaller than the square root of the number of cells of the required type. If the\ntest size defines an area larger than the number of cells that the required type can",
      "content_length": 2880,
      "extraction_method": "OCR"
    },
    {
      "page_number": 242,
      "chapter": null,
      "content": "248 Section 3 Artificial Intelligence\n\noccupy, then there is no way that the square will find an area consisting entirely of\nthose cells.\n\nif initialTestSize > sqrt(CellCount)\nthen initialTestSize = sqrt(CellCount)\n\nThe main loop of the rectangularization process begins by testing the world with\na square of the maximum defined size and decreasing that square with each iteration\nuntil it is zero.\n\nfor testSize = initialTestSize, testSize > 0, testSize = testSize - 1\n\nThe square is passed across the map from bottom left to top right:\n\nFor startX = 0 to mapWidth — testSize\nFor startY = 0 to mapHeight - testSize\n\nThe square defines an area of the world that is tested for uniform cells (of the\nrequired type) such that no cell under the square is contained by another area.\n\nFor testX = startX to startX + testSize\nFor testY = startY to startY + testSize\nIf cell{testX][testY] is not free or not of the required type,\nfail\n\nIf the square fails, then move it to the next testing position and test again. If the\nsquare contains only free cells of the required type, then attempt to expand the square\nNorth, East, South, and West by one cell width, one direction at a time. New cells\nadded to the area by each expansion are permanently added to the rectangle (if they\nare of the required type and contained by any other area). The algorithm continues to\nexpand in all four directions until it fails to give a valid set of cells.\n\nFail = 0\nWhile fail < 4\nFor North, South, East, and West\nExpand the area by one cell width\nIf the new rectangle is valid\nFail = 0\nElse\nFail = Fail + 1\nContract the rectangle along this direction\n\nAt this point, we have an area defined by this expanded rectangle that should be\nadded to the list of areas.\nFor x = rectStartX to rectEndXx\nFor y = rectStartY to rectEndy\nCell{x][y] set to unavailable\n\nAdd new area to area list",
      "content_length": 1855,
      "extraction_method": "OCR"
    },
    {
      "page_number": 243,
      "chapter": null,
      "content": "3.2 Area Navigation: Expanding the Path-Finding Paradigm 249\n\nCellCount = CellCount — new area size\nIf CellCount = 0 then exit\n\nBy altering the maximum size of the initial comparison square, it is possible to\ntrade speed optimization for optimal rectangularization. If the initial side length is set\nto one, then the minimal number of rectangle comparisons will be made, hence opti-\nmizing the speed of the procedure. If it is set to a maximum value, the width of the\nmap for instance, then far more rectangle comparisons will be made; however, the set\nof areas produced will adhere to the first two aspects of optimal rectangularization. It’s\na tradeoff that the developer must choose for their particular need.\n\nPath Traversal _\n\nrious: SOAPS SSSSERRESRMNIE LES CLA ht SMS Net RE\n\nOnce a path has been produced, the next step is for a character to follow that path to\nthe destination. There are two aspects to basic path traversal: attraction toward some\ngoal and repulsion from static obstacles along the way. The attraction is either toward\nthe next portal on the path or toward the goal point if the character has entered the\ngoal area. The repulsion comes from proximity to nonwalkable areas. (There are no\nstatic obstacles within each area, by definition.)\n\nTo move a character toward its next area in a realistic manner, two simple modes\nof attraction are used in conjunction (as seen in Figures 3.2.6 and 3.2.7):\n\n1. Attraction to the central point of the portal.\n2. Attraction along the normal of the portal. (The portal’s normal is defined\nby a vector perpendicular to the portal’s vector.)\n\nThese modes can be applied to varying degrees depending on the position of the\ncharacter relative to the portal. If the character does not lie on a point along the por-\ntal normal, then attraction along the normal of the portal will not result in a convinc-\ning movement to the new area. So, some amount of attraction to the center of the\nportal might be necessary. Figure 3.2.8 shows the portion of area B where attraction\nby the normal alone will result in the transition from area B to area C.\n\nAn example attraction algorithm is to use the normal vector shown in Figure\n3.2.7 while in the shaded area and a mixture of the two vectors outside that area\n(increasing the proportion of the central-point vector with distance along the line of\nthe portal).\n\nRepulsion works similarly to the normal attraction, except that the direction of\nthe normal is reversed such that the vector is heading into the character's current area\nrather than out of it. In the specific case of the simple tile world described so far, it\nwould be necessary to store a list of walls as well as portals, so that the walls could be\nused to repulse the characters from nonwalkable cells. In the more general case, every\ncell type would have its own area list, and all areas would have portals to all their\nneighbors. Neighbors leading to areas that a specific character could not use would\nrepulse that character by using a different area type in the traversal algorithm.",
      "content_length": 3049,
      "extraction_method": "OCR"
    },
    {
      "page_number": 244,
      "chapter": null,
      "content": "250 Section 3 Artificial Intelligence\n\nsee\n\n—\n\nee\neG\n\nFIGURE 3.2.6 Autraction to area C by the central point of the portal connecting areas B\nand C.\n\nFigure 3.2.9 shows the map broken into walkable and unwalkable areas, with\npoints defining the center of each portal.\n\nFor each unwalkable area connected to the character’s current area, a repulsion\nvector is applied along the normal to the portal. This repulsion is only applied if the\ncharacter is within the confines of the portal, as shown by the shaded area of Figure\n3.2.10.\n\nFinally, once the path traversal is in place, dynamic object avoidance can be\nachieved by using basic flocking techniques and adding repulsion vectors from other\ncharacters in the world to the path-traversal vectors. For more information on flock-\ning see [Reynolds87] or [Woodcock00].",
      "content_length": 817,
      "extraction_method": "OCR"
    },
    {
      "page_number": 245,
      "chapter": null,
      "content": "3.2 Area Navi\n\ntion: Expanding the Path-Finding Paradigm ; — 251\n\nFIGURE 3.2.7 Attraction to area C by the normal of the portal connecting areas B and C.\n\nDynamic Landscapes\n\nDeconstructing the world into areas is a CPU-intensive process that must be carried\nout at appropriate points during runtime, if at all. It is preferable to carry out the pro-\nduction of areas during some batch process as the level is loaded. However, if the envi-\nronment is dynamic due to player interaction or scripted changes, then the\ndeconstruction process might have to be called during runtime. In these cases, speed\nis a primary consideration, and the process of deconstruction must be approached in\nsuch a way as to avoid frame lag without reducing the quality of the areas produced.\nThis is achievable as follows:",
      "content_length": 799,
      "extraction_method": "OCR"
    },
    {
      "page_number": 246,
      "chapter": null,
      "content": "252 Section 3. Artificial Intelligence\n\nee ee ec ee en ee ec ee\n\nFIGURE 3.2.8 The shaded area defines the portion of area B where attraction by the\nnormal of the portal connecting areas B and C (shown in Figure 3.2.7) will suffice to\ntraverse a character from area B to area C.\n\n° Initially, use the fastest deconstruction algorithm. With the rectangularization\nalgorithm detailed above, choose an initialTestSize value of 1. This might pro-\nduce an inferior set of rectangles for path traversal than a higher value would, but\nthe speed of the process is maximized.\n\n¢ During runtime, minimize redundant rectangularization (i.e., do not rectangu-\nlarize areas that are unaffected by the environment change).\n\n* Re-rectangularize the environment for optimal path traversal at an appropriate\ntime. Reconstruct the entire world when a slight lag would not be noticed, such\nas when the player switches to an in-game menu.",
      "content_length": 917,
      "extraction_method": "OCR"
    },
    {
      "page_number": 247,
      "chapter": null,
      "content": "FIGURE 3.2.9 The entire map is broken into walkable and unwalkable areas connected\nby portals with their centers marked by points.\n\nRemember, altering the set of areas not only requires deconstructing the world,\nbut it also requires recalculating the characters that are positioned in those areas.\n\nWhile this gem has focuse\n\napproach is applicable to every type of game world (including 3D). All that is\nrequired is a method of deconstructing the world into efficient areas that obey the\nrules described above as well as redefining the connecting portal region.",
      "content_length": 562,
      "extraction_method": "OCR"
    },
    {
      "page_number": 248,
      "chapter": null,
      "content": "254 Section 3 Artificial Intelligence\noc :\n:\nAo\nFIGURE 3.2.10 Repulsion is applied to characters within the area defined by the normal\nof the portal, which is shown by the shaded section of area B.\nConclusion\n\nThis gem presents a highly efficient algorithm for creating and following paths in a\nvariably navigable environment—one that we are using successfully in our current\ntitle. By identifying optimal areas within the environment that are trivially navigable,\nrepresenting them with a single node, then linking these nodes wherever the associ-\nated areas have a navigable interface, we are able to quickly produce paths covering\nlong distances. Redundancy is minimized, resulting in high speed and storage effi-\nciency. To support this process, a method of determining these optimal areas has been\nsuggested. Also, in order to use the resulting area-wise path and apply it to a navigat-",
      "content_length": 891,
      "extraction_method": "OCR"
    },
    {
      "page_number": 249,
      "chapter": null,
      "content": "3.2 Area Navigation: Expanding the Path-Finding Paradigm _ 255\n\ning character, a path-traversal method has been described. The results are inexpensive\nand the paths realistic.\n\necon aenene ROI LR RO LEI OLEY TRE ILL RPE TO TOLLE SN AE ALLE ITEC.\n\n[Reynold87] Reynolds, Craig, “Flocks, Herds and Schools: A Distributed Behavioural\nModel,” Computer Graphics Proceedings (SIGGRAPH 1987): pp. 25-34.\n\n[Sedgewick89] Sedgewick, Robert, Algorithms, Second Edition, Addison Wesley,\n1989.\n\n{Stout00] Stout, Bryan, “The Basics of A* for Path Planning,” Game Programming\nGems, Charles River Media, Inc., 2000.\n\n{Woodcock00] Woodcock, Steve, “Flocking: A Simple Technique for Simulation\nGroup Behavior,” Game Programming Gems, Charles River Media, Inc., 2000.",
      "content_length": 747,
      "extraction_method": "OCR"
    },
    {
      "page_number": 250,
      "chapter": null,
      "content": "What Is a Finite-State Machine?\n\n256\n\nFunction Pointer-Based,\nEmbedded Finite-State\nMachines\n\nCharles Farris, VR1 Entertainment, Inc.\n\ncharlesf@vri.com\n\nhe goal of this gem is to create an FSM (Finite State Machine) implementation\n\nusing function pointers, inheritance, and function overloading. This implemen-\ntation has three design requirements: object-oriented implementation, minimal cod-\ning, and fast execution.\n\nThe first requirement, object-oriented implementation, is very important in\nmodern games development. Many developers are moving toward object-oriented\nlanguages, such as C++ and Java, because these languages support features like\nabstract object manipulation and inheritance. To be used effectively in an object-ori-\nented programming (OOP) environment, an FSM implementation needs to be\nobject-oriented in design.\n\nThe second requirement, minimal coding, arises from a fundamental rule in soft-\nware engineering: “Keep It Simple, Stupid.” Accordingly, this implementation makes\nthe addition of FSM functionality as simple as inheriting a class and adding some\nmember variables and functions.\n\nFinally, this implementation uses function pointers to avoid computationally\nexpensive if-then-else comparisons at runtime (Calder94].\n\nThe most general definition of an FSM describes it as a model of an event-driven sys-\ntem. A system's behavior is represented within an FSM as a set of states, a set of input\nevents, and a state-transition function. A simple lightbulb example is demonstrated in\nTable 3.3.1 and Figure 3.3.1.\n\nFor a more in-depth description of FSMs and their application to game program-\nming, both Eric Dysband’s “A Finite-State Machine Class” (Dysband00] and Andre\nLaMothe’s Tricks of the Windows Game Programming Gurus (LaMothe99] are excellent\n\nsources of information.",
      "content_length": 1807,
      "extraction_method": "OCR"
    },
    {
      "page_number": 251,
      "chapter": null,
      "content": "3.3 Function Pointer-Based, Embedded Finite-State Machines 257\n\nTable 3.3.1 Lightbulb State Transition Function\n\nCurrent State Input Event State Transition\nOn Switch On\n\nOn Switch Off Off\n\nOff Switch On On\n\nOff Switch Off\n\nSwitch Off\n\nSwitch On\nFIGURE 3.3.1 Lightbulb FSM.\n\nWhy Use FSMs?\n\nIn game programming, FSMs are generally used to control a game object’s behavior at\nruntime by selectively executing portions of the object’s code based on the current\nstate. While FSMs can be used to control virtually any game object, they are\nextremely popular for AI programming for the following reasons:\n\n¢ FSMs are useful for reducing complex behaviors into smaller, simpler behaviors.\n\n* FSMs are useful for synchronizing an Al’s behavior with external events, such as\nanimations, sounds, or timers. FSMs allow developers to integrate animations\nwith AI behavior without placing too many restrictions on the animator’s artistic\nvision.\n\n¢ FSMs are much easier to debug and tune than other AI techniques, such as neural\nnetworks or genetic algorithms [Woodcock00, Woodcock01]. FSMs generate",
      "content_length": 1085,
      "extraction_method": "OCR"
    },
    {
      "page_number": 252,
      "chapter": null,
      "content": "258 Section 3 Artificial Intelligence\n\ndeterministic behavior during execution because state transitions are predefined\n- for a given state and input event.\n\nFSM Implementation\n\nFirst, we need to make some assumptions regarding our game objects. Each object\nshould be represented by a C++ class, have a function called Update() that is called\nevery tick, and have a set of state functions (which are called in the Update() func-\ntion). Given these assumptions, an FSM implementation requires a variable to track\nthe current state and some code for handling the state transitions. Most importantly,\nit needs some code for mapping the current state to the appropriate state functions in\nthe game object.\n\nFSM integration\n\nFSM implementations can be integrated into game objects in one of two ways. The\nfirst and simplest method is to include an instance of the FSM within the game\nobject. The second method is to embed the FSM within the game object via inheri-\ntance. Both methods have advantages and disadvantages, but this gem will use the\nsecond method for two main reasons. First, inherited FSMs allow greater flexibility\nbecause the FSM’s state-transition logic can use the game object’s data directly. Sec-\nond, embedded FSMs have slightly better performance, since there is less redirection\nrequired when accessing the FSM.\n\nThe main disadvantage with inherited FSMs lies in the dependency between the\nFSM and the game object classes, which can pose a challenge later on in development,\nsince changes to the inherited FSM class might require extensive modifications to the\nderived classes.\n\nThe Switch implementation\n\nThe most common form of FSM implementation is the switch implementation. In\nthis implementation, the current state is stored as an integer, and a switch statement\nis used to map the current state to the state function calls [LaMothe99]. The primary\nadvantages of this approach are ease of implementation and low memory usage.\n\nHowever, the common switch implementation does have disadvantages. First,\nthe switch implementation is not very object-oriented [Sweeney00]. Adding states\ninvolves modifying the switch statement. When these modifications are combined\nwith inheritance and function overloading, the end result is often ‘spaghetti’ code.\nAlso, for large projects with multiple developers, the non-object-oriented design\nof the switch implementation can lead to significant maintenance and debugging\nproblems.\n\nSecond, the performance of this implementation is dependent on the size of the\nFSM. Most switch statements are converted into if-then-else statements by the\ncompiler and are difficult to optimize. For an FSM having states, the program will",
      "content_length": 2681,
      "extraction_method": "OCR"
    },
    {
      "page_number": 253,
      "chapter": null,
      "content": "3.3 Function Pointer-Based, Embedded Finite-State Machines 259\n\naverage about #/2 if-then-else comparisons before finding the appropriate state\nfunction call. If the FSM is distributed over a class hierarchy, the search for an appro-\npriate state function might require several virtual function calls up the class hierarchy\nin addition to the if-then-else comparisons.\n\nA more object-oriented solution to the function-mapping problem is to encapsu-\nlate the state function calls within the current state variable. Since the state functions\nare usually associated with the game object, implementing the state functions directly\nwithin a state object is not practical. However, the state functions can effectively be\nstored within a state object through the use of function pointers.\n\nFunction Pointers\n\nFunction pointers in C are very straightforward, but the syntax is somewhat cryptic.\n<return type>(*<pointer>) (<arguments>)\n\nIn C++, nearly all function calls are made to class member functions. Function\npointers to these functions require significantly more syntax because the functions are\nclass-specific. Accordingly, the declaration syntax requires the class name.\n\n<return type>(<class>: :*<pointer>) (<arguments>)\n\nLet’s assume IsOdd() is a member function of a class called “cMath.” The function\npointer declaration to Isddd() would be:\n\nbool (CMath: :*pfnFunction) {int )=&CMath: :IsOdd;\n\nThe class-specific nature of function pointers to member functions extends\nbeyond the declaration syntax. Function pointers to member functions cannot point\nto functions in a derived class unless the function is already declared in the base class\n[Stroustrup97]. This is a serious limitation because all functions must be declared in\nthe base class, resulting in severe code bloat. On the plus side, function pointers to\nvirtual functions will resolve to the proper function call using the virtual function call\nmechanism. This allows function pointers to member functions to work properly in\nderived class hierarchies (assuming the functions are declared in the base class).\n\nExecution of a member function through a function pointer also presents a prob-\nlem. Member functions use a different calling convention from regular functions as\nthey pass the class instance to the function via a hidden parameter (the this pointer).\nThus, execution of a member function through a function pointer requires a class\ninstance. The code below illustrates the execution of the IsOdd{) member function\nthrough the pfnFunction function pointer.\n\nCMath Instance;\n\nbool bResult=(Instance.*pfnFunction) (5);\nCMath *pInstance=&Instance;\n\nbool bResult=(pInstance->*pfnFunction) (3);",
      "content_length": 2665,
      "extraction_method": "OCR"
    },
    {
      "page_number": 254,
      "chapter": null,
      "content": "260\n\nSection 3 Artificial Intelligence\n\nWith these limitations, the use of function pointers to store the state functions\nseems difficult at best. For the moment, let us assume that workarounds exist, so we\ncontinue to examine the use of function pointers in an FSM implementation. (For\nmore on function pointers, Lars Haendel’s “The Function Pointer Tutorials” [Haen-\ndel01] is an excellent reference on function pointers, and it is available online.)\n\nThe Function Pointer Implementation\n\nIn a function pointer implementation, each state is now represented as an object.\nWithin this object, the state function calls are stored in function pointers, and the\nfunction mapping occurs when the state is initialized. The FSM tracks the current\nstate by maintaining a pointer to the current state object, and the state function calls\nare executed directly from the state object through the function pointers.\n\nThe primary advantage of the function pointer implementation over the switch\nimplementation is its object-oriented design. The function mapping is now part of\nthe state object and not the game object. This difference in implementation avoids\nthe necessity of extending the FSM execution code into the game object classes.\nInstead of overloading the Update() function in the derived class, new states can be\nadded to the FSM by merely including new state objects.\n\nAnother advantage of this implementation is that the performance is indepen-\ndent of the number of states within the FSM. Since each state object knows exactly\nwhat functions to call, there are no if-then-else comparisons and no traversal of the\ngame object’s class hierarchy.\n\nThis implementation does have some disadvantages, however. Implementation is\nmore difficult due to the limitations inherent in function pointers to member func-\ntions. In addition, this implementation requires significantly more memory, as the\nstate function mapping is now stored as a set of function pointers instead of being\ncompiled into the code.\n\nThe Implementation (CFSM)\n\nIn order to best satisfy the design requirements, the CFSM implementation will consist\nof a base class using the function pointer implementation, as previously described.\nThe CFSM implementation has two separate parts: the state objects and the FSM.\n\nThe State Objects\n\nIn the game object assumptions, we stated that each state in the game object would be\nrepresented as a set of functions. In the CFSM implementation, each state is represented\nby three functions. As an example, let us create a game object class called CEnemy,\nwhich implements an idle state.\n\nclass CEnemy : public CFSM\n\n{\nvoid BeginStateIdle();",
      "content_length": 2642,
      "extraction_method": "OCR"
    },
    {
      "page_number": 255,
      "chapter": null,
      "content": "3.3 Function Pointer-Based, Embedded Finite-State Machines __ _ 261\n\nhs\n\nvoid StateIdle();\nvoid EndStateIdle();\n\nThe BeginStateIdle() and EndStateIdle() functions are called during state\ntransitions and provide a convenient location for initializing and cleaning up states.\nThe StateIdle() function is the main state function and is called every tick from the\nUpdate() function. Since three functions make up each game object state, the CFSM\nstate object uses three function pointers to store the state functions.\n\nTo create state objects, a two-class hierarchy is necessary. The base class, cstate,\nprovides a generic interface for executing the stored state functions.\n\nclass CState\n\n{\npublic:\nvirtual ~CState() {}\nvirtual void ExecuteBeginState()=0;\nvirtual void ExecuteState()=0;\nvirtual void ExecuteEndState()=0;\n}3\n\nThe second class, CStateTemplate, is derived from CState. To avoid the problem\nof class-specific function pointers, CStateTemplate is a template class.\n\ntemplate <class T>\nclass CStateTemplate : public CState\n\n{\nprotected:\ntypedef void (T::*PFNSTATE) (void) ;\nT *m_pInstance;\nPFNSTATE m_pfnBeginState;\nPFNSTATE m_pfnState;\nPFNSTATE m_pfnEndState;\npublic:\n\nCStateTemplate() : m_pInstance(0),\nm_pfnBeginState(0),\nm_pfnState(0) ,m_pfnEndState(0) {}\n\nvoid Set(T *pInstance,PFNSTATE pfnBeginState,\nPFNSTATE pfnState,PFNSTATE pfnEndState)\n\n{\nm_pInstance=pInstance;\nm_pfnBeginState=pfnBeginState;\nm_pfnState=pfnState;\nm_pfnEndState=pfnEndState;\n\n}\n\nvirtual void ExecuteBeginState()\n\n{\n(m_pInstance->*m_pfnBeginState) ();\n\n}\n\nvirtual void ExecuteState()",
      "content_length": 1567,
      "extraction_method": "OCR"
    },
    {
      "page_number": 256,
      "chapter": null,
      "content": "262 Section 3 Artificial Intelligence\n\n{\n(m_pInstance->*m_pfnState) ();\n}\nvirtual void ExecuteEndState()\n{\n(m_pInstance->*m_pfnEndState) ();\n}\n\nhs;\n\nCStateTemplate implements the three state function pointers as well as a pointer\nto the class instance. The execution functions from the CState class are overloaded\nand implemented in CStateTemplate. Since CState is the base class for CStateTem-\nplate, a game object can create class-specific state objects using CStateTemplate\ninstances. The FSM implementation, however, can use the state objects generically by\ntreating them as instances of CState and thus avoids having to know the details of a\ngame object in order to execute its state functions.\n\nThe FSM\n\nWith state objects now defined, the CFSM base class can now use them to implement\nthe FSM.\n\nclass CFSM\n\nprotected:\nCState *m_pCurrentState;\nCState *m_pNewState;\nCStateTemplate<CFSM> m_StateInitial;\npublic:\nCFSM();\nvirtual ~CFSM() {}\nvirtual void Update();\nbool IsState(CState &State) ;\nbool GotoState(CState &NewState) ;\nvirtual void BeginStateInitial() {}\nvirtual void StateInitial() {}\nvirtual void EndStateInitial() {}\n\n};\n\nThe current state, m_pCurrentState, isa pointer to a CState object. The use of a\nCState pointer allows the FSM to completely implement the state function execution\ncode within the CFSW’s Update() function. In addition to the current state pointer, a\nCState pointer, m_pNewState, is also declared. This variable is tracked by the FSM and\nwill cause the FSM to execute a state transition if set.\n\nThe CFSM implementation defines an initial state using the CStateTemplate class\nand stores it in the state object m_StateInitial. This state is provided so that the\nFSM implementation always has a state to execute. The CFSM constructor initializes\nthe initial state along with the pointers to the state objects.",
      "content_length": 1843,
      "extraction_method": "OCR"
    },
    {
      "page_number": 257,
      "chapter": null,
      "content": "3.3 Function Pointer-Based, Embedded Finite-State Machines 263\n\nCFSM: :CFSM()\n\n{\nm_StateInitial.Set(this,BeginStateInitial,\nStateInitial,\nEndStateInitial) ;\nm_pCurrentState=static_cast<CState*>(\n&m_StateInitial) ;\nm_pNewState=0;\n\n}\nThe execution of the state functions occurs in the Update() function.\n\nvoid CFSM: :Update()\n\n{\nif (m_pNewState)\n{\nm_pCurrentState->ExecuteEndState();\nm_pCurrentState=m_pNewState;\nm_pNewState=0;\nm_pCurrentState->ExecuteBeginState() ;\n}\nm_pCurrentState->ExecuteState();\n}\n\nUpon entering the Update() function, the FSM checks for a state transition using\nthe m_pNewState variable. If one is pending, Update() calls the ExecuteEndState()\nand ExecuteBeginState() functions, and changes the current state.\n\nThe GotoState() and IsState() functions are provided to simplify the handling\nof state objects. The GotoState() function sets the new state variable and causes a\nstate transition on the next Update() function call.\n\nbool CFSM::GotoState(CState &NewState)\n\n{\nm_pNewState=&NewState ;\nreturn true;\n\n}\n\nThe IsState() function provides a syntax-friendly method of comparing the cur-\nrent state to any given state.\n\nbool CFSM::IsState(CState &State)\n{\n\n}\n\nreturn (m_pCurrentState==&State) ;\n\nUsing CFSM\n\nBy way of example, we are now going to create a game object that simulates a light-\nbulb. The game object will use the FSM introduced at the beginning of this gem, and\nthe CFSM class will provide the FSM functionality.",
      "content_length": 1449,
      "extraction_method": "OCR"
    },
    {
      "page_number": 258,
      "chapter": null,
      "content": "264\n\nSection 3 Artificial Intelligence\n\nAdding CFSM to a Class\n\nFirst, we create a class called CLightBulb and derive it from the CFSM base class. To\nimplement the states, we add two state objects using the CStateTemplate class and the\ncorresponding state functions. The two input events are handled through the\nSwitchOnEvent() and SwitchOffEvent () functions.\n\nclass CLightBulb : public CFSM\n{\nprotected:\ncStateTemplate<CLightBulb> m_StateOn;\ncStateTemplate<CLightBulb> m_StateOff;\npublic:\nCLightBulb();\nvirtual void SwitchOnEvent();\nvirtual void SwitchOffEvent();\nvirtual void StateInitial({);\nvirtual void BeginStateOn({);\nvirtual void StateOn() {}\nvirtual void EndStateOn() {}\nvirtual void BeginStateOff{);\nvirtual void StateOff() {}\nvirtual void EndStateOff() {}\n\nhi\n\nThe constructor initializes the CFSM base class and initializes the two state objects.\n\nCLightBulb::CLightBulb() : CFSM()\n\n{\nm_StateOn.Set(this,BeginStateOn,StateOn,\nEndStateOn) ;\nm_StateOff.Set(this,BeginStateOff,StateOdff,\nEndStateOff ) ;\n}\n\nNext, we add the SwitchOnEvent() and SwitchoffEvent() functions for handling\nthe input events and state transition logic.\n\nvoid CLightBulb: :SwitchOnEvent()\n\nif (IsState(m_StateOff) )\nGotoState(m_StateOn) ;\n\n}\nvoid CLightBulb: :SwitchOffEvent()\n{\nif (IsState(m_StateOn) )\nGotoState(m_StateOfFf) ;\n}\n\nSince this is a simple example, the state functions are mostly stub functions.\nHowever, the BeginStateOn() and BeginStateOff() functions contain code for dis-\nplaying the current state so we can follow the FSM’s execution.",
      "content_length": 1539,
      "extraction_method": "OCR"
    },
    {
      "page_number": 259,
      "chapter": null,
      "content": "3.3 Function Pointer-Based, Embedded Finite-State Machines 265\n\nvoid CLightBulb: :StateBeginOn()\n\n{\ncout << \"State: On” << endl;\n}\nvoid CLightBulb: :StateBeginOff {)\n{\ncout << \"State: Off” << endl;\n}\nFinally, the StateInitial() function is overloaded to ‘jump-start’ the lightbulb\nFSM.\nvoid CLightBulb: :StateInitial({)\n{\nGotoState(m_StateOfFf) ;\n}\n\nChanging an FSM’s Behavior in a Derived Class\n\nLet us create a new class to simulate a flashing light. Since a flashing lightbulb is sim-\nilar to an ordinary lightbulb, we can use the CLightBulb class and simply extend its\nbehavior. First, we need to derive a new class called cFlashingLightBulb from\nCLightBulb. We then need to add a new state for handling the flashing and overload\nthe On state functions from CLightBulb.\n\nclass CFlashingLightBulb : public CLightBulb\n{\nprotected:\ncStateTemplate<CFlashingLightBulb> m_StateOnDim;\nunsigned int m_uTimer;\npublic:\nCFlashingLightBulb({) ;\nvirtual void SwitchOffEvent() ;\nvirtual void BeginStateOn();\nvirtual void StateOn();\nvirtual void BeginStateOnDim() ;\nvirtual void StateOnDim();\nvirtual void EndStateOnDim({) ;\n\noe\nLike the previous example, the new state is initialized in the constructor.\n\nCFlashingLightBulb: :CFlashLightBulb() : CLightBulb()\n\n{\nm_StateOnDim(this ,BeginStateOnDim,StateOnDim,\n\nEndStateOnDim) ;\n}\n\nThe flashing behavior will be handled by cycling between the On and On Dim\nstates, with a timer controlling the flash interval. The On state functions from\nCLightBulb are overloaded to reflect the new behavior.",
      "content_length": 1530,
      "extraction_method": "OCR"
    },
    {
      "page_number": 260,
      "chapter": null,
      "content": "266\n\nvoid CFlashingLightBulb: :BeginStateOn()\n\n{\nCLightBulb: :BeginStateOn() ;\nm_uTimer=10;\n}\nvoid CFlashingLightBulb: :State0n()\n{\n--m_uTimer;\nif (m_uTimer==0)\nGotoState(m_StateOnDim) ;\n}\n\nLikewise, we implement the On Dim state functions.\n\nvoid CFlashingLightBulb: :BeginStateOnDim( )\n\n{\ncout << \"State: On Dim\" << endl;\nm_uTimer=10;\n}\nvoid CFlashingLightBulb: :StateOnDim()\n{\n--m_uTimer ;\nif (m_uTimer==0)\nGotoState(m_StateOn) ;\n}\n\nFinally, we update the SwitchOffEvent() function to take into account the new\nstate.\n\nvoid CLightBulb: :SwitchOffEvent()\n\nif (IsState(m_StateOn) || IsState(m_StateOnDim) )\nGotoState(m_StateOff) ;\n\n}\n\nDuring execution, the FSM will cycle between the On and On Dim states, thus\nsimulating the behavior of a flashing light. This example illustrates both the use of\nnew states and the overloading of existing states to extend the behavior of the FSM.\n\nConclusion\n\nThis gem illustrates an FSM implementation using function pointers that allows\ndevelopers to quickly add FSM functionality to either new or existing game objects.\nWhile applicable for game development in its current form, the FSM implementation\npresented here is minimal and intended mainly to be used as a starting point for\ndevelopers wishing to create their own FSM implementations. Accordingly, there are\nmany areas of possible modification, including memory optimizations, more-compli-\ncated state-transition logic, customized state objects, and additional error checking.",
      "content_length": 1472,
      "extraction_method": "OCR"
    },
    {
      "page_number": 261,
      "chapter": null,
      "content": "3.3 Function Pointer-Based, Embedded Finite-State Machines 267\n\nReferences\n\n[Calder94] Calder, Brad, Dirk Grundwald, and Benjamin Zorn, “Quantifying\nBehavioral Differences Between C and C++ Programs,” available online at\nhetp://www.cs.colorado.edu/department/publications/reports/docs/CU-CS-698-\n94.ps, January 1994.\n\n[Dysband00] Dysband, Eric, “A Finite-State Machine Class,” Game Programming\nGems, Charles River Media, Inc., 2000: pp. 237-248.\n\n[Haendel01] Haendel, Lars, “The Function Pointer Tutorials,” available online at\nhttp://www.function-pointer.org, October 2001.\n\n[LaMothe99] LaMothe, Andre, Tricks of the Windows Game Programming Gurus,\nSams, 1999: pp. 729-734.\n\n[Stroustrup97] Stroustrup, Bjarne, The C++ Programming Language, Third Edition,\nAddison Wesley Longman, Inc., 1997: pp. 418-421.\n\n[Sweeney00] Sweeney, Tim, “Unreal Technology FAQ,” available online at http://\nunreal.epicgames.com/UnrealScript.htm, June 2000.\n\n[Woodcock00] Woodcock, Steve, “Game AI: The State of the Industry,” Game\nDeveloper Magazine, August 2000: pp. 34—43.\n\n[Woodeock0 1} Woodcock, Steve, “Game AI: The State of the Industry,” Game\nDeveloper Magazine, August 2001: pp. 24-32.",
      "content_length": 1171,
      "extraction_method": "OCR"
    },
    {
      "page_number": 262,
      "chapter": null,
      "content": "3.4\n\nAreas\n\nmeniscus .\n\n268\n\nTerrain Analysis in an RTS—\nThe Hidden Giant\n\nDaniel Higgins,\nStainless Steel Studios, Inc.\ndan@stainlesssteelstudios.com\n\nA’ children (and, well, even as adults), we strive to understand the world around\nus. By the time we enter school, we can easily recognize and identify many\nthings. We know what a street is, or a building, and can recognize the sky, the ocean,\na hill, and a forest. Even if we had silly notions as kids, such as the woods behind our\nsuburban home actually being part of a forest that stretched on for miles, we at least\nrecognized these terrain elements and many of their properties.\n\nMoving into the virtual world, computer games strive to provide a rich environ-\nment for players by creating a world that is full of interesting terrain elements. Just as\na teenager can decide either to cut through the woods to get to a friend’s house or go\nby way of the street, programmers can use the same type of terrain information to\nmake decisions. Programmers might have a virtual teenager avoid traveling through\nthe forest if it’s after sunset, or perhaps take a chance on the forest if they are walking\nwith a group of friends.\n\nGathering the information about the world environment is called terrain analysis.\nIt is a vital element of today’s computer games, especially real-time strategy (RTS)\ngames. Unfortunately, this important task can be overlooked or grossly underesti-\nmated in terms of development time. Make no mistake—writing a terrain-analysis\nengine can be a gigantic undertaking, depending on how much information you want\nto analyze. However, it is one of the most important developmental tasks in an RTS\ngame.\n\nGARB RE EES H IN BETIS A E UMR ENE HEE\n\nThe first step in terrain analysis is planning. When choosing what terrain elements to\nanalyze, we must consider: “What areas do I need to know about?” Will you want to\nrecognize forests, choke points, or oceans in your game? Brainstorm a list of world\nareas you will want to recognize.\n\nAfter brainstorming a list of areas, you might find that these areas need to be\ndivided into two major categories: static and dynamic. Despite conceptual differ-",
      "content_length": 2165,
      "extraction_method": "OCR"
    },
    {
      "page_number": 263,
      "chapter": null,
      "content": "in an RTS—The Hidden Giant 269\n\nences, static and dynamic areas can be represented very similarly (if not identically) in\ncode. Since both are very similar, you should consider writing a generic “Area” base\nclass full of virtual methods that will facilitate easier future programming.\n\nStatic Areas\n\nStatic areas don’t change throughout the course of the game. Generally, static areas\ntend to have the most points (or tiles) and cover the largest areas. In contrast to\ndynamic areas, static areas must be preprocessed before the game starts. This is an\nadvantage over dynamic areas because dynamic areas might need frequent processing\nbefore, during, and after the game.\n\nReprocessing a very large area during runtime could make the game slow down to\na crawl, or it could even freeze the game world. That would be a disaster for a game\nand obviously should be avoided. Static areas are therefore a necessity in order to\nreduce processing time during a game.\n\nSome examples of static areas are:\n\n¢ Continents: Continents are one of the most important areas of terrain analysis.\nEvery point on every map should exist on some type of continent, even if the\npoint is a cliff, an ocean, or a waterfall. Continents are used to determine\nthe accessibility properties of different parts of the map. You might have naval\nunits that can only travel in ocean continents, land units that can only traverse\nland continents, or air units that can fly over all continent types.\n\n¢ Hills: If an RTS engine makes use of true line of sight or gives an advantage to\nfighting on an elevation, then detecting hills is a good idea. In Empire Earth, we\ndefined a hill as a collection of points adjacent to each other that are above a cer-\ntain elevation level. We found hills to be very useful for adding to the perception\nthat the computer player played intelligently. Archers owned by the computer\nplayer might flee to a nearby hill to attack from an elevated point, or perhaps the\ncomputer player would choose a hill near a resource site as a good spot for a guard\ntower.\n\n* Shore Tiles: A shore tile is defined as a tile that meets the ocean and the land.\nThis means some shore tiles exist mainly in the ocean and some exist in the shal-\nlow water where most land units can walk. A game with shore waves can use shore\ntiles to determine if they should make a wave, how far out it should start in the\nocean, and what its neighboring waves should look like. Shore tiles can also be\nvery useful for determining at what point a transport ship should pick up or drop\noff a unit.\n\n¢ Shore Rings: Shore rings are defined as tiles that exist within some distance of\nland. If a tile exists two tiles from land, then it would be stored in ‘shore ring 2.’\nShore rings work great for RTS games with units that can span multiple tiles.\nSince collision detection with large units can be a tricky issue, one way to keep\ngigantic ships like aircraft carriers from traveling too close to the land is to build\nrings around the coastline. Any number of rings can be used to keep different",
      "content_length": 3050,
      "extraction_method": "OCR"
    },
    {
      "page_number": 264,
      "chapter": null,
      "content": "270\n\nSection 3 Artificial Intelligence\n\nsizes of ships from reaching the land. If keeping ships away from coastlines is not\nan issue, this is probably not an area that needs to be processed.\n\nDynamic Areas\n\nDynamic areas, which change with the runtime variations of the world, help keep a\ngame from getting stale and add longevity to a product. Computer players that react\nto a changing world provide a greater illusion of intelligence to human players and\ncan give players a fresh gaming experience every time they play.\n\nIn the code, dynamic areas look much the same as static areas, but dynamic areas\ncarry an inherent danger with them. If an area is very large and needs to be\nreprocessed often during a game, it can cause the game to run poorly or even freeze.\nThis can be avoided with some creative tricks, but efficiently reprocessing dynamic\nareas goes beyond the scope of this gem.\n\nSome examples of useful dynamic areas in an RTS are:\n\n* Forests: Forests are defined as a collection of trees that all touch each other.\nForests need to be dynamic, since if a player chops down a tree, the old location\nof the tree should no longer report that it belongs in a forest. If we assume people\nunderstand and recognize forests, then it’s easy to put them to good use. The uses\nof forests should be intuitive. For example, if the player selects a citizen, then\nclicks on a tree in the middle of a forest, the player will probably expect that the\ncitizen (or unit) would harvest from a tree in the vicinity of the unreachable one\nthat was clicked on. If we have analyzed the forest, then we have a variety of sim-\nple ways to find the perfect tree to chop. One technique is simply to go to the\nclosest tree to the unit. Another technique is to calculate the line from the unit to\nthe selected tree, find the first tree in the forest that the line intersects, and then\nsend the unit to that tree. The AI can also use knowledge about the forest for var-\nious tasks, such as planning where to build a wall or where to hide units for an\nambush.\n\n¢ Towns: In the everyday world, most people think of a town as a collection of\nbuildings that are within proximity of each other. The concept is much the same\nin an RTS, with the exception that in the game world, towns should be repre-\nsented as a convex hull in which a number of buildings live (see Figure 3.4.1).\n\nTowns are dynamic because they can grow, shrink, or even merge when a\nbuilding is created or destroyed. Towns also differ from most other areas because\nthe convex hull encompassing all the points is more significant than the points\ninside (individual buildings). In a sense, if one wants to see if a given point were\ninside a town, then they would need to get its convex hull and do a point-in-\npolygon test instead of checking its actual points.\n\nTowns are created and destroyed when buildings are built or razed. The\nprocess of assigning a building to a town starts with the newly constructed build-\ning checking its distance to each town’s convex hull. The distances are then used\nto determine if the new building should join a town, merge two or more towns,",
      "content_length": 3120,
      "extraction_method": "OCR"
    },
    {
      "page_number": 265,
      "chapter": null,
      "content": "3.4 Terrain Analysis in an RTS—The Hidden Giant 271\n\nfe map1_ply - Terain Analysis Test Application :\n\nCreate: 5248 us (5 ms}\nSlowInsert: 5545 us (5 ms)\nBuildPointList: 9804 us (9 ms]\nContains: 3011 us (3 ms)\nExtremePaints: 98 us (0 ms}\nRemove: 61 us (0 m3}\n\nFIGURE 3.4.1 Highlighted area indicates a town.\n\nor create a new town of its own. If a building is within the acceptable distance of\ntwo towns, the towns merge and become a single, larger town.\n\nAn identified town can also serve a greater purpose than just mapping out a\ncluster of player buildings. Storing information about a town can help the AI\nunits make intelligent decisions about where to attack, with what units, and what\nstrategy is best for approaching a town.\n\nA few of the many pieces of information that can be stored about a town are:\n\n* IsCoastal: In many situations it can be quite useful to know if a town is\nlocated near an ocean. The most obvious use for this is to let the computer\nplayer quickly know if they should bother bringing in sea units to bombard\nthe town.",
      "content_length": 1046,
      "extraction_method": "OCR"
    },
    {
      "page_number": 266,
      "chapter": null,
      "content": "272 Section 3 Artificial Intelligence\n\n* TownCost: Computing the economic cost of all the buildings in the town can\ntell the computer player if this is the enemy's biggest town, or if it’s really just a\nsmall hamlet.\n\n¢ Choke Points: Choke points are defined as a narrow routes, such as between two\nforests, which provide passage through to other regions. Choke points are useful\nfor RTS computer players in that they can indicate good guard locations, ambush\nspots, and wall building locations. They can even help a computer player avoid\nblocking itself in by indicating where not to construct buildings. A more detailed\nchoke point description and algorithm can be found later in this gem.\n\n¢ Herds: Herds are packs of similar animal units that share a territory and group\ndynamics. Tracking herds as areas provides a way to keep the herd acting realisti-\ncally, such as having territory disputes or moving around the game world as a\ngroup.\n\ne Armies: Armies are certainly dynamic. They can grow and shrink many times in\nthe course of a game. They are primarily useful for the computer player and its\nplayer interaction, but there are other creative game-engine uses for armies as\nwell, including group movement and group behaviors.\n\nBuilding Generic Areas\n\nObject-oriented programming (OOP) techniques can sometimes have a large up-\nfront development cost; but in general, they make subsequent development faster and\neasier. Designing a generic area system is an example of how OOP can make life easier\nin the long run.\n\nAn area class needs only a few data members. It needs to know the points inside\nthem, the convex hull of those points (more on that soon), the type of area they are,\nand lastly, it needs to have a unique ID. In addition to data, areas should have some\nvirtual methods to make using them a snap.\n\nVirtual methods should include:\n\n* Create(): Creates the area.\n\n* GetClosestPoint(): Gets the closest point to a given point.\n\n* GetClosestPointToArea(): This method takes another area and returns the clos-\nest point between the two areas.\n\n© GetClosestPointToHull(): This is different than GetClosestPoint() because it\nrelies on checking the hull. You could make your derived classes call GetClosest -\nPointToHull() in the GetClosestPoint() method. This is most useful for areas\nlike towns, which have few actual points (the buildings); but you want it to seem\nlike every point in a town is actually stored inside this object (instead of just the\nfew that were used to make the hull).\n\n* GetRandomPoint(): This is probably the most useful area-related method. Using\nthis for computer-player guard destinations saves development time and can help\ncreate the illusion of intelligence.",
      "content_length": 2703,
      "extraction_method": "OCR"
    },
    {
      "page_number": 267,
      "chapter": null,
      "content": "3.4 Terrain Analysis in an RTS—The Hidden Giant 273\n\nOptimization Tip: When you derive a continent area, consider putting lots of\nother areas inside the continent class. For example, have a vector of choke points on\nthe continent so that programmers can quickly get the choke points that they want.\nThis can also serve as a memory optimization for other areas. Using continents as sort\nof a hash table can cut down the search time for tasks, like finding which forest’s hull\na user clicked in. If you return the continent the user clicked on and only search that\nforest, you've cut down your search time.\n\nBuilding your area system with a generic base class will make using your areas a\nlot easier. Your computer player can often make intelligent decisions just by perform-\ning some basic actions on areas without having to know much about the area with\nwhich they are interacting.\n\nOne of the more-complex areas of simulating human intelligence deals with the com-\nputer’s lack of vision. A human can receive an enormous amount of data in a few\nblinks of an eye, while our computer companions cannot. We can simulate this\nbehavior by using a simple and powerful geometric shape, the convex hull.\n\nA convex hull is a shape that does not fold in on itself. If one were to walk clock-\nwise around the edges of a hull, they would turn only to the right and never to the\nleft. Also, If you were to draw a line between those points, the line would never leave\nthe convex hull.\n\nWhile a convex hull is a shape that can exist in many dimensions, for reasons of\nefficiency and usefulness to most RTS engines, it’s generally safe to focus on the 2D\ncase. Certainly, developing a hull system that works in multiple dimensions has its\nbenefits given the development time or specific need for them.\n\nWhy Use Convex Hulls?\n\nConvex hulls take up very little memory, can be very efficient, and provide a fuzzy\nlevel of accuracy. On one end of the spectrum, you could have perfect accuracy by just\nkeeping a list of all the points, but this would be costly in terms of memory usage as\nwell as performance. A concave hull could be more accurate, but it would cost more\nin memory and performance. On the other end of the spectrum, you can use bound-\ning boxes or bounding circles to approximate the areas in question. Both of these use\nvery little memory and can be more efficient (performance-wise), but they suffer from\npoor accuracy in representation. The convex hull brings all of these together, giving us\ngood accuracy, good performance, and low memory usage.\n\nConvex hulls can be used in almost every area of an RTS game engine. They are\nideal for determining if a unit is hidden in the vicinity of a forest or ifa unit has crossed\nthe borders of a town. They also make the creation of complicated AI behaviors simple\nto implement because they provide the programmer with a quick representation of an\narea. Being a special geometric shape, they are bound to mathematical rules that allow\nthe AI to make optimizations and assumptions based on those rules (see Figure 3.4.2).",
      "content_length": 3062,
      "extraction_method": "OCR"
    },
    {
      "page_number": 268,
      "chapter": null,
      "content": "Remove: 61 us (0 ms)\n\n'fsssercessasssss==sss=\n\nFIGURE 3.4.2 A convex hull surrounds an area (shown in a test application).\n\nIt’s not just the useful tasks alone that make the investment in convex hulls so\nappealing. The development time for hulls is fairly short, since the math knowledge\nrequired for writing 2D convex hulls is small (i-e., implementation shouldn't be diffi-\ncult for programmers who aren’t math gurus).\n\nWhat's in a Hull?\n\nA convex hull is really a polygon with special rules. It therefore makes sense to begin\nthe construction of a convex hull class by constructing a base polygon class. It is also\na good idea to make the polygon/convex hull class a template, since most tasks in an\nPC-based RTS game can use integer-based hulls for added performance. Otherwise,\nwe use float-based hulls.",
      "content_length": 809,
      "extraction_method": "OCR"
    },
    {
      "page_number": 269,
      "chapter": null,
      "content": "in an RTS—The Hidden Giant 275\n\nTable 3.4.1 Data Members for a Polygon Class\n\nType Variable Description\nvector<U2DPoint<T>> mPoints All the vertices of the polygon.\nU2DRectangle<T> mBoundingBox Quick representation of the\narea of the polygon. Its area\ncovers the extreme points of\nthe hull or polygon. The box\nhas two points, one at top left,\nand the other at bottom right.\nU2DPoint<T> mCenterPoint Center of mass point. This is\n\nvery handy for making quick,\nfuzzy decisions about distances\n\nto a polygon, or as a homing\n\nbeacon for this shape.\nfloat mArea The area inside the polygon.\n\nNote: U2DPoint<T> is a template xy point class, and U2DRectangle<T> is a template rectangle class\nwith top, left, right, and bottom coordinates.\n\nData members for a polygon class might appear like those shown in Table 3.4.1.\n\nSince this is a base class, there are quite a few necessary virtual methods that it\nshould provide in addition to the normal Get/Set and construction/destruction\nmethods.\n\n* CalculateArea(): Determines the area of the polygon or hull.\n\n* ClearPolygon(): Clears the polygon’s data.\n\n* Contains(): This inline version does a fast point-in-rectangle check before calling\nthe virtual and more-expensive ContainsInPoly() method.\n\ninline bool Contains(const U2DPoint<T>& inPoint) const\n{ return (this->mBoundingBox.Contains(inPoint)) ?\nthis->ContainsInPoly(inPoint) : false; }\n\n* ContainsInPoly(): This virtual method does the appropriate point-in-polygon\ntest for the given point.\n\n* Create(): This creates the polygon, and an optional sorted flag is passed as an\noptimization for shapes like the convex hull.\n\n* CreateCenterPoint(): This virtual method computes the center point using the\nappropriate algorithm. One way to compute the center point is the center-of-\nmass method described here.\n\nU2DPoint<float> theSums(0.0f,0.0f) ;\nlong theSize = this->mPoints.size();\nlong theLoop;",
      "content_length": 1891,
      "extraction_method": "OCR"
    },
    {
      "page_number": 270,
      "chapter": null,
      "content": "276\n\nSection 3 Artificial Intelligence\n\nsavour RSE EEN SAN A ER Rh RO HS SN OSH NTO ATOM HOES\n\n/* Sum up all the points. */\nfor(theLoop = theSize - 1; theLoop >= 0; theLoop--)\n\n{\n// cast to floats regardless of template type.\n\ntheSums .SetX(theSums .GetX() +\n((float)mPoints[theLoop] .GetX() /(float)theSize) );\n\n// cast to floats regardless of template type.\n\ntheSums.SetY(theSums.GetY() +\n\n((float)mPoints[theLoop].GetY() / float)theSize));\n}\n\n//{ cast it into the right format: (template function)\ntheSums .CopyTo(this->mCenterPoint); }\n\n* €xpand(): A handy method for increasing the size of polygons proportionally by\nexpanding outward, a simple expand algorithm would be to draw a line from\neach vertex to the center point and project that vertex away from the center.\n\n* GetClosestPoint(): One of the most useful methods for a convex hull, GetC1los-\nestPoint() returns a potentially fabricated point on the hull. It’s a good idea to\nhave two closest-point methods, one for returning the closest vertex and one for\nreturning the closest line-intersection point on the hull or polygon.\n\n* GetClosestPoints(): Use this method to find the closest point given two poly-\ngons or convex hulls.\n\n* GetIntersection(): Returns true if the two polygons intersect and can optionally\ncreate a polygon representing the intersection.\n\n* SortPoints(): This is a template function used to sort the points.\n\ntemplate<class K> // inFO is a function object.\ninline void SortPoints(const K& inFO)\n{ std::sort(mPoints.begin(), mPoints.end(), inFO); }\n\n* TrimToVitalPoints(): This is where the convex hull-creation algorithm should\nrun; however a normal polygon would probably do nothing in this method.\n\nDeriving from U2DPolygon<T>, the convex hull class needs to overload some of\nthe polygon’s base class methods, and one of the most important methods is Create().\n\nThe Create() method is the entry point for the convex hull-creation algorithm.\nPicking the right algorithm to construct a hull will make a big difference in hull-cre-\nation performance. There are many published convex hull-creation methods and util-\nity functions [O’Rourke98]. One of the favorites among programmers, and the\nmethod used in Empire Earth, is Graham’s algorithm [O’Rourke98].\n\nOptimization Tip: The most expensive part of Graham's algorithm is sorting the\npoints; passing in an ‘already sorted’ flag for those rare occasions when you already\nhave a list of sorted points will save you some CPU time.\n\nConvex hulls are very effective elements in terrain analysis as they allow the pro-\ngrammer to create lots of incredible features in relatively little time. Powerful features",
      "content_length": 2641,
      "extraction_method": "OCR"
    },
    {
      "page_number": 271,
      "chapter": null,
      "content": "277\n\nand low development costs are two things that designers, gamers, and programmers\ncan all smile about.\n\nThe Giant in the Matchbox\n\nORS NERS a PANERA ASAE RELL ARRT EPA ION CLE Sad\n\nHaving the convex hull of an area is terrific—until you need to get an actual point\nfrom the area. If you want a real point (a point that exists on a continent, for example,\nand not just in its convex hull), then you will need a data structure to contain all of\nthe continent's points.\n\nEgads! You're probably imagining thousands or millions of points floating around\nin memory. It is true that gigantic maps and even some smaller maps will be serious\nmemory hogs unless we can employ smarter techniques.\n\nWhat we need is a memory superhero, something to crunch all these evil points\ninto a tiny space without causing a major CPU hit. Answering the call for this crisis is:\nMajor Matchbox—the template-based U2DMatchboxContainer class.\n\nThe u2DMatchboxContainer class, known throughout the rest of this gem as the\n“matchbox container,” is a series of linked lists that contain point ranges and simulate\nactual points. A matchbox container is really just a one-dimensional array in x, which\ncan contain linked lists of start and end y value nodes.\n\nConsider a square blank map that consists of a single land continent. If the map\nis 400 x 400, then the continent contains 160,000 points. If we put these points\ninside a matchbox container, the 160,000 points end up turning into only 400 points,\nsince we only need to store one point for each x value. This is because the continent is\nalready convex (it’s a square). If we take a more-complicated example and store the\npoints from Figure 3.4.3a in a matchbox container, the end result would look much\n\nlike Figure 3.4.3b.\n\nConti\n\nnent “|\n\ne=end\n\nor Area _ sie = start and end nodes\n\nA B\n\nFIGURE 3.4.3 (a) A continent or area. (6) How a continent’ points would be stored in a matchbox\n\ncontainer.",
      "content_length": 1929,
      "extraction_method": "OCR"
    },
    {
      "page_number": 272,
      "chapter": null,
      "content": "Section 3 Artificial Intelligence\n\nWhat’s in the Matchbox?\n\nThere are three important structures in the matchbox system—the matchbox con-\ntainer node, the matchbox container list header, and the manager of all these: the\nmatchbox container. Inside the matchbox container lives an array of header nodes.\nThe array represents the x-axis, although it could just as easily represent the y-axis, or\neven be dynamically based, which would take up less memory.\n\nData members for the matchbox container are shown in Table 3.4.2. Note that\n\nthis should be made into a template class; but for simplicity, this is being shown as an\ninteger container.\n\nTable 3.4.2 Data Members for the Matchbox Container\n\nvector<MatchboxListHeader*> MPointArray X-axis representation of\n\nVariabl Description\n\npoints. Each element in the\narray is a y (start-end) point\n\nlong\n\nrange-linked list.\nMOffset Odds are that x won’t start at\nzero; but we want our array\n\nlong\n\nto start at zero, so we will\nshift all incoming x\n\ncoordinates by this amount.\nThis means if our points go\nfrom x,y (10,50) to (25,99),\nthen our offset would be 10.\nMSize Number of points inside this container.\n\nSome of the methods for the matchbox container are:\n\nBuildPointList(): Fills the incoming vector with all of our points. In a sense, it\nputs all of our points into an array format. Passing in a step level is important for\ntemplate versions because, if this container used floating-point numbers instead\nof integers, the step level would indicate at what rate we increment each value as\nwe generate our list of points.\n\nComputeCenterPoint(): This handy method uses a center-of-mass computation\nto determine the center of all these points.\n\nContains(): Returns true if the passed-in-point exists (real or implied) inside this\ncontainer.\n\nCreate(): Creates our container from the passed-in-points.\n\nGetClosestPoint(): Odds are, you'll eventually want to quickly retrieve the clos-\nest point to a passed-in-point or another matchbox container.\nGetOnlyExtremeEdgePoints(): This gets only the extreme edges of a polygon.\nThis means if a continent is doughnut shaped, none of the inner-rim doughnut",
      "content_length": 2143,
      "extraction_method": "OCR"
    },
    {
      "page_number": 273,
      "chapter": null,
      "content": "3.4 Terrain Analysis in an RTS—The Hidden Giant 279\n\npoints would be returned. This is ideal for optimizing the computation of a con-\nvex hull. It's a huge optimization to build a hull with 200 points instead of\n80,000. It’s also possible to write a very fast convex hull-creation method based\non previously known extreme points and incorporating the sorting implied in the\nstorage of this structure.\n\n® GetRandomPoint(): By passing in a random number generator, you can have a get-\nrandom-point method that will be used more than you might expect.\n\n* Insert(): Having three insert methods is useful. One method takes a point,\nanother takes a vector of points, and a third method takes a matchbox container.\n\n* Remove: Given a point or a vector of points, this method should remove them\nfrom the container.\n\n* Operator[]: A useful method that simulates an array traversal.\n\nMatchboxListHeader\n\nThis class contains a linked list of container nodes and a size. It does most of the work\nby inserting, removing, and merging nodes.\n\nMatchbox Container Node\nThe matchbox container node contains a start y and an end y coordinate. All methods\nin it are based on checks to see if a passed in point or coordinate exists within its start-\n\nto-end range.\nA Contains() method would look like this:\n\ninline bool Contains(long inNum) const\n{ return (inNum >= this->mStart && inNum <= this->mEnd); }\n\nBy putting the pieces of the matchbox nodes, header, and container together,\nyou'll have a fast data structure capable of handling many points in a small amount of\nmemory. It’s an incredibly useful tool for optimizing terrain analysis and other areas.\nMost game engines use points, and therefore should have this or a similar structure in\ntheir toolbox.\n\nYou will recall that choke points are narrow passages that provide access to other\nregions. That being said, the method of creating choke points is really unique to every\ngame. In the RTS game Empire Earth, choke points are created when two or more\nlarge areas—such as a forest, cliff, ocean, or edge of the map—are near each other but\ndo not touch (see Figure 3.4.4).\n\nFrom out of the Blue\n\nImagine it is a bright sunny day and you want to send a cavalcade of riders and vil-\nlagers north toward the plains to build a settlement. You seem cheery and optimistic",
      "content_length": 2302,
      "extraction_method": "OCR"
    },
    {
      "page_number": 274,
      "chapter": null,
      "content": "280\n\nSection 3 Artificial intelligence\n\nas you set out on your journey. You anticipate a smooth trip, since reports of enemy\nsightings along the road have been minimal.\n\nWhile on your journey, you approach a passage that is flanked by a forest on either\nside. The passage seems harmless enough as your traveling companions bask in the\nbright morning sun and smile at the sound of singing birds. Midway through the\nwooded lane, the songs of the birds become drowned out by a volley of curses and the\nthunder of hooves, which seem to come from all directions. The passage, once a tran-\nquil scene, now seems to be collapsing in around you with a hail of fiery arrows and\ncharging horsemen! Screams fill the air as you beckon your troops to turn back. You\nwheel and turn, only to have lines of despair crease your forehead. You watch helplessly\nas the rear of your army collapses under a mass of enemy troops. Your army breaks in a\npanic, and you stare, too shocked to move, at the helpless villagers that were under\nyour protection. You put your hands to your ears, attempting to block the screams that\nwere once laughing, joking voices. There is no escape, the enemy is everywhere at once,\nand the only choice is to charge blindly into the rising dust at either the front or the\nrear of the passage. You know what must be done; and you begin your final assault. You\nare now one of the screaming horde, sword raised, horse charging, and for the few\nmoments before you are cut down, you try to even the score a bit.\n\nThe Plan\n\nHow did the computer player plan such an evil encounter? Was it good planning,\nluck, or perhaps just knowing information about the terrain? As you might imagine,\nchoke points are great for planning ambushes. Let’s walk through how the computer\nwas able to plan this attack.\n\nFirst, the computer must pick a choke point from which to launch its ambush.\nMaybe it selected a random choke point or found a highly traveled one, or perhaps it\neven selected one between the enemy (the human player) and the main town. Regard-\nless of how it was chosen, the computer might choose to divide its ambush troops into\nfour divisions and place them all at opposite, extreme points of the choke point, as\nindicated in Figure 3.4.4.\n\nNotice that the four black Xs are the farthest points of the choke point. This is\nwhere the computer player hides its troops and waits for the enemy to pass. It waits\nand watches until the enemy has reached the center of the choke point (the + sign),\nthen the computer lets out a howl and attacks!\n\nIn Empire Earth, having the choke point, together with its points and its convex\nhull, made planning and executing this ambush simple. The computer player did not\nhave to do a lot of intensive CPU planning. Instead, it simply picked a good spot and\nthen waited for its opportunity to attack.\n\nFinding the Choke Point\n\nThe algorithm for finding a choke point temporarily costs a large amount of memory\nand CPU time, all of which fortunately go away once the choke points have been",
      "content_length": 3020,
      "extraction_method": "OCR"
    },
    {
      "page_number": 275,
      "chapter": null,
      "content": "3.4 Terrain Analysis in an RTS—The Hidden Giant _ 281\n\nFIGURE 3.4.4 Ambush in a choke point.\n\ncomputed. Most of the memory requirements involved go into making the algorithm\nrun quickly, so you can trade performance for memory if you wish.\n\nBefore we describe the algorithm, keep in mind that you'll need quite a few\n(mainly integer) arrays that are the size of the world. Don’t panic; this is only tempo-\nrary memory and will be returned after the choke points are computed. If you can’t\nafford the memory even temporarily, consider breaking the world down into conti-\nnents or some other area division first, and then use the bounding box of the conti-\nnent or area as the ‘map of the world.’\n\nThe idea behind this algorithm is that each terrain area is given an influence\n(called throughout the rest of this gem as an “aura”) that can grow. The number of\npasses this algorithm will perform determines how much this aura will grow. If two or\nmore auras intersect each other, then a choke point is formed.\n\nThe main loop of the algorithm is as follows:\n\n// copy the original map into choke point map.\nCopyOriginalMapInt oChokePointMap(inMap, theOutMap) ;\n\n// inPasses controls how much area's auras grow.\nfor(theLoop = inPasses - 1; theLoop > 0; theLoop--)\n{",
      "content_length": 1259,
      "extraction_method": "OCR"
    },
    {
      "page_number": 276,
      "chapter": null,
      "content": "282 Section 3 Artificial Intelligence\n\ninfluence\naura\n(light grey)\n\nFIGURE 3.4.5 An area (dark color) and its influence aura (light gray).\n\n// copy the map. (uses cached map from above\n\n// the loop)\n\nCopyOriginalMapIntoChokePointMap(inMap,\ntheResultMap) ;\n\n// apply the algorithm\nApplyChokePointAlgorithmToMap(theOutMap,\ntheTempMap, theMaxX, theMaxyY));\n\n}\n// create the final choke points.\n\nCreateChokePointAreas(inMap) ;\n\nBefore the main loop begins, we have to generate and cache a map of obstacles. If\na tile has an obstacle on it, then the tile gets a blocked cost (whatever is appropriate\nfor your game), otherwise it gets a zero cost.\n\nThen, for every tile in the world:\n\n// cache the XY array position\nlong thexY = ((theXLoop * theMaxX) + theYLoop);\n\n// if this tile is blocked, fill in the areas id\nif (ChokePoint: : IsBlockedTile(inMap ->GetTile(theXLoop,\ntheYLoop), theXLoop, theYLoop, theArealID) )\n\n{\n// store the blocking area's id and set a cost.\nChokePoint: :sTerrainIDMap[thexY] = theArealID;\nChokePoint: :sCostMap[theXY] = kBlockedCost;\n\n}\n\nelse",
      "content_length": 1063,
      "extraction_method": "OCR"
    },
    {
      "page_number": 277,
      "chapter": null,
      "content": "3.4 Terrain Analysis in an RTS—The Hidden Giant 283\n\nelt IE SON ER US RR RH RCE EERE LE ORO\n\nChokePoint::sTerrainIDMap[thexXY] = 0;\nChokePoint: :sCostMap[thexY] = 0;\n}\n\nAfter caching these values in the static cost/terrain ID map, subsequent calls to\nCopyOriginalMapIntoChokePointMap() will simply do a memcpy()of the sCostMap.\n\nThe real algorithm is in the ApplyChokePointAlgorithmToMap() method. This\nmethod must loop through every tile in the world (‘“tile” in this case means the map\nof open and obstacle tiles). If a tile does not have an obstacle, then for each of this\ntile’s neighbors, we sum up all the costs for all the nonblocking tiles. To add up each\nneighbor's cost, we simply refer to the ‘current cost map,’ which means we get all the\ncosts from previous algorithm passes. Using the costs from prior passes is what makes\nthe auras grow.\n\nIf we get a tile with a cost when looping through the neighboring tiles, we then\ncache its area ID. This tells us from which area the aura grew. That’s not enough,\nhowever, since we have to identify whether this cost came from our aura or a different\none.\n\nAs the auras grow, they mark tiles as being from their aura. If the auras intersect,\nthey mark tiles with a ‘compound-area’ ID. If we see that one of our neighbors has\neither the compound-area ID or an aura ID that is not our own, then we keep this\ncost. Otherwise, we set our cost to zero if no neighbors have a cost and come from\neither a different aura or a compound aura. This keeps areas from creating choke\npoints with only themselves.\n\nAt the end of our tile loop, each tile takes the sum of its neighbors (zero if they\nwere not a compound aura or a different aura) and divides the sum by the number of\nqualified neighbors that contributed to our sum. That tends to give the choke points\nan hourglass shape, but you can fine-tune this to achieve different results.\n\nAfter executing all the desired passes, you end up with an array of scores that are\neither zero, blocked, or some other score. The last step is to gather the adjacent scores\nand create choke points out of them. The perfect tool for this (and all other terrain\nanalysis detection tasks) is the A* machine described in the book Al Wisdom [Hig-\ngins02a]. If you don’t want to create an A* machine, then a flood-fill algorithm can\ngather these scores and create the choke point areas.\n\nThis algorithm sounds expensive, but with the right optimizations, it can be very\nfast.\n\nWhen you write a terrain-analysis engine, much of its success is determined by\nhow generic it can be written and how optimized it is. In Empire Earth, we used an\nA* machine, which is a highly optimized and generic tool that can be used for every-\nthing from path-finding units to creating forest areas and other terrain-analysis tasks\nas well.",
      "content_length": 2798,
      "extraction_method": "OCR"
    },
    {
      "page_number": 278,
      "chapter": null,
      "content": "284 Section 3 Artificial Intelligence\n\nConclusion\n\n‘ss Mea RR ARI\n\nCertainly, one of the major tasks faced when creating an RTS engine is terrain analy-\nsis. Successful games can still ship without complex terrain analysis, but the more\ntools provided to programmers, the more plentiful and advanced the game features\nwill be. Terrain analysis demands a high-performance, generic engine, and developing\nsuch an engine takes a significant amount of time. However, if done well, and if the\nterrain information is used creatively, it pays for itself many times over.\n\nSRR SAR es eR ES ERRORS TTR RT en\n\nReferences\n\n[Higgins02a] Higgins, Daniel F, “Generic Path-finding,” AJ Game Programming\nWisdom, Charles River Media, Inc., 2002.\n\n[Higgins02b] Higgins, Daniel E, “How to Achieve Lightning Fast A*,” AJ Game Pro-\ngramming Wisdom, Charles River Media, Inc., 2002.\n\n[O’Rourke98] O’Rourke, Joseph, Computational Geometry in C, Second Edition,\nCambridge University Press, 1998.",
      "content_length": 971,
      "extraction_method": "OCR"
    },
    {
      "page_number": 279,
      "chapter": null,
      "content": "3.5\n\nAn Extensible Trigger System\nfor Al Agents, Objects,\nand Quests\n\nSteve Rabin, Nintendo of America, Inc.\n\nsteve@aiwisdom.com\n\nWw\": your players exhaust the single-player version of your game and then search\nonline for more levels or the level editor, you should be prepared to quench\ntheir thirst. Extensible levels and quests are the hallmark of a well-designed game, and\nenable a faithful following to extend your game’s normal life span. Whether your\ngame is an RTS, an RPG, or an action game, you should allow the player some way to\ncustomize the levels and build new areas to conquer.\n\nBaldur’s Gate, StarCraft, and Dungeon Siege are all great games that allow the\nplayer to create new quests, and in certain cases, modify and extend the AI. However,\nthe player is not a programmer, and you shouldn't force them to learn a fictional pro-\ngramming language and debug their creations. Simplicity is the key to allowing the\naverage player to tinker with your game, and it can be achieved by implementing an\nextensible trigger system.\n\nIntroducing t the the Trigger System —\n\nA trigger system is a centralized piece © of code that does o: one ne thing: It evaluates condi-\ntions and executes responses. If a set of conditions is met, a set of responses is exe-\ncuted. This simple system is elegant, easy to implement, and easy to data-drive\n[Rabin00]. It can solve a variety of problems and is especially good at being modified\nby designers and players. Best of all, it makes it easy to create exciting, new, interactive\nenvironments for the players to explore.\n\nConsider a game where you take a brave band of adventurers to explore a dun-\ngeon. As you trace through the catacombs, a pillar crumbles and almost crushes your\nleader. As you reach an impressive stone door, an icy draft snuffs your torches. After\nlighting your last torch, you decipher the inscription on the door and it reads, “Heavy\nare the hearts who pass through this doorway.” With a little thought, you place the\nmembers of your party on the heart-shaped floor tiles, and the door slowly grumbles\nopen.\n\n285",
      "content_length": 2082,
      "extraction_method": "OCR"
    },
    {
      "page_number": 280,
      "chapter": null,
      "content": "286\n\nObject-Owned Trigger | Systems\n\neR\n\nSection 3 Artificial Intelligence\n\nEach of the previous events can be specified with a trigger system using the sim-\nple condition-and-response paradigm. When a party member walked within a meter\nof a particular pillar object, it responded by falling. When the party walked within\ntwo meters of the door, the response was to play a sound effect for wind and extin-\nguish the surrounding torches. When each heart-shaped floor tile was touched by a\nmember of the player’s party, the response was to slide open the door and play a stone-\ngrinding sound effect.\n\nA trigger system can be made with just enough hooks that both your designers\nand your players can spend hours making innovative scenarios and quests. The Star-\nCraft level editor is a fine example of a trigger system that you should examine and\nplay with. Many of the following ideas will expand on that particular functionality.\n\naan RARE oS REE Ra rR IRR\n\nWhile a master trigger system seems like the natural choice (as demonstrated in\n[Orkin02]), perhaps a more-powerful architecture is to consider a trigger system class\nthat any agent, object, or quest can own. Not every object requires one, but the abil-\nity to own an instance of a trigger system keeps data encapsulated within the objects\nand makes the system more flexible and object-oriented. It’s also natural to think of\ntriggers existing on particular items, so the concept is still easy for players to grasp.\n\nConsider the pillar that falls over when someone stumbles near it. We could\ndefine such a pillar in a level editor and attach a trigger definition that encompasses\nthe falling behavior. Then, a designer or player could place dozens of these pillars in\nthe game and they all magically display the same behavior, since the trigger behavior\nis directly attached to the object. In this way, any agent, object, or quest can own a\ntrigger system that is completely dedicated to that single entity.\n\nDefining a Condition\n\nRET HIB INAT NY Ta NN TINH BERTHS GER SS WH\n\nA condition can be any event or state that you can quantify i in your game. Conditions\nare fixed in the executable, but are highly configurable through arguments or a level\neditor. Below is a list of possible conditions:\n\n¢ Player within radius R of spot (x, y, z)\n\n* Player within boxed area position (x, , z)\n¢ Proximity of an enemy to the player\n\n° Life of the player below X%\n\n* Object X in player's inventory\n\n* Object X equipped by player\n\n¢ Player was killed\n\n¢ Player reached X level\n\n¢ Player talked to character X\n\n¢ Player killed enemy X\n\n° Player received message X",
      "content_length": 2612,
      "extraction_method": "OCR"
    },
    {
      "page_number": 281,
      "chapter": null,
      "content": "3. 5 An Extensible Trigger System for Al Agents, Objects, and Quests — oe 287\n\nConditions Connected with Boolean Logic\n\nsthgoaeeenansgaunesbonmnnnmessien RE MSA RAR RSET RCH\n\nAAR A AE RRS EOR TREE\n\nIn order to make conditions even more flexible, it is advantageous to allow conditions\nto be linked together with Boolean operators, such as AND, OR, NOT, or XOR. For\nexample, if a door is to open when you are equipped with the ice sword, ice shield,\nand ice armor, these conditions must be ANDed together. If a door opens if you are\nholding either the silver key or the skeleton key, then those conditions must be ORed\ntogether. Figures 3.5.1 and 3.5.2 demonstrate these conditions with a tree structure.\n\nIf true, trigger fires\n\na at Door Opens\n\nEquipped\nIce Armor\n\nEquipped Equipped\nIce Sword Ice Shield\n\nFIGURE 3.5.1 [fall three conditions are “true,” then the door will open.\n\nIf true, trigger fires\n\n— Door Opens\n\nHolding Holding\nSilver Key Skeleton Key\n\nFIGURE 3.5.2 Jf either condition is “true,” then the door will open.\n\nThe situation gets even more interesting if you require that the player have the ice\nsword, ice shield, and ice armor equipped, as well as possessing either the silver key or\nthe skeleton key. Figure 3.5.3 shows this configuration.\n\nThe visualization from these first three figures is important, since it provides a\ngood way to structure the code. If each element is a class, we can have two types of\nclasses: an Operator class and a Condition class. The Operator class can be configured\nto behave like any Boolean operator. It also contains a list of pointers to Operator\ninstances or Condition instances, which are the subjects of the single Boolean opera-\ntor. The Condition class is able to evaluate any testable condition and contains the\narguments that customize it.",
      "content_length": 1801,
      "extraction_method": "OCR"
    },
    {
      "page_number": 282,
      "chapter": null,
      "content": "Definin\n\nSection 3. Artificial intelligence\n\nIf true, trigger fires\n—_—_ > Door Opens\nEquipped\nIce Armor\nHolding Holding\nSilver Key Skeleton Key\n\nFIGURE 3.5.3 A more-complicated set of conditions for the door to open.\n\nEquipped\nIce Shield\n\nA response can be any state or action in the game that you want to change. Again,\nthese are fixed in the executable, but they can be customized through arguments or a\nlevel editor. The following is a list of possible responses:\n\n* Level/Quest complete\n\n¢ Hurt/Heal player by X points\n\n¢ Give player X experience\n\n¢ Open/close/lock/unlock door\n\n¢ Spawn X creatures of type Y\n\n* Kill X creatures\n\n¢ Play sound\n\n¢ Play random sound from list\n\n¢ X% chance of playing sound\n\n¢ Move player/enemy X to spot (x,y,z)\n¢ Spawn special effect in spot or on player/enemy\n¢ Set player/enemy X on fire\n\n* Poison player/enemy X\n\n¢ Stun player/enemy X\n\n¢ Make player/enemy X invincible\n\n¢ Make player/enemy X invisible\n\n¢ Reset trigger\n\n¢ Send message X to player\n\nIf a particular set of conditions is met, the response will be executed. However,\nthe responses can be further expanded to include a list of responses, instead of just",
      "content_length": 1155,
      "extraction_method": "OCR"
    },
    {
      "page_number": 283,
      "chapter": null,
      "content": "289\n\none. In this way a single trigger can either affect several things simultaneously when it\nfires or randomly choose between several possibilities.\n\nEvaluating a Trigger\n\nOnce a trigger is defined\nwhen it should fire. The first consideration is if a particular condition should be\nevent-driven (waiting for an event to be reported to the trigger system), or if it should\npoll the world (checking for the truthfulness of the condition every couple of game\nticks). In practice, you'll want the flexibility to create conditions that are either event-\ndriven or polled; it will be advantageous to build in this dual functionality.\n\nFor conditions that are event-driven, we need an interface for events to enter the\ntrigger system. The simplest mechanism is to use event messages. Event messages are\nsimply a notification that some event has occurred, along with any relevant data. For\na more in-depth discussion of event messages, refer to [Rabin02].\n\nFor conditions that are polled, we can call an update function within the trigger\nsystem that allows for each polling condition to do its work. Event-driven conditions\nwould ignore this update.\n\nWhether an event message or a polling update enters the trigger system, we need\na way for it to propagate through the conditions. Figure 3.5.4 shows an example of a\ncondition set that requires both event messages and polling. The left condition is\nwaiting for a collision event, while the right condition will poll for the condition\nwhen a polling update is received.\n\nWhen an event message or polling update enters the trigger system, it is routed to\nthe root Operator instance of each trigger. The Operator then passes it through to its\nchildren and expects either a “true” or “false” to be returned. Each child in turn passes\n\nEvent Messages\nand\nPolling Updates\n\nIf true, trigger fires Spawn 10\nRats\n\nPlayer Within Player Health\n10 meters Above 50%\n\nFIGURE 3.5.4 A trigger example that contains an event-driven condition (bottom left)\nand a polling-based condition (bottom right).",
      "content_length": 2029,
      "extraction_method": "OCR"
    },
    {
      "page_number": 284,
      "chapter": null,
      "content": "290\n\n_Section 3 Artificial Intelligence\n\nit to its own children. When it reaches a condition, the child then returns “true” or\n“false” based on the new state of the condition. The return values are then evaluated\nat every Operator instance, and then passed up to its parent.\n\nIt is important to note that the Operator class should use lazy evaluation when\nprocessing its children. If any condition is not satisfied according to the operators, the\ntrigger testing is abandoned at this time. For the example in Figure 3.5.4, an event\nmessage sent to the left condition, which happens to result in “false,” should cause the\nevent message to never be sent to the right condition. This will help reduce the\namount of processing required.\n\nAnother important thing to note when using event-driven conditions is that they\nmust remember events until they are manually reset. With the example in Figure\n3.5.4, if the player gets within 10 meters, a collision event should be sent to the trig-\nger. The condition should remember that event and always return “true” upon further\nevent messages or polling updates.\n\nAt some point, the conditions for the specific trigger will all return the proper value,\ncausing the trigger to fire. Once a trigger is fired, it will remember and not fire again.\n\nSingle Shot and Reload Times\n\n“SbORR SY eR oa er oaananiOSE Sats: RARER ER AAN\n\neiconinnnnee CREE\n\nAll triggers should have two additional properties that are defined by the designer:\n\nbool SingleShot; // Whether the trigger should only\n// fire once.\n\nfloat ReloadTime; // If it should fire multiple\n/{ times, how long before it\n// resets.\n\nThese two properties allow triggers to fire more than once. The SingleShot prop-\nerty determines whether the trigger should fire once or be allowed to fire multiple\ntimes. If SingleShot is “false,” then the ReloadTime determines how long before the\ntrigger resets all of its conditions and accepts events again.\n\nCombining Triggers with Flags and Counters\n\nqr cReRNPRREARNRGN\n\nERA URNA SO AIR BH RRR a RARE ME HERMES.\n\nTriggers can be combined together only if they are able to set intermediary states that\nevery trigger within the system has access to. Thus, every trigger system can be outfit-\nted with a set of flags and counters to keep track of triggers that have fired. To make\nthis as general as possible, we'll let each trigger create arbitrary flags simply by refer-\nring to them with a string name. The trigger system will create a flag as it is refer-\nenced, or set and keep it around until the system is destroyed.\n\nConsider these new conditions:\n\n¢ Is flag_name true/false?\n\n* Is flag_name even/odd?\n\n* Is flag_name1 and flag_name2?\n\n* Js flag_name1 and not flag_name2?",
      "content_length": 2707,
      "extraction_method": "OCR"
    },
    {
      "page_number": 285,
      "chapter": null,
      "content": "3.5 An Extensible Trigger System for Al Agents, Objects, and Quests 291\n\n¢ Is flag_name1 OR flag_name2?\n\n¢ Is flag_name1 XOR flag_name2?\n\n* Is flag_name1 and flag_name2 and flag_name3?\n¢ Is flag name count equal to X?\n\n* Is flag_name count more than X?\n\n¢ Is #lag_name count less than X?\n\nConsider these new responses:\n\n¢ Increment the value represented by flag_name.\n\n* Decrement the value represented by flag_name.\n\n¢ Set the value represented by flag_name to a value of X.\n\n¢ Set the value represented by f1ag_name2 to the value of flag_name1.\n* Toggle the boolean value represented by f1ag_name.\n\n¢ Set the boolean value represented by f1ag_name to TRUE.\n\n¢ Set the boolean value represented by flag_name to FALSE.\n\nWith these flags and counters, we can have the trigger system mark or count\nevents, such as counting how many times a player visits a particular area. In addition,\nthe trigger system can now be made to only trigger on particular sequences of events,\nlike stepping on three individual tiles in a specific order. Because these flags and coun-\nters hold state information, many more types of triggers are now possible.\n\nThe example in Figure 3.5.5 shows how to cause a clue to be dropped if the\nplayer can't get through a particular door and is visiting certain areas over and over\n\n> Increment . Increment\n\nPlayer in\nAreaA\n\nFIGURE 3.5.5 Three triggers that work together through a counter named “Visited.” If\nthe player visits Areas A and C alternatively eight times without unlocking Door D, then\na clue is dropped.",
      "content_length": 1534,
      "extraction_method": "OCR"
    },
    {
      "page_number": 286,
      "chapter": null,
      "content": "292\n\nSection 3 Artificial Intelligence\n\nagain in desperation. Note that there are three separate triggers that are cooperating\nthrough a counter named “Visited.”\n\nNote that with the addition of flags and counters, the trigger system becomes\nstrikingly reminiscent of a blackboard architecture [Isla02]. The flags and counters\nmake up the blackboard, and the triggers are the knowledge sources (KSs) that operate\non the blackboard data. However, since the triggers mostly act on data coming from\noutside of the blackboard, the trigger system is not formally a blackboard architecture.\n\nTrigger Systems Versus Scripting Languages\n\nPRU aRRIRRA SH ORR aR IRRRTININ SGRBBORUDRNS TARANEH 2 AAA OE LARA H ORN I\n\nYou have probably noticed that the functionality of the t trigger system, especially with\nthe addition of state information, is becoming strikingly similar to the functionality\nof a scripting language. While the functionality does overlap, consider these benefits\nof using a trigger system instead of a full-featured scripting language:\n\n° A trigger system can be specified completely within a GUI. Scripting languages are\nrarely focused enough to allow this type of simplified and robust authoring.\nIncorrect syntax isn’t a problem, since triggers are structured around conditions\nand responses.\n\n° A trigger system 1s very accessible to users. The concept is easier to understand, and\nmore people will actually try to use it.\n\n° A trigger system is constrained. Since the trigger system is well-constrained, the user\nis unlikely to crash the game, since they can only perform a small, focused, well-\ntested set of actions (responses).\n\n° A trigger system is quick to implement and modify. A trigger system can be imple-\nmented in a fraction of the time of a full scripting language. The time scale is on\nthe order of weeks compared to a scripting language, which can take months or\nyears to implement [Tozour02], [Brockington02].\n\n° A trigger system is easy to document. A trigger system is relatively simple to write\ndocumentation and examples for—something always needed if you want the user\nto roll their own after the game is released.\n\nLimitations\n\nARR RE RHE 9 A BR amma ari DIER 89 rR RR SAH RY LER ET ROO HER,\n\nThe main n limitation of the system described is that it doesn’t scale well. However, this\ncan be fixed with some extra code to cull irrelevant triggers. Proximity culling has\nproven to be quite effective.\n\nAnother limitation of the system is that the vocabulary for defining conditions\nand responses is fixed within the executable. Thus, hooks into the code have to be\ndeliberately placed by programmers. This is also a good thing, since it helps to safe-\nguard your game from random or malicious tinkering.",
      "content_length": 2734,
      "extraction_method": "OCR"
    },
    {
      "page_number": 287,
      "chapter": null,
      "content": "3.5 An Extensible Trigger System for Al Agents, Objects, and Quests 293\n\nConclusion\n\nRRS RNR eke IN SESE TENDONS TTA RAST SE Rn EAN a Qe Sa RRL eee gwoRseRRERE ERENT\n\nAn extensible trigger system might be a luxury for many games with tight develop-\nment schedules, but it’s a worthy feature that will add value and depth to your game.\nIn addition, an extensible trigger system is also an effective way to have level designers\nconstruct logic without having to become proficient programmers. While a trigger\nsystem at first glance can seem too simple a solution, the goal is to empower designers\nand players. The easier it is to define content and level-specific logic, the bigger your\ngame can be and the more fun your players will have.\n\nReferences\n\nNEAR RITRE\n\n[Brockington02] Brockington, Mark, and Mark Darrah, “How Not To Implement a\nBasic Scripting Language,” AJ Game Programming Wisdom, Charles River Media,\nInc., 2002.\n\n[Isla02] Isla, Damian, and Bruce Blumberg, “Blackboard Architectures,” AJ Game\nProgramming Wisdom, Charles River Media, Inc., 2002.\n\n[Orkin02] Orkin, Jeff, “A General-Purpose Trigger System,” Al Game Programming\nWisdom, Charles River Media, Inc., 2002.\n\n[Poiker02] Poiker, Falco, “Creating Scripting Languages for Non-Programmers,” A/\nGame Programming Wisdom, Charles River Media, Inc., 2002.\n\n[Rabin00] Rabin, Steve, “The Magic of Data-Driven Design,” Game Programming\nGems, Charles River Media, Inc., 2000.\n\n[Rabin02] Rabin, Steve, “Enhancing a State Machine Language Through Messag-\ning,” Al Game Programming Wisdom, Charles River Media, Inc., 2002.\n\n[Tozour02] Tozour, Paul, “The Perils of AI Scripting,” AJ Game Programming Wis-\ndom, Charles River Media, Inc., 2002.\n\nea RRNA ERR ORR SIN PE Ck LOS NUL A A RRS ERTS",
      "content_length": 1747,
      "extraction_method": "OCR"
    },
    {
      "page_number": 288,
      "chapter": null,
      "content": "3.6\n\n294\n\nTactical Path-Finding with A*\n\nWilliam van der Sterren, CGF-Al\n\nwilllam@cgf-ai.com\n\nf all games were just about getting from point A to point B, AI would solely have to\nprovide the shortest paths. A standard A* algorithm could do the job. However,\noften when trying to reach point B, the AI also needs to avoid being seen or shot at.\nThis is called tactical path-finding, a situation where the AI needs to balance short\ntravel times with avoiding hostile observation and fire (see Figure 3.6.1). Whether\nhandling a tank platoon retreating behind a ridgeline or an X-Fighter sneaking\nthrough a cloud of meteoroids, the AI needs to consider enemy positions and their\nlines of fire.\nTactical path-finding not only adds a realistic touch to AI movement, but it also\npresents a more-rewarding and less-predictable opponent for the player. This gem will\nhelp you to extend the standard A* algorithm so it generates tactical paths.\n\ndestination\n\nFIGURE 3.6.1 A path that alternates exposure with cover and concealment.",
      "content_length": 1021,
      "extraction_method": "OCR"
    },
    {
      "page_number": 289,
      "chapter": null,
      "content": "3.6 Tactical Path-Finding with A* 295\n\nFirst, we will introduce a small change to the ‘shortest-path’ A* algorithm by\nincreasing the costs for movement through locations subject to enemy observation or\nfire. As a result, A* will generate paths that atrempt to avoid enemy observation and\nfire. These attempts, however, often look artificial and are not tactically sound.\n\nWe will then look at a few of these ‘flawed’ tactical paths, figure out why these\npaths are flawed, and how we can correct this in our A* cost function. We will also\ncompare the computing costs of finding tactical paths with those of finding shortest\npaths. Obviously, finding tactical paths will be more expensive, but we will look into\na few techniques and tricks to limit the overhead of the A* search and the line-of-fire\nevaluations that need to be done during the tactical path computation.\n\nOn the CD-ROM, you will find an extended version of James Matthews’ A*\nExplorer tool [Matthews01]. With this tool, you can experiment with tactical A* (and\nfollow all the examples included in this gem).\n\nA* is a generic search algorithm. To allow it to find paths for our AI, we equip it with\na cost function and a heuristic function [Stout00]. For path-finding, the cost function\ncomputes the exact cost of moving from one location to another. These movement\ncosts are computed from the distance traveled and the speed allowed by the terrain.\n\nThe heuristic function for path-finding typically provides an estimate of the\nremaining costs to the destination, such as the vector length divided by the maximum\nspeed. Listing 3.6.1 shows an example of a cost function and a heuristic.\n\nListing 3.6.1 Cost function and heuristic for evaluating shortest paths.\n\nfloat MovementCostNodeToNode(node* aFromNode, node* aToNode) {\nfloat dist, fromMoveCost, toMoveCost;\ndist = (aFromNode->origin —\naToNode->origin) .Length();\n\naFromNode->GetLocalMovementCosts();\naToNode->GetLocalMovementCosts();\n\nfromMoveCost =\n\ntoMoveCost =\n\n// take the average\n\nreturn kTravelTimeFactor * dist *\n(fromMoveCost + toMoveCosts) / 2;\n\n}\n\nfloat HeuristicNodeToDestination(node* aToNode,\nnode* aDestination) {\nfloat dist;\ndist = (aToNode->origin —\naDestination->origin) .Length();\n\nreturn kTravelTimeFactor * dist *\n(minimalMoveCostForAnyLocation) ;",
      "content_length": 2288,
      "extraction_method": "OCR"
    },
    {
      "page_number": 290,
      "chapter": null,
      "content": "296 Section 3 Artificial Intelligence\n\nne kote Cc LEE RE EN ee SRN HOE RA Senn oneeKoRUN Ryn RIE\n\nUsing such a cost function and heuristic A* will find and return a path with the\nlowest costs to the destination. Typically, the AI is interested in the path that gets it to\nthe destination most quickly, so the costs are expressed as time.\n\nIf we now introduce additional costs for visiting locations in the enemy’s line of\nsight and line of fire, the resultant generated paths will also attempt to avoid observa-\ntion and hostile fire. Our revised A* algorithm will automatically balance short travel\ntime versus visiting risky locations, based on the weights for each type of cost\n\n[Reece00].\n\nListing 3.6.2 Cost function for evaluating tactical paths.\n\nIER SHA RTS ATR StH RREARE RAGAN REE\n\nSUE RN\n\nfloat TacticalCostNodeToNode1 (node* aFromNode,\nnode* aToNode) {\nfloat travelTime, riskFrom, riskTo, riskTotal;\ntravelTime = MovementCostNodeToNode(aFromNode,\naToNode) ;\n\n// use duration of move, and average risk of\n\n// both locations\n\nriskFrom =\nGetRiskOfEnemyObservationOrFire(aFromNode) ;\n\nriskTo =\nGetRiskOfEnemyObservationOrFire(aToNode) ;\n\nriskTotal = (riskFrom + riskTo) / 2 * travelTime;\n\n// return the weighted combination of travel\n\n// and risk costs\n\nreturn kTravelTimeFactor * travelTime +\nkRiskFactor * riskTotal;\n\n}\n\nYou'll find an example of a more-tactical A* cost function in Listing 3.6.2. The\nadditional risk costs depend on the risk sampled at each of the nodes and the travel\ntime needed to move from one node to the other. If the nodes are not too far apart,\nthis approximates the total risk of moving from one node to the other. Otherwise, you\nmight need to sample the risk at additional locations between the nodes.\n\nThe GetRiskOfEnemyObservationOrFire() function determines the risk of a given\nnode by checking the enemy’s ability to observe or fire at that position from all of the\nknown or presumed enemy positions. This typically involves performing a number of\nray casts in the game world geometry. Because these ray casts are often expensive, this\ngem will also discuss how to create small lookup tables of precomputed line-of-fire\ninformation.\n\nListing 3.6.2 explicitly does not provide a tactical version of the heuristic. Because\nwe don’t know about the risk in the remaining part of the path, we can only estimate\nthe remaining travel time. The HeuristicNodeToDestination() already does this, so\nwe'll just leave it alone.\n\nHave a look at the results in Figure 3.6.2. In Figure 3.6.2a, you see a ‘traditional’\nshortest path, happily passing through potential hostile fire (gray areas). In Figure",
      "content_length": 2629,
      "extraction_method": "OCR"
    },
    {
      "page_number": 291,
      "chapter": null,
      "content": "3.6 Tactical Path-Finding with A* 297\n\n3.6.2b, you see the result of our TacticalCostNodeToNode1() cost function. Just by\nadding costs for the risk of being under fire, we can obtain paths that show a clever\nand convincing balance between speed and cover.\n\ndestination éstination\n\n_{ under fire\n\nA B\n\nFIGURE 3.6.2 (a) Shortest path. (b) Path offering protection and concealment.\n\nWe are not done yet! In a large number of situations, this simple tactical A* cost\nfunction will provide paths that are tactically flawed and break the illusion of intelli-\ngence. Another problem is that the ‘tactical’ nature of path-finding also comes with a\n(CPU) cost.\n\nIn the remainder of this gem, we will first identify and correct a number of tacti-\ncal flaws in our cost function. Then, we will investigate the additional costs of tactical\npath-finding and come up with some ways to limit these costs.\n\nTactical Improvements to Flawed Paths\n\nALLIANT OUI IN ELEMENTS BUR DOES TUTE R TEE AA ITNT DU RL RE RU RNT RN TAN IRU ACS ARTY\n\nIt only takes one AI flaw to break the illusion of intelligence. When the player has\ncarefully led wingmen, squads, or his tank platoons to an assault position, there is\nnothing more annoying than seeing them getting killed due to a lack of tactical\nunderstanding. Unfortunately, the tactical cost function defined previously lacks this\nunderstanding in a couple of places:\n\n* It does not distinguish between long and short exposures to hostile fire, but sim-\nply adds up the total exposure;\n¢ It assumes that threats remain static during the path’s duration.\n\nWe will look into each of these problems and come up with improvements to the\ntactical-cost function to try to solve them.\n\nosure Time and Enemy Modelin\n\nRRR RETREAT\n\nImagine a helicopter traversing some terrain defended by surface-to-air missile launch-\ners. Imagine that the helicopter can reach its destination via two paths of identical\n\nHAHAH RNC ERNR MURR:",
      "content_length": 1942,
      "extraction_method": "OCR"
    },
    {
      "page_number": 292,
      "chapter": null,
      "content": "298 Section 3 Artificial Intelligence\n\nlength. One path exposes the helicopter to the missile launcher only once but for 20\ncontinuous seconds. The other path exposes the helicopter for 20 seconds also, but in\nfour stretches of 5 seconds, each exposure separated by at least 5 seconds of conceal-\nment. Both paths are equal to our cost function, Tact icalCostNodeToNode1(), which\nsimply adds up the amount of exposure. So, which one should the helicopter really\nchoose?\n\nTo the enemy, the duration of the helicopter’s exposure is very important. The\nsingle 20-second exposure might just be long enough for a missile launcher to detect\nand lock on to the helicopter so it can launch a smart missile. If the helicopter picks\nthe path with four brief exposures, however, this is less likely to happen. Whether it’s\nmissile launchers that need to lock on, snipers requiring time to properly aim, or\nguards turning around in response to some noise—they all prefer their target to have\nlong exposure times with only brief intervals of cover.\n\nTo take into account the enemy’s ‘aiming’ ability, therefore, we need to extend our\nnodes and cost function:\n\nListing 3.6.3 A* node with one additional field to take into account\n_the _enemy’s aiming quality.\n\n“struct node {\nnode(): aiming(0) { }; // default ctor: start\n// with zero aim\nnode(float anInitialAim) : aiming(anInitialAim) { };\n\nfloat location[3];\nfloat aiming;\n\n}5\n\nIn the cost function, we use and update the aiming information detailed in List-\n\ning 3.6.4.\n\nListing 3.6.4 Cost function tactical path.\n\nspate\n\n_ RRSP NN RR IES ATE RES AAAI STN\n\nfloat TacticalCostNodeToNode2 (node* aFromNode,\nnode* aToNode) {\nfloat travelTime, riskFrom, riskTo,\nriskTotal, aiming;\n\n// compute travelTime and riskTotal\n\n// update aiming quality based on risk,\n// and add it to risk\naiming = aFromNode->aiming;\nif ( riskTotal > 0 ) { // spotted,\n// so increase aiming\naiming = min({kMaxAiming, aiming + travelTime);\n} else { // not spotted, so decrease aiming\naiming *= power(kAimingDamping, travelTime) ;",
      "content_length": 2039,
      "extraction_method": "OCR"
    },
    {
      "page_number": 293,
      "chapter": null,
      "content": "3.6 Tactical Path-Finding with A* 299\n\n}\n\nriskTotal += kAimingFactor * aiming;\n\n// store aiming quality at destination\naToNode->aiming = aiming;\n\n// return the weighted combination of\n\n// travel and risk costs\n\nreturn kTravelTimeFactor * travelTime +\nkRiskFactor * riskTotal;\n\n}\n\nFigure 3.6.3 shows a simple test case generated against the helicopter path prob-\nlem, and the graphs below the image show the exposure and aiming quality for each\npath.\n\nthreat threat threat threat\nrit nas\n\ndestination\n\ncosts\n\nFIGURE 3.6.3 A flawed tactical path where one long exposure is preferred over four brief\nones.\n\nBoth paths feature the same amount of exposure to hostile fire—20 seconds. In\nthe top path, the exposure (dark bars) consists of four intervals separated by an inter-\nval of cover of equal length. In the bottom path, the exposure consists of one interval\nof 20 seconds. For both paths, aiming by the threat (gray bars) starts as soon as the\npath is exposed. The aiming quality increases with each exposure until a maximum\nhas been reached. As soon as the path is no longer exposed, the aiming decreases (gray\nbars). The threat might predict the movement on the covered path for a while, but the\naiming decreases with time. For the top path, the total amount of ‘aiming’ when\nexposed is less (gray bars with borders) than that for the bottom path. The intervals of",
      "content_length": 1367,
      "extraction_method": "OCR"
    },
    {
      "page_number": 294,
      "chapter": null,
      "content": "sence pM ADR REE NERA\n\nThreats\n\nSection 3 Artificial Intelligence\n\ncover between the exposures decrease the enemy’s aiming ability and prevent it from\nstaying at its maximum.\n\nSimilarly, when the AI starts a search for a tactical path from a position already\nexposed to hostile fire, it should start assuming the enemy has a maximum aiming\nquality. This will result in paths that try to visit nearby cover early on its path.\n\nThus, by also modeling the enemy’s ability to improve its observation and aim in\nour A* cost function, we get tactically better paths. Our A* now prefers brief expo-\nsures separated by long intervals, rather than the alternative of long exposures and\nshort intervals of cover, which definitely looks more intelligent.\n\nDon’t Remain Static\n\nem\n\neR\n\nUnfortunately, in most games, threats are not static. They patrol an area or move out\nupon spotting a unit in their path. Our current tactical A* solution, however, will\nhappily plan a movement lasting perhaps 10 seconds, using the exact threat positions\nat a single moment. By ignoring the threat’s movement, much of the ‘tactical quality’\nof the path is left to chance, and so is the player’s perception of the AI.\n\nTo obtain better tactical paths, we must anticipate the enemy's movements. This\nis less complex than it sounds and can be done without using ‘chess AI with minmax-\ntrees’ to anticipate the most likely enemy movement. Instead, we can just assume that\nthe enemy also occupies each and every position within a few steps of their current\nposition. Have a look at Figure 3.6.4:\n\nNote how much the path in Figure 3.6.4a depends on the initial position of\nthe threat. The path chosen is not robust against threat movement, and it ignores the\nlarger presence of obstacles and the cover on the left side of the map.\n\n. destination... : vers destination\n\nA B\n\nFIGURE 3.6.4 (a) Tactical path assuming threats remain static. (b) A path assuming threats move\n\ntwo Steps.",
      "content_length": 1949,
      "extraction_method": "OCR"
    },
    {
      "page_number": 295,
      "chapter": null,
      "content": "3.6 Tactical Path-Finding with A* 301\n\nWhen we assume that threats occupy all positions within two steps of their initial\nposition, we indeed pick a more pessimistic scenario. The result, as shown in Figure\n3.6.4b, is more robust against threat movement and also favors the higher availability\nof obstacles on the left side of the terrain. It’s hard to fault the Al for picking this path.\n\nMost game AI implementations provide a fast way to obtain all positions within\na few steps of the threat. These usually correspond with the outgoing waypoints or\nneighboring nodes.\n\nable to use cover and concealment in a\nplausible and effective way. There is more to tactics than just cover and concealment.\nHere are some more tactical considerations that can easily be taken into account by\nour tactical A* cost function.\n\nNot all lines-of-fire are equal. If the AI will face only a few enemies, it is wise to\ncount the number of hostile lines-of-fire to a given path position, rather than just dis-\ntinguishing ‘cover’ and ‘risk’ positions. The distance to the threat and the threat’s\nweapon might also have a large influence on the risk of being in the line-of-fire.\n\nGames rewarding stealth and/or locations with shade, foliage, or small objects\noffer important protection from observation. The path-finding algorithm will prefer\nthese locations if the cost function includes a small penalty for all other locations.\n\nEven in the absence of known threats, there can still be tactical path-finding.\nRather than avoiding known and suspected hostile lines-of-fire, it is now important to\navoid weak combat positions. For example, a tank should not unnecessarily cross\nridgelines because its weaker bottom might be exposed, or it might stand out against\nthe skyline. Similarly, a marine should avoid using ladders because his movement on\na ladder is very predictable, and he is unable to return fire while climbing it. Visiting\nthe location of a recently shot squad member probably isn’t smart either. Many tacti-\ncal properties of a location can be analyzed and precomputed, as is explained in [Ster-\nren01]. By introducing additional costs for visiting these locations, the paths\ngenerated by our tactical A* path-finding will try to avoid them.\n\nObviously the added tactical ability of A* described here comes with some additional\nCPU and memory costs as compared to a standard A*. Our approach compares even\nless favorably with the fast, yet predictable precomputed path lookup tables used by\nsome games. As a point of reference, finding a tactical path with A* was about 10\ntimes more expensive than finding a shortest path for squad AI in a Quake-based\ngame.\n\nOn the other hand, most AI movement does not require a tactical path. Often it\nsuffices to replan a squad’s tactical path once every three seconds or so. The individual\nsquad members then move in brief, ‘shortest path’ hops along this path, and a few\nline-of-sight checks are used to find cover.",
      "content_length": 2951,
      "extraction_method": "OCR"
    },
    {
      "page_number": 296,
      "chapter": null,
      "content": "302 Section 3 Artificial Intelligence\n\nLet’s have a look at the origins of some of these additional costs, what they add,\nand what we can do to limit them. First, we'll consider the line-of-fire tests, which\noften add the largest costs. Then, we'll look at A* and its tactical cost function, and\nthe larger search space involved.\n\nEfficient Line-of-Sight/Fire Tests\n\nAN EORTC RCRA Cte ee\n\nScena RRA RT\n\nIn many games, line-of-sight and line-of-fire (LOF) tests consume considerable CPU\ntime. For tactical path-finding, however, it suffices to use approximations of the\nactual lines-of-fire (the AI might not have spotted all threats and threats may move or\nlook the other way). Trading CPU time for a lookup table of sampled lines-of-fire\nmight be a good option in this case.\n\nIf the terrain is not too large, you might consider using a lookup table with one or\nmore bits per line-of-sight/fire, as described in [Lidén02]. Such a lookup table con-\nsumes O(*) memory. Alternatively, you can record the incoming lines-of-sight and\nlines-of-fire per location in terms of sectors, consuming O(N) memory. This\napproach and the results for our 2D example are illustrated in Figure 3.6.5.\n\nincorrect: ©\n\n8 sectors of\n45 degrees;\nLOF in three\ndistances\n\nincorrect\ndanger zone\n\ns t e:\n11+ already a LOF from far\n\n10 - a LOF from medium distance\n01.- a LOF from near distance\n\n00 - no LOF from this direction\n\nall 8 sectors together make one 16 bit word\n\nFIGURE 3.6.5 Sector-based LOF lookup and the resulting path.\n\nUsing one 16-bit word per location, information is precomputed and stored. For\neach location, every sector describes the worst-case distance from which a potential\nenemy in that sector can have a line-of-fire to that location. This worst-case distance\nis represented using four values, from ‘no line-of-fire at all in this sector’ to a ‘line-of-\nfire at the maximum engagement distance.’ Note that the value stored is a pessimistic\none: a single position in the sector that has a line-of-fire is sufficient to mark that sec-\ntor as having a LOF from locations in that direction.",
      "content_length": 2085,
      "extraction_method": "OCR"
    },
    {
      "page_number": 297,
      "chapter": null,
      "content": "3.6 Tactical Path-Finding with A* 303\n\nDuring an A* search, an approximation of the line-of-fire from a given threat\nposition can be efficiently determined using the sector-based lookup table (see Listing\n3.6.5). For the threat and position, the corresponding 45° sector and distance are\ncomputed. The lookup table then tells us whether it is possible for the location to be\nfired at from the threat’s sector and for the threat-to-fire into the location's sector. If\nboth lines-of-fire are feasible, the threat likely has a line-of-fire.\n\nObviously, such a small sector-based lookup table does not represent all lines-of-\nfire correctly. You can easily verify this by comparing the lines-of-fire in Figure 3.6.4\nwith the danger zones in Figure 3.6.5. In many cases, the (pessimistic) errors corre-\nspond to lines-of-sight easily achieved by the threat if the threat were to move. In\nother cases, such as the danger zones outside the box, the errors are more serious.\nWith a few more bits and smaller sectors, however, you can easily reduce the number\nof errors.\n\nFor 3D environments and for games offering partial cover (which removes the\nsymmetry in lines-of-fire), you might need to store some more bits. Still, this sector-\nbased lookup approach stores lines-of-sight for some 1,000 locations in a few tens of\n\nkilobytes and is generally quite efficient.\n\nListing 3.6.5 Computing an approximate risk using sector-based,\nprecomputed LOF information\n\nWA DAA AANA ARRAN ALLIS NOL AM PANE R iH dH iit ar DAT RTH ISR INST AT LIE EN I\n\nfloat GetApproximateRiskFromThreat(node* threat,\nnode* location) {\nint sector = GetSectorForLine(threat, location);\nint reverse sector = (sector + 4) % 8;\nfloat distance =\nGetDistanceForLine(threat, location) ;\n\nNARI NORTH hs loose\n\nif (HasLineOfFireFromSector(location->id,\nsector, distance)\n&& CanFireIntoSector (threat->id,\nreverse_sector, distance) )\nreturn distance / kMaxDistance;\n\nelse\nreturn 0.0;\n}3\nbool HasLineOfFireFromSector(int index, int sector, :\nfloat distance) {\nunsigned int allsectors = sectors[index] ;\nunsigned int mask = (0x3 << sector);\nunsigned int value = ((allsectors & mask) >>\nsector) ;\nreturn ( (value == 3 && distance < kMaxReach )\n|| (value == 2 && distance < kFarReach  )\n|| (value == 1 && distance < kMediumReach) );\n}3\n\nbool CanFireIntoSector(int index, int sector,",
      "content_length": 2332,
      "extraction_method": "OCR"
    },
    {
      "page_number": 298,
      "chapter": null,
      "content": "Section 3 Artificial Intelligence\n\nfloat distance) {\n// assume firing is symmetric, otherwise\n// an extra table is needed\nreturn HasLineOfFireFromSector (index,\nsector, distance);\n\nExtended A* Costs\n\nsm IR IRENE Mena Re hee eg TaN eA NSN S ANTE ERS NL SERS RE EEO BS\n\nAs mentioned earlier, in its tactical format, A* consumes more CPU and memory, pri-\nmarily through the tactical cost function and the larger search spaces being explored\nby A*. One source of additional cost is the floating-point arithmetic in the tactical\ncost function. You can gain performance by implementing approximate versions of\nfloating-point computations using integer math. You should do this only after having\nverified and tuned the path-finding with the more ‘exact’ floating-point cost func-\ntions to avoid introducing other problems.\n\nThe space being searched by the tactical A* algorithm is typically much larger\nthan one for a standard A* algorithm, as is shown in Figure 3.6.6. The larger search\nspace is a result of the added line-of-fire obstacles that typically are placed between the\nstart and destination position of the path. A* will spend a lot of effort exploring loca-\ntions to the rear and the sides, since those seem safer. It does not help that the heuris-\ntic cannot reflect these added line-of-fire obstacles.\n\ndestination\n\ndestination\n\nunexplored\n| search space\n\nA B\n\nFIGURE 3.6.6 (a) Search space for shortest path. (b) Search space for tactical path.\n\nOne way to reduce the search space is to introduce even more-costly ‘virtual’\nobstacles. If you want your AI to find a tactical path to a forward destination, why not\nrestrict its attempts to evaluate positions deep in the rear or far to the sides by tem-\nporarily marking those nodes ‘off-limits’? Nothing says you can’t use the algorithm to\nignore these areas.",
      "content_length": 1816,
      "extraction_method": "OCR"
    },
    {
      "page_number": 299,
      "chapter": null,
      "content": "3.6 Tactical Path-Finding with A* 305\n\nAnother way of reducing the search space is to use hierarchical path-finding, exe-\ncuting the path-finding in ‘layers.’ First, generate a shortest path search at a higher\nlevel between areas of the map. Then, select the areas used for that shortest path and\ntheir neighboring areas, and run the tactical path-finding to the locations within the\nselected areas. Both Board/Ducker [BoardDucker02] and White [White02] address\n\narea navigation in their gems.\n\nExplorer (ASE) application on the CD-ROM. James Matthews [Matthews01] laid\nthe foundation for this A* tool. The tactical enhancements and line-of-fire approxi-\nmation described in this gem were added. Note that the A* implementation in this\nASE is not representative of a high-performance tactical A*. Instead, the algorithm\nhas been designed for hosting alternative cost functions and visualization.\n\nFinding tactical paths with A* is a bit more complex than treating locations under\nenemy fire as terrain that is expensive to visit. You also should look at the path from\nan enemy perspective and deal with enemy aiming and movement in the cost func-\ntion. These features will ensure paths that intelligently use stretches of cover and con-\ncealment to limit the risk of hostile fire, even when the enemies move. Using a similar\napproach, you can extend A* to pick paths that stay in touch with friendly or hostile\nelements, if that is important. Hopefully, this gem offers sufficient help to add these\nfeatures to your game with efficiency.\n\nReferences\n\n[BoardDucker02] Board, Ben and Mike Ducker, “Area Navigation: Expanding the\nPath-Finding Paradigm,” Game Programming Gems 3, Charles River Media, Inc.,\n2002.\n\n[Lidén02], “Strategic and Tactical Reasoning with Waypoints,” AJ Programming Wis-\ndom, Charles River Media, Inc., 2002.\n\n[Matthews01], A* Explorer, available online at http://www.generation5.org, 2001.\n\n[Patel99] Patel, Amit J., “Amit’s Thoughts on Pathfinding”, available online at\nhttp://www-cs-students.stanford.edu/~amitp/gameprog.html, November 18, 2001.\n\n[Rabin00] Rabin, Steve, “A* Speed Optimizations,” Game Programming Gems,\nCharles River Media, Inc., 2000.\n\n[Reece00] Reece, Doug, et al., “Tactical Movement Planning for Individual Combat-\nants,” Proceedings of the 9th Conference on Computer Generated Forces and\nBehavioral Representation, available online at http://www.sisostds.org/cgf-br/\n9th/, 2000.\n\n[Sterren01] van der Sterren, William, “Terrain Analysis for 3D Action Games,” Game\nDevelopers Conference 2001 Proceedings, paper and presentation available\nonline at www.cgf-ai.com, 2001.",
      "content_length": 2613,
      "extraction_method": "OCR"
    },
    {
      "page_number": 300,
      "chapter": null,
      "content": "306 Section 3 Artificial Intelligence\n\n[Stout00] Stout, Bryan, “The Basics of A* for Path Planning,” Game Programming\nGems, Charles River Media, Inc., 2000.\n\n[White02] White, Stephen, “A Fast Approach to Navigation Meshes,” Game Pro-\ngramming Gems 3, Charles River Media, Inc., 2002.",
      "content_length": 283,
      "extraction_method": "OCR"
    },
    {
      "page_number": 301,
      "chapter": null,
      "content": "3.f\n\nA Fast Approach to\nNavigation Meshes\n\nStephen White and\nChristopher Christensen,\nNaughty Dog\n\nswhite@naughtydog.com,\ncchristensen@naughtydog.com\n\nAv problem in video games is how to navigate around objects in a complex\nenvironment. In the case of Jak and Daxter: The Precursor Legacy, we wanted\ncreatures to be able to maneuver around highly detailed 3D environments, where\neach level was composed of millions of polygons and filled with many creatures and\nobstacles. We wanted the creatures to move intelligently and to exhibit several types of\nmovement behaviors. Due to the density of creatures in our world, we needed a sys-\ntem that was faster than the more-common navigation techniques, such as A*; but it\nstill needed to be flexible, accurate, and give the appearance of intelligent movement.\nTo solve this problem, we developed our own navigation mesh technology, which\nadmirably solved our needs, but also had a few interesting limitations.\n\nStatic vs. Dynamic Obstacles\n\nare Rr pn ERD ee CAT PRR AR RIRR\n\nThe most fundamental problem of navigation is how to get from point A to point B.\nThe shortest distance between these two points is a straight line. However, a straight\nline isn’t appropriate when there is an obstacle blocking a direct movement between\nthe two points. Obstacles can be broken down into two categories: static and\ndynamic. Static obstacles are obstacles that don't move, ever. These are our favorite\ntype of obstacles since there are many optimizations that can be made to navigate\naround them. Examples of static obstacles are cliffs, walls, trees, and pillars. Dynamic\nobstacles are obstacles that can move or be removed, such as other creatures, the\nplayer, moving platforms, and crates. Dynamic obstacles are more difficult to deal\nwith since their ability to move makes it difficult to use precomputed solutions. To\nmake things worse, a dynamic obstacle might move in such a way as to invalidate a\npreviously computed path. Since static and dynamic obstacles have so many different\nadvantages and disadvantages, we chose to approach the problems separately.\n\npa aNec A\n\n307",
      "content_length": 2114,
      "extraction_method": "OCR"
    },
    {
      "page_number": 302,
      "chapter": null,
      "content": "308 Section 3 Artificial Intelligence\n\nNav Meshes\n\nThe most common type of static obstacle encountered in Jak and Daxter was the ter-\nrain. Natural boundaries, such as walls and cliffs, described an area within which a\ncreature could maneuver. Inside that boundary there could be other static obstacles,\nsuch as trees, large rocks, pillars, gaps too large to leap across, and other things that\nthe creature should not be allowed to pass through.\n\nTo describe where a creature was allowed to maneuver within an area, the artists\nmodeled a ‘nav mesh.’ The mesh was a collection of triangles, and each triangle repre-\nsented a valid area where the creature could maneuver. The mesh was modeled to the\nextent of the natural boundaries of the desired area, and holes in the mesh were used\nto represent areas where the creature could not travel within the natural boundaries.\nNote that our nav meshes were largely two-dimensional in nature and defined a\ntwo-dimensional area where a creature could travel. There was, however, a three-\ndimensional element to our meshes, which will be explained later.\n\nAs an example, suppose there is a clearing that we want a creature to be able to\nnavigate within (see Figure 3.7.1). In this clearing, there is a large rock that the crea-\nture should not pass through. The artist would model a nav mesh that would both\ndescribe the extent to which the creature can travel as well as a hole cut out around\nthe rock (see Figure 3.7.2). Each triangle in the mesh would describe a valid area\nwhere the creature is allowed to travel. By restricting the creature’s travel to the two-\ndimensional space described by the mesh triangles, the creature could neither exit the\nclearing nor pass through the rock.\n\nThe beauty of this system was in its simplicity. Both area-boundary and inner-\nobstacle problems were solved using the same solution. A fairly simple nav mesh\ncould even represent highly detailed and complicated terrain.\n\nclearing\n\nFIGURE 3.7.1 A clearing with a static obstacle.",
      "content_length": 2010,
      "extraction_method": "OCR"
    },
    {
      "page_number": 303,
      "chapter": null,
      "content": "3.7 AFast Approach to Navigation Meshes 309\n\nortals\n\nFIGURE 3.7.2 A clearing with a nav mesh added.\n\neieesnories 2a maamUAY\n\nThe triangles of the nav mesh do more than just establish an area where a creature can\nwalk—they also establish what we refer to as “portals.” Portals can be thought of as\ndoorways to other triangles. In the case of our nav meshes, the portals were repre-\nsented by the edges of the triangles. As a simplification, we established that our\nmeshes could not contain any T-junctions, which simply meant that we only allowed\nan edge to be shared between no more than two triangles. Since a triangle has three\nedges, this means that a single triangle could be connected to at most three other tri-\nangles; so a single triangle has at most three portals leading to other connected trian-\ngles. This limitation did pose some three-dimensional issues, but it did give us some\nnice data characteristics. For one thing, we could use two bits to specify a portal of a\ntriangle (first portal, second portal, or third portal) and still have one value left over\nfor other uses.\n\nSuppose our problem is moving from point A to point B. If point A represents\nthe creature, point B represents the desired destination of the creature, and both\npoints are within the same triangle, then we know that the creature can move directly\ntoward point B, since we already know that the creature can move anywhere within\nthe triangle. A problem arises when the destination is not contained within the same\ntriangle as the creature. In this case, the creature might need to choose a direction that\nwill both keep the creature on the nav mesh and intelligently move the creature along\na path that will reach the desired destination, even if that path temporarily moves the\ncreature in a direction away from the desired destination.\n\nSo, if we're on some triangle and our desired destination is on some other trian-\ngle, how do we decide which way to go? The solution that we used was to precompute\na two-dimensional array that specified the portal to use to get from any triangle to any\n\nSSRN BS",
      "content_length": 2089,
      "extraction_method": "OCR"
    },
    {
      "page_number": 304,
      "chapter": null,
      "content": "310\n\nSection 3 Artifici\n\nIntelligence\n\nother triangle on the mesh. Remember that it only took two bits to specify a portal, so\nthe memory cost of our table was roughly equal to squaring the number of triangles\nin the mesh and dividing by four. This means that the table for a mesh of 256 trian-\ngles (the maximum our implementation allowed) cost only 16 KB of memory. In\npractice, our nav meshes rarely exceeded more than 64 triangles (one kilobyte of\nmemory) and were often smaller. Also, since multiple creatures typically shared the\nsame nav mesh, there were relatively few nav meshes overall, so the memory cost was\nnot significant. Now, consider the advantages of having this two-dimensional table.\nFiguring out which portal to use is now extremely fast, since it is a simple table\nlookup. The entry in the table is found by using the index of the source triangle and\nthe index of the destination triangle. If the table was composed of byte values instead\nof two-bit values, then the C code might look like the following:\n\nportaliIndex = portalTable[destTrilIndex][srcTriIndex];\n\nOf course, using a byte table would quadruple the memory cost for little gain, so\nour bit-packed table code becomes:\n\nbitIndex = 2*(destTriIndex*triCount + srcTrilIndex);\nbyteIndex = bitIndex / 8;\n\nbyteShift = bitIndex & 7;\n\nportalIndex = (portalTable[byteIndex] >> byteShift)&3;\n\nOnce we know the portal to use for a given triangle, we can take the desired direc-\ntion vector from point A to point B and then solve for the point on the portal that\nmost closely matches our desired direction. The creature then moves in the direction\nof the point on the portal until it reaches the portal, where it transitions to the trian-\ngle on the other side of the portal. If point B is within the creature’s new triangle, then\nthe creature can move directly to point B. If point B is still not within the creature's\nnew triangle, then another look-up in the table is done to determine which portal to\nuse next. The logic repeats until the creature eventually reaches the triangle that con-\ntains point B.\n\nAs an example, refer to Figure 3.7.3. Point A starts the creature out located within\ntriangle 0, and point B (its destination) is located within triangle 3. Since point A is not\nin the same triangle as point B, a look-up in the table is done to determine which por-\ntal to use, and the returned value tells us to use the portal connecting triangle 0 to tri-\nangle 1. A point is found on that portal that most closely matches the desired direction\nof point B, and the creature is moved to that point. The creature is then considered to\nbe within triangle 1. This behavior is repeated until the creature enters triangle 3,\nwhich is where point B is located; and the creature can then move directly to point B.\n\nAlthough the above example was fairly simple, the same logic works for far more\ncomplicated cases. Consider Figure 3.7.4 (on page 000), which shows the same sim-\nple logic applied to navigating a more complicated mesh.\n\nThis logic works for forking and looping paths. When there is more than one\nportal that can be used to reach a destination, the table entry specifies which portal",
      "content_length": 3172,
      "extraction_method": "OCR"
    },
    {
      "page_number": 305,
      "chapter": null,
      "content": "3.7 A Fast Approach to Navigation Meshes 311\n\ntri 1 tri3\n\n‘ i ir)\n\\ ‘oe\n\\ ooo \" }\n. oo ; ‘\n‘ aoe - : . i\naa \\\nwet \\\n= \\ \\.\n\\ :\nj\nA |\n; \\. i\n\\\n, \\. i\nj \\ F ‘ /\n\\ i < ;\n: \\ ; \\ i\n\\ : :\ni \\ { ;\nj :\nSF\ntrio tri2\n\nFIGURE 3.7.3 Navigating from A to B on a simple mesh.\n\nrepresents the shortest route to the destination. However, there is actually one com-\nplication to consider. A triangle represents an area, and not a single point. This means\nthat the distance between a point on one triangle and a point on another triangle can\nvary dramatically, depending on where the points are located on their respective tri-\nangles. Since the precomputed table tells us how to get from one triangle to another\ntriangle, rather than how to get from an exact position on a triangle to an exact posi-\ntion on another triangle, the precomputed portal might not actually lead to the short-\nest path to the destination. In practice, however, this was rarely a problem, since if\nmore than one path covered a similar distance, then it really didn’t matter that the\nchosen path wasn’t always the shortest.\n\nBuilding the Table\n\nSo, how do you precompute the table? Several methods could be used, but the\nmethod that we chose was to compute a point to represent the center of each triangle.\nPreferably, this was a point that was equidistant to the three corners of the respective\ntriangle. We then used a simple flood-fill algorithm to find the paths connecting the\ntriangles. If more than one path was found between two triangles, then the algorithm\nwould discard the longer path.\n\nAn important item to consider when constructing the nav mesh is that it repre-\nsents a single path to each destination. Each portal should provide a single, clear route\nbetween any two areas in order to produce acceptable results. Providing more than",
      "content_length": 1808,
      "extraction_method": "OCR"
    },
    {
      "page_number": 306,
      "chapter": null,
      "content": "312\n\nSection 3 Artificial Intelligence\n\n5 eS Rr DN St EL STONER eR at: aeEHSTNNsCS\n\nf \\\n4 : A\n4 A B / \\\n+ j .\na a.\ney rt é\n* 1 /\n« a /\ns : /\n* \\ rj / ’\n* \\ LS f\n© \\ nj 4\n* \\ '\n® . ‘\nee i cen é _ ~\n—_ . . oer\n\\ . o* i ‘\n‘ s of\n\\, °\nS e @ i\nN ‘ o* .\nLoos ° .\n\\, 29” j \\\n‘ \\\n/ e ‘\\ i\n¢ \"\no\nU i i\ni A \\ iH\nS /\n\nFIGURE 3.7.4 Navigating around a corner.\n\none portal to pursue a single path could result in zigzagging movement. Figure 3.7.5\nshows a case where it is unclear at precompute time which portal is the best way to get\nfrom point A’s triangle to point B’s triangle. In this example, only one portal is chosen\nat precompute time, which would be inappropriate at runtime, since it does not inter-\nsect a direct path from point A to point B. Figure 3.7.6 shows the proper way to con-\nstruct this nav mesh, where the direct path is always taken.",
      "content_length": 844,
      "extraction_method": "OCR"
    },
    {
      "page_number": 307,
      "chapter": null,
      "content": "3. 7 A Fast Approach to Navigation Meshes 313\n\n. a\n\nFIGURE 3.7.5 Poor mesh construction.\n\nFIGURE 3.7.6 Good mesh construction.\n\nAdditional Portal Issues\n\nSS NteRRNTIN i a psianirennERE\n\nAlthough the concept of using portals is quite te simple, there are a few complications in\ntheir implementation. One such complication is that as point A approaches a portal\nedge, the test for whether the vector from point A to point B intersects the portal edge\nmight become unreliable. For example, floating-point round-off errors might shift\npoint A outside of the current triangle, causing the test to go awry. Also, when the\nsource-to-destination vector is nearly parallel to the portal edge, the intersection test\ncan give unreliable results. To avoid these problems, we checked to see if the source\n\nNER RE AHSAN\n\nRDA RARE ARRESTS NOR ES",
      "content_length": 830,
      "extraction_method": "OCR"
    },
    {
      "page_number": 308,
      "chapter": null,
      "content": "314 Section 3 Artificial Intelligence\n\ntic rte RN Se FA on her ORL HEE ey na NaH HRSA MENGE\n\npoint was closer than some chosen epsilon distance to the portal edge. When it was,\nwe simply looked ahead to find the next portal on our path that wasn't so close to the\nsource point and used that as our portal.\n\nAnother item to consider is choosing alternate directions when the desired direc-\ntion vector does not intersect the portal. It might not be clear which of the two portal\nendpoints is the best choice to follow. Choosing an endpoint based on which end-\npoint most closely matches the desired direction might not be sufficient. For example,\nif the desired direction vector is perpendicular to the portal and moving away from it,\nthen either of the portal’s endpoints is equally desirable. Floating-point precision and\nother minor variations could cause undesirable oscillations. One method that can\nresolve this ambiguous situation is to look ahead at successive portals until a portal is\nfound that clearly indicates which endpoint of the current portal is closest to our\nfuture path. This ‘look-ahead’ technique also has the added benefit of creating more-\ndirect navigation as the creature travels around winding pathways. Since this tech-\nnique is rarely needed and usually only requires a few triangles of look-ahead, the\nextra CPU cost is minimal.\n\nRepresenting Creatures\n\neA\n\nUsing a nav mesh, we are able to travel intelligently from one point on the mesh to\nanother point on the mesh. Most creatures, however, occupy more space than a single\npoint, and so a question arises about how to account for their thickness. Since effi-\nciency was more important to us than accuracy, we simply used a circle to represent\nthe two-dimensional area of a creature on the nav mesh, where the radius of the circle\nrepresented the thickness of the creature. Using circles gave us some problems with\ncreatures that were not very circular in shape. For example, a horse doesn’t look very\ncircular when viewed from above. If you made the circle big enough to enclose the\nentire horse, then other creatures would avoid the sides of the horse, and the horse\nitself wouldn't be able to squeeze into an area that it visually should fit into. If you\nmade the circle smaller so that creatures could get closer to the horse, then youd let\nthe ends of the horse poke out of the circle, where they might occasionally overlap\nsomething else.\n\nDespite these problems, we felt that the advantages of using circles outweighed\nthe disadvantages. For Jak and Daxter, we were always able to find a radius that\nappeared to be a reasonable compromise between these two adverse effects. Another\nadvantage to using circles was that rotation didn’t have to be factored in when check-\ning for collision with the nav mesh or other dynamic obstacles.\n\nInstead of trying to adapt our nice, simple, point-to-point nav mesh logic to a\nmuch more computationally expensive circle-to-circle logic, we opted to preshrink\nour nav meshes to account for the radii of the creatures that may be using it. The con-\ncept is simple in that instead of modeling the nav mesh to exactly abut against obsta-\ncles, the mesh is modeled to stay at least some radius from all obstacles. Figure 3.7.7\nshows how a nav mesh might be modeled for a small creature, and Figure 3.7.8 shows",
      "content_length": 3330,
      "extraction_method": "OCR"
    },
    {
      "page_number": 309,
      "chapter": null,
      "content": "3.7 A Fast Approach to Navigation Meshes\n\nFIGURE 3.7.7 Mesh for small creatures.\n\nthe same scene with a nav mesh modeled for a larger creature. If we guarantee that the\ndistance from the edges of the nav mesh to all static obstacles is greater than or equal\nto the radius of the creatures that use the nav mesh, then the creature can be repre-\nsented by a point instead of a circle.\n\nThis is an enormous optimization, since moving a point around the nav mesh is\nmuch simpler than moving a circle around the mesh, though it does come with some\nproblems. The biggest problem is that different types of creatures might want to use\nthe same nav mesh, and some creatures might have significantly larger circles than\nother creatures. If the nav mesh is modeled to work for the larger creatures, then the\nsmaller creatures might not be able to move very close to the static obstacles. In gen-\neral, this wasn’t a problem for us, but occasionally we had situations where the dis-\ntance of the nav mesh was far enough from static obstacles that the player could stand\nnext to a wall and a smaller creature couldn't get close enough to the wall to attack the\nplayer. To fix this undesirable behavior, we would adjust the distance of the nav mesh\nto any surrounding static obstacles until we found a compromise in which larger crea-\ntures would overlap the static obstacles slightly, but smaller creatures would be able to\nreach the player.\n\nOur second biggest problem was that it was often difficult to judge what distance\nto use when modeling a nav mesh. The appropriate distance to use was based on the\nradii of the circles representing the creatures on the mesh, and the types of creatures\nand radii of their circles were subject to occasional design and programming changes.",
      "content_length": 1768,
      "extraction_method": "OCR"
    },
    {
      "page_number": 310,
      "chapter": null,
      "content": "316\n\nSection3 Artificial Intelligence\n\nLL\n\nFIGURE 3.7.8 Mesh for large creatures.\n\nDynamic Obstacles\n\nsesamiae aa rea\n\nis na RIN Ce\n\nUsing circles to represent creatures gave us the advantage that we could treat creatures\nas points when moving them around the nav mesh. This is also true for moving crea-\ntures around dynamic obstacles, such as other creatures. Instead of using computa-\ntionally expensive logic for moving a circle around other circles, we can simply inflate\nthe circles of surrounding obstacles by the radius of the creature currently being\nmoved. For example, Figure 3.7.9 shows a creature of radius r and two dynamic\nobstacles with different radii, and Figure 3.7.10 shows how we treat the creature as a\npoint by adding its radius to the obstacles. By inflating surrounding circles before\nmoving a creature, we've unified the representation of a creature to being a single\npoint and reduced our navigation issues to the relatively simple problem of moving a\npoint inside the bounds of a mesh while avoiding surrounding circles.\n\nTo navigate the point among the circles, we checked to see if the direction that we\nwanted to travel would cause us to collide with any nearby circles. If not, then we\ncould go ahead and move in the desired direction. If it was determined that a collision\nwould occur, we computed two new vectors that would steer us clear of the collision\n(see Figure 3.7.11).\n\nThese two vectors could be considered as rotations away from the original vector:\na rotated vector to steer to the left of the obstacle, and a rotated vector to steer to the",
      "content_length": 1585,
      "extraction_method": "OCR"
    },
    {
      "page_number": 311,
      "chapter": null,
      "content": "3.7 AFast Approach to Navigation Meshes 317\n\nobstacle\nobstacle\n\né\n\ncreature\n\nFIGURE 3.7.9 Creature as circle with two circular dynamic obstacles.\n\ni\n\npo\n\nFIGURE 3.7.10 Creature simplified to a point with obstacles enlarged to\ncompensate.\n\nright of the obstacle. We would then check these two new vectors to see if either of\nthem would collide with any other obstacles. If so, then we would appropriately rotate\nthe right-most vector to the right or rotate the left-most vector to the left to avoid any\nadditional obstacles. Once all potential obstacles had been accounted for, the two\nresulting vectors showed two possible ways to move that would avoid the dynamic",
      "content_length": 664,
      "extraction_method": "OCR"
    },
    {
      "page_number": 312,
      "chapter": null,
      "content": "318\n\nSection 3 Artificial Intelligence\n\nFIGURE 3.7.11 Getting around a dynamic obstacle that intersects\nour desired path.\n\nobstacles’ blocking the originally desired direction of movement. To avoid an undesir-\nable cyclic movement behavior and to keep things simple, we usually chose the vector\nthat more closely matched the creature’s last direction.\n\nOne problem we had with this approach was that the creature could occasionally\nbecome stuck inside of other dynamic obstacles. This was commonly caused by float-\ning-point precision issues, but it could also occur due to various other movement\nbehaviors. Instead of trying to solve the thorny problem of not allowing overlaps to\noccur under any situation, we opted to have an embedded creature attempt to move\naway from the obstacles that overlapped it. Basically, we identified which circle the\ncreature overlapped the most, and after computing the directions to avoid the other\ncircles, we blended those results toward the direction away from the overlapping cir-\ncle, proportionate to the amount of the overlap. This technique caused overlap cases\nto resolve themselves in a reasonable manner.\n\nAnother potential problem was that a creature could become completely sur-\nrounded by other dynamic obstacles such that the left and right vectors both faced\nexactly opposite of the originally desired vector. We chose to ignore handling this\ncase, which meant that a creature could potentially move to a position that would\ncause them to overlap one of the surrounding dynamic obstacles. In practice, how-\never, this wasn’t an issue for us, especially since creatures naturally tended to move\naway from overlaps.\n\nNavigation of Both Static and Dynamic Obstacles\n\nOur final logic for maneuvering creatures turned out to be quite simple and broke\ndown into the following steps. First, we found the best direction to reach our destina-",
      "content_length": 1883,
      "extraction_method": "OCR"
    },
    {
      "page_number": 313,
      "chapter": null,
      "content": "3.7 A Fast Approach to Navigation Meshes\n\n319\n\ntion using the nav mesh and its portals. We then checked to see if the resulting direc-\ntion would hit any dynamic obstacles (circles). If so, we modified the direction to\navoid them. Finally, we checked to sce if this new direction would lead us off of the\nnav mesh. If so, we clamped the movement to the nav mesh.\n\nThe final step of clamping movement to stay on the nav mesh was done for effi-\nciency and required a little bit of finesse. One problem was that a creature might\nbecome blocked and be forced to stop. Another issue was that we sometimes allowed\na creature's movement vector to be bent against the edge of the nav mesh instead of\nbeing simply clamped. The bent vector allowed the creature to continue moving, but\nwe didn’t do an additional check to see if the bent vector would cause the creature to\noverlap nearby circles; so a creature might subsequently become embedded within\nanother creature. Since our circle avoidance logic made creatures naturally want to\nmove away from overlaps, this usually wasn’t an issue between two moving creatures.\nWe did, however, encounter issues when a moving creature overlapped a dynamic\nobstacle that didn’t move, such as a crate. To eliminate this problem, we made sure\nthat nonmoving dynamic obstacles, such as crates, were not placed near the bound-\naries of a nav mesh.\n\nAdditional Nav Mesh Thoughts\n\n‘SiH aURReRm SIAR IRNI RON RESUS ROIS BN SRILA RpR SS RSRRRNNDRE NNT EAI\n\nOur nav meshes predominantly denoted two-dimensional areas where dynamic\nobstacles were allowed to move. This sufficed in most cases, since most creature setups\ncan be described using two-dimensional boundaries. However, we occasionally had\nsituations that required three-dimensional information. For example, if we wanted to\nput a creature on a circular staircase that spiraled upward, it would not be sufficient to\nuse just a two-dimensional nav mesh to describe the staircase. For this type of situa-\ntion, we had a maximum height that the creature could be from the surface of a nav\nmesh triangle in order to be considered on that triangle. This gave the ability for a nav\nmesh to have three-dimensionally crisscrossing triangles, as long as the triangles that\noccupied the same two-dimensional space were at sufficiently different elevations so\nthat it was clear which triangle a creature was using.\n\nAnother enhancement that we made to our nav mesh system was the ability for\ncreatures to jump across certain obstacles to reach the desired final destination. For\nexample, a creature might jump across small chasms in pursuit of the player. Model-\ning triangles across the chasm and marking those triangles as special ‘gap triangles’\naccomplished this ability. When a creature crossed a portal into a gap triangle, a\nsearch found the triangle on the far side of the gap, and the creature was sent a mes-\nsage telling it to jump across the gap to that triangle. In order to keep the creature\nfrom landing on top of a dynamic obstacle on the other side of the gap, the creature\nused a temporary circle that reserved a safe landing place.\n\nKAA EMSC TRI.",
      "content_length": 3135,
      "extraction_method": "OCR"
    },
    {
      "page_number": 314,
      "chapter": null,
      "content": "320 Section 3 Artificial Intelligence\n\nConclusion\n\nenisaReROOORONE SAIN\n\nOur navigation mesh system admirably fit our needs for the development of Jak and\nDaxter (see Plate 3). We were able to create many different types of creatures that\nexhibited a variety of behaviors while intelligently navigating our complex three-\ndimensional environments. Although navigational approaches exist that might pro-\nvide more-robust general solutions to this difficult problem, our system excelled at\nbeing both fast and conceptually simple, creating a winning combination for us.",
      "content_length": 567,
      "extraction_method": "OCR"
    },
    {
      "page_number": 315,
      "chapter": null,
      "content": "3.8\n\nChoosing a Relationship\nBetween Path-Finding\nand Collision\n\nThomas Young, PathEngine\nthomas@pathengine.com\n\nlor many games, the Al is all about characters moving around within an environ-\n\nment. It’s no use having sophisticated decision-making systems if the resulting\ndecision can’t be executed when the player moves behind a bunch of crates. On the\nother hand, if a character correctly understands how to deal with the obstructions in\nits environment, then even a very simple decision-making structure can result in\nimpressive-looking AI.\n\nWe can think of the pathfinder as a system with the responsibility of understand-\ning collision. The relationship between path-finding and the collision system is a key\narchitectural issue when creating characters that understand how to react to the\nobstructions in their environment. Three different approaches to this architecture and\nthe implications of each approach will be explained in this gem.\n\nMoving Under the Control of Collision\n\nWe don't want characters walking through walls, tables, or other obstructions. To pre-\nvent this from happening, character movement can be controlled by a collision sub-\nsystem. Decisions made by the AI are subject to arbitration by this subsystem before\nbeing implemented as character movement.\n\nThis creates a strong dependency between code that generates character movement\nand collision code that arbitrates that movement. Behavior code depends on the results\nof the collision code in order to work as intended. Imagine the situation where behav-\nior code thinks a character can walk directly toward the player, but in fact that charac-\nter is snagged on an obstruction. The behavior code must take collision into account.\n\nThe Collision Model for Path-Finding\n\nA pathfinder allows certain possibilities for movement and disallows others. This\nimplies a certain understanding about how collision works. We can call this the\npathfinder’s collision model.\n\n321",
      "content_length": 1951,
      "extraction_method": "OCR"
    },
    {
      "page_number": 316,
      "chapter": null,
      "content": "322\n\nSection 3 Artificial Intelligence\n\nWe can often describe this collision model in terms of path-finding space and\nobstructed space. In a tile- or cell-based pathfinder, path-finding space is defined by the\nset of unobstructed tiles or cells. Figure 3.8.1a shows a tile-based path-finding space\n(white cells) and obstructed space (black cells). In a points-of-visibility- or waypoints-\nbased system, the path-finding space is represented explicitly along with a set of\npoints. Figure 3.8.1b shows what the path-finding space might look like in this case.\n(Note that this path-finding space must correspond with the set of points used, oth-\nerwise the pathfinder will not function correctly.) When generating a path, the\npathfinder allows the possibility of movement within the path-finding space, but it\ndoes not allow paths to cross through obstructed space.\n\nFIGURE 3.8.1 Path-finding space for (A) a tile-based system and (B) a points-of-\nvisibility system.\n\nIt is the relationship between this collision model for path-finding and the colli-\nsion actually applied to movement that differentiates the three approaches to be\ndiscussed.\n\nApproach #1: Fault-Tolerant Al\n\nSRN SOR GIHTUHE Re I HY RNAI TE OB ANSE\n\nA defined relationship between the collision model used by path-finding and collision\nactually applied means that there is an interdependency, or linkage between these two\nsystems. The implication is that whoever codes the path-finding system will need to\nbe aware of any changes to the collision system (or vice versa) to make sure that the\nrelationship is not broken.",
      "content_length": 1584,
      "extraction_method": "OCR"
    },
    {
      "page_number": 317,
      "chapter": null,
      "content": "3.8 Choosing a Relationshp Between Path-Finding and Collision 323\n\nCARRERE\n\nFrom an architectural point of view, reducing interdependencies is good practice.\nHuman behavior doesn’t depend on our knowing the precise physics behind collision\nwith our environment. We have a rough idea of how to move through our environ-\nment, get by with feedback mechanisms and so on, and avoid collisions. Can we use a\nsimilar approach for our AI and thereby avoid direct linkage with the collision system?\n\nThe idea behind the fault-tolerant approach is that the collision model for path-\nfinding need only roughly correspond to the actual, more-detailed collision applied to\nmovement. The pathfinder’s representation might perhaps be edited manually to\napproximate collision, or it could be built automatically from the same world and\nobject representations used by collision without any further assumptions about how\nthat collision works. The pathfinder is used to generate guide paths, and then the AI\nuses fault-tolerance methods to ensure that characters can actually move along those\npaths under arbitration by the collision system.\n\nIn Figure 3.8.2, collision takes place between a character and the obstacles drawn\nin black. The pathfinder approximates this with a polygonal path-finding space,\ndrawn in white. The black line shows a guide path returned by the pathfinder. The\ngray line shows the direction in which the character must move to avoid collision\n(with the obstructions in black) while continuing in the general direction of the guide\npath. [Reynolds97] describes how steering behaviors can be combined to achieve this\n\nkind of effect.\n\nFIGURE 3.8.2 Steering to avoid collision.\n\nThe fault-tolerant approach is attractive because it produces plausible results\nfrom the point of view of modeling real-world behavior. If we have simple collision\nand a relatively small world to test our behaviors against, then this approach can\nwork well. The more closely path-finding space approximates real collision, the bet-",
      "content_length": 2016,
      "extraction_method": "OCR"
    },
    {
      "page_number": 318,
      "chapter": null,
      "content": "324\n\nSection 3 Artificial Intelligence\n\nter this approach will work. However, if we have reasonably complex collision, then it\nwill be difficult to approximate this with a pathfinder. If our behaviors will be applied\nin a large number of different situations, then we can also expect problems with this\nmethod.\n\nIn some situations, it is difficult to find the correct steering. For the character in\nFigure 3.8.3, it is necessary to change direction several times in order to get through\nthe gap. The squiggly gray line in Figure 3.8.3 indicates the steering that is required. If\nthe correct steering cannot be found in a situation like this, the result will probably just\nbe a character floundering momentarily against an obstruction. In a more extreme sit-\nuation, the result could be a character getting stuck in between obstructions.\n\nFIGURE 3.8.3 Steering correctly can be a complex problem.\n\nTo find the correct steering in a difficult situation requires future possibilities for\nmovement to be taken into account. The gray line in Figure 3.8.3 is really a detailed\npath for planned movement as opposed to a steering vector. A combination of path\nsections needs to be found to solve for movement through the gap. The first section\nof this needs to correctly position the character for movement along the second sec-\ntion, and so on. In this case, finding the correct steering really requires planning and\nsome detailed understanding of collision.\n\nSometimes, it might not actually be possible to move along the guide path. Con-\nsider for example a gap slightly narrower than that in Figure 3.8.3. In this case, we\nwould like characters to recognize in advance that a gap cannot be passed and choose\nanother, more appropriate path. Again, this requires planning and detailed under-\nstanding of collision.\n\nWe can perhaps extend the fault-tolerant approach to address these problems by\nusing planning mechanisms that adapt to feedback from collision. The first time a",
      "content_length": 1970,
      "extraction_method": "OCR"
    },
    {
      "page_number": 319,
      "chapter": null,
      "content": "3.8 Choosing a Relationshp Between Path-Finding and Collision 325\n\nApproa\n\ncharacter arrives at the gap in Figure 3.8.3 and fails to find a way through with reac-\ntive behaviors, we could mark that gap as blocked in our path-finding representation.\nThis kind of fault tolerance is difficult to implement and still does not provide any\nreal guarantees about behavior. There is nothing to stop a character from walking into\na situation that they cannot steer out of.\n\nAnother approach might be to use machine-learning techniques, such as neural\nnetwork training, to build behavior directly from collision feedback. These kinds of\ntechniques effectively automate the linkage between collision and behavior—but note\nthat a dependency on collision still remains. The results of these kinds of techniques\ndepend very much on the exact nature of the collision, so any change in the collision\nsystem introduces the risk of breaking behaviors. Even if the collision system doesn’t\nchange, these techniques do not work well in collision situations that are different\nfrom those they were trained on.\n\nIf we need guarantees about behavior, then we are probably better off accepting\nlinkage between AI and collision. This enables us to design an understanding of colli-\nsion into our Al.\n\nch #2: Path-Finding in a Subset of\nructed Space\n\nBAAS SURRY CNHOSS RNR EE ARR A RRA NOON RNAS CRRA TTR TANIA ISMN AHI\n\nWith this approach, we can define a relationship between collision and path-finding\nwhile avoiding the need for interdependencies between these systems. Specifically, we\nneed to guarantee that all points in path-finding space are unobstructed by collision;\nor in other words, that valid space for the pathfinder is a subset of true unobstructed\nspace.\n\nTrue unobstructed space means the set of positions where a character can be\nplaced without being in collision. If the orientation of a character affects whether that\ncharacter is in collision, then that orientation adds an extra dimension(s) to unob-\nstructed space, and therefore a position in unobstructed space will include orientation\nas a component. For this approach, path-finding space can be represented in fewer\ndimensions than true unobstructed space, and the boundary of path-finding space is\nsimplified. What is important is that the movement through positions in path-find-\ning space is guaranteed to be collision-free.\n\nFigure 3.8.4 shows how path-finding space might be constructed for this\napproach. In this case, the rotational dimension of collision is eliminated by using a\nbounding box that is large enough to fit the character at any rotation. Sets of obstruc-\ntions are simplified by taking convex hulls and then expanding the resulting geometry\nby the shape of our bounding box. (See [Young01] for more detail.) The result is that\nwe can guarantee that our character will not collide at any rotation of that character\nfor any position in path-finding space.\n\nWe can use a similar approach for tile-based path-finding. In this case, we can\nrender expanded shapes into the path-finding grid and flag any grid tiles overlapped\nby these shapes as obstructed.",
      "content_length": 3126,
      "extraction_method": "OCR"
    },
    {
      "page_number": 320,
      "chapter": null,
      "content": "326\n\nSection 3 Artificial Intelligence\n\nFIGURE 3.8.4 Path-finding in a subset of unobstructed space.\n\nThe advantage of this approach is that the pathfinder can now tell us how to\nmove without colliding. A path returned by the pathfinder can be followed without\nthe need for a layer of reactive behaviors because we know that the path will be unob-\nstructed. The AI still doesn’t know how to get through the narrow gap, but now this\nis integrated into movement-planning so that our behavior can choose another path\nor do whatever is appropriate. If we want our character to be able to get into the top-\nleft part of our environment, then we will need to widen the gap; but now we can use\nthe pathfinder to tell us about this kind of problem automatically.\n\nBecause path-finding space is only a subset of true unobstructed space, we must\ndeal with the possibility that characters might find themselves outside of valid space.\nCharacters should never get to an invalid position by following paths returned by the\npathfinder; but we must consider the possibility that characters might be pushed out-\nside of path-finding space by interactions with other characters, the force of an explo-\nsion, or whatever.\n\nThe pathfinder cannot tell a character outside path-finding space how to get back\ninto path-finding space without colliding. Once a character is outside of path-finding\nspace, we have the same kind of problems as with the previous approach. We can use\nreactive methods to get back to a valid position, but if a character is pushed into a nar-\nrow gap, then there is still a possibility that the character might get stuck. This situa-\ntion is a lot less likely because characters will not move into gaps by themselves; hence,\nthe reactive methods can be focused on simply getting characters back to a valid\npoint. They are simpler to code and more functional.\n\nA good, practical solution that enables us to give guarantees about character\nbehavior is to allow characters to cheat collision when moving back into path-finding\nspace. If everything works correctly and problematic configurations of geometry are",
      "content_length": 2112,
      "extraction_method": "OCR"
    },
    {
      "page_number": 321,
      "chapter": null,
      "content": "3.8 Choosing a Relationshp Between Path-Finding and Collision 327\n\navoided, then this shouldn't be needed, but designing this into our system can give us\na lot more peace of mind during beta testing. (Beware of potential consequences of\ncheating collision, as discussed below.)\n\nFinding a Valid Position\n\nThe simplest way to obtain a valid position for a character that has somehow found\nitself outside of path-finding space is to keep track of the last known good position. This\ncan give bad results if a character moves a significant distance while outside path-finding\nspace (see Figure 3.8.5a). Additionally there will be times when we need to deal with a\nposition outside path-finding space for which there is no last-known good position.\n\nA more elegant approach is for the pathfinder to provide a query that returns the\nclosest point inside path-finding space to a given point outside that space. This works\npretty well and applies more generally; but in certain situations, the resulting point\nmight be on the other side of a wall from a character's current position (Figure\n3.8.5b). If this happens, the character will not be able to get back into valid space by\nmoving toward that point unless they are allowed to cheat collision. If they are\nallowed to cheat collision, then the result is that a character gets through a wall and\ninto another part of the game. This can sometimes have humorous consequences, but\nis nonetheless a pretty serious bug.\n\nA B C\n\nFIGURE 3.8.5 (A-C) Finding a valid position.\n\nPutting Backbones in the World\n\nWe can improve the closest valid point method by adding an extra level of hard-colli-\nsion ‘backbones’ to the world (Figure 3.8.5c). These backbones can be represented\nexplicitly or can be based on the existing world representation. If the world is already\ndivided into cells, then it could be sufficient to use boundaries between cells as back-\nbones. The closest valid point query is then modified to look for the closest point that\ndoes not involve crossing a backbone. This gives us a more appropriate result.",
      "content_length": 2059,
      "extraction_method": "OCR"
    },
    {
      "page_number": 322,
      "chapter": null,
      "content": "328 _ Section 3 Artificial Intelligence\n\nFor the case where characters are allowed to cheat collision while returning to\npath-finding space, the backbones provide a way for us to enforce constraints about\nconnectivity in the game world. Theoretically, this means that path-finding around\nbackbones might now be required in order to maintain our guarantee that characters\ncan always get back to a valid position; but in practice, this will probably not be nec-\nessary. If we do implement path-finding around backbones, then this will also be use-\nful for hierarchical path-finding (see [Rabin00)).\n\nApproach #3: Using the Pathfinder Itself for\nCharacter Collision\n\nASH SSSRURNMRMEY Cre NMRENRANNN\n\nBoth of the previous approaches are complicated by the possibility of situations where\nobstruction by the collision system is not understood by the pathfinder’s simpler\nmodel. We can avoid this with a third approach, which uses the pathfinder itself to\nprovide character collision. This approach guarantees that characters cannot be\npushed out of path-finding space and, therefore, that the pathfinder will always be\nable to understand a character’s current position (and that paths returned by the\npathfinder can always be followed). This gives us a simplified architecture and reliable\ncharacter movement, but at the cost of having to use simplified mechanics for charac-\nter collision.\n\nThere are other advantages to using simplified character collision. The collision\nwill be extremely fast, robust, and predictable. We can use the collision system to\nimplement constraints on game progression or to trigger scripts and be confident that\nthis will all work exactly as intended. On the other hand, we potentially lose a lot of\ninteresting interaction between the character and the world, which a sophisticated\ncollision system would have provided.\n\nCharacters might still need to deal with target positions outside path-finding\nspace, and for this, we might still need a query to find the closest valid point. The\nadvantage is that we no longer depend on these methods to extract a character from\npotentially being stuck in positions.\n\nEAE HER ERE EEA SE RHE Ns AREER ESTEE ORES SS TRIOS RAAT\n\nLayered Collision\n\nIn order for the AI to understand the mechanism that controls character movement,\nwe need to simplify this mechanism; but complex collision interaction is necessary if\nwe want to create an interesting and believable environment. The trick to meeting\nboth of these requirements at the same time is to use a layered collision architecture.\n\nIf behavior is implemented in terms of movement through path-finding space\nand the pathfinder understands the system that governs that movement, then we have\nall the guarantees that we need. Movement through path-finding space will often\nmean the translational part of the movement of a character’s local origin. In our lay-\nered architecture, a path-finding collision layer deals with this part of character move-\nment. More-sophisticated interactions can be provided in a world collision layer as\nlong as those interactions do not affect this movement of the character’s origin.",
      "content_length": 3132,
      "extraction_method": "OCR"
    },
    {
      "page_number": 323,
      "chapter": null,
      "content": "3.8 Choosing a Relationshp Between Path-Finding and Collision 329\n\nWorld collision can take responsibility for extra dimensions of the character's\nposition (such as the vertical coordinate of that position or the orientation of the\ncharacter) if those dimensions are not relevant to the pathfinder’s collision model.\nNote that if a character needs to turn in a certain direction in order to move, then we\nhave to be careful when applying world collision to character orientation. World col-\nlision can also give us 3D interactions between a character’s limbs and the environ-\nment as long as that character's skeleton remains anchored to the character’s origin.\n\nBy designating certain events as temporary or exceptional, we can add more-\ninteresting interactions to the system. It makes sense for certain events to interfere\nwith the ability of a character to move along a path; so for these types of events, we\ncan allow world collision to affect movement through path-finding space. Consider\nfor example the blast from an explosion or interaction with a projectile. The only con-\nstraint for these types of events is that the character should not be moved outside\npath-finding space by the interaction, so we know that the character will be able to get\nup afterward and resume path-finding. Figure 3.8.6 shows how a force resulting from\na 3D interaction might be fed back into the path-finding collision layer.\n\n~_@,’\n\n~——— Interaction in 3D\n\n\\\n\nForce applied in\npathfinding ~__\ncollision\n\nFIGURE 3.8.6 Interaction between collision layers.\n\nIm lementing Movement Along a Path\n\nsUNURARE RAAT ARE STIRRUP NENA RONEN AER ASER CRRA EAE ATR AUT NAMES LTE TH SOTA TRATES\n\nFor the second and third approaches, we assume that a character moving along a path\nwill not leave path-finding space. In order to ensure that this is true, we have to be\ncareful exactly how movement along a path is implemented.\n\nIt is quite common to implement character control through a turn-and-move\ninterface. A range of angles might be used to detect success in turning toward the next\npath target before moving forward. However, this will result in characters clipping\ncorners (Figure 3.8.7a). Even if we get the angle exactly right, a character might still\nend up at an invalid position by overshooting a path target (Figure 3.8.7b). With\napproach number two, this means the pathfinder must find the closest valid point,",
      "content_length": 2398,
      "extraction_method": "OCR"
    },
    {
      "page_number": 324,
      "chapter": null,
      "content": "330 Section 3 Artificial Intelligence\n\nA B c D\nFIGURE 3.8.7 (A-D) Moving along a path.\n\nbut moving to that point will interfere with smooth movement along the path. For\napproach number three, these problems can result in a character being blocked by\npath-finding collision and unable to move along the path. Making the characters slide\nalong the edges of path-finding space will help in many cases, but not all.\n\nThe code required to eliminate these kinds of errors in a turn-and-move interface\ngets quite complex. We can simplify the situation by switching to parametric move-\nment along a path (Figure 3.8.7c). Turn constraints can still be satisfied before start-\ning to move along a path, but for turn constraints during movement along the path,\nwe are better off modifying the path to satisfy the constraints (Figure 3.8.7d).\n\nEven with parametric movement, there are issues about the approximation for\npoints along a path. The most common problem will be when a path follows a diago-\nnal boundary of path-finding space, as shown in Figure 3.8.8a. Approximating a point\nat a given distance along this path might result in a point that is just outside path-find-\ning space. In this case, we could avoid the problem by choosing the direction of\napproximation, depending on the direction of the path before and after this section.\n\nHowever, choosing the direction of approximation will not solve a situation such\nas that shown in Figure 3.8.8b. Here, even though we’ve approximated the point in\nthe right direction with respect to the angle of the following corner, we still come up\nwith a point inside an obstacle. A more general solution is to attempt to move to a\nfirst approximation, and only if this fails generate another point by approximating in\nthe other direction.\n\nIn a situation such as that shown in Figure 3.8.8c, there might be no valid points\nalong a path section. This kind of situation is pretty rare; so for static maps, we can\nadd code to the map-validation routines to check for this possibility and, if it occurs,\nsimply modify the maps to remove the problem. For geometry that changes at run-\ntime, we don’t have this option. One solution is to restrict the edges of dynamic\ngeometry to horizontal, vertical, or 45° lines because the problem cannot occur with\n\nthese kinds of edges.",
      "content_length": 2307,
      "extraction_method": "OCR"
    },
    {
      "page_number": 325,
      "chapter": null,
      "content": "3.8 Choosing a Relationshp Between Path-Finding and Collision 331\n\nFIGURE 3.8.8 (A-C) Problems with approximation.\n\nConclusion\n\nThe relationship between AI, path-finding, and collision is a key issue for movement-\nbased Al. The fault-tolerant approach produces the most plausible results from the\npoint of view of simulating real behaviors and requires minimal constraints on path-\nfinding and collision. However, this approach can add a lot of complexity to the\nimplementation of behavior, which makes it very difficult to build behaviors that will\nwork reliably in all circumstances.\n\nPath-finding in a subset of truly unobstructed space gives reliable behavior most\nof the time at the cost of requiring some minimal linkage between the path-finding\nand collision subsystems. Since characters can still get outside path-finding space, we\nstill need to be able to deal with this case. It is possible to guarantee the results of\nbehavior with this approach if we allow characters to cheat collision in certain cir-\ncumstances,\n\nUsing the pathfinder itself to control character collision results in the simplest\narchitecture and the most reliable behavior. If it is essential to guarantee the results of\nbehaviors, then this is the approach to use. More-interesting collision interactions can\nbe provided through a layered collision architecture.\n\nThe second and third approaches can perhaps be seen as ‘control freak’\napproaches. To make these approaches work best, we need to extend this attitude to",
      "content_length": 1500,
      "extraction_method": "OCR"
    },
    {
      "page_number": 326,
      "chapter": null,
      "content": "Section 3 Artificial Intelligence\n\n332\nthe mechanisms for implementing movement along paths. These approaches do not\ngive the most plausible architecture for behavior simulation, but for games that make\ndifficult demands on the AI, they provide a way to get through beta without too\n\nYP y to g 8\n\nmuch cost to hair or to sanity.\n\nReferences\n\nstv aa oreo ER BRN RATA ISAH ARRAN LESLIE SOTO NI ELLE LILO REE ERAS TRL TEL LON TS ITE\n\n[PathEngine] Path Engine, available online at http://www.pathengine.com, January\n\n[Rabin00] Rabin, Steve, “A* Aesthetic Optimizations,” Game Programming Gems,\nCharles River Media, Inc., 2000.\n\n[Reynolds97] Reynolds, Craig, “Steering Behaviors for Autonomous Characters,”\navailable online at http://www.red3d.com/cwr/steer/, September 6, 1997.\n\n[Young01] Young, Thomas, “Expanded Geometry for Points-of- Visibility Path-find-\ning,” Game Programming Gems 2, Charles River Media, Inc., 2001.",
      "content_length": 919,
      "extraction_method": "OCR"
    },
    {
      "page_number": 327,
      "chapter": null,
      "content": "4.1\n\n338\n\nT-Junction Elimination\nand Retriangulation\n\nEric Lengyel, Terathon Software\nlengyel@terathon.com\n\nuppose that a scene contains two polygons that share a common edge as shown in\n\nFigure 4.1.1a. When two such polygons belong to the same object, the vertices\nrepresenting the endpoints of the common edge are usually not duplicated. Instead,\nboth polygons reference the same vertices to save space and bus bandwidth. Graphics\nhardware is designed so that when adjacent polygons use exactly the same coordinates\nfor the endpoints of shared edges, the rasterizer produces pixels for each polygon that\nare precise complements of each other. Along the shared edge, there is no overlap\nbetween the pixels belonging to one polygon and those belonging to the other; and,\nmore importantly, there are no gaps between the polygons.\n\nA problem arises when adjacent polygons belong to different objects that have\ntheir own copy of the endpoint vertices for the shared edge. These vertices might\ngreatly differ in each object’s local coordinate space. For instance, when the vertices\n\n(a) (b)\n\nFIGURE 4.1.1 (A) Adjacent polygons sharing a common edge. (B) Adjacent polygons\nwith edges falling within the same line in space, but not sharing the same endpoints.",
      "content_length": 1253,
      "extraction_method": "OCR"
    },
    {
      "page_number": 328,
      "chapter": null,
      "content": "339\n\nare transformed into world space, floating-point round-off error could produce\nslightly different vertex positions for each object. Since the vertex coordinates are no\nlonger equal, a seam might appear when the polygons are rasterized.\n\nA greater problem occurs when two polygons have edges that fall within the same\nline in space, but they do not share the same endpoints, as illustrated in Figure 4.1.1b.\nIn such a situation, a vertex belonging to one polygon lies within the interior of an\nedge belonging to the other. Due to the shape that the edges form, the location at\nwhich this occurs is called a T-junction. Because the adjacent edges do not share iden-\ntical endpoints, T-junctions cause visible seams in any game engine that does not\neliminate them.\n\nThis gem describes how to detect possible sources of these seams in complex 3D\nscenes and how to modify static geometry so that visible artifacts are avoided. Since T-\njunction elimination adds vertices to existing polygons (that are not necessarily con-\nvex), we also discuss a method for triangulating arbitrary concave polygons.\n\nT-Junction Elimination\n\npiesinae care NN RR EONNNONe ae\n\nHERR RRS ERR eNO RASHLSNSSRS SSID ON MAE RARE\n\nGiven an immovable object Ai in our world, we e need to ) determine whether there exist\nany other immovable objects possessing a vertex that lies within an edge of object A.\nWe only consider those objects whose bounding volumes intersect the bounding vol-\nume of object A. Let object X be an object that lies close enough to object A to possibly\nhave adjacent polygons. We treat both objects as collections of polygons having the\ngreatest possible number of edges. We perform triangulation of these polygons after the\nT-junction elimination process in order to avoid the creation of superfluous triangles.\n\nBefore we locate any T-junctions, we first want to find out if any of object A’s ver-\ntices lie very close to any of object X’s vertices. We must transform the vertices belong-\ning to both objects into world space and search for vertices separated by a distance less\nthan some small constant €. Any vertex V, of object A that is this close to a vertex Vy\nof object X should be moved so that V, and Vy have the exact same world-space coor-\ndinates. This procedure is sometimes called welding.\n\nOnce existing vertices have been welded, we need to search for vertices of object\nX that lie within a small distance € of an edge of object A, but which do not lie within\nthe distance € of any vertex of object A. This tells us where T-junctions occur. Let P;\nand P, be endpoints of an edge of object A, and let Q be a vertex of object X. The\nsquared distance d? between the point Q and the line passing through P, and P, is\ngiven by\n\n2 =(Q-B) _[@-2)-@-Pf (4.1.1)\n\nIf d? < €”, then we know that the point Q lies close enough to the line containing\nthe edge of object A, but we still need to determine whether Q actually lies between\nP, and P,. We can make this determination by measuring the projected length ¢ of the",
      "content_length": 3021,
      "extraction_method": "OCR"
    },
    {
      "page_number": 329,
      "chapter": null,
      "content": "340 Section 4 Graphics\n\nline segment connecting P; to Q onto the edge formed by P; and P,. As shown in\nFigure 4.1.2, this length is given by\n\nt= ja — P,|| cos a, (4.1.2)\n\nwhere @ is the angle between the line segment and the edge. Using a dot product to\ncompute the cosine, we have\n\n(2-9) -(B - Bi) (4.1.3)\n\nBl\n\nIf t > lr, - P|| — €, then the point Q does not lie within the interior of the edge\nformed by P, and P,. Otherwise, we have found a T-junction, and a new vertex\nshould be added to the polygon of object A between P, and P,, precisely at Q’s\n\nlocation.\n\nFIGURE 4.1.2 The length t is equal to the distance from P, to the projection of point Q,\n\nonto the edge between P, and P;.\n\n. :\nRetriangulation\n\nEO RRO NI ARROEN\n\nRR si\n\naR RRS EUAN ASAIN et ER RE\n\nAfter all the static world geometry has been processed, we must triangulate the result-\ning polygons so that they can be passed to the graphics hardware. Any vertex added to\na polygon to eliminate a T-junction is collinear (or at least nearly collinear) with the",
      "content_length": 1024,
      "extraction_method": "OCR"
    },
    {
      "page_number": 330,
      "chapter": null,
      "content": "4.1. T-Junction Elimination and Retriangulation\n\n341\n\nendpoints of the edge for which the T-junction occurs. After all T-junctions have been\neliminated for a single polygon, its edges might contain several vertices that fall in a\nstraight line. This prevents us from using a simple fanning approach that might ordi-\nnarily be used to triangulate a convex polygon. Instead, we are forced to treat the\npolygon as concave.\n\nThe algorithm that we describe takes a list of 2 vertices wound in a counterclock-\nwise direction as input and produces a list of m — 2 triangles. At each iteration, we\nsearch for a set of three consecutive vertices for which the corresponding triangle is\nnot degenerate (not wound in the wrong direction) and does not contain any of the\npolygon’s remaining vertices. Once such a set of three vertices is found, the middle\nvertex is disqualified from successive iterations, and the algorithm repeats until only\nthree vertices remain.\n\nIn order to determine whether a set of three vertices is wound in a counterclock-\nwise direction, we must know beforehand the normal direction No of the plane con-\ntaining the polygon being triangulated. Let P,, P,, and P; represent the positions of\nthe three vertices. If the cross-product (P, — P,) x (P3 — P,) points in the same direc-\ntion as the normal Np, then the corresponding triangle is wound counterclockwise. If\nthe cross-product is near zero, then the triangle is degenerate. Thus, two of our three\nrequirements for a triangle are satisfied only if\n\n(P, -P,)x(P,-P)-N.>e (4.1.4)\n\nfor some small value € (typically, € = 0.001).\n\nOur third requirement is that the triangle contains no other vertices belonging to\nthe polygon. We can construct three inward-facing normals, N,, N,, and N;, corre-\nsponding to the three sides of the triangle, as follows.\n\nN, = N, x(P, -B)\nN, = N, x(P; — Py)\n\nN, = N, x(P, - Py) (4.1.5)\n\nAs shown in Figure 4.1.3, a point Q lies inside the triangle formed by P,, P,, and\nP; if and only if N, - (Q— P,) > -€ for every i = 1,2,3.\n\nSince we have to calculate the normals given by Equation 4.1.5 for each triangle,\nwe can save a little computation by replacing the condition given by Equation 4.1.4\nwith the equivalent expression\n\nN, -(P,-P,)>e (4.1.6)\n\nThis determines whether the point P; lies on the positive side of the edge con-\nnecting P, and P,.",
      "content_length": 2345,
      "extraction_method": "OCR"
    },
    {
      "page_number": 331,
      "chapter": null,
      "content": "342 Section 4 Graphics\n\nFIGURE 4.1.3 A point Q lies inside a triangle if and only if it lies on the positive side of\n\neach of the three edges of the triangle.\n\nImplementation\n\nEE\n\nSoo NAAT RAPIER REAR RR ER RRR NTIS\n\nThe source code provided on the CD-ROM demonstrates an implementation of the\n€e2%% — retriangulation algorithm. This particular implementation maintains a working set of\noNTHECD —_ four consecutive vertices and, at each iteration, determines whether valid triangles can\nbe formed using the first three vertices or the last three vertices. If only one of the sets\nof three vertices forms a valid triangle, then that triangle is omitted, and the algorithm\ncontinues to the next iteration. If both sets of three vertices can produce valid trian-\ngles, then the code selects the triangle having the larger smallest angle. In the case that\nneither set of three vertices provides a valid triangle, the working set of four vertices is\n\nadvanced until a valid triangle can be constructed.\nThe method presented by the source code was chosen so that the output of the\nalgorithm would consist of a series of triangle strips and triangle fans. Such triangle\nstructures exhibit excellent vertex cache usage on modern graphics processors. The",
      "content_length": 1245,
      "extraction_method": "OCR"
    },
    {
      "page_number": 332,
      "chapter": null,
      "content": "343\n\n4.1. T-Junction Elimination and Retriangulation\n\nimplementation also includes a safety mechanism. If a degenerate, self-intersecting, or\notherwise nontriangulatable polygon is passed to it, then the algorithm terminates\nprematurely to avoid becoming stuck in an infinite loop. This happens when the code\ncannot locate a set of three consecutive vertices that form a valid triangle.\n\nConclusion\n\nRendering artifacts such as seams between adjacent objects can be avoided by welding\nnearly-coincident vertices and performing T-junction elimination.\n\nWhen these operations are performed as a preprocessing step, the resulting set of\npolygons may contain three or more collinear vertices. Fortunately, these polygons\ncan be triangulated using a simple but robust algorithm that emits a single triangle at\na time and recursively triangulates smaller sub-polygons.",
      "content_length": 862,
      "extraction_method": "OCR"
    },
    {
      "page_number": 333,
      "chapter": null,
      "content": "4.2\n\nFast Heightfield Normal\nCalculation\n\nJason Shankel, Maxis\nshankel@pobox.com\n\na are two-dimensional arrays of height values, commonly used to store\nterrain or water surface data, and are also commonly used for calculating bump\nmaps. This gem will describe how we can take advantage of the special characteristics\nof heightfield meshes to significantly optimize vertex normal calculation.\n\nlighting- and/or environment-mapping calculations are needed for the final rendering\nresult. There are two kinds of normals typically associated with a 3D mesh—face nor-\nmals and vertex normals. Face normals are, as the name implies, normals associated\nwith each face in a mesh. Vertex normals are normals associated with each vertex.\n\nFace Normals\n\nCalculating face normals is relatively straightforward. Pick two edges of the face that\nshare a common vertex and define two vectors (v, and v2) pointing along the edges\nwith their origin at the shared vertex. The face normal (m;) is a unit vector pointing in\nthe direction of the cross-product, , of v, and v2. Note that any two edges will do for\ntriangles, as shown in Figure 4.2.1.\n\nne = (v, X vy)! |v, X 0, | (4.2.1)\n\nVertex Normals\n\nVertex normals are a little less straightforward. While there is only one correct normal\nfor a given face, a given vertex might have multiple normals, each associated with a\nparticular face or group of faces. However, for meshes that are fairly smooth (which is\ntypical for heightfields), we can find a reasonably unique vertex normal by averaging\nthe normals of each face that touches the vertex. This average should be weighted by\nthe relative angle of each face at the vertex to prevent thin or highly tesselated faces\nfrom skewing the result.\n\n344",
      "content_length": 1732,
      "extraction_method": "OCR"
    },
    {
      "page_number": 334,
      "chapter": null,
      "content": "4.2 Fast Heightfield Normal Calculation 345\n\nng = (019 v9)/lv, 9 v9|\n\nFIGURE 4.2.1 Calculating a face normal for a triangle.\n\nLet {72), 7, 3...2,} be the normals of the faces touching vertex v, and let {a), a,\n4;...a,} be the angles between the edges of faces 1 through n.\n\nThe normal at vertex v is given by Equation 4.2.2, as shown in Figure 4.2.2.\n\nn\n\nn — 120\n\n7 (4.2.2)\n\nny = (1141+ NzA7+ 1343+ N4gA4)/(a,+a7+ 43+ a4)\n\nFIGURE 4.2.2 Calculating a vertex normal using face normals,",
      "content_length": 483,
      "extraction_method": "OCR"
    },
    {
      "page_number": 335,
      "chapter": null,
      "content": "346 Section 4 Graphics\n\nSESE CER ANAS! eS eA REAR RRRRA\n\nHeightfield Normals\n\nThe vertices of a heightfield mesh can be defined as follows by v,,, where\n\nVp = {x y, A(x, yh. (4.2.3)\n\nIn Equation 4.2.3, x and y are regularly-spaced indices into the heightfield grid,\nand A(x,y) is the height at x,y. For a given vertex v in the heightfield, we can arrange\nthe neighboring vertices as shown in Figure 4.2.3. For simplicity, 4,4 refer to the\nvalues of A() for the four neighbors, and the four vectors which have their origins at v\nand point to the neighboring vertices are labeled 14,4.\n\nvy={x,y+1, Aa}- v\n\nv3={x-1, y,h3}-v v,={x+l, y,Ay}- v\n\nv={ x,y,h}\n\nvg={xy-1, Ag} o\n\nFIGURE 4.2.3 Heightfield vertex neighbors.\n\nSimplifying with Assumptions\nGiven the unique characteristics of heightfield vertices, we can make a number of\nassumptions that simplify the general vertex normal formula.\n\nFirst, we can assume that each vertex in the heightfield belongs to exactly four\nfaces. Note that, strictly speaking, this might not be the case. We are assuming that\nthe mesh is composed of quads, when it will most likely be composed of triangles.\nHowever, this assumption should not adversely affect the quality of our normals.\n\nSecond, we can assume that each of a vertex’s faces contributes equally to the ver-\ntex normal, thus eliminating the need for performing a weighted average. Again, this\nassumption is not completely safe. If two neighboring height values greatly diverge,\nthen the angle of their corresponding face will significantly diverge from 90°, thus",
      "content_length": 1555,
      "extraction_method": "OCR"
    },
    {
      "page_number": 336,
      "chapter": null,
      "content": "ield Normal Calculation 347\n\nchanging the ‘correct’ contribution of the face. However, in cases where neighboring\nheight values diverge significantly, the local vertices no longer have unique normals;\nand any formula, even the ‘correct’ one, will produce suspect results.\n\nFinally, since the x and y values are regularly spaced, when we set the origin at »,\nthe neighboring vertices will all have x and y values of 1, -1, or 0. These constants will\ngreatly simplify the cross-product formula.\n\nDoing The Math\n\nLet’s start with the original formula:\nn\ndna\n\nn, = 20 (4.2.4)\n\nn\na\n1=0\n\nNext, since there are only four faces and each contributes equally to the normal,\nwe can simplify the average:\nn,=(n, +n, +n, + 14)/4 (4.2.5)\n\nNow, when we go to calculate 7. 4, we will find that the cross-products reduce to\nsimple terms:\n\nn= 0,XV,= {-A, - h, 1}\nNy =V, X03 = {h,,—h,,1}\nNy =0;X04 = {h,h,,1}\n\nNg =U, XV, = {—h,,Ag.1} (4.2.6)\n\nIdeally, we would like 2,4 to have equal magnitudes, since variation in their\nmagnitudes will affect the averaging formula. However, since the magnitudes of 7, 4\nonly significantly vary in cases where the neighboring height values diverge, we can\nget away with using 7,4 as they are.\n\nAdding up, we get:\nn, = (n, +, +5 +14) 4 = {2(b, — hy), hy — hy), 44 (4.2.7)\n\nSince the magnitude of , is not important at this stage, we can multiply the\nwhole thing by two just to simplify the arithmetic:\n\nn, = {(bs ~ by)» (by — hy)» 2} (4.2.8)\n\nSince /,, 4 are most likely just memory lookups, it is clear that this formula is sig-\nnificantly faster than averaging four cross-products. It is important to remember that x,\nis not a unit vector and might need to be normalized, depending on your application.",
      "content_length": 1718,
      "extraction_method": "OCR"
    },
    {
      "page_number": 337,
      "chapter": null,
      "content": "348 Section 4 Graphics\n\nacetate nnstonnnlttcinrtaatsine ni fain RE aan BenittnechNctre Oe oNhn  ae RSE EANEn R eacnaeeneoReR ENERO\n\nConclusion\n\net wi Sad\n\nHeightfields are often used to store landscapes and other static objects. For these\nkinds of applications, the speed of vertex normal calculation is probably not an issue,\nas normals will most likely be calculated offline or only once at data load.\n\nHowever, for applications that use dynamic heightfields (say, to simulate the sur-\nface of a body of water or for procedural bump-map animation), speed is of the\nessence. This gem has shown how we can significantly improve the performance of\nthe standard vertex normal formula by taking advantage of the special characteristics\nof heightfield vertices.\n\nSample Code\n\npom\n\nThe sample code applies the fast normal formula to a heightfield, which animates\nbetween flat and a fractally-generated random landscapes. The sample code uses\nOpenGL and GLUT. See Color Plate 4 for some screenshots of this application.\n\nON THE CD\n\nRefe nces\n\neo REE SITNNR EB AOL REE RTS RHI NN ANCA RRR SIRES\n\n] Ebert, D., et al., Texturing and Modeling, AP Professional, 1994.\n[Fernandes00O] Fernandes, Antonio Ramires, “Terrain Tutorial,” available online at\nhttp://www. lighthouse3d.com/opengl/terrain/, September, 2000.",
      "content_length": 1302,
      "extraction_method": "OCR"
    },
    {
      "page_number": 338,
      "chapter": null,
      "content": "Fast Patch Normals\n\nMartin Brownlow, Shiny Entertainment\nmbrownlow@shiny.com\n\nSS\" patches are a memory-efficient way of creating smooth surfaces that can be\nrendered at many levels of detail. However, having a smooth surface is not as use-\nful if you cannot light it properly. For that, you need the normal vector at each vertex.\nAlas, this needs to be computed afresh for each vertex.\n\nAlthough the method described here works for any basis matrix, for the purposes of\nthis gem, we will limit ourselves to discussion of bicubic Bézier patches (referred to\nhereafter simply as “patches”). These patches are represented by 16 control points\narranged in a 4 X 4 grid. The control points form a convex hull that the actual surface\nlies within. Only the four corner control points actually lie on the surface.\n\nA surface normal (hereafter referred to as “normal”) is a unit vector that lies per-\npendicular to the surface at the point it is associated with. This vector has many uses,\nthe most common of which are lighting and collision detection.\n\nA point on a patch is defined uniquely by two parametric coordinates, which are\nusually referred to as u and », and have a valid range of [0.0, 1.0]. These are not to be\nconfused with texture coordinates (although they might be used directly as such). If\nwe regard the patch as a 4 X 4 grid of control points, then the u value represents the\nhorizontal fraction of the way across the grid, and the v value represents the vertical\nfraction. The actual-world position of a (u, v) point depends entirely on the control\npoints. Indeed, if the control points are not evenly spaced in the world (as is more\noften the case than not), then a continuous step in the u direction can produce steps\nof varying lengths in the world.\n\nThe efficient tessellation and rendering of patches is beyond the scope of this\ngem. Many excellent texts exist that detail the different methods for drawing patches\n(see [Farin96], [Foley96], and [Gallier00]). A description of any single one of them\nhere would be inappropriate, since this method of generating normals is applicable to\nmost, if not all, methods of rendering a patch.\n\n349",
      "content_length": 2155,
      "extraction_method": "OCR"
    },
    {
      "page_number": 339,
      "chapter": null,
      "content": "350 Section 4 Graphics\n\ntao npc inelebem enn ae eeOOet RR eerste Stacie Si mMM DREHER Ht tienen ooeolaen ES age eR ROR Da RO BEE EERE HIRES ANY\n\nTraditional Approaches\n\n_HomrERERNNOR ENRRRETHRCNNRRRRRE RMON\n\nThe most obvious approach to generating a patch vertex normal involves examining\nits neighbors. By considering the previous and next vertex in both the w and »v direc-\ntions of the patch, you can approximate the surface tangents. The normal is then sim-\nply the normalized cross-product of these two vectors.\n\nAnother method is to use the first derivative of the patch equations to directly\ngenerate the two tangent vectors. However, although this does not require any neigh-\nbors, it still needs a cross-product and a normalize operation per vertex.\n\nA ER SP TR ARR ORRIN ROS\n\nConsiderations\n\nRN RRR i\n\nIn order to efficiently process a patch on current PC graphics hardware, you must use\nwhat is called a “vertex shader.” This is basically a custom program written in a mini-\nmal but powerful instruction set that executes once for each vertex in the vertex\nstream. To gain the maximum parallelism and throughput, a vertex shader is restricted\nto operate on only one vertex at a time; it cannot access any vertex other than the one\ncurrently being processed. In other words, every vertex in the stream must contain all\nthe information needed to process it. It is also desirable to have the minimum amount\nof information per vertex to reduce the time spent by the graphics card in actually\naccessing the data, and to maximize the time spent in processing it. Obviously, our\ntarget is to have the vertex stream just contain the patch (#, v) coordinates for each\nvertex. Since the # and v coordinates have a range of [0.0, 1.0], and it is unlikely that\nwe will need more than about 100 subdivisions, it is possible to encode these into\nbytes, giving an impressive two bytes per vertex in the vertex stream!\n\nA Simpler Method\n\n‘a\n\nSHRM\n\nThese two methods presume that we only know the position at each control point,\nfrom which we can generate the curve equations and, ultimately, the normals. What if\nwe also have the normals at each control point to start with?\n\nThese are easily generated at each control point using a variety of methods,\nincluding the two methods previously described. A control point would then consist\nof a position and a normal. Any skinning code applied to a control point’s position\ncould also be applied to its normal. Given this, all we have to do is interpolate the\nnormal across the patch, just as we do the position. This has the added advantage of\nbeing a nonlinear interpolation, which will better approximate the real normal.\n\nThis meets all our hardware requirements; it requires only the (w, v) patch coor-\ndinates of the current vertex to correctly generate its position, normal, and texture\ncoordinates. It also has the advantages of working for any basis system and using\nexactly the same code as the position generation, just using control normals instead of\ncontrol points.",
      "content_length": 3020,
      "extraction_method": "OCR"
    },
    {
      "page_number": 340,
      "chapter": null,
      "content": "4.3 Fast Patch Normals 351\n\nOther Advantages\n\nPECAN dee eB AOR RS BS TR TENN HEEB Ue eS\n\nAnother advantage of this method is that by generating the normals in different ways,\nyou can eliminate shading artifacts from curve continuity issues. If we treat the set of\ncontrol meshes for the whole object as a single continuous mesh, then we can create\nvertex normals for each control point exactly as we would for a Gouraud-shaded\nmodel. Although the normals wouldn't strictly be correct with respect to the curves, it\ncan give the model a much smoother look that would otherwise take the modeler\nmuch longer to create. If the normals are generated in this way, we eliminate curve-\ncontinuity issues in the model. This method also eliminates any shading issues that\nare introduced during the skinning process, when the curves lose continuity with each\nother as they are influenced by different bones.\n\nMost modern graphics architectures use a vector-based processor that operates on\nfour data elements simultaneously. This method uses two vectors, but each contains\nonly three items. We can use this to our advantage and interpolate two extra values\nacross the patch. This could be used for a variety of things, such as arbitrary texture\nmapping or a varying alpha value for better transparency effects.\n\nExactly How Accurate Can This Be?\n\n‘eoteiauuarga aise tenance eee Reh A NAME ARUN ICSE\n\nA Bézier curve has the property that the control points form a bounding mesh that\nthe curve never exceeds. This means that the interpolated normal will never be greater\nthan the modulus of the control mesh normals. However, except in the case of a\nstraight curve segment, a Bézier curve never passes through the center two control\npoints. In other words, the modulus of the interpolated normal will always be less\nthan or equal to the modulus of the control normal. The result is an interpolation\nthat is somewhere between linear and the correct arc interpolation. In practice, the\nnormal difference across the patch is not too large, meaning that the interpolation is\nvery close to the correct value.\n\nFor other curve basis systems, the problem can be a little more severe, with the\nnormals getting quite large for sudden, sharp turns on the surface. However, with\nstrategic use of most modern graphic cards’ ability to automatically normalize nor-\nmals, this is less of an issue than it would otherwise be.\n\nConclusion\n\n2s SHARIR TSUN HP UA a A ERT RE RIN eS OR RNS\n\nPatch surfaces are useful for creating smooth, resolution-independent geometry with\nminimal memory usage. By treating the normal at each control point as a second con-\ntrol mesh, we can quickly approximate the correct surface normal. Although the\nresults are not strictly correct, they can produce superior results by eliminating shad-\ning errors due to curve discontinuity introduced during skinning.\n\nase",
      "content_length": 2864,
      "extraction_method": "OCR"
    },
    {
      "page_number": 341,
      "chapter": null,
      "content": "352 Section 4 Graphics\n\nesas he eee EAS\n\nReferences\n\n“sss eA LL RR RS NAOT TNE ES HORAN AN RSE NN IRE ERRORS RRR\n\n[Farin96] Farin, Gerald E., Curves and Surfaces for Computer Aided Geometric Design:\nA Practical Guide, Fourth Edition, Academic Press, 1996.\n\n[Foley96] Foley, Van Dam, et al., Computer Graphics: Principals and Practice, Second\nEdition in C, Addison Wesley, 1996.\n\n[Gallier00] Gallier, Jean, Curves and Surfaces in Geometric Modeling: Theory and Algo-\nrithms, Morgan Kaufmann Publishers, 2000.",
      "content_length": 507,
      "extraction_method": "OCR"
    },
    {
      "page_number": 342,
      "chapter": null,
      "content": "4.4\n\nFast and Simple\nOcclusion Culling\n\nWagner T. Corréa, Princeton University;\nJames T. Klosowski, IBM Research;\nand Claudio T. Silva,\n\nAT&T Labs-Research\n\nwtcorrea@cs.princeton.edu, jklosow@us.ibm.com,\nand csilva@research.att.com\n\ni many graphics applications, such as building walkthroughs and first-person\ngames, the user moves around the interior of a virtual environment and the com-\nputer creates an image for each location of the user. For any given position, the user\ntypically sees only a small fraction of the scene. Thus, to speed up the image render-\ning, an application should avoid drawing the primitives in the environment that the\nuser cannot see. There are several classes of algorithms to determine which primitives\nshould be ignored or culled. Back-face culling algorithms determine those primitives\nthat face away from the user. View frustum culling determines the primitives that lie\noutside of the user’s field of view. Occlusion culling determines the primitives that are\noccluded by other primitives.\n\nWhile back-face and view frustum culling algorithms are trivial, occlusion culling\nalgorithms tend to be complex and usually require time-consuming preprocessing\nsteps. This gem describes two occlusion culling algorithms that are practical, effective,\nand require little preprocessing. The first one is the prioritized-layered projection\n(PLP) algorithm, which is an approximate algorithm that determines, for a given bud-\nget, a set of primitives that is likely to be visible. The second algorithm, cPLP is a con-\nservative version of PLP that guarantees finding all visible primitives.\n\ndetermine which primitive fragments are visible; that is, which fragments are con-\nnected to the eye-point by a line segment that meets the closure of no other primitive\n[Dobkin97]. Researchers have studied this problem extensively, and many approaches\n\n353",
      "content_length": 1873,
      "extraction_method": "OCR"
    },
    {
      "page_number": 343,
      "chapter": null,
      "content": "P\n\nto solve it exist [Cohen-Or01, Durand99]. A recent survey on visibility algorithms,\n[Cohen-Or01] classifies algorithms according to several criteria. We will now briefly\nsummarize those that are most relevant to our gem.\n\nFrom-Point Versus From-Region\n\nSome algorithms compute visibility from the eye-point only, while others compute\nvisibility from a region in space. Since the user often stays in a region for some time,\nthe from-region algorithms amortize the cost of visibility computations over a num-\nber of frames.\n\nPrecomputed Versus Online\n\nMany algorithms require an offline computation, while others work in real-time. For\ninstance, most from-region algorithms require a preprocessing step to divide the\nmodel into regions and compute region visibility.\n\nObject Space Versus Image Space\n\nSome algorithms compute visibility in object space using the exact, original 3D prim-\nitives. Others operate in image space using only the discrete, rasterized fragments of\nthe primitives.\n\nConservative Versus Approximate\n\nFew visibility algorithms compute exact visibility. Most algorithms are conservative\nand over-estimate the set of visible primitives. Other algorithms compute approxi-\nmate visibility and do not guarantee finding all visible primitives.\n\nPLP [Klosowski00] is an approximate, from-point, object-space visibility algorithm\nthat requires very little preprocessing. PLP can be understood as a simple modifica-\ntion to the traditional hierarchical view-frustum culling algorithm [Clark76]. The tra-\nditional algorithm recursively traverses the model hierarchy from the root node down\nto the leaf nodes. If a node is outside the view frustum, we ignore the node and its\nchildren. If the node is inside or intersects the view frustum, we recursively traverse its\nchildren. The traversal eventually visits all leaves within the view frustum.\n\nThis PLP algorithm differs from the traditional one in several ways. First, instead\nof traversing the model hierarchy in a predefined order, PLP keeps the hierarchy of\nleaf nodes in a priority queue called the front and traverses the nodes from highest\nto lowest priority. When we visit a node (or project it, in PLP parlance), we add it to\nthe visible set. Then, we remove it from the front and add its /ayer of unvisited neigh-\nbors to the front (hence, the algorithm’s name, “prioritized-layered projection”). Sec-\nond, instead of traversing the entire hierarchy, PLP works on a budget, stopping",
      "content_length": 2458,
      "extraction_method": "OCR"
    },
    {
      "page_number": 344,
      "chapter": null,
      "content": "4.4 Fast and Simple Occlusion Culling 355\n\nthe traversal after a certain number of primitives have been added to the visible\nset. Finally, PLP requires each node to know not only its children, but also all of its\nneighbors.\n\nAn implementation of PLP can be simple or sophisticated, depending on the\nheuristic to assign priorities to each node. Several heuristics precompute the initial\nsolidity of a node and accumulate the solidities along a traversal path. The node’s accu-\nmulated solidity estimates how likely it is for the node to occlude an object behind it\n[Klosowski00]. In this gem, we use an extremely simple heuristic to assign priorities\nto the nodes. The node containing the eye-point receives priority —1, its neighbors\nreceive priority —2, their neighbors receive priority —3, and so on. Using this heuristic,\nthe traversal proceeds in layers of nodes around the eye-point. This is simple to imple-\nment, very fast, and quite accurate. We will show accuracy measurements when we\npresent the runtime results. The only precomputation this heuristic requires is the\nconstruction of the hierarchy itself.\n\nWe use PLP as a front-end to the hardware’s implementation of the z-buffer algo-\nrithm [Foley90]. For a given budget, PLP gives us the set of primitives it considers\n\n€ » most likely to maximize image quality. We simply pass these primitives to the graph-\noNTHECD ics hardware. The C++ implementation of PLP can be found on the CD-ROM.\n\nTh\n\nPLP Algorith\nAlthough PLP is, in practice, quite accurate for most frames, it does mot guarantee\nimage quality, so some frames might show objectionable artifacts. To circumvent this\npotential problem, we use cPLP [Klosowski01], a conservative extension of PLP.\n\nThe main idea of cPLP is to use the visible set given by PLP as an initial guess,\nwhile adding nodes to the visible set until the front (of the priority queue) is empty.\nThis guarantees that the final visible set is conservative [Klosowski01]. There are\nmany ways to implement cPLP, including exploiting new platform-dependent hard-\nware extensions for visibilicry computation. The implementation we describe in this\ngem uses an item-buffer technique that is portable to any system that supports\nOpenGL.\n\nThe cPLP main loop consists of two steps. First, we determine the nodes in the\nfront that are visible. To do this, we draw the bounding box of each node in the front,\nusing flat shading with a color equal to its identification number. We then read back\nthe color buffer and determine the nodes seen. Second, for each front node found\nto be visible, we project it (adding it to the visible set), remove it from the front,\nand then add its unvisited neighbors to the front. We iterate the main loop until\nthe front is empty. The bottleneck of the item buffer-based implementation of cPLP\nis in reading back the color buffer. To avoid reading the entire color buffer at each\nstep, we break the screen into tiles. Tiles that are not modified in one step can be\nignored in subsequent steps. The C++ implementation of cPLP can be found on the\n\nCD-ROM.\n\ncena rat\n\nHB Ratnam ea a SO EN",
      "content_length": 3102,
      "extraction_method": "OCR"
    },
    {
      "page_number": 345,
      "chapter": null,
      "content": "356 Section 4 Graphics\n\nACAARRAATARRN SRNR\n\nPLP and cPLP are attractive visibility algorithms for several reasons:\n\n¢ PLP and cPLP are from-point algorithms, and they make no assumption about\nthe model. In contrast, some from-region algorithms assume the model consists\nof axis-aligned rooms and portals [Teller91, Funkhouser93], which might be a\nsignificant restriction.\n\n¢ PLP and cPLP require little preprocessing. For most heuristics, the precomputa-\ntion consists of creating the model hierarchy and computing simple summary sta-\ntistics per node, such as the total number of primitives. This can be done quickly,\neven for a large model. On the other hand, other techniques [Teller91, Hong97,\nZhang97] can require preprocessing times on the order of hours or days, even for\nrelatively small models.\n\n¢ Although occlusion culling algorithms such as PLP avoid rendering unseen\ngeometry, they might still render small primitives that have little effect on the\nfinal image. As shown by [El-Sana01], PLP can be easily integrated with level-of-\ndetail management.\n\n¢ PLP is suitable for time-critical rendering. Even if we use the lowest levels of\ndetail, the number of visible primitives in a given frame might overwhelm a low-\nend graphics card. The PLP budget gives the user a convenient way to balance\nboth accuracy and speed. The impact of slightly incorrect images on the user’s\nperception of the walkthrough is often far less than the impact of low frame rates\n{Funkhouser96].\n\nPLP is most useful when higher frame rates are more important than absolute\naccuracy—for example, when the user is moving fast to get to a certain point. On the\nother hand, cPLP is necessary when artifacts are not acceptable, such as when the user\nhas reached his target and is closely examining its details. Ideally, an application\nshould allow the user to switch back and forth between PLP and cPLP on the fly.\n\nUNC power-plant model on a Pentium III, 733-MHz computer with a Nvidia\nGeForce2 graphics card. We collected statistics for both PLP and cPLP using a 500-\nframe path. Figure 4.4.1 shows a typical frame of this path using a budget of 140,000\ntriangles per frame.\n\nFor PLP, the average frame rate was 10.1 Hz, with 75% of the tests having a\nframe rate above 9.3 Hz. For cPLP, the average frame rate was 2.1 Hz, with 75% of\nthe tests having a frame rate above 1.5 Hz. Although the rates for cPLP are lower than\nthe rates for PLP, the image is guaranteed to be 100% correct. We measured the accu-\nracy of PLP by counting the number of incorrect pixels in the images it generated ver-\nsus the correct images generated. The average accuracy for PLP was 96.3%; and for\n75% of the test, the accuracy was above 94.9%.",
      "content_length": 2705,
      "extraction_method": "OCR"
    },
    {
      "page_number": 346,
      "chapter": null,
      "content": "4.4 Fast and Simple Occlusion Culling 357\n\nFIGURE 4.4.1 Using the prioritized-layered projection algorithm (PLP) to walk through\nthe 13-million triangle UNC power plant model. On a 733-MHz Pentium IIT\ncomputer with Nvidia GeForce2 graphics, PLP achieves an average frame rate of 10.1\nHz and an average accuracy of 96.3%.\n\nBecause of the layered traversal of the model hierarchy, the wrong pixels tend to\nbe at regions far from the eye-point. Sometimes the artifacts are noticeable, but they\nare usually tolerable and have little impact on the user's experience. Recall that we\nachieved this level of accuracy with the embarrassingly simple heuristic of traversing\nthe model hierarchy one layer at a time. We believe this accuracy can be even better\nwith more-sophisticated heuristics.\n\nConclusion\n\nPLP and cPLP are practical solutions to the ubiquitous visibility problem. PLP allows\nthe user to trade off accuracy for speed. With PLP there is no guarantee of image\nquality; however, in practice, it is good enough to give the user a sense of smooth nav-\nigation. Whenever 100% accuracy is critical, the program could switch to cPLP and\nstill be able to walk through the model at slower frame rates.",
      "content_length": 1199,
      "extraction_method": "OCR"
    },
    {
      "page_number": 347,
      "chapter": null,
      "content": "358\n\nReferences\n\nSection 4 Graphics\n\nThere are several ways to improve upon what we have presented in this gem.\nFirst, we have presented only one simple heuristic for estimating the visibility of a\nnode. More sophisticated heuristics exist [El-Sana01], and there is still room for\nimprovement. Second, these algorithms could be combined with level-of-detail man-\nagement [El-Sana01]. Finally, these algorithms could be used to drive caching\nschemes to handle models that are larger than the available main memory.\n\nRRO RUA BRIE RASTA\n\n[Clark76] Clark, James H., “Hierarchical Geometric Models for Visible Surface\nAlgorithms,” Communications of the ACM, 19(10): 547-554, October 1976.\n[Cohen-Or01] Cohen-Or, Daniel, Yiorgos Chrysanthou, Cldudio T. Silva, and Frédo\nDurand, “A Survey of Visibility for Walkthrough Applications,” ZEEE Transac-\n\ntions on Visualization and Computer Graphics.\n\n[Dobkin97] Dobkin, David and Seth Teller, Handbook of Discrete and Computational\nGeometry, Computer Graphics Chapter, CRC Press, 1997.\n\n[Durand99] Durand, Frédo, “3D Visibility: Analytical Study and Applications,”\nPh.D. Thesis, Université Joseph Fourier, Grenoble, France, 1999.\n\n[El-Sana01] El-Sana, Jihad, Neta Sokolovsky, and Cldudio T. Silva, “Integrating\nOcclusion Culling with View-Dependent Rendering,” in Proceedings of IEEE\nVisualization, 2001: 371-378.\n\n[Foley90] Foley, James D., Andries van Dam, Steven K. Feiner, and John FE. Hughes,\nComputer Graphics: Principles and Practice, Second Edition, Addison Wesley,\n1990.\n\n[Funkhouser93] Funkhouser, Thomas A. and Carlo H. Séquin, “Adaptive Display\nAlgorithm for Interactive Frame Rates during Visualization of Complex Virtual\nEnvironments,” Computer Graphics Proceedings, SIGGRAPH 1993: pp.\n247-254.\n\n[Funkhouser96] Funkhouser, Thomas A., “Database Management for Interactive\nDisplay of Large Architectural Models,” Proceedings of Graphics Interface ‘96:\npp. 1-8.\n\n[Hong97] Hong, Lichan, et al., “Virtual Voyage: Interactive Navigation in the\nHuman Colon,” Computer Graphics Proceedings, SIGGRAPH 1997: pp.\n27-34.\n\n[Klosowski00] Klosowski, James T. and Claudio T. Silva, “The Prioritized-Layered\nProjection Algorithm for Visible Set Estimation,” in JEEE Transactions on Visual-\nization and Computer Graphics, April-June 2000, 6(2):108—-123.\n\n[Klosowski01] Klosowski, James T. and Cldudio T. Silva, “Efficient Conservative Vis-\nibility Culling Using the Prioritized-Layered Projection Algorithm,” in JEEE\nTransactions on Visualization and Computer Graphics, October-December 2001,\n7(4):365-379.\n\n[Teller91] Teller, Seth and Carlo H. Séquin, “Visibility Preprocessing for Interactive\nWalkthroughs,” Computer Graphics Proceedings, SIGGRAPH 1991: pp. 61-69.\n\n[Walkthru01] The Walkthru Project at UNC Chapel Hill, “Power Plant Model,”\navailable online at http://www.cs.unc.edu/~geom/Powerplant/.\n\n[Zhang97] Zhang, Hansong, Dinesh Manocha, Thomas Hudson, and Kenneth E.\nHoff III, “Visibility Culling Using Hierarchical Occlusion Maps,” Computer\nGraphics Proceedings, SIGGRAPH 1997: pp. 77-88.",
      "content_length": 3033,
      "extraction_method": "OCR"
    },
    {
      "page_number": 348,
      "chapter": null,
      "content": "4.5\n\nTriangle Strips _\n\nTriangle Strip Creation,\nOptimizations, and Rendering\n\nCarl S. Marshall, Intel Labs\nCarl.S.Marshall@intel.com\n\nn the current age of high-performance consoles, triangle strips have moved to the\n\nforefront of primitive selection when representing and rendering geometry. This\ngem focuses on how to generate triangle strips from arbitrary 3D polygonal models.\nWe will describe and provide source code for developing long triangle strips. After\ndescribing the triangle strip algorithm, we will explain the benefits of triangle strips,\nthe possible pitfalls encountered when creating them, and how to submit them to the\ngraphics API. In addition, several other triangle strip creation algorithms will be\nreviewed and critiqued.\n\nA triangle strip (tri-strip) is a series of connected triangles. The connection of the tri-\nangles allows vertex caching so that graphics cards can reuse the shared edges between\nthe triangles. Figure 4.5.1 shows a simple triangle strip with shared edges V,V3 and\nV3V4. In order for a triangle to be a part of a triangle strip, the triangle must contain\nthe same smoothing group and material group as the other triangles in the tri-strip. A\nsmoothing group is a group of triangles that all have one normal per vertex, and\na material group is a group of triangles that all have the same lighting and texture\nproperties.\n\nBackground\n\nThe technique of using triangle strips has been around for a long time. Before that,\nthe general format for submitting triangles to the API was to explicitly send each ver-\ntex’s position, normal, and color. But because fewer vertices need to be sent for trian-\ngle strips, this gives them a tremendous advantage over a pure triangle graphics API\ncall. Today, vertex indexing has virtually displaced the earlier process and now is the\nprimary method for submitting polygons to a graphics card. [Marselas00] suggests\nthat by using triangle strips and vertex indexing, it is possible to bring the vertex-to-\n\n359",
      "content_length": 1990,
      "extraction_method": "OCR"
    },
    {
      "page_number": 349,
      "chapter": null,
      "content": "360 Section 4 Graphics\n\nV4\n\n(A)\n\nVy V3 V5\n\nVo Counter-Clockwise V4\n\n(B)\n\nVy Clockwise V3 Clockwise Vs\n\nFIGURE 4.5.1 (A).A simple triangle strip with shared edges V,V; and V3V,. (B) The\nordering of the triangles in the tri-strip alternate between clockwise and counterclockwise\nordering.\n\ntriangle ratio close to 1:1 for certain meshes. This gives tri-strips the advantage of data\nreduction.\n\nTriangle strip creation has four goals:\n\n1. To minimize the number of tri-strips\n\n2. To minimize the number of repeated vertices\n3. To minimize the number of isolated triangles\n4, To maximize vertex caching",
      "content_length": 598,
      "extraction_method": "OCR"
    },
    {
      "page_number": 350,
      "chapter": null,
      "content": "4.5 Triangle Strip Creation, Optimizations, and Rendering 361\n\nThese goals often conflict with one another. For example, it is difficult to gener-\nate extremely long tri-strips or cache friendly tri-strips without repeating many ver-\ntices. It is also better to have several isolated triangles (tri-strips of three vertices) than\na few tri-strips of four vertices because you can batch the isolated triangles into an\nindexed vertex list.\n\nBenefits\n\nUsing triangle strips instead of independent triangles will allow for a reduced submis-\nsion of vertices or vertex indices. Depending on how the triangle strips are submitted\nto the graphics hardware, you can receive substantial savings in vertex data, transfor-\nmation, and lighting. Triangle strips can also give you an advantage with vertex\ncaching on the graphics card.\n\nTriangle Strip Creatio\n\nThere are several triangle strip creation algorithms in the research space, but each\nalgorithm has its advantages and disadvantages, due to the fact that finding the opti-\nmal tri-strips is an NP-complete problem. [Evans96a] uses a quad-based mesh to\noptimize tri-strips within patches, whereas [Hoppe99] uses a cache-friendly triangle\nstrip approach. The approach we chose is to optimize the length of the triangle strip\nto overcome the graphics API overhead.\n\nSince it is impossible to have the perfect triangle stripping of a mesh for any situ-\nation, we have:to create algorithms that will find the most optimal tri-strips for the\nspecific implementation. The algorithm that we use aggressively generates tri-strips\nfrom any arbitrary 3D polygonal model. This tri-strip generation algorithm can be\nplaced into any of your favorite 3D authoring tools, or it can be run as a stand-alone\ntool. The goal is to generate long tri-strips and then write them out into a format that\nis easily rendered. Color Plate 5 shows a sample image of two models after the trian-\ngle strip algorithm has been run on the mesh.\n\nDefinitions\n\nBefore we go into our creation algorithm, it will help to define a few terms. An active\nedge is the edge of a triangle within the strip onto which new triangles can be added.\nThe active edge is between the second and third vertices of the last triangle to be\nadded to the triangle strip. The bold edge in Figure 4.5.2a shows the active edge, DE,\nin which the triangle with vertex F can be added. A swap is used when the active edge\ndoes not align with the neighboring triangle to be added to the strip. Figure 4.5.2b\nshows a case in which the active edge is DE, but the next triangle to be added is on\nedge CE. To add the new triangle, vertex C will have to be repeated and then swapped\nwith vertex E. This will keep the proper clockwise, counterclockwise ordering. The\nlast term we will define is called a flip, which is when two duplicate vertices have to be\nadded and swapped to add a new vertex, as shown in Figure 4.5.2c.",
      "content_length": 2898,
      "extraction_method": "OCR"
    },
    {
      "page_number": 351,
      "chapter": null,
      "content": "362 Section 4 Graphics\n\n(A)\n\n(B)\n\n(C) ‘S\n\nA\n\nFIGURE 4.5.2 The various stages in which triangles can be added to a triangle strip.\n\n(A) A tri-strip with a vertex index ordering of ABCDE and an active edge DE. Since the\nactive edge borders the new triangle, F can just be added to the end of the tri-strip. The\nnew tri-strip is ABCDEE (B) Tri-strip ABCDE with active edge DE. To include vertex\nE Cwill have to be duplicated and then swapped with E, since the active edge does not\nborder the new triangle to be added. The new tri-strip is ABCDCEE (C) A case where\nreordering the first face of a triangle strip to match the second face is crucial to minimize\nrepeated vertices. If the triangle strip started as CAB, then B and C would have to be\nrepeated to add vertex D. CABBCD is the new triangle strip. If the active edge is facing\naway from the second triangle, then two vertices have to be repeated.",
      "content_length": 900,
      "extraction_method": "OCR"
    },
    {
      "page_number": 352,
      "chapter": null,
      "content": "4.5 Triangle Strip Creation, Optimizations, and Rendering 363\n\nThe preprocess stage is used to create metrics for generating quality triangle strips.\n\n1. Find a triangle with the smallest area, which we will call the origin triangle.\nTo avoid poor triangle stripping, you might want to get the 10 smallest-area\ntriangles in the mesh and select between those triangles for the origin\ntriangle.\n\n2. Select a vertex of the origin triangle or create its centroid, which will be the\nstarting point for the triangle strip algorithm.\n\n3. Create a centroid for each triangle. This can be easily done by averaging the\nthree vertices of each triangle (see Equation 4.5.1). C is the centroid posi-\ntion, and V,, V;, and V3 are the vertex positions of the triangle.\n\n4, For each triangle, calculate and store the Euclidean distance between the\nstarting vertex and the centroid.\n\nC=(V,+V,+V,)/3.0 (4.5.1)\n\nCreation Algorithm\n\nOnce we have the preprocess stage complete, we can start generating triangle strips.\nEach time a triangle of the mesh is added to a tri-strip, mark the triangle invalid.\n\n1. Select a valid triangle. This triangle will be the first triangle of the triangle\nstrip.\n\n2. If the triangle has neighbors, select the triangle with the smallest distance\nvalue, and make it the current triangle. Otherwise, end the triangle strip\nand go to Step 6.\n\n3. Reorient the first triangle so that its active edge matches the second triangle.\nThe edge between the second and third vertices should match the neigh-\nboring triangle.\n\n4. Get the neighbor of the current triangle by finding the triangle with the\nsmallest distance value, which was stored in preprocess Step 4. If the trian-\ngle does not align with the active edge, then a vertex will have to be repeated\nwith a swap in order to continue creating the triangle strip (see Figure\n4.5.2c).\n\n. Go to Step 2.\n\n6. Check to see if any remaining triangles are not included in a tri-strip. If so,\n\ngo to Step 1.\n\nWr\n\nThe high-level pseudo-code for running the tri-strip algorithm is show in Listing\n4.5.1.",
      "content_length": 2051,
      "extraction_method": "OCR"
    },
    {
      "page_number": 353,
      "chapter": null,
      "content": "364 Section 4 Graphics\n\nLISTING 4.5.1 High-level pseudo-code for running the tri-strip algorithm.\n\nvoid main( )\n\n{\nMesh *pMesh;\n\nLoadMesh(pMesh); // Load 3D polygonal mesh\noriginTriangle = FindSmallestAreaTriangle() ;\nCalculateCentroidForEachTriangle() ;\n\n// Get Euclidean distance from centroid of\n// the origin triangle to the current\n\n// triangle origin\nCalculateDistanceFromToEachTriangle(\nOriginTriangle) ;\n\n// Generate the triangle strips\nTriStripGeneration(pMesh) ;\n\n// Run a second pass filter to see if any of\n\n// the previous triangle strips can be connected\nConnectTriangleStrips() ;\n\nConvertTriStrips(); //Use custom data structure\n\n}\n\nOnce the creation algorithm is finished, the output will be N triangle strips. Each\nof these triangle strips will belong in one smoothing group and have the same mater-\nial ID. Once the tri-strips are stored in memory, you can customize the data into any\nformat that is required by your game I/O.\n\nConnecting Triangle Strips\n\nAs a second pass, the triangle strips can be analyzed to see if there are any points at\nwhich they can be connected to each other. The analysis starts by finding all of the\nstarting edges and ending edges of each triangle strip along with the face index\nattached to each edge. Then, the starting and ending edges are compared with those\nof all of the other triangle strips to see if a match occurs. Once a match is found, the\ntwo triangle strips are analyzed to see which stage they fall into (from Figure 4.5.2).\nMost cases will require some number of vertex repetitions to merge the triangle strips.\nOne of the simpler cases is when an isolated triangle is matched with another triangle\nstrip. In most cases, the isolated triangle’s vertices can be reordered to conform to the\nmatching triangle strip.\n\nOptimizations\n\nseat RR NRE RS\n\nSince the goal of developing triangle strips is to increase performance, optimizations\nare a key part of any triangle strip generation algorithm. Optimizations can be placed\ninto several areas of the triangle strip development process: preprocess, generation,\nand runtime.",
      "content_length": 2082,
      "extraction_method": "OCR"
    },
    {
      "page_number": 354,
      "chapter": null,
      "content": "4.5 Triangle Strip Creation, Optimizations, and Rendering 365\n\nPreprocess:\n\n* Create meshes with only a few smoothing groups (more than one normal per\nvertex).\n\n* Limit the number of material groups per model.\n\n* Optimize the model so that polygonal faces do not swap back and forth between\nmaterial groups or smoothing groups. This will limit the length of a triangle strip.\n\n¢ Sort triangle strips via material groups before submitting them to the graphics\ncard.\n\n¢ Eliminate all dummy faces. A dummy face is when two or more of the three ver-\ntex locations are equivalent. This can cause the triangle strip to flip inside out and\npossibly get culled when rendered.\n\nGeneration:\n\n* Batch isolated triangles into a single, indexed buffer.\n\n¢ Try to merge triangle strips that have neighboring beginning or ending triangles,\nwhere possible.\n\n¢ Know the cache size of the hardware, and optimize as appropriate.\n\nRuntime:\n\n© Use an indexed array API call instead of a pure ordered vertex submission call.\n* Reduce state swapping and dynamic texture coordinate changes.\n\nRendering\n\nMost graphics APIs have support for rendering triangle strips. There are usually a cou-\nple of formats you can choose from when submitting triangle strips to the graphics\ncard. One format requires sending the vertex data for each vertex in the triangle strip.\nThis is very expensive, since many vertices will be duplicated due to shared edges by\nmultiple triangle strips. Another format requires submitting the triangle strips via an\nindexed format. An indexed format is one in which you submit a vertex pool, and the\ntriangle strip vertex indices into the vertex pool. One issue with most graphics APIs is\nthat they only allow one triangle strip submission per API call. In some APIs, you can\nsubmit dummy vertices to allow the submission of multiple triangle strips. [Nei-\nder99] and [Microsoft00] both list the API submission calls for triangle strips.\nOpenGL uses the primitive type GL_TRIANGLE_STRIP, and Microsoft Direct3D uses\nD3DPT_TRIANGLESTRIP.\n\nCache-Friendly Triangle Strips\n\nAnother triangle strip creation algorithm creates triangle strips that are cache friendly\nby minimizing vertex cache misses [Hoppe99]. [Nvidia00] uses a vertex-caching\nscheme that will run as a post-process on previously created triangle strips in order to\noptimize cache usage. The advantage to this approach is that you can optimize trian-",
      "content_length": 2408,
      "extraction_method": "OCR"
    },
    {
      "page_number": 355,
      "chapter": null,
      "content": "366 Section 4 Graphics\n\ngle strips to a specific graphics card. Of course, the drawback with this routine is that\nthe optimizations can hinder you if the same content is used on another graphics card\nwith a different cache size.\n\nAs soon as a vertex or face is removed from the mesh, it can have a dramatic effect on\nthe triangle strips that were created at the higher resolution by breaking them up and\ncreating invalid faces. There are a couple of ways to solve this problem. The first\nwould be to create a set of triangle strips for every resolution of the model. This is\nextremely impractical and would balloon your memory usage. The second choice\nwould be to create the triangle strips on the fly and store them in memory until the\nresolution changes. We chose the second method, only allowing triangles to be added\nto a triangle strip that neighbored its current active edge or required a swap. If no\nneighbors existed, then the triangle strip would be ended. The key here is to optimize\nthe data structures for fast neighbor lookup and traversal. The advantage is the ability\nto use triangle strips with dynamic geometry; however, this will require additional\noverhead in memory.\n\nyou consider rendering primitives for your geometry, triangle strips can help provide a\nbeneficial speed-up compared with submitting simple triangle lists. We encourage you\nto test your geometry with triangle strips and compare the differences for yourself.\n\n[Evans96a] Evans, Francine, Steven Skiena, and Amitabh Varshney, “Optimizing Tri-\nangle Strips for Fast Rendering,” Visualization 96 Proceedings, IEEE, 1996: pp.\n319-326\n\n[Evans96b] Evans, Francine, Steven Skiena, and Amitabh Varshney, “Completing\nSequential Triangulations Is Hard,” Technical Report, Department of Computer\nScience, State University of New York at Stony Brook, 1996.\n\n[Hoppe99] Hoppe, Hughes, “Optimization of Mesh Locality for Transparent Vertex\nCaching,” Computer Graphics Proceedings, SIGGRAPH 1999: pp. 269-276.\n\n[Isenburg00] Isenburg, Martin, “Triangle Strip Compression,” Graphics Interface, pp.\n197-204, 2000.\n\n[Marselas00] Marselas, Herb, “Optimizing Vertex Submission for OpenGL,” Game\nProgramming Gems, Charles River Media, Inc., 2000.\n\n[Microsoft00] Microsoft DirectX 8.0 Software Development Kit, available online at\nhttp://www.msdn.microsoft.com/downloads, 2000.\n\n[Neider99] Neider, Jackie, et al., OpenGL Programming Guide, Version 1.2, Addison\nWesley, 1999.\n\n[Nvidia00] Nvidia NvTriStrip v1.1., available online at http://developer.nvidia.com/\nview.asp*lO=nvtristrip_v1_1, 2000.",
      "content_length": 2558,
      "extraction_method": "OCR"
    },
    {
      "page_number": 356,
      "chapter": null,
      "content": "4.6\n\nComputing Optimized\nShadow Volumes for\nComplex Data Sets\n\nAlex Viachos and Drew Card,\n\nATI Research\nAlex@Viachos.com and DCard@ati.com\n\nA s graphics hardware performance increases, shadow volumes become a more rel-\nevant topic for the game industry. In this gem, we describe a method for com-\nputing the exact front cap geometry visible from a given static light source. This is the\nexact geometry that is visible from the light’s point of view, and it is useful for calcu-\nlating shadow volumes. Previous work has been done on this topic; however, most\nmethods suffer from either infinite recursion (with complex polygonal models) or fail\nto solve for cyclically overlapping polygons. The method presented here also works\nfor scenes that have intersecting polygons.\n\nPrevious Work\n\nThe Weiler-Atherton algorithm {Weiler77] provides an interesting method for com-\nputing front cap geometry. The advantage of its method is that it does not require a\nperfectly sorted list of polygons with respect to the light source. Additionally, the\nWeiler-Atherton algorithm solves for cyclically overlapping polygons. However, when\nusing even a slightly complex scene, this method lends itself to infinite recursion due\nto precision errors when using 64-bit, floating-point variables. The method presented.\nin this gem borrows some of the basic methods from the Weiler-Atherton algorithm,\nbut it approaches the problem from a different direction.\n\nsource are somewhat complex. Starting with all the front-facing polygons that lie in\nthe light frustum, roughly sort them back-to-front. A simple quick-sort based on each\npolygon’s closest vertex will suffice. At this point, you want to assign each polygon a\nunique ID for later reference. You might also want to store these polygons into bins to\n\n367",
      "content_length": 1791,
      "extraction_method": "OCR"
    },
    {
      "page_number": 357,
      "chapter": null,
      "content": "Section 4 Graphics\n\npe sree 22 A A NT HHT TH HHH na eR aE EEN\n\nenable quicker searching. We call these polygons the “input array.” We also need an\n“output array,” which will be initialized as empty.\n\nNow we perform a series of operations on each of the polygons in the input array.\nFirst, create a beam (a small frustum) from the light source and the polygon. Three of\nthe four clip planes that make up the beam are simply the planes defined by the light\nposition and each edge of the polygon. The fourth clip plane is the plane of the poly-\ngon itself. All of the geometry that we have stored so far in our output array that falls\ninside the beam’s frustum is discarded. The remaining fragments are stored back into\nthe output array (see Figure 4.6.1).\n\nSince it is sometimes impossible to perfectly sort polygons (as with cyclically\noverlapping polygons), there may be polygons remaining in the output array that\nobscure the currently selected polygon from the light’s viewpoint. To account for this\ncase, we recurse one level deep for each of the obscuring polygons. A temporary array\nis created with just the current input polygon, and it is clipped using the beams of\neach obscuring polygon. The remaining polygons (in the temporary array) are copied\nto the output array. If there are no obscuring polygons, we simply add the input poly-\ngon to the output array (see Figure 4.6.2).\n\nAfter processing each input polygon, we need to run an optimization algorithm\non the output polygon array to reduce the amount of polygon splitting. This algo-\nrithm is explained in the following section. Note that this step needs to occur at each\niteration of the main loop.\n\nAfter looping through all the input polygons, solve for T-junctions in the final out-\nput array to prevent rasterization artifacts. At this point, the clean front caps have been\ncreated, and the shadow volume can now be easily generated. Since the front caps do\nnot overlap from the light’s point of view, a copy of the final front cap geometry can be\nprojected onto the far plane of a spotlight frustum to generate the back cap. Point\nlights can be split into eight subregions to facilitate the creation of the volume.\n\nFIGURE 4.6.1 Ax illustration of beam construction and output polygon culling. The\ndark gray polygon is the currently selected one, and the white polygons are in the output\narray. A beam is created from the light point (in this case the eye-point) and the selected\npolygon. The output polygons are then clipped against this beam.",
      "content_length": 2514,
      "extraction_method": "OCR"
    },
    {
      "page_number": 358,
      "chapter": null,
      "content": "4.6 Computing Optimized Shadow Volumes for Complex Data Sets 369\n\nOriginal if Recursive xt Unobstructed\n\\ Front Cap\n\nBeam \\ Beam\n1 \\\n- i\nLe 1 \\\n- isti Pe G6,\nNia Vw, s me\nN \\ ‘\\ a a\n\\ 1 \\\n\\ .\nPolygon ¢\\ \\ Recursive\n\\ | ‘> Bean\n‘ \\ Frusum\nBeam ‘\\\n\nFrustum\n\n(B) (C)\n\nFIGURE 4.6.2 Dealing with obstructing output polygons. Shown from a top\n(orthographic) view. (A) The light beam is illustrated by the dotted lines surrounding the\n(black) beam polygon. (B) The light-gray polygon, which is in the output array, is clipped\nby the original beam frustum from (A). Since a portion of the clipped polygon obstructs\nthe currently selected (black) polygon, a recursive step is taken to create a beam frustum\nwith the clipped portion, and the original (black) polygon is clipped against it. (C) The\nresult is the exact front cap geometry.\n\nOptimization Al orithm —\n\nAs previously mentioned, an optimization algorithm is required in order to avoid\nnumerical inaccuracies and improve performance. In many cases, the repetitive clip-\nping to beam frustums can create excessive numbers of sliver polygons. To help avoid\nthis, all subpolygons created from an original input polygon are collapsed into the\nsmallest number of polygons possible at each pass through the loop.\n\nThe input stream should also be optimized before the main loop. This will make\nit unnecessary to optimize across the original polygon boundaries at every iteration.\nOptimizing in groups based on the original input polygons does everything that is\nrequired.\n\nThere are two algorithms that can be utilized to optimize the polygonal mesh.\nThese algorithms, which we will outline here, provide a method for determining\nwhich vertex should be removed or which edge collapsed. The remaining n-gon will\nthen need to be retessellated into triangles using a robust tessellation algorithm such\n\nas that in [deBerg00].\n\nVertex Removal\n\nAn example of removing a vertex is illustrated in Figure 4.6.3. The first step is to build\na mesh from all of the triangles that correspond to an original input triangle (by the\ntriangle ID). Next, build an edge table for all of the edges in this mesh. For each ver-",
      "content_length": 2149,
      "extraction_method": "OCR"
    },
    {
      "page_number": 359,
      "chapter": null,
      "content": "370 a 7 Section 4 Graphics\n\ntarget\nvertex\n\nFIGURE 4.6.3 Removing a vertex.\n\ntex in the mesh, choose a starting triangle that contains that vertex, and use the edge\ntable to walk clockwise around the vertex to neighboring triangles that also contain\nthat vertex. Continue to walk around the vertex until no more triangles exist in the\nchain or until the original triangle is reached. If the walk around the vertex is success-\nful (i.e., a full walk back to the original triangle is completed), then the vertex can be\n\nremoved.\n\nEdge Collapse\n\nAn example of collapsing an edge is illustrated in Figure 4.6.4. Similar to the vertex-\nremoval algorithm, the first step is to build a mesh from all of the triangles that corre-\nspond to an original input triangle. Now, build an edge table for all of the edges in the\nmesh. For each vertex in the mesh, choose a starting triangle, which contains the ver-\ntex, and use the edge table to walk clockwise around the vertex to neighboring trian-\ngles that also contain the vertex. Compare the current triangle’s leading edge with the\noriginal edge for collinearity, using a cylinder test (or sum up the angles of the trian-\ngles and test for equality with 180°). If the two edges are found to be collinear, col-\nlapse the edge by combining the two adjacent edges into a single edge and removing\nthe shared vertex.\n\nNote that keeping track of the original edges of the input triangles might also\nreduce the computation time for the edge collapse. This method allows for the com-\nparison of the edge IDs while also reducing possible error due to floating-point\ninaccuracies.",
      "content_length": 1610,
      "extraction_method": "OCR"
    },
    {
      "page_number": 360,
      "chapter": null,
      "content": "4.6 Computing Optimized Shadow Volumes for Complex Data Sets 371\n\nBefore\n\nshared vertex\n\nFIGURE 4.6.4 Collapsing an edge by removing a shared vertex.\n\nFor an example of precomputed shadow volumes combined with other rendering\ntechniques in real-time, see Color Plate 6.\n\ntion,” Computational Geometry Algorithms and Applications, Second Edition,\n2000: pp. 45-61.\n\n[Weiler77] Weiler, K. and P. Atherton, “Hidden Surface Removal Using Polygon Area\nSorting,” Computer Graphics, SIGGRAPH, 1977: Vol. 11, pp. 214-222.",
      "content_length": 512,
      "extraction_method": "OCR"
    },
    {
      "page_number": 361,
      "chapter": null,
      "content": "4.7\n\nSubdivision Surfaces for\nCharacter Animation\n\nWilliam Leeson, Trinity College, Dublin\n\nwleeson@indigo.ie\n\nonstructing surfaces through subdivision has become popular with high-end ren-\n\ndering packages over the past few years. This is due in no small part to the stun-\nning visuals produced by companies such as Pixar [DeRose98]. These schemes solve\nmany of the problems associated with other curved-surface techniques, such as\nNURBS surfaces. Since they behave in a way similar to polygonal meshes, there are\nfewer restrictions. Character skins can be used almost directly with some subdivision\nschemes. Others require some modification in order to get a good representation of\nthe original mesh.\n\nThis gem introduces subdivision surfaces as a means of improving the appearance\nof game characters. First, we will present the different schemes available, focusing on\ntwo implementations of subdivision surfaces. Then, we will explore a number of opti-\nmization methods based on culling and preprocessing.\n\nSubdivision Schemes\n\n372\n\nThere are two main types of subdivision surfaces [Kobbelt98], namely approximating\nand interpolating schemes. The three most important properties of subdivision sur-\nfaces, as relates to this gem, are:\n\n° Efficiency\n¢ Affine invariance (i.e., transformation of the control points transforms the surface)\n* Continuity (i.e., they can produce smooth surfaces)\n\nSubdivision schemes use a mask to define a set of vertices and corresponding\nweights. There are two types of masks for each scheme: the odd mask and the even\nmask. Odd masks are used to produce new vertices, while even masks are used to\nrefine old vertices for the newly produced mesh. These two types can be further\ndivided into edge, crease, and normal masks. Additionally, in order to be able to rep-\nresent sharp features, special crease masks must be created. For triangular schemes,\nvertices with a valency (number of connected vertices) of six are known as ordinary\nvertices. The others are called extraordinary. The masks are applied to each vertex in",
      "content_length": 2055,
      "extraction_method": "OCR"
    },
    {
      "page_number": 362,
      "chapter": null,
      "content": "4.7 Subdivision Surfaces for Character Animation 373\n\nFIGURE 4.7.2 Butterfly interpolating subdivision surface for four iterations.\n\nthe mesh to produce a new mesh. After successive applications of the mask, the mesh\nconverges to a surface (see Figures 4.7.1 and 4.7.2). The masks can also be applied to\nthe texture coordinates in exactly the same manner. This generates the texture coordi-\nnates for each vertex. Generally, approximating schemes are faster because they have\nfewer constraints imposed on them, as they do not have to interpolate the control\npoints. However, when dealing with edges and noncontinuous surfaces, special masks\n(which take these circumstances into account) must be applied.\n\nApproximating Schemes—Loop Subdivision\n\nLoop subdivision [Loop87] is perhaps the simplest subdivision scheme. It has a very\nsmall support area. The mask for this scheme is given by Equation 4.7.1 (see Figure\n\n4.7.3).\n1 3\ng (* + v») + a? + 7) even\n»y Qu, + (1 = nQ)y; odd\njr\nwhere\n3n\n2 — n>3\na=+)/2- 3d oo 2% orQ=48\nn{8 \\8 4 n 3\n— rza= 3\n16",
      "content_length": 1044,
      "extraction_method": "OCR"
    },
    {
      "page_number": 363,
      "chapter": null,
      "content": "374\n\nSection 4 Graphics\n\nvy\n\nv\nv4 . y v2 ‘\nv3\n\nFIGURE 4.7.3 Loop subdivision mask.\n\nA convenient feature of the Loop scheme is that the tangent vectors can be com-\nputed for each point using\n\n—1 °\n\nx 2ni\n= by cos — v;\n5 n\n7=0\n\n(4.7.2)\n\n-] .\na,\n= by sin — »,\n#=0 n\nwhere »; is one of the 7 vertices that is connected to the vertex we are trying to find a\nnormal for. Note that different masks are needed for computing the tangents at a\nboundary edge [DeRose98]. Although sin and cos are expensive to compute,\noptimizations (which will be described later) can be used to remove them from the\ncomputation.\n\nInterpolating Schemes—Modified Butterfly\n\nThe butterfly scheme got its name from the distinctive shape of its mask, which\nresembles that of a butterfly. The original butterfly [Dyn90] method is probably the\nmost common interpolating scheme used, but it does not guarantee a continuous sur-\nface for arbitrary meshes. For a small amount of extra work, a modified scheme\n[Zorin96] can be used. Fortunately, it has the same small support area as the original\nscheme. Like most interpolating schemes, there is no even mask. The original vertices",
      "content_length": 1145,
      "extraction_method": "OCR"
    },
    {
      "page_number": 364,
      "chapter": null,
      "content": "4.7 Subdivision Surfaces for Character Animation\n\n05 % v7\n\nFIGURE 4.7.4 Butterfly subdivision mask.\n\nare reused, since the surface must pass through them. An example mask is shown in\n\nFigure 4.7.4.\n\nv; even\n\n(4.7.3)\n\nv,=4 1 1 1\n\n-=( + vu, + U6 + v3) + gl + v,) +5 (% + v5) odd\n\nUnlike the Loop method, computing the tangent vectors can be quite involved. It\n\nis probably quicker to compute them from the faces, so that information will not be\ncovered in this gem.\n\nHierarchical Half-Edge Mesh\n\nOne of the most difficult aspects of using a subdivision scheme is creating a suitable\ndata structure [Weiler85] for traversing the nodes so that the subdivision rules can be\napplied. A half-edge data structure can be created for each level of subdivision. The",
      "content_length": 754,
      "extraction_method": "OCR"
    },
    {
      "page_number": 365,
      "chapter": null,
      "content": "376\n\nSection 4 Graphics\n\nores ennui nO oer InegeAAeR NI: sAlaAnUEMESH IRR RUSSO necivemmuceeeenniiromaioninas\n\nhalf-edge data structure uses a vertex, an edge, and a face structure to make up the\n\nmesh:\n\nstruct vertex\n\n{\nedge *p_edge;\n\nstruct edge\n\n{\nedge *p_ pair;\nedge *p_next;\nedge *p_prev;\nface *p_face;\nvertex *p_ vertex;\n}3\nstruct face\n{\nedge *p_edge;\n}\n\n/*\n\n/*\n/*\n/*\n/*\n/*\n\n/*\n\nedge vertex starts */\n\nother half of edge */\n\nnext edge in face */\nprevious edge in face */\nface edge is part of */\nvertex that starts edge */\n\nan edge in the face */\n\nThis data structure is similar to a winged-edge data structure. A half edge is an\nedge that is split between two neighboring faces. Each edge points to its next and pre-\nvious edges. (Actually, the original half-edge data structure did not have a pointer to a\npreceeding edge, but it makes some queries easier.) It also references the face it is part\nof, as well as the vertex starting the edge (see the previous code). Each edge need only\npoint to one vertex. Each vertex points to the edge it starts, and each face points to\n\none of the edges that make up the face (see Figure 4.7.5).\n\nFIGURE 4.7.5 Half-edge mesh.",
      "content_length": 1169,
      "extraction_method": "OCR"
    },
    {
      "page_number": 366,
      "chapter": null,
      "content": "4.7 Subdivision Surfaces for Character Animation\n\n377\nThis arrangement allows for easy querying of neighboring faces and connected ver-\ntices. For example, to determine all the vertices connected to a given vertex, simply go to\nthe half edge associated with that vertex. Then, move to that half edge’s pair edge—this\nhalf edge references the first connected vertex. If this is repeated until we return to the\ninitial edge, then all connected vertices will have been found (see Figure 4.7.6).\n\nKASS\nNg\n\nFIGURE 4.7.6 Connection traversal order for finding connected vertices to vp.\n\nEven if the half-edge data structure is not used directly within the sub-\ndivision computation, it is a fast and convenient way to determine the rele-\nvant indices for the masks. The half-edge data structure is also perfect for\nexamining other properties of the mesh, such as connectivity and error\ndetection (e.g., more than two faces sharing an edge). In order to store the\nhierarchical information, each face can also store pointers to its siblings.\nAlternatively, each sibling can be stored at an address in an array kn + 7+ 1,\nwhere 7 is the sibling's number 0...(4-1), is the parent’s offset, and & the\nnumber of siblings. An important aspect of this structure is that it cannot\nhave an edge shared between more than two faces without undergoing\nmodification. This can cause trouble if there is no checking done when a\nmesh is loaded (don’t say you weren't warned). In any event, the two\nschemes presented here do not have masks to cater for this situation.",
      "content_length": 1544,
      "extraction_method": "OCR"
    },
    {
      "page_number": 367,
      "chapter": null,
      "content": "378 Section 4 Graphics\n\nreso eaten OT EG eo teaetcecnenE H HEE OEE b li een rorteeacevannett\n\nWhen animating a character, a bone hierarchy is often needed. Implementing a bone\nhierarchy is a trivial task, so we won't go into much detail here. The bone hierarchy is\na simple transformation hierarchy where a series of transformations are applied to the\nnodes. As the hierarchy is descended, each node and its vertices are transformed by\nthe current transformation. Fortunately, when using subdivision surfaces for character\nanimation, we only need to transform the control points of the mesh to alter\nthe shape of the skin. This is advantageous, since fewer transformations will be per-\nformed.\n\nWeighted Vertex-Accumulation Buffer\n\nVertex weighting introduces complications to the task of transforming the vertices. To\nimplement skinning, a buffer is used to accumulate the resulting vertices. This is then\nused as the vertex buffer for the subdivision scheme. As the hierarchy is descended,\neach node is transformed by the current transformation matrix, multiplied by its\nweight, and then added to the accumulation buffer. With this method, the initial sub-\ndivision mesh is not altered by the skinning procedure. Now the subdivision mesh\ncan be altered at will, preventing the accumulation of floating-point errors. As an\nadded advantage, the subdivision surface and skinning procedures are now separated\nand will not interfere with each other, making the implementation easier.\n\nOptimizations\n\nWhen using many subdivision surfaces together, it is important to reduce the overall\nworkload this causes. We will describe four schemes that can be used to reduce the\npotential workload in two distinct places in the subdivision hierarchy.\n\nHierarchical Back-Face Culling\n\nThe technique of hierarchical back-face culling is based on the clustering idea of hier-\narchical visibility culling [Kumar96], where faces are grouped together. Since we are\nusing subdivision surfaces, we know that child faces have similar properties to their\nparents. Therefore, if their parents and neighbors all face away from the view, then so\ndo the children. This technique is very effective, especially when high polygon counts\nare involved. It is also used to reduce the number of subdivision faces that need to be\nprocessed, since we avoid the subdivision of hidden surfaces. A more thorough inves-\ntigation of this technique was presented in a SIGGRAPH sketch by Carlo Séquin\n[Séquin01].\n\nView-Frustum Culling\n\nAnother optimization method is lazy spatial subdivision, which uses the subdivision\nhierarchy to skip processing subsurfaces. This method involves using either a k-d",
      "content_length": 2657,
      "extraction_method": "OCR"
    },
    {
      "page_number": 368,
      "chapter": null,
      "content": "379\n\n(BSP) tree or an octree to separate faces into visible, hidden, or partially visible status\nwith respect to the view frustum. Thus, if the viewer is looking at the characters’ faces,\nthe subdivision is only performed on those faces. This is very important if an opti-\nmum frame rate is desired.\n\nEach subdivision mesh is contained in a bounding box. If the whole bounding\nbox is visible, then it is drawn. Otherwise, the box is split into another four boxes,\nwhose visibilities are then determined. This continues until either the maximum\ndepth is reached or the minimum number of faces is reached. Determining these con-\nditions is crucial to optimizing this algorithm and depends on the rendering method\nor graphics card used. One of the problems with this technique is that some polygons\nmight occupy more than one bounding box. This would cause those polygons to be\ndrawn or tested against the frustum multiple times. To stop this from happening,\neach face is tagged with the frame number each time its visibility is determined. Then,\nwhen processing other nodes, faces that are tagged can be left out, thereby reducing\nthe number of faces that have to be tested against the frustum. By using this test, we\ncan cull out faces where subdivision is unnecessary and only subdivide those that are\nin the frustum. For small meshes, it is preferable to use the view frustum directly for\nculling visible faces.\n\nFIGURE 4.7.7 Lazy frustum cull using BSP tree.",
      "content_length": 1460,
      "extraction_method": "OCR"
    },
    {
      "page_number": 369,
      "chapter": null,
      "content": "380\n\n; Section 4 Graphics\n\nThe two previous approaches are used to mark faces that are deemed either visible\nor invisible. This data is then used to reduce the number of child faces produced by\nsubdivision or to cull out any faces before they are sent down the rendering pipeline.\n\nThe next two optimizations are methods that precompute data in order to reduce\nthe cost of traversing the half-edge data structure. These techniques, unfortunately,\ncan significantly increase the amount of memory required, but they do substantially\nspeed up the display and generation of subdivision surfaces.\n\nPrecomputed Face Vertex Indices\n\nPrecomputation of the face vertex indices is very useful when it comes time to display\na face in the subdivision surface. This is an index array and needs to be done only\nonce for the surface. The idea is to store the indices of the vertices that make up the\nfaces prior to using the subdivision surface. Thus, they do not have to be computed\neach time the surface is going to be rendered. This is then used as part of a vertex\narray. The face index array looks like:\n\n{(2, »Vyy> v3), Lees (2, Uy Vn, )} (4.7.4)\n\nPrecomputed Weights and Vertex Indices\n\nPrecomputation of the weights and vertex indices is used for the generation of even\nvertices and also for the refinement of odd vertices, making traversal of the half-edge\nmesh unnecessary. Basically, a set of weights (w;) and indices (v,) for each vertex (2) in\nthe mask are computed and stored with the destination index (v,) of the resulting ver-\ntex. Thus, a simple for loop is all that is necessary to generate the next set of vertices.\nThis scheme can also be used to compute the tangent vectors for the Loop and but-\nterfly schemes, avoiding the use of sin and cos. The method differs slightly for each\nsubdivision scheme. The butterfly scheme requires less memory, as it has a fixed num-\nber of vertices for each mask. Thus, eight vertex indices and weights are stored, as well\nas the destination index for the resulting vertex. The butterfly weight-and-index array\nlooks like:\n\nnx {(205%0)s--+(ve»w5),2} (4.7.5)\n\nThe Loop scheme is a bit more complicated. The even masks do not have a fixed\nnumber of vertices from which the resulting vertices are generated. Thus, to store\nthese, we have to add an extra field that identifies how many vertices are stored. For-\ntunately, the odd masks have a fixed number and can be stored in a similar manner to\nthe butterfly scheme, but with only four indices and weights. A Loop odd and even\nweight-and-index array looks like:\n\n((+0,w)s-+-(v4s04),24) odd\n\n(é, (v>@o)s++- (414) 74} even (4.7.6)\n\nnx",
      "content_length": 2622,
      "extraction_method": "OCR"
    },
    {
      "page_number": 370,
      "chapter": null,
      "content": "4.7 Subdivision Surfaces for Character Animation — 381\n\nThe storage costs can be further reduced. If the vertices are always stored in the\nsame order, then weights are the same for the odd masks. Therefore, they do not need\nto be stored. To use the arrays, the program simply runs through the sets, multiplying\nthe vertex by its weight and adding that result to the total for the vertex.\n\nPutting It All Together\n\naa\n\nAARC\n\nThe implementation of the subdivision schemes i is pretty y straightforward. In this\nimplementation, a multiple pass approach is adopted, where a new level of the mesh\nis generated on each pass. This method makes the code fairly simple and enables the\noptimizations to be performed on each pass, if necessary. For each pass, the vertices\nare stored in a single array, whose size grows to accommodate the number of vertices\nneeded. On the final pass, the vertices and faces are dumped into a geometry array,\nwhich is then sent down the rest of the rendering pipeline.\n\nStoring the Data\n\nArrays are used to store the data for subdivision surfaces. This is for speed reasons as\nwell as for ease of management. It is also relatively easy to pass the arrays directly to\nthe graphics API in the form of vertex arrays. Arrays are far easier to manage, since\nonly one big allocation is ever needed. Then, if the space is too small, we can reallo-\ncate more memory. This way, only the first few frames are slow (until sufficient mem-\nory has been allocated). Arrays tend to use less memory because pointers do not need\nto be stored for simple hierarchical and linear storage schemes. Since the memory is\nallocated as a single chunk, it caches much better and, therefore, is accessed faster.\nAnother significant advantage of the array-based approach is that when using the\naccumulation buffer for skinning, the face indices and other reference data need not\nbe regenerated. This is because each vertex generated is stored at the same relative\nlocation in the array.\n\nRemoving What Is Not Seen\n\nThe visibility culling is only performed on the original mesh to save time, since it is an\nexpensive option. While determining the visible faces is relatively easy, deciding\nwhich faces are needed to produce child faces is a bit harder. In order to do this, we\nneed to know in advance how many levels of subdivision are required. This is because\nthe support areas required by the subdivision schemes overlap, producing a depen-\ndence hierarchy (see Figure 4.7.8). The more levels of subdivision required, the larger\nthe support area must be. An alternative to explicitly determining these regions is to\nuse a lazy evaluation method that generates faces as they are needed. Unfortunately,\nthese methods prove to be slower, as the memory accesses are fragmented.\n\nLuckily, the support areas for the butterfly scheme and Loop scheme are very sim-\nilar, with the butterfly being marginally smaller (see Figure 4.7.8). This allows us to\n\nuse the same methods to determine the extra faces needed in addition to those that are",
      "content_length": 3027,
      "extraction_method": "OCR"
    },
    {
      "page_number": 371,
      "chapter": null,
      "content": "382 Section 4 Graphics\n\nchisierohe etl eReteiinr inNee NH ineeeaHatoceeeceaitseueee a mbna or\n\nFIGURE 4.7.8 Support areas required by Loop and butterfly subdivision schemes.\n\nvisible for a given subdivision level. It also highlights the fact that for a mesh with rel-\natively few nodes, such as a cube made with triangles, the child node can be quite\ndependent on the rest of the mesh.\n\nRendering the Frame\n\nTo render the surfaces, a list of triangles, vertices, normals, and texture coordinates are\nput into a vertex array and then rendered. A simple API separates the rendering API\nfrom the rest of the code. This allows more-complex operations and rearrangement of\nthe scene to facilitate faster rendering by minimizing state changes.\n\nSource Code\n\n‘ee tance NR HR RA TE\n\nA sample program is available on the CD-ROM.\n\nON THE CD\n\nConclusion\n\n\"Sn nae trata NSB STR SBR AS RA AN NNSA TN 8 one\n\nSubdivision surfaces can be used to create very detailed characters with natural forms.\nThe same formulas can also be applied to the texture parameters to generate proper\nsurface coordinates. In addition, many of today’s modeling packages provide support\nfor subdivision schemes. They also furnish a very easy route for increasing the amount\nof detail. However, these subdivision methods don’t provide an easy means to reduce\nthe mesh detail from the initial mesh. This is where progressive meshes [Svarovsky00,\nHoppe96] would be more useful. It would be great to combine the two methods—\nuse subdivision to increase detail, and use progressive meshes to reduce it. Subdivision\nsurfaces also reduce the number of transformation operations necessary to perform",
      "content_length": 1653,
      "extraction_method": "OCR"
    },
    {
      "page_number": 372,
      "chapter": null,
      "content": "4.7 Subdivision Surfaces for Character Animation 7 a ; 383\n\nskinning, as only the initial mesh needs to be modified. Modern accelerators provide\nT&L support and vertex-weighting extensions, however, using these features with\nsubdivision surfaces is possible. To do this, the view frustum is trarisformed, rather\nthan the vertices of the mesh. Then, when the culling is done with this modified frus-\ntum, the untransformed visible triangles are sent to the graphics card for transforma-\ntion and display.\n\nReferences\n\n[DeRose98] DeRose, Tony, et al., “Subdivision Surfaces in Character Animation,”\nComputer Graphics Proceedings (SIGGRAPH 1998): pp. 85-94.\n\n[Dyn90] Dyn, Nira, et al., “A Butterfly Subdivision Scheme for Surface Interpolation\nwith Tension Control,” ACM ‘Transactions on Graphics, Vol. 9, No. 2, pp.\n160-190, 1990.\n\n[Hoppe96] Hoppe, Hugues, “Progressive Meshes,” Computer Graphics Proceedings\n(SIGGRAPH 1996): pp. 99-108.\n\n[Kobbelt98] Kobbelt, Leif, et al., “Subdivision for Modeling and Animation,” Course\nNotes (SIGGRAPH 1998).\n\n[Kumar96] Manocha, Kumar, et al., “Hierarchical Visibility Culling for Spline Mod-\nels,” Graphics Interface, 1996: pp. 142-150.\n\n[Loop87] Loop, Charles, “Smooth Subdivision Surfaces Based on Triangles,” Master’s\nThesis, University of Utah, Department of Mathematics, 1987.\n\n[Séquin01] Séquin, Carlo, et al., available online at http://www.ce.chalmers.se/staft/\ntomasm/research/subdiv/, December 25, 2001.\n\n[Svarovsky00] Svarovsky, Jan, “View-Independent Progressive Meshing,” Game Pro-\ngramming Gems, Charles River Media, Inc., 2000.\n\n[Weiler85] Weiler, Kevin, “Edge-Based Data Structures for Solid Modeling in\nCurved-Surface Environments,” IEEE Computer Graphics and Applications,\nVol. 15, No. 1, pp. 21-40, 1985.\n\n[Zorin96] Zorin, Denis, et al., “Interpolating Subdivision for Meshes with Arbitrary\nTopology,” Computer Graphics Proceedings (SIGGRAPH 1996): pp. 189-192.\n\n‘nRCRRRNSIEE",
      "content_length": 1930,
      "extraction_method": "OCR"
    },
    {
      "page_number": 373,
      "chapter": null,
      "content": "4.8\n\n384\n\nBackground\n\nImproved Deformation\nof Bones\n\nJason Weber, Intel Corporation\njason.p.weber@intel.com\n\nItists can produce beautifully realistic meshes to represent the actors in their\n\names. To bring them to life, these models need to be animated for a wide vari-\n\nety of behaviors. Storing a full set of vertex positions for every frame of animation is\n\nnot only prohibitively memory-consumptive, it restricts movements to only those\n\nactions explicitly created by the artist. So, many applications use a hidden hierarchy of\nsegments that looks and acts very much like a subset of a natural skeleton.\n\nBy transforming each vertex of a mesh through multiple matrices instead of just\none, and then by doing a carefully weighted average of the results, we are able to\nsmoothly deform these meshes to any position and play back the results at any frame\nrate. This approach permits a significant reduction in the required animation data\nand allows the skeleton, and thereby the mesh, to be spontaneously adjusted to any\npose, perhaps reacting to unpredictable events in its environment.\n\nHowever, the popular deformation algorithm has some problems when used in its\noriginal form. We will demonstrate how large deflection angles cause joints to shrink,\npotentially even to a point. Fortunately, this can be overcome by adding a small chain\nof additional bones at troublesome joints, such as the elbows and knees. By carefully\nreworking the weighting data to account for these ‘links,’ we can use the same simple\ncore deformation algorithm and only incur the small additional burden of a few extra\nbones.\n\nThe skeletal structure is a hierarchy of transforms, like a scene graph. At each trans-\nform, we define a bone length, which is really a displacement along that transform’s\nlocal x-axis. By default, the origin of all child bones is positioned at the displaced\npoint on the end of the parent bone. We allow for an arbitrary additional displace-\nment, but in most cases where bones connect end-to-end, it is zero.",
      "content_length": 2018,
      "extraction_method": "OCR"
    },
    {
      "page_number": 374,
      "chapter": null,
      "content": "A reference pose of the skeleton describes the state of the hierarchy where it aligns\nwith the given undeformed mesh. (Biped, in 3DS Max, calls this the “figure mode.”)\nThe motion of the bones away from the reference pose is used to deform the mesh to\nany arbitrary position. The motion of these bones comes from some driving source,\nsuch as motion capture, authored motion, or inverse kinematics [Weber02]. (For a\nlonger description of the background material, refer to the GDC 2000 proceedings\n[Weber00].)\n\nSimple Methods\n\n[Woodland00] and is also nicely explained in Jeff Lander’s Game Developer article\n[Lander98]. As an example of this technique, consider vertices on an elbow whose\nposition needs to be affected by the current transform of both the upper and lower\narm bones. As we pass each vertex in the elbow through each of the two transforms,\nwe get two different resultant vertices. If we then do a weighted average of these trans-\nformed vertices, we get a reasonable ‘in-between’ position. An important guideline\nhere is that these weightings for the vertices should smoothly transition from 100%\nupper arm to 100% lower arm from the top of the elbow to the bottom. Otherwise,\nthe mesh will stretch abnormally and might appear to tear.\n\nAs the deflection angle of the lower arm increases and the difference in the results\nfrom each bone increases, serious visual abnormalities could arise. For example, the\nworst case might be if you twist the child bone 180° about its lengthwise axis. The\ntwo transformed resultants are on opposite sides of the elbow, so a 50/50 average is at\na point inside the elbow. The overall effect is much like twisting or bending a card-\nboard paper towel tube. Figures 4.8.1 and 4.8.2 show illustrations of problem cases.\n\nFIGURE 4.8.1 Twisted elbows: a simple skinning method demonstrated on the left arm contrasted\nwith an enhanced technique on the right arm.",
      "content_length": 1903,
      "extraction_method": "OCR"
    },
    {
      "page_number": 375,
      "chapter": null,
      "content": "386 . Section 4 Graphics\n\nFIGURE 4.8.2 Corresponding effect with elbows bent. The right arm uses the enhanced\ntechnique.\n\nAdding the Bones\n\nRa aS RN SR RR TER\n\ncd\n\nIf large angles cause defects, one solution is to limit all deflections to a small angle. We\ncannot really restrict the motion of the existing bones, but we can distribute these\nlarge angles over several smaller bones conveniently placed at the joints. Since a\ndeflection of 60° seems to be a safe limit, using three or so of these ‘links’ should usu-\nally be sufficient. The length of the links can be left to the author of the model. We\nare often content with a default value derived from the mesh’s cross-sectional radius at\n\nthe joint and the length of the child bone:\n\ntotal_linklength=0.3*child_length+1.5*joint_radius\n\nThe placement of the bones should look something like a spline. The bones\nshould stay arranged end-to-end, but they may slide together a little as the joint flexes.\nWe don’t have to actually shorten the bones, but the overlap will naturally compress\nthe mesh slightly. Our solution is demonstrated in GPGBoneNode: :CalcBoneLinks() in\nGPGBoneNode.cpp on the CD-ROM, and it works as follows.\n\nTo compute the position of the bones, first consider three points, as shown in Fig-\nure 4.8.3a—the original joint connection A, the first link center B, and the last link\ncenter C. They will form a triangle as the joint flexes. For each link, take two points,\none along BC and the other along either BA or AC, depending on whether the link is\nin the first or second half of the chain. The displacement of these points along these\nlines is proportional to the ordering of the link along the chain. Once you have these\ntwo points, take a weighted average to find the center for the desired link. The\nweighting goes linearly from 100% of the point on BC at either the first or last link to",
      "content_length": 1867,
      "extraction_method": "OCR"
    },
    {
      "page_number": 376,
      "chapter": null,
      "content": "4.8 Improved Deformation of Bones\n\nFIGURE 4.8.3 (A) A small chain of bones added to the joint. (B) Example of new\nweighting relationships.",
      "content_length": 138,
      "extraction_method": "OCR"
    },
    {
      "page_number": 377,
      "chapter": null,
      "content": "388\n\neek eriamnea nti niatmmnonneinnnanetiynaeeiib Wisin nrxteuttenineiiolini nsiceeeutaninneitoklttctr cinta mre eR pinionionuniisitnnoonteio\n\nSection 4 Graphics\n\n50/50 for a link in the exact center. Rotations of the links are computed as the linear\ninterpolation of the overall change in angle so that the total deflection is evenly\ndistributed.\n\nThe instantiation and weighting of the links only need to occur once. The posi-\ntion and rotation of the links need to be recomputed every time the parent or child\nmoves, potentially every frame.\n\nChanging the Weights\n\nTE ED AMATO ENE NINTTI TS ESSE RON 2 ILHAM LDS\n\nMost of the weights around a bone-linked joint will need to be reassigned. The\nweights should transition smoothly from the original parent to the first link, then\nalong to each element in the chain, and finally to the original child bone. If there is no\nfork at this joint and all the original influences were assigned only to this parent and\nchild bone, it is sufficient to use the longitudinal (x) position to find which two bones\nto attach to (including the new link bones). If we look at the links as an integer num-\nber line, with the parent bone as zero and the original child as (number_of_links+2),\nthen we use the local x position of the vertex along the chain, scaled to the size of the\nnumber line. We find the integer numbers above and below where that vertex falls\nand use the fractional part to determine the weights. For example, if our local x posi-\ntion scales to 2.3 in ‘bone link space,’ the new weights will be 70% for the second link\nbone and 30% for the third link bone.\n\nIf there is a fork in the bone hierarchy nearby, more information needs to be con-\nsidered, even if there is not an explicit sibling to the particular child bone. The hip\nand shoulder areas are two good examples of this type of situation. The goal for any\nparticular link chain is to only reassign a fair fraction of the parent’s influence and\nleave the remainder of the influence for other bones to consider. For example, a vertex\non the chest near the shoulder might be partially influenced by the motion of the\nupper arm, but it is also well anchored to one or more spinal bones. When adding\nbones between the clavicle and upper arm, we don’t want to reassign the portion that\nbelongs to the spine.\n\nTo determine this fair fraction, all the weights are found for the particular vertex\nthat have the same parent as an ancestor to the child in question. These ‘competitors’\nreduce how much influence we can reassign for that child. To make sure the effect is\nnot dependent on the order that the weights are processed, only competitor entries\nthat follow the current weight entry on the weight list are considered. Adding up\nthese competitor weights, we determine the fraction as:\n\nfraction = 1 — competitor | (competitor + childweight)\nThe weight to be reassigned is then:\nfraction * parentweight + childweight\n\nAt this point, we continue as in the unforked case. We adjust the existing stored\nparent weight in place. For our two new weights, we can first overwrite the previous",
      "content_length": 3090,
      "extraction_method": "OCR"
    },
    {
      "page_number": 378,
      "chapter": null,
      "content": "4.8 Improved Deformation of Bones 389\n\nchild entry, which has now been entirely reassigned, and then add a new weight entry\nfor the second influence.\n\nFigure 4.8.4a shows a shoulder joint with reassigned weights. This diagram shows\nwhich of the given links the vertices are weighted to. It does not show the magnitude\nof the weights or any weights to other bones, like the spine. A chain of three links\nconnects the clavicle bone to the upper arm. Lines are drawn from each vertex to the\n\noe : io \\of eS\n\nFIGURE 4.8.4 New weighting with three added links (A) for a shoulder mesh (B).",
      "content_length": 583,
      "extraction_method": "OCR"
    },
    {
      "page_number": 379,
      "chapter": null,
      "content": "390\n\nSection 4 Graphics\n\n\\itceerteennattemstttensiivinattss eos glancing ecestcarMemcnenac ret Ab i vRNA RHONA NRGiASESENi CROOK AAARANEIIDTA NRA ADELE EN HatotentneeatonenEIOHESeIt\n\nON THE CD\n\ncenter of each bone that the vertex is influenced by. The shade of the line matches the\nshade of the bone, varied for clarity. Note how the links have influences deep into the\nchest. These create a gradual stretching of the skin when the arm is moved.\n\nNormal-Derived Influence Fade\n\nThere is one side effect we cannot ignore. Since we are reassigning based purely on\nposition, joints with apparent right angles in the mesh can incur excessive bulging.\nThe shoulders tend to display this problem. When the upper arm moves up, the side\nof the chest will push out sideways, as though it were a very wide region of the arm\n(see Figure 4.8.5).\n\nWe can use the inherent difference in the normal direction to correct for this. We\ntake the dot product of a vertex’s normal with respect to the longitudinal bone axis.\nFrom this result, we subtract the x displacement of the vertex along the bone, divided\nby the approximate fadius at the joint (the subtracted value and the result both have a\nfloor of zero). This reduction has the effect of isolating the correction toward the par-\nent side of the joint. The secondary result is a fraction from 0.0 to 1.0, which we\nsquare for good measure. This fraction is applied to the weight that was previously\ndestined to reassignment. That portion of the weight is not reassigned, but directly\nadded to the parent’s weight. In our example code, see GPGSkin: :RelinkWeights() in\nGPGSkin.cpp on the CD-ROM.\n\n(A)\n\nFIGURE 4.8.5 Raised arms (A) without and (B) with normal-derived influence fade.",
      "content_length": 1719,
      "extraction_method": "OCR"
    },
    {
      "page_number": 380,
      "chapter": null,
      "content": "391\n\nit is critical chat we lay out our runtime data in a cache-friendly manner. The biggest\ndecision to make is whether to process the weights in a ‘bone-major’ or ‘vertex-major’\nfashion.\n\nFor the bone-major method, you have to first clear all the vertex positions and\nnormals in the mesh. Then for each bone, you process all the vertices that the bone\ninfluences, accumulating fractional components to their stored positions and nor-\nmals. While this will probably keep the current matrix in cache, it reads and writes the\nmesh in a very scattered manner.\n\nIn the vertex-major method, we process the vertices in order, pulling in matrices\nas necessary. While this may incur some scattered access to the matrix array, the\nadvantages are numerous. First of all, there is no clearing stage. We know when the\nfirst write to a vertex occurs, so that access can be a pure set instead of an add. Since\nthe weights for a vertex are clumped together, we can accumulate the results in a local\nvariable and dump them out with one write per vertex, instead of one read and one\nwrite per weight per vertex.\n\nWe have tried it both ways, and for all our measurements, the vertex-major\napproach was at least twice as fast, and probably much faster, even with all the opti-\nmizations we were able to add later on due to the flexibility of the layout.\n\nTransform Matrices\n\nEvery bone in the skeleton has a transform, including the added bone links. Until the\nactual deformation stage, we use quaternions because of their superior interpolative\nqualities [Bobick98]. However, for raw vertex transforms, using the matrix form is\nalmost four times faster. So, just before the core deformation loop, we fill in a nicely\npacked array of 3 x 4 matrices, one for each bone. Each matrix is assigned the inverse\nof the bone’s reference transform, multiplied by the bone’s current transform. In this\nway, we can transform directly from the original, undeformed mesh without having\nto store vertex offsets relative to each bone.\n\nThe core deformation loop contains only about 50 lines of code. See\nGPGSkin: :ComputeDeformedVerticesPacked() in GPGSkin.cc on the CD-ROM.\n\nPackweights |\n\nSince the vertex weights will usually be a larger data structure than the matrix array or\neven the mesh, it is important to keep the weight list small in order to reduce the\namount of data we need to process each frame. This not only saves space, but it\nshould really optimize our cache usage. However, we/also need to be aware that exces-\nsive byte conservation might throw off the word alignment, which would be just as\ndetrimental to the process.",
      "content_length": 2607,
      "extraction_method": "OCR"
    },
    {
      "page_number": 381,
      "chapter": null,
      "content": "392\n\nSection 4 Graphics\n\nThe packweight structure is a big byte block with alternating sections of one ver-\ntex definition and one or more boneweight influences. The vertex definition contains\nthe vertex index, a copy of the undeformed vertex position and normal, and the num-\nber of weights to follow. The boneweight block contains just the bone index into the\nmatrix array and the fractional weight. As we read any block, we can prefetch the next\none.\n\nNote that storing the vertex position and normal in the weight list means that we\ncan continuously deform to an output mesh without having to retain an undeformed\ninput mesh, If we wanted to allow outside modifications to the input mesh, such as\nwith a piorphing modifier, we would not store that data in the weight list, but we\nwould have to take the penalty of rereading vertices from the input mesh every frame.\nSee the file GPGPackWeights.h on the CD-ROM for our example code.\n\nON THE CD\n\nNormal Renormalization\n\nWe can perform a weighted average of multiple normals just like we do with the posi-\ntions, but the result will have a reduced magnitude. These differences are easy to fix.\nSince the reduced normals are known to have a range of magnitude from 0 to 1, you\ncan use a modest table to eliminate the sqrt() operation. If you do not renormalize\nthem, they could cause a reduction in lighting intensity. Our observations show very\nlittle difference, so you might want to consider leaving them as is or hook the option\n\nto a quality toggle.\n\nLERNER ETSI SURE BS HR A ENE\n\nRRR rd\n\nBones-based animation can be a key to reducing animation overhead and allowing for\nspontaneous and. unique behaviors. Existing deformation techniques can be made\nvery fast and are easily extended to overcome some inherent limitations.\n\nAdditional topics could cover the generation and manipulation of the original\nvertex weights. Color Plate 7 demonstrates improvements achieved by using a com-\npletely automated procedure to generate raw weights, remove anomalies, smooth the\ndistribution, and add bone links.\n\nThe improvement in the waist is mostly due to the regenerated weights. The\nupper leg benefits dramatically from using the links to reduce shrinkage. Even the\nshoulder and knees improve significantly by eliminating excessive stretching. Also, the\nchest looks more realistic, since using links in the shoulder permits a wider spread of\ninfluences over the surrounding mesh.\n\nReferences\n\nRRR RRR ERR RR ROR ES ENR ARMAS ERE RENT NR NHS PO RRA I RIRRRALNRRA OBEN SEA BIE MTORO\n\n[Bobick98] Bobick, Nick, “Rotating Objects Using Quaternions,” Game Developer\nMagazine, February 1998: pp. 34-42. Also available online at http://www.\ngdmag.com.\n\n[Lander98] Lander, Jeff, “Skin Them Bones: Game Programming for the Web Gen-\neration,” Game Developer Magazine, May 1998: pp. 11-16.\n\n_saenttrny",
      "content_length": 2837,
      "extraction_method": "OCR"
    },
    {
      "page_number": 382,
      "chapter": null,
      "content": "4.8 Improved Deformation of Bones\n\n[Weber00] Weber, Jason, “Run-Time Skin Deformation,” Game Developers Confer-\nence Proceedings (GDC 2000): pp. 703-721. Also available online at\nftp://download.intel.com/ial/3dsoftware/animatedoc.pdf.\n\n[Weber02] Weber, Jason, “Constrained Inverse Kinematics,” Game Programming\nGems 3, Charles River Media, Inc., 2002.\n\n[Woodland00] Woodland, Ryan, “Filling the Gaps—Advanced Animation Using\nStitching and Skinning,” Game Programming Gems, Charles River Media, Inc.,\n2000: pp. 476-483.\n\nThe author will make an effort to maintain a long-term archive and link site for some\nrelated resources at http://www.imonk.com/baboon/bones.",
      "content_length": 661,
      "extraction_method": "OCR"
    },
    {
      "page_number": 383,
      "chapter": null,
      "content": "4.9\n\nA Framework for Realistic\nCharacter Locomotion\n\nThomas oung, PathEngine\nthomas@pathengine.com\n\nith today’s hardware, we can render extremely realistic-looking characters.\n\nHigh-fidelity motion-capture systems are widely available for providing anima-\ntion data. However, in most games, as soon as a character starts to walk, the illusion of\nreality is destroyed. The character's feet slide against the ground, the character is\nrotated arbitrarily in mid-animation, or the animation jumps suddenly to a com-\npletely different state.\n\nEven a small amount of foot-sliding is noticeable. As soon as we see a foot slide\nagainst the floor, we know that breaking friction has been overcome. Without friction\nbetween the foot and the floor, there is no mechanism that a character’s forward\nmotion can be attributed to, so the movement of the character is strongly perceived as\nunrealistic.\n\nIt is difficult to solve all the constraints for realistic animation at the same time.\nWe can ensure smooth transition between animations with a tweening modifier. This\nmodifier calculates the in-between (or tween) positions in animation poses. We can\nsolve the problem of arbitrary targets for locomotion by modifying the translation\nresulting from each animation segment. However, a straightforward implementation\nof these modifiers will result in foot-sliding.\n\nThis gem presents a solution to this problem based on adjusting the position of\nthe feet only when they are already in motion. A framework is described for applying\nthis idea to the problem of realistic character animation by using independent modi-\nfiers for different parts of a skeleton.\n\nProblem: Locomotion to an Arbitrary Target —\n\nSARS MAHAN NUS NNT NORE ARR U AR A ARSN RU RAR\n\nToward the end of the 2D era, we started t to see games such as Prince of Persia and\nFade to Black, which featured beautifully sequenced animations. The trick was that\nthe game environment was built from unit-length tiles on a fixed grid. Since the ani-\nmation was designed around exactly the same unit-length, it was possible to guaran-\ntee that the animation ended perfectly, just pixels in front of a wall or a cliff.\n\n394",
      "content_length": 2164,
      "extraction_method": "OCR"
    },
    {
      "page_number": 384,
      "chapter": null,
      "content": "4.9 A Framework for Realistic Character Locomotion\n\n(A) (>>+——> —_ > x\n\n®) (>>> >\n\n— &\n\nFIGURE 4.9.1 A character with fixed animations attempting to move to arbitrary points and angles.\n(A) The character will not reach the point with a start, walk, walk, stop sequence. (B) The character\nwill overshoot the target with a start, walk, walk, walk, stop sequence. (C) The character will not\npoint toward the target with one or two rotation animations.\n\nAs soon as the possibilities for movement include turning in arbitrary angles and\nmoving forward, the situation becomes more complicated because we can no longer\nconstrain this movement to a fixed grid. Now we are stuck with the problem of char-\nacters needing to move arbitrary distances and turn in arbitrary angles.\n\nThe character in Figure 4.9.1 has an animation for starting to walk, a walk cycle\nanimation, and an animation for stopping. In Figure 4.9.1a, two walk cycles will not\ntake the character far enough, but in Figure 4.9.1b, three will take the character too\nfar. Figure 4.9.1¢ shows how the same problem applies when turning arbitrary angles.\nIn this case, the character only has one turn animation. Playing the animation once\ndoes not turn enough, but playing it twice turns the character too far. We can improve\nthe situation by providing more animations for a character to choose from, but the\nbasic problem remains.\n\nPlan and Modify\n\nWe can solve this problem by modifying the translational or rotational offsets for ani-\nmations as they play. In Figure 4.9.2, the closest set of animations in length is chosen\nprogrammatically from the available animations. The offset required to take the end\npoint of the animations to the target is split across the animations and applied as a\nmodification to each animation. The animation sequence now ends exactly at the tar-\nget point.",
      "content_length": 1845,
      "extraction_method": "OCR"
    },
    {
      "page_number": 385,
      "chapter": null,
      "content": "396\n\nSection 4 Graphics\n\n‘ene ses Reh Aes EE EEE EEE GA ENE ROARS OCA OEE HDETSERAOOE HAA OEE NRE\n\n) >>> >\n\nacon\n\nFIGURE 4.9.2 Plan and modify movement to arbitrary targets. (A) Calculating the necessary\nadjustment to move to the target. (B) Distributing the adjustment among the fixed animations.\n(C) The same process with angles.\n\nIn order to modify the translational or rotational result of an animation, we sim-\nply apply an offset to the position or orientation of the character origin with a\n‘ramped’ multiplier that goes from 0 to 1 smoothly as the animation is played. How-\never, since this multiplier will change during parts of the animation, such as when a\nfoot is supposed to be stationary, the result is foot-sliding.\n\nmooth Transition Between Animations\n\nsane 6 tr a RR\n\nMotion-captured moves will never start or end in exactly the right stance, no matter\nhow good the actor is. Concentrating on hitting the right stance can also have a neg-\native effect on the quality of motion. It is a shame to discard a capture in which the\nactor got the movement right, just because the capture ends a bit out of stance. With\nmotion-captured animation, we need to transition smoothly between captures that\nare out of stance. Even if we are working with hand-animated moves that start and\nend in perfect stance, we still need to be able to transition early out of a move.\n\nAn Approach\n\nThe best result will be achieved by transitioning directly between the state of the\nskeleton at the end of one motion and the state at the start of the next motion, as\nopposed to transitioning in and out of a predefined stance. Since we do not want to\ninterrupt the flow of movement, a transition should be made while the animation is\nplaying. For the greatest flexibility, we should not project which animation will play\nnext until we must play that animation. Based on these considerations, a good\napproach to the problem is to modify the start of each animation to be the same as the",
      "content_length": 1974,
      "extraction_method": "OCR"
    },
    {
      "page_number": 386,
      "chapter": null,
      "content": "4.9 A Framework for Realistic Character Locomotion 397\n\n(A) (B) (C)\n\nFIGURE 4.9.3 Transition between stances. (A) State of skeleton at end of previous\nanimation. (B) State of skeleton at start of following animation. (C) Applying the same\nmodification later in an animation causes problems at a foot.\n\nend of the previous animation, and then ease out this modification as the animation\nis played.\n\nThe character in Figure 4.9.3a shows the state of the skeleton at the end of the\nprevious animation. Figure 4.9.3b shows the skeletal state at the start of the following\nanimation. We need a modification that will transform the skeleton from the state in\nFigure 4.9.3b to the state in Figure 4.9.3a. We also need to be able to smoothly tran-\nsition back to the original position as the second animation plays.\n\nA common approach to solving the transition problem is to store the state of a\nskeleton as a set of hierarchical relative orientations and to interpolate between these\norientations. Orientations are often interpolated with the use of spherical linear inter-\npolation of quaternions. (See [Shankel00] for a more detailed description of quater-\nnion interpolation.) If we use this interpolation method, then our modification takes\nthe form of a set of quaternion offsets for each joint. This modification can be eased\nout by multiplying the offsets by a ‘tween ratio’ that goes from 1.0 to 0.0, over the\nduration of the current animation. Figure 4.9.3b shows how a set of rotations at the\njoints can take the skeleton to the desired position. The origin for the character in\nFigure 4.9.3 is between the hips. As the height of the origin can vary with animation,\nour modification should also include an offset to this height.\n\nProblems with this Approach\n\nThe first problem with this kind of straightforward interpolation approach is that for\nany modification that affects the position of the feet, easing out that modification will\nalso affect the feet. If this happens while the foot is supposed to be stationary against",
      "content_length": 2028,
      "extraction_method": "OCR"
    },
    {
      "page_number": 387,
      "chapter": null,
      "content": "398\n\nSection 4 Graphics\n\nthe floor, then we get foot-sliding. The amount of sliding will depend on the size of\nthe original discrepancy and the length of time over which our modifier is eased out.\n\nThe second problem is that our modifier will give us undesirable results when it\nis applied to the skeleton later on in the animation. Figure 4.9.3b shows the rotations\nthat will be applied by our modifier to the left leg. We know that these rotations result\nin a ‘correct’ position for the skeleton when applied to the first frame of animation\nbecause the rotations were chosen to achieve a specific target position when applied at\nthis point. Figure 4.9.3c shows how the application of the same rotations to the leg\nlater on in the animation results in the foot hovering above the floor. The interface\nbetween the foot and the floor over a period of animation depends on a combination\nof translation at the origin and rotation of the leg. Applying a modifier to the rotation\nof the leg breaks this interface. This will result in feet hovering or interpenetrating the\nfloor, feet being positioned at the wrong angle with respect to the floor, and feet slid-\ning against the floor when they are supposed to be stationary. The problem gets worse\nas the skeleton gets further from its start position. We can improve the situation by\neasing out our modification more quickly, but this will affect the smoothness of the\ntransition and make the foot-sliding more pronounced over the ease-out duration. So,\nonce again, while we have an approach for transitioning between two animations, the\nsliding-feet problem still plagues our result.\n\nA Framework for a Solution: Local Modifiers\nwith Independent Tween Ratios\n\nSEERA con ete\n\nRRR Ran\n\nBy modifying an animation slightly as it is played, we can solve some problems in\ncharacter locomotion. However, if this modification affects the positions of the feet\nwhile they are supposed to be stationary against the floor, then there is still a problem.\n\nWe can choose when to reduce our tween ratio. If a character jumps in the air\nhalfway through an animation, then we can delay tweening until both feet leave the\nfloor and finish tweening by the time the character lands. This would eliminate prob-\nlems resulting from changing tween ratio while the feet are on the floor. Unfortu-\nnately, most animations will have at least one foot on the floor most of the way\nthrough the animation.\n\nAffecting Feet Only When They Are Already Moving\n\nThe trick is to use independent modifiers for different parts of a skeleton. This way,\nwe can ease out each modifier over different sections of the animation. Thus, to mod-\nify an animation without introducing foot-sliding, we use a separate modifier for each\nleg. For a walk animation in which the left foot moves first, followed by the right foot,\nwe ease out the left-leg modifier while the left foot is moving forward, then we wait\nuntil the right foot starts to move before easing out the right-leg modifier.\n\nWe can generalize this to any kind of animation and automate the process of\ndetermining when to perform the ease-out for each modifier. Figure 4.9.4 shows a\ntwo-step animation with the corresponding movement profile for each foot. We can",
      "content_length": 3227,
      "extraction_method": "OCR"
    },
    {
      "page_number": 388,
      "chapter": null,
      "content": "4.9 A Framework for Realistic Character Locomotion 399\n\nmesa eee Meee eewA OI sauces HENGE ORRSMRA DERE AT ORS REE\n\nLeft Foot\n\nRight Foot\n\nFIGURE 4.9.4 A two-step animation with corresponding movement profile ford the 1 fet\n\ntake the tween ratio for each leg directly from this movement profile. The tween ratio\nat a given point can be set as the movement up to that point divided by total move-\nment over the course of the animation.\n\nIf a foot does not move at all during the animation, or if there is insufficient total\nmovement (and so the rate of tweening would be too fast), then we can choose either\nto allow some foot-sliding for that animation or allow the modifier to remain at the\nend of the animation without being eased out completely.\n\nBecause the feet will move slightly as a result of error accumulation down the\nskeleton hierarchy and/or because of error in the original motion capture, it helps to\nset a threshold for foot movement and ignore any movement below that threshold.\n\nApplication: Locomotion to\n\naR ONO)\n\nan Arbitrary Target\n\neR ES REAR TATOO\n\nFor the problem of locomotion to an arbitrary target, we need the animation to be\nunmodified at the start, but uniformly offset at the end. By applying an offset at the\ncharacter origin, we already bring the feet and legs to the correct position by the end\nof the animation. However, to apply our framework to this problem, we need some\nway to apply this offset at different times for each foot.\n\nThe solution is to keep track of three tween ratios.’ A straightforward, ramped\ntween ratio controls a global offset applied to the character origin. Tween ratios,\ndetermined from the movement profiles of the feet, keep track of the desired amount\nof offset at each foot. A modifier is then applied at each leg to correct the difference\nbetween the tween ratio already applied by the global modifier and the desired tween\nratio for that foot. Figure 4.9.5 shows how this would apply to the two-step anima-\ntion in Figure 4.9.4. Halfway through the animation, the global tween ratio is 0.5; the\nleft foot has finished its step and therefore should be at 1.0, and the right foot has not\nmoved yet, so it should be at 0.0. To correct the positions of the feet, the left leg needs\nto be modified by 0.5 and the right leg by —0.5.",
      "content_length": 2295,
      "extraction_method": "OCR"
    },
    {
      "page_number": 389,
      "chapter": null,
      "content": "400 _Section 4 _Graphics\n\nseatsioisentoutanretanon i eons nm eR SenSneeeeeeeeeenaribNRLREADR NERIND ONAN TOR HHA RRS catennce tpn eect\n\nFIGURE 4.9.5 Correcting a global modifier. The arrows show modifications applied to a\nskeleton at different points in a two-step animation. The skeleton in gray shows the\nsituation halfway through the animation.\n\nA rotational or translational modifier will need to be set up as required to create\nthe same effect as the global modifier, when the modifier is applied with a positive\nvalue, or to cancel that effect when the modifier is applied with a negative value. If the\ncharacter origin is at the hips, then a rotational modifier can simply rotate the leg by\nchanging the orientation of the hip joint. A translational modifier will be more\ninvolved, and we have some choices about how to implement this.\n\nTranslational Modifiers\n\n_SeRSUSUREAA Tr mctuannineIRRRR RERUNS EBA EU PR RN\n\nA translational modifier for a L foot needs to apply an offset to the position of that foot\nand set up the rest of the leg appropriately, without affecting the position of the hips.\nThis is a classic problem for inverse kinematics (IK) (see, for example, [Tolani00]).\nWith an IK approach, a set of constraints is solved for the leg, with the goal of putting\nthe foot in the desired position. We have to take into account the possibility that the\nIK can fail. In this case, we could put the foot at the closest position that we can\nachieve within the given constraints. Figure 4.9.6a shows a required offset for the\nfoot. Figure 4.9.6b shows how an IK solution might achieve this offset as a combina-\ntion of rotations at the joints.\n\nA simpler alternative is to point the ankle in the desired direction by rotating the\nhip joint and then apply scaling to the leg to bring the ankle to the correct position,\nas shown in Figure 4.9.6c.\n\nAt first glance, the IK solution looks better because it maintains skeletal con-\nstraints correctly throughout the animation, but there are some problems with this\napproach. A straightforward IK solution does not take into account the need for con-\nsistency across frames. Small changes in the position of the IK target can lead to big",
      "content_length": 2192,
      "extraction_method": "OCR"
    },
    {
      "page_number": 390,
      "chapter": null,
      "content": "4.9 A Framework for Realistic Character Locomotion 401\n\n\\ a _ __ e\n(A) (B) (C)\n\nFIGURE 4.9.6 Transform modifiers. (A) The required offset. (B) Rotations at joints\nfound by inverse kinematics. (C) A simpler approach rotates the whole leg and then scales\n\nto fit.\n\nchanges in the position of the leg and inconsistency between frames. These inconsis-\ntencies between frames can result in unnatural animation.\n\nThe most important constraint for consistent animation is that the modifier\nshould have a very small effect on the leg for a small offset. In order to enforce this\nconstraint in the IK solution, we need to reformulate the problem for IK. We can\nredefine the problem and find a modification to the angles in the leg in order to\nachieve an offset to the position of the foot. Unfortunately, there is no guarantee that\nthe position of the leg in the original animation conforms to the constraints of our IK\nin the first place.\n\nIn practice, the simpler approach is recommended (applying a single rotation at\nthe hip and then scaling). This gives us smoother animation and an acceleration at\neach point in the leg that corresponds better to the original animation. For a small\noffset, we are guaranteed a small modification. The angle at the knee is also preserved\nwith this method. Because we do not enforce constraints at the hip, however, the\nskeleton can get into some strange positions; and while using a small amount of scal-\ning on the leg will not be noticeable, any significant amount will look very odd. For\nthese reasons, we should try to avoid using large values for modifiers and also try to\navoid leaving modifiers on characters when they are stationary.\n\nSometimes, even a small amount of scaling can mess up the skinning. One trick\nwe can use as an alternative to a simple scaling is to stretch the leg along the direction\nof the bones without scaling in the other directions.",
      "content_length": 1895,
      "extraction_method": "OCR"
    },
    {
      "page_number": 391,
      "chapter": null,
      "content": "402 Section 4 Graphics\n\nApplication: Transitions\n\nRRR REREAD HERE ORR ORI RARER CARER THS REARS DARREN MSE AES\n\nWe can apply the same framework for transitions between animations. By using sepa-\nrate modifie ach leg, we can eliminate problems resulting from changing the\ntween ratio while a foot is supposed to be stationary. However, applying a modifier to\nthe angles of the legs while the character origin is moving will still cause problems at\nthe feet.\n\nThe solution is to use an ‘anchored modifier.’ This essentially does the same thing\nas the translational modifiers previously discussed, but also affects the orientation of\nthe foot. Instead of specifying an offset, we specify a target position for the foot in\nworld space (or in the character's local coordinate system, if that does not change as\nthe animation plays). The target position for the anchored modifier is the position of\nthe foot at the end of the previous animation. Assuming that the foot is correctly\nplaced with respect to the ground at that point, the modifier will ensure that the foot\nremains correctly placed with respect to the ground until that foot starts moving. As\nsoon as the foot starts moving, the modifier can be eased out.\n\nAn anchored modifier will ensure that the position of the feet corresponds to the\nend of the previous animation, but it does not do anything about the rest of the leg.\nEven if the hip and the leg do not move across the transition, if the position of the leg\nin-between those points does not match up across that transition, then the animation\ncan still appear jerky. We can solve this problem by simply applying spherical interpo-\nlation to the leg as before, but with the anchored modifier applied to the result of that\ninterpolation.\n\nseeiesesnmmmen\n\nFurther Details\n\nRRNA NINERS ee Sete tec A HR RH LAR A RN NS MI SE RRS NANA RUAAERAOT ERATE A NNO\n\nSingle-Step Animations\n\nIn a two-step animation where both feet move over the course of the animation, we\nget the chance to ease out modifiers on both legs while the animation is playing. Tran-\nsition modifiers enable us to generalize the technique also to single-step animations.\nAny modifiers not eased out by the end of an animation will be dealt with by modi-\nfiers at the start of the next animation.\n\nKeeping Characters Moving\n\nIn order to make characters look alive, we must keep them moving. We can use a col-\nlection of moving-on-the-spot animations to avoid characters standing completely\nstationary. If these animations include moving the feet slightly, then this gives the ani-\nmation system a chance to ease out any remaining modifiers.\n\nThe player will most likely notice irregularities in a character’s posture when that\ncharacter comes to a stop. Therefore, it is a good idea to ease out any modifiers when\na character stops. If there is a pause key, then the same concerns apply for paused\naction.",
      "content_length": 2880,
      "extraction_method": "OCR"
    },
    {
      "page_number": 392,
      "chapter": null,
      "content": "4. ‘Oo A Framework for Realistic Character Locomotion | 403\n\nLimiting Modifiers\n\nDegenerate captures, which are a long way out of stance, can result in modifiers with\nlarge values. Sequences of animations over which a given foot does not move at all can\nresult in the errors at transitions getting built up into large modifiers. It is a good idea\nto limit the range of values that can be applied through a modifier in order to prevent\nstrange effects in these kinds of situations.\n\nConclusion\n\n_ stamens esata mame et ea SRI RR i Ae ASTER SSE NR NN HE OR ROR RE\n\nIn order to solve problems in character locomotion, we often need to modify anima-\ntion. Unfortunately, modifying animation can break the interface between the foot\nand the floor, and can result in unrealistic-looking movement. By using separate mod-\nifiers, and therefore independent tween ratios for each leg, we can apply modifications\nto each leg at a time when the corresponding foot is already moving and avoid prob-\nlems of foot-sliding.\n\nReferences\n\n[Shankel00} Shankel, Jason, “Interpolating Quaternions,” Game Programming Gems,\nCharles River Media, Inc., 2000.\n\n[Tolani00] Tolani, Deepak, et al., “Real-time inverse kinematics techniques for\nanthropomorphic limbs,” available online at http://hms.upenn.edu/software/ik/\nikan_gm.pdf, September 8, 2000.\n\nSADDLE ERTS ENG ILL ASSTT NT AL SAT IEE AEDES",
      "content_length": 1371,
      "extraction_method": "OCR"
    },
    {
      "page_number": 393,
      "chapter": null,
      "content": "4.10 —_\n\nammable Vertex Shader\n\n404\n\nA Programmable Vertex\nShader Compiler\n\nAdam Lake, Intel Labs\nadam.t.lake@intel.com\n\nhis gem discusses the implementation of a compiler for programmable vertex\n\nshaders. There are many reasons why it is now desirable for graphics program-\nmers to consider compilers for programmable shading hardware. Some examples\ninclude increased readability and greater portability of the programs we write for pro-\ngrammable hardware. As the underlying instruction set changes, we do not need to\nrewrite our shaders. If the shader is written in a high-level language, we need only\nretarget the front end of our compiler to a new code generator for the new instruction\nset. This allows shaders written in a high-level language to be compiled to the shader\nimplementation in OpenGL, DirectX, or an in-house software-rendering library.\nAlso, by writing a shader in a high-level, C-like language, it is easier for us to read and\nwrite new shaders. This makes it easier to make changes to your shaders library.\n\nThe CD-ROM includes a full implementation of a simple vertex shader com-\npiler. It also contains documentation on how to create a workspace for building com-\npilers and an example that compiles the OpenGL lighting equation into a DirectX\nvertex shader! To give a practical foundation to this gem, we are focusing on the ver-\ntex shader implementation in DirectX8. Future implementations might vary, but the\nframework and infrastructure we provide should still be applicable.\n\neiprmamaaRBRETIe\n\nA vertex shader is a program that takes the standard lighting equation parameters, such\nas color, position, normal, and texture coordinates (known as the vertex stream), as\ninput and computes the final values that are submitted for rasterization. Material and\nlight parameters are sent to the vertex shader through a set of constant registers that\ndo not change while a specific vertex stream is being processed by the vertex shader. A\nwidely used vertex shader implementation, DirectX8, has 96 constant registers, 12\ntemporary registers, and 16 vertex registers [Microsoft00] (see Figure 4.10.1). The\noutput of this program (the final vertex properties) are loaded into a set of output reg-",
      "content_length": 2216,
      "extraction_method": "OCR"
    },
    {
      "page_number": 394,
      "chapter": null,
      "content": "4.10 Programmable Vertex Shader Compiler\n\n405\n\nVertex Registers\n(16)\n\nVertex Program -! Temporary Registers\n(128 instructions) = tex) (12)\n\nConstant Registers\n(96)\n\nOutput Registers\n(5)\n\nFIGURE 4.10.1 DirectX8 shader architecture. There are 16 registers for vertex data, 96\nfor constants, 12 temporary registers, and 5 for output. In DirectX8, there is a limit of\n128 instructions per vertex program. Temporary registers are the only registers that are\nread/write.\n\nisters that, after transformation and lighting calculations have been performed by the\nvertex shader, are passed to the pixel shader for final display. All registers are four-\ncomponent vectors. Individual elements can be referenced in an individual instruc-\ntion using x, y, z, and w as accessors of the elements. We will not cover pixel shaders\nin this gem, but more information can be found in the References.\n\nAs previously mentioned, the vertex shader program utilizes a set of assembly\ninstructions along with the values in the input registers to compute values to the out-\nput registers. Mathematical operations such as add, mult, max, and min are supported,\nas well as a set of higher-level assembly instructions, such as dp3, dp4, logp, and dst.\n([Microsoft00] and [Microsoft01] offer a detailed instruction set.) An example assem-\nbly program is given in Listing 4.10.1.",
      "content_length": 1346,
      "extraction_method": "OCR"
    },
    {
      "page_number": 395,
      "chapter": null,
      "content": "406\n\n_Section 4 Graphics\n\nListing 4.10.1 A cartoon vertex shader in vertex shader assembly\n[Lake01].\n\noe Ha BRAT Epa eeeninee pe eamNRNee te NNR ER RRMA\n\nVertex Transform\n\nrN is a temporary register\n\nvN is a vertex register\n\ncN is a constant register\n\noPos and oTo are output registers\n\nee ee ee ee\n\nTransform to view space\nm4x4 rg, vO, c8;\n; Transform to projection space\nm4x4 r10, r9, c12;\n; Store output position\nmov oPos, r10;\n’\n\n3; Lighting calculation (N.L dot product)\n\nt]\ndp3 oT0.x, c20, v3;\n\nThe Compiler\n\niH oS RRA RRR HERR\n\nrari RE OR RRO BORE NE LB MANNE\n\nThe compiler consists of six key components. It will translate the high-level language\ninto a lower-level instruction set. We introduce each here and go into greater detail in\n\nlater sections (see Figure 4.10.2).\n\nSymbol Table—Contains keywords and variables used in the program. Used to\nlook up and store the register to which a variable has been assigned.\nScanner—Works with the parser to accept or reject a program. Builds tokens, or\nsymbols, out of the characters that are passed to the scanner. Passes these tokens\nto the parser and adds new variables to the symbol table. (Lex is short for lexical\nanalyzer. In practice we use flex, the gnu version of Lex, to create our scanner.)\nParser— Works with the scanner to accept or reject a program. Builds statements\nfrom the tokens the scanner passes as input. Uses these statements to create the\nabstract syntax tree. (Yacc stands for yet another compiler compiler [Levine92]. In\npractice we use bison, the gnu version of Yacc, to create our parser.)\n\nAbstract Syntax Tree (AST)—Each time the parser accepts a statement, it adds it\nto the syntax tree. The syntax tree is passed from the parser to the code generator.\nCode Generator—Walks the AST and emits code for the vertex shader based on\ndata in the AST.\n\nTemporary Register Allocator—Manages the temporary register set used by the\ncode generator.\n\nThe compiler we are generating is simple when compared to the complexity of a\n\nstandard compiler, which has support for loops, branches, and extensive optimization",
      "content_length": 2086,
      "extraction_method": "OCR"
    },
    {
      "page_number": 396,
      "chapter": null,
      "content": "4.10 Programmable Vertex Shader Compiler 407\n\nON THE CD\n\nitnuneseecseeeseusrooneettsoncetraor steak hnee A eeoO EO NOS MAA R m HAN eR\n\n—\n\n| Scanner\n\nFIGURE 4.10.2 We start with a high-level program that is passed to our compiler. First,\nwe use our scanner and parser to determine whether we have a valid program. During\nthis process, we also build a syntax tree and a symbol table. Next, we pass these to the code\ngenerator. The code generator walks the syntax tree and emits a valid vertex shader\nassembly program.\n\nVertex\nShader\nAssembly\nProgram\n\nHigh-Level\nProgram\n\nGenerator\n\nroutines. We could add many enhancements. This is definitely an opportunity for\nfuture work, and you are encouraged to experiment, optimize, and augment the\nexample source code provided on the CD-ROM.\n\nCompiler Components\n\nThe compiler is broken up into seven components: the language, scanner, parser,\nabstract syntax tree, symbol table, temporary register set, and code generation.\n\nThe Language\n\nThe first task is to define the language we are going to compile. Since we are inter-\nested in creating a language that is familiar, we based it on a C-like procedural lan-\nguage model. Eventually, we want to support things like parameter-passing, function\ncalls, and loops; but for the first version, we do not handle these constructs. We would\nalso like to migrate many of the features and keywords into a Renderman-like lan-\nguage in the future. While this is too complicated for the vertex shaders, a real-time\nRenderman language is inevitable in the future of fully programmable graphics\npipelines.\n\nSince vertex shaders do not currently support looping or branching, we do not\nneed to support the syntax for these elements. However, we do have a large set of val-\nues that we would like to utilize in our vertex shader. These are listed in Table 4.10.1.\nEach of these values are considered constant, or nonvarying across a particular mesh\nduring its rendering. We assign each of the values into a specific register in the con-\nstant register set. There is an agreement between the application and the shader that\nthe value will be stored in that particular register, and both the application and the\ncompiler agree on which register this value resides in. For example, in our compiler,\nwe store the light direction for the first light, LightDiro, in constant register 26. The\napplication must put the light direction into this register for the shader, or the shader",
      "content_length": 2450,
      "extraction_method": "OCR"
    },
    {
      "page_number": 397,
      "chapter": null,
      "content": "408\n\nSection 4 Graphics\n\nTable 4.10.1 Keywords Used in Vertex Shading Language\n\nProperty Keywords\n\nVertex Light Material Output\n\nPos LightDiro..4 MatAmb oPos\n\nNormal LightAmbo. .4 MatDif oColor\n\nTexCoordo. .4 LightDifo. .4 MatSpec oFog\nLightSpeco. .4 MatShininess oTexture\n\nLightPoso. .4\n\nNote: In the example, we do not use the second color channel or the second texture layers that\nare part of the output register set in DirectX8.\n\nwill read bogus data contained in the register. The compiler knows where this value is\nstored by looking up LightDiro in the symbol table and returning the register index\nwhere it was assigned. In our example, this is the method GetRegNumFromName (char\n*name) in the class CTempRegSet. Table 4.10.2 lists the math keywords that are used in\nour vertex shader.\n\nScanner\n\nThe scanner is also known as the “lexical analyzer.” The lexical analyzer works with\nthe parser to determine whether your program can be accepted as input. Again, our\nscanner is simple. We recognize the list of tokens in the symbol table, as well as vari-\nables (strings that are not keywords), punctuation, floating-point numbers, math\noperations, and comments using regular expressions defined in our token list.\n\nThe CD-ROM contains an example in the directory for this gem, (see scanner.l).\nLex is used to build the actual C program that is then compiled to build the scanner.\nDetails of this process are beyond the scope of this gem, but it’s always interesting to\ntake a look at the C file generated, lex.yy.c.\n\nTable 4.10.2 Math Keywords\n\nMath Keywords\ndot3 cos clampTo1 floor normalize negate\ndot4 sin sqrt ceiling maxWithoO\n\nNote: The math keywords are in addition to the +,-,* ,/,*, (, and ) operators. Notice there\nis only support for unary operators. Binary operators would be an obvious addition. For exam-\nple, max(x,y).",
      "content_length": 1837,
      "extraction_method": "OCR"
    },
    {
      "page_number": 398,
      "chapter": null,
      "content": "4.10 Programmable Vertex Shader Compiler 409\n\nThe scanner has three sections. The first section, denoted by the {% and %} oper-\nators, includes the C definitions that will be necessary for your scanner. The second\nsection, denoted by the %% at the beginning and end of the segment, includes the\nactual rules that the scanner recognizes, from highest to lowest precedence. The final\nsection, after the last %%, is used to insert any C/C++ code that is needed by the rules.\nTypically, these are functions to look up symbols, functions to handle error control, or\nfunctions that handle error reporting.\n\nTo create a lexical analyzer, or scanner, from the file scanner.l, we use the GNU\ntool flex, which is available at [Streett02]. These are not shipped on the CD-ROM\nand need to be downloaded to compile the example compiler.\n\nParser\n\nThe parser works in conjunction with the scanner to accept or reject a program.\nWhile the scanner recognizes tokens, or symbols, the parser accepts or rejects sets of\nsymbols, or statements. For example, the expression AmbientLight = AmbientMaterial\n* LightAmbO is one statement. It is made of six tokens—the variables, the arithmetic\nsymbols, and the semicolon at the end of the statement. As the scanner scans the sym-\nbols, it first recognizes the string AmbientLight as a new variable, adds it to the sym-\nbol table, and passes it to the parser. The parser can find no statement that consists of\njust a variable name, but it has several that start with the variable name, so it goes\nahead and stores it on a stack of symbols. For this example, assume the stack starts\nempty, and we are only trying to recognize this statement. Next, = is considered.\nAgain, this symbol is placed on the stack. Eventually, the entire expression is recog-\nnized as a set of symbols because it matches one of the statements in the language. In\nthis case, it matches the statement Expr T_PLUS Expr. All of these elements are\npopped off of the stack, and the process begins again with the next statement. If the\nprogram is complete, and we are not left with only the start symbol on the stack, then\nwe know that the program has a syntax problem. Similarly, if we are processing a sym-\nbol combined with a stack that has no opportunity to match any of the rules of the\ngrammar, then the program has a syntax problem, and parsing stops. The start sym-\nbol is assumed to be the first symbol in the grammar description of the parser. In our\nexample grammar file, yaccer.c, the start symbol is Program.\n\nThe parser has three sections that are structured similar to the scanner. First, the\nsection between {% and %} contains C-related data structures that are needed in the\naction section of the grammar. Second, between the pair of %% symbols, is the gram-\nmar. The grammar is the set of statements the parser will recognize. Each statement in\nthe grammar has an action section. An action section is C code that describes what to\ndo if the statement is matched. In other words, if the set of symbols on the stack with\nthe most-recently recognized symbol (or token) matches this statement, then take the\nfollowing actions. In our parser, the action is to simply add this statement to the\nabstract syntax tree, as follows:",
      "content_length": 3230,
      "extraction_method": "OCR"
    },
    {
      "page_number": 399,
      "chapter": null,
      "content": "Section 4 Graphics\n\nExpr: Expr T_PLUS Expr\n{\n\n$$ = new CastNode(\"Expr\");\n\n((CastNode *)$$)->addChildNode(0,(CastNode *)$1);\nCastNode *pNewNode = new CastNode(\"T_ PLUS\");\n\n((CastNode *)$$) ->addChildNode(1,(CastNode *)pNewNode) ;\n((CastNode *)$$) ->addChildNode(2,(CastNode *)$3);\n\n}\n\nIn this example, the first line contains the rule. It says that if two expressions are\nfound with a plus sign in between, then we are to pop these elements off of the stack\nand reduce the stack to the single token, Expr. In addition to this reduction, there are\na set of actions we are to take between the { and } that consist of C code. The $$ refers\nto the left-hand-side token Expr. Each of the subsequent $1, $2, and so forth, refer to\nthe right-hand-side (RHS) tokens from left to right, respectively. Here, we are creat-\ning a new node in our AST and adding children to that node that correspond to the\ntokens on the RHS. The (CastNode *) type cast is necessary because we have declared\neach of these tokens as type void. (For more information, see [Levine92].)\n\nThe preceding description of the scanner and parser are only meant to provide\nyou with enough information for a basic understanding of how these tools are used in\nthe context of the vertex shader compiler. If you are interested in adding symbols,\nchanging their names, or changing their assigned registers, the information presented\nhere should be sufficient. However, any reader interested in doing their own nontriv-\nial modifications to the compiler (adding functionality like type-checking or a more\nsophisticated symbol table) is encouraged to read the how-to manual on Lex and Yacc\n[Streett02]. Another excellent reference is the classic by John Levine [Levine92]. All\nthree should be consulted if you are building your own compiler.\n\nAbstract Syntax Tree\n\nThe abstract syntax tree is the data structure produced by the parser as it validates the\nstatements during parsing. As each statement is determined to be valid, it is added to\nthe AST. When the parsing is complete, the AST is passed to the code generator,\nwhich walks the tree and emits code for each statement in the parse tree. It is consid-\nered an abstract syntax tree because it does not contain all of the syntax elements of\nthe grammar [Aho86]. For example, the semicolons are not stored in the tree because\nthey are not needed to emit the code. In contrast, a concrete syntax tree would keep\nevery token that is parsed.\n\nSymbol Table\n\nThe symbol table stores symbols that are used in the compiler. At startup, it is initial-\nized with all of the keywords and symbols used in the language. As the compiler\nparses the program, new variables are added to the symbol table. If the symbol already\nexists, then a reference to that symbol is recorded in the symbol table (see Table\n4.10.3).",
      "content_length": 2808,
      "extraction_method": "OCR"
    },
    {
      "page_number": 400,
      "chapter": null,
      "content": "ON THE CD\n\n4.10 Programmable Vertex Shader Compiler ; ;\n\n\"Senate REO SN RIN CeO ccc ce\n\n411\n\nTable 4.10.3 A Symbol Table Entry\n\nRegister Pointer\n\nRegister Register Component to next\nName Type Scope Token Type Number (x, y,z,w) Entry\n\"LightDir1\" \"Keyword\" 0 T_STRING eRegTypeConst 37 eRegCompAll NULL\n\nNote: An entry consists of the name of the symbol, the symbol type, its scope, and the token that repre-\nsents the symbol in the scanner. It also contains the register number, type of register, and the specific\n\n’ component of the four-component register once the symbol has been assigned to a register. Finally, we\n\nplace a pointer to the next symbol in the table. An example symbol table is contained in the file CSymbol-\nTable.cpp on the CD-ROM.\n\nTemporary Register Set\n\nFigure 4.10.1 showed that there is a set of temporary registers that we use as our work-\ning set when creating our assembly instructions. We have created a CRegister class\nthat simply marks a register as empty or full. From this class, we construct a CTem-\npRegisterSet class that manages the temporary registers. The types of things we can\ndo to a register are: mark it as full or empty, MarkAsFilled() and MarkAsEmpty();\nrequest a specific register, RequestSpecificReg(); or get the next available register,\nGetNextAvailableTempReg(). This class is used in the code generator.\n\nCode Generation\n\nThe code generator contains the heart of the compiler. The code generator takes in an\nAST that was produced from a correct grammar. It then walks this AST and emits\ncode for each statement it finds. Two alternatives for optimization exist at this point.\nThe first and most obvious is to run different algorithms over the tree; each algorithm\ndoes a different type of optimization. Another would be to output an intermediate-\nlevel language description and run your algorithms on that intermediate language.\nSeveral of these techniques are discussed in [Muchnick97]. The point of this gem is to\nget you started with a working compiler that you can then extend by adding enhance-\nments and optimizations appropriate to your target platform—this is where that cus-\ntomization can begin!\n\nConclusion\n\nTo see the results, compile the example vertex shader compiler with the shader on the\nCD-ROM as input. Now, imagine that you are working on a new shader. Would you\nrather debug the high-level code or the assembly that is generated? There will always\nbe a need to get close to the hardware for certain applications, but having a compiler\nhandy to do the dirty work is probably a better solution in many cases. This compiler\nhas been used to generate shaders successfully for applications using DirectX8. As",
      "content_length": 2674,
      "extraction_method": "OCR"
    },
    {
      "page_number": 401,
      "chapter": null,
      "content": "412 ; Section 4 Graphics\n\nwith all projects, there are plenty of opportunities for improvement, and we welcome\nany contributions that readers would like to make.\n\nAcknowledgments\n\nLLL M EE LL LITER\n\nNone of this work would have been possible without the support of the management\nof the Intel Labs Graphics and 3D Technologies team (G3D). I’m especially grateful\nto Carl Marshall and Stephen Junkins for continuing to push me that little bit further\nto complete the task and rise to the next challenge. Thanks also to Jeff Lander and\nMike Macpherson for reading early drafts and providing feedback.\n\net ue gg HR re RT RRA NSN NES\n\n[Aho86] Aho, Alfred, Ravi Sethi, and Jeffrey D. Ullman, Compilers: Principles, Tech-\nniques, and Tools, Addison Wesley, 1986.\n\n[Lake01] Lake, Adam, “Cartoon Rendering Using Texture Mapping and Programma-\nble Vertex Shaders,” Game Programming Gems 2, Charles River Media, Inc.,\n2001.\n\n[Levine92] Levine, John, Tony Mason, and Doug Brown, Lex and Yacc, O’Reilly and\nAssociates, 1992.\n\n[Moller 02] Méller, Tomas and Eric Haines, Real-Time Rendering, Second Edition,\nA.K. Peters, Ltd., 2002.\n\n[Microsoft00] Microsoft DirectX 8.0 Software Development Kit, available online at\nhttp://www.msdn.microsoft.com/downloads, 20000.\n\n[Microsoft01] Microsoft DirectX 8.1 Software Development Kit, available online at\nhttp://www.msdn.microsoft.com/downloads, 2001.\n\n[Muchnick97] Muchnick, Steven S., Advanced Compiler Design and Implementation,\nMorgan Kaufmann, 1997.\n\n{Olano00] Olano, Marc “Interactive Shading Language, Language Description,”\nCourse Notes on Approaches for Procedural Shading on Graphics Hardware\n(SIGGRAPH 2000).\n\n[Proudfoot01] Proudfoot, Kekoa, William R. Mark, Svetoslav Tzvetkov, and Pat\nHanrahan, “A Real-Time Procedural Shading System for Programmable Graphics\nHardware,” Conference Proceedings (SIGGRAPH 2001).\n\n[Streett02] http://www.monmouth.com/-wstreett/lex-yacc/lex-yacc.html. Flex and\nbison ports to Win32, including source and documentation.\n\n[Upstill89] Upstill, Steve, The Renderman Companion: A Programmer’ Guide to Real-\nistic Computer Graphics, Addison Wesley, 1989.\n\n[Woo099] Woo, Mason, et al., OpenGL Programming Guide, Third Edition, Version\n\n1.2, Addison Wesley, 1999.",
      "content_length": 2226,
      "extraction_method": "OCR"
    },
    {
      "page_number": 402,
      "chapter": null,
      "content": "4.11\n\nBillboard Beams\n\nBrian Hawkins, Seven Studios\nwinterdark@sprynet.com\n\nazzling special effects are a key component to the graphical flair of many games,\n\nand an effect that appears again and again is the laser light beam. Beams are used\nfor everything from spacecraft weaponry to magic spells, and solid beams can also be\nused to create structural elements in buildings.\n\nSeveral methods are available for creating a beam effect, each of which has its own\ndisadvantages. The simplest technique uses multiple spherical billboard sprites along\nthe line of the beam. This can require a large number of sprites to create a small num-\nber of beams, and the visual illusion can break down under numerous conditions,\nsuch as during the production of larger beams. A much more economical technique\nuses only a single rectangle rotated around the axis of the beam to face the camera as\ncompletely as possible. This efficiently produces a convincing beam from the side\nview, but the polygonal nature of the beam be $ apparent as the view approaches\na straight-on perspective.\n\nThese two methods can be combined to create a better method that is both effi-\ncient and maintains visual integrity under most conditions. Two triangles are oriented\ntoward the camera to form the endpoints, and two more triangles form the main\nbeam section. The rest of this gem describes in detail the positioning and texture\nmapping of the triangles to create the illusion of a three-dimensional beam.\n\nMatrices\n\nA billboard matrix is determined for each endpoint, given the camera-to-world\nmatrix, and the two endpoints of the beam. An ordinary billboard matrix for a cam-\nera-oriented sprite uses the same orientation as the camera-to-world matrix with a dif-\nferent position. However, for a beam, the billboard matrices should be oriented along\nthe beam’s screen direction. Therefore, the front vector remains the same as the cam-\nera-to-world matrix, but the up and right vectors must be modified. First, a direc-\ntional vector for the beam is obtained from the two endpoints:\n\nB=B, -B,\n\n413",
      "content_length": 2069,
      "extraction_method": "OCR"
    },
    {
      "page_number": 403,
      "chapter": null,
      "content": "414 so — _— a _Section 4 Graphics\nNext, a directional vector, termed the “eye vector,” from the camera position to\none of the beam endpoints is calculated:\nT\nE= [Mos M3 M,,| ~ Bw\nThen, the cross-product of the eye vector and the beam vector produces a vector\nthat is oriented perpendicular to the beam vector in screen space:\nP=BXxE\nFinally, the normalized cross product of the perpendicular vector and the camera-\nto-world front vector provides the up vector for the billboard matrices:\nT\nF= [Moo Mo M,9|\n_ FXxP\n[Fx P|\nFrom this, the right vector is easy to calculate:\nR=FxU\nNow, the billboard matrices for each endpoint are generated from the orientation\nvectors and the endpoint positions:\nF. U, R, B 1x F. U, R, Bo.\nM, = f U, R, B, and M, = f U, k, B,,\nE, U, R, B lz F, U, R, B 2z\n0 0 0 1 0 0 0 l\nVertices\n\nsmn bin BEARERS BRAM rR ORIN\n\nFigure 4.11.1 shows the two triangles that will form the end caps of the beam,\nwhose radius is specified by S$, once transformed by the appropriate billboard matrix.\nVertices V,, V2, and V; are transformed by Mj, and Vy, V;, and V¢ by M>. Vertices V,,\nV3, V4, and V; can then be used to form the other two triangles that make the beam.\nThe two end triangles will then be camera-oriented, which in turn will cause the other\ntwo triangles to be camera-oriented as well.\n\nA further optimization can be achieved on most modern architectures by passing\nthe triangles as a triangle strip, thus reducing the number of vertices sent per beam\nfrom 12 to 6. For this to work, the vertices are sent in order from V, to V¢, and shared\nvertices must share the same properties. This second requirement is of particular\nimportance when considering texture mapping.\n\nSOARS ASML IMR RE",
      "content_length": 1709,
      "extraction_method": "OCR"
    },
    {
      "page_number": 404,
      "chapter": null,
      "content": "415\n\nV1(0,s,0)\nV2(-s,0,0) V3(s,0,0)\nVa(-s,0,0) Vs(s,0,0)\nVe(0,—-s,0)\n\nFIGURE 4.11.1 Vertex coordinates before transformation.\n\nSSRRERRRAR RS oRREREH AEN RIOR RMN URRRRRERATT SS\n\nFigure 4.11.2 shows the two main texture mapping alternatives that allow for triangle\nstrip creation. Vertices V, to V¢ are matched up with the corresponding texture coor-\ndinates T, to Ts. When choosing which layout to use, consider the tradeoffs between\nthe two options. The first method, shown in Figure 4.11.2a, matches the actual shape\nof the beam better and therefore suffers fewer graphical artifacts. However, the texture\nspace left is broken into two triangles that might be hard to use for other textures. The\nsecond method, presented in Figure 4.11.2b, is more efficient in its use of texture\nspace, but it achieves this by stretching the texture in such a way that visual artifacts\ncould be introduced in the final image. This problem is not seen in most beams, mak-\ning the second method the preferred choice unless a noticeable visual problem is\nencountered.",
      "content_length": 1050,
      "extraction_method": "OCR"
    },
    {
      "page_number": 405,
      "chapter": null,
      "content": "416 Section 4 Graphics\n\nter EN EL NEE\n\ncsbnenesnesieunaine eens wininns och ease OM MRE LR DEAN CH\n\nTe(1,1) T.@,1)\n\nTs(,0.5) T2005) $T:(0.50.5)\n\nT:(,0) ' T0.50)\n\nFIGURE 4.11.2 Example texture layout with texture coordinates.\n\nope RRL\n\nThe algorithm presented here provides a generic method of efficiently rendering\nbeams. The performance could be enhanced by tailoring the algorithm to take advan-\ntage of particular architectural features of the platform that is used, while still main-\ntaining the visual effect desired. Let the fireworks begin.",
      "content_length": 547,
      "extraction_method": "OCR"
    },
    {
      "page_number": 406,
      "chapter": null,
      "content": "4.12\n\n3D Tricks for\nisometric Engines\n\nGreg Snook, Bungie Studios\ngregsn@microsoft.com\n\nfrome engines are one of the last bastions of two-dimensional graphics left in the\ngame industry. While this gem proposes some 3D methods to enhance what is\nessentially a sprite-based display system, it tries to preserve the essence of sprite-based\ngraphics. While you could simply represent a majority of the game objects with 3D\nmodels to get the same visual effect, the ideas presented here maintain the use of\nsprites by adding a few tricks to make them appear as flexible as 3D models. The con-\ncepts may also be useful in other 3D engines as a replacement for flat billboard sprites\nof as a means to represent distant objects at a lower level of detail.\n\nConsider an isometric game engine where each game object is created in some 3D\nmodeling package. The game world itself is divided into rectangular volumes, which we\nwill call “cells.” Each cell is represented in the game by a single 2D image. These images\nare orthographic projections of the cell contents onto a plane placed at the front of the\ncell (see the projected texture created in Figure 4.12.1). Since we view the game through\nan orthogonal camera, rendering the game world is a matter of figuring out which cells\nare onscreen, and then drawing the image of each cell’s contents at the appropriate\nscreen coordinates. There is no scaling or perspective correction needed to display the\ncells, so our 2D cell projections have completely replaced the original 3D models.\n\nTo move into a 3D, perspective-correct environment, we need to add what our\n2D projections are lacking—depth information. This converts our 2D images into\nsomething approaching a voxel representation. We will look at a few methods to ren-\n\nder these depth-enabled images in a 3D setting.\n\nMoving into the Third Dimension |\n\nents\n\nrae.\n\nThe first step in moving into 3D is to change our rendering method. The most com-\nmon way to draw 2D images within a 3D system is through the use of billboards.\nThese are flat pieces of geometry onto which the individual cell images are texture-\nmapped. If one billboard is used for each of the game cell images, and the scene is ren-\ndered through an orthogonal camera, then the display will look nearly identical to the\n\noriginal 2D version. The billboards have become a replacement to the traditional\n\n417",
      "content_length": 2372,
      "extraction_method": "OCR"
    },
    {
      "page_number": 407,
      "chapter": null,
      "content": "418\n\nSection 4 Graphics\n\nCell Volume\n\nAlpha layer ~~\nProjec (Depth)\n\nTexture\n\nFIGURE 4.12.1 An orthogonal projection of the original cell contents creates both the\ntexture image and per-pixel depth information, stored as shades of gray in the alpha\nchannel.\n\ndrawing method, yielding the same result. Using a nonorthogonal camera will handle\nall the distance-related scaling and parallax effects, but will immediately show the bill-\nboard’s lack of depth.\n\nTo create the illusion of depth in the billboards, some volumetric data for each\ntexture must be recorded. Remember that each image placed on the billboard cards is\nintended to represent the objects within a certain volume of space. This is essentially\na projection of the cell’s contents onto a plane. Per-pixel depth information can be\nrecorded, representing the distance from the projection plane to the point of intersec-\ntion with the cell’s contents (see Figure 4.12.1). This per-pixel depth information is\nthe catalyst for each of the three methods presented here for creating a volumetric rep-\nresentation from the billboard image. It also proves useful when calculating per-pixel\nbump-mapping information for the texture—a technique that can be used in tandem\n\nwith any of the methods described here.\n\nMethod 1: The More Billboards the Better\n\nThe elevation map method, first described by Sim Dietrich [Dietrich00], is a tech-\nnique that uses multiple billboards to represent a volume of space. Each billboard is\ntextured with a slice of the cell volume, so that together they approximate the original\ngeometry when stacked facing the camera. Dietrich also showed that all the billboards\nin a cell group can be mapped with a single texture containing depth information for\n\nthe cell within the alpha channel of the texture. Using hardware-enabled alpha test-",
      "content_length": 1824,
      "extraction_method": "OCR"
    },
    {
      "page_number": 408,
      "chapter": null,
      "content": "4.12 3D Tricks for lsometric Engines 419\n\noreeeumoninneneiuneiosbienieasen stesso SaaS AHR\n\nFIGURE 4.12.2 An exploded view of mutltiple-depth slices, texture-mapped on stacked\nbillboards to emulate a solid object.\n\ning, individual depth layers of the cell texture can be drawn on each billboard. This\nallows for the creation of a pseudo-volumetric solid with a few polygons and a single\ntexture (see Figure 4.12.2).\n\nThe desired depth value is placed in the alpha component of each vertex’s diffuse\ncolor. Using a subtraction operation within the texture stage, this value is subtracted\nfrom the alpha channel of the texture sample. The hardware is set up to perform an\nalpha test to reject pixels that are less than zero after the subtraction operation. This\nensures that only those portions of the texture that have a depth value higher than the\nvalue set into the vertex color are drawn.\n\nIn DirectX8, the setup is just a few simple render and texture states:\n\nSetRenderState(D3DRS_ALPHATESTENABLE, TRUE) ;\nSetRenderState(D3DRS_ALPHAREF, 0) ;\nSetRenderState(D3DRS_ALPHAFUNC, D3DCMP_GREATER) ;\n\nSetRenderState(D3DRS_ALPHABLENDENABLE, TRUE) ;\nSetRenderState(D3DRS_SRCBLEND , D3DBLEND_ ONE);\nSetRenderState(D3DRS_DESTBLEND , D3DBLEND_ZERO);\n\nSetTextureStageState(0, D3DTSS_COLORARG1, D3DTA_TEXTURE) ;\nSetTextureStageState(0, D3DTSS COLORARG2, D3DTA_DIFFUSE) ;\nSetTextureStageState(0, D3DTSS COLOROP, D3DTOP_SELECTARG1) ;\n\nSetTextureStageState(0, D3DTSS_ALPHAARG1, D3DTA_TEXTURE) ;\nSetTextureStageState(0, D3DTSS_ALPHAARG2, D3DTA_DIFFUSE) ;\nSetTextureStageState(0, D3DTSS_ALPHAOP, D3DTOP_SUBTRACT) ;",
      "content_length": 1598,
      "extraction_method": "OCR"
    },
    {
      "page_number": 409,
      "chapter": null,
      "content": "420\n\nON THE CD\n\nSection 4 Graphics\n\nDepending on the camera type used to view the scene, it might be necessary to\ndraw the cell from some wide angles. The elevation map holds up quite well in these\nsituations, but might begin to show silhouette artifacts as the viewing direction\napproaches a parallel angle to the billboards. To account for this, additional angled\nbillboards can be added to handle the wider viewing angles. Because the desired depth\nvalue for each billboard is encoded into the diffuse color of its vertices, Gouraud shad-\ning between the vertex colors allows for the slice to occur on just about any angle\nneeded.\n\nAnother drawback of the elevation map technique is that it deals with depth as a\nheight map. Only one height value is used per pixel to define the image volume, giv-\ning the resulting object an extruded appearance when viewed from an angle. To help\nalleviate this problem, a second depth map can be used to define the rear of the\nobject, giving us two values per pixel: one to define the depth value at the front of the\nobject and one to define the back.\n\nThis is created in the same manner as our current depth texture using a camera\nplaced on the opposite side of the cell volume. During rendering, a pixel shader can\nbe used to perform a second subtraction operation, this time using the depth infor-\nmation in the second texture. If both subtraction operations provide a positive result,\nthe point in question is between the front and back depth buffer values, and is output\nto the screen. If either subtraction operation is negative, the point is either in front or\nin back of our object volume and is rejected. The sample application included on the\n\nCD-ROM shows this technique in action.\n\nMethod 2: Warping Textures\n\nWhile not the fastest method for representing a cell’s contents on a billboard, proce-\ndurally warped relief textures do provide the benefit of no additional geometry. What\nthey suffer from is a preprocessing step to warp the billboard texture each time the\nviewing angle changes. Because this can be somewhat costly in terms of performance\nand requires a discrete texture for each cell, it is only useful for unique objects in the\ngame. However, single-instance objects, such as the player’s character or boss mon-\nsters, can get a strong sense of depth from relief textures.\n\nThe notion of relief textures is borrowed from Manuel Oliveira and Gary Bishop,\nwho developed the technique at the University of North Carolina at Chapel Hill\n[Olivera99]. The idea is based on the fact that the texture contains per-pixel depth\ninformation for the cell, which can be reprojected onto the billboard plane to emulate\nanother viewing angle. Given a camera position, each pixel in the texture can be off-\nset to a new position on the texture, given its original texture position and depth\nvalue. The resulting texture, created after all pixels have been offset, describes the cell\ncontents as seen from the position of the viewer (see Figure 4.12.3).\n\nThe trouble is that this is a two-pass operation. Pixels must first be offset along\nthe w axis of the texture, then again along the » axis to locate their final resting place.\nIn the interest of speed, the v-offset operation can often be skipped and still produce",
      "content_length": 3265,
      "extraction_method": "OCR"
    },
    {
      "page_number": 410,
      "chapter": null,
      "content": "4.12 3D Tricks for Isometric Engines 421\n\nON THE CD\n\ndepth value { view vector\n\nbillboard\n\noriginal pixel — offset pixel\n\nFIGURE 4.12.3 Viewed from above, this diagram shows the reprojection of a pixel onto\nthe billboard plane. The offset location is calculated from the original pixels (x, y)\nlocation on the billboard and the depth information encoded into the texture’ alpha\nchannel.\n\na believable result. The nature of most isometric game objects (usually tall, thin enti-\nties such as bipeds) and the screen's aspect ratio help to hide the effects of this cheat.\nIn the sample code provided, only the u offset is performed during the texture warp.\n\nWhen performing the w-offset operation, there is the possibility of holes being\ncreated in the image (locations to which no pixels have been offset), and occlusion\nproblems (locations where more than one pixel offset to the same position) might\noccur. To handle occlusion, the texture must be processed in the direction of the pixel\noffset. This ensures that pixels closer to the camera overwrite those further away. For\nexample, if the billboard is located on the camera's left side, the pixels will be offset to\nthe right. In this case, the texture must be processed from left to right to ensure that\npixels closer to the camera (toward the right of the image) overwrite those further\naway. If the billboard is to the right of the camera, the opposite is true, and the texture\nmust be processed in right-to-left order. In the worst case, where the billboard strad-\ndles the camera's view vector, the texture must be processed in both directions,\noccluding toward the center.\n\nHoles are created when two adjacent pixels in the original texture map to two\nnonadjacent positions after the warp is performed. In these cases, the desired view of\nthe object is from an angle not accounted for in the original orthographic projection\nof the depth values. A suitable result can still be obtained by performing a blend\nbetween the two separated pixels to fill the gap.\n\nThe final result yields a texture that is properly warped for the given viewing\nangle. This texture can then be mapped directly on the billboard for display. The sam-\nple program provided on the CD-ROM shows this technique in action.",
      "content_length": 2250,
      "extraction_method": "OCR"
    },
    {
      "page_number": 411,
      "chapter": null,
      "content": "422\n\nSection 4 Graphics\n\nMethod 3: Vertically Interlaced Textures\n\nThe final method presented here builds off of the relief textures used earlier. Using the\nprogrammable pixel shaders in Direct X8 (or greater) on suitable hardware, a blend\nbetween prewarped versions of our texture can be performed during rendering. This\nwill emulate various viewing angles.\n\nThink of the texture mapped across the billboard as a sheet of paper riddled with\npinholes, through which the cell contents can be seen. Each texel is a pinhole, and the\ncolor placed there is what is seen though the hole. What the relief textures do, in a\nsense, is compute what would be seen through the pinholes at various angles.\n\nIn this final method, a texture is created that contains four views of the cell con-\ntents interlaced as vertical strips. Using a pixel shader and a second utility texture, the\ninterlaced strips are blended on the GPU. This provides nearly the same quality as the\nrelief texture method, without the need for a procedural texture warp. The downside\nis that some texture resolution is lost along the x-axis of the texture in order to pack in\nthe various image samples. For every pixel in the original image, there must instead be\na horizontal sample set of four pixels, one for each viewing angle. This method can\nalso extend into the v-axis of the texture, but at the cost of more texture resolution\n(see Figure 4.12.4).\n\nThe pixel shader is built around the bump environment map instruction\n(texbem). It works in two basic steps. First, it converts the incoming (u,v) coordi-\nnates, pointing them to the start of the desired sample set. Second, it offsets the new\nu coordinate to the desired viewing angle within that set, using the texbem instruc-\ntion. The result is a per-pixel blend between two of our four viewing angles, packed\ninto the texture.\n\nThe first step of the shader uses the utility texture mentioned earlier. This texture\ncontains a lookup table that converts our incoming wv coordinate pair to the start of\n\nTextureA TextureB  TextureC —‘Textu\nFIGURE 4.12.4 The interlaced texture is created by sampling identical pixel locations in\nthe source textures and organizing them into sample sets of four pixels each.",
      "content_length": 2222,
      "extraction_method": "OCR"
    },
    {
      "page_number": 412,
      "chapter": null,
      "content": "4.12 3D Tricks for Isometric Engines\n\nON THE CD\n\nReferences\n\n423\n\nthe sample set in the second texture. This texture should be the same width as the\ninterlaced texture and is filled with the value (w*4) for every pixel on the w-axis. If the\nbillboard is given texture coordinates along u from 0.00 through 0.25, then the utility\ntexture will convert the incoming value to the range [0.0, 1.0] in steps that are equiv-\nalent to a four-pixel span within the interlaced texture. This forces each incoming tex-\nture coordinate to point to the start of our four-pixel sample set.\n\nThe second step is to offset this value to select the desired pixel within the sample\nset. This offset value is in the range [0.0, four_pixel_span], which can be calculated in\na vertex shader and written into a second set of uv coordinates for each vertex. The\nfour_pixel_span value is the width, in texture space, of four pixels. This can be calcu-\nlated as 4 divided by the width of the image in pixels.\n\nFinally, the texbem instruction performs the offset from the start of the sample set\nto the desired sample within, resulting in a per-pixel blend of the two closest camera\nviews. Source code on the CD-ROM shows the implementation details of both the\nvertex and pixel shader. Also, Color Plate 8 shows three methods of generating\npsuedo-3D images from a 2D image source.\n\ncena AANA RNR NNR ROUT\n\nWhile no billboard method can fully replace a complex 3D model, these techniques\ndemonstrate that prerendered images can still be used in a 3D environment with great\neffect. With some careful content creation, it is certainly possible to create an object\nthat is nearly indistinguishable from the original model. Whether you wish to update\nan isometric sprite engine or need an easy way to bring more objects into your 3D\nworld, we hope these ideas will prove useful.\n\n[Dietrich00] Dietrich, Sim, “Elevation Maps,” available online at Nvidia's developer-\n\nsupport Web site: http://developer.nvidia.com/docs/IO/1334/ATT/Elevation-\nMaps2.doc, January 2000.\n\n[Olivera99] Olivera, Manuel M. and Gary Bishop, “Relief Textures,” available online\nat UNC's Image-Based Rendering Web page: http://www.cs.unc.edu/~ibr/pro-\njects/RT/RT.html, April 1999.",
      "content_length": 2220,
      "extraction_method": "OCR"
    },
    {
      "page_number": 413,
      "chapter": null,
      "content": "4.13\n\nCurvature Simulation Using\nNormal Maps\n\nOscar Blasco, Aside Software\noscar@asidesoft.com\n\noday’s in-game models are still far from being realistic. Prelit textures are the com-\n\nmon way to simulate curvature using low-detail models. Nevertheless, current\nhardware is now capable of calculating per-pixel lighting equations (both the com-\nmon and not-so-common). This gem explains how to perturb the normals on a sur-\nface to simulate the curvature of a denser model by using bump mapping. We will\nenhance the visual quality without losing speed or having to abandon more-tradi-\ntional ways of adding detail (e.g., handmade bumps; see Figure 4.13.1 and Color\nPlate 9).\n\nFIGURE 4.13.1 Result of the bump-mapping process. Left to right: The low-resolution model, the\noriginal model, and two examples of the final result using bump mapping.\n\n424",
      "content_length": 847,
      "extraction_method": "OCR"
    },
    {
      "page_number": 414,
      "chapter": null,
      "content": "4. 130 Curvation Simulation Using Normal Maps 425\n\nNormal Maps\n\nBump mapping is a per-pixel process that disturbs the intensity of the light at the cur-\nrent point. This means that we can lighten or darken the pixel that is being rendered.\nIn other words, we can compute the lighting equation on a per-pixel basis rather than\non a per-vertex basis. Equation 4.13.1 shows a simple and common lighting equation\nwith a specular component:\n\ncolor = (n . !) - Surface _ Color + (n . by (4.13.1)\n\nSHURA RRR:\n\none teecRNRSID\n\nIn our case, 7 is stored as a texel in a texture (the coordinates of the vector codi-\nfied as an RGB color), which is called a normal map. The hardware is responsible for\ncalculating the dot product between 7 and / (the same for » dot 4), and then uses the\nresult as a modulation factor for the surface color. Note that / is transformed to local\nspace, and the dot product is done in texture space (more on this later).\n\nOverview of the Process\n\nso or a NR a A NNR\n\nThe curvature simulation algorithm presents a general scheme for obtaining the detail\nof a dense model so that it can be used on a lower-resolution model for real-time ren-\ndering. By modulating the lighting across the low-resolution model surface, we will\nsimulate the captured detail.\n\nThe first model is a dense mesh, which is modeled as if it were going to be used\nfor nonreal-time rendering. A second, similar model has a more reasonable number of\ntriangles to be used for rendering at interactive rates. It also has uv coordinates for tex-\nturing. The low-resolution model does not need to be a simplified version of the\ndense one, which is why this technique is a viable solution. It allows the modeler to\nmodify the low-resolution mesh to fix problems or to simply use another mesh with\nno direct relationship.\n\nAs we said, our objective is to store the detail that is not present in the low-reso-\nlution mesh into a normal map. This is done by capturing the curvature of the origi-\nnal model while taking into account that our low-resolution mesh has a curvature of\nits own. This curvature is defined by the normals on the dense model, so we need to\ncapture those normals and store them into a map.\n\nAt runtime, the generated texture will perturb the normal for each point on the\nlow-resolution mesh. This changes the dot products in the lighting equation (Equa-\ntion 4.13.1) and produces the simulation of curvature. Each texel is perturbed to\nmake the surface seem like the original object at that point (note that our normal map\nmust have a finite size). The algorithm can be outlined as follows:\n\n* Preprocessing\n¢ Computing the map\n¢ Post-processing",
      "content_length": 2648,
      "extraction_method": "OCR"
    },
    {
      "page_number": 415,
      "chapter": null,
      "content": "426 Section 4 Graphics\n\nComputing the map requires:\n\n¢ Rasterizing each polygon into the map (using the uv coordinates of each vertex).\n* Calculating the perturbed normal at each texel.\n\nPreparing Our Data\n\nERRNO tC RR PORES RRA\n\nWe will need some data before starting:\nFor the high-resolution model:\n\n¢ Normals at each vertex, which are smooth across the model.\n\nFor the low-resolution model:\n\ne A tangent-space basis at each vertex (smooth tangent, binormal, and normal)\n¢ The wv texture coordinates of vertices\n\nThe tangent-space bases are needed to transform the computed normals into tex-\nture space.\n\nIt is easy to see why the object has to be uv mapped; otherwise we would not\nknow how to map the low-resolution mesh map to the texture. (See “Known Issues”\nto explore the common problems related to uv coordinates.)\n\nCasting Rays\n\nNow let’s discuss how to calculate the perturbed normal at each texel. Since the two\nmeshes do not share vertices, we have to shoot rays from the low-resolution mesh sur-\nface and check where they intersect with the dense model.\n\nSander, et al. [Sander] discuss about two ways to choose the direction of the rays.\nThe first and easiest way is to use the normal of the current face (closest-point). A sec-\nond way requires interpolation of the normals along the surface to use as the direc-\ntions (normal-shooting).\n\nAs you can see in Figure 4.13.2, normal-shooting parameterization leads to better\nresults, while closest-point produces more discontinuities.\n\nSR RRND RRR TARR,\n\nClosest-Point Normal-Shooting\n\nhigh resolution model\na ~~\n»\n\nx\nN _W\n\nN\n-\n\nlow resolution model\nFIGURE 4.13.2 Rays traced using closest-point and normal-shooting.",
      "content_length": 1677,
      "extraction_method": "OCR"
    },
    {
      "page_number": 416,
      "chapter": null,
      "content": "427\n\n4.13 Curvation Simulation Using Normal Maps\n\nFor each ray, once we have shot the ray and obtained the point of intersection\nwith the dense model, the normal at that point is computed using the barycentric\ncoordinates within the triangle.\n\nBarycentric coordinates are an easy way to define a point inside a triangle. Let P\nbe our intersection point defined in object space, and v,, v,, and v, will be the vertices\nof the triangle. We can calculate them as follows:\n\n_ lea-a)r Pa) (4.13.2)\n\n(4.13.3)\n\nw =1-(u+2) (4.13.4)\n\nThe barycentric coordinates are relative to the areas of the subtriangles defined by\nthe intersection point and the triangle vertices (Figure 4.13.3).\n\nThey are useful for collision checking because any property defined per-vertex\ncan be interpolated using u, v, and w. For example, the intersection point is defined\nas:\n\n(4.13.5)\n\nP=u-ytv-ytw-d,\n\nThe steps that we have covered in this section are: First, for each point on the\nlower-resolution mesh, shoot a ray along the interpolated normal and obtain the\nintersection point in a triangle of the high-resolution model. Second, compute its\nbarycentric coordinates so we can interpolate the normal of the high-resolution mesh\nat that point. As you can see, we now have what we are looking for—a normal vector.\nNow we must store it into the normal map.\n\nV2\n\nYo Vy\nFIGURE 4.13.3 Barycentric coordinates are relative to the area of each subtriangle.",
      "content_length": 1422,
      "extraction_method": "OCR"
    },
    {
      "page_number": 417,
      "chapter": null,
      "content": "428 Section 4 Graphics\n\nsome nenn ondnoloe gla RaINaaeineiuReNSiGrNaRNanineaeaenncots art titrboBbMe nana mame nRRALNE ANN KRaALASI DBE ZT Bes pb BEN neckkeSiter osteo neieakicnetiekineneBhAOBIHIAAEIDESAMWBEEKDDEENKADDEMINRE EIA\n\nFIGURE 4.13.4 The captured normal (H) is converted to texture space (H’).\n\nGetting the Detail\n\nce HE Ha TR RU NORE tee ASH RIAN RGN RS ANNA\n\nSince we chose to evaluate the lighting j in texture space, a transformation of space is\nneeded to use the captured normal (see Figure 4.13.4).\n\nThe tangent, binormal, and normal at any point on the surface form a matrix\n(Equation 4.13.6), which is a transformation from model space into texture space.\n(Equation 4.13.7 is the transformed normal.) T, B, and Nare also called the tangent\nspace basis (Lengyel01].\n\nT Tx Ty Tz\n\nM=|B |=)Bx By Bz (4.13.6)\nN Nx Ny Nz\nx Tx Ty Tz Hx\nH'=|y|=|Bx By Bz lel Hy (4.13.7)\nz Nx Ny Nz Hz\n-Processing\n\nAfter computing the normal rr map, it will still have many empty regions. During ras-\nterization, texture filtering will alter the normals we use, due to these gaps in the nor-\nmal map. We solve this by filling the normal map with a light blue color—RGB (127,\n127, 255) or vector (0.0, 0.0, 1.0).",
      "content_length": 1203,
      "extraction_method": "OCR"
    },
    {
      "page_number": 418,
      "chapter": null,
      "content": "4.13 Curvation Simulation Using Normal Maps 429\n\nThe blue color is often sufficient, but we can do something else to achieve better\nresults. With an edge-expansion filter, we Can expand the colors of the polygon edges\nin the texture. This will fix any hardware filtering issues.\n\nSave your texture using an image format that does not alter the texels. For exam-\nple, JPEG is not a good idea, since it uses a lossy compression algorithm that denor-\nmalizes the normals.\n\nKnown Issues\n\nLLL AL ALLL LAT TL ATT ES RI BOSRO AR RCT EROTO TIS LOLS ° ePhoaeies\n\nThere are two reasons for problems that we might encounter when using the ray-trac-\ning scheme presented here. One is the uv-coordinates, and the other one relates to\nmissed rays or incorrect intersections.\n\nIf the models have significant differences (e.g., a ray intersects the surface of the\ndense mesh twice), we will get wrong normals. It is important to instruct the model-\nets to avoid such situations (see Figure 4.13.5).\n\nAs for #v coordinates, there are two major problems that need to be addressed:\n\n° Discontinuities in the tangent space bases. This problem is common to any bump\nmapping that computes the lighting in texture space. Doing the lighting in tex-\nture space allows us to change the geometry and still use the same normal map.\nThe problem is that due to the uv mapping, the tangent space bases are not\nsmooth along the model surface, which produces discontinuities in the light vec-\ntor. Doing the lighting in model space completely avoids the problem; although\n\nhigh-resolution model\n\nlow-resolution model\n\nFIGURE 4.13.5 The ray-casting algorithm does not know which intersections are incorrect.",
      "content_length": 1673,
      "extraction_method": "OCR"
    },
    {
      "page_number": 419,
      "chapter": null,
      "content": "430 Section 4 Graphics\n\natisieiosoooiianteeseee nie kaeinneteargtOnr sii RORA PENCE O/B OEE ERNEED REA ee te EMO\n\nit has a counterpart: If the normals were defined in model space, we would need\nto change them each time the geometry is deformed. However, you can transform\nthe light into the new space defined by the deformed geometry to solve the prob-\nlem. In any event, this all depends on the engine design and quality desired.\n\n° Incorrect mapping. The algorithm has a huge dependency on uv coordinates. The\nobject needs to be well mapped in order to avoid strange results.\n\nAnother Approach\n\n_SaaRUR ae HNERERURRAR ARRREMRU NS RARER RT ANNOTATE IKON\n\nIt is interesting to talk about other approaches for computing the normal map, par-\nticularly when the models have spatial similarities. We will consider that the low-\nresolution mesh was obtained directly from the dense one using some simplification\nalgorithm, and that this algorithm only used the vertices from the original model.\nMoreover, the original model was already uv mapped, or it was added using some\nscheme. With those conditions, we can easily make a direct relationship between the\nmodels for each texel, since they have common vertices (the same 4 coordinate and v\ncoordinate).\n\nThis scheme can be simplified if we do not transform the normals into texture\nspace. Since this is exactly the same as drawing the normals of the dense model\ndirectly to the normal map, we can implement this scheme using 3D hardware raster-\nization. This is very useful if we are able to uv map the model.\n\nConclusion\n\neR\n\nKENSAL LITERATE RL NRA CONNER\n\nThis gem strives to make the algorithm presented as general as possible, though gen-\neralization also implies less accuracy and less speed. By ‘general,’ we mean it does not\ndepend on any relationship between the models. The exact goal was to make an\napproach, which allows the artist to modify the vertices of the low-resolution mesh.\nOther algorithms used to extract the original curvature depend on the fact that the\nmodels share vertices (and their properties, like uv coordinates). A simplification algo-\nrithm that uses edge collapses is often used to obtain the low-resolution mesh from\nthe dense model. The disadvantages of this are obvious: Simplification tends to create\nfaces with no uniform size, and the mesh is hard to unwrap (map with uv coordi-\nnates). Also, if the original objects were already uv mapped, the mapping usually gets\ncorrupted. Nevertheless, there are cases in which you might want to use this.\n\nAfter generating the normal map, we can still add hand-made bumps for small\ndetails; in fact, it is actually desirable to do so. Modeling such details in a dense mesh\nis hard and completely inefficient. The ray tracing will not be able to get the same\nprecision as if we were to add it with hand-made bumps. They can be added to the\ngenerated normal map with simple normal-map combiner code; only a perturbation\nof the normal stored in the texture is needed.",
      "content_length": 2990,
      "extraction_method": "OCR"
    },
    {
      "page_number": 420,
      "chapter": null,
      "content": "4.13 Curvation Simulation Using Normal Maps 431\n\nFIGURE 4.13.6 Example of a perturbed sphere. The top two images are the original\nobject, the bottom two are the final result using the algorithm.\n\nAcknowledgments\n\nom SRLS IRE ra NN rs ORRIN RSE ARR aS SAR oR RRR enn eA STANCE IRCNS\n\nI would like to thank Julio Cesar Espada for all the models he created (especially for\nthe head in Figure 4.13.1) and for his feedback in using and testing this technique. I\nwould also like to thank Ignacio Castafio for his comments and support.\n\nReferences\n\n‘santo cae aa aR RNIN He RR\n\n[Ebert] Ebert, David S., et al., “Texturing and Modeling: A Procedural Approach,”\n(SIGGRAPH).\n\n[Kilgard] Kilgard, Mark J., “A Practical and Robust Bump-Mapping Technique for\nToday's GPUs,” paper available online at nVIDIA site: http://developer.nvidia\n.com/docs/IO/1329/ATT/bumpmap. pdf.\n\n[Lengyel01] Lengyel, Eric, Mathematics for 3D Game Programming & Computer\nGraphics, Charles River Media, 2001.\n\n[Sander] Sander, Pedro V., et al., “Silhouette Clipping,” SIGGRAPH 2000 Proceed-\nings: pp. 327-334. Available online at http://research.microsoft.com/~hoppe/.\n\nRU HE TR a NPA",
      "content_length": 1146,
      "extraction_method": "OCR"
    },
    {
      "page_number": 421,
      "chapter": null,
      "content": "432\n\nSection 4 Graphics\n\n[Watt92] Watt, Alan H. and Mark Watt, Advanced Animation and Rendering Tech-\nniques, Addison Wesley, 1992.\n\n[Wynn] Wynn, Chris, “Implementing Bump-Mapping Using Register Combiners,”\navailable online at nVIDIA site: hep developer avdia com/ docs 10/1273/\n\nATT/BumpMapping WithRegisterCombiners.pdf.",
      "content_length": 322,
      "extraction_method": "OCR"
    },
    {
      "page_number": 422,
      "chapter": null,
      "content": "4.14\n\nMethods for Dynamic,\nPhotorealistic Terrain Lighting\n\nNaty Hoffman and Kenny Mitchell,\nWestwood Studios,\n\nnaty@westwood.com,\nkmitchell@westwood.com\n\nurrent rendering technologies enable us to include expansive and detailed out-\n\ndoor scenes in our games, using large numbers of triangles. However, an impor-\ntant part of the visual complexity and appeal of an outdoor scene is due to its lighting,\nnot just its geometry. If the lighting is static, it is simple enough to precompute a\nhigh-quality lighting solution—but what should we do when the lighting changes\ndynamically? This gem will present several methods for producing high-quality, phys-\nically based lighting solutions for terrain under dynamic lighting conditions.\n\nlight correctly. Light is electromagnetic radiation in the\nvisible portion of the spectrum (about 400-700 nm). The most common metric for\nlight is radiance, or light flux along a ray. To understand how radiance is defined, visu-\nalize a small square (area A) centered on the light ray and perpendicular to it (see Fig-\nure 4.14.1a).\n\n(A) (B)\nFIGURE 4.14.1 (A-B) Radiance area A along a light ray and patch Aon the radiance sphere.\n\n433",
      "content_length": 1169,
      "extraction_method": "OCR"
    },
    {
      "page_number": 423,
      "chapter": null,
      "content": "434\n\nSection 4 Graphics\n\nLight energy continuously passes through this square in all directions and fre-\nquencies. In RGB space, this energy (and any quantity derived from it) is specified as\nthree numbers. This can roughly be thought of as dividing it into three ‘buckets,’\nbased on frequency. At a given point in time, we measure the rate of energy over time\n(light power or radiant flux ®). The amount of flux going through the square depends\non the size of the square, and doesn’t really indicate the amount of light along the ray.\nWe can measure the flux per area at the intersection point p (M = d® / dA, or power\nper area, measured in watts per square meter). However, M includes light going in all\ndirections, not just along the ray—we need to take direction into account. In Figure\n4.14.1b, we see a sphere (radius R) centered on p, and a small patch (area A’) on this\nsphere surrounding the ray. A part of M (which we will call AZ‘) goes through this\npatch—/M' does not depend on the radius of the sphere, but only on the part of the\nsphere’s area covered by the patch. This represents a range of directions and is called a\nsolid angle (w = A' / R, measured in steradians). The quantity of light along the ray is\nthe radiance (ZL = dM' / dw, measured in watts per meter squared per steradian). Radi-\nance is power per projected area per solid angle—the projected area being measured\nperpendicularly to the ray. If we use an area that is at an angle to the ray (e.g., when\nlooking at light reflected from a surface), then a correction factor equal to the dot\nproduct between the surface normal and the ray is needed.\n\nIn outdoor scenes, radiance can vary by six orders of magnitude [Debevec98], but\nmost hardware limits us to a small range of light values. In this gem, we will compress\nall light values into the [0, 1] range. A related issue is the nonlinear relationship\nbetween pixel values and display radiance. The human visual response to light intro-\nduces other issues. We have chosen to ignore these problems and deal only with linear\nradiance values.\n\nAnother important quantity used in measuring light is the irradiance, E. This is\nsimilar to the flux per area, M above (with the same units), except that instead of mea-\nsuring the total of all the outgoing light at a point, it measures the total incident\n(incoming) light. Since this is measured at a surface, the incoming radiance at a point\npis integrated over a hemisphere H(p) that is centered on the surface normal N(p):\n\nE(p)= | 1,(p-V)N(p): Var (4.14.1)\n\nVeH(p)\n\nHere, V is an outgoing unit vector in the hemisphere H(p), L,(p, —V) is the inci-\ndent radiance at p from —V, and dQ is the differential solid angle used for integration.\nThe dot product is the projected area correction factor.\n\nIn this gem, we deal only with Lambertian (diffuse) terrain surfaces. For such sur-\nfaces, the outgoing radiance L, is the same in all directions and is equal to the irradi-\nance multiplied by the color C(p) divided by m:\n\nL,(2) = ov) E(p) (4.14.2)",
      "content_length": 3019,
      "extraction_method": "OCR"
    },
    {
      "page_number": 424,
      "chapter": null,
      "content": "4.14 Methods for Dynamic, Photorealistic Terrain Lighting © 435\n\n\"ease eniesuunusbonuutesateante xi npisieieeineeeoiiesonieaeatderrasdsn eed doceteecombneetse ASAE SSCS SUSAN (He AORN RNHRanoRsoB ooo DEnNHUD RRB EREDAR ENBEUNEN\n\nThe color is an RGB triple, in which each value is between 0 and 1. A color of 0\nreflects none of the incoming energy in the relevant band of frequencies, and 1 reflects\nall of it.\n\nThe problem we are trying to solve here is the calculation of L,(p) for all the\npoints on a heightfield terrain (at a finite resolution) under changing lighting condi-\ntions. Since the terrain is Lambertian, and we assume that C(p) is known, this is\nequivalent to calculating F(p). For this, we need to know the incoming radiances from\nall directions in H(p). These directions are divided into three groups: those from\nwhich the sun is visible, those from which the sky is visible, and those from which\nother terrain points are visible. We assume that certain data is available at each\nmoment in time: the sun’s position, angular size, and radiance. We might also want\ninformation about cloud positions, and other data. Note also that the sky’s radiance\nmight vary over different parts of the sky.\n\nNow, the directions in which other terrain points are visible pose a difficult prob-\nlem. In order to know the incoming radiance for these directions, we need to first\nknow the outgoing radiance for other terrain points. If the radiance and positions of\nthe sun and sky were static, we could use an iterative algorithm such as radiosity to\nprecalculate a solution, but this is not practical in the dynamic case.\n\nA A Taxonomy of Solutions\n\noT EN SRA HORRENAS RES BSS SM OMAN ARTE TERRERNTRRERARRS\n\nWe will present a range of techniques to solve the radiance calculations. These tech-\nniques will differ in the amount of precalculation and storage needed for the results,\ntheir limitations and assumptions, and how well the outcomes approximate the cor-\nrect results. Most of them require too much precalculation to be usable with\ndeformable terrain (we will note the exceptions). Since there are two sources of\nlight—sun and sky—we can split the problem into a ‘sunlight-only’ subproblem and\na ‘skylight-only’ subproblem. Most of these techniques solve only one of these sub-\nproblems, in which case two techniques must be used and the resulting radiances\nsummed.\n\nSome of these solutions involve calculating light values on the CPU and upload-\ning light maps to the graphics card. In this case, care must be taken so that the CPU\nand bandwidth consumptions are not too high. Since lighting values usually change\nslowly, we can amortize the update over multiple frames. We experimented with mul-\ntithreading for a while; however, we ended up with a single-threaded, double-buffer-\ning scheme that calculated and uploaded chunks of an active texture while using the\nprevious texture for rendering. When the active texture was complete, we swapped\nthe active and rendering texture and started again.",
      "content_length": 3007,
      "extraction_method": "OCR"
    },
    {
      "page_number": 425,
      "chapter": null,
      "content": "436 Section 4 Graphics\n\n_eeekmarteneeonenmmeibocasinnmennn sige! OI KTM heneecRmcRDSRINENE OHNO tt tra theta SESH issbtetetraoroeeet nanan psec eoeansahiecenrmetas\n\nSunlight: Horizon Angles,\nShadow Ellipses, and PTM\n\nNNN EG : aR\n\n‘sats efeciniauamen natin At tet cea NNN\n\nThe solutions in this section solve the ‘sunlight-only’ subproblem. Most of the solu-\ntions to this subproblem ignore light reflected from other terrain points. Our experi-\nence has shown that as long as inter-reflections are taken into account in the skylight\nsubproblem, the results are acceptable. That said, it is preferable to take sunlight\ninter-reflections into account if possible, and we will show one technique that does so.\nWithout inter-reflections, the sun’s contribution to the irradiance at p is\n\nEx(?)= J Lan N(p): Vea (4.14.3)\n\nVeSN H(p)\n\nwhere S is the set of directions that point at the sun. Since the sun’s solid angle, @,,,,\nis small, then we can assume that the result of the dot product is constant, and we get\n\nEan(P) = Opn(P)@sunZainN (2) * Veun (4.14.4)\n\nwhere V,,,, is the direction to the sun’s center and O,,,(p) the percentage of the sun\nthat is outside H(p) or otherwise occluded at p. The two quantities, which vary\nbetween terrain points, are the dot product and the occlusion factor. To reduce the\ncost of calculating the dot product, we quantized the normals of all the terrain points\ninto a 256-entry normal table in a preprocessing stage. Then, for each frame, we cal-\nculated the dot product between each entry in the table and the current sun vector.\nThis reduced the dot product calculation for each point to a simple table lookup.\nAnother possibility is to use a normal map and dot3 texture blending in hardware.\n\nThere are several methods for calculating the occlusion factor. One of these meth-\nods uses horizon mapping, which was introduced by Max in [Max88]. This idea is\nbased on storing the horizon angles for each point in a given set of directions (see Fig-\nure 4.14.2a). If the sun motion is restricted to an arc that passes through the zenith,\nthen two horizon angles suffice. Given this information, determining whether a point\nis in shadow or not is simply a matter of comparing the angle of the sun to the horizon\nangle in that direction. If the sun angle @ is below the horizon angle g, the point is in\nshadow (0O,,,,(p) = 0). Otherwise, it is not (O,,,,(p) = 1). Soft shadows can be supported\nby tracking two angles for the sun (8,,, and O,or0m> the angles to the sun’s top and bot-\ntom) and comparing both to the horizon angle. If p 2 0,,,, then O,,,(p) = 0. If 9 S$ 4...\ntom then Osun(p) = 1. If Oop > P > Ahorrom> then Osin(P) = (Arop -— P) / 1, where OF is the\nangular diameter of the sun. We have had good results with storing the horizon angles\nas 16-bit fixed-point numbers and doing the calculations on the CPU, as well as stor-\ning them in 8-bit texture channels and performing the calculations in a pixel shader.\nFor efficiency, the direction along which the horizon angles are defined should corre-\nspond to rows in the heightfield array. This will help when calculating horizon angles.\nYou should scan along the heightfield to a fair distance on each side, since hills can cast\nquite long shadows when the sun is at oblique angles. Note that horizon angles must\nalways be clamped to H(p), or errors will result (see Figure 4.14.2b.).",
      "content_length": 3374,
      "extraction_method": "OCR"
    },
    {
      "page_number": 426,
      "chapter": null,
      "content": "4.14 Methods for Dynamic, Photorealistic Terrain Lighting 437\n\n(B)\n\nFIGURE 4.14.2 (A) Terrain profile showing sun angle ® and horizon angle @. (B)\nHorizon angles must be clamped to H(p).\n\nOf all the sunlight methods, horizon mapping requires the least amount of pre-\nprocessing. It would be possible to handle occasional local changes to the heightfield\n(such as small craters) by recalculating the horizon maps in the affected area and to\nsome distance on both sides.\n\nOcclusion can also be calculated using shadow ellipses, introduced in [Hei-\ndrich00). Here an ellipse is fitted to the set of visible angles from each point. This\nellipse is parameterized using six numbers, which can be stored in two RGB texture\nmaps. Software, register combiners, or pixel shaders can then be used to evaluate sun\nocclusion for each point. This method cannot do soft shadows easily. Its main advan-\ntage over horizon angles is that it can handle arbitrary sun positions. (See [Hei-\ndrich00] for details and [Kautz00] for implementation details using hardware under\nOpenGL.)",
      "content_length": 1061,
      "extraction_method": "OCR"
    },
    {
      "page_number": 427,
      "chapter": null,
      "content": "438 . Section 4 Graphics\n\nPolynomial texture maps (PTMs), introduced in [Malzbender01], can also be\nused for evaluating sunlight. This is one of the few techniques that can handle terrain\ninter-reflections for sunlight. To create a terrain PTM, first render a series of N images\nof the terrain using a radiosity package, with the sun at several different positions. The\nsun does not need to move in an arc through the zenith as it does in horizon mapping,\nbut it does need to be restricted to a one-dimensional arc. Use a sun color of\nRGB(1,1,1). Then process the resulting NV images into a single PTM. The first step is\nto separate the color and luminance values for each image. Then, fit a quadratic uni-\nvariate polynomial (apx* + a)x + az) to the N luminance values for each pixel, with the\nsun’s position along its arc as the variable. Finally, generate two RGB textures: One\nstores one color value per pixel (by averaging across all images), and the other stores\nthe three coefficients of the per-pixel luminance polynomials. At runtime, the poly-\nnomials are evaluated with the current sun position, either in software or in a pixel\nshader. The result is combined with the color value and modulated with the current\nsun color. (More details on PTMs are in [Malzbender01], and tools for implementing\nthem are available in the download section of the associated Web site. Note that the\npaper deals mostly with bivariate polynomials requiring six coefficients, which is more\ncomplex and expensive than is needed for the purposes of this gem.)\n\nIf lighting conditions depend only on a single variable (like the time of day), it is\npossible to use PTMs to get the full lighting solution. In this case, a separate polyno-\nmial will probably need to be stored for each R, G, and B channel to capture the color\nvariations, requiring nine values per pixel instead of six (three + an RGB color).\n\nSkylight: Radiosity Approximations and Patches\n\n_SegReehaeRStaee aRRRRSeeRaRC enti sin EeRR sete ENN RR\n\nThe solutions in this section solve the ‘skylight-only’ subproblem. First, we will han-\ndle the case where the entire sky is assumed to have the same radiance. This approxi-\nmation is not as bad as it would seem. We have used it with good results. In this case,\nall we need to do is calculate the lighting for our terrain with a sky radiance equal to\nRGB(I,1,1), and then store the result in a RGB texture. At runtime, we multiply this\ntexture with the current RGB sky radiance to get the desired result. The color in the\ntexture will be relatively subtle, since it will result from inter-reflections with the col-\nored terrain. If space is at a premium, the texture could be converted to 8 bit-per-pixel\ngrayscale with a small loss in quality.\n\nIf precalculation time and space are not a problem, then the best way to generate\nthe skylight texture is to use a radiosity package, with the terrain and a hemispherical\ndistributed light source as input. If this is not practical (for time or space reasons, or\nbecause the terrain might change), then there is a useful approximation that can gen-\nerate a very similar result in far less time. Stewart and Langer found in [Stewart97]\nthat in a scene lit by a diffuse hemispherical illuminator, a point p tends to ‘see’ other\npoints in the scene that have a similar radiance value. So, we can assume that for all V\nin H(p), where another terrain point is visible, L;(p, -V) = L,(p). Stewart and Langer\nshowed that the error introduced by this approximation is small. The significance of",
      "content_length": 3530,
      "extraction_method": "OCR"
    },
    {
      "page_number": 428,
      "chapter": null,
      "content": "4.14 Methods for Dynamic, Photorealistic Terrain Lighting 439\n\nthis is that it breaks the interdependence between different terrain points, enabling us\nto derive a closed-form expression for E(p). Stewart and Langer have derived a closed\nform using horizon angles to determine which directions are covered by terrain. Their\nformulation uses any number of horizon angles. We have had good results with eight\n(which is a convenient number for computation, since it corresponds to the rows,\ncolumns, and diagonals of the heightfield array). Assuming there are eight horizon\nangles (measured from the vertical, and not from the horizontal, as with sunlight) 90,\nD1 Px Oz Po Ds Po and Pz the skys contribution to the irradiance, including inter-\nreflections, at p is:\n\nby Me) (4.145)\n\n1(p) = 5 N(e) . ¥ (2 _ 2281s sin, (° _ sn 28s cos; & sin’ ®\n\n(4.14.6)\n\nAsin; = - a= (i + ) - an( ) (4.14.7)\n4 4\n\nAcos; = cof 2 J = cof 2 (i + | (4.14.8)\n\n(For details on the derivation of Equations 4.14.5—8, see either the original paper\n[Stewart97] or the summary in [Hoffman01].) The horizon angles used here can be\nscanned to a relatively short distance, unlike those used for sun shadows. Of course, if\nyou are already calculating horizon angles for sunlight shadows, there is no reason not\nto use those for two out of the eight angles. Since this technique uses relatively little\npreprocessing, it can also handle occasional minor edits to the heightfield (e.g., small\ncraters) by recalculating the skylight texture in the affected area and a small distance\naround it.\n\nIf assuming a single radiance value for the sky does not produce acceptable\nresults, the sky subproblem can be further broken up into sub-subproblems. For\nexample, the sky could be divided into NV patches, and N skylight textures could be\ncalculated, each one based on the terrain being illuminated only by the relevant patch.\nAt runtime, each of the skylight textures is modulated by the radiance of the relevant\npatch, and the results are summed together. Each of these skylight textures is essen-\ntially a basis function for calculating the final skylight solution. These basis functions\ncan be calculated either via radiosity or by Stewart and Langer’s method ([Stewart98]\nderives the necessary math). Another possibility is to use the method in [Sloan 02],\nwhich can handle very complex skylight distributions.",
      "content_length": 2370,
      "extraction_method": "OCR"
    },
    {
      "page_number": 429,
      "chapter": null,
      "content": "440\n\nAnimated Cloud Shadows\n\nON THE CD\n\nSection 4 _ Graphics\n\nsco tt tuner atscoeeeh nao Scents tthe BRL eM aR RMT RHONA HEENE SH AEMOOIMOIIBOEE a rome MceLMcREENeEtee\n\nseen nme RRNA\n\nse TR RUS ER\n\nClouds are seldom absent from an outdoor scene, and the shadows cast by clouds are\nequally important to overall realism. Clouds’ shadows are cast onto terrain through the\nocclusion of light from the sun. With increasing cloud density, sunlight is obscured\nmore, resulting in darker areas on the ground. Therefore, it follows that a simple model\nof such shadows can be incorporated into a scene by multiplying the inverted cloud\ndensity with sunlight and oll the result to the sky’s light contribution\n\nE(p) = Egy (9) +[1- D(p)| Euan (4.14.9)\n\nwhere D(p) is the cloud density as aa onto the point p. Strictly speaking, the\nmapping of a cloud to its shadow on the ground is a perspective projection from the sun\nonto the earth's curved terrain at an angle. However, as the sun's distance is very far rela-\ntive to the area cast in shadow, it is common to assume a planar projection. A less accu-\nrate assumption frequently made in the calculation of texture-mapping coordinates for\ncloud shadows is that the sun is located vertically above the terrain. This assumption\npermits optimization by directly applying the ground-plane world-space location (G,,.)\nof terrain vertices to texture coordinates using only scale and bias factors:\n\nuv = G,,, Scale + Offset (4.14.10)\n\nWithout this assumption, a more complex texture projection matrix is required,\nresulting in more cycles per vertex. This per-vertex cost is particularly important with\nterrain meshes, which involve large numbers of vertices. However, when modeling the\nchange in time of day, the sun’s angle should be taken into account in the texture-pro-\njection calculation.\n\nWith the exception of events like storm clouds and twisters, clouds generally\ntravel in a linear direction. So, animating the movement of clouds is reduced to\nupdating texture offsets in the direction of cloud movement. However, care must be\ntaken in the projection to avoid generating out-of-range texture coordinates.\n\nOn the CD-ROM, a DirectX8 PC cloud-mapping sample demonstrates the use\nof vertex- and pixel-shading hardware for the method just described. First, the vertex\nprogram transforms the world-space vertex position to the screen. Doing this as early\nas possible is important in order to permit the graphics hardware to determine\nwhether to reject the vertex through clipping.\n\ndp4 oPos.x, VPOSITION, c[CV_VIEW_PROJECTION_0]\ndp4 oPos.y, VPOSITION, c[CV_VIEW_PROJECTION_1]\n\ndp4 oPos.z, VPOSITION, c[CV_VIEW_PROJECTION 2]\ndp4 oPos.w, VPOSITION, c[CV_VIEW_ PROJECTION 3]\n\nThe terrain’s color texture is mapped as a planar projection and is performed\nusing the world-space vertex position in the ground plane. This is then scaled and\nbiased using the single multiply add (mad) instruction.\n\nmad oTO.xy, VPOSITION.xz, [CV_BASE_TEX_PROJ].xy,\nc[CV_BASE_TEX_PROJ].zw",
      "content_length": 3001,
      "extraction_method": "OCR"
    },
    {
      "page_number": 430,
      "chapter": null,
      "content": "4.14 Methods for Dynamic, Photorealistic Terrain Lighting\n\nssonneeeneenonenntnenne acacia ananassae cee eR Rae eR EEN NOOO GS AREAS ASN NEON\n\n441\n\nThe sunlight texture is mapped in the same way, but the projection is redone, as\nit is more efficient to recalculate here than to store the result and copy to the output\ntexture register.\n\nmad oT1.xy, VPOSITION.xz, c[CV_BASE_TEX_PROJ].xy,\nc[CV_BASE_TEX_PROJ].zw\n\nNext, the cloud layer is mapped. Again, this is simply a case of scale and bias\noperations, with the addition of the animation of the texture offset.\n\nmad o T2.xy, VPOSITION.xz, c[CV_CLOUD_TEX_PROJ].xy,\nc[CV_CLOUD_TEX_PROJ].zw\n\nThe second cloud layer projection is applied to a fourth set of output texture\ncoordinates in the same way, with alternative scale and bias parameters. Note that the\nonly input stream to the vertex program is the world-space location of the vertex.\nEverything else is generated procedurally from that. This benefits us by reducing the\nbandwidth to the vertex processor (again this is an important concern with high-den-\nsity meshes, such as terrains).\n\nIn the pixel shader, each texture is combined according to Equation 4.14.9 to\nyield the final rendered result. After the texture declarations, the average density of the\ntwo cloud layers is calculated.\n\nadd_d2 AVG_CLOUD_DENSITY, TEX_CLOUD_LAYER_O,\nTEX_CLOUD_LAYER_1\n\nThis is then inverted and multiplied by the contribution from the sunlight texture.\n\nmul CLOUD_SHADOW_LUM, TEX_SUNLIGHT,\n1-AVG_CLOUD_DENSITY\n\nNext, a constant skylight color factor is multiplied by the terrain texture color.\n\nmul SKYLIGHT, TEX_TERRAIN_COLOR, CP_SKYLIGHT\n\nFinally, the skylight contribution is added to the shadowed sunlight factor, times\n\nthe terrain color.\n\nmad OUTPUT_REG, CLOUD _SHADOW_LUM, TEX_TERRAIN COLOR,\nSKYLIGHT\n\nFor this example, the constant sky radiance factor and sun radiance textures were\nstatically pregenerated using Terragen [Terragen01]. They were extracted from Terra-\ngen images using the following methods:\n\n¢ For the color texture, place the sun vertically above the terrain and disable terrain\nshadows.\n\n¢ For the skylight factor, render terrain with a gray surface with sun at an angle, and\nsample the darkest point in the image.\n\n¢ For the sunlight texture, subtract the skylight factor from the above image.",
      "content_length": 2310,
      "extraction_method": "OCR"
    },
    {
      "page_number": 431,
      "chapter": null,
      "content": "Sect ion 4 Graphics\n\neen Fon ERS\n\n442\n\nThe cloud density texture was generated by hand. This texture could also be used\nto render the clouds themselves.\n\nVideo-Based Solution\n\nstores RN RRR Ua RR ae CURRIER\n\nA brute-force method for generating dynamic te terrain lighting is to render canned\nsequences using an advanced offline rendering tool, then play back the sequence onto\na video texture. Any view-independent lighting effects could be represented entirely\nin the video texture. Certain view-dependent effects, such as fog, might be applied to\nthe video texture with traditional techniques. Furthermore, a novel, detailed bump-\nmap effect can be achieved by applying a lit video texture to the terrain at a smaller\nscale.\n\nWith no time constraints imposed, unlimited complexity could be applied to this\nsolution. However, a serious caveat is the high offline cost of generating video sequences.\nThis time-consuming process must be appropriately budgeted during the develop-\nmental process. With that in mind, the remaining challenge of this technique is the\nefficient playback of video textures in the 3D scene.\n\nPC and console hardwares are moving toward accelerated support for video tex-\ntures in 3D, albeit at a slower pace than vertex and pixel processing. For example, the\nimage-processing unit ([PU) on the PlayStation2 accelerates decompression of mpeg\nframes. However, the path that video data must take via the IPU before reaching\nvideo memory is somewhat convoluted [Hoffman01]. On the PC, such support is\npresently orthogonal to textured geometry support in 3D, although advanced video-\ndecompression hardware has existed for some time.\n\nAn attractive potential hardware solution would be to decompress a video texture\nformat from video memory prior to the pixel shader stage. This would have the ben-\nefits of greatly reduced bandwidth and accelerated decompression.\n\nRENE\n\nNonterrain Objects\n\nA large task to consider when rendering outdoor environments with dynamic lighting\nis the effect of objects, such as buildings and vehicles, on the terrain. Many methods\nexist for rendering general shadows in real-time [Haines01], which can be applied to\nterrain shadows in various situations.\n\nIn one technique, decal shadow texture projection, the texture is pregenerated (or\ngenerated by rendering the shadow to a texture surface) and mapped onto the terrain.\nA slight z-bias is required to avoid z-buffer conflicts when the projected decal mesh\ndoes not match the underlying terrain mesh [McNally99]. This method produces\ndetailed soft shadows, can quickly shadow large numbers of static objects (such as\ntrees), and can easily be integrated with a shadow level-of-detail scheme.\n\nFor dynamic objects, techniques range from drop shadows to stencil- and\nshadow-buffer methods. The choice depends on hardware performance and con-\nstraints. However, the need for fast projection onto an arbitrary terrain mesh is com-\n\neC",
      "content_length": 2934,
      "extraction_method": "OCR"
    },
    {
      "page_number": 432,
      "chapter": null,
      "content": "4.14 Methods for Dynamic, Photorealistic Terrain Lighting 443\n\nmon among these methods. This can be optimized by assuming an axis-aligned sun\nposition and, in the case of a heightfield, an axis-aligned mesh.\n\nConclusion\n\nLAR IE ORIEL EELS LESTE SE ENE NEET ESTNESTSSLLOES LETS IE DELS DIL IEE EII IBIAS\n\nWe have presented various methods for achieving photorealistic, quality terrain light-\ning under changing lighting conditions in real-time. For an example of photorealistic\nterrain lighting in real-time, see Plate 10. The methods have differing tradeoffs and\ncharacteristics in order to fit different types of games, platforms, and development\npipelines. If you are developing a game with outdoor environments, we hope at least\none of these methods will prove useful.\n\nReferences\n\n[Debevec98] Debevec, Paul, “Rendering Synthetic Objects into Real Scenes: Bridgin:\nTraditional and Image-Based Graphics with Global Illumination and High\nDynamic Range Photography,” Computer Graphics Proceedings (SIGGRAPH\n1998), pp. 189-198.\n\n[Haines01] Haines, Eric, et al., “Real-time Shadows,” GDC 2001 Conference Pro-\nceedings, also available online at http://www.gdconf.com/archives/proceedings/\n2001 /haines. pdf.\n\n[Heidrich00] Heidrich, Wolfgang, et al., “Illuminating Micro Geometry Based on\nPrecomputed Visibility,” Computer Graphics Proceedings (SIGGRAPH 2000):\n\n. 455-464. Also available online at http://www.cs.ubc.ca/~heidrich/Papers/.\n\n[Hoftman01] Hoffman, Naty, et al., “Photorealistic Terrain Lighting in Real-Time,”\nGame Developer Magazine (July 2001): pp. 32-41.\n\n[Kautz00] Kautz, Jan, et al., “Bump Map Shadows for OpenGL Rendering,” available\nonline at http:/ /evww.napi-sb.npe, del ~jnkautz/projects/shadowbumpmaps/.\n[Malzbender01] Malzbender, Tom, et al., “Polynomial Texture Maps,” Computer\nGraphics Proceedings (SIGGRAPH 2001): pp. 519-528. Also available online at\n\nhttp://www.hpl.hp.com/ptm/.\n\n[Max88] Max, Nelson, “Horizon Mapping: Shadows for Bump-Mapped Surfaces,”\nThe Visual Computer (July 1988): pp. 109-177.\n\n[McNally99] McNally, Seamus, “Treadmarks Engine.” Phone conversation available\nonline at http://www.vterrain.org/.\n\n[Sloan02] Sloan, Peter-Pike, et al., “Pre computed Radiance Transfer for Real-Time\nRendering in dynamic, Low-Frequency Lighting Environments,” to appear, Pro-\nceedings of SIGGRAPH2002. Available online at http://research.microsoft.com/\n~ppsloan/.\n\n[Stewart97] Stewart, James, et al., “Towards accurate recovery of shape from shading\nunder diffuse lighting,” EEE Transactions on Pattern Analysis and Machine Intel-\nligence (September 1997): pp. 1020-1025. Also available online at http://www.cs\n-queensu.ca/home/jstewart/papers/.\n\n[Stewart98] Stewart, James, “Fast horizon computation at all points of a terrain with\nvisibility and shading applications,” JEEE Transactions on Visualization and Com-\nputer Graphics (March 1998): pp. 82-93. Also available online at http://www.cs\n.queensu.ca/home/jstewart/papers/.\n\n[Terragen01] Fairclough, Matt, “Terragen.” Software available online at http://www\n\"planetside.co.uk/terragen,",
      "content_length": 3065,
      "extraction_method": "OCR"
    },
    {
      "page_number": 433,
      "chapter": null,
      "content": "4.15\n\nPhysical Properties of Cube Maps\n\n444\n\nCube Map Lighting\nTechniques\n\nKenneth L. Hurley, NVIDIA Corporation\nkhurley@nvidia.com\n\nCc: maps were introduced to game developers in DirectX7. In 1999, NVIDIA\nintroduced the Geforce 256 and brought cube maps to the mass PC gamer mar-\nket. Until now, they had been mainly used to render shiny objects. However, the cube\nmap can be used in more-interesting ways. This gem will describe some ways to\nencode different lighting conditions as well as other properties within cube maps. It\nwill give a brief overview of the properties of cube maps and how to index into them.\nSome references for fallback methods will also be given. This gem is DirectX-centric,\nbut the same principles can be applied to OpenGL.\n\nSOROS LORRI HRE REET EOBR PA ALY ER TE A LITE\n\nCube maps are represented as six textures in hardware. Each texture represents a side\nof a cube. Normally, code is written so that a reflection vector is used to index into the\ncube map. A three-component vector is then passed into the hardware, which gives\nthe hardware the information needed to pick the correct face and select the uv coor-\ndinates for that face (Figure 4.15.1). The hardware uses the longest component of the\nthree components to select the face. For instance, if the vectors (0.4f, 0.5f, 0.7f) were\npassed into the hardware, it would select the positive z face of the cube map, since 0.7\nis the largest component. The hardware would then use the other two components\n(0.4f, 0.5f) to select the uv coordinates. One difference between cube maps and regu-\nlar texture addressing is that the uv coordinates are signed values, and the texture is\naddressed such that the center of the cube face is uv coordinate (0, 0). Normal texture\nmapping uses the upper-left corner as the (0, 0) uv coordinate.",
      "content_length": 1812,
      "extraction_method": "OCR"
    },
    {
      "page_number": 434,
      "chapter": null,
      "content": "445\n\n+y Direction\n\n|\n{\n{\n|\n\n—\n\n+X\n\n-x Direction +z Direction +x Direction -Z Direction\n\n+X -Z\n\n-y Direction\n\nI,\n+X\n\nFIGURE 4.15.1 Hardware layout of a cube map.\n\nHow Get Data to/from a Cube Map\n\neveral ways. The easiest way\nto create a .dds cube map file is to use Microsoft's DirectX Texture Tool, which is\nincluded with DirectX8. The following code demonstrates loading a cube map from\n\na .dds file.\n\nLoading cube maps in DirectX8 can be accomplished in s\n\nLPDIRECTSDCUBETEXTURES m_pCloudTexture;\n\nD3DXCreateCubeTextureFromFile(m_pD3DDev, \"cloudtex.dds\",\n&m_pCloudTexture) );\n\nMake sure to use D3DXCreateCubeTextureFromFile and not D3DXCreateTexture-\nFromFile with a LPDIRECTSDTEXTURES pointer, as DirectX8 will accept the call, but\nstrange results will occur upon rendering. To render the selected texture, simply set the\ntexture in one of the texture stages. The following code is a sample of how to do this.\n\nm_pD3DDev->SetTexture (0, (LPDIRECT3DBASETEXTURE8)m_pCloudTexture) ;\n\nAnother way to load the texture is from six individual bitmap files. This requires\na call to D3DXCreateCubeTexture to create the cube map texture and then a call to",
      "content_length": 1148,
      "extraction_method": "OCR"
    },
    {
      "page_number": 435,
      "chapter": null,
      "content": "446\n\nSection 4 Graphics\n\netna eaatottnacennobnaaiaoaassnemoonbiinsoetinatieeiaitr teeter tena LAE no LRN RHE RARER\n\nGetCubeMapSurface for each face of the cube map. Alternatively, the texture maps can\nbe loaded with one of the D3DXLoadSurface* functions.\n\nRendering with the Cube Map\n\ngc em tt EN RRR sr me RN RT TING BHT EI IIE SAT ESR ROLE BIE TN ARIAT,\n\nSetting up the 3D texture coordinates for a cube map can be done in one of several\nways. Prior to DirectX8, a programmer would use code similar to the following to set\nup rendering of cube maps:\n\nfor( LONG i = 0; i < cV; i++ )\n\n{\n// eye vector (doesn't need to be normalized)\nFLOAT fENX = m_vEyePt.x - pVIn->v.x;\nFLOAT fENY = m_vEyePt.y - pVIn->v.y;\nFLOAT fENZ = m_vEyePt.z - pVIn->v.z;\nFLOAT fNDotE = pVIn->v.nx*fENX + pVIn->v.ny*fENY +\npVIn->v.nz*fENZ;\nFLOAT fNDotN = pVIn->v.nx*pVIn->v.nx + pVIn->v.ny*pVIn->v.ny +\npVIn->v.nz*pVIn->v.nz;\nFNDotE *= 2.0;\n// reflected vector\npVIn->v.tu = pVIn->v.nx*fNDotE - fENX*fNDOtN;\npVIn->v.tv = pVIn->v.ny*fNDotE - fENY*fNDotN;\npVIn->nz = pVIn->v.nz*fNDotE - fENZ*fNDotN;\npVIn++;\n}\n\nThis code calculates the reflection vector on a per-vertex basis and places the vec-\ntor into the 3D texture coordinates that are to be passed to the hardware.\n\nDirectX8 introduced a new method for dealing with cube maps. Vertex buffers\ncan now be set up to use either the fixed function pipeline or vertex and pixel shaders.\nThe fixed function pipeline of DirectX8 is very similar to that of DirectX7. It can be\nset up by specifying texture stage states and render states, with the cube map-specific\nrender states for the fixed function pipeline being D3DRS_LOCALVIEWER and D3DRS_\nNORMALIZENOAMALS. The texture stage state that needs to be considered is D3DTSS_\nTEXCOORDINDEX. For this gem, the D3DTSS_TCI_PASSTHRU texture stage state value is the\nfocus. This instructs the hardware to use the texture coordinates directly without\ntransforming them in any way.\n\nIn DirectX8 and above, vertex shaders can be used to change the normal based on\na rotation. The vertex shader then puts the normal into the output texture coordinate\nthat corresponds to the texture stage where the cube map was selected. The following\ncode snippet demonstrates how to do this.\n\n;transform normal, put into texture coordinate output\ndp3 oTO.x, srcNormal, c[CV_ROTATION_X]\ndp3 oT0.y, srcNormal, c[CV_ROTATION_Y]\ndp3 oT0.z, srcNormal, c[CV_ROTATION_Z]",
      "content_length": 2407,
      "extraction_method": "OCR"
    },
    {
      "page_number": 436,
      "chapter": null,
      "content": "4. 15 _Cube Map Lighting Techniques 447\n\nEncodin Cloud Cover\n\nES TERE\n\nEncoding cloud cover into a cube map is not as straightforward as it might at first\nappear. Fractional Brownian motion (fBm) and Perlin noise [Perlin85] are used exten-\nsively to create 2D cloud textures. This technique works quite well and allows the reg-\nular textures to tile seamlessly; however, these images cannot be loaded into cube\nmaps without apparent seams. The reason for these seams is that the edges of the 2D\nimage only match with parallel edges. The top and bottom edges will only match with\neach other, but not with the side edges, since they do not tile with the top or bottom\nedges. This poses a problem for cube maps, since all the edges must match in order to\nprevent seams. The solution is to use a 3D fBm or Perlin noise function to encode the\nclouds into a cube map. The following code will do this.\n\nD3DXVECTORS3 tVec;\n\n// now loop through each pixel of the cube map, gathering the fBm\nfor (i=0; i<CUBEMAP_TOTAL_DIR; i++)\n\n{\ndest = m_CubeFacesData[i];\nfor (pos.y=0; pos.y < m_CubeSize.cy; pos.yt+)\n{\nfor (pos.x = 0; pos.x < m_CubeSize.cx; pos.x++)\n{\nGetCubeVector(i, &pos, &m_CubeSize, &tVec);\n*dest++ = fBm(tVec);\n}\n}\n}\na\n// Function: GetCubeVector\n// Description: returns a 3 vector given a from an x,y, face of a cube\n// map\n// Parameters: face = face of cube map to calculate vector from\n// tInfo = x,y, width and height of cube map face texture\n// vecOut = 3 vector pointer for output\n// Returns: pointer to vecOut\n/ /SSesssessssssssssssssrsssssssSssssessssSSSSSS Ss SsSSSSSsSSssSSSSSSss=a=\n\nD3DXVECTOR3 *CCubeMapDoc::GetCubeVector(DWORD face, const CPoint *pos,\nconst CSize *size, D3DXVECTOR3 *vecOut)\n\n{\nfloat s, t, sc, tc;\n\n// move pixels to center\n\n= ((float) pos->x + 0.5f) / (float) size->cx;\nt = ((float) pos->y + 0.5f) / (float) size->cy;\nsc s*2.0f - 1.0f;\nte = t*2.0f - 1.0f;\n\nswitch (face)\n\n{\n\ncase CUBEMAP_POS xX:\nvecOut->x = 1.0f;",
      "content_length": 1943,
      "extraction_method": "OCR"
    },
    {
      "page_number": 437,
      "chapter": null,
      "content": "_somosrgnmiienrotitremmeicunnensn atin eh ssenctiter thyme anne OE ND RONEN\n\n}\n\nvecOut->y = -tc;\nvecOut->z -SC;\nbreak;\n\ncase CUBEMAP_NEG_X:\nvecOut->x = -1.0f;\nvecOut->y = -tc;\nvecOut ->z SC;\nbreak;\n\ncase CUBEMAP_POS_Y:\nvecOut->x = SC;\n\nvecOut->y = 1.0f;\nvecOut->z = tc;\nbreak;\n\ncase CUBEMAP_NEG_Y:\nvecOut->x = SC;\n\nvecOut->y = -1.0f;\nvecOut->z = -tc;\nbreak;\n\ncase CUBEMAP_POS Z:\nvecOut->x = sc;\n\nvecOut->y = -tc;\nvecOut->z = 1.0f;\nbreak;\n\ncase CUBEMAP_NEG_Z:\nvecOut->x = -SC;\nvecOut->y = -tc;\nvecOut->z = -1.0f;\nbreak;\n\n}\n\nD3DXVec3Normalize(vecOut, vecOut);\nreturn vecOut;\n\nSection 4 Graphics\n\nTo use this cube map for a sky sphere, create a sphere that is representative of the\nworld’s atmosphere and use the coordinates as lookups into the cube map. There is no\nneed to normalize the coordinates, since the lookup into the cube map does not\nrequire a normalized vector. Here is a code snippet for a vertex shader that demon-\n\nstrates this technique.\n\nvs.1.1\n\n;transform position\n\ndp4 oPos.x,\ndp4 oPos.y,\ndp4 oPos.z,\ndp4 oPos.w,\n\n; Output texture coordinates\n\nsrcPosition,\nsrcPosition,\nsrcPosition,\nsrcPosition,\n\nc[CV_WORLDVIEWPROJ_0]\nc[CV_WORLDVIEWPROJ_1]\nc[{CV_WORLDVIEWPROU_ 2]\nc[CV_WORLDVIEWPROJ_3]\n\nmov destTexCoord, srcPosition\n\nAnimating the clouds is fairly straightforward. Using DirectX8, rotate the sky\n\nsphere using a rotation matrix passed into the vertex shader.",
      "content_length": 1377,
      "extraction_method": "OCR"
    },
    {
      "page_number": 438,
      "chapter": null,
      "content": "4.15 Cube Map Lighting Techniques 449\n\nA side benefit of encoding the clouds in a cube map is that shadows from the\nclouds can be drawn onto the terrain. The alpha can be encoded with the inverse\ngrayscale image of the clouds, minus the sky color. The color can also be obtained in\na pixel shader by taking one minus the color from the original cloud cube map. The\npositions for the terrain are used as indices into the cube map, and the alpha compo-\nnent is used to darken the terrain. This has the added benefit of creating soft shadows\nfrom your preblended clouds with semitransparent edges. The lighting calculations\nfor the terrain, with regards to the sun, could also be altered by using this value. For\ninstance, the light calculation can be blended with half of the alpha channel values,\ngiving the effect of semitransparent clouds.\n\nEncodin Lights in a Cube Map\n\nStatic and dynamic lights can be encoded in a cube map in a number of ways. Infinite\nstatic lights, like the sun, can be prerendered into the cube map using the techniques\ndescribed to index into the cube map. The normal of the vertex is used to index into\nthe cube map and retrieve the light that is rendered into the cube map. This works\nwell for infinite static lights, but not for dynamic lights. Dynamic lighting usually\nrequires multiple texture passes. The idea is to render the moving lights into the cube\nmap by using a 90° field of view and pointing the camera at each side of the cube.\nThe camera position to render from would be the position of the object that is being\nlit. This technique would work well for rendering a scene that had, for example, a\ndisco ball where there could be 100 lights or so in the scene. Rendering the disco\nroom and objects in the room could be accomplished using this technique. The cube\nmaps do not have to be very big for this technique to work convincingly, so keep this\nin mind when calculating the rendering time.\n\nEncoding Diffuse Lighting in a Cube Map\n\nDiffuse maps can also be incorporated into scenes with many lights by using the\nabove code that traversed through a cube map to build the cloud texture. For each uv\ncoordinate on a face of a cube map, a vector 7 (normal) is calculated. For vector n,\nanother vector / (light) is calculated from each uv coordinate of each cube face. These\ntwo vectors are used in a dot product operation to determine the cosine of the angle\nbetween the two vectors. This is the same calculation used in standard vertex lighting.\nIf the result of the dot product is negative, it is safe to assume that vector / is not con-\ntributing to vector m. Otherwise, the result of the dot product is the weighting factor\nthat is used to blend the pixels of the cube map together. The pixels chosen for the\nblending operation are from the uv coordinates that were used to calculate the two\nvectors 7 and /. This, in essence, samples a hemisphere of pixels centered about vector\nn. The cube map in Figure 4.15.2 is the result of this sampling. To use this cube map\nfor lighting, the sample should be gamma corrected, as some range is lost in the con-\nversion into low dynamic range.",
      "content_length": 3126,
      "extraction_method": "OCR"
    },
    {
      "page_number": 439,
      "chapter": null,
      "content": "450\n\nSection 4 Graphics\n\nFIGURE 4.15.2 Encoded diffuse cube map.\n\nEncoding of a specular map can be accomplished in much the same way as the dif-\nfuse map by following the same guidelines for traversing the cube map and sampling\neach direction as before. Instead of taking a dot product for the weighting of the two\nvectors, take the mth root of the dot product, where is specified as the specular expo-\nnent. Some user interaction will have to occur for this phase, as the specular exponent\nvaries on a material-by-material basis.\n\nEncoding a Day/Night Cycle into the Cube Map\n\nDay/night cycles can also be used with the cloud cube map p by using the technique\ndescribed to create a cloud cube map and only encoding the grayscale portions of the\nclouds. When lighting the sky sphere, clamp the dot product with a value that repre-\nsents the lowest point on the horizon that changes color. The sky color is passed to the\npixel shader as part of the lighting calculation, and, as the sun rotates, the color of the\nsky sphere can be changed by writing the color to vertex memory. As the sun\napproaches the horizon, the sky color can be ramped from blue to orange. After the\nsun passes the horizon, simply ramp the colors, based on time, from orange to black.\nThe nice thing about clamping the dot product is that any color can be picked based\non the clamp value.",
      "content_length": 1360,
      "extraction_method": "OCR"
    },
    {
      "page_number": 440,
      "chapter": null,
      "content": "4.15 Cube Map Lighting Techniques ; 451\n\nConclusion\n\nsc oeraeeReeR RANA RI i SN TEE NAAN NUE TET CEERI TN INIT RNR ES EERR RE NN ACD ETS MONEE PARR AEERE RE\n\nCube maps can be used for a wide variety of effects besides rendering shiny reflective\nobjects. This gem describes some more-interesting uses for cube maps. Note that\nhardware that doesn’t support cube maps can still take advantage of these techniques\nby using sphere maps or dual-paraboloid maps [Heidrich99]. In this case, the calcula-\ntions will have to be done using texture coordinate generation or using the CPU to\ncalculate the uv coordinates.\n\nThe source code for a few demonstrations of the described techniques can be\nfound on the CD-ROM. An animated cloud cube map over terrain and the diffuse\nlighting (envlight.nvp) code snippet are included. Also, see Color Plate 11.\n\nON THE CD\n\nReferences\n\n[Debevec97] Debevec, Paul E. and Jitendra Malik, “Recovering High Dynamic\nRange Radiance Maps from Photographs,” (SIGGRAPH 1997): pp. 369-378.\n\n[Elias02] Elias, Hugo, “Perlin Noise,” available online at http://freespace.virgin.net/\nhugo.elias/models/m_perlin.htm, January 5, 2002.\n\n[Heidrich99] Heidrich, Wolfgang and Hans-Peter Seidel, “Realistic, Hardware-\nAccelerated Shading and Lighting,” Computer Graphics Proceedings (SIG-\nGRAPH 1999): pp. 171-178.\n\n[Perlin85] Perlin, Ken, “An Image Synthesizer,” Computer Graphics Proceedings (SIG-\nGRAPH 1985): pp. 287-296.",
      "content_length": 1430,
      "extraction_method": "OCR"
    },
    {
      "page_number": 441,
      "chapter": null,
      "content": "4.16\n\n452\n\nParameters and Procedures\n\nProcedural Texturing\n\nMike Milliger, 2015, Inc.\nmikem@2015.com\n\nrocedural texturing is an area of research that includes topics ranging from\n\nFourier synthesis to stochastic models to creating textures based on chemical gra-\ndients. Darwyn Peachy, in Texturing & Modeling, defines procedural as a way “to dis-\ntinguish entities that are described by program code rather than by data structures\n[Ebert98].” In the context of games and this gem, we are mainly concerned with the\nability to map a texture image onto a surface through mathematical functions.\n\nWhenever discussing procedural texture mapping with artists, almost invariably\ntheir first response is, “So, you are trying to put me out of a job?” All the content cre-\nators can put their sharp objects down; in the end, hand-painted textures will always\nlook better than pure texture synthesis done through the use of programs. Using a\nprocedural system exclusively for a title would not only be inefficient task-wise for a\nbalanced development team, but the system would also be inadequate from an aes-\nthetic point of view. A combination of procedural and traditional methods will\nstrengthen the artwork of a game and make the game environment look more natural.\nNot only can we generate unique, new textures with procedures, we can manipulate\nthe various properties (color, location, aspect ratio, etc.) of pregenerated images. The\ngoal of this gem is to introduce basic concepts for using procedures to manipulate and\nsynthesize images for games and to give simple guidelines for implementation.\n\nsoso\n\nThe creation of a procedural texture requires two elements—a procedure that will be\nused to generate the texture and the parameters that control this procedure.\n\nParameters\n\nParameters passed into generating procedures guide the outcome of the texture.\nManipulating variables in mathematical functions generally creates the variations in\nprocedural textures. Much as an audio engineer mixes sound signals by using a variety\nof electronic processing gear, the visual-effects artist manipulates a variety of signal\ngenerators and processing functions to create a unique texture. Often, we use the\nsame terminology. Signals (or base textures) are generated at various wavelengths and\nare filtered and blended through a variety of controls. Common parameters for pro-",
      "content_length": 2366,
      "extraction_method": "OCR"
    },
    {
      "page_number": 442,
      "chapter": null,
      "content": "4.16 Procedural Texturing 453\n\nFocusing on Games\n\ncedural algorithms include terms like “frequency,” “amplitude,” and “bias.” However,\ninstead of manipulating sound, these functions are used to manipulate texture prop-\nerties, such as color values and translucency.\n\nProcedures\n\nThe majority of procedural effects used in games have been based on Ken Perlin’s\nfamily of procedural algorithms, known as “noise.” A pseudo-random number gener-\nator (PRNG) is at the heart of most noise procedures, and this randomness helps gen-\nerate natural-looking effects. Noise is the workhorse of procedural textures and the\nmost-applicable and widely used type of procedure for games. There are many deriva-\ntions of noise—value noise, gradient noise, value-gradient noise, lattice convolution,\nand sparse convolution. All of these procedures are variations on the idea of turning\npseudo-random numbers into sources of textures for graphic images [Macri00]. The\nPRNG generates a lattice. A lattice refers to an m-dimensional, smoothed grid of uni-\nformly distributed points in texture space, each containing a random number (float).\nThe spacing of these points determines the frequency. Several sources of noise of dif-\nferent frequency can be combined together. Each of these noise sources (or octaves)\ncan be added together to form a final image using various mathematical methods.\nThese methods are then fine-tuned to create specific effects. For example, Kim Pallis-\nter's gem in Game Programming Gems 2 [Pallister01] explains how to use noise to gen-\nerate dynamic, procedural clouds by summing octaves into turbulent noise.\n\nNoise algorithms are a direct method for the creation of a procedural texture\nsource. Another method for texture generation takes a texture source and evolves it\nover time using an algorithmic procedure. One such procedure is cellular automaton\n[Macri00]. When used to generate procedural textures, an initial texture is divided\ninto a number of discrete samples called “cells” or “texels.” The color at every texel in\nthe image defines the current state of the cellular automaton system. At every itera-\ntion of the procedure, each texel in the texture is modified according to a set of rules.\nThese rules generally involve setting each texel to be the weighted average of a speci-\nfied set of the neighboring texels. Using these simple systems, a great variety of effects\ncan be achieved. For example, setting each cell’s value to be the averaged value of the\nneighbor cells beneath it can simulate a fire effect. At each iteration of the system,\nthe virtual flames in the texture spread upward [Macri00].\n\nIterative procedures, such as cellular automaton, complement direct methods,\nlike the noise functions. For example, a pseudo-random noise procedure can generate\na group of randomly scattered points that can then be used as the initial system state\nfor the iterative algorithm.\n\ns sIEL Romer eT RRE RRR NH RRURR NERA ARRAN ESA ARR INRA MRR RRO\n\nProcedural texturing techniques have been used in a variety of computer graphics\napplications, such as scientific visualization and visual effects. This gem is focused on\nthe use of these techniques in game applications.",
      "content_length": 3191,
      "extraction_method": "OCR"
    },
    {
      "page_number": 443,
      "chapter": null,
      "content": "Section 4 Graphics\n\nUses of Procedural Textures\n\nProcedural texturing is still in the early stages as far as prime-time game development\nis concerned. Most of the effects in past games have been simple water or fire effects.\nHowever, procedural texturing excels at representations of natural phenomena and\ncan be used to generate textures for wood, marble, snow, grass, stars, or volumetric\neffects, such as clouds [Pallister01]. These are exactly the type of surfaces that are\ncommonly needed in game projects.\n\nA generated texture can be used in a static manner much like any other form of\ntexture. By using the texture-transformation capabilities of modern graphics hard-\nware, the texture can be moved over the image’s surface. A series of textures can be\ngenerated and then played back as an animated texture. This is a common practice in\nmany games. However, a predictable pattern can often be seen on the surface, and\nthe effect is easily spotted when the animation repeats. To some extent, this takes the\nviewer out of the immersion of the game. The real power of procedural textures is\nachieved when the textures are generated in real-time within the game project.\nBecause the procedures are mathematical and with endless variation, repetitive cycles\nare eliminated.\n\nIn addition to their use as color source material, procedural textures can be used\nas bump, diffuse, specular, or dynamic environment maps in multitexture systems. A\nprocedural texture could be used to show cracks or dents in a surface by perturbing\nthe texture space normals using a function. Diffuse mapping with noise can break up\nlarge areas of solid color and show unevenness (large areas of solid color tend to stand\nout and look fake). Fractal terrain is often a noise image used as a heightfield (dis-\nplacement map) on a dense mesh, Many outdoor engines use this technique to gener-\nate the geometry for unique terrain instead of storing all the data. Since the noise\nimage is made by a seeded PRNG, the terrain can be generated again into the same\nshape if the player returns to the same area.\n\nAdvantages of Procedural Textures\n\nThere are many advantages to using procedural textures in your game. The decision\nto use them often boils down to a classic problem in computer science: the trade-off\nbetween computation time and memory size. Even though it takes processor time to\nbuild the texture, there is virtually no memory footprint. Also, procedural textures are\nnot limited by bandwidth constraints. There is no need to continually load and refer-\nence texture memory for pixel colors. Since the texture is regenerated every frame,\nthere is no reduction in the fidelity of the image. This is especially beneficial in first-\nperson games where the view can move extremely close to a surface. A bark texture on\na tree could be regenerated each frame as a player moves toward the tree, increasing in\ndetail as the view moves closer.\n\nWhile most procedures are written in highly optimized assembly code, rendering\nscenes with a lot of different procedural textures will lower the frame rate. We can\nhave a large number of surfaces that utilize procedures in a single level, as long as most",
      "content_length": 3177,
      "extraction_method": "OCR"
    },
    {
      "page_number": 444,
      "chapter": null,
      "content": "4.16 Procedural Text\n\nring 455\n\nof them are not visible at the same time. It is simple to cull textures that do not appear\non the screen and to skip the calculations. Procedural textures lend themselves to\nreuse, and we can use the same texture for multiple objects, like a fire procedure for all\nthe torches in a hallway. Although procedures are hard to debug, given their lack of\ncontrol and randomness, this can also be the source of pleasant surprises (serendipity)\n[Ebert98]. Even so, procedures can be controlled to some extent by parameters that\nchange the outcome texture rather than being limited to a fixed image.\n\nProcedural textures can be one-, two-, or three-dimensional. Three-dimensional\ntextures serve as new tools for artists and programmers to create effects. A procedurally\ngenerated, three-dimensional texture will allow a plane, intersecting at any angle with\nthe volume (color space), to be textured appropriately and in relation to the rest of the\ncolor space. This technique is also known as “solid texturing.” The color space incor-\nporates the use of a 3D array of color values for texturing, and the textured object is\nplaced within this color space. Destructible environments are becoming more com-\nmon in games, and solid texturing will amplify the reality of objects in the scene. Imag-\nine a pillar mapped with procedurally generated marble getting caught on the wrong\nend of a rocket launcher and blown into large chunks. Not only will the inside of the\nremaining pillar be mapped with the continuous veins of marble, the chunks blown off\nof the pillar will be mapped as well, as long as they are in the color space. Believable\ncaustics and clouds can also be achieved with this technique. Procedural textures have\nno fixed area and can cover arbitrary-size areas without repetitions and seams. To add\ndetail for large areas, increase the number of octaves in the procedure.\n\nGetting Procedural Textures in the Game\n\nThere are two basic types of procedural textures that can be used in your game: real-\ntime and pregenerated. Pregenerated procedural textures can be made in content\napplications such as Lightwave or Photoshop, or in a professional procedural texture\npackage such as DarkTree, and then mapped in the traditional method (losing some\nbenefits of calculating them in real-time). DarkTree allows users to modify parameters\nvisually by piping functions into each other, generating different effects. Results are\ndisplayed in real-time, giving the user instant feedback about the effect. Animated\ntextures can also be saved out on a frame-by-frame basis.\n\nIf you want to implement a real-time procedural system in your game engine,\nthen there are some general heuristics that will be helpful. The first step is to create a\nsolid workflow that is fairly simple. A top priority should be to make it simple for\nnoncoder types. An authoring tool with sliders and an instant previewing window is\nmore than worth the effort of writing it. The key is to allow content creators to con-\ntinue doing what they do best, making art instead of typing arcane parameters in a\ntext editor. The authoring tool should save out the parameters and procedure name\nfor the surface to a shader file; and when the level or area loads, the parameters gener-\nated by the tool are passed into the procedure when drawing the surface. Assign rea-",
      "content_length": 3360,
      "extraction_method": "OCR"
    },
    {
      "page_number": 445,
      "chapter": null,
      "content": "456\n\nHardware Acceleration\n\nSection 4 Graphics\n\nsonable defaults to surfaces that can be overridden if values exist for the surface\ndescription.\n\nIn the future, games can look forward to a more Renderman-like environment for\ntexturing and shading. Most game engines already have, or are moving toward, shader\nsystems. A standardized, shading language for games would allow a clean method for\ndefining parameters and applying functions to materials.\n\nOther Uses for Procedural Functions\n\nWhile this gem mainly focuses on image synthesis, most procedural techniques can be\nextended to other aspects of game development. We have already discussed using\nnoise to make terrain. When it comes to animation, a user could apply noise to IK-\nbased death animation so that several bad guys that die in the same room do not end\nup in the same death pose. When using morph targets, add a noise weight to the ver-\ntices in order to get different results, such as random blinking or variable tail flips on\ndolphins. Perlin has demonstrated the use of noise for generating facial expressions\n[Ebert98]. Procedural modeling is an increasing area of interest for game designers,\nespecially for memory-challenged architectures. Trees and their branches could be\nprocedurally spawned, resulting in a variety of vegetation without the need to store\nmassive amounts of geometry.\n\nsrr RSE SRR ARAN LRH A TORSIIAT AAAI AOI INE\n\nCalculating the texture during runtime on a per-pixel basis takes a lot of computa-\ntional time. Having the majority of per-pixel work done by the graphics hardware\ninstead of the main processor is one way to offset the computational cost of proce-\ndural calculations. Now, with the latest consumer graphics hardware, we can have\nreal-time procedural textures in games without a large performance hit on the main\nprocessor. If you don’t have the graphics chipset that can handle per-pixel operations\nand coloring effects, then the calculations will take place on the main processor.\n\nThe main issue for real-time generation of procedural textures is the ability of the\ngraphics hardware to render directly to a surface. This can be done with capable hard-\nware using either Direct 3D or OpenGL. As an example, a pseudo-random function\ncan be used to create several source noise textures of various frequencies. These source\nnoise textures can then be combined by rendering them to a surface using the avail-\nable hardware blending and filtering modes. On graphics hardware that supports\nmultitexture rendering, several textures can be combined in a single pass. The results\nof these operations can then be used as a texture that is applied to an object in the\ngame scene.\n\nBeyond this kind of direct, procedural texture creation, it is even possible to cre-\nate iterative cellular automaton system directly in hardware. Using hardware that sup-\nports blending four simultaneous textures, and feeding the results back into the\nsystem, effects such as animated fire and water can be generated [James01].",
      "content_length": 3006,
      "extraction_method": "OCR"
    },
    {
      "page_number": 446,
      "chapter": null,
      "content": "4.16 Procedural Texturing 457\n\nConclusion\n\nseg aR Saree\n\nsaa\n\nProcedural texturing is a powerful and flexible way to g\nify existing textures. ‘he techniques have not found their way into a lot of games,\neven though procedures would strengthen the artwork of a game. This is mainly due\nto the time necessary to perform the per-pixel operations needed to generate the tex-\nture. With consumer-level hardware now able to perform pixel operations on the\ngraphics chipset, which frees up the main processor, we should see more procedurally\ngenerated effects in future games. There is no doubt that the most popular families of\nprocedures, noise and cellular systems, will be leading the way.\n\nThe included sample demonstration code from Simon Green (NVIDIA) shows\nthe use of graphics hardware to create dynamic procedural 3D textures. It uses a sin-\ngle precomputed 3D noise texture, which is accessed multiple times using the texture\nmatrix to control the frequency and the register combiners to weight and sum each\nlayer and produce the final color.\n\nThe 3D texture is 64xX64x64 texels in size and uses the single-channel ‘lumi-\nnance’ format, and therefore consumes only 256 KB of memory. It is interesting to\nnote that although the period of this texture is relatively small, it is surprisingly diffi-\ncult to see any repeating patterns once the octaves have been combined together. The\nnovel part of this technique is that the noise texture is prefiltered using a cubic filter.\nThis helps avoid some of the artifacts that would occur if we just used a texture with\nrandom texels and let the hardware linearly interpolate between them. It also allows\nus to precompute the absolute function that is needed for the Perlin ‘turbulence’\nfunction.\n\nTo produce the final fractal noise pattern, we use four or more 3D texture\nlookups for the noise texture. Each layer is known as an octave, since the frequency\ntypically doubles each time, just as in a musical scale. We use the texture matrix to\nscale each set of texture coordinates and thereby increase the spatial frequency for each\noctave, but this could also be done easily using a vertex program. Interesting animated\neffects can also be created by translating or rotating the texture coordinates of each\nlayer at different rates. This is much cheaper than actual four-dimensional noise\nwould be. The best results seem to be achieved when the speed of animation for each\noctave is proportional to the spatial frequency.\n\nFinally, the register combiners are used to weight the value from each octave by\nthe correct amplitude and sum the contributions of all the octaves together. Once we\nhave the final (scalar) summed noise value, there are various ways to produce a color\nfrom this. For simple coloring effects, the register combiners can be used to interpo-\nlate between two or more colors based on the noise value, but for more nonlinear pat-\nterns (such as veined marble), we can use a color table. One way to achieve this\ninvolves rendering the scene to a texture, and then in a second pass, drawing a screen-\naligned quad using the dependent_gb texture shader and a one-dimensional texture\nthat maps the noise values to colors. The alpha test function of the graphics hardware\ncan also be used to discard pixels that are above or below a certain threshold, creating",
      "content_length": 3320,
      "extraction_method": "OCR"
    },
    {
      "page_number": 447,
      "chapter": null,
      "content": "458 Section 4 Graphics\n\ninteresting ‘corroded’ looks. Future programmable hardware will be able to do this\n(and more) in a single pass and provide much more flexible procedural texturing pos-\nsibilities.\n\ni exturing & Modeling, Second Edition, AP Profes-\n\nsional, 1998.\n\n[James01] James, Greg, “Operations for Hardware-Accelerated Procedural Texture\nAnimation,” Game Programming Gems 2, Charles River Media, Inc., 2001.\nDemos available online at http://developer.nvidia.com.\n\n[Macri00] Macri, Dean, and Kim Pallister, “Procedural 3D Content Generation,”\navailable online at http://cedar.intel.com/, February 8, 2001.\n\n[PallisterO1] Pallister, Kim, “Generating Procedural Clouds Using 3D Hardware,”\nGame Programming Gems 2, Charles River Media, Inc., 2001.",
      "content_length": 755,
      "extraction_method": "OCR"
    },
    {
      "page_number": 448,
      "chapter": null,
      "content": "4.17\n\nUnique Textures\n\nTom Forsyth, Mucky Foot\n\ntomf@muckyfoot.com\n\nIr the real world, no two surfaces are the same. They have a myriad of tiny differ-\nences—wood grain, surface texture, dirt marks, scuffs, faded paint, footprints, graf-\nfiti, and so forth. Nevertheless, computer games reuse the same textures over and over\nagain. In the past, this was done for practical reasons. Video memory was in short\nsupply, and using a different texture for each surface in a scene would have caused\nexcessive paging in and out of textures, even for static views.\n\nNow, video memory is relatively cheap and plentiful, but there are new problems.\nWe demand higher-resolution textures, which chew memory at a prodigious rate.\nAlso, we are creating such mammoth worlds to play in that no single team of artists\ncould possibly create unique data for every surface, even if there was the disk space to\nstore them all.\n\nMany of these problems can be solved by generating textures in a more proce-\ndural way, rather than relying on the hand of the artist to generate every single texel.\nThe core idea that we will explore in this gem is how to use a relatively small number\nof artist-generated source textures and combine them at runtime using a variety of\nblends, fractal methods, and random numbers to create the textures required for the\nscene.\n\nProcedural Textures\n\nssa ERR Nilen oR,\n\nAs described in Mike Milliger’s gem in this section [Milliger02], the use of procedural\ntextures allows artists to do less actual pixel-pushing, and start generating descriptions\nof classes of surfaces. These descriptions can then be applied to large areas of levels\nand multiple objects in that level. Because the descriptions use pseudo-random num-\nbers for some of their values, each instance will be slightly different in exact appear-\nance, just as they are in real life. The important thing is to allow the artists to take\nback full control at any stage of the process—for certain important items, they will\nwant to lock down a finished article and not have it change in any way. However, for\nalmost all the terrain and scenery in a game world, this rigid control is not necessary.\n\n459",
      "content_length": 2166,
      "extraction_method": "OCR"
    },
    {
      "page_number": 449,
      "chapter": null,
      "content": "460\n\nSmart Texture C\n\nComposition Model\n\nsnaainccannoranuniiotanenisseunnineninea iulrmelneiiaoiiein® HioKREstiRNNeisoisnehtirm een\n\nBecause each surface’s texture is uniquely generated, each one can adapt to the\ngeometry of the object it is mapped onto. The most obvious benefit is that texture\nseams vanish—continuous textures, such as rock or wood, can flow smoothly and\ncontinuously around any geometry. Artists frequently struggle with conventional\nmethods, and it is hard to hide seams while avoiding excessive texel distortion. Also,\nexposed corners can be scuffed, concealed corners can gather dirt, and surfaces\nexposed to the sun will be bleached.\n\naching\n\nRaa Na RTT AN\n\nSRSA RSENS\n\nAt the heart of a typical graphics system is a texture cache. The graphics system can\nthen composite the various source textures together in cunning ways to create the\nfinal result. In some cases, this composition might be complex and slow, so it is\nimportant to avoid cache thrashing in order to be compatible with ‘dumb but fast’\ncaches (e.g., the Direct3D texture cache).\n\nIf you expect or find the texture cache to be relatively slow, some simple refine-\nments can be made to improve performance. For example, you can work out the\nhighest-resolution mipmap level that will be required for a given texture on an object.\nThis is usually as simple as dividing a constant (calculated offline) by the object’s dis-\ntance and taking the base-2 logarithm. This gives a conservative estimate and assumes\nthat the texture will be viewed perpendicular to the viewer's line of sight. More-\naggressive estimates that take viewer/surface orientation into account can be made,\nbut they are more expensive (for example, on a curved surface, it is likely that some\n\npart of the texture will always be roughly perpendicular to the viewer).\n\nay\n\nThe simplest method is the Photoshop ‘stack’ method—a series of RGBA layers, each\nwith a source texture, composited on top of the last result with a type of blend. How-\never, any useful blending controlled by random numbers requires a more-complex\nsystem based on a tree of blends, not just a single stack. In addition, you are often\nrequired to composite together many alpha channels and then do a color blend using\nthe resulting alpha channel. Since these alpha channel-only blends are common, there\nneeds to be an explicit way of labeling layers and blends as alpha-only to ensure that\nfull 32-bit RGBA textures are not used all the time—thus, ensuring more-efficient\nmemory access.\n\nThe tree model is only required for a tenth of the blends in most cases. We will\nrefer to layers and blends between them, rather than tree nodes and leaves, regardless\nof the internal representation.",
      "content_length": 2712,
      "extraction_method": "OCR"
    },
    {
      "page_number": 450,
      "chapter": null,
      "content": "4.17 Unique Textures 461\n\nLayer Mapping and Transforms\n\nThe most fundamental aspect of a layer is its mapping onto the geometry. This is usu-\nally determined by the 3D package: either by explicit uv mapping, or by some sort of\nplanar or spherical projection. This includes the layers representing source textures,\nthe intermediate layers, and, most importantly, the target layer—the texture that will\nbe generated by the composition and actually passed to the graphics chip to texture\nthe image.\n\nThe mapping of the source and target layers do not need to have any relationship\nto each other. Frequently, a single source will be mapped over a join between two or\nmore target textures, ensuring a smooth transition between the two. Typically, data on\nsource layers and for mapping will be determined per-vertex rather than per-triangle,\nwhich allows textures to be combined to flow continuously over any surface shape. In\nmany cases, at a particular vertex, some layers will be discontinuous (such as paint\nschemes on walls or vehicles), while others will be continuous (such as dirt or scratch\nmarks). When designing the data structures, it is important to remember that in most\ncases, an object cannot simply be partitioned into different materials with one texture\nper material. Once the composition is done and the target textures are generated, this\nis precisely what happens to the data that is passed to the low-level mesh rendering\nsystem, but this model does not work at a higher level.\n\nIn addition to raw layer uv mapping data, additional data can be held at each ver-\ntex. This data can control aspects of the blends performed and will usually be linearly\ninterpolated between the vertices. For example, the random numbers that control a\nblend might be biased and scaled by values held at each vertex; this way the artist can\nlabel some vertices as more dirty or less dirty, rougher or smoother, and so on. Getting\nthese values into the 3D model is a problem that some 3D packages do not handle\nvery well (vertex coloring is poorly supported, and multiple channels can be even\ntrickier). In some cases, these values might need to be encoded into another texture\nlayer instead and possibly converted to per-vertex values later by a preprocessing stage.\n\nLayers can also have their wv mappings perturbed or determined by various other\nmethods. For example, rotations, scales, skews, and so on are all possible (usually con-\ntrolled by random numbers), as are hard-coded complex methods—for example, a\nbrick wall might be generated by compositing many individual source bricks, each\nbrick taken randomly from a selection of 20 or so. In this case, the source of the brick\nis a random number, quantized to 20 positions, and the destination is the staggered-\nbrick pattern of the wall. This would normally be done with two transforms, one to\nshift the chosen source brick to the upper-left corner and one to shift it into the cor-\nrect position on the target texture. At runtime, the two would be combined in an\noverall uv transformation before any texels were actually read.",
      "content_length": 3081,
      "extraction_method": "OCR"
    },
    {
      "page_number": 451,
      "chapter": null,
      "content": "The layers can be derived from a variety of methods. For example, the artist can sup-\nply a bitmap, or procedural data, such as Perlin noise [Perlin], or cellular automata\n(CA) to generate moss or wood grain [Ebert94]. All the parameters for these various\nmethods can be derived from per-pixel or per-vertex factors supplied by the artists or\nfrom pseudo-random numbers derived from the supplied information.\n\nThe sources can also be filtered. The most usual filter is a simple scale and bias on\nthe RGB or alpha values, especially when applied to noise functions or other similar\nremappings, such as sigmoid curves or step functions. Interpolating splines of 1° to 4°\ncan be useful and give the artist gamma, contrast, and brightness controls with a sin-\ngle graph. Most of these methods simply generate a 256-entry lookup table (or some-\ntimes three different RGB tables), and this is then applied to the image. Other\ncommon filters are blurs and edge-finding methods, and similar 2D convolution-\nkernel-based techniques. These are implemented as single-source blends.\n\nCompositing Methods\n\nSERRE RAR SOR HOSE RCNA ARATE CARE STAR ER TNS SARE NSDL IONE\n\nMost of the standard Photoshop blends should be supported, such as the standard\nalpha blend, multiplicative, additive, subtractive, and so on. Table 4.17.1 shows some\nsimple Photoshop blending methods with their equivalent mathematics and alpha-\nblend settings. Note that these blends will frequently be applied using alpha blends,\nnot using multitexture. Although in many cases using multitexture methods is theo-\nretically more efficient than multiple alpha-blending passes, in practice it is some-\ntimes a struggle to conform to the restrictions of multitexture.\n\nIn some cases, triadic blends—blends with three sources—can be required, for\nexample, in a blend between two alpha channels with the blend factor determined by\na third alpha channel. Sometimes this requirement can be worked around using mul-\ntiple two-argument blends, but this will be slower and less flexible, so it is worth keep-\ning the blend architecture open enough to allow blends that take any number of\n\nTable 4.17.1 Photoshop Blending Methods and the Equivalent Multipass Alpha Blend\nSettings\n\nPhotoshop Blend Mathematical Operation\n\nAlpha Blend (source, combine, destination}\nNormal Arg1*alpha + Arg2*(1-alpha) SRCALPHA, ADD, INVSRCALPHA\n\nMultiply Argl * Arg? DESTCOLOR, ADD, ZERO\nAdditive Argl + Arg2 ONE, ADD, ONE\nSubtractive Arg] — Arg2 ONE, SUBTRACT, ONE\nScreen Arg1+Arg2-Arg1*Arg2 INVDSTCOLOR, ADD, ONE\nLighten Max (Argl, Arg2) ONE, MAX, ONE\n\nDarken Min (Argl, Arg2) ONE, MIN, ONE",
      "content_length": 2619,
      "extraction_method": "OCR"
    },
    {
      "page_number": 452,
      "chapter": null,
      "content": "4.17 Unique Textures 463\n\ninputs. Triadic blends should be implemented using multitexture hardware if possi-\nble, as this avoids additional temporary textures.\n\nNumber Controls\n\nEN SANTANDER ONE RAN RRR NNR aa\n\nAs a result of using unique texturing systems, artists require increasingly sophisticated\nways to generate numbers as blend factors or mapping transforms. At first they need\nobvious things in the system—a slider they can move, a pseudo-random number gen-\nerator with fixed scale and bias, and so on. Then they might want to make a hundred\nof the objects and only use one slider to control the parameters of all the objects.\n\nYou might find the need for variables and mathematical operations on them, in\nwhich case you could employ a full programming language (Python, LUA, LISP,\netc.—take your pick). However, artists prefer more-visual programming techniques—\nboxes that hold variables, arithmetic operations, and so on. So, you might want to\nconsider a graphical representation. In practice, we found that a tree structure pre-\nsented in a similar style to file-selector trees was best for calculating values. We added\ndraggable rubber-band lines between them for showing where the results were used in\nthe blends or other calculations.\n\nDynamic Textures\n\nSSSR RSA RRA ee eA SRR RR\n\nSERN!\n\nAnother powerful technique changes the layers according to gameplay. The most\nobvious examples are footprints, blood splatters, bullet holes, and explosion scorch\nmarks. These are typically simple layers that have their 4» mappings determined in\nreal-time. The advantages of these over conventional geometry decals is clear: There\nare no z-fighting issues, no extra geometry required to draw each frame, a much wider\nvariety of effects and texture variations are possible without losing batching efficiency,\nand much ‘smarter’ blends are possible.\n\nOne example when dynamic texture blends might be useful is on bump maps.\nSimply alpha-blending multiple Dot3 bump maps together does not work very well.\nThey overlap (e.g., multiple footprints in sand), and typically the interaction between\nthem does not make sense—one footprint simply obscures part of the another com-\npletely. However, we can composite the individual heightfields of the footprints using\na max blend that takes the maximum of the two height values (or indentations). Once\nthey are composited, the result is added to the original surface’s heightfield. Only then\nis the complete heightfield turned into a Dot3 normal-map texture with a filter. With\nstandard decals that simply alpha-blend into the frame buffer, this sort of compositing\nis impossible.\n\nAnother use of this method is to composite multiple shadow maps together in a\nscene. For example, in a forest, the shadow maps of trees do not actually need to pre-\ncisely match the shape of the trees—using just three or four different maps can easily\nprovide enough variation to fool the eye. This method would increase texture-cache\nperformance. As an additional bonus, the shadow map can be recomposited if, for",
      "content_length": 3038,
      "extraction_method": "OCR"
    },
    {
      "page_number": 453,
      "chapter": null,
      "content": "464 Section 4 Graphics\n\neee sorrento anette ene noecnnesa N\\aeoEontncneeel ee ceMeeeeK RECO ERO\n\nexample, any trees are destroyed during gameplay. Alternatively, as the sun moves, the\nshadow maps can be recomputed with the new light-source direction in mind.\n\nScalability and portability are important on PC systems as well as consoles. It is\nimportant to spend the available cycles and memory where the player can see it.\n\nUnique texture systems already have scalability built in. Using a simple distance-\nbased estimation of the maximum size of mipmap level, the compositing is done only\non the texels that are likely to be visible. This optimizes CPU time and enables video\nmemory to be used more efficiently to generate higher-resolution textures only on the\nobjects that are visible.\n\nUsing a scalable system also allows for more realism when it’s most needed. For\nexample, in a hectic firefight, players care about frame rate, not the quality of the tex-\ntures. When the firefight is over, the player can admire their gruesome handiwork.\nWith less movement, fewer textures are being brought into the cache every second,\nand frame rate is not so crucial, so the composition system can spend more time on\nthe textures.\n\nThings that can be done to enable this scalability are:\n\n* Reduce the size of source textures, using smaller mipmaps. This increases mem-\nory cache efficiency and reduces disk accesses on a demand-loaded or virtual-\nmemory system.\n\n* Reduce the size of target textures. This means fewer texels to composite and\nreduces swapping of textures in and out of video memory.\n\n* Simplify sampling filters. Instead of Gaussian or trilinear filters, use bilinear fil-\nters or even-point filters.\n\n* Simplify image filters. Light blurs or edge-enhancements can be omitted alto-\ngether, and filters that use large convolution kernels can be replaced by lower-\nquality versions using smaller kernels.\n\n* Reduce the number of blends by marking certain blends with a level-of-detail fac-\ntor. For example, detail textures and decals can be removed or reduced without\ntoo much quality loss. They can always be added back in when the scene's level of\ndetail increases again.\n\nSome of these items can also be applied selectively to distant textures.\n\nSomething to be careful not to do is recompositing all textures when the scene-\nwide level of detail changes. This will lead to two problems: First will be a large frame-\nrate stall as every texture in the scene is recomposited. Second, all the textures will\nvisibly change, giving a nasty, popping effect. A far better method is to only recom-\nposite textures when they are offscreen. If a texture does need to be recomposited\nwhile onscreen for whatever reason, at least spend the time to alpha-blend between\nthe two versions in order to eliminate the visible pop.",
      "content_length": 2823,
      "extraction_method": "OCR"
    },
    {
      "page_number": 454,
      "chapter": null,
      "content": "4.17 Unique Textures 7 465\n\nIdeally, all compositing would be performed by the graphics chip. That is what the\ngraphics chip is designed to do—take several textures, apply uv transformations to\nthem, apply some pixel effects to them, and then blend them with an existing image.\nIt is designed to do all this in parallel, achieving amazing throughput. Unfortunately,\nsome of the filters and blends that are required are fairly complex, and hard or impos-\nsible to do on the majority of graphics chips. Additionally, there are often problems or\nspeed penalties when swapping source and target textures in and out of video mem-\nory, and performing the compositions on the graphics chip can become counterpro-\nductive. There will always be a blend that an artist vitally requires near the end of a\nproject that just cannot be done by the graphics chip. For this reason, it is a good idea\nto always have a method of composition that is entirely CPU-based, even if a lot of\nthe operations can then be moved to the graphics chip for speed.\n\nPc\n\nThe PC’s CPU is good at compositing. The MMX (SIMD small-integer) instructions\nare powerful and fast, and most simple blends and filters will be limited by memory\nbandwidth rather than CPU speed. Memory is plentiful and backed by a ‘huge’ vir-\ntual memory store that is itself a form of cache.\n\nUsing the graphics chip to perform composition is trickier for PC games than for\nconsole games. The wide diversity of PC graphics cards makes life particularly diffi-\ncult here. Render-to-texture capabilities vary widely (even on recent cards) from no\nsupport to full support. Additionally, the range of blends and filters available again\n\nvaries widely, and many require multiple passes to emulate, reducing speed.\n\nXBox\n\nThe XBox shares some similarities with the PC. The CPU is the same, and it has very\nfast MMX instructions for image composition, so that part of the pipeline can be\nshared. However, the graphics chip is smart and can do 90% of the filters and blends\nthat are required without CPU assistance. Best of all, the graphics chip and CPU\nshare the same memory, which means that at each stage of the composition, the faster\nof the two can be used for that stage. Since graphics data is all stored in system mem-\nory, there is no need to worry about copying the data back and forth. Unfortunately,\nthis does create some bandwidth and fill-rate issues.\n\ned on the CD-ROM shows a very simple procedural landscape.\nThere is only one source texture used, which has been colored differently according to\nthe terrain type at each vertex. The texture is also shifted randomly at each vertex\nbefore being applied. When compositing a particular texture, the terrain types for\neach of the 25 vertices on that texture are blended together. Then, any decals (here a",
      "content_length": 2800,
      "extraction_method": "OCR"
    },
    {
      "page_number": 455,
      "chapter": null,
      "content": "466 Section 4 Graphics\n\nsimple-colored ‘splat’) are alpha-blended over the top. The data for the decals hangs\noff the nearest landscape vertex, so retrieving the relevant list of decals for a particular\ntexture is very quick.\n\nHolding down the shift key shows a false-color picture of the different mipmap\nlevels used—all the mipmap calculations are done as if the camera were placed in the\nmiddle of the landscape. The central mipmaps are 256 X 256 texels, reducing by a fac-\ntor of two each time with distance.\n\nThis demo illustrates several things. Seamless texturing using a small number of\nsource textures (just one in this case) is simple and effective. A large number of decals\ncan be applied to a surface with relatively minor speed penalties, unlike traditional\nframe-buffer composition. A smart texture cache and simple distance-based mipmap-\nping substantially reduces the amount of compositing and texture memory required.\nFinally, even a software implementation of composition can be quick and effective—\nthis demo uses no graphics hardware capabilities for its compositing.\n\nUnique texturing encompasses a whole range of interesting features. The main aim is\nto make every texture in the world unique and to remove the cookie-cutter look from\ngames. The same technology can be used for cunning effects.\n\nImmersion is improved by having surfaces change depending on their positions\nin the game world. Extra details normally produced with detail textures, light maps,\nand decals can be added more efficiently, cheaper, and with more flexibility. Artists’\ntime is reduced by freeing them from large amounts of tedious pixel-pushing, even on\nhuge and diverse worlds, while allowing them more time to fine-tune the really\nimportant bits of a scene.\n\nFinally, using a scripting language to drive the texture-composition engine gives\nartists and designers awesome flexibility and opportunity to create worlds with a look\nnot commonly seen in today’s computer games.\n\nReferences\n\n[Ebert94] Ebert, et al., Texturing and Modeling: A Procedural Approach, AP Profes-\nsional, 1994.\n\n[Milliger02] Milliger, Mike, “Procedural Texturing,” Game Programming Gems 3,\nCharles River Media, Inc., 2002.\n\n[Perlin] Ken Perlin’s page about noise: http://mrl.nyu.edu/ ~ perlin/doc/oscar.html.",
      "content_length": 2280,
      "extraction_method": "OCR"
    },
    {
      "page_number": 456,
      "chapter": null,
      "content": "4.18\n\nTextures as Lookup Tables\nfor Per-Pixel Lighting\nComputations\n\nAlex Viachos, John Isidoro,\nand Chris Oat; ATI Research\n\nAlex@Vlachos.com, jisidoro@atil.com,\ncoat@ati.com\n\nhe latest generation of graphics hardware has brought forth a new level of per-\n\npixel programmability for real-time applications [Microsoft02]. However, they\nare limited by both the size and the types of instructions that can be performed.\nBecause of this limitation, programmers need to utilize a new set of tricks to perform\nmore-advanced graphics algorithms on a per-pixel basis. In this gem, we show ways to\nuse texture maps as a means to solve functions through a lookup table, focusing on\nlighting computations. This technique saves precious pixel shader instructions, and in\nmany cases, it is the only way to make certain per-pixel effects possible on the current\ngeneration of hardware.\n\nSpecular Per-Pixel Lighting Without Using a Cube\n\nthat the halfway vector, 4, can become denormalized when it is linearly interpolated\nacross a polygon. One standard solution is to use a normalization cube map to renor-\nmalize the halfway vector [Baker01]. Normalization cube maps have the disadvan-\ntages of requiring an additional texture fetch as well as consuming a lot of texture\nmemory. An alternative to using normalization cube maps followed by a 1D specular\ntexture fetch is to use an 2.4/h.h map as a lookup table in your shader. This optimiza-\ntion reduces the number of texel fetches required per pixel from two to one. However,\nthe normalization cube map is still used to normalize tangent space light vector, /.\n\n¢ Fetch 7 (per-pixel normal) from the normal map (bump map).\n¢ Halfway vector (H) is stored as a 3D texture coordinate and interpolated across\nthe polygon causing it to be denormalized at each pixel.\n\n467",
      "content_length": 1805,
      "extraction_method": "OCR"
    },
    {
      "page_number": 457,
      "chapter": null,
      "content": "468 Section 4 Graphics\n\nFIGURE 4.18.1 n.h/h.h Map (k = 32). An example of a procedurally created n.hih.h\nmap that allows for per-pixel specular lighting with a specular exponent of 32.\n\n* Store ./ in the first component of the texture coordinate.\n\n* Store 4.4 in the second component of the texture coordinate.\n\n* Using this 2D texture coordinate, fetch into the n.4/h.4 map. The resulting texel\nfetched is the specular lighting term raised to some constant power &.\n\nCreating the .4/h.h map is relatively simple (see Figure 4.18.1). The map is a\nmonochrome image that potentially uses 1/18th of the texture memory required by a\nnormalization cube map (six RGB color faces of a cube). The 2.h/h.4 map is essen-\ntially a lookup table for the following function:\n\nret) ={((4)((e4\"\")) 4.18.1)\n\nwhich can also written as\n((n.») 1 Jal) (4.18.2)\n\nThe following is a DirectX8.1 pixel shader (Version 1.4) that performs the\nn. hl h.h mapping:\n\n3(0.0, 0.5, 1.0, 1.0)\nSetPixelShaderConstant 0 psCommonConst\nSetPixelShaderConstant 1 ambient\nSetPixelShaderConstant 2 diffuse",
      "content_length": 1062,
      "extraction_method": "OCR"
    },
    {
      "page_number": 458,
      "chapter": null,
      "content": "4.18 Textures as Lookup Tables for Per-Pixel Lighting Computations 469\n\nPer-Pixel Specular Exponent Using an (n.h)}* Map\n\nSetPixelShaderConstant 3 specular\nStartPixelShader\nps.1.4\ntexld r0O, tO ;normal map n\n;tangent space H (not necessarily normalized)\ntexcrd r2.rgb, t2\n;tangent space L (normalizer cube map lookup)\ntexld r4, t1\ndp3_sat r4, rO_bx2, r4_bx2 ;(n.1)\ndp3_sat r3.r, rO_bx2, r2 ;(n.h)\ndp3_sat r3.g, r2, r2 ;(h.h)\nphase ‘\n;Base map\ntexld ri, to\n3(n.h)/(h.n)*k map lookup\ntexld r2, r3\nslight = n.1 * diffuse + ambient\nmad r5.rgb, r4, c2, cl\n;basemap * light\nmul r5.rgb, r1, r5\n3(specular * color) + (basemap * light)\nmad_sat rO.rgb, r2, c3, r5\nt+mov_sat r0.a, cO.b\nEndPixelShader\n\nee\n\nSSSI ASEAN OAUTH RRRRARURROR RRR RSENS RRS\n\nUsing a method similar to the one previously described, it is possible to specify a\nunique specular exponent on a per-pixel basis. This requires some additional math in\nthe pixel shader. A specular exponent (shininess) map, as well as the creation of an\n(n.h)* texture, is also required. The grayscale specular exponent map is often stored in\nthe alpha channel of the base texture. This is what an artist paints to define the spec-\nular exponent & at each pixel.\n\nFetch x (per-pixel normal) from the normal map (bump map).\n\nFetch & from the exponent (shininess) map.\n\nHalfway vector (H) is stored as a 3D texture coordinate and interpolated across\nthe polygon causing it to be denormalized at each pixel.\n\nStore (7.4) in the first component of the texture coordinate.\n\nStore (&*4./) in the second component of the texture coordinate.\n\nStore (4.4) in the third component of the texture coordinate.\n\nA projective, dependant texture fetch is required into the (7.4)* map. The projec-\ntion causes the first two coordinates to be divided by the third, resulting in\n((n.4)?/(h.A), k). The texel fetched with these coordinates is the specular lighting\nterm raised to the per-pixel power &.\n\nJust like the .4/h.4 map, the n.4* map is used to reduce the amount of math you\n\nwould otherwise have to do explicitly in the pixel shader (such as normalizing 4 and\nraising 7.4 to a power of &). In this case, & = [0.0, 1.0], where 0.0 corresponds to the\nminimum & value used during (n.4)* texture creation, and 1.0 corresponds to the",
      "content_length": 2257,
      "extraction_method": "OCR"
    },
    {
      "page_number": 459,
      "chapter": null,
      "content": "470\n\n: Section 4 Graphics\n\nmaximum & value in the n./* texture. When doing the dependent texture fetch, use\nthe projective divide (_dz in D3D) to divide the first two coordinates by the third.\n\nThis projective divide causes the resulting texture lookup coordinates to be:\n\n$= ((n.) * (»4)) / (4.4) = (n.h) | (4.18.3)\nt-k\n\nFor n.h* mapping, the texture lookup table computes the following function:\n\nf (st) = °°\" (4.18.4)\n\nBy performing the texel fetch from this map, using the above coordinates, the\nequation becomes:\n\n((v.4) / fal)’ (4.18.5)\n\nThis results in the standard Phong specular lighting component raised to the\nexponent &. The beauty of this technique is that the projective texel fetch both nor-\nmalizes the 4 vector and performs the exponentiation. The tiled quad at the bottom\nof Color Plate 14 was rendered using an (n./4)* map to achieve varying degrees of spec-\nular lighting on a per-pixel basis. The specular exponent varies per-pixel as defined by\nthe exponent map shown in Figure 4.18.4. Figure 4.18.3 is an example of a procedu-\nrally generated (n.4)* map that allows for per-pixel specular lighting with a per-pixel\nexponential range of [0, 64].\n\nFIGURE 4.18.2 An RGB texture of a tiled surface without any lighting.",
      "content_length": 1238,
      "extraction_method": "OCR"
    },
    {
      "page_number": 460,
      "chapter": null,
      "content": "4.18 Textures as Lookup Tables for Per-Pixel Lighting Computations\n\n471\n\nFIGURE 4.18.3 A procedurally generated (n.h} (k=[0,64]) map that allows for per-\npixel specular lighting with a unique specular exponent specified at each pixel.\n\nFIGURE 4.18.4 Grayscale specular exponent map that is used in combination with the\ntexture from figure 4.18.3 to obtain artist-editable per-pixel specular exponents.",
      "content_length": 401,
      "extraction_method": "OCR"
    },
    {
      "page_number": 461,
      "chapter": null,
      "content": "472\n\nColor-Shift Iridescence\n\nSection 4 Graphics\n\n;(0.0, 0.5, 1.0, 1.0)\nSetPixelShaderConstant 0 psCommonConst\nSetPixelShaderConstant 1 ambient\nSetPixelShaderConstant 2 diffuse\nSetPixelShaderConstant 3 specular\nStartPixelShader\nps.1.4\n;dot 3 map (specular exponent stored in alpha)\ntexld r0, to\ntexcrd r2.rgb, t2 ;tan H\n;tangent space L (normalizer cube map lookup)\ntexld r4, t1\ndp3_sat r4, rO_bx2, r4_bx2 ;(n.1)\ndp3_sat r3.b, r2, r2 ;(h.h)\ndp3_sat r3.r, rO_bx2, r2 ;(n.h)\nmul r3.g, r3.b, rO.a ;k*((h.h))\nmul r3.r, r3.r, r3.r 3(n.h)*2\nphase\n;Base map\ntexld r1, to\n;Attenuated (n.h)*k map\ntexld r2, r3_dz\n3n.1 * diffuse + ambient\nmad r5, r4.r, c2, cl\n;diffamb = basemap * (n.1 * diffuse + ambient)\nmul r5.rgb, r1, r5\n;diffamb + (specular * specular color)\nmad_sat rO.rgb, r2, c3, r5\n+mov_sat r0.a, c0.b\n\nEndPixelShader\n\nAnother rendering effect using texture lookup tables is color-shift iridescence. This\ntype of iridescence can be seen on insects’ wings, certain finishes on glasswork, and\npearl-like objects. The effect this algorithm simulates is based on the empirical obser-\nvation that the color at a particular point on an object tends to change in hue depend-\ning on the angle between the view vector and the surface normal. This is usually\ncaused by a thin layer of semitransparent film on an object that diffracts different fre-\nquencies of incident light in different directions. The base algorithm performs stan-\ndard Phong lighting and then multiplies the specular highlight color by a texel\nfetched from a 1D, hue-based gradient texture addressed by (n.v), where 7 is the per-\npixel normal, and v is the tangent space view vector. See Color Plate 15 for images of\nhue-based gradient and objects rendered using color-shift iridescence. The following\npixel shader performs the color-shift iridescence. Note that this example uses the\n(n.h)* technique of the previous subsection.\n\n3(0.0, 0.5, 1.0, 1.0)\nSetPixelShaderConstant 0 psCommonConst\nSetPixelShaderConstant 1 ambient",
      "content_length": 1985,
      "extraction_method": "OCR"
    },
    {
      "page_number": 462,
      "chapter": null,
      "content": "4. 18 Textures as Lookup Tables fe for Per-Pixel Lighting Computations © 473\n\nSetPixelShaderConstant 2 diffuse\nSetPixelShaderConstant 3 specular\nStartPixelShader\n\nps.1.4\n\n;dot 3 map (Specular exponent stored in alpha)\n\ntexld ro, to\n\n;tan H\n\ntexcrd r2.rgb, t2\n\n;tangent space L (normalizer cube map lookup)\n\ntexld r4, t1\njtangent space V (normalizer cube map lookup)\ntexld r5, 3\n\ndp3_sat r4.gb, r0_bx2, r4_bx2 ;(n.1)\ndp3_sat r4.r, rO_bx2, r5_bx2 ;(n.v)\ndp3_ sat r3.b, r2, r2 ;(h.h)\ndp3_sat r3.r, rO_bx2, r2 ;(n.h)\nmul r3.g, r3.b, rO.a ;k*((h.h))\nmul r3.r, r3.r, r3.r j(n.h)*2\n\nphase\n\n;Base map\n\ntexld ri, to\n\n;Attenuated (n.h)*k map\n\ntexld r2, r3_dz\n\n;Iridescent map 1D tex map lookup\n\ntexld r3, r4\n;lridescent * Specular\nmul_sat rO.rgb, r2, r3\n3n.1 * diffuse + ambient\nmad rS, r4.g, c2, c1\n;diffamb = basemap * (n.1 * diffuse + ambient)\nmul r5.rgb, rt, rs\n;diffamb + specular * specularcolor\nmad_sat rO.rgb, r0, c3, rsd\n+mov_sat r0.a, cO.b\n\nEndPixelShader\n\nPer-Pixel Point Lights with Correct\nPer-Pixel Falloff\n\nASN CR SRAM\n\nAnother useful application for texture lookup functions i is correct per-pixel light\nattenuation. Computing distance falloff for point lights is traditionally sampled at the\nvertices and the distance is then linearly interpolated for per-pixel effects. The prob-\nlem with this approach occurs when a light is near the surface of a large polygon, and\nthere is no vertex to catch the light near the light source.\n\nThe approach for this algorithm is to calculate the distance from each pixel to the\nlight source instead of each vertex. This results in the exact falloff value, based on a\ngiven light source, thus avoiding the common problems with the vertex-based\n\nLARNER TITRES\n\napproach.\n\nThe vertex shader computes the vertex position in normalized light space (NLS)\ninstead of directly using the distance from the vertex position. The NLS transform is\na translation by (-lightPos), then a uniform scaling by (1 / lightFalloff). This",
      "content_length": 1958,
      "extraction_method": "OCR"
    },
    {
      "page_number": 463,
      "chapter": null,
      "content": "474 Section 4 Graphics\n\nFIGURE 4.18.5 1D point light texture that renders light color and intensity change as a function of\ndistance from the point light source.\n\ngives us each vertex’s position in NLS. The pixel shader then computes the distance\nsquared on a per-pixel basis by simply taking the dot product of this interpolated ver-\ntex position with itself. Then, a 1D texture is sampled using the NLS distance squared\nas the texture coordinate. This allows you to vary the intensity and color of the light\nusing distance in any way possible. The per-pixel nature of the algorithm solves any\nvertex-sampling issues. Since NLS position is linear by definition, this approach\nworks perfectly without artifacts. This method hides a per-pixel square-root function\nin a texel fetch (see Figure 4.18.5).\n\nPer-Pixel Spotlights and Directional Lights with\nCorrect Per-Pixel Falloff\n\nA natural extension of the per-pixel point light attenuation is to model spotlights and\ndirectional lights. This technique is similar to the point light shader above, but it\nrequires slightly different vertex and pixel-shader operations. Instead of creating a 1D\ntexture for the light, a 2D texture is required. The # axis of the texture is indexed with\ndistance squared in the same way as a point light. However, the v axis of the texture\nencodes falloff based on the spot angle (the angle between the NLS vertex position\nvector and the spotlight direction).\n\nTo use this 2D texture, we extend the notion of normalized light space to repre-\nsent a rotation, as well as extending a scale factor and a translation. This rotation\nmatrix is composed of the light’s orthonormal basis with the light direction as the z-\naxis.\n\nIn the vertex shader, similar to point lights, the vertex position is transformed\ninto normalized light space. In the pixel shader, we can load this new position into a\nregister as a set of texture coordinates and perform a dot product with itself to get the\nNLS distance squared (exactly like point lights, above). This NLS position is also\nloaded into a separate register with a projection modifier, causing the first two com-\nponents to be divided by the first. This will compute the projected position. This pro-\njection performs a divide by z in NLS, which gives the spotlight its cone-like shape.\nThen, by doing a dot product with itself, we get a squared, scaled distance from the\nNLS z-axis, which acts like an ‘angle’ in the range 0-1. If the dot product is done\nwithout a modifier, this value represents an angle of 0°-90°.\n\nThese two dot product values are then used as a lookup into a 2D texture, which\nis a visually convincing approximation to the usual spotlight distance multiplied by\nthe angle equation, assuming squared values as input.",
      "content_length": 2753,
      "extraction_method": "OCR"
    },
    {
      "page_number": 464,
      "chapter": null,
      "content": "4.18 Textures as Lookup Tables for Per-Pixel Lighting Computations 475\n\nTable 4.18.1 Available Scale Factors and Resulting Frustum Angles\n\nScale Factor _d8 _d4 _d2 None _x2 _x4 _x8\nFrustum Angle (°) 165.7 151.9 126.8 90.0 53.1 28.1 14.3\n\nIf we simply do a dp3 as written below, the 2D texture map represents values\nwithin a 0°-90° light frustum. This means that the texture created for the spotlight\nmust encode the full 0°-90° frustum. For lights with larger or smaller cones, texels can\nbe better utilized by selecting an appropriate range. Using scale factor instruction\nmodifiers, the 2D texture can represent other frustum angles. The formula for frus-\ntum angle is 2*arctan(1/scale factor). Table 4.18.1 shows the available scale factors\nand the resulting frustum angle:\n\nBy using the scale factors for the frustum angle, the y resolution of the texture\nlookup table can be decreased for smaller frustum angles because much less space is\nbeing represented. If the desired frustum angle is not listed in the table, just choose\nthe closest table entry that is larger than the frustum to be represented, and make up\nthe difference by scaling down the lookup table in the y direction.\n\n;(0.0, 0.5, 1.0, 1.0)\nSetPixelShaderConstant 0 psCommonConst\nStartPixelShader\nps.1.4\n;NLS pos\ntexcrd r1.xyz, t1.xyz\n;NLS pos in xy plane scaled by 1/z\ntexcrd r2.xy, t1_dz.xyz\n;distance squared from light\ndp3 ri, ri, ri\n;Sset z= 0\nmov r2.b, cO.r\n;(dist in xy plane scaled by 1/z)*2\ndp3 ri.g, r2, r2\nphase\n;Base\ntexld ro, to\n;Light attenuation\n\ntexld r1, r1\n;Base* light\nmul rO, r0, ri_x2\n5\" * NLL\nmul rO, rd, vO\nEndPixelShader\n\nRemoving the _dw from the second texcrd instruction provides a cylindrical\ndirectional light frustum. This removes the scaling by 1/z of the distance in the xy-\nplane and gives the light’s domain a cylindrical shape (see Figure 4.18.6). Note that\nthis light still has a position and a falloff from that position. If positional distance\nfalloff is not desired, just remove the first dot product and use the second dot product\nto index into a 1D texture.",
      "content_length": 2067,
      "extraction_method": "OCR"
    },
    {
      "page_number": 465,
      "chapter": null,
      "content": "Section 4 Graphics\n\nFIGURE 4.18.6 2D spot/directional light texture that renders how, along one axis, light\ncolor and intensity changes as a function of distance from the light source. The other axis\nrenders how the light changes as a function of angle from the light vector. This example\nassumes a 90° frustum and is a perfect candidate for using the 53.1° frustum to save\ntexture usage.\n\nConclusion\n\n‘SSeoRUTE\n\nORTLAND TASS ANI SHARIN RAEI RRR HITTITE ERP RE ICS LAT OL ANA RTS AN AR UMARINE\n\nWe have shown a variety of effects using textures as function lookups. Using this idea,\nmany graphics algorithms that have been per-vertex-only techniques can now be per-\nformed per-pixel. Of course, these are just a few useful examples of the many effects\nthat can be achieved with this technique.\n\nReferences\n\naR SARA a AN eset eR ERA SA Tn NIT\n\n[Baker01] Baker, D. and C. Boyd, “DirectX 8.0 Shader Applications (Per Pixel Light-\ning),” DirectX Developer Day, 2001, available online at http://www.microsoft\n.com/corpevents/gdc2001/developer_day.asp.\n\n[Microsoft02] MSDN. Microsoft.com, “DirectX 8.1 Pixel Shader Reference,” avail-\n\nable online at http://msdn.microsoft.com/library/default.asp?url=/library/en-us/\n\ndx8_c/directx_cpp/Graphics/Reference/Shader/Pixel/Instructions/Instructions.a\n\nsp, February 2002.",
      "content_length": 1308,
      "extraction_method": "OCR"
    },
    {
      "page_number": 466,
      "chapter": null,
      "content": "Rendering with Handcrafted\nShading Models\n\nJan Kautz,\nMax-Planck-institut fiir Informatik\nkautz@mpi-sb.mpg.de\n\nuite a few techniques have been proposed on how to implement more-complex\n\nand more-realistic shading models for graphics hardware [Heidrich99, Kautz99],\nmaking them useful for games. Still, these techniques are rarely used, probably due to\ntwo reasons: complex implementation issues and unintuitive parameters for the shad-\ning models used. We propose to use a simple technique called normal distribution\nfunction (NDF) shading. \\t allows an artist to handcraft shading models, with the\nshape and color of highlights simply stored in bitmaps. The technique uses per-pixel\nshading, and can also be used in conjunction with bump mapping. Anisotropic shad-\ning models can also be created.\n\nA shading model determines how much light reflects off a surface, depending on the\ndirection to the light source, 4, the direction toward the viewer, v, and the surface\nnormal, n.\n\nSo far, most-interactive rendering systems use the Blinn-Phong [Blinn77] model,\ndue to its simplicity:\n\n= h(n 1) + k(h- n)” (4.19.1)\n\nThe parameter &, is the diffuse coefficient, usually stored in a color texture map;\nk, is the specular coefficient, often chosen globally, but sometimes stored in a gloss\nmap; and the parameter N is the specular exponent, which changes the shininess of\nthe material. The vector 4 is the normalized halfway vector between the view and\nlight directions.\n\nAs you can see, this model mainly uses simple operations, except for the one\nexponentiation. On today’s graphics hardware it can be implemented with a pixel\nshader [Kilgard00, Mitchell01], since dot products and dependent texture reads are\navailable.\n\nss aR\n\n477",
      "content_length": 1729,
      "extraction_method": "OCR"
    },
    {
      "page_number": 467,
      "chapter": null,
      "content": "Section 4 Graphics\n\nNonetheless, the lit objects often look like shiny plastic. It is nearly impossible to\nmake a piece of cloth look like cloth. For anisotropic shading, which is used to render\nmaterials like brushed aluminum, Blinn-Phong cannot be used at all, since it is only\nisotropic (i.e., orientation independent).\n\nPrevious Methods for Incorporating Better\nShading Models\n\nA few methods have been proposed that can incorporate better shading models [Hei-\ndrich99, Kautz99], but these usually have limitations, such as unintuitive parameters,\nor require measured data that is not widely available.\n\nMicrofacet-Based Shading Models\n\n[TRU Rena NE LIER SS NI RAR RENNES PION\n\nSAE CAN NO oe\n\nShading models that are based on microfacets (see [Cook81]) assume that the surface\nconsists of tiny specular facets pointing in different directions (Figure 4.19.1). These\nmicrofacets are so small that they cannot be discerned, but the overall distribution of\ntheir orientations governs the shape of the specular highlight. Hence, all the microfacet-\nbased shading models use the distribution of the microfacet normals 7 ,,. We denote the\nNDF with p(v ,,). What does this distribution tell us? If we look up a value with p(A), it\ngives the percentage of the surface’s microfacets that face toward direction 4.\n\nAs previously mentioned, microfacet models assume that all the microfacets are\nsmall, perfect mirrors. If the halfway vector between the view and light directions is\nthe same as the normal of a perfect mirror, we see the reflection of the light source.\n\nFIGURE 4.19.1 A surface consisting of tiny microfacets and its normal distribution\nfunction.",
      "content_length": 1654,
      "extraction_method": "OCR"
    },
    {
      "page_number": 468,
      "chapter": null,
      "content": "419 Rendering with Handcrafted Shading Models 479\n\nThis is almost true for a surface consisting of tiny microfacets. If there are microfacets\nwith a normal x,, that is equal to the halfway vector 4 between the light and view\ndirections, we see light reflected trom the light source, but at the microfacct scale. he\ndistribution function p(4) tells us what percentage of the incoming light is reflected,\nsince not afl microfacets are oriented in the same direction.\n\nThe specular part of the Blinn-Phong model can be seen as a simple microfacet-\nbased shading model. [t assumes that che orientations of the microfacets have a cosine\nto the power of V distribution.\n\nNOF Shading\n\nThe shading model that we want to use is just a slight modification of the original\nBlinn-Phong model:\n\nL, = h(n L)~ bp(Bigca:)s Pieg = (b&b, bn} (4.19.2)\n\nFisecti\n\nAs you can sec, the only difference is that instead of the fixed cosine’ distribu-\ntion, we use an arbitrary normal distribution function. The surface tangent ¢, binor-\nmal 4, and the normal » define the local surface coordinace frame, which is also\nneeded for bump mapping. If the normal distribution function happens to be pix,,} =\n(n,, °°. we get the original Blinn-Phong model. However, since the normal distribu-\ntion now depends on the full local halfway vector, instead of only its z coordinate\n(simply /-»)}, we can also create anisotropic highlights.\n\nHow To Store the NDF\n\nHow can we store the normal distribution function so that it can be used with graph-\nics hardware? We store it in a 2D texture map. Assuming the microstructure of the\nsurface is a heightfield, the orientations of the microfaccts can only vary within the\nupper hemisphere: in other words, the z coordinates of the microfacets’ normals »,,\nare always positive. Therefore, it is sufficient to use the following two coordinates to\nindex into our 2D p(v,,) texture:\n\nFigure 4.19.1 ilkustrates an example of a normal distribution function that was\nstored in such a way. Imagine a hemisphere where all the values of the normal distrib-\nution function lic. Now, we project this hemisphere onto a square plane. ‘Phis is\nexactly what is shown in Figure 4.19.1 and what the mapping detailed here does.\n\nRendering/Pseudo-Code\n\nSo, how do we render an object with this new shading model? Well, it is not much\nmore complicated than the standard Blinn-Phong model. If we have already created a",
      "content_length": 2404,
      "extraction_method": "OCR"
    },
    {
      "page_number": 469,
      "chapter": null,
      "content": "Section4 Graphics\n\ntexture by storing a normal distribution function, then we need to do the following to\nrender the specular highlight:\n\nGiven:\na light source at position Pgh:\n\n* a VIEWEE at POSITION Pyiewer\nBind NDF texture\nFor every vertex v, of a polygon:\n\n* Compute the normalized vector 1 from vy; to pugs\n* Compute the normalized vector v from ¥; to Pyiewer\n* Compute the halfway vector h = v+l\n\nNormalize h\nRetrieve the tangent t; and the binormal b;\n\n* Compute x, = th*t+1)/2\n* Compute x, = (h*bj+1)/2\n* Set texture coordinates (u,, ,)\n\nu\n\nRender polygon\n\nThe diffuse term can be added either later or in the same stage if multitexturing is\nsupported. An additional gloss map can also be applied, if desired.\n\nGenerating the NDF Texture\n\nSo how do we create such an NDF texture? We use a paint program to model our nor-\nmal distribution, which is equivalent to drawing the highlight itself! Figure 4.19.2\nshows a few highlights and how they look on objects.\n\nWe now will suggest how to use the diffuse term and the new specular NDF term to\ngenerate interesting shading models. If a standard highlight (as in the original Blinn-\nPhong model) is desired, then the NDF texture should probably be grayscale, so that\nyou can change its color according w the light source, The texture should not contain\na directional diffuse term. In Figure 4.19.2, two different NDFs are applied to some\ngeometry; a standard diffuse term was added as well.\n\nMore- interesting shading effects can be achieved by including a (colored) direc-\ntional diffuse term. In contrast to the normal diffuse term, the directional diffuse term\ndepends on 4-7, Therefore, we can include it in the NDF. This directional diffuse\nterm can, of course, have some color, which makes it possible to achieve interesting\neffects.\n\nIn Color Plate 16, on the left, you can sce a piece of cloth rendered with a bluish\ndirectional diffuse NDF plus a red diffuse term. The cloth looks mostly purple, but at",
      "content_length": 1965,
      "extraction_method": "OCR"
    },
    {
      "page_number": 470,
      "chapter": null,
      "content": "4.19 Rendering with Handcrafted Shading Models 481\n\nFIGURE 4.19.2 NDF: applied to a piece of cloth and a teapot.\n\ngrazing angles, the red diffuse term has more influence than the blue directional term,\nmaking the cloth more reddish. In the middle, you can see an NDF that varies from\ndark red to bright red at grazing angles of the halfway vector, which is the opposite\nway an NDF usually looks like. Applying this NDF to the piece of cloth gives it a vel-\nvet-like look. On the right side, we created an anisotropic NDF, which goes from red\nto blue. Now, the cloth looks like anisotropic satin.\n\nBump Mapping with NDFs\n\nNDF shading can be easily incorporated with bump mapping, as long as you have\ndependent texture reads. It is almost equivalent to bump mapping with the Blinn-\nPhong model, only you have to compute the texture coordinates, #, and w,, with the\ntangent and the binormal for the lookup. This makes it necessary to store them in\ntexture maps as well. Here is a pixcl shader (DirectX8.1 notation) chat will do this\ncomputation:\n\nps.1.4\n\ntexld ri, tO ; Normal (tex1)\n\ntexcrd r2.rgb, ti ; Tangent Space 1 vector\n\ntexcrd r3.rgbh, t2 ; Tangent Space Halfangle vector\ntexld r4, tO ; Bainormal (tex4)\n\ntexld rS, tO ; Tangent (tex5)\n\ndp3_sat rt.xyz, ri_bx2, r2 3; r1 = max(n*1,0)\ndp3 r2.x, r4_bx2, r3 ; r2.x = bth\n\ndp3 r2.y, r5_bx2, r3 ; r2.y = t*h\nadd d2 ré.xy, r2, one ; r2 = (r2+1)/2",
      "content_length": 1394,
      "extraction_method": "OCR"
    },
    {
      "page_number": 471,
      "chapter": null,
      "content": "482 Section 4 Graphics\n\nphase\ntexld r0, tS ; tex0.rgb = k_d and tex0.a = k_s\ntexld r2, r2 ; NDF is in texture unit 2\n\nmul rO.rgb, rO, rt ; Kd * {Nn*1)\nMul ri.rgh, rO.a, r2 ; k_s * NDF(}\nadd rO.rgb, rO, r1 5 kd * (Nn*1L) + k_s * NDF{)\n\nExtensions\n\nThe shading model could be extended with a Fresnel term and a (so-called) self-\nshadowing term, which refers to the self-shadowing of microfacets. This is commonly\nused in more-accurate microfacet models [Cook81]. Although these two terms do\nchange the resulting shading, in many cases they do not significantly add to the shad-\ning model, especially if point light sources are used for illumination.\n\nOne other extension is to include the area foreshorting of incident light for the\nspecular term as well:\n\nL, = kg{n-2) + k,p(Poca)(n >) (4.19.4)\n\nThis makes a big difference in the shading, especially if a directional diffuse term\nis encoded in the NDF texture. In the end, however, the use of this additional term\ndepends on the effect/material you wish to create.\n\nConclusion\n\nWe have presented a shading technique that is easy to implement and easy to use. A\nwide variety of materials can be simulated. An artist can modify the appearance of an\nobject in an intuitive way by just painting a highlight and/or a directional diffuse term\ninto a texture! See Color Plate 19 for an example of NDF shading applied to the\nStandford Buddha model combined with a diffuse color. Although there is some\nphysical explanation behind this shading technique, it does not accurately model any\nreal world surfaces. Nonetheless, the visual richness that can be achieved with this\nshading model is fascinating.\n\nReferences\n\n[Blinn77] Blinn, J., “Models of Light Reflection for Computer Synthesized Pictures,”\nComputer Graphics Proceedings (SIGGRAPH 1977), Pp. 192-198.\n\n[Cook81} Cook, R. and K. Torrance, “A Reflectance Model for Computer Graphics,”\nComputer Graphics Proceedings (SIGGRAPH 1981): pp. 307-316.\n\n[Heidrich99] Heidrich, W. and H. P. Seidel, “Realistic, Hardware-Accelerated Shad-\ning and Lighting,” Computer Graphics Proceedings (SIGGRAPH 1999): pp.\n171-178.",
      "content_length": 2105,
      "extraction_method": "OCR"
    },
    {
      "page_number": 472,
      "chapter": null,
      "content": "4.19 Rendering with Handcrafted Shading Models 483\n\n[Kautz99] Kautz, J. and M. McCool, “Interactive Rendering with Arbitrary BRDFs\nUsing Separable Approximations,” Tenth Eurographics Workshop on Rendering,\npp. 281-292, June 1999.\n\n[Kautz01] Kautz, Heidrich W. and H. P. Seidel, “Real-Time Bump Map Synthesis,”\nEurographics! SIGGRAPH Workshop on Graphics Hardware, August 2001, pp.\n109-114.\n\n[Kilgard00] Kilgard, M., “A Practical and Robust Bump-Mapping ‘Technique for\noday’s GPUs,” available online at hetp://developers.nvidia.com, July 2000.\n[MitchellO1] Mitchell, J., “Advanced Vertex and Pixel Shader Techniques,” available\n\nonline at http://www.ati.com/developer, September 2001.",
      "content_length": 683,
      "extraction_method": "OCR"
    },
    {
      "page_number": 473,
      "chapter": null,
      "content": "5.1\n\nMinimizing Latency in Real-\nTime Strategy Games\n\nJim Greer, EA.com, and\nZachary Booth Simpson, Mine Controf\n\njamesfgreer2@yahoo.com,\n0ink54321@yahoo.com\n\nultiplayer real-time strategy games have different networking requirements than\n\ntwitchy action games. Rather than transmitting the millisecond-by-millisecond\nmovements of the player, they must manage hundreds of semi-autonomous units.\nThis allows their network protocol to be optimized in ways that action games cannot.\nIn this gem, we will! describe event-locking, a time-synchronized method well-suited to\nthe coordination of real-time strategy games. The technique could also be applied\nto simulation games and other nontwitch games.\n\nFrame-Locking Versus Event-Locking\n\nEarly networked games, often written for local area network (LAN) play, used a tech-\nnique called frame-locking. Under this method, the clients send out an update every\nframe; at a minimum, this includes all the user input that occurred during the frame.\nThis update might be sent to all other clients (in a peer-to-peer arrangement) or to a\ncentral server that processes it and echoes the results to all clients. In practice, some\nsuch frame-locked games render more than one frame before sending an update; but\nthe updates typically happen at some fixed interval. While this method is suitable for\nLAN play, it does not extend well to Internet play, even under low to moderate\nlatency (150-300 ms).\n\nConsider a network architecture with a central server. As long as all clients are send-\ning in their updates at the same pace, everything is fine. However, if one client’s update\nis not received due to network latency or other reasons, then the server and all other\nclients must freeze, awaiting the arrival of the update. If they were to proceed without\nwaiting for the delayed client's input, the game would immediately be out of synchro-\nnization—the player would see the results of their actions, but no one else would.\n\nFigure 5.1.1 shows an example of this arrangement as an event timeline. For the\nfirst update at time 0, Clients A and B send their updates to the server. The server",
      "content_length": 2125,
      "extraction_method": "OCR"
    },
    {
      "page_number": 474,
      "chapter": null,
      "content": "5.1 Minimizing Latency in Real-Time Strategy Games 489\n\nTime ClientA Server Client B\n\n0\n\ni}\ni\nI\ni]\ni]\nJ\n|\n|\nJ\nI\nt\nt\nt\n|\n|\n|\n|\n|\n|\n|\n|\n|\n|\n|\n|\ni\nI\nl\nI\nI\n\nFIGURE 5.1.1 Freezing under frame-locking: Server and Client A are held up by Client B,\n\nreceives both updates at nearly the same instant and sends the results immediately.\nHowever, for the second update, Client B’s update takes longer in transit due to net-\nwork latency. The server waits, and so does Client A.\n\nThis behavior makes pure frame-locking suitable only for LAN games, but with\nmodifications, it can handle longer latencies. For example, Age of Empires [Bettner01]\nused a peer-to-peer architecture with adaptive communication turn lengths. Pauses\nwould occur when communications weren't received from one machine, but then the\nturn length would be increased to compensate. Instead of more pauses, players would\nexperience slightly diminished responsiveness overall. Unfortunately, the performance\nof the game was still limited by the slowest network connection among the players.\n\nEvent-Locking\n\nWhat is needed is a method that, in contrast to frame-locking, avoids slowing down\nall clients to the speed of the slowest one. We propose event-locking as an efficient\nmethod. Under this method, each client sends requests for events, which are evaluated\nby the server and, if approved, broadcast to all clients simultaneously.",
      "content_length": 1389,
      "extraction_method": "OCR"
    },
    {
      "page_number": 475,
      "chapter": null,
      "content": "Section 5 Network and Muttiplayer\n\nFor example, imagine a typical real-time strategy game in which one player\ndecides that they want to move a tank. The player issues the movement command on\ntheir client, which performs preliminary legality checking. If legal, the client sends a\nRequestMoveTank packet to the server. The server then performs its own authoritative\nlegality check, and upon determining that the movement is legal, sends a MoveTank\npacket to all clients, including the one that originally made the request. (For more dis-\ncussion about selecting what actions to use as events, see [Dickinson01].)\n\nNote that not all clients will receive the event packets at the same time. Therefore,\nevents must be structured so that clients can begin execution at the appropriate time.\nFor example, a movernent event such as the MoveTank packet described above might\ncontain a series of waypoints, each encoded with an arrival time. A client that receives\nthe packet later can either warp the tank to the appropriate current position or, if the\ndifference is small, simply animate its movement slightly faster.\n\nIt might appear that this arrangement would introduce unacceptable delays for\nplayers. If it takes 300 ms or more for their tank to start moving, won't they be frus-\ntrated? The answer is to give the player immediate ‘request feedback.’ In the simplest\ncase, this feedback might be a client-side animation or sound effect. Or, for move-\nment requests, it could be safe to start ‘unofficial’ movement on the client if server\ndenial is unlikely. For example, in the MoveTank example, the tank driver can say “Yes,\nsir!” and start moving immediately, assuming that the server will confirm the move-\nment the vast majority of the time. Figure 5.1.2 illustrates this example.\n\nThere will be cases when the server rejects a client’s request or sends a path differ-\nent than the one the client generated. For example, perhaps just prior to Client A issu-\ning a RequestMoveTank, Client B requested the construction of a building near the tank.\nClient A might create a path that rolls the tank to the north and begins the movement\nin anticipation of the server's authorization. However, because the server knows that a\nbuilding now exists in the tank’s northerly path, it reroutes it to the west. When\nClient A receives the correct path, it must warp the tank from the unofficial path to\nthe correct one, and this might be extremely disconcerting to the player. However,\nunless latency is very high, significant warping will be rare; furthermore, for many\ngames, uncommon but dramatic warping is preferable to the alternative of common,\nbut less-dramatic freezing. Furthermore, the warping will only be experienced by the\nplayer with the poorer connection.\n\nThe fact that some units might be in unofficial positions on a given client means\nthat all important decisions must be handled by che server. In games that don’t have a\nsingle final authority, out-of-sync bugs can be a big problem [Bettner01]. In many\nreal-time strategy games, one of the client machines is also the server. Typically, unit\ncreation, destruction, path-finding, and targeting decisions are server-controlled and\nbroadcast. However, movement and attacks are animated independently on each\nclient, generating no network traffic.\n\nThe following code illustrates how path-finding packets might be exchanged\nbetween the client and server.",
      "content_length": 3410,
      "extraction_method": "OCR"
    },
    {
      "page_number": 476,
      "chapter": null,
      "content": "6.1 Minimizing Latency in Reai-Time Strategy Games 491\n\nTime ClientA Server Client B\n|\n\n0\n4 !\nG9. ; !\nMoy, t\n\nPP |\nSy. | |\n1 i i\nI\n!\nMy !\nOp, |\nang !\n2 i\nI\n\n3\n\n|_|\n\nFIGURE 5.1.2 Zank movement example—the tank moves in boxed areas (gray is\nunofficial movement). All players see the tank arrive at the same time.\n\nvoid MoveableUnit: :moveRequest( Coord destination ) {\n// GENERATE a temporary path and\n// begin traversing it. This will\n// probably be ths same as the path the\n// server finds but not guaranteed:\nsetActivePath(generatePath({destination) );\n\n// SEND a AequestMovement the server,\n// even if this client also happens\n// to be the server:\nsendRequestMovement( destination );\n\n}\n\nvoid handleAequestMovement (\nMoveableUnit aunit,\nCoordinate destination\n\n)¢{\n// This is the handler for the destination\n// request packet. Note that all clients send\n// requests, even the client who also happens",
      "content_length": 901,
      "extraction_method": "OCR"
    },
    {
      "page_number": 477,
      "chapter": null,
      "content": "492\n\nSection 5 Network and Multiplayer\n\n// to be the server\n\n// This can only run on the client who\n// is also the server\nassert( thisClientIsAlsoTheServer );\n\n// €NCODE which unit is to move and compress\n\n// the path into a compact form:\nPath path = unit.generatePath{ destination };\nMovementPacket p = makeMovementPacket({unit, path};\n\n// SEND the packet to every client\n/f including the original sender\n{f/f even if that sender is also the server:\nbroadcast({ p );\n}\n\nvoid handleMovement(MoveableUnit &unit, Path &path) {\n// This function is called in response to\n// a MovementPacket.\n\n// Note: setting the path may induce warping if the new\n// path is not the same as the temporary path on\n\n// the requesting client\n\nunit.setPath{ path );\n\nTransport Layer for Event-locking—TCP\n\nAssumed in the implementation of event-locking is a reliable delivery protocol, such\nas TCP [Postel80-2]. In other game protocols—for example, those that might be used\nin a flight simulator, where units generate traffic as they move—dropped packets are\nnoncatastrophic because newer data will soon arrive to correct the loss. However, in\nevent-locking implementations, the server sends each critical event only once; and\ntherefore, the transport layer must ensure delivery. We have used and were pleased\nwith TCP for this. Some game developers have written their own reliable protocols on\ntop of UDP [Postel80-1], working under the theory that they can reduce latency by\n‘improving’ upon the TCP algorithms. We strongly advise against this approach. Not\nonly is the complexity of the task often underestimated, but so also are the ramifica-\ntions. Smooth operation of the Internet depends upon the well-defined and well-\ntested flow-control mechanisms of TCP. Attempting to override this flow-control\nwith a custom algorithm can induce catastrophic router feedback and possibly even\ntemporary denial of service. (In the case that the game developer deploys their own\ncentralized servers, this denial-of-service would most likely occur on their own\nrouters). One final point against UDP is that it is often firewalled on corporate net-\nworks because it is more difficult to secure. This implies that game developers will\nneed to consider a TCP connection as a protocol-of-last-resort, even in the case that\nthey implement a custom UDP-based system.",
      "content_length": 2330,
      "extraction_method": "OCR"
    },
    {
      "page_number": 478,
      "chapter": null,
      "content": "6.1 Minimizing Latency in Real-Time Strategy Games 493\n\nTime Synchronization\n\nPerformance of event-locking is significantly improved by time-synchronizing the\nclients. For example, imagine that when a unit moves, the server broadcasts a message\nlike: “Move unit X such that it will arrive at position P at time 7 in the future.” With-\nout clock synchronization, time 7 on one client could differ from another client's by\nas much as the current packet latency (which might be much higher than the average\nlatency). In such a case, a player with lower latency will have an advantage because\nthey will see the world closer to the way the server sees it and are thus less likely to\nhave requests denied.\n\nExisting Clock Synchronization Protocols\n\nClock synchronization is a topic of major importance, and several well-developed\nprotocols already exist. The simplest technique is incorporated in the Simple Network\nTime Protocol (SNTP) [Mills96]. In this protocol, the client machine to be synchro-\nnized sends a datagram (UDP) packet to the server, which then immediately replies to\nthe receiver with the time as it is known to the server. Although simple, the SNTP\nalgorithm is not useful when accuracy is critical and latency is variable, because it does\nnot attempt to measure or compensate for latency.\n\nUnlike SNTP, the Network Time Protocol (NTP) [Mills92}] does attempt to\ncompensate for latency by sophisticated statistical methods. Unfortunately, NTP is\nvery complicated and, more importantly, slow to converge on the accurate time delta.\nThis makes NTP less than ideal for network game play where players expect games to\nstart immediately and are unwilling to allow for dedicated synchronization time.\n\nFurther complicating matters, NTP and SNTP both use UDP in place of TCP to\navoid the anomalous latency measurements induced by hidden retransmits thac TCP\nmight generate. As noted above, UDP is often firewalled by many Internet service\nproviders, especially by corporate WANs, and is therefore undesirable.\n\nA Simple Alternative: High Mode Elimination\n\nAn alternative to SNTP and NTP is required for games. Ideally, the protocol should\nbe reasonably accurate (150 ms or better), quick to converge, simple to implement,\nand able to run on stream-based protocols, such as TCE\n\nWe propose the following algorithm, which we call “stream-based time synchro-\nnization with elimination of higher order modes”:\n\n1. The client stamps the current local time on a ‘time request’ packet and\nsends it to the server.\n\n2. Upon receipt by the server, the server stamps its time and returns the packet.\n\n3. Upon receipt by the client, a time delta is calculated by delta = (current Time —\nsentTime) f 2.\n(Note that so far this algorithm is very similar to SNTP}",
      "content_length": 2753,
      "extraction_method": "OCR"
    },
    {
      "page_number": 479,
      "chapter": null,
      "content": "Section 5 Network and Multiplayer\n\n4, The first received result is immediately used to update the clock, since it\nwill get the local clock at least into the right time zone.\n\n5. The client repeats Steps 1 through 3, five or more times, pausing a few sec-\nonds each time. Other traffic might be allowed in the interim, but should\nbe minimized for best results.\n\n6. The time deltas of each packet are accumulated and sorted in lowest-latency\nto highest-latency order. The median is determined by picking the mid-\npoint sample from this ordered list.\n\n7. All samples above that are approximately 1.5 times the median are dis-\ncarded, and the remaining samples are averaged using an arithmetic mean.\n\nThe only subtlety of this algorithm is the discarding of samples with a time delta\nmore than 1.5 times the median. The purpose of this is to eliminate packets that were\nretransmitted by TCP. To visualize this, imagine that a sample of 10 packets was sent\nover TCP and there happened to be no retransmission. In this case, the latency his-\ntogram will have a single mode (cluster) centered on the median latency. Now, imag-\nine that in another trial, a single packet of the 10 is retransmitted. The retransmission\nwill cause this one sample to fall far to the right on the latency histogram, typically\nmore than twice as far away as the median of the primary mode. By simply cutting\nout all samples chat fall far from the median, these stray modes are easily eliminated,\nassuming that they do not comprise the bulk of the statistics, which is likely that they\ndo not.\n\nOne very important consideration in time synchronization is that while the syn-\nchronization is running, #me might go backward! It is extremely critical that any time-\ndependent checks used during time synchronization (¢.g., animations during the\nstartup phase or startup timeouts) do not slave themselves to the clock being synchro-\nnized. Failure to heed this warning could result in odd ‘lock-up’ bugs that will not\nmanifest themselves until play-testing with players who span more than one time\nzone and are therefore likely to be mysteriously unreproducible within the developer's\nworkplace.\n\nThis basic algorithm was tested in NetStorm: Islands At War, a real-time, Internet\nstrategy game co-implemented by the authors at Titanic Entertainment (1997). The\nresults were satisfactory and usually resulted in synchronizations of less than 100 ms.\nAnecdotal evidence in large-scale trials suggested that bad synchronizations due to\nretransmission were infrequent, and when they did occur, were often symptomatic of\nan unusually bad Internet connection that would eventually cause more-catastrophic\nerrors (such as dropped connections), rendering the failure due to time-sync moot.\n\nThe following code sample demonstrates the statistical technique:\n\n// GLOBAL variables holding time samples:\n8&3\n\ntypedef double Time; // or appropriate type for platform\nTime timeSamples[MAX_TIME SAMPLES];\n\nint numTimeSamples; // Num valid samples in the timeSamples",
      "content_length": 3016,
      "extraction_method": "OCR"
    },
    {
      "page_number": 480,
      "chapter": null,
      "content": "5.1 Minimizing Latency in Real-Time Strategy Games 495\n\n// CODE that calculate the time correction:\n{{——- J!\nassert({ numTimeSamples > 2 };\n\n// FIND the median:\nsort( timeSamples, numTimeSamples };\nTime median = timeSamples[ numTimeSamples/2 ];\n\n// FIND mean of samples less than 1.5 times the median:\nsum = (Time)d.0;\nint count = 0;\nfor({ int i=0; i<numTimeSamples; it+ } {\nif( timeSamples[i] - median < (Time})1.5 * median ) {\nsum += timeSamples[i};\ncount++;\n\n}\n4}\n\nTime carrectedDelta = sum / (Time}count;\n\nConclusion\n\nWe had great success using the event-locking method. Our first multiplayer RTS,\nNetStorm: Islands at War, was teleased by Activision in 1997, and despite having heavy\naction with hundreds of units animating at once over eight clients, it required only a\n9600-baud modem on the server machine and even less on the clients. Next Genera-\ntion magazine described the network play as “smooth as silk” even on terrible connec-\ntions. We hope you'll have similar results.\n\nReferences\n\n[Bettner01] Bettner, Paul and Mark Terrano, “GDC 2001: 1500 Archers on a 28.8:\nNetwork Programming in Age of Empires and Beyond,” Game Developer Con-\nference, 2001, available online at http://www.gamasutra.com/features/20010322/\nterrano_01. hem.\n\n[Dickinson01] Dickinson, Patrick, “Instant Replay: Building a Game Engine with\nReproducible Behavior,” Gamasutra.com, July 2001, available online at\nhetp://www.gamasutra.com/features/20010713/dickinson_01.htm.\n\n[Mills92] Mills, David, “Network Time Protocol (Version 3) Specification, Imple-\nmentation and Analysis,” University of Delaware, March 1992, RFC-1305, avail\nable online at hetp://www.eecis.udel.edu/-mills/ntp.hum.\n\n[Mills96] Mills, David, “Simple Network Time Protocol (Version 4),” University of\nDelaware, October 1996, RFC-2030, available online at http://www.eecis.udel\n.edu/~mills/ntp.htm.\n\n[Postel80-1] Postel, J., “User Datagram Protocol, STD 6,” USC/Information Sci-\nences Institute, August 1980, RFC-768.\n\n[Postel80-2} Postel, J., “Transmission Control Protocol, STD 6,” USC/nformation\nSciences Institute, August 1980, RFC-761.",
      "content_length": 2094,
      "extraction_method": "OCR"
    },
    {
      "page_number": 481,
      "chapter": null,
      "content": "5.2\n\nReal-Time Strategy\nNetwork Protocol\n\nJan Svarovsky\n\njan@svarovsky.com\n\nhis gem aims to explain a simple and practical system for connecting up to 10\n\ncomputers over the Internet to play dynamic strategy, management, or combat\ngames. Star Topia [StarTopia01) is a real-time strategy (RT'S) game that supports four-\nplayer multiplay over the Internet. Player interaction involves placing and maintain-\ning facilities, interacting with individual characters, and ordering troops around the\nbattlefield. This gem is based on the simple network protocol we used for this game.\nAlthough this gem is primarily a description of the general principles, it includes our\nexperiences, both good and bad, in an actual commercial implementation.\n\nFirst, we will briefly discuss common protocols that we have come across, then\ncover the basic principles. Following that will be some refinements to the protocol, a\ndescription of modules we found useful, and some of the pitfalls we encountered. We\nwill also include a simplified example game. Part of the system found in Star Topia is\non the CD-ROM.\n\nOther Protocols\n\n496\n\nThe systems that concern us here are for games involving up to 10 players, rather than\nthose for massively multiplayer online games.\n\nClient/Server: First-Person Shooter\n\nThe most common protoco! for first-person action games is that each player is sitting\nin front of a ‘client’ program, which could almost be considered as a dumb terminal.\nA server runs the game, effectively remote from any client, even if in practice it resides\non the same machine as one of the clients. The server tells each client what it can see.\nEach client tells the server what it wants to happen, based on player controls. There\nare refinements to smooth out the game, based on the client’s prediction of server\nresponse.\n\nThis protocol benefits from its simplicity and its ability to avoid cheating (since\nthe server can veto some illegal acts). Clients can drop in and out, but the game on the",
      "content_length": 1987,
      "extraction_method": "OCR"
    },
    {
      "page_number": 482,
      "chapter": null,
      "content": "6.2 Real-Time Strategy Network Protocol 497\n\nserver lives on. However, it does require thar the client’s visible game state is small\nenough that it can be repeatedly transmitted. This limitation eliminates this protocol\nas an option for real-time strategy games where a tremendous amount of game state is\ninvolved.\n\nPeer-to-Peer\n\nWith the peer-to-peer protocol, no computer in the game is more important than any\nother. Each computer ‘owns’ a part of the game state and has a final say on what hap-\npens to that part (typically, the game-player entity and a few AI agents).\n\nThe benefit of this protocol is that the game state owned by the computer is\ninstantly updated. In an ideal world, your computer owns the AI agents that are clos-\nest to you, since they are not as important to other players that are farther away. The\ndownside is that any interaction between two characters or objects in the game must\nhave a corresponding network packet so that different computers can establish a con-\nsistent outcome. Of course, as the size of the game state increases, the number of\npackets sent around the network communicating state increases quadratically.\n\nLockstep\n\nAs the name implies, a game using this protocol runs in lockstep with ali computers\ninvolved. They start with the same game state, and game time is split into turns. With\neach turn, each computer models the game world to advance the action by one step.\nAt the end of the turn, each machine tells every other machine what actions the user\nhas performed. Since all of the computers know what all users are doing, they can col-\nlectively model the next game turn and stay synchronized.\n\nThis is an easy protocol to implement and has a relatively low bandwidth, since\nuser input (which might be idle for many frames) is all that needs to be transmitted.\nThe bandwidth is also unrelated to the size of the game state, which is a big advantage\nfor real-time strategy games.\n\nA problem with this protocol is chat the number of game turns per second is lim-\nited by the round-trip network delay; at the end of each game curn, the machines\nmust receive at least an acknowledgement from all the other machines before model-\ning the next turn. Keeping the machines synchronized is also fairly difficult. You have\nto ensure that no user actions directly affect the game, but rather indirectly affect the\ngame via the network code. This ensures thar all machines are acting on the same\ninformation, and this discipline must be followed. Similarly, you have to keep their\nrandom-number generators synchronized.\n\nIn a similar way to the client/server system, some cheats are difficult because any\nillegal changes enacted on the game state will cause that machine to fall out of sync\nwith the other machines. On the other hand, because the entire game state is available\non each machine, other cheats become possible—for example, changing the game to\nbe able to see more of the map than usual.",
      "content_length": 2943,
      "extraction_method": "OCR"
    },
    {
      "page_number": 483,
      "chapter": null,
      "content": "498 Section 5 Network and Muitiplayer\n\nOur Protocol\n\nWe based our protocol on the lockstep system, with several changes to limit its short-\ncomings. One machine is declared the server in order to keep the network traffic lin-\nearly proportional to the number of players. Otherwise, the network traffic is\nproportional to the square of the number of players. Each client only sends one\npacket per event (to the server), rather than one to each of the other clients. This\nmethod enables the server to be in charge of negotiating the game state when a\nmachine drops its connection.\n\nWith lockstep, the clients collect input from the others between each game turn.\nHowever, we can remove this round-trip network delay between turns. The server\nsimply broadcasts ‘advance the turn’ packets on a regular basis, and user input from\neach client is broadcast to all machines upon being received by the server. This means\nthat each uset-input event must make the trip to the server and back before it can be\nprocessed, but the game turns continue to occur at a steady pace in the meantime (see\nFigure 5.2.1).\n\nThe main features of this system are as follows:\n\n* At the start of play, the state of the game on all machines is identical.\n\n* The server then sends an identical stream of packets to the clients. This is a steady\nstream of ‘advance the turn’ packets, interspersed with user input.\n\n¢ The game progresses forward based solely on information received from the\nserver, which is identical for all machines. Therefore, the game stays synchronized\nacross the network.\n\n* For this reason, it is vital to decouple local user input from the local game state.\nUser input gets transmitted to the server, which in turn broadcasts them to the\nother machines so that parallel action can take place.\n\n© Game turns don’t necessarily happen absolutely simultaneously on all computers,\nbut game events occur in the same order.\n\n* There is at least one round-trip delay between a user input and its effect on-\nscreen. (This will be discussed in the next section.)\n\n* All network packets must have guaranteed delivery. You want all user actions to\nget processed, so packets to the server must arrive. Also, packets from the server\nmust arrive in order, so that all clients receive identical event streams.\n\nNumber of Game Turns per Second\n\nSeveral factors must be considered when deciding how many game turn updates\nshould be issued per second. As will be discussed in the next section, the graphics\nengine does not draw the game state as it is, but rather as an interpolated version. This\nmeans that the number of turns per second is not directly visible to the player, so we\nmust look elsewhere for this design decision.\n\nThere is a balance, of course. Lowering the game-turn rate has the following\nadvantages:",
      "content_length": 2794,
      "extraction_method": "OCR"
    },
    {
      "page_number": 484,
      "chapter": null,
      "content": "499\n\nGame controls\nan clients...\nsend information\nto server.\n\nspa dh\nSie ania ppthedb heed spe\n22 8b edo de a Be Sr AB RE ROG ob ob iy Gir Benen we teninte aie MM HR ae mentee cee i\neis Bongo ap guage Aiansyt hs  t DDD yy BO aD ap ee tes\n\nServer clock\n\nproduces steady\nstream of\n\npagans enaee “increment\n\ngameturn\" packets\n\nUser inputs get\n\ninserted into\nstream...\nBabohheiay gf\n‘REARS Deh i pe ae ae aetna a be eae a\nSeat SAteanye gene greene oh ge A\nwhich gets\nduplicated...\n\nand broadcast...\n\nen,\nback to affect the\ngame world on\nthe clients.\n{-———————}\n\nFIGURE 5.2.1 The server/client and game turn/time relations.\n\n* Most of the time, the only network activity that occurs is the server issuing game-\nturn update packets, so a lower number of turns lowers this expected bandwidth.\n* Most game-turn processing is at a constant cost per turn, no matter how many\nturns per second there are, The simplest example is the movement of objects with\na constant velocity. Lowering the game-turn rate reduces the CPU cost of model-\n\ning the game.\nOn the other hand, there are advantages to higher turn rates:",
      "content_length": 1102,
      "extraction_method": "OCR"
    },
    {
      "page_number": 485,
      "chapter": null,
      "content": "500\n\nSection 5 Network and Multiplayer\n\n* Some game processing has a constant cost per second, rather than cost per game\nturn. For example, if your robots are meant to scan the surrounding area once per\nsecond, then halving the number of turns per second will double the amount of\nscanning that has to be done per turn. In the extreme, the processing of the world\nwill be visible as a pause in the smooth rendering. In Star Topia, it was possible to\ncreate this effect by running a very low-spec computer with a higher-spec video\ncard and then filling the game area with lots of activity. The frame rate is high,\nbut the computer struggles with processing the game.\n\n* When user input arrives, its effect is only realized in the game the next time it is\nmodeled. This means that, on average, the response time of the game is lagged by\nhalf of a game turn. If game turns happen more often, this effect is reduced.\n\nIn StarTopia, we eventually settled on six turns per second. The Dungeon Keeper\nteam [Keeper01] used four turns per second. In both cases, different numbers were\nexperimented with, and in fact varied frequently during game development. A similar\nnumber of turns per second should work for most real-time strategy games.\n\nRefinements\n\nOnce the basic protocol has been implemented, there are some improvements that\nwill make the whole game much more playable.\n\ninterpolating Between Game Turns\n\nFirst, the clients anticipate when game turns will arrive from the server and try to\ninterpolate the scene smoothly between turns. In reality, all that is arriving is permis-\nsion from the server to model the next turn, possibly with some new user input.\n\nThough the world is modeled at a steady number of updates per second, what is\nshown on-screen can be updated as frequently as each client computer can handle.\nPlayers with faster machines get a much smoother view, but the game is the same for\nall players.\n\nIt is impossible to correctly anticipate the precise arrival of the next turn, of\ncourse, so any prediction system that comes close is acceptable. We found that basing\nthe prediction on the weighted average of the previous few arrival times was adequate.\n\nThis improvement needs no prediction of future game state. You just interpolate\nbetween the last two game turns you modeled. This interpolation can be linear for\nmost things, such as object position, even when there are as few as four turns per sec-\nond. Ideally, the system will correctly anticipate the moment the next game turn\noccurs, so you can continue with the interpolation. This adds up to one extra game-\nturn fag, which can be a significant time, but it allows for better gameplay.\n\nHiding the Lag\n\nThe main issue that remains is the very noticeable delay between player actions and\ntheir effects on the game world. User input only affects the game after the event has",
      "content_length": 2855,
      "extraction_method": "OCR"
    },
    {
      "page_number": 486,
      "chapter": null,
      "content": "5.2 Real-Time Strategy Network Protocol 501\n\nmade the trip to the server and back, adding a game-turn delay plus an extra turn for\nthe interpolation.\n\nYou can effectively conceal this lag in a management-style game by separating the\ngame into the interface, the network code, and the game state. The game state is the\nonly thing that must stay synchronized. The ‘interface’ is expanded to include as\nmuch of the response of the game to the user as possible.\n\nExamples of game state that we (re)classify as interface are:\n\n* In a game where the player creates rooms or buildings, partially designed room\nlayouts are all done locally, and only the final room design is broadcast.\n\n¢ The Al’s response to commands is delayed, but the user interface response to\ncommands, such as flashing circles around targets, gets immediately processed\nlocally. The fact that your tank actually turns to fight its target a quarter of a sec-\nond later is unnoticeable to the player.\n\n* Camera movement doesn’t usually need to be transmitted if where youre looking\ndoesn’t affect the game.\n\n* Finishing touches to the GUI should happen only on the local machine. For\nexample, our characters’ heads track the mouse pointer around the screen when\n\nthey are being talked to directly.\n\nIt is, in fact, possible to use this protocol in a game that involves more-direct\ninteraction with the world, such as a first-person shooter, but it is awkward. One\nexample is player character movement. The ‘move left’ packet would change to ‘I\nwant to have moved left on game turn x.’ The image displayed to the local user would\nupdate as if the move had been allowed. Every client, on receipt of the event packet\nfrom the server, would decide whether or not the move was possible. However, the\ndecisions would be identical on all machines, leaving the local machine with the task\nof covering up any denied actions. .\n\nHost Migration\n\nSince one machine is dedicated as the server, a problem arises when that machine\nleaves the game. This is quite likely to happen, since players are unlikely to be willing\nto leave their machines connected for the sake of the others.\n\nTo handle this situation, you must first make sure that there is as little state as\npossible on the server. The system described above is ideal because the server is merely\na clock that counts game turns and acts as a short-term holding bay for user input\npackets.\n\n‘The remaining clients must decide which machine will host the new server. Dif-\nferent clients might have received different amounts of the event stream from the\nserver. The most up-to-date version must be used because the client that has received\nthe most-recent events will not be able to roll back.\n\nFor a more seamless transition, clients should check if they had sent any packets\nto the server that did not make it into the new broadcast stream. These should then",
      "content_length": 2867,
      "extraction_method": "OCR"
    },
    {
      "page_number": 487,
      "chapter": null,
      "content": "502\n\nSection 5 Network and Multiplayer\n\nbe resent. Storing perhaps five seconds of network packets is not particularly expen-\nsive, due to the small nature of the packets.\n\nIn StarTopia, we supported server dropout to a lesser extent than this. Most\ngames were just one-on-one, so server dropout happened less often than expected. We\nhad a frequent autosave system {every minute or so). If for some reason, the server\nleft, the remaining machines could just restart from their latest autosave with very lit-\ntle effect on the game.\n\nHandiing a Slow Computer\n\nThe server will keep generating game turns at a steady rate, which might be too fast\nfor one of the clients, even if only for a short while. If game turn update requests are\narriving four times a second, but the client takes half a second to model a game turn,\nit will never catch up and will freeze, unable to advance the game fast enough.\n\nWe simply added an occasional extra packet that clients would send to the server,\nwhich would not be rebroadcast. This would tell the server what percentage of CPU\ntime was taken by modeling the game. The server could then slow down gameplay\nand allow the slower client to catch up by ensuring that the CPU modeling cost had\ndropped sufficiently for all the clients.\n\nNext, we will describe four other techniques that we found useful.\n\nSimulating Lag in Single Player\n\nEven in the single-player game, there should be a simulated network lag. This worked\nwonders for us, because the majority of game development and testing was done in\nthe single-player mode. When we started testing the network game, the testers were\nvery worried about the effect the network lag would have on playability. Ac this point,\nwe could smugly point out that they'd been playing with lag all along. The game was\nprogrammed and tested against network lag by incorporating it from the start.\n\nPointer-to-Unique-ID\n\nAlthough the game state might be completely synchronized, pointers won't necessar-\nily be equal across machines, so any object (in C++) chat must be referred to by net-\nwork packets, such as ‘Tm clicking on this unit’ needs a unique ID. This is relatively\neffortless; simply derive all referenced objects from a base class that contains a unique\nnumerical ID (and a pointer-to-number conversion function), and include a lookup\ntable for number-to-pointer conversion.\n\nThere are some subtle pitfalls to watch out for. For instance, when objects are\ndestroyed and new objects are assigned the same number, some network packets\nmight exist that refer to the old object. This is fixed by attaching a small extra number\nto each ID, which is incremented when the object dies and the ID is used for another",
      "content_length": 2691,
      "extraction_method": "OCR"
    },
    {
      "page_number": 488,
      "chapter": null,
      "content": "5.2 Real-Time Strategy Network Protocol 503\n\nobject. An alternative is to simply use a much larger number of object [Ds and never\nreuse [Ds, or reuse them in least-recently used order. This will increase the size of the\nlookup table for [D-to-pointer conversion, or it can be turned into a hash table. In\nStarTopia, a surprisingly large number of objects were created and destroyed in a typ-\nical session.\n\nDebugging Out-of-Syncs\n\nThe major part of network game debugging was tracking down reasons why clients\nwent out of sync with each other. Detecting that the game was out of sync was done\nby a simple checksum system. The checksum included the number and position of\nobjects, and little else.\n\nOnce the game is out of sync, looking at the differences in the game state tells you\nvery little. So, the best strategy is to litter the code with printts, especially around\ndecision points in the code. You then compare the output from the two machines to\nfind where they went out of sync.\n\nOf course, printfs are expensive. Hence, since most of what we printed were\nnumbers and constant strings, we kept a large queue of little structures, which could\ncontain either pointers to strings or numbers. The printf operation simply wrote\nonto the end of this queue. The pointers were then dereferenced to produce the ‘sync\ndump’ only when the game went of sync. For simplicity, the output was written out to\na shared network drive with a machine-specific filename.\n\nPacket Loss\n\nAs previously mentioned, all network messages in our system must be guaranteed to\narrive in the right order. We found it worthwhile to roll our own guaranteed messag-\ning system, which was effectively a layer under the protocol described here. There is a\nstream of messages from each client to the server, consisting of user input and some\nhousekeeping packets. There is also one stream from the server to each client, con-\ntaining game-turn increments and user events. Though each client receives the same\ninformation, the streams were handled independently.\n\nPitfalls in StarTopia\n\nWe will describe the most common problems we had when implementing this sys-\ntem. Of course, this section is specific to StarTopia, but the lessons we learned will\nhopefully help you with your project.\n\nOut-of-Sync\n\nAs mentioned above, this was by far our biggest problem, but it was not insuperable.\nAlthough there was a huge ammount of detail in the game, we reduced the out-of-synes\nto the point that we were unable to find them during testing. At this point, we\n#defined out the ‘syncdebug’ module and put in a message suggesting that people try",
      "content_length": 2606,
      "extraction_method": "OCR"
    },
    {
      "page_number": 489,
      "chapter": null,
      "content": "504\n\nSection 5 Network and Multiplayer\n\nrestarting the game from the latest autosave. This message was never found (unless we\ncheated to trigger it).\n\nOur main cause of out-of-sync bugs was that, out of necessity, we had written a\nlarge portion of the game before the network protocol was incorporated. So, legacy\ncode that was left in by accident would break the rules of the protocol. The most\ncommon out-of-sync bugs due to this were [Ireland01]:\n\n* Changing game state directly rather than making the change via a network packet\nthat would be broadcast around to all clients.\n\n* Game code referring to the player that is local to the player’s machine.\n\n* Game code referring to the camera.\n\n* Game code referring to the system clock for timing, rather than the game turn.\n\nThese problems can be avoided by keeping the interface and game state as far apart\nas possible. For example, no code that controls game state should know which player is\nsitting in front of the machine or where the player is looking. Once you have complied\nwith this principle, the remaining common reasons for out-of-sync scenarios are:\n\n* Uninitialized data.\n\n* Different versions of data files. Once the game is shipped, this is less of a prob-\nlem. But during development, when people can be running many different ver-\nsions, it is almost worth having a checksum of all data loaded into the game.\n\n© Different executables. Again, the simplest solution is to make the game insist that\nall players use identical executables, though this can get in the way of some\ntesting.\n\nEvent Packets Becoming Irrelevant\n\nThe typical instance of this pitfall or bug is that an event packet refers to some object\nthat is destroyed during the time the packet makes the trip to the server and back.\nAlternatively, a packet describes a change for an object, but the object is no longer in\nan appropriate state to receive this event. (For a while, we could hire and fire charac-\nters in our game, even if they died in the meantime!)\n\nOf course, the tests for this are simple—the unique-ID system described above\ncatches object deaths. In addition, you should always check if your object is in a fit\nstate to respond to an event. What makes this a pitfall is that it happens most often\nwhen players are sending many packets or if they are simultaneously referring to the\nsame object. These situations happen more frequently coward the end of game devel-\nopment, when the game is near enough to completion for big showdowns to be\nplayed. Hence, these bugs can go unnoticed for an inconveniently long time.\n\nExample Game\n\nOtt THE CD\n\nSync debug has been included on the CD-ROM. We encourage you to look at the\ncode and comments. More-complete modules, such as synedebug, have been",
      "content_length": 2739,
      "extraction_method": "OCR"
    },
    {
      "page_number": 490,
      "chapter": null,
      "content": "3.2 Real-Time Strategy Network Protocol 505\n\nincluded, so they are a good basis for a practical implementation. We encourage you\nto leok at the code and comments.\n\nConclusion\n\nThis protocol was easy to implement and worked well for our game. It gave us great\nfreedom to write a game full of many concurrent events, without worrying about\ntheir effect on network bandwidth. We hope this gem will help you, should you wish\nto try our protocol.\n\nI would like to thank the other members of the team who built StarTopia, espe-\ncially Tom Ireland, who gave me helpful comments as I wrote this gem.\n\nReferences\n\n(Ireland01) Ireland, Tom, list compiled during game development, July 2001.\n\n[Keeper01] Bullfrog, Dungeon Keeper I, PC game, information available online at\nfittp://wwrw.dungeonkeeper.com, June 1999.\n\n[StarTopia01] Mucky Foot, Star Topas PC game, information available online at\nhttp://www.muckyfoot.com, July 2001.",
      "content_length": 920,
      "extraction_method": "OCR"
    },
    {
      "page_number": 491,
      "chapter": null,
      "content": "5.3\n\nA Flexible Simulation\nArchitecture for Massively\nMultiplayer Games\n\nThor Alexander, Hard Coded Games\nthor@hardcodedgames.com\n\nassively multiplayer (MMP) games offer fun and addictive gameplay to hun-\n\ndreds of thousands of players who meet online and battle each other or join\nforces to fight common foes. Constructing such large and persistent Internet-based\nplaygrounds is one of the most challenging aspects of game development and possibly\nsoftware development in general. An MMP consists of many components, including\nnetworking, rendering, database access, and game simulation. This gem focuses on\ngame simulation, and it presents a solution that provides for a flexible simulation\narchitecture that can be reused to create many different styles of online games.\n\nA commercial MMP game is much mote of a service than a product. A successful\nonline game service will have a lifetime of at least five years. Over this time, the code\nbase must be maintained and modified in a timely fashion into a production or five\nenvironment with hordes of pesky players critiquing every change. To survive in such an\nenvironment, a code base needs to be built on a solid engineering foundation. To\nachieve this, we will leverage techniques from both the Design Patterns tools and UML.\n\nDesign Patterns are very useful and proven software engineering tools that have\ngained favor in recent years. A pattern is a recurring solution to a standard problem.\nFor more information on patterns, see [Gamma94]. The Unified Modeling Language\n(UML) is a design process for visualizing and specifying a software system. This gem\npresents UML class and sequence diagrams. For an in-depth discussion of UML, see\n[Booch98].\n\nArchitecture Overview\n\nFirst, let us overview the architecture we wish to achieve for MMPs.\n\nClient/Server Components\n\nAt its core, an MMP is a client/server system. It provides a network layer that\nrelays message packets across the Internet between the client and server processes.\n\n506",
      "content_length": 1993,
      "extraction_method": "OCR"
    },
    {
      "page_number": 492,
      "chapter": null,
      "content": "5.3 A Flexible Simulation Architecture for Massively Muitiplayer Games 507\n\nThese message packets are received and interpreted by the game-simulation layer. This\nlayer is responsible for maintaining the consistency of the game state-space on the\nclient and the server. Detailed simulation of the physical representations of the objects\nthat occupy this state-space is handled by the physics layer. Since the client rendering\nlayer presents only what the player can perceive, the number of objects simulated at\nany given time on the client need only be a subset of those on the server. This allows\nthe client to perform the physics simulation at a much higher level of detail than the\nserver physics layer. See Figure 5.3.1 for an overview of this architecture.\n\nPhysics (Detailed) Physics (Simple)\na\n\n[ Game Simulation ; Cl Game Simulation\n\nServer\n\nClient\nFIGURE 5.3.1 Client/Server game architecture.\n\nSimulation by Proxy\n\nThe game-simulation layer on the server holds the one true representation of the\nstate-space. It must serve as the arbitrator if any clients chat it serves fall out of synch.\nThe server broadcasts changes to the actors and objects in the state-space as simula-\ntion events to the client. The client uses these events to update the proxy objects that\nmake up its local copy of the state-space. The user interacts with the server simulation\nby sending action requests that the server simulation layer must validate before the\naction takes place. Figure 5.3.2 depicts the request/event flow. For security reasons, an\n\nClient Server\nSimulation Simulation\n\n+ [___Aation Requests >> +\n+ k << SimuaionBents | 77 k\n\nProxyActors Actors\n\nFIGURE 4.3.2 Chtent/Server simulation via Actors and Prexies.",
      "content_length": 1713,
      "extraction_method": "OCR"
    },
    {
      "page_number": 493,
      "chapter": null,
      "content": "508 Section 5 Network and Multiplayer\n\nMMP design must never trust the client’s representation of state-space. For a detailed\ndiscussion on issues surrounding simulation by proxy, refer to the Virtual Simultane-\nity section of [Perlin96].\n\nSupport Classes\n\nBefore we jump into the core classes of our architecture, we need to define a few sup-\nport classes that we will layer to construct the core classes of the system.\n\nDictionary/Hash Tables\n\nA dictionary is an abstract data type that stores items associated with values. Basic\noperations are AddEntry, LookupEntry, and RemoveEntry. A good dictionary imple-\nmentation method is the hash table, which is an associative array in which keys are\nmapped to array positions by a hash function. Figure 5.3.3 shows the class diagram\nfor such a dictionary. This dictionary will prove to be the workhorse data structure of\nthis architecture.\n\n-HashMap\n\n-argList\n-channel\n-sourceld\n-targetid\n-type\n\n+GetargListd\n+GetChannat)\n+GetSourceldd\n+GeiTargetad\n\n+GefType\n\nFIGURE 5.3.3 Support class\ndiagrams.\n\nSimulation Events\n\nSimulation events are the transactional objects of this system. When an actor interacts\nwith the environment by performing actions, the results of these actions are broadcast\nto other actors that can perceive them as events. An event object contains the event\ntype, source-actor ID, and target-actor ID, as well as a list of arguments specific to the\nevent type. Additionally, it has a channel attribute thar is used by the receiver of\nthe event to filter out the categories of events that it is interested in.\n\nSimulationState\n\nSimulationStaie is our implementation of the state pattern. For the sake of clarity, we\npresent a simplified version of the pattern that does not include a state machine or\nstate manager. (For a detailed and more-robust implementation, see [Boer00] and",
      "content_length": 1844,
      "extraction_method": "OCR"
    },
    {
      "page_number": 494,
      "chapter": null,
      "content": "5.3 A Flexibie Simulation Architecture for Massively Multiplayer Games 509\n\n[Dybsand00].) SimulationState serves as the base class for all states in our architec-\nture. Basic operations are CanTransition and Transition. The base CanTransition is\na pretest method that validates if the specified context object can make a valid cransi-\ntion to this state. Derived state classes can implement additional checks to meet their\nindividual needs. The Transition method is where all of the real work takes place.\nEach child class will need to implement this method and provide any specific behav-\niors that occur when this state is entered.\n\nActionState\n\nActionStates are the typical game-simulation operations, such as slapping an opponent\nor opening a door. Each ActionState has its own durationTime attribute that details\nhow long this action takes to execute. Typically, this attribute is used to synchronize\nthe server simulation with the animation play-back time on the client. The Action-\nState also maintains the startTime attribute. This is useful for calculating the time\nindex into an animation when a spectator enters the view of the actor sometime after\nthat actor has already transitioned into an ActionState (see Figure 5.3.4).\n\nrate\n\n-id -durationTime\n-transitions : Dictionary [“Usercortrotsiate | -startTime\n\n+AddTransitiong\n\n+CanTransttiond\n+Getdd\n\nond] | aiContratstate |\n+GefTransitions0 -AlControlData +ClearLastActionRequesi? +SetOurationTimed\n+PerformAc\n\n+ClearActionRequestQueve()\n\n+PerformActiond +SetStartTimed\n\n-QueueActionRequestd +Transitiond\n\n+RequestactionO\n\n+RemoveTransition)\n\nFIGURE 5.3.4 Simulation state class diagrams.\n\nControlState\n\nA ControlState defines from where the associated actor can accept commands. This\nallows the actor to be under player control, AI control, or in some additional mode,\nsuch as a scripted state for use with in-game cut-scenes. The ControlState can be\nswapped on the fly to transition the actor between these states. Another use for Con-\ntrolStates is for training by observation. When in such a training state, the players\ncontrol the actor as they would in the user-controlled state, with the computer eaves-\ndropping in on the actor and learning from their actions. (For more details on train-\ning by observation, refer to [Alexander02a].)\n\nUserControlState\n\nThe UserControlState maintains a queue of pending action requests that have been\nreceived on the server from the user on the client. This control state’s PerformAction\nmethod will pull requests from this queue when it is called.",
      "content_length": 2551,
      "extraction_method": "OCR"
    },
    {
      "page_number": 495,
      "chapter": null,
      "content": "510\n\nSection 5 Network and Multiplayer\n\nAlControlState\n\nThe AlControlState is responsible for determining the appropriate action to perform\nwhen an actor in this state calls its Performaction method. This decision process\nshould be implemented with an AI technique that best suits a given simulation’s game\nmechanics, such as finite state machines, neural nets, or fuzzy logic. For one example\nof such a decision subsystem, refer to [Alexander02b].\n\nGore Classes\n\nNow, let us discuss the core classes for this architecture.\n\nSimulationObject\n\nA Simulation Object (SOB) forms the base for all of the core classes that the simulation\ndeals with, including actors, areas, items, and obstacles. Figure 5.3.5 shows the core-\nclass hierarchy. An SOB is assigned its own ID that designates it as a unique object.\nSimulationObjects communicate with each other by sending simulation events. They\ncan subscribe to the events that they care about with other simulation objects. Each\nSOB maintains a subscribers dictionary that it uses to publish events that it generates.\n\n=\n=\n\nHonOdject\n\nSESE\n\n=\n\nFIGURE 5.3.5 Core class hierarchy.\n\nAn SOB might contain other SimulationObjects. Each SOB maintains a con-\ntents dictionary of the objects that it contains, as well as an ownerld that refers to the\nSOB that contains it. SimulationObject containment serves as an abstract concept\nthat can facilitate many features for the child classes. Actor subclasses can use it to\nimplement inventory-item management systems. Items can become in-game con-\ntainers, like chests and bags, which contain other items. Areas, which are abstract\nspatial representations, make use of containment to track other SimulationObjects\nthat enter and exit their boundaries.\n\nSimilar to containment, SimulationObjects also maintain a dictionary of links\nto each other. Links provide an aggregation, or ‘whole/part’ relationship, between",
      "content_length": 1895,
      "extraction_method": "OCR"
    },
    {
      "page_number": 496,
      "chapter": null,
      "content": "5.3 A Flexible Simulation Architecture for Massively Multiplayer Games 511\n\nSOBs. This provides for a simple, yet powerful way to enable objects to receive events\nfrom component parts on a transitory basis. Links can be used to implement portals\nor doorways between areas that can be opened and closed. Compound items can be\nconstructed from parts by linking items together.\n\nSimulationObjects also provide a property dictionary for storing game system-spe-\ncific attributes per-object in a data-driven fashion. Each simulationObject subclass\ncan add its own properties to the dictionary as needed. The contents of this dictionary\ncan be replicated down to the associated proxy object on the client in an intelligent,\njust-in-time fashion that minimizes the network-traffic overhead. Examples of prop-\nerties include attributes like the object’s location in the world space, movement speed,\nhit points, mana, and so forth.\n\nFinally, SimulationObjects provide a persistence mechanism that allows the sim-\nulation layer to interface with storage systems in a generic fashion. Each simula-\ntionObject maintains a dirty flag that is set when persistent properties and data are\nchanged. The simulation layer can call the Store method on the SOB when needed.\nStore tests the dirty flag and archives the object if it is set. The Restore method per-\nforms the converse operation and loads the object into the simulation. These methods\ncan be implemented in the target application to save the objects to flat-file formats,\nsuch as XML or relational databases such as Oracle or MS-SQL (see Figure 5.3.6).\n\n-contents : dictionary\n-diny: boolean\n\n-id\n\n-links : dictionary\n-ownerld\n\n-properties ; dictlonaty\n-subscribess : dictionary\n\n+8ubserived\n+Unlinkd\n+Unsubscribed\n\nFIGURE 5.3.6 Simulation Object class diagram.\n\nPerformer\nThe abstract Performer core class provides for the shared client/server functionality\n\nand common interface of the Actor and ActorProxy simulation object classes. The Per-\nformer class maintains a schedulePriority attribute that is used by the simulation for",
      "content_length": 2073,
      "extraction_method": "OCR"
    },
    {
      "page_number": 497,
      "chapter": null,
      "content": "512 Section 5 Network and Multiplayer\n\nscheduling. A performer also maintains the object’s currentActionState, which rep-\nresents the action that the object is currently performing. This attribute is determined\nand set by the PerformAction method. More-advanced simulations can be imple-\nmented by expanding the object to contain several parallel action states for mutually\nexclusive activity layers, such as movement states, posture states, conversation states,\n\nand so forth (see Figure 5.3.7).\n\n-currentActionState : ActionState\nid\n-schedulePriority\n\n+GetCurrentActionStated : ActionState\n\nFIGURE 5.3.7 Performer class diagram.\n\nActor\n\nAn Actor is defined to be a server-side simulation object that is capable of interacting\nwith the simulation environment. Actors have a ControiState that allows them to be\ncontrolled by a number of different agents, including players, Al, and scripted cut-\nscenes. The PerformAction and RequestAction methods are delegated down to the\ncurrent control state, where the controlling agent is responsible for providing the\nappropriate implementation. The Actor class also maintains an eventQueue that is\npopulated by the ReceiveEvent method (see Figure 5.3.8). This queuing of events\nallows the Actor to batch them up and defer handling them until its next scheduled\nPeformAction method.\n\nThis passive, just-in-time event-handling scheme allows the system to avoid hav-\ning to decide what it needs to do every time an Actor receives an event. In a high-\n\n+ProcessEventQueued\n+RecerveEventd\n+RequestActiong\n+ResetControlStated\n-etCurrentControlStated\n\nFIGURE 5.3.8 Actor class diagram.",
      "content_length": 1619,
      "extraction_method": "OCR"
    },
    {
      "page_number": 498,
      "chapter": null,
      "content": "5.3 A Flexible Simulation Architecture for Massively Multiplayer Games 513\n\nevent simulation, like MMP games where the actors need to be aware of everything\ngoing on around them, this is a critical improvement. The ReceiveEvent method can\nalso filter out event types that require immediate attention and bypass the queue to\nperform the required handling when the event is received.\n\nActorProxy\n\nAn ActorProxy is the client-side counterpart of an Actor. It shares the same Simula-\ntionObject ID as its Actor and replicates the actor’s relevant data. The client-side sim-\nulation will route all incoming events to the appropriate actor proxy, where it will be\nhandled by the ReceiveEvent method. The proxy also provides a RequestAction\nmethod that routes outbound action requests to the associated actor on the server.\nFinally, there is a PerformAction method available to process any client-side-only\nbehavior that does not need to be replicated by the server simulation, such as dynamic\nsoundtrack selection or triggering of UI elements (see Figure 5.3.9).\n\nmAction?\n+RecelveEventd\n+Requestactiono\n\nFIGURE 5.3.9 ActorProxy class diagram.\n\nNonperformers\n\nMuch simpler than performers ate the other core classes that do not directly interact\nwith the simulation environment. These objects do not perform actions and do not\nreceive any scheduled processing time from the simulation. All events must be han-\ndled actively as these objects receive them. These objects include:\n\n* Ltems—Small game objects that can be picked up, moved, and dropped by actors.\n\n* Obstacles—Nonmoveable objects in the game that cannot be picked up.\n\n* ProxyObject—Client-side counterpart of the Item and Obstacle classes.\n\n* Avea—Abstract spatial representations used to partition the simulation space\ndown into manageable sections, Areas define the local potential visible set that is\nused to filter who can and cannot see (or if needed, hear) simulation events.\n\nManagers and Factorles\n\nManagers and factories are implemented as singletons [Gamma94]. A singleton\ncomes in handy when a single global object needs to be accessed by several different\nclasses and objects. They are created when the simulation layer is initialized, and they\nremain in service until the layer is shut down. Parallel managers are maintained inde-\npendent of each other on both the client and server.",
      "content_length": 2353,
      "extraction_method": "OCR"
    },
    {
      "page_number": 499,
      "chapter": null,
      "content": "514\n\nSection 5 Network and Multiplayer\n\nSOBFactory\n\nThe SOBFactory is responsible for creating simulation objects and guaranteeing that\nthey have a unique ID number. To achieve this, the SOBFactory is the sole keeper of\nthe nextSobId. The factory provides a Create method that takes an SOB-type argu-\nment that specifies what subclass of simulationObject (Actor, Area, Item, etc.) it cre-\nates. If the client-side simulation needs to create local simulation objects, it can\nmaintain its own SOBFactory, which will need to implement a scheme to ensure that\nclient-side SOB [Ds do not conflict with those generated on the server (see Figure\n5.3.10).\n\nsobFactory\n-nextSobld\n\n+Created : simulationObject\n-GenerateSobldd\n\nFIGURE 5.3.10 SOBFactory class diagram.\n\nSOBManager\n\nAn SOBManager is responsible for maintaining a dictionary of simulation objects.\nThe main function of this manager is to resolve SOB IDs into object references via\nthe LookupById method. This manager also provides methods to Store and Restore\nall of the objects under its supervision. These two methods delegate the actual object-\npersistence implementation down to the specific simulation objects. This allows for a\nsingle call to be made transparently from the sirnulation layer to save or load all of the\nobjects within it (see Figure 5.3.11).\n\n-sobs : Olctionary\n\nFIGURE 8.3.11 SOBManager class diagram.\n\nScheduleManager\n\nThe ScheduleManager is responsible for scheduling a Performaction method callback\nfor all of the Performer simulation objects that are active in the simulation (see Figure\n5.3.12). It also provides the Processtasks method that takes a time slice argument\nand calls all of the pending scheduled callbacks that it can process within that time,",
      "content_length": 1737,
      "extraction_method": "OCR"
    },
    {
      "page_number": 500,
      "chapter": null,
      "content": "5.3 A Flexible Simulation Architecture for Massively Multiplayer Games 515\n\nsorted by the Performer’s schedulePriority. Although an effective schedule can be\nimplemented with a directory, as shown here, a more optimized solution is the prior-\nity queue. (For an excellent article, on implementing priority queues refer to\n\n[Nelson 96].)\n+CancelTaskd\n+ScheduleTaskd\nFIGURE 5.3.12 Class diagram for ScheduleManager.\nLookupManager\n\nThe LookupManager provides a fast and effective mechanism for accessing static\ngame data at runtime (see Figure 5.3.13). Typically, this data is stored in relational\nor object databases and loaded on simulation startup. The data is mapped into a\nnested dictionary with a primary Zzble key and secondary Entry keys. Some exam-\nples of static game data include initial ActionState data, SimulationEvent types, and\nSimularionObject properties.\n\nLookuphtaraget\n\n-tables : dictionary\n\nFIGURE 5.3.13 Class diagram for LookupManager.\n\nPutting It All Together\n\nNow that we have defined the support, core, and manager classes, we need to wrap\nthem all up in a nice top-level interface for managing the client/server simulation lay-\nets. The BaseSimulation class provides such a common interface. It contains all of the\nobject references to our manager singletons, as well as a reference to the root simula-\ntion object. This object represents the entire simulation universe and provides a\npointer to anchor all top-level Area simulation objects to. The simulation maintains\ntwo instances of the SOBManager, an areaManager and an actorManager. This sepa-\nration of simulation objects is useful for debugging, maintenance, and archival pur-\nposes (see Figure 5.3.14).",
      "content_length": 1685,
      "extraction_method": "OCR"
    },
    {
      "page_number": 501,
      "chapter": null,
      "content": "516\n\nSection 5 Network and Multiplayer\n\n+AttachUserd)\n+DetachUserQ\n\n+LogOfig\n\n*LogOnd\n+ReceiveSimulationEvent)\n\n-root : SimulationObject\n-scheduUleManager\n-sobFactory\n\n+GetActorManager()\n+GetAreaManager\n+GetLookupManager(\n\n+GetScheduleManager()\n\nFIGURE 5.3.14 Simulation class diagrams.\n\nAttaching Users to Actors\n\nThe ServerSimulation and ClientSimulation classes each implement AttachUser and\nDetachUser methods, providing a mechanism to request that the calling user be\nmapped to a specific Actor instance on the server, as well as its associated ActorProxy\non the client. Attaching a user to an Actor allows that user to send action requests and\nreceive simulation events. It is up to the current control state of the target actor to\narbitrate whether or not the actor will accept or decline the attach request. Such an\nattachment mechanism has the added benefit of supporting advanced features, such\nas allowing multiple users to attach to the same Actor. A few uses for this feature in an\nMMP are to allow customer-support personnel to take over control of a troublesome\nplayer's character, or to be able to see the game from the exact perspective of a newbie\nplayer who is having trouble and requesting help.\n\nAction Requests\n\nOnce attached to a user on the server, the client’s primary outbound communication\ncomes in the form of action requests. The SendActionRequest method on the\nClientSimulation takes an ActionStateId and an argument list representing the user's\ndesired action, and passes them to the server simulation layer. The server, in turn,\ndelegates these requests down a chain of responsibility from the attached Actor to its\ncurrentControlState, where it is processed or rejected. Figure 5.3.15 illustrates the\naction-request sequence.\n\nAction Scheduling\n\nThe ServerSimulation provides a single Tick method that can be called from outside\nthe simulation layer to trigger all processing of pending actions. This method is\nresponsible for calculating the available time slice for simulation processing and hand-",
      "content_length": 2032,
      "extraction_method": "OCR"
    },
    {
      "page_number": 502,
      "chapter": null,
      "content": "5.3 A Flexible Simulation Architecture for Massively Multiplayer Games 517\n\n(suamk]  [erSimatdon)] [Sonera] [esunensome :Sanlinngee} [Artec] [ison nents\n| 1:SendActionRequest) | |\n2ReceivaActionRequest) |\n\n3:Looku\n\n4:RequesiActiond\n\n------4+\n\n|\ni\n!\nI\nFIGURE 5.3.15 Action request sequence diagram.\n\ning it over to the schedule manager via the ProcessTasks method. Since the server\nphysics layer typically requires processing at a higher frequency than the simulation\nlayer, the Tick method serves as a good callback method to be registered with the\nphysics layer that maintains the main game loop (see Figure 5.3.16).\n\nOptimized Event Broadcasting and Handling\n\nThe PerformAction method on the ControlState determines the desiredAction State for\nthe calling Actor to attempt to transition. If this actionSrate passes its CanTransition\n\ntenascateen x] [:Sanmemdeton| | [ -Scheaamaeaeas) [sata\n\n' 4-Tieko !\n\n7\n|\n|\n2:ProcessTasksQ) \\\n\n3:PerformActiond\n\ni\n|\n|\n!\n&ProcessEventQueveg |\n|\n|\n|\n|\n\n5:Performaction®\n\nU | |\n| 1 |\n| ! I\ni | '\n' | |\nI i I\n\ni\nI\n|\ni\ni\n|\n\nFIGURE 5.3.16 Action-scheduling sequence diagram.",
      "content_length": 1106,
      "extraction_method": "OCR"
    },
    {
      "page_number": 503,
      "chapter": null,
      "content": "518\n\nSection 5 Network and Multiplayer\n\npretest, then its Transition method is called to do the heavy lifting. Each actionState\nneeds to provide its own specific implementation. Typically, this implementation will\nneed to inform other simulation objects of the state transition. This is accomplished\nthrough simulation events. The acting simulationObject maintains the subscribers\ndictionary of other objects that have registered an interest in its actions. These sub-\nscribers are notified by calling their ReceiveEvent method. The receiver can deter-\nmine if it needs to give the event immediate or passive attention. In the former case,\nit is handled as it is received; in the latter case, it is queued and is processed on the\nreceiver's next PerformAction tick. Figure 5.3.17 shows this sequence diagram.\n\n1:Performaction®\n\ni\n| 1\n| | |\n| |\n| |\ni]\n\n2:<¢eslredActianState>PerformAction\n\n7:For subscritier Ih supscnipars\n\n&:Recehsévent)\n9: eventType Is Imrmadiate then\n\n10:HandleEventd\n\n11:Elee\n\n12:;QueveEvent}\n\nT\n|\n| } |\n|\n|\n|\n\nFIGURE 5.3.17 Event-broadcast sequence diagram.",
      "content_length": 1078,
      "extraction_method": "OCR"
    },
    {
      "page_number": 504,
      "chapter": null,
      "content": "5.3 A Flexibie Simulation Architecture for Massively Multiplayer Games 519\n\nConclusion\n\nDeveloping an MMP is a vast undertaking and presents many challenges that are\nunique. Starting with a solid and well-engineered foundation, like the one presented\nhere, will carry you far and allow you to spend more time and effort on innovative\n\ngame mechanics, rather than bug fixes and workarounds.\n\nReferences\n\n[Alexander02a] Alexander, Thor, “GoCap: Game Observation Capture,” A Game\nProgramming Wisdom, Charles River Media, Inc., 2002.\n\n[Alexander02b] Alexander, Thor, “An Optimized Fuzzy Logic Architecture for Deci-\nsion-Making,” Al Programming Wisdom, Charles River Media, Inc., 2002.\n\n[Boer00] Boer, James, “Object-Oriented Programming and Design Techniques,”\nGame Programming Gems, Charles River Media, Inc., 2000.\n\n[Booch] Booch, Grady, “The Unified Modeling Language User Guide,” Addison\nWesley, 1998.\n\n[Dybsand00] Dybsand, Eric, “A Finite-State Machine Class,” Game Programming\nGems, Charles River Media, Inc., 2000.\n\n(Gamma94} Gamma, et al., “Design Patterns,” Addison Wesley Longman, Inc.,\n1994.\n\n[Nelson96] Nelson, Mark, “Priority Queues and the STL,” Dr, Dobbs Journal. Also\navailable online at http://www.dogma.net/markn/articles/pq_stl/priority.htm,\nJanuary 1996.\n\n[Perlin96] Perlin, K. and A. Goldberg, “Improv: A System for Scripting Interactive\nActors in virtual Worlds,” Computer Graphics Proceedings (SIGGRAPH 1996),\nACM, 1996,",
      "content_length": 1440,
      "extraction_method": "OCR"
    },
    {
      "page_number": 505,
      "chapter": null,
      "content": "5.4\n\nScaling Multiplayer Servers\n\nJustin Randall,\n\nSony Online Entertainment\nlogic@jniogic.dyndns.org\n\nears ago, multi-user dungeons (MUDs) would often see 50 to 100 players inter-\n\nacting simultaneously. Even during these humble, early stages of multiplayer\ngaming, players suffered from lag and server resource starvation. Server administra-\ntots, implementers, and wizards fought constant battles against bugs, cheaters, grief\nplayers, and ‘bots’ running on player machines. Yesterday's problems live on today,\nbut with added complications of scale. The complexity of game systems and designs\nleave servers open to more exploits, The amount of throughput required to simulate\nan interactive 3D world for thousands of players exacerbates lag. As the technology\nadvances, so do the tools used to decipher, automate, peek, cheat, crash, or otherwise\nruin a gameplay experience. We are fighting the same battles, but they are bigger and\nrequire some different tactics to win.\n\nThis gem will describe strategies to improve fair gameplay, as well as methods of\nclustering server processes and optimizing systems to reduce throughput requirements\nwhile improving process performance.\n\nategies to Improve Fair Play |\n\n520\n\nNever trust the client to send good information back to the game server. Assume\nevery packet is malformed. Players will send false packets to move faster in a game, to\ninflict more damage, or to crash servers. They might do it to exploit data duplication\nbugs, or they might do it just to inflict grief on server administrators and other play-\ners, For whatever reason, they will send garbage—-and the server must be prepared to\nthrow out the trash.\n\nExploits in a multiplayer game fall into two general areas:\n\n* Data that is sent from the client—the client lies to the server about what it is\ndoing or assaults another client on the network,\n\n¢ Data that is on the client—the player sneaks a peak at the data vo gain unfair\nadvantage.",
      "content_length": 1954,
      "extraction_method": "OCR"
    },
    {
      "page_number": 506,
      "chapter": null,
      "content": "5.4 Scaling Multiplayer Servers §21\n\nIt is impossible to exploit information that is not available. Game clients usually\nuse information that is relevant to maintain the world simulation. It is helpful to have\nas much information on the client as possible to prevent objects from ‘popping’ into\nexistence or to prevenc lagging while waiting for simulation data to arrive. This\n‘potentially relevant’ information can be exploited to give a player an advantage\nbeyond the scope of normal gameplay. The client only presents portions of informa-\ntion, while the player extracts the rest through some other means (e.g., third-party\nsoftware).\n\nStrategy 1: Don’t Send the Data\n\nData sent to the client should be on a ‘need-to-know.’ basis. Less data on the client\nequates to fewer opportunities for exploitation, lower bandwidth costs, and better\nperceived performance.\n\nFor example, the health point value of a foe might be useful during combat to\nimprove client-side simulation, but sending health points for all potential foes in the\nworld will let the player pick and choose their prey without interacting directly with\nthe game. Programs like ShowEQ [ShowEq01] and proxy bots in first-person shoot-\ners are examples of how black-hat users exploit extraneous information sent to the\nclient. If the data is not available, these kinds of exploits are impossible.\n\nStrategy 2: Temporarily Lock the Data\n\nOf course, the realities of gameplay in the context of limited bandwidth require that\nsome precaching data be sent to improve the simulated experience on the client. All is\nnot lost! Another strategy is to encrypt precache data with 4 randomly generated key\nthat is not sent to the client.\n\nThe data is in ciphertext when it reaches the client. The client, not having a key\nto decrypt the data, can only resort to an attack on the cipher itself. The time required\nto make a brute-force assault on a cryptographically strong cipher like Twofish\n[Schnier98] far exceeds the relevance of the precache before it becomes interactive.\nAfter all, precaching information is sent because the client will likely be interacting\nwith it in the near future (probably within the next 60 seconds).\n\nWhen the decryption key (16 bytes is usually large enough) is sent, the data mag-\nically ‘appears’ on the client. The time required to send tens or hundreds of kilobytes\nis amortized, and the data becomes relevant in the time it takes to send those few\nbytes to decipher precaching information.\n\nSome information, such as how to draw an object, could be in the clear as a pre-\ncache message to request a background load of assets; while game information like\nexperience values, health points, object name, and so forth are ciphertext. This strikes\na balance between network-send latencies, blocking disk reads, CPU-lag loading\nassets, and fair play.",
      "content_length": 2832,
      "extraction_method": "OCR"
    },
    {
      "page_number": 507,
      "chapter": null,
      "content": "522\n\nSection 5 Network and Multiplayer\n\nStrategy 3: Clients Send Commands, Not States\n\nIf the client is not authoritative for position, health points, combat results, or what-\never, then it is not possible for the player to say, “I have 65536 health,” or “Joe is\ndead.” Instead, the client should only be allowed to send commands like “walk,”\n“run,” or “attack Joe.”\n\nStrategy 4: Server Validates Client Output\n\nThe player might not be allowed to send the message “Attack Joe,” or might send a\npacket of garbage that is not valid. If the server receives an invalid command, it\n\nshould be ready to either discard the data or discard the client altogether by discon-\n\nnecting it.\n\nStrategy 5: Never, Ever Tell a Client the Network\nAddress of Another Client\n\nIf a player knows the network address of another player, any number of attacks could\nbe launched against the remote client. For example: The player is engaged in combat\nwith Joe, and Strategy 3 has already been implemented, meaning only commands\nmay be sent, However, the player might employ a denial of service (on the game net-\nwork port) against Joe during combat. Joe is effectively incapacitated and cannot issue\nany commands. He is summarily executed in a duel, the denial of service disconnects\nJoe's computer, and the black-hat player wins the batde.\n\nThe game design might require high-bandwidth services, such as voice commu-\nnications. In this case, peer-to-peer communications are attractive solutions to prob-\nlems of throughput and the cost of ownership. There will be a tradeoff, however,\nbetween lower operational expenses and customer experiences. Permitting players to\nactivate peer communications selectively, explaining the risks to them when they do\nit, and allowing them to choose who they peer with are some compromises that might\nbe acceptable.\n\nDesigning Scalable Servers\n\nIt is important to prepare the server code for the consequences of a high-throughput\napplication. Data delivery should be efficient. Using the network system in game code\nshould be simple and safe. Efficiency, simplicity, and safety are common-sense goals,\nbut these goals can often be lost in the details of implementing massively multiplayer\nservers.\n\nEfficiency—-Use Modern System Interfaces\n\nEveryone would like code to be portable. By writing a select, connect, accept, lis-\nten, send, and recy, wrapped with a few #ifdef’s to handle nuances of Winsock ver-\nsus BSD sockets, a network subsystem can be authored with very little code in a\ncouple of hours, and it can be reasonably portable.",
      "content_length": 2548,
      "extraction_method": "OCR"
    },
    {
      "page_number": 508,
      "chapter": null,
      "content": "5.4 Scaling Multipiayer Servers &23\n\nThis is fine for low-volume network services handling a few dozen connections,\nbut ic does not scale well when writing services handling hundreds or thousands of\nactive sessions. Most modern operating systems provide extended APIs that are more\nefficient than basic BSD socket services.\n\npo11() and POSIX2 AIO\n\nPOSLX2 defines an asynchronous I/O system (AIO) that is better suited to high-\nthroughput applications. Unfortunately, it is not very well-supported on all plart-\nforms. As of 2001, glibc provides fallbacks for AIO, and Linux supports AIO only for\nfiles that allow 1seek(). At some point, however, AIO will be the preferred approach\nto high-volume networking.\n\nBut for today, game code has to work on real-world platforms that are tested and\nstable. An alternative to POSIX2 AIO for UN*X is the po11{) system call. poll() is\nclosely related to select(}. File descriptors (specifically, poll file descriptors) are\npassed to the call, and it returns the number of descriptors that have some events\npending.\n\nIt does not, however, tell the application which descriptors are ready. The applica-\ntion must iterate through the descriptor list to see which of them have events.\n\npoll() is better suited than select(), because the events are posted in the\ndescriptor list directly. The network system does not have to leave user space to find\ndescriptors with pending events. Finding pending sockets in a set of hundreds, or\neven thousands, now only takes a few milliseconds, without the pains associated with\nmaking system calls querying for events on each socket.\n\nThis code is an example of using the poll call:\n\nint result = poll(fds, count, 0);\nint c = 0;\nfor(i = 0; i < count, c <= result; ++i)\n\nif(fds[I]).revents == POLLIN)\n{\n\nctt;\nfi .,. receive data\n\n}\n\nWin32 I/O Completion Ports and Overiapped I/O\n\nMicrosoft introduced IOCP with Winsock2. IOCP is an asynchronous I/O API that\nefficiently presents I/O events to an application. Rather than using select ()or other\nasynchronous methods, a socket is associated with a completion port, and normal\nWinsock operations commence. When an event occurs, however, the completion port\nis queued by the operating system. The application can then query the kernel for\ncompletion ports. Microsoft indicates that this is the best way to implement high-\nvolume network server applications [MSDN00]. This code roughly demonstrates\nIOCP usage:",
      "content_length": 2427,
      "extraction_method": "OCR"
    },
    {
      "page_number": 509,
      "chapter": null,
      "content": "$24\n\nvoid foo()\n{\nSOCKET s = socket{AF_INET, SOCK_STREAM, 18);\nHANDLE iocp = CreateIoCompletianPort{\n$, g_iocpGroup,\n0, 0);\n}\n\nvoid updateNetwork (]\n\nbool success = true;\n\nwhile (success)\n\n{\nint ok = GatQuevedCompletionStatus (\niocp, // completion port of interest\n&bytesfransferred, // number of bytes sent or\n\n/?/ received\n\n&completionKkey,\n&overLapped,\nO // timeout immediately if there are no\nf/ completions\n3\n\nif (ok}\n\n{\nsuccess = true;\ni/ handle event\n\n}\nelsa\n{\nsuccess = false;\n}\n}\n}\nSafety—Mossage Serialization\n\nA server written in a strongly typed language can catch message-type errors at compile\ntime, before mistakes are introduced to a running application. Enforcing type safety\nover a network is no more difficult than ensuring type safety when storing objects on\ndisk. In fact, the same design and strategies used for file-based persistence should be\nused for network-based data synchronization, with a few exceptions.\n\nWhen persisting data to disk, programs might often assume that the data will be\nreread by the same program on the same host that wrote the data. When writing data\nto the network, this is not necessarily che case, Simply chrowing a raw chunk of mem-\noty containing some structs or classes to the network will definitely break, even if two\nhosts ate of the same endian architecture. The local and remote systems might both\nbe x86 systems, but running applications compiled with different word-alignment\noptions (Dev Studio aligns at 8 bytes by default and gcc at 4 bytes). The client might\nbe a little-endian x86, and the server might be a big-endian 64-bit alpha (with little-\nendian emulation disabled). Perhaps they are of the same architecture today, but",
      "content_length": 1692,
      "extraction_method": "OCR"
    },
    {
      "page_number": 510,
      "chapter": null,
      "content": "5.4 Scaling Multiplayer Servers 525\n\nservers could be upgraded next year. There are no guarantees about byte alignment or\nendianness when dealing with the network.\n\nOpt for serialization that is common to network messaging, file I/O, and data-\nbase persistence (if a database is in use). Unified serialization might be used to apply\ndeltas to object data as well as to construct whole objects. For example, a database\nprocess might receive a position update network message, interpret it as SQL, and\nwrite only the object position to the back-end database. The database could then be\ntreated like any other server receiving updates. The interface is common; the imple-\nmentation is what differs.\n\nEnforcing type safety saves time in the long run, provides a more-stable applica-\ntion, and permits better reuse of code as development progresses. One of the most\neffective uses of a typed message system is in dispatching data to server systems.\n\nSimplicity—Message Dispatch\n\nTypically, a protocol will identify messages with a short one- to four-byte header. As\nthe message is received, the header is read, and more data is extracted from a packet\nuntil the whole message has been processed. This often happens in a single function\nwith a large switch statement that forwards a network buffer to other functions for\nfurther processing.\n\nThis is a method that gets the job done, does it efficiently, and is easy to under-\nstand. It is also somewhat painful to add new messages. When enough message types are\nintroduced to the system, the switch statement can grow to a ten thousand-line behe-\nmoth that is unreadable. With each new addition to the messaging system, the switch\nimplementation induces increasingly large build times. Most importantly, the dispatch\ncode is tightly coupled with each new message. New message code cannot leverage old\ncode to implement new behavior. The old code must be updated to understand the new\nmessage data. Unused data paths might remain in the code base undetected.\n\nThe typed-message system mentioned earlier might be used to avoid some of this\npain. It would be beneficial if an application could say to the dispatching system.\n“when connection X sends message Y, invoke my member function Z to handle it.”\n\nWith this kind of dispatching system, there should be no prior knowledge of\nwhat types of objects are requesting a message or what types of messages are handled.\nOnce the dispatch system is written, it need not be touched again, and it will be far\nless than ten thousand lines of code!\n\nHow it works (see the code provided on the CD-ROM for full implementation\ndetails):\n\n* Aconnection object has a dispatch object.\n* Another object in the system registers itself with the dispatch object.\n\n* It provides a ‘connect’ method that accepts a reference to a dispatch object that\nit listens to—a ‘this’ from the object invoking ‘connect’ and a pointer to a\nmember function that is executed when the requested message is emitted.",
      "content_length": 2969,
      "extraction_method": "OCR"
    },
    {
      "page_number": 511,
      "chapter": null,
      "content": "526 Section5 Network and Multiplayer\n\n* The connection object adds the requestor’s dispatch object and callback function\nto a container of recipients by type.\n\n* When the dispatch system receives a network message, it constructs the message\nand ‘emits’ the message, which was already resolved to the proper dispatch\nmethod at compile time.\n\n© Requestor objects have their member functions invoked with the message as an\n\nargument.\n\nThis requires some meta-programming magic with templates if C++ is used. It\nprovides type-safe message dispatch and compile-time errors when message types (or\nrequestor methods) are unresolved.\n\nIn the context of a network messaging system, a connection receives a network\nbuffer, constructs a new message of a specific type, and dispatches it:\n\nvoid Client::Client(Connection * connection) :\nmyCallbackObj ect ()\n\n{\nmyCallbackObject.connect{¢\n\nconnection->getEmitter({},\nthis,\n&Client: :onDisconnect});\n\n}\n\nvoid Client: :onDisconnect(DisconnectMessage & d)\n\ncleanup{)};\n\n}\n\nvoid Connection: :onReceive(const Archive: :Stream & data}\n\n{\nArchive: :Stream: :AeadIterator cr = data.begin({);\nMessage & m = MessageFactory: :create(r};\nemitMessage({m);\n\n}\n\nThis can be used for far more than network messaging. Consider a monster\nobject on the server process. When the monster dies, it should be removed from all\nclients that see the monster.\n\nvoid Client: :onCreateMonsterOnRemote(Monster * m)\n\n{\nmyCallbackObj ect .connect (\nm->getEmitter(},\nthis,\n&Client::onKilledMonster);\n}\n\nvoid Client: :onKilledMonster(KillMsssage & k)\n\nRemoveObjectMessage r({k.getMonster()->getId(}};",
      "content_length": 1603,
      "extraction_method": "OCR"
    },
    {
      "page_number": 512,
      "chapter": null,
      "content": "5.4 Scaling Multiplayer Servers 527\n\nsend(r);\n}\nvoid Monster: :onKilled{Character * destroyer)\n{\nKillMessage k({this, destroyer);\nemitMessage(k};\n}\n\nLater in development, designers might decide that the character object has to\nknow if it kills a monster. In this case, the character only wants to know about mon-\nsters that are killed when it is in combat. Perhaps all characters involved in combat\nwith the monster gain experience points. Using the dispatch system, the single kill\nmessage that was emitted by the monster in the old code can trigger new code in a\nnew character object.\n\nvoid Character: :onEnterCombat{Monster * m)\n\n{\nmyCallbackObject.connect (\nm->getEmitter(),\nthis,\n&Glient: :onKilledMonster) ;\n}\nvoid Character: :onKilledMonster{KillMessage & k)\n{\nexperiencePoints +=\nk.getMonster(} ->getExperienceValue();\n}\n\nAs an additional bonus to using this particular (C++) implementation of a dis-\npatch system, function pointers that are passed as callbacks can be protected mem-\nbers, thus hiding interface details, yet exposing them selectively to individual objects\nwhen they need to handle particular messages. No one may invoke the protected\nmembers directly, unless they are exposed explicitly within implementation code of\nthe object that defines them.\n\nDistributing the Load\n\nEnsuring that server systems can scale to arbitrarily large connection counts often\nentails clustering host systems and running multiple processes. Game services span-\nning several processes introduce technical design challenges. How does a client find\nthe right service? How do services cooperate to present a unified world simulation?\nWhere does the world persist game data between process startup and shutdown? How\nare processes spawned? What happens when clients need to interact with objects on\nmultiple servers? These are just a few of the problems nearly every distributed-game\nserver will have to address.",
      "content_length": 1909,
      "extraction_method": "OCR"
    },
    {
      "page_number": 513,
      "chapter": null,
      "content": "Section 5 Network and Multiplayer\n\nOnce solutions are implemented, meeting the demands of the game ceases to be\nas much of a technical problem as an economic problem. Ideally, throwing more\nhardware at the server cluster would increase capacity.\n\nConsider Using a Front-End Process To Interact\nwith Clients\n\nSeparating client traffic from the rest of the servers is a good first step to solving prob-\nlems of location (How does a client find the right service?) and presenting a unified\nworld simulation. When a client connects to a game server, it is really interacting with\na front-end process (FEP). Several front-end processes might cooperate to increase the\ntotal connection count that a server cluster handles.\n\nHow Does a Client Find the Right Service?\n\nA common design employs a well-known login service that will validate a client, then\npresent the client with several ‘servers’ with which it may interact. Each server is one\nof several front-end processes that separate the client from back-end game processes.\nOnce the client connects to an FEP, that process will communicate with other back-\nend processes to insert a player’s character into the world simulation so that it may\nbegin gameplay (see Figure 5.4.1). How the world is presented to the client and which\nback-end process interacts with the client depends on the design of the game. If there\nis a process for each city in a role-playing game, then the city that the player was last\nin might be the target process for the new client.\n\nClient\n\nBack-end processes\n\nFEP\n\nFIGURE 5.4.1 Connection diagram using a Login Service and a Front-End\nProcess (FEP).",
      "content_length": 1622,
      "extraction_method": "OCR"
    },
    {
      "page_number": 514,
      "chapter": null,
      "content": "3.4 Scaling Multiplayer Servers 529\n\nThe back-end will likely consist of other location services. Which objects are on\nwhich servers? Which players are on which servers? This relationship is abstracted\nfrom the client. It will only interact with the FEP. There is no need for a client to con-\nnect directly to a locator service or any other back-end process. Back-end locators\nneed a single connection with each FEP, which in turn can successfully redirect client\ncommunications to a world-simnulation service somewhere in the back-end.\n\nHow Do Services Cooperate To Present a Unified\nWorld Simulation?\n\nFEPs facilitate the presentation of a unified world simulation. A unified simulation is\none in which the game world appears as a single server covering a contiguous simula-\ntion through a single connection. If a client has to move from one back-end game-\nserver process to another, there is no reconnection process necessary on the client.\nThis might all be handled with interactions between the FEP and the game-server\nprocesses involved. ,\n\nThe FEP introduces a single process to filter packets. A FEP might handle com-\npression and encryption for client connections, dumping raw, uncompressed clear\ntext to back-end processes in order to save precious CPU resources for other activities\n(like AI or physics). Because the FEP is the single point of entry for client data, pack-\nets might also be validated on the FEP, without requiring protocol upgrades (e.g., ifa\nclient attempts to send a malformed packet to crash game servers).\n\nFront-end processes safeguard clients from game-service failures on the back-end.\nIf there is a recovery scenario implemented, clients need never know that the server\ndied a horrible death. The connection between the FEP and the client can remain\nactive while the back-end starts a new game service and redirects the clients to the new\nprocess. Meanwhile, the developer can browse the core files, while players happily\ncontinue abusing their servers.\n\nOf course, every design has its flaws. Introducing a FEP will induce latency as\ndata is read from the network, dispatched to the appropriate connection on the back-\nend, committed to the wire, and read on a back-end process. It is another process to\nmanage when maintaining or diagnosing server clusters.\n\nDistributing server processes does not necessitate the use of FEPs. Some game\ndesigns that involve autonomous game servers (i.e., there is no requirement for a uni-\nfied world simulation) requiring near-real-time latencies are probably not candidates\nfor using front-end processes.\n\nInterprocess Interaction\n\nThe majority of technical exploits arise when players interact across process bound-\naries. A player trading items for gold with an NPC or player on another process is a\ngreat example of a duplication exploit. If Joe (on Server A) is accepting plate mail\narmor offered by Jane (on Server B), and Joe (or anyone else) manages to crash Server\nB, he might be able to duplicate the plate mail armor. This happens if Joe's server",
      "content_length": 3030,
      "extraction_method": "OCR"
    },
    {
      "page_number": 515,
      "chapter": null,
      "content": "530 Section 5 Network and Multiplayer\n\ncommits the transaction while Server B is crashing and has not committed the trans-\naction. Jane still has plare mail armor; so does Joe. There are two plate mail armors in\nthe world where before there was only one. Next time they trade 2 armors, then 4, 8,\n16, and so on, until they have an obscene amount of armor to loot.\n\nThe liberal use of UML {Larman01] sequence diagrams is indispensable when\nidentifying interprocess exploits. As diagrams are built, assume one or both servers\nwill crash at some point during an interprocess interaction, Identify what will happen\nto the state of the game if this happens.\n\nWhen building sequence diagrams, take time to consider interactions with over-\nloaded servers and how these affect gameplay. It would be unfair to keep a player\nlocked in a trade screen while it waits for a server that might never return. Messages\nsent between processes might not be processed right away. Assume that one or more\nprocesses will have a 100% CPU load and might never have an opportunity to process\nan interaction. Thinking asynchronously will help to design a system that the player\nperceives as better-performing. It will be more tolerant to unfair demands on some\nprocesses and can help to build load-balancing systems to even out the CPU load on\na server cluster.\n\nOptimization\n\nThree-dimensional clients limit the number of polygons sent to a rendering pipeline\nto what is potentially visible in the scene. This is done to save the amount of process-\ning necessary to draw a scene. Large-scale, distributed servers are under a much heav-\nier load, interacting with more objects than a client scene has polygons. N? operations\nbetween one million objects that are scattered over 20 or more processes will quickly\ndemonstrate a requirement to cull objects on the server as well!\n\nOn a client, culling happens relative to a single camera in a single scene. On a\nserver, the problem balloons out of proportion. Each object has its own perspective on\nthe world! The strategies that worked so well on a single game client are not an exact\nfit for the complications presented by the server—it cannot afford to spend most of its\nCPU in sorting and culling algorithms, leaving only a few cycles for Al, messaging,\nphysics, persistence, and the plethora of other tasks it must complete.\n\nIt is desirable, even necessary, to limit what each object can interact with to some\nvery small subset of other objects in the world. A system that could rapidly sort and\nupdate objects, independent of any perspective presented by a single object, and use\nless than 10% of the CPU would be ideal.\n\nThose systems do exist, and which one is right for a server really depends on the\nsimulation. This gem will focus on a particular subdivision system proposed in a pre-\nvious article by John Ratcliff in Game Programming Gems 2—the Sphere Tree [Rat-\ncliff]. Ic will also present a perspective strategy for objects that fit well with a\ndistance-based culling system.",
      "content_length": 3012,
      "extraction_method": "OCR"
    },
    {
      "page_number": 516,
      "chapter": null,
      "content": "&.4 Scaling Multiplayer Servers 531\n\nThe Sphere Tree\n\nDistance-based culling is best suited to large worlds that cover a lot of area and have\nclusters of populations scattered throughout world space. Interactions aggregate\naround objects close to one another and cull objects that are far off in the distance.\nThe sphere tree is an ideal distance-based spatial sorting algorithm.\n\nSphere trees make speedy distance queries, quickly returning a solution set of\nobjects that are within an arbitrary sphere. They also have the property of extremely\nrapid resorting of objects in motion. These characteristics can be employed to main-\ntain a perspective-independent sorting and subdivision system to facilitate limited\ninteraction between objects in the world simulation.\n\nA sphere tree organizes objects in a hierarchy of spheres, There is a root node con-\ntaining all child spheres (see Figure 5.4.2). Children are subdivided into progressively\nsmaller spheres until suitable-size bounding spheres populate the tree. As an object\nmoves within a sphere, it checks its parent’s boundaries. If it exceeds the boundary,\nthe parent either resizes itself to accommodate the new position, or, if some maximum\nsize has been reached, the object is sorted into the parent's parent sphere, and a new\nchild sphere is created.\n\nFIGURE 5.4.2 A three-level sphere tree depicting a root node, two super spheres, and six\nchild spheres.\n\nSphere-to-sphere testing is a reasonably efficient process and compares vector dis-\ntances. This process can be further optimized by comparing square distances to avoid\na slow sqrt() call. Because objects in a sphere tree are sorted based on bounding\nspheres, when a range-based query is made to the tree, it tests the top-most nodes in\nthe tree. Those spheres that satisfy an intersection are further queried. Their child",
      "content_length": 1840,
      "extraction_method": "OCR"
    },
    {
      "page_number": 517,
      "chapter": null,
      "content": "532\n\nSection 5 Network and Multiplayer\n\nspheres are tested against the query. This process repeats recursively through the tree\nuntil a set of objects thar satisfy the range query are identified.\n\nPerformance of the query depends on the size of the range requested, The smaller\nthe query, the fewer top-most nodes will be included for recursion. This is the second\nuseful property of sphere trees with distance-based culling.\n\nEach object has a bounding sphere so that it properly sorts into the tree. Addi-\ntionally, it has an ‘interest’ sphere, in which it has its own perspective on the world,\nbased on some distance. As the object moves, so does the interest sphere. That sphere\nis used to query the sphere tree. When the query returns a new object to interact with,\nthen it is ‘in view,’ relative to the object moving. The new object is placed in a set of\npotentially interactive objects.\n\nWhen the server checks for interactions between objects, it need only query the\npotentially interactive set. This is a much smaller subset (depending on the interest\nradius) than the total number of objects in the world.\n\nAs the new object is added, the server might also check to see if it is a player char-\nacter moving about in the world. If it is, chen when the object is added to the poten-\ntially interactive list, and baseline information for the new object might be sent to\nthe client. As the object moves or changes, the client can receive updates about\nthat object. The server will only have to send updates about objects that are poten-\ntially interactive with the client. Likewise, when objects are removed from the po-\ntentially interactive set, they might be unloaded from clients.\n\nIt is tempting to place an interest radius on a client’s character object. This pro-\nvides a single interactive set that the client can query for new information. It is more\nefficient, however, to have interactive sets relative to other objects. A building might\nhave a long range of interaction (it might be visible for hundreds of meters in game-\nworld space), while a shrubbery next to the building might have a visible range of\nonly a few meters.\n\nBy storing the interactive set on the viewed objects rather than the viewer,\nupdates can be ‘pushed’ to viewers by the observed object. This will prevent excessive\npolling, incurring CPU usage only as events take place.\n\nFor the most part, objects are not in motion, and so they do not query the sphere\ntree to update their interactive sets. Objects that are in motion will need to collide\nwith the interaction spheres of stationary objects. The building will want to know\nwhen a character is close enough to see it when the character walks toward the city.\n\nInteraction spheres might be bounding spheres placed into a sphere tree as well.\nCollision tests with spheres in the tree are efficient. When a collision occurs, the tar-\nget might receive notification and add the source (mover) to its interactive set. Using\nthis method, stationary objects such as buildings or idle nonplayer characters can be\nadded to a client’s world-view and update the client if their state changes.\n\nThis same approach can be used to cull server-to-server interactions. Reducing\nservet-to-server traffic is at least as important as server-to-client traffic. Servers will\nneed to perform some processing on remote objects if they interact. Forcing all server",
      "content_length": 3383,
      "extraction_method": "OCR"
    },
    {
      "page_number": 518,
      "chapter": null,
      "content": "6.4 Scating Multiplayer Servers 533\n\nprocesses to spend CPU on all objects in the world will quickly bring a server cluster\nto its knees.\n\nSphere trees are not the only solution to problems of spatial sorting and culling\ninteractions, but they are a reasonable solution for large worlds where distance matters.\nQuadtrees and octrees are just as reasonable for large worlds, but these have their own\ndrawbacks. Some worlds consisting of interconnected spaces are better suited to a por-\ntal-based system to cull interaction. Portals, quadtrees, octrees, sphere trees, and many\nother algorithms are at the disposal of the developer. The hard part is not in imple-\nmenting the right solution; the hard part is to find the right solution to implement.\n\nConclusion\n\nThis gem has described several techniques that are useful in the design of scalable\nmultiplayer servers. Be sure to take advantage of the server platform’s most efficient\nnetwork API, even at the expense of portability, so that servers can handle the greatest\npossible number of connections. Architectural features like front-end processes and\nsphere trees for culling provide high server performance and isolate back-end servers\nfrom direct contact with client machines. Spending extra time early in the develop-\nment process to build simple, safe, and reusable APIs, like message dispatching and\nmessage factories, will ensure more-rapid implementation of gameplay features as the\nproject nears completion.\n\nReferences\n\n[Larman01} Larman, Craig, Applying UML and Patterns: An Introduction to Object-\nOriented Analysis and Design and the Unified Process, Prentice Hall, 2001.\n\n[MSDN00] Microsoft Corporation, “Windows Sockets 2.0: Write Scalable Winsock\nApps Using Completion Ports,” available online at hrtp://msdn.microsoft.com/\nmsdnmag/issues/1000/Winsock/Winsock.asp, MSDN, October 2000.\n\n[Ratcliff] Ratcliff, John W., “Sphere Trees for Fast Visibiliry Culling, Ray Tracing,\nand Range Searching,” Game Programming Gems 2, Charles River Media, Inc.,\n2001.\n\n[ShowEq01] HackersQuest. “HackersQuest” is available online at hrtp://www-hack-\nersquest.org/, March 2002.\n\n[Schnier98] Schnier, Bruce Twofish, “A 128-bit Block Cipher,” available online ac\nhetp://www.counterpane.com/twofish-paper.html, Counterpane Labs, 1998.",
      "content_length": 2282,
      "extraction_method": "OCR"
    },
    {
      "page_number": 519,
      "chapter": null,
      "content": "Template-Based Object\nSerialization\n\nJason Beardsley, NCsoft Austin\njbeardsley@ncaustin.com\n\n| a networked game, either client/server or peer-to-peer, it is important to have\nan efficient method of converting objects to and from a network-friendly repre-\nsentation, most typically a stream of raw bytes. This process is known as serialization.\n\nEven for non-networked games, serialization is useful for dealing with the file\nsystem (e.g,, when loading resources from disk or saving game state). However, file-\nbased schemes often trade space efficiency for capabilities that are not usually required\nin a network environment, such as random access, in-place modification, a hier-\narchical directory structure, or versioning. This makes them unsuitable for network\ncommunication.\n\nThis gem presents a serialization method designed for network usage. It achieves\na high degree of flexibility and uniformity in handling all types of objects—built-in\ntypes, STL containers, and user-defined classes.\n\nExisting Solutions\n\nSerialization itself is nothing new. One commonly employed method is to define a\nstructure containing the data to be serialized, fill it in, and simply use memcpy(} to\nconvert it into a format suitable for network transmission. This approach is very fast\nand satisfactory for many applications, but it has some inherent limitations:\n\n* Tt only works when the bit-level representation of data is exactly what should be\nsent over the network. This is not generally true for C++ classes—in particular,\nthose that use dynamic storage or have embedded pointers, or any class with vir-\ntual methods.\n\n* Care must be taken when in laying out the structure in order to minimize\npadding by the compiler. In a cross-platform environment, any padding must be\napplied equally by all compilers.\n\n* Any byte order conversions must be done explicitly before copying.\n\n* Handling variable-length data, such as strings or arrays, is clumsy at best.",
      "content_length": 1948,
      "extraction_method": "OCR"
    },
    {
      "page_number": 520,
      "chapter": null,
      "content": "5.5 Template-Based Object Serialization 535\n\nIn summary, the ‘struct/memepy()’ serialization method is only applicable when\ndealing with fixed-size structures containing plain data types. Another standard prac-\ntice involves the use of an object that has methods to store and retrieve each desired\ntype. This class might look something like the following:\n\nclass Serializer\n\n{\npublic:\n{// plain o1' data\nbool Put(int val};\nbool Get(int& valdut};\nbool Put(float val);\nbool Get(float& valOut);\n// standard classes\nbool Put(const std::string& val);\nbool Get(std::string& valOut) ;\n// STL containers\ntemplate <typename T>\nbool Put{const std::set<T>& val);\ntemplate <typename T> bool\nGet (std: :set<T>& valdut};\n// et cetera\n‘5\n\nNote that Put({} and Get() are overloaded instead of being named for the type\nthey handle (e.g., PutInt() or GetString()). This is essential for STL container sup-\nport. If the methods were not overloaded, then the code for handling an STL collec-\ntion could not be written in a generic fashion (i.e., by calling Put() and Get() on its\nrespective elements).\n\nWhen it comes to user-defined classes, we face a dilemma—should Serializer\nbe extended to directly support every class, or should the class have its own serializa-\ntion methods? The answer to the first question is a resounding “NO,” for a variety of\nreasons. First, Serializer must have access to the internals of any nontrivial class\n{requiring friendship). Second, every time support for a new type is added, there\nmight be a large amount of unnecessary recompilation. In addition, Serializer’s\ninterface could easily grow out of control. In short, this is a maintainability night-\nmare, not to mention very inelegant.\n\nTherefore, serialization support should be incorporated into each class directly.\nTypically, this involves defining an abstract interface class with pure virtual methods\nto support serialization:\n\nclass Serializable\n\n{\n\npublic:\nvirtual bool PutInto(Serializer& s} const = 0;\nvirtual bool GetFrom{Serializer& s} = 0;",
      "content_length": 2020,
      "extraction_method": "OCR"
    },
    {
      "page_number": 521,
      "chapter": null,
      "content": "536 Section 5 Network and Multiplayer\n\nThen, extend Serializer to support serializable objects:\n\nbool Serializer::Put(const Serializable& obj)\n{ return obj.Putinto(*this}; }\n\nbool Serializer: :Get(Serializable& obj}\n{ return obj.GetFrom(*this); }\n\nThere is nothing wrong with this idea, but it has some drawbacks. It requires\nmodification of the class to be serialized, which is fine, if possible. However, what if\nthe class is provided by a third-party library and cannot be changed? There are per-\nformance implications, forcing what might otherwise be a very simple, standalone\nclass into an inheritance hierarchy. For a game, where speed is of the utmost impor-\ntance, introducing virtual methods into a simple class might be an unacceptable price\nto pay.\n\nAside from the requirement that user classes be detived from Serializable, and\naccepting some other minor performance problems (e.g., the header declaring Seri-\nalizer must include all STL container headers, increasing compilation times), this\nsatisfies the goal of a consistent, extensible serialization system. The question is, can it\nbe refined further to eliminate (or reduce in scope) these last few problems? The\nanswer is “Yes,” but before we can present the final method in detail, some back-\nground material is in order.\n\nPortability\n\nNetworked games, especially those of the client/server variety, are often multiplatform\napplications. The client might run on Windows, Macintosh, or PlayStation2, whereas\nthe servers might be a mixture of Linux, Solaris, and Windows, running on different\nprocessor architectures. Any serialization library must therefore be highly portable,\nwhich means it must be ported to (and tested on) each target platform.\n\nOne of the first lessons learned when writing multiplatform code is that the C++\nlanguage does not dictate the exact size (in bits) of built-in types, such as int and\nfloat. For serialization, this poses a problem, because the exact size of an object must\nbe known. Otherwise, a value could be written using 32 bits, but read out using 64\nbits, leading to undefined results. The most recent C standard addresses this by pro-\nviding the <inttypes.n> header, but it could be some time before all compiler ven-\ndors implement this. The next best thing is to define (via typedef) a group of\nfixed-size primitive types (int8, int16, int32, inté64, uinté, ..., uint64, floatsz,\nfloaté4), and use only these when serializing data. Care must be taken when dealing\nwith data that might be implicitly converted to more than one of the supported\ntypes—enumerated types and manifest constants should be explicitly cast to an\nappropriate numeric type before being stored or retrieved.\n\nThe next complication with cross-platform code is that of byte order. Different\nchip architectures store multibyte values (both integers and floating-point numbers) in",
      "content_length": 2858,
      "extraction_method": "OCR"
    },
    {
      "page_number": 522,
      "chapter": null,
      "content": "5.5 Template-Based Object Serialization 537\n\nmemory using either ‘big-endian’ or ‘little-endian’ order [Kernighan99]. Thus, the\nserialization system must be able to convert to and from a standard byte order in order\nfor the low-level data format to be truly portable. Which specific byte order (big or lit-\ntle) is chosen is not extremely important, so long as it is consistent. A good rule of\nthumb is to go with the native format on the server side, since clients presumably have\nmore CPU cycles to burn. Regardless, byte swapping should never be a noticeable per-\nformance problem. Since we are using our own primitive types, we must implement\nour own set of conversion functions instead of using the standard hton1() and friends.\n\nSpeaking of primitive types, floating-point numbers might prove to be a signifi-\ncant barrier to portable code, depending on the target platform. Fortunately, almost\nevery processor manufactured today uses the standard IEEE formats, so bit-level\ncopying of floating-point data is actually portable. Keep in mind thar floats also have\na byte order, which is almost certainly the same as the integer order, so they might\nneed to be swapped. It is not difficult to write a program to test a particular architec-\nture for IEEE compliance, though what to do on a nonconforming platform is left as\nan exercise for the unlucky reader.\n\nThe Serializer Class\n\nThe goals for the serialization system are as follows:\n\n* Present a consistent interface for storing and retrieving all types of data.\n\n* Support primitive types, STL containers, and user-defined classes, with minimal\ncode changes to the latter.\n\n* Beas efficient as possible, while still remaining portable.\n\nAs the title of this gem suggests, the key to meeting these goals is the use of tem-\nplates—specifically, the use of member function templates.\nSuppose we declare Put () and Get() inside Serializer as follows:\n\nclass Serializer\n\n{\n\npublic:\ntemplate <typename T> bool Put(const T& obj);\ntemplate <typename T> bool Get(T& obj};\n\n}\n\nAll that is necessary now to support any type T is simply to define specialized ver-\nsions of each function. For example, the standard C++ string class:\n\ntemplate <>\nbool Serializer: :Put(const std::string& obj)\n{ {/* implementation */ }\n\ntemplate <>\nbool Serializer: :Get(std::string& obj)\n{ /* implementation */ }",
      "content_length": 2341,
      "extraction_method": "OCR"
    },
    {
      "page_number": 523,
      "chapter": null,
      "content": "Section 5 Network and Multiplayer\n\nRegrettably, it is at this point when another lesson in cross-platform program-\nming is learned—not all compilers are created equal. While the above code is stan-\ndard C++, it is not accepted by all compilers. Microsoft Visual C++ 6.0, for example,\ndoes not support member template functions defined outside the enclosing class dec-\nlaration. Working around compiler differences is standard operating procedure for\nthe network coder, and as is the case with many programming problems, the answer\nlies in introducing another layer of indirection.\n\nIf there were auxiliary functions that handled the low-level details of storing\n(PutInto()) and retrieving (Getfrom()) the bits for any given type T, safely tucked\ninside the SerializeHelper namespace to avoid any conflicts, then we could trivially\nimplement Put() and Get() in the following manner:\n\ntemplate <typename T> bool Put(const T& obj}\n{\n\n}\n\nreturn SerializeHelper::PutInto(*this, obj);\n\ntemplate <typename T> bool Get(T& obj}\n{\n\nreturn SerializeHelper: :GetFrom(*this, obj);\n}\n\nThe task then becomes defining PutInto{) and GetFrom() for all of the requisite\ntypes: integers, floats, strings, STL containers, and so forth. Since the namespace can\nbe extended arbitrarily and in separate compilation units, user-defined types are easily\nand efficiently supported.\n\nInput and Output Storage\n\nSerializer makes use of a ‘byte-buffer’ utility class that handles the mundane details\nof reading and writing to memory, including automatically resizing itself when being\nwritten to. The partial interface for this class is as follows:\n\nclass BuTffer\n\nPublic:\nbool Write(const void* data, int len};\nbool Read(void* dataOut, int len);\nconst void* GetData(} const;\nint GetLength{} const;\n\n}5\n\nHandling Simple Fixed-Length Types\n\nIntegers, floats, and bool can be dealt with in two ways—using functions inside the\nSerializeHelper namespace or directly inside Serializer itself (i.c., by overloading\nPut(} and Get()). Since these types are so fundamental, we will employ the fatter\nmethod, as it might also speed up compile times.",
      "content_length": 2108,
      "extraction_method": "OCR"
    },
    {
      "page_number": 524,
      "chapter": null,
      "content": "5.5 Template-Based Object Serialization 539\n\nThe code for each type is similar. Convert the value to network byte order (if nec-\nessary), and copy the bits, For bool, first convert to a uints (true = 1, false = 0), since\nthe underlying representation might be a larger integral type.\n\nHandling Simple Variable-Length Types\n\nTwo types fall into the simple variable-length types category: C-style strings and\nuntyped byte arrays. Since strings are null-terminated, it is possible to store the char-\nacter atray with its null terminator, without a Pascal-style lengthfield. Nonetheless,\nexplicitly storing the length (and omitting the terminator) is safer overall, even if it is\nmarginally less space-efficient. Both string objects and char* can be passed to Put ().\nHowever, there is no Get(char*) function, because the size of the output cannot be\ndetermined.\n\nWide character strings are a portability issue, because the size of wchar_t is not\nstrictly defined by the language. Even on a single platform, the exact size can vary,\ndepending on compiler options. Therefore, there is no built-in support for wide\nstrings. One workaround is to define an application-specific wide-string class (per-\nhaps based on the basic_string template), and make it serializable.\n\nRaw byte arrays also pose something of a problem. The interface to Put() takes in\na single argument, but it is necessary to know the number of items to write (as well as\nthe maximum number of items that can be read), Fortunately, we have introduced a\nclass that can act like a byte array (Buffer), and it is easily made serializable. There\nwill be times, however, when using Buffer is not possible, or when doing so might\ninvolve extra copying. Two additional methods, putRaw() and GetRaw(}, provide low-\nlevel access to the serialized stream. These take a length parameter that indicates the\n\nnumber of bytes to be written or read, respectively.\n\nHandling STL Containers\n\nStoring the contents of an STL container is straightforward. First, write out the num-\nber of elements, and then walk from the container’s begin() to end()}, writing out\neach individual item (calling Put() again). The code to implement this is virtually\nidentical for all containers, so naturally it would be nice to only have to write it once.\n\nProgrammers familiar with the STL know that the key to working with STL con-\ntainers (and the true power of the STL) is effectively using iterators [Meyers01]. The\nmany algorithms that come with the STL (e.g., find_if()}) use iterators almost exclu-\nsively. Serialization is no different, and although Put() and Get() do operate on con-\ntainers explicitly, underneath the hood are a pair of functions that only manipulate\niterators—PutRange() and GetRange{). These are in the SerializeHelper namespace\nand only rely on the public interface of Serializer.\n\nHere is the implementation of PutRange(). Note that it could compute the num-\nber of items by using the distance(} algorithm, but it is generally more efficient for\nthe caller to compute it (using size()), and pass it in as a parameter.",
      "content_length": 3074,
      "extraction_method": "OCR"
    },
    {
      "page_number": 525,
      "chapter": null,
      "content": "Section 5 Network and Multiplayer\n\ntemplate <typename Iterator>\n\nbool SerializeHelper: :PutRange(Serializer& s,\nconst Iterator& begin,\nconst Iterator& end,\nuint32 size)\n\n{\nif (!s.Put(size)) return false; // store size\nfor (Iterator it = begin; it != end; ++it)\nif (!s.Put(*it)) return false; // store item\nreturn true; // Success\n}\n\nRetrieving the elements of a container is slightly more complicated. This process\nhas two extra wrinkles—first, the type of objects contained must be determined (e.g.,\nfor set<T>, figure out what T is); and second, once an element has been unserialized,\nit must be inserted back into the container. Given this, it is a matter of reading\nthe number of elements and then reading each element out one-by-one, adding to the\ncontainer. Fortunately, the designers of the STL have provided the necessary func-\ntionality in the iterator_traits class and the concept of insert iterators [Josuttis99),\n[Austern98].\n\ntemplate <typename Inserter>\nbool SerializeHelper: :GetRange(Serializer& s,\nInserter it}\n\n{\nuint32 size;\nif (‘s.Get(size}) return false;\nfor ({uint32 i = 0; i < size; ++i}\n{\niterator_traits<Inserter>: :value type obj;\nif (1s.Get(obj}} return false;\n*it = obj; // inserts into container\n}\nreturn true; // success\n}\n\nOnce again, compiler differences (or more accurately, STL differences) arise and\nmake this piece of code nonportable. The culprit here is iterator_traits, which is\nnot fully functional on all platforms, The workaround is something of a hack. What\nis needed is a way to determine the type of the contained objects. The caller of\nGetRange(} certainly knows this, and thus can pass in a null pointer of that type T,\nwhich becomes another template argument. The result (differences in bold) is:\n\ntemplate <typename T, typename Inserter>\n\nbool SerializeHelper: :GetRange(Serializeré& s,\nInserter it,\nT* /* unref */}\n\nuint32 size;\nif (!s.Get({size)} return false;\nfor (uint32 i = 0; i < size; ++i)",
      "content_length": 1945,
      "extraction_method": "OCR"
    },
    {
      "page_number": 526,
      "chapter": null,
      "content": "5.5 Template-Based Object Serialization 541\n\n{\n\nTF obj;\n\nif (!s.Get(obj)) return false;\n\n*it = obj; // inserts into container\n}\n\nreturn true; // success\n\n}\n\nGiven Putfange() and GetRange(), writing the other helper routines for an STL\ncontainer is straightforward. For list, this is the code:\n\ntemplate <typename T>\n\nbool SerializeHelper: :PutInto(Serializeré s,\nconst list<T>& 1)\n\n{\n\n}\ntemplate <typename T>\n\nbool SerializeHelper: :GatFrom{Serializer& s,\nlist<T>& 1)\n\nreturn PutRange(s, 1.begin(), l.end{), 1.size(}};\n\n{\nl.clear(); // destroy any existing contents\nreturn Gethange(s, back_inserter(1}), (T*}0);\n\n}\n\nThe rest of the STL containers are handled similarly, with the only difference\nbeing in the number of template arguments (e.g., map requires two types—key and\nvalue) and the creation of the insert iterator in the call to GetRange(). Sequence-based.\ncontainers use the back_inserter adapter (which calls push_back()), while the others\nuse a plain inserter (which calls insert(}).\n\nIn order to completely support associative containers (map, hash_map, etc.), we\nmust also define serialization functions for the utility template class pair. Note that\nSTL containers of any serializable class are supported (including nested containers),\nso long as the class has a default constructor.\n\nHandling User-Defined Classes\n\nThe final piece to the system is dealing with user classes (i.e., any arbitrary class that\nyou want to serialize). Classes (or structures) whose public interface can be used to\nread and write an object's complete state, and which are not part of an inheritance\nhierarchy, are simple: define PutInto() and GetFrom(), and that's it. No changes to\nthe class are necessary!\n\nWhen a class has private data, the SerializeHelper functions will have to be\nmade friends. If these are viewed as external member functions, then this does not\nreally break encapsulation. In fact, it is similar to adding iostream support to a class.\n\nA class hierarchy makes life interesting. For example, say we have an abstract base,\nMessage class, and concrete subclasses, MoveMessage and ChatMessage. The base class\nhas members that need serialization, as do the subclasses. Since more message classes",
      "content_length": 2206,
      "extraction_method": "OCR"
    },
    {
      "page_number": 527,
      "chapter": null,
      "content": "§42\n\nExtensions and Optimizations\n\nSection 5 Network and Multiplayer\n\necottA meen SAA MRU gmc aR mH cae A re ra ar RA RU Nop UM arte NMI DN ra\n\nwill probably be added in the future, the network layer (where messages are serialized\nbefore going out on the wire) only knows about Message objects. How can this layer\nproperly serialize an arbitrary Message, and how can it create an arbitrary Message out\nof a bunch of received bytes?\n\nFor serialization, the answer is to reintroduce the serializable concept. Make che\nbase class Message directly serializable {i.c., define PutInto() and GetFrom{}). Have\nthese functions call into pure virtual methods that Message subclasses must define in\norder to handle class-specific data. On the receiving end, use the factory pattern\n[Gamma95) to create the right type of Message before unserializing. In order for the\nreceiver to know which kind of Message was sent, and therefore which kind to manu-\nfacture, a header with type information (e.g., a ‘message~class id’) is also required.\n\nPointers and Arrays\n\nDealing with pointers is pretty easy—simply dereference them and call the existing\nmethods. Defining Put() and Get() that take pointer arguments does not work,\nbecause it gives the compiler a choice of which template to instantiate (Put<T>(T*) or\nPut<T*>(T*)), and this is an ambiguity error. Compilers do not fike choices, As a\nresult, this means that STL containers of pointers cannot be automatically serialized.\n\nThe interface must change to properly support arrays, because we need to know\nhow many elements are to be written in Put () and the maximum number that can be\nread in Get(}. Since one of che overriding goals is a consistent interface, this is unde-\nsirable. However, working with plain arrays is of obvious importance for efficiency, so\ntemplatized Putarray{) and GetArray{) functions (taking a length parameter) are\nincluded—-but in general, using the STL vector class is every bit as fast as arrays. Just\nlike pointers, an STL container of arrays is not going to work out-of-the-box,\nalthough this hardly sounds like a limitation.\n\nA Variable-Length Count\n\nStrings, buffers, and $TL containers store their sizes in serialized outputs. The ques-\ntion is: What kind of integer should be used for this lengthfield? To minimize output\nsize, it should be as small as possible. Requiting the length to fit inside (say) a uint16\nlimits the ability to serialize large collections, which might impact user code. Using a\nuint32 certainly provides enough space, but will waste bytes in most cases.\n\nAn idea that minimizes the output size yet allows for large lengthfields, is to\nencode the length in a variable number of bytes. Each byte contains seven data bits,\nand one ‘stop’ bit. To encode a count with N significant bits, a total of (LV - 1)/7 + 1)\nbytes are required. This format will end up using 5 bytes to encode a value with 29 or\nmore significant bits, but if there are chat many elements being stored, the extra byte\nwill hardly be noticeable.\n\nYou might be tempted to use this process for all multibyte integers. However, this\nis a bad idea if the values being stored falf into an even distribution across the type’s",
      "content_length": 3185,
      "extraction_method": "OCR"
    },
    {
      "page_number": 528,
      "chapter": null,
      "content": "5.5 Template-Based Object Serialization 543\n\nentire range, because the average encoded length will actually be larger than the fixed\nlength. Encoding is beneficial only because most of the values being serialized are\nsmall.\n\nKeyed Serializor\n\nScripting languages often have a built-in ‘generic’ hash table, capable of storing a\nmapping from just about any object to any other—Perl’s associative array and\nPython's dictionary types are two examples. Using serialization, this same concept can\nbe implemented in C++. The geal is to create a class that maintains a mapping from\nsome known type T to any arbitrary type of object—like an STL map with no restric-\ntions on the value type. As might be expected, this class is a template (with member\ntemplate functions), and has the following interface:\n\ntemplate <typenama KEY>\nclass KeyedSerializer\n\n{\npublic:\ntemplate <typename T>\nbool Put{const KEY& key, const T& value};\ntemplate <typename T>\nbool Get(const KEY& key, T& value);\nI;\n\nThe implementation is actually pretty simple. It has an internal map from KEY\nto the Buffer class defined earlier. Put() first serializes value into a Buffer, and\nthen adds to the map. Get() does the reverse (leaving the map unchanged—so it\ncan be called multiple times with the same key). One interesting characteristic of\nKeyedSerializer is that it, unlike Serializer, allows random access to its stored\nobjects. If an object is never retrieved, its (potentially complicated) deserialization\ncode is never invoked. Finally, KeyedSerializer can itself be made serializable, and\nthis is where it becomes truly useful in a network context.\n\nPartial Serialization\n\nNetwork programmers know that bandwidth is money. Just about anything a net-\nwork game can do to minimize the size of messages being sent between client and\nserver (or client peers) is worth trying. In light of that, the KeyedSerializer class can\nbe quite useful for sending partial updates over the network.\n\nFor example, suppose a ‘game object’ has the following basic properties: position,\norientation, velocity, scale, color, and type. If an object update message contained\nevery one of these values, and updates were sent on a regular basis, it is pretty clear\nthat bandwidth would be wasted—an object's scale, color, and type are not likely to\nchange very frequently, if ever. Obviously, individual message types could be used for\neach property, but as the number of properties grows, the number of potential mes-\nsages (including combinations of related properties) can grow quite large. However, if",
      "content_length": 2550,
      "extraction_method": "OCR"
    },
    {
      "page_number": 529,
      "chapter": null,
      "content": "544 Section 5 Network and Multiplayer\n\nan object update contained a KayedSerializer (perhaps using uints as the key type),\na single message can handle any combination of properties, use a single code path,\n\nand with minimal overhead.\n\nObject Tagging\n\nThere is a potentially serious problem with Serializer. This is type safety—or, the\nlack thereof. If two objects serialize into the same number of bytes (e.g., float32 and\nuint32), then it is possible to store one type and read the other. Of course, this is a\nbug in the application and not in the serialization library, but the fact remains that it\ncan happen without any indication of error (except for whatever odd side-effects\nresult).\n\nThe solution is to introduce a measure of safety by preceding each object with a\ntag. When reading, the tag is checked against what is expected, If the tags do not\nmatch, then an error is returned. To compute the tag for a given type, another func-\ntion inside the SerializeHelper namespace is used (and therefore must be defined for\n\nall supported types). Using a one-byte tag, this is the resulting code (changes in bold):\n\ntemplate <typename T> bool Put(const T& obj)\n\n{\nuint8 tag = SerializeHelper: :ComputeTag (obj);\nreturn WriteTag(tag) 2&\n\nSerializeHelper: :PutInto(*this, obj);\n}\n\ntemplate <typename T> bool Get(T& obj)\n\nuint& expected = SerializeHelper: :ComputeTag(cbj};\nreturn ReadAndCheckTag(expected} &&\nSerializeHelper: :GetFrom(*this, obj};\n}\n\nIt goes without saying that this will increase the size of the serialized output.\nHowever, this additional overhead can be eliminated by making the tag processing\noptional (e.g., only in debug builds or as a runtime toggle). The auxiliary functions\nWriteTag{) and ReadAndCheckTag() hide all of the details, so that is where conditional\nprocessing of tags takes place. If tags are turned off, these simply do nothing and\nreturn true.\n\nThere are a number of ways by which Serializer and its related classes can be\nextended further, Here are a few ideas:\n\n* Generalize the storage mechanism (instead of always using Buffer) to use an\nabstract interface and implement serialization to/from files, both binary and\nhuman-readable text (useful for debugging).\n\n* Integrate support for a favorite scripting language.",
      "content_length": 2259,
      "extraction_method": "OCR"
    },
    {
      "page_number": 530,
      "chapter": null,
      "content": "5.5 Template-Based Object Serialization 545\n\n* Write adapters that allow che stream operators (<< and >>) to be used for some\nsyntactic sugar (be careful to consider proper error-handling).\n\n* Build a code generator that automates the creation of serializable classes, based on\na specification with types and field names.\n\n* Add encryption and/or compression at the serialization layer.\n\n* Port the code to a new compiler or platform.\n\nConclusion\n\nThis gem has presented a system for object serialization that is efficient, extensible,\nand minimally intrusive. Using the power and expressiveness of templates, it provides\na great deaf of functionality in a relatively small amount of code.\n\nReferences\n\n[Austern98] Austern, Matthew H., Generic Programming and the STL, Addison Wes-\nley, 1998.\n\n[Gamma95] Gamma, Erich, et al., Design Patterns, Addison Wesley, 1995.\n\n[Josuttis99] Josuttis, Nicolai M., The C++ Standard Library: A Tutorial and Reference,\nAddison Wesley, 1999.\n\n[Kernighan99] Kernighan, Brian W. and Rob Pike, The Practice of Programming,\nAddison Wesley, 1999.\n\n[Meyers01} Meyers, Scott, Effective STL, Addison Wesley, 2001.",
      "content_length": 1138,
      "extraction_method": "OCR"
    },
    {
      "page_number": 531,
      "chapter": null,
      "content": "IPSec\n\nSecure Sockets\n\nPete Isensee, Microsoft Corporation\npkisensee@msn.com\n\nheating and hacking in multiplayer games is a common problem that can destroy\n\na gaming experience. One way to prevent cheating is by using cryptography,\nencrypting and authenticating network traffic. This gem explores the Internet Proto-\ncol Security (IPSec) standard and shows how games can leverage portions of the stan-\ndard to protect network packets and prevent spoofing, sniffing, and replay attacks.\n\nIPSec is an Internet standard developed by the Internet Engineering Task Force based\non academic and government research. It is published in [RFC2401] through\n[RFC2411], as well as [IPSec2]. IPSec provides services for authentication, integrity,\nand confidentiality, and is widely used to implement virtual private networks (VPNs).\nIPSec is designed to be implemented at the network layer (network stack) and is typ-\nically hidden from applications. Unfortunately, native [PSec is not a viable option on\nmost gaming platforms. Even when IPSec is available in a given OS (e.g., Windows\n2000), it’s neither on by default nor required that applications support it. Neverthe-\nless, game programmers can learn a lot from IPSec, and many of the features of IPSec\ncan be implemented within the context of game network code.\n\nAuthentication means verifying who sent a message; integrity means ensuring\nthat a message was not modified. IPSec implements authentication and integrity\nusing keyed cryptographic hashes like MD5 [RFC1321] and SHA-1 [RFC3174].\n“Confidentiality” is the term used to describe obscuring data, which implies encryp-\ntion. [PSec uses symmetric encryption algorithms like DES [RFC2405] and AES\n[AESDraft]. For game traffic, it usually makes sense to choose a high-performance\nalgorithm. Data requiring a higher level of encryption (e.g., player damage packets,\ntournament scores, etc.) can use stronger, slower algorithms. (For a good summary of\nalgorithm performance, see [WeiDai01).)\n\nCryptography alone cannot prevent replay attacks. An authentic, encrypted mes-\nsage that is intercepted and resent by an attacker will authenticate and decrypt just\nfine. Therefore, IPSec also includes a mechanism for preventing replay attacks by\nusing a combination of sequence numbers and a sliding replay window.",
      "content_length": 2302,
      "extraction_method": "OCR"
    },
    {
      "page_number": 532,
      "chapter": null,
      "content": "5.6 Secure Sockets 547\n\nCaveats\n\nOne of the most critical steps in establishing a secure system is key management. This\ngem does not cover key-exchange techniques or the proper ways to generate, expire,\nand update keys. The assumption here is that both ends of a secure connection have\nthe same keys and that the keys were established and exchanged in a secure fashion.\nAnother process essential to secure systems is the proper generation of truly random\nbits for keys, shared secrets, and initialization vectors [Isensee01]. This gem assumes\nthat keys use cryptographically random values. .\n\nThe IPSec standard requires the implementer to embed a copy of the IP header\ninto the payload of the packet, which is in turn both encrypted and authenticated.\nThis allows the receiver to verify that the actual IP header wasn't altered. Implement-\ning this level of authentication is both complicated and usually unnecessary, since the\nauthentication of the payload proves that the packet came from someone who knows\nthe proper authentication key. This gem does not cover IP authentication.\n\n[IPSec implementations are closely tied to the fragmentation system of the IP pro-\ntocol. To avoid this issue altogether, this gem assumes that all packets are sent using\nunfragmented UDP packets and not via TCP, avoiding fragmentation. Most games\nuse UDP packets anyway, so this assumption is not unreasonable. This gem also\nassumes that all messages are less than the maximum transmission unit (MTU).\nApplications must implement their own sequence mechanism for messages larger\nthan the MTU.\n\nSecurity Associations\n\nA security association (SA) is a logical ‘connection’ created for security purposes. The\nSA defines how traffic is secured from one node to another. An SA includes cipher\nand authentication keys, modes, algorithms, and other data that define the packet for-\nmat. The SecurityAssociation class included with this gem contains the information\nshown in Table 5.6.1.\n\nSAs almost always occur in pairs, with an SA on the sender exactly matching an\nSA on the receiver. In a client-server game, the server might have a list of one SA per\nclient, and each client would have a single SA that matched an SA on the server. In a\npeer-to-peer game, each peer would have a list of SAs. The list of security associations\nmaintained by a host is called the “security association database” (SAD). For games,\nthis ‘database’ typically resides in the memory of the game or game server.\n\nPrior to sending or receiving secure data, the communicating pair must establish\na security association. This gem does not cover the means by which the SA data is\nexchanged by the sender and receiver. Some of the data, like the algorithms, could be\nbaked into the code. Other data, like the keys, should change on a regular basis for\nmaximum security, and should be exchanged using secure protocols like EKE, Ker-\nberos, or Diffie-Hellman [Schneier96]. Be sure to use different keys for authentica-\ntion and encryption in order to maximize security.",
      "content_length": 3020,
      "extraction_method": "OCR"
    },
    {
      "page_number": 533,
      "chapter": null,
      "content": "548 Section 5 Network and Multiplayer\n\nTable 5.6.1 Security Association Data\n\nData Description\n\nAuthentication Algorithm — The exyptographic hashing algorithm used for authentication (e.g.,\nMDS, SHA-1)\n\nAuthentication Key The symmetric key data used for authentication\n\nEncryption Algorithm The symmetric encryption algorithm used when encrypting and\ndecrypting packets (e.g., DES, AES)\n\nEncryption Key The synumecric key dava used by the encryption algorithm\n\nSequence Number The next sequence number ro be used by a packet sent on this SA\n\nLast Sequence Number The highest sequence number received on this SA\n\nReplay Window A bitmask used as the sliding window for rejecting replay attacks\n\nTV Size The size of the encryption initialization vector (2-8 bytes)\n\nICV Size The size of the integrity check value (8-12 bytes)\n\nMax Padding Blocks The maximum number of additional random padding blocks (0-4\n\nblocks). The block size is based on the encryption algorithm.\n\nPacket Format\n\nImplementing secure sockets is a matter of encrypting and stamping a hash on data\nbefore sending it, and authenticating and decrypting the data when receiving it. Table\n5.6.2 shows the format of a secure packet, detailing which portions of the packet are\nauthenticated and encrypted.\n\nTable 5.6.2 Secure Packet Farmat\n\nData Size (bytes) Default Size (bytes) Authenticated Encrypted\n\nre ene\n\nSecurity Parameters Index (SPI} = 1-4 2 Yes No\nSequence Number 4 4 Yes No\nInitialization Vector (IV) 2-8 4 Yes No\nPayload Variable Variable Yes Yes\nPadding 0-255 0-255 Yes Yes\nPad length 1 1 Yes Yes\nIntegrity Check Vafue (ICV} 8-12 10 No No\n\nSecurity Parameters Index\n\nThe security parameters index (SPI) is a handle thar uniquely identifies a security\nassociation in a security association database. An SPI is transmitted in every secure\npacket so the receiver can select the SA under which the packet will be processed. The\nsize of the SPI is game-specific, and depends on the maximum number of SAs that",
      "content_length": 1978,
      "extraction_method": "OCR"
    },
    {
      "page_number": 534,
      "chapter": null,
      "content": "5.6 Secure Sockets 549\n\nON THE CO\n\nwill be active at any one time. The example implementation included on the CD-\nROM generates random, unique two-byte SPIs. The SPI is not, and cannot be\nencrypted, because it is used to identify the SA thar defines the algorithms and keys.\nIf an attacker modifies the SPI, the packet validation will fail, since the SPI is always\nauthenticated.\n\nSequence Number\n\nThe ‘sequence number’ is a monotonically increasing counter value. The first packet\nsent using a given security association will have a sequence number of one, the next\npacket will be number two, and so on. The receiver uses the sequence number to\nensure that duplicate packets and ‘old’ packets are ignored. The sender must ensure\nthat if there’s a possibility of the sequence number rolling over to zero, the two end-\npoints of the connection generate a new pair of security associations and expire the\nold SAs prior to rollover. The sequence number is not encrypted so that replay attacks\ncan be detected without having to decrypt the packet. This can also reduce the effect\nof a denial-of-service attack. If an attacker modifies the sequence number, the packet\nvalidation will fail, since the sequence number is always authenticated.\n\nInitlalization Vector\n\nAn initialization vector (IV) is a binary blob of random data used to initialize a sym-\nmetric encryption algorithm. The IV ensures that even if the same plaintext data is\nsent multiple times, it will encrypt to different ciphertext. The IV is initialized by the\nsender with random data and is fed to the encryption algorithm, The receiver initial-\nizes its decryption routine using the same [V. Each encryption algorithm defines a\nstandard IV length, with most symmetric algorithms using an IV of eight bytes. To\nminimize bandwidth at the expense of less security, an implementation can transmit\nsmaller [Vs. The example implementation uses four-byte IVs as the default. The\nremainder of the IV is set to the sequence number when it is used during the encryp-\ntion or decryption phase.\n\nPayload\nPayload refers to the original plaintext data. This data is encrypted in the packet that\n\nis sent over the wire.\n\nPadding is appended to the payload before encryption. Padding is used for two rea-\nsons. First, the encryption algorithm might require a certain block size. For instance,\nmany symmetric encryption algorithms use eight-byte blocks. Second, it might be\ndesirable to add a random amount of padding to hide the true size of the payload.\nPadding bytes are initialized with a series of integer values (starting at one) that can be\n\nverified by the receiver, providing an additional level of security.",
      "content_length": 2664,
      "extraction_method": "OCR"
    },
    {
      "page_number": 535,
      "chapter": null,
      "content": "550 Section 5 Network and Multiplayer\n\nPad Length\nThe pad length is a one-byte field chat stores the number of padding bytes in the\npacket.\n\nIntegrity Check Value\n\nThe integrity check value (ICV) is a truncated, hash-based message authentication\ncode (HMAC). An HMAC is a keyed hashing algorithm that uses a combination of a\nstandard cryptographic hash algorithm and a secret symmetric key [RFC2104]. Like\na thumbprint uniquely identifies a human being, an HMAC uniquely identifies a\nsecure packet. Truncating the HMAC is a well-known security practice. The example\nimplementation on the CD-ROM tuncates the hash to eight bytes by default.\n\nThe sender calculates the ICV by hashing the encrypted packet data using the\nauthentication key of the SA. The receiver performs the same calculation and com-\npares the ICV it computed with the ICV that was sent. If they match, the packet is\nvalid—it was sent by someone with a matching SA (authentic) and it was not modi-\nfied in transit (integrity intact). If not, the packet is bogus and is thrown away.\n\nae\n\nON THE CD\n\nSending Data\n\nSending data is a matter of encrypting the payload and generating a cryptographic\nhash of the data to be sent. The following sections describe the details used by the\nexample implementation.\n\nEstablishing a Security Assaciation\n\nPrior to sending secure data, the sender establishes a security association with the\nreceiver. Once the SAs and SPIs have been set up, each end of the communication\nlink has the data it needs to encrypt, decrypt, and authenticate traffic sent between\nthe two endpoints.\n\nBuilding the Header\n\nThe header includes the SPI, the sequence number, and the encryption IV. The SPI\ncorresponds to the SA used to encode and authenticate the payload. The current\nsequence number is also found in the SA. Once a sequence number has been used, it\nis incremented in the SA. The encryption IV is generated randomly. If the SA encryp-\ntion algorithm requires a larger TV than what is sent in the packet, the remaining\nbytes are set to the sequence number.\n\nGenerating Padding\n\nPadding is generated based on the size of the plaintext payload and the SA encryption\nalgorithm. Additional random padding might be added to hide the true size of the\npayload, The amount of random padding is configurable. The padding bytes are ini-\ntialized with a series of integer values, starting at one.",
      "content_length": 2375,
      "extraction_method": "OCR"
    },
    {
      "page_number": 536,
      "chapter": null,
      "content": "5.6 Secure Sockets ; 551\n\nEncrypting the Payload\n\nThe encrypted portion of the packet includes the original payload, the padding, and\nthe pad-length byte. The symmetric encryption is initialized with the IV generated\nabove, and the encrypted payload is generated using the SA symmetric encryption key\nand SA symmetric encryption algorithm. The resulting ciphertext is appended to the\nheader.\n\nGenerating the Authentication Code\n\nThe last step before sending the data is to generate the ICV. The HMAC algorithm is\ninitialized with the SA cryptographic hash algorithm and authentication key. The\nhash algorithm is then applied to the packet header and encrypted payload/padding.\nThe resulting hash value is appended to the ciphertext. The hash value is not\nencrypted.\n\nSending the Secure Packet\n\nThe secure buffer is now ready to be sent using whatever UDP socket mechanism the\ngame uses, typically send().\n\nReceiving Data\n\nOn the receiving end, the order of operations is critical for security and performance.\nThe receiver must validate the packet SPI, ICV, and sequence number. The receiver\nmay then decrypt the packet and validate padding. Only after all validation checks are\ncomplete can the receiver process the packet payload. If any validation check fails, the\npacket must be thrown away. If the receiver is a game server, the server might also\nwant to audit the failure event as a way of detecting and tracking cheaters.\n\nRecelving the Secure Packet\n\nThe secure packet is received using whatever UDP socket mechanism the game uses,\ntypically recv().\n\nValldating the Packet\nThe simplest check that can be made on the packet is validating the SPI. If the SPI\n\ndoes not match a security association in the receiver’s security association database,\nthe packet is deemed invalid. Assuming an SA match, a quick check is made on the\nsize of the block, based on the minimal amount of data that must be included in the\nsecure packet.\n\nThe next step is to validate the packet against the ICV. The HMAC algorithm is\ninitialized with the SA cryptographic hash algorithm and key. The hash algorithm\nis then applied to the packet header and encrypted payload. The resulting hash\nvalue is truncated and compared with the ICV received. If it matches, we have an\nauthentic packet.",
      "content_length": 2271,
      "extraction_method": "OCR"
    },
    {
      "page_number": 537,
      "chapter": null,
      "content": "552 Section 5 Network and Multiplayer\n\neeececae,\n\nThe last step prior to decrypting the packer is to check the sequence number. If\nthe packet is a replay or too ‘old,’ there’s no reason to decrypt it. The example imple-\nmentation uses a 64-bit sliding window to reject replay attacks and yet still allow\nout-of-order packets, which can occur with UDP. The ‘right’ edge of the window rep-\nresents the highest validated sequence number received on the SA. Packets that con-\ntain sequence numbers lower than the ‘left’ edge of the window are rejected (they're\ntoo old). Packets falling within the window are checked against the list of received\npackets. Ifa packet with a matching sequence number is received, it is a replay and is\nignored. New packets set the cortesponding bit in the window. Packets with a\nsequence number larger than the right edge cause the window to shift.\n\nDecrypting the Payload\n\nThe first step of decryption is to extract the IV. The IV is extended with the sequence\nnumber if necessary and then used to initialize the decryption algorithm. The payload\nand padding bytes are deciphered using the SA symmetric decryption key. The result-\ning plaintext includes the original payload, padding bytes, and padding size.\n\nValidating Padding\nThe padding size is validated to ensure that it’s reasonable. The padding bytes are then\n\nvalidated to ensure that they contain a series of integer values. Finally, all padding\ninformation is stripped from the plaintext, leaving the original payload.\n\nExample Implementation\n\nThe sample code on the CD-ROM, which is included with this gem, includes C++\nclasses that wrap cryptographic functions, security associations, and. secure buffers.\nTable 5.6.3 shows the list of classes provided.\n\nThe essential implementation details are contained in SecurityAssociation and\nSecureBuffer. The next section shows how the classes are used in a game for sending\nand receiving secure data.\n\nTable 5.6.3 Secure Socket Classes\n\nClass name Description\n\nCryptContext Win32 CryproAPl cryptographic service providers\nKey Cryptographic keys and algorithms\n\nCipher Encryption and decryption functions\n\nHash Hashing algorithms\n\nBuffer std::string<unsigned char>\nSecurityAssociation Security association data\n\nSADatabase std::map<Spitype, SecurityAssociation>\n\nSecureBuffer Functions for encrypting, decrypting, and authenticating payloads",
      "content_length": 2374,
      "extraction_method": "OCR"
    },
    {
      "page_number": 538,
      "chapter": null,
      "content": "5.6 Secure Sockets 553\n\nCreating a Security Association\n\nCreate a security association and add it to the security association database (SAD):\n\n// One-time association of SAD to SecureBuffers\nSADatabase sad;\nSecureBuffer: :SetSADatabase( &sad };\n\n// Generate random keys. This example uses the\n// DES cipher for encryption and MD5 for hashing\nKey keyAuth( CALG DES );\n\nKey keyCrypt( CALG_DES );\n\n// Create a new SA using the specified keys\n// and algorithms; other values get defaults\nSecurityAssociation sa{ keyAuth, keyCrypt, CALG_MD5 });\n\n/{ Generate a new SPI and add the pair to the db\nSpiType nSPI = sad,.GenNewSPI{);\nsad.Insert( nSPI, sa );\n\n// Securely exchange nSPI and keys with other end\nf/f of connection...\n\nSending a Secure Packet\n\nGenerate and send a secure packet:\n\n{/ Associate SecureBuffer with SA via SPI\nSecureBuffer sb( nSPI );\n\n// Generate the encrypted and authenticated buffer.\n// Encryption and hashing happens here.\nsb.Create( \"payload\", 7 };\n\n// Send the secure packet\nsend( sock, sb.GetDataPtr({), sb.GetSize(), 0 };\n\nReceiving a Secure Packet\n\nReceive and process a secure packer:\n\n{/ Receive the secure packet\n\nchar pData[ 1024 ];\n\nint nm = recv({ sock, pData, 1024, 6 );\n\nif( mn == 0 || n == SOCKET_ERROA )\nreturn false;\n\n// Validate the packet\n\nSecureBuffer sb({ pData, n );\n\nif{ Isb.IsAuthentic({) )\nreturn false;\n\n// Extract the original payload\nif( Isb.GetPayload{ pData, &n ) )",
      "content_length": 1412,
      "extraction_method": "OCR"
    },
    {
      "page_number": 539,
      "chapter": null,
      "content": "554 Section 5 Network and Multiplayer\n\nreturn false;\n\n// Adjust the replay window\nsb.SetAccepted({};\nreturn true;\n\nCryptoAPl\n\nThe cryptographic algorithms and key management use the Windows CryptoAPI, Alf\nof the crypto code is modularized into crypto.cpp so that you can replace the low-\nlevel crypto with other implementations (¢.g., Crypto++) [WeiDai01]. One of the\nfrustrating features of the CryptoAP! is that it doesn't provide direct access to key\ndata. There are no APIs that allow you to directly set or get a key. However, Microsoft\nKnowledgeBase article Q228786 [KB228786] discusses a method for directly access-\ning key data, and that method is used by the Key class.\n\nBecause of the way the CryptoAPI is designed—using cryptographic service\nproviders—not all potential algorithms or key lengths are available on all versions of\nWindows. Be sure to check the return codes for failure cases.\n\nPerformance\n\nThere are two major performance issues involved with using secure sockets. The first\nis additional bandwidth requirements. Using the default settings and an encryption\nalgorithm with eight-byte block requirement (e.g., DES), minimum packet overhead\nwith the sample implementation is:\n\n2 (SPI) + 4 (SeqNum) + 4 (IV) + 0-15 (Padding) + 1 (PadLen) + 10 (ICV) =\n21-36 bytes\n\nThose 21-36 bytes are in addition to the standard UDP packet overhead. You\ncan tweak the SA parameters to reduce the overhead, but only at the expense of secu-\nrity. To reduce the effects of the overhead, consider changing from small, frequent\npayloads to larger payloads sent less frequently. To avoid unnecessary padding, send\npayloads whose size+1 is evenly divisible by the block size of the SA cipher. (The +1\naccounts for the pad length byte.)\n\nThe second performance issue is encryption/decryption and authentication.\nTable 5.6.4 shows the costs of creating, authenticating, and decrypting one kilobyte\nof payload data, which indicates chat performance is not unreasonable. The most\nimportant factors at work here are the speed of the algorithms and the size of individ-\nual packets. Choose algorithms and key lengths that provide solid security at a rea-\nsonable performance cost.\n\nThese values were generated on a Pentium III, 866 MHz, running Windows\n2000, and using the default SA settings with DES encryption (64-bit keys) and MD5\nhashing. The “Create” column is the time in milliseconds required to repeatedly call\nSecureBuffer::Create on total payload data using the given payload size. The",
      "content_length": 2491,
      "extraction_method": "OCR"
    },
    {
      "page_number": 540,
      "chapter": null,
      "content": "5.6 Secure Sockets 555\n\nTable 5.6.4 Performance\n\nTime to process one kilobyte of payload data\nPayload Size (bytes) Create (ms) Authenticate (ms) Decrypt (ms}\n\ntee ere tevarvaneomranramarvarere NOHO ta rrarrarrerre eta Ee LT rg eiietasiaarammesrenran me remrerhrg;iAijarvaiininianaremnmey tema nzn\n\n64 2.07 0,90 1.07\n128 1.06 0.45 0.57\n256 0.59 0.24 0.34\n512 0.35 0.14 0.23\n1024 0.23 0.09 0.16\n\n“Authenticate” column shows the time spent in SecureBuffer : : IsAuthentic, and the\n“Decrypt” column shows the time in SecureBuffer;:GetPayload. Performance\nincreases as the payload size increases, since relative packet overhead decreases for\nlarger packets.\n\nSecurity\n\nThe intent of this gem is to present an implementation that strikes a balance between\nextremely robust security with huge packer overhead and reasonable security with\nminimal packet overhead. The quality of security provided is primarily dependent on\nthe strength of the algorithms used. Don’t use XOR as an encryption or authentica-\ntion algorithm and expect to have packets that are never cracked. Choose well-known,\nstandard algorithms with solid implementations, like DES, Triple-DES, Blowfish,\nand AES for encryption, MD5 and SHA-1 for hashing. Understand the security lev-\nels and performance trade-offs between the algorithms. Use large keys (128-bits)\nwhen they're supported by the algorithm. Change keys regularly. Don't reduce the IV\nsize to less than four bytes or the ICV size to less chan eight bytes, or security will be\nsubstantially diminished.\n\nAlthough it’s technically possible to turn off encryption and only use authentica-\ntion, be aware that an authenticated packet without encryption exposes your game to\nsniffing attacks, which can result in cheating that’s just as bad as spoofing attacks (and\nharder to detect).\n\nConclusion\n\nAs more games support features like tournaments and prize competitions, secure\ncommunication not only reduces cheating, but also becomes an essential requirement\nof the game. The IPSec specification includes security elements that can directly ben-\nefit networked games. Although the packet overhead is not insignificant, performance\nis good, and the benefits of secure traffic are considerable.",
      "content_length": 2211,
      "extraction_method": "OCR"
    },
    {
      "page_number": 541,
      "chapter": null,
      "content": "556 Section 5 Network and Multiplayer\n\nReferences\n\n[AESDraft] “The AES Cipher Algorithm and Its Use With IPSec,” draft available\nonline at http://www.ietf.org/10.html, November 2001.\n\n[Howard02] Howard, Michae! and David LeBlanc, Writing Secure Code, Microsoft\nPress, 2002.\n\n[IPSec2] “IP Encapsulating Security Payload (ESP),” updated draft available online at\nhetp://www.ietf.org/ID. html, November 2001.\n\n[Isensee0 1} Isensee, Pete, “Genuine Random Number Generation,” Game Program-\nming Gems 2, Charles River Media, Inc., 2001.\n\n[KB228786] “How to Export/Import Plain Text Session Key Using CryptoAPI,”\navailable online at hetp://support.microsoft.com; q228786, July 2001.\n\n[RFC1321] “The MD5 Message-Digest Algorithm,” available online at herp://\nwww.iecf.org/rfc/rfcl321.txt, April 1992.\n\n{RFC2104] “HMAC: Keyed-Hashing for Message Authentication,” available online\nat http://www. ietf.org/rfc/rfc2104.rxt, February 1997.\n\n[RFC2401] “Security Architecture for the Internet Protocol,” available online at\nhttp://www. ietf. org/rfc/rfc240 1.x, November 1998.\n\n[RFC2403] “The Use of HMAC-MD5-96 within ESP and AH,” available online at\nhetp://www.ierf.org/rfc/rfc2403.mt, November 1998.\n\n[RFC2404] “The Use of HMAC-SHA-1-96 within ESP and AH,” available online at\nhttp://www. iecf.org/rfc/rfc2404.txt, November 1998.\n\n{RFC2405] “The ESP DES-CBC Cipher Algorithm with Explicit IV,” available\nonline at http:/Awww.ietforg/rfc/rfc2405.ct, November 1998.\n\n[RFC2406] “IP Encapsulating Security Payload {ESP),” available online at http://\nwww.ietf.org/rfc/rfc2406.txt, November 1998.\n\n[RFC3174] “US Secure Hash Algorithm (SHAI),” available online at http://\nwow iethorg/rfc/ rfc3174.cxt, September 2001.\n\n[Schneier96] Schneier, Bruce, Applied Cryptography, Second Edition, John Wiley &\nSons, 1996.\n\n[Schneier99] Ferguson, Neils and Bruce Schneier, “A Cryptographic Evaluation of\n[PSec,” available online at http://www.counterpane.com/ipsec.huml, February\n1999.\n\n[WeiDai01] Dai, Wei, “Crypto++ Cryptographic Class Library,” available online at\nhetp://www.eskimo.com/~weidai/cryptlib.html, November 2001.",
      "content_length": 2097,
      "extraction_method": "OCR"
    },
    {
      "page_number": 542,
      "chapter": null,
      "content": "5.7\n\nON THE CD\n\nA Network Monitoring and\nSimulation Tool\n\nAndrew Kirmse, LucasArts\n\nEntertainment Company\nark@alum.mit.edu\n\nost online games are developed under ideal conditions on a high-bandwidth,\n\nlocal network with extremely low latency. In contrast, online games are typically\nplayed in low-bandwidth, high-latency environments with unpredictable network\nbehavior between machines. This gem describes a Windows-based simulation tool\ncalled “NetTool” that you can use to make a LAN behave more like the Internet.\nComplete source code and Win32 binaries are on the CD-ROM.\n\ninterface\n\nFigure 5.7.1 shows a picture of the Net Tool interface. The top section defines a set of\nfilters. Each filter describes the behavior of the network between two (IP address,\nport) pairs. TCP filters, being connection-oriented, allow communication in both\ndirections, so only one filter is required between any two hosts. UDP filters are one-\nway—the ‘Add reverse’ button will take the currently selected filter and create a new\none with the endpoints reversed. This is useful in the common case where the hosts\nuse the same port to send and receive data.\n\nNetTool simulates network latency on a per-packet basis according to a Gaussian\ndistribution. The interface allows you to set the mean and variance of each filter's\nlatency distribution.\n\nThere are several other controls available on each filter. Incoming packets are only\nforwarded when the Enabled box is checked, allowing you to selectively restrict traffic\nfrom individual hosts. Checking the Listed box causes incoming packets to be dis-\nplayed in the large list box on the lower right of the screen. The UDP Options set-\ntings apply only to UDP filters, and are described later.\n\nThe title bar displays all of the IP addresses assigned to the machine running Net-\nTool.",
      "content_length": 1818,
      "extraction_method": "OCR"
    },
    {
      "page_number": 543,
      "chapter": null,
      "content": "558 Section 5 Network and Multiplayer\n\n127.0.0.1:3999\n127.0.0 1:3393\n127.0.0.1:3989\n127.0,0.1:9999\n127.0.0.1:9999\n127.0.0.1:9999\n127.0.0.1:9959\n127.0.0.1:9999\n127.0.0.1:9999\n127.0.0.1:9989\n127.0.0.1:9999\n427.0.0.1:9999\n127.0.0.1:9999\n127.0.0,1:9999\n127. 0.0.1:9989\n127.0.0.1:9999\n127.00.1:9999\n127.0.0.1:9898\n127.0.0.4:9999\n127.0.0.1:9999\n127.0.0.1:3995\n127.0.0.1: 9999\n127.0.0.1:9999\n\n3\n3\na\n3\n3\n3\n3\n3\n3\n3\n3\n3\n3\n3\n3\n3\n3\n3\n3\n3\n3\n3\n9\n\nNetwork Monitoring\n\n192 1680.37777\n192.168.0.9:7777\n192.168.7777\n192.168.0777?\n192.468.0.27777\n192,168.0.5:7777\n192,168.03: 7777\n192.168.0.9; 7777\n192.188.0.3:7777\n192168.0.27777\n192. 368.0.3:7777\n192,168.0.3:7777\n192,.168.0.9:7777\n192,168.0.9:7777\n192.168.0.9:7777\n192168.0.%.7777\n\n. 192468.0.47777\n\n492,168.0.3:7777\n192,168.0.8:7777\n192.168.0.9:7777\n192 188 0.9:7777\n\nDelayed 1110 ms\nDelayed 1205 ms\nReordered\nDelayed 822 ms\nDuphested\nDelaped 10 ms\nReordered\nReordered\n\nAs packets arrive, NetTool dispatches them according to the settings of the filters thac\nthey match, If the Show packets box is checked, a summary of each packet is dis-\nplayed in the list box in the lower right on the interface. This shows the packet's\narrival time, payload size, incoming and outgoing addresses, and the action that was\ntaken by NetTool. The action will be one of the following:\n\n* Sent immediately: No extra latency is required for this packet, so it’s sent right\n\naway.\n\n* Delayed Xms: The network simulation requires that the packet be delayed before\nbeing forwarded. The amount of delay is a combination of the filter's latency set-\ntings and the host bandwidth simulation (to be addressed later in this section).\n\n* Dropped: The packet was not forwarded. This occurs only for UDP packets\n\nwhen the filter’s Packet Joss setting is nonzero.",
      "content_length": 1767,
      "extraction_method": "OCR"
    },
    {
      "page_number": 544,
      "chapter": null,
      "content": "5.7 A Network Monitoring and Simulation Tool 559\n\n* Reordered: The packet was sent before another packet that arrived previously.\nThis can only occur for UDP packets when the Reordering setting is nonzero.\n\n* Duplicated: The packet was sent twice. This occurs only for UDP packets when\nthe filter’s Duplication setting is nonzero.\n\n© Wair for connect: For a TCP filter, data arrived before the remote connection\ncompleted. It will be sent as soon as the connection succeeds.\n\nIf the Log to file box is checked, the same summary information will be logged to\nthe file log.txt.\n\nTCP Simulation\n\nTCP is a reliable, stream-based protocol: Data arrives in the order it was sent, in arbi-\ntrary-size chunks. NetTool appends all incoming data on a filter to a single queue. It\nthen polls the queue, forwarding as much data as the sender’s and receiver's band-\nwidth simulations will allow.\n\nSeveral subtleties arise in NetTool because of TCP’s connection-oriented nature.\nFor example, data can arrive from the sender before the connection to the receiver has\ncompleted, or the sender can shut down the connection before previously sent data\nhas been forwarded. These cases are accounted for and should be transparent to\napplications.\n\nUDP Simulation\n\nUDP is message-oriented, meaning that data arrives in the same chunks in which it\nwas sent. UDP is also unreliable, meaning that individual messages might be lost in\ntransit, arrive out of the order in which they were sent, or even arrive multiple times.\nOn a local network, UDP packets are almost never lost; but on the Internet, packet\nloss is common,\n\nNetTool drops packets with a probability given by the Packet loss box. These\npackets are simply thrown away, much like a router on the Internet might do under a\nheavy load.\n\nIf a packet is not dropped, it might be duplicated (sent twice) with a probability\nequal to that shown in the Duplication box. The latency model is applied to the two\nduplicate packets independently. If reordering is enabled, it’s possible that the dupli-\ncated packets will not arrive one after the other.\n\nPacket reordering will only occur under certain circumstances. Suppose two UDP\npackets, A and B, arrive on the same port. The latency simulation is applied to each\npacket independently, causing A and B to be scheduled for transmission. If, as a result,\nA is scheduled before B, no reordering will occur. However, if B is scheduled before A,\nNetTool will preserve this ordering with the probability given in the Reordering set-\nting. In order to force reordering to occur for testing purposes, it’s useful to introduce\nlatency with a high variance to make this second scenario more probable.",
      "content_length": 2671,
      "extraction_method": "OCR"
    },
    {
      "page_number": 545,
      "chapter": null,
      "content": "560 Section 5 Network and Multiplayer\n\nHost Bandwidth Simulation\n\nIn addition to latency arising from network delays, latency is also induced at the end-\npoints of a connection by the available bandwidth For example, on a 300-bps\nmodem connection, it takes an entire second just to send 30 bytes (assuming 8 bits\nper byte, plus a start bit and a stop bit). In the lower-left section of the interface, you\ncan set the bandwidth available at each host. The send and receive bandwidth can be\nset separately, as this is actually a common case with 56k modems (which can only\nupload at 33.6k), and with asymmetric DSL connections. Several predefined band-\nwidth settings are available on buttons below the bandwidth sliders; these values are\nonly approximate.\n\nThe Netfoo! bandwidth calculations take into account the size of the header\nattached to each packet. For UDP, this is 28 bytes (20 bytes IP header plus 8 bytes\nUDP header), though this can be reduced to a simulated 7 bytes if Uses PPP is\nchecked, as PPP compresses the IP header. For TCP, the header would normally be 40\nbytes, but most slow consumer connections use VJ header compression, which\nreduces the size to about 8 bytes. In addition, many modems have optional compres-\nsion, which can be simulated by setting a compression percentage in the lower-left\ncorner, This bandwidth simulation is somewhat simplistic, but it is sufficient to pro-\nduce the approximate behavior of a client connection.\n\nConclusion\n\nNetTool is a convenient way to simulate consumer Internet connections on a LAN. It\nis particularly useful for stress-testing under poor network conditions; an ideal use\nwould be testing an implementation of reliable communication on UDP. Please for-\nward any improvements you make to the author so that they can be shared with others.",
      "content_length": 1806,
      "extraction_method": "OCR"
    },
    {
      "page_number": 546,
      "chapter": null,
      "content": "Creating Multiplayer Games\nwith DirectPlay 8.1\n\nGabriel Rohweder,\n\nMicrosoft Corporation\ngrohwed@hotmail.com\n\ndding multiplayer functionality to a game can be a daunting task. Often, develop-\nrs will write their networking engines specifically to meet the needs of one title.\nPorting this code over to another title can be more of a headache than starting a new\none from scratch. DirectPlay helps provide solutions to these problems with a generic,\nextensible network-gaming API thar is both easy to use and easy to maintain. This gem\nis meant to explain some of the more-intricate details of using DirectPlay, as well as\noffer tips for avoiding common pitfalls. If you don’t have any experience with Direct-\nPlay, review the sample code in the DirectX SDK before reading this gem. DirectPlay\nsupports two types of networking architectures—client/server and peer-to-peer.\nAlthough there are many successful games on the market today that use the peer-to-\npeer architecture, this gem will focus mainly on the client/server architecture.\n\nInside DirectPlay\n\nTo reap the greatest rewards from DirectPlay, you should be familiar with how the\nAPI is constructed. DirectPlay consists of three separate layers: core layer, protocol\nlayer, and service provider layer.\n\nYour application will interact directly with the core layer, as seen in Figure 5.8.1.\nThe core layer is responsible for various tasks, such as initialization and maintaining\nthe player list. DirectPlay 8.1 utilizes a push model of information exchange. This\nmeans that your application will need to register a reentrant callback function with\nthe core layer, which will be called by the core layer when relevant messages are\nreceived from the protocol layer.\n\nThe protocol layer is responsible for the construction and interpretation of pack-\nets. DirectPlay adds 4 bytes to each packet—this is called the “packet header.” Direct-\nPlay is built on the UDP protocol, so these 4 bytes are in addition to the 28 bytes\nrequired for the UDP and IP headers. The header contains information that the\nreceiving side needs to know in order to process the packet correctly. This protocol is\n\n561",
      "content_length": 2146,
      "extraction_method": "OCR"
    },
    {
      "page_number": 547,
      "chapter": null,
      "content": "562 Section 5 Network and Multiplayer\n\nnad\n\nApplication\n\nFIGURE 5.6.1 The DirectPlay message flow.\n\nalso responsible for throttling data (which will be explained later) and verifying that\nincoming packets are formed correctly.\n\nThe service provider layer provides the transport for your session. It allows you to\nsupport many different methods of networking, such as TCP/IP, serial, and IPX.\n\nAnother element of DirectPlay that is worth mentioning here is DPNSVR.\nDPNSVFR is an optional service that maintains a list of all the current hosts on your\nmachine. Doing this helps to ensure that your application doesn’t try to host a session\non a conflicting port and allows your client applications to enumerate all of the avail-\nable sessions hosted on a particular machine by querying port 6073. DPNSVR sup-\nports only the IPX and IP service providers at this time.\n\nTransmitting Data\n\nIt was mentioned earlier that DirectPlay is a generic API. By ‘generic,’ it is meant that\nDirectPlay was not designed around a specific game genre. One of the most popular",
      "content_length": 1056,
      "extraction_method": "OCR"
    },
    {
      "page_number": 548,
      "chapter": null,
      "content": "5.8 Creating Multiplayer Games with DirectPlay 8.1 563\n\ntypes of games on the shelves today is the first-person shooter (FPS). The FPS gener-\nally requires very frequent transmission of smal! amounts of data. The fast action asso-\nciated with the FPS dictates the use of nonguaranteed messaging for most of your\ngame data. If a packet is lost on the wire, it could be irrelevant by the time it was suc-\ncessfully resent by the client. For this reason, most FPS network layers are built on\nUDP. UDP offers fast transmissions of data, with no guarantee that the packets will\natrive in the correct order or even arrive at all. There are times, however, when you\nwill want to make sure a packet gets to its intended recipient, and in the order sent.\nPlayer deaths and level changes are examples of when you would want to do this.\nDirectPlay will handle all of these scenarios for you, because it allows the programmer\nto specify if an individual packer is to be sent guaranteed, nonguaranteed, sequentially,\nor nonsequentially. A typical client-side send in DirectPlay is implemented as follows:\n\nMYMSG_OBJECT msgShoot;\nDPN_BUFFEA_DESC buffDesc;\nDPNHANDLE hAsync;\n\nmsgShoot .dwiype = MYMSGTYPE_SHOOT;\nbuffDesc.dwBufferSize = sizeof (MYMSG_OBJECT);\nbuffDesc,pBufferData = (BYTE*}&msgShoot;\npClient->Send(&buffDesc,1,0, NULL,&hAsync,0);\n\nBy default, DirectPlay sends messages nonguaranteed and sequential. The last\nparameter in the call to send()} is the dwFlags parameter. This parameter is used to\nspecify your send characteristics. For example, if you wanted to send your data guar-\nanteed and nonsequential, you would use the following call:\n\nDWORD dwFlags = DPNSEND_ GUARANTEED |\nDPNSEND_NONSEQUENTIAL;\npClient ->Send(&buffDesc,1,0,NULL, &hAsync , dwFlags) ;\n\nAfter a call to Send(} or SendTo{), your message is placed into the DirectPlay\ninternal send queue for that player. The reason for this is that DirectPlay throttles\ndata, a process whereby the protocol layer will increase or decrease the frequency of\nsends, depending on link conditions and how quickly the recipient can process them.\nThere is an associated send queue with every connection in a session, This ensures\nthat one slow connection will not affect the performance of all players in that session.\nIn order to increase performance in your application, it is important to process net-\nwork traffic as efficiently as possible. (See Reentrant Callbacks for tips on how to\nprocess data more effectively in your callback function.) You can check the status of\nyour send queue by calling GetSendqueueInfo(), as shown in the following code. The\nserver interface takes an additional parameter, specifying which player's send queue\ninformation to return.\n\nDWORD dwNumMsgs; //number of msgs in the send queue\n\nDWORD dwNumBytes; //number of bytes in the send queue\npClient ->GetSendQuevelInfo(&dwNumMsgs, &dwNumBytes, 0};",
      "content_length": 2878,
      "extraction_method": "OCR"
    },
    {
      "page_number": 549,
      "chapter": null,
      "content": "564 Section 5 Network and Multiplayer\n\nSone me mr Amman aA an re DER UR mero LEERY mre meh SRI ear RMN eRe SRS aaa aumrm OMe nneetORRRSSAnmrmn\n\nA message will remain in the send queue until it is either sent or a timeout occurs.\nAtimeout value can be associated with each message, dictating the maximum amount\nof time that the message should be allowed to remain queued. If the message will\nbecome invalid after a certain amount of time, as was discussed earlier, it would be\nwise to specify a timeout value for that message. The following code specifies a time-\n\nout value of 30 ms:\n\nOWORD dwTimeOut = 30; //time in milliseconds\npClient->Send{&buffDesc, 1, dwlimeOut, NULL, &hAsync,0};\n\nIf you notice that your send queue is growing too large, there are two possibilities\nto consider. One possibility is that you are blocking the receive threads on the\nreceiver, prohibiting DirectPlay from processing incoming messages. The other possi-\nbility is that you are sending data more quickly than the receiver can process it, caus-\ning dropped packets. If your message queue is growing too large, but the number of\nbytes queued is relatively small, try coalescing your data. Coalescence means combin-\ning two or more messages into one larger message. DirectPlay will not do this for you\nbecause it is a generic API, and as such has no idea how to logically group your data.\nOne thing to be wary of when grouping your data is mixing message types. For\ninstance, you probably wouldn't want to combine a message telling the server that a\nplayer is now invisible, with a message saying that the player has fired a railgun. If you\nsend the message nonguaranteed, then you run the risk of losing the invisibility mes-\nsage, because the packet might be dropped and not resent. On the other hand, if you\nsend the message guaranteed, the player might start sporadically firing their railgun at\nan inopportune moment.\n\nOnce a message is received, the recipient sends back an ACK to the sender An\nACK is a special message telling the sender that the recipient received the message. If\nno ACK is received by the sender for a particular packet, then it is considered unde-\nlivered. The difference between a guaranteed send and a nonguaranteed send is how\nthe sender will handle an undelivered packet. With a nonguaranteed message, the\nsender will simply continue sending data from the message queue, ignoring the\ndropped packet. With a guaranteed message, the sender will retry sending the dropped\npacket until it is received, or until a timeout occurs. It is important to note here that\nthis timeout value is different from the one mentioned earlier, When a guaranteed\nmessage times out in this manner, DirectPlay determines that the connection has\nbeen Jost, and issues DPN_MSGID_TERMINATE_SESSION and DPN_MSGID_DESTROY_PLAYER\nmessages as appropriate. In DirectPlay, an ACK rides piggyback on a normal data\npacket to maximize throughput. In the event that there are no data packets to piggy-\nback, DirectPlay will create a special ACK packet and attempt to deliver it to the\nsender, Although it is optimized for bidirectional traffic, the frequency at which\nDirectPlay will create these special ACK packets is high enough (around 100 ms) to\navoid causing throttling issues on the sender in the event that your data stream is uni-\ndirectional.",
      "content_length": 3327,
      "extraction_method": "OCR"
    },
    {
      "page_number": 550,
      "chapter": null,
      "content": "5.8 Creating Multiplayer Games with DirectPtay 8.1 665\n\nOne other popular type of game today is the massively multiplayer, online role-\nplaying game (MMORPG). While this genre of game shares some similarities with\nthe FPS networking model, there are many differences. An MMORPG tends to cater\nto thousands of players, simultaneously interacting in an expansive virtual environ-\nment. Current implementations of this model tend not to send network traffic for\nevery key press a player makes; instead, it sends state information across the wire. If\nyouve ever played an MMORPG, you will probably have noticed that while engaged\nin combat, the results are not governed by your keyboard or mouse dexterity as they\nare in an FPS, but rather by your character's attributes and abilities. You send a mes-\nsage to the server that you are entering combat mode and what your current target\nis—the server handles the rest. State information can also be used to communicate\nother data to the server, such as movement. When sending this kind of information\nacross the wire, you want your messages to be guaranteed. If the player's client is\ntelling them that they are in combat mode and fighting a mountain troll, but the\nserver is recognizing them as standing idle while being beaten to a pulp by a mountain\ntroll, you will have some angry players. Managing thousands of simultaneous connec-\ntions is another big issue with the MMORPG. DirectPlay scales well when properly\nimplemented and offers the programmer some handy tricks to help things go\nsmoothly. One such trick is grouping.\n\nGrouping allows the application developer to perform fewer sends, because they can\ntransmit to a group of players, rather than transmitting the same data to all of them\nseparately. In the MMORPG, the landscape is usually broken into zones or sectors.\nThis is an excellent way to group players. You can create a group of all the players in a\ncertain sector and send out your data to that one group. There is an overhead to\nadding and deleting players from groups, so you must be careful how you partition\nthem. In an FPS, it probably would not be beneficial to group players geographically.\nDue to the size of the average FPS map, a player could be switching from one sector\nto another every few seconds. Instead, you could use teams or some similar method to\ngroup players. The following code shows how to create a group in DirectPlay:\n\nDPN_GROUP_INFO dpnGrpInfo;\n\nDPNHANDLE hAsync;\n\nZeroMemory{&dpnGrpInfo, sizeof (DPN_GROUP_INFO)) ;\ndpnGrpInfo.dwSize = sizeof ({DPN_GROUP_INFO) ;\ndpnGrpinfo.dwiInfoFlags = DPNINFO_NAME;\n\nwescpy (dpnGrpInfo.pwszName, \"ThievesGuild\"};\n\npServer ->CreateGroup (&dpnGrpInfo, NULL ,NULL&hAsync , 0) ;\n\nOnce this code has been executed, your server interface’s callback function will be\ninvoked with a message of type DPN_MSGID_CREATE_GROUP, containing a DPNID. A\nDPNID is a unique identifier assigned to each player or group in a session. Once the\nDPN_MSGID_CREATE_GROUP message is received, it is safe to start adding players to the",
      "content_length": 3037,
      "extraction_method": "OCR"
    },
    {
      "page_number": 551,
      "chapter": null,
      "content": "566\n\nSection 5 Network and Multiplayer\n\ngroup. To send a message to the group, you would need to supply the returned\nDPNID to the SendTo({) method of the server interface. You can also send a message\nto all players in your session by setting the DPNID_ALL_PLAYERS_GROUP constant in\nplace of the DPNID.\n\nWhen you send a message, DirectPlay creates an internal copy of that message.\nThis copying process carries an overhead. To optimize performance, there is a\nDPNSEND_NOCOPY flag that you can specify in your call to Send() or SendTo() that will\nprevent DirectPlay from making that internal copy. The down side to this is that the\nbuffer being sent must remain valid until the send completes. If you allocate your\nmessage on the local stack, you should not use asynchronous Send({) operations\nbecause the memory containing your message will go out of scope when your func-\ntion returns. Instead, allocate the buffer from the heap, and free it when the asyn-\nchronous send completes. For best results, you should use a pool of buffers to avoid\nthe cost of allocating and freeing each message. Sending a message synchronously will\nnot encounter this condition, since the Send() call will not return until the message\nhas been sent.\n\nReentrant Callbacks\n\nOne of the hardest issues to tackle in any application is multithreading. This is not\nonly because it can be tricky to program, but because it can be tricky to debug as well.\nLikewise, multithreading issues tend to be one of the biggest problems faced by devel-\nopers because DirectPlay relies heavily on reentrant callback functions. You must be\ncareful when writing your code, as an unexpected context switch could crash your\napplication. When designing your data structures, such as linked lists, keep in mind\nthat they could be accessed by two separate threads. Add reference counters to them\nto avoid resource conflicts. Use critical sections whenever accessing a global variable\nor other shared resource in your callback function. Besides the obvious need to avoid\ndeadlocks, be aware that waiting for locks or performing other lengthy operations in\nyour callback function prevents DirectPlay from using that thread to process other\ndata. This might cause the sender to throttle back, artificially limiting your through-\nput.\n\nOne way to avoid holding DirectPlay threads is to queue up your incoming mes-\nsages, and have a separate thread process them, thus freeing up the DirectPlay threads\nto do more work. Returning DPNSUCCESS_PENDING from the DPN_MSGID_RECEIVE mes-\nsage event will allow you to avoid the overhead of copying the buffer to your queue\nbecause DirectPlay will temporarily hand ownership of this buffer over to your appli-\ncation. If you choose to do this, you must call ReturnBuffer() when you are finished\nprocessing the message so that DirectPlay can free those resources.\n\ncase DPN_MSGID_ RECEIVE:\n\nPDPNMSG_ RECEIVE pRevMsg;\npAcvMsg = (PDPNMSG_RECEIVE)pMessage;",
      "content_length": 2939,
      "extraction_method": "OCR"
    },
    {
      "page_number": 552,
      "chapter": null,
      "content": "5.8 Creating Multiplayer Games with DirectPlay 8.1 567\n\n//lock the queue to avoid race condition\n\nLockMyQueus{);\n\n//pass the hBufferHandle to the queue because\n\n/fyou will need that in your\n\n//call to ReturnBuffer()\n\nAddToMyQueue ( pRevMsg->pReceiveData,\npRevMsg->hButferHandle );\n\nUnlockMyGQueue {} ;\n\nreturn OPNSUCCESS PENDING;\n\n}\nOnce the queue has processed the message, make the call to ReturnBuffer():\n\npClient->ReturnBuffer (hBufferHandle , 0) ;\n\nIf your application needs to scale to a larger number of connections, a single\nqueue could hamper your performance. In this case, you might wish to devise a more\nsophisticated way of offloading message processing from your callback function.\n\nAsa side note, it is not always a bad thing to hold DirectPlay receive threads. It is\npossible that the network is able to handle more data than a CPU-bound receiver can\nprocess. If the receiver continues to queue these messages, the queue will grow with-\nout bounds. One solution is to queue received data until a limit is reached, and then\nbegin blocking new DPN_MSGID_RECEIVE callbacks. If and when all threads are blocked,\nthe senders will be forced to ‘back off.’\n\nDirectPlay lets you specify the size of your thread pool by calling setspPcaps(). By\ndefault, DirectPlay spins up 2” + 2 threads, where » is the number of processors in your\nsystem. If your CPU is not being utilized to its fullest and message queues are starting\nto back up, you could consider increasing your threadpooi size. Most likely, many of\nyour threads are busy waiting for disk I/O or critical sections. Therefore, you won't\ncause the CPU to thrash if you spin up more threads to handle DirectPlay messages.\nOn the other hand, if your application seems to be CPU bound, then you might want\nto decrease the number of threads DirectPlay can use. When setting the number of\nthreads in your DirectPlay application, remember that the threadpool can only be\nincreased, not decreased, once a call to Host(}, Connect(), or EnumHosts() is made.\nPrior to these function calls, the threadpool can be set to whatever size you deem\nappropriate. The threadpool is shared among all interfaces in a process. You can\nretrieve the thread count available by DirectPlay to process incoming messages by\ncalling GetSPCaps().\n\nDPN_SP_CAPS dpnCaps;\npClient ->GetSPCaps{&CLSID_DP&SP_TCPIP, &dpnCaps ,Q) ;\ng@pnCaps.dwSize = sizeof (DPN_SP_CAPS};\nif (dpnCaps.dwNumThreads < 16)\ndpnCaps.dwNumThreads = 16;\n\n}\npClient->SetSPCaps (&CLSID_DPSSP_TCPIP, &dpnCaps ,0) ;",
      "content_length": 2511,
      "extraction_method": "OCR"
    },
    {
      "page_number": 553,
      "chapter": null,
      "content": "Section 5 Network and Multiplayer\n\nRefer back to Figure 5.8.1. When a message arrives, the service provider directly\ninvokes the protocol layer, the protocol layer invokes the core, and the core invokes\nyour callback function, all in the same thread from the service provider. This reduces\nthe amount of context-switching between the time a message is received on the wire\nand when it is passed to your application.\n\nDirectPlay gives you a few tools to help you with multithreading and perfor-\nmance issues in your callback function, one of them being the context value. A user\ncontext is a value that you pass to DirectPlay, and DirectPlay will pass that value back\nto you in related calls to your callback function. Why is this helpful? Imagine that you\nhave an application with two client interfaces, one for data and one for voice (as you'll\nsee later in this gem, a DirectPlay voice connection requires a DirectPlay client or peer\ninterface). Although you have two client interfaces, you might only want to code one\ncallback function for them both, When the core layer calls into your callback func-\ntion, you have no idea which interface the new message belongs to. Specifying a user\ncontext value in the call to Initialize() allows you to determine for which client\nobject the newly arrived message is relevant. A context value can also be associated\nwith every player in the sesston. This player context value can play a large part in opti-\nmizing the time you spend inside of your callback function. When a client connects\nto a session, you can associate its context value during the DPNMSG_INDICATE_CONNECT\not DPNMSG_CREATE_PLAYER messages. All subsequent messages arriving from that client\nwill contain a pointer to the relevant player. Notice in the following code that once a\nplayer joins the session, its context value is set. Later, when a message is received from\nthat same player implying that it now has a damage modifier, the server can use the\nplayer context as an index into the player list. This quickly adds up to a lot of saved\nprocessing time.\n\nHAESULT WINAPI DPClientMsgProc(PVOID pvUserContext,\n\nDWORD dwMessageType,\nPYOID pMessage}\n\nHRESULT hr = S_OK;\nswitch(dwMessageType)\n{\ncase DPN_MSGID_CREATE_PLAYER:\n{\n//add player to your list and\n//set their user context value\nPDPNMSG_CREATE_PLAYER pMsg;\npMsg = (PDPNMSG_CREATE_PLAYER)pMessage;\nMYPLAYER mpPlayer;\nmpPlayer.dpnid = pMsg->dpnidPlayer;\nLockMyPlayerList{)} ;\npAddress = AddPlayarToList (&mpPlayer) ;\nUnlockMyPlayerList ();\npMsg->pVUserContext = pAddress;\nbreak;\n}\ncase DPN_MSGID_RECEIVE:",
      "content_length": 2570,
      "extraction_method": "OCR"
    },
    {
      "page_number": 554,
      "chapter": null,
      "content": "5.8 Creating Multiplayer Games with DirectPlay 3.1 569\n\nPDPNMSG_RECEIVE pRevMsg;\npRevMsg = (PDPNMSG_RECEIVE) pMessage;\nMYPLAYER * pPlayer = NULL;\nLockMyPlayerList{);\npPlayer = GetPlayerFromlist (\npRevMsg->pvPlayerContext };\nif({pPlayer == NULL)\n{\nhr = OPNERR_GENERIC;\nUnlockMyPlayerList (};\nbreak;\n\n}\n\nMYMSGTYPE * pMsg = NULL;\npMsg = (MYMSGTYPE*}\npRcevMsg-> pReceiveData;\nswitch( p¥sg->dwType }\n\n{\ncase MYMSG_QUADDAMAGE:\n\n{\npPlayer->DamageFactor *= 4;\nbreak;\n\n}\n\n}\nUnlockMyPlayerList();\nbreak ;\n}\n}\nreturn hr;\n}\n\nAnother benefit that DirectPlay provides you is the serialization of callbacks. Seri-\nalization means that you are guaranteed that any two messages involving a particular\nplayer will not be handled on separate threads at the same time. A good example here\nwould be a server receiving a message from a client to join a session. Immediately after\njoining the session, however, the client decides to disconnect. If a DPN_MSGID_\nDESTROY_PLAYER message were to arrive before the server has had time to complete its\nplayer initialization code, the server could be left trying to access an invalid object in\nits player list. The DirectPlay callback serialization guarantees us that this will never\nhappen.\n\nSending Voice with DirectPlay\n\nWhether it is to discuss tactics, taunt your enemies, or just chat with a friend, com-\nmunication is an important part of any multiplayer game. Unfortunately, text-based\nchat interfaces can be distracting when you are trying to play a game, and canned\naudio can become monotonous after you've heard the same words repeated for the\nhundredth time. Luckily, there is another option. If you're using DirectPlay for your\nnetworking layer, you can easily add voice communications to your game, and it only\n\ntakes a little extra work.",
      "content_length": 1772,
      "extraction_method": "OCR"
    },
    {
      "page_number": 555,
      "chapter": null,
      "content": "570 Section 5 Network and Multiplayer\n\nThe DirectPlayVoice interface allows you to send voice data over your network\nconnection, using a DirectPlayClient or DirectPlayPeer connection as a transport.\nYou will need to register a callback function in your call to Initialize(), just as you\ndid for your client interface. Assuming that you already have your client/server\nDirectPlay session setup for your voice data to use as a transport session, getting\nDirectPlay Voice up and running is simple. The following code is all you need to get a\nVoice server to host a session:\n\n/ipServer is your iDirectPlay8Server interface pointer\n\n//and must be currently hosting a session\npVoiceSrvr ->Initialize({pServer, SrvrProc, NULL, NULL, 0};\n\nDVSESSIONDESC dvSesDesc;\nZeroMemory (&dvSesDesc, sizeof (DVSESSIONDESC) ) ;\n\ndvSesDesc.dwSize = sizeof (DVSESSIONDESC) ;\ndvSesDesc.dwFlags = DVSESSION_NOHOSTMIGRATION;\nif (fMixingServer == TAUE)\n\n{\n\ndvSesDesc.dwSessionType\nDVSESSIONTYPE_MIXING;\n\nelse {/Forwarding server\n\ndvSesDesc .dwSessionType\nDVSESSIONTYPE_FORWARDING;\n}\n//this value must be retrieved by a call to\n// GetCompressionTypes()\ndvSesDesc,guidCT = MyCodecGuid;\ndvSesDesc. dwBufferQuality =\nDVBUFFERQUAL ITY_DEFAULT ;\ndvSesDesc .dwBufferAggressivensss =\nDVBUFFERAGGRESSIVENESS DEFAULT;\npVoiceSrvr ->StartSession(&dvSesPesc, 0);\n\nInitializing and connecting a voice client to a hosting session is similarly easy. The\nfollowing code will initialize, connect, and set transmit targets for your voice client:\n\n/fpClient is your IDirectPlay8Client interface pointer\nf/and must currently be joined to a session\npVoiceClient->Initialize(pClient , VoiceProc ,NULL,0,0) ;\nDVCLIENTGONFIG dvClientConfig;\nZeroMemory (&dvGlientConfig, sizeof (DVCLIENTCONFIG }};\ndvClientConfig.dwSize = sizeof (DVCLIENTCONFIG );\ndvClientConfig.dwFlags =\nDYCLIENTCONFIG_AUTOVOICEACTIVATED |\nOVCLIENTCONFIG_AUTORECORDVOLUME ;\névClientConfig.1PlaybackVolume =\nDVPLAYBACKVOLUME_DEFAULT;\ndvClientConfig. dwBufferdguality\nBYBUFFERQUALITY_DEFAULT;",
      "content_length": 2006,
      "extraction_method": "OCR"
    },
    {
      "page_number": 556,
      "chapter": null,
      "content": "6.8 Creating Multiplayer Games with DirectPtay 8.1 571\n\ndvGlientContig.dwaufferAggressiveness =\nDVBUFFERAGGRESSIVENESS DEFAULT;\n\ndvGlientGonfig .dwThreshold = DVTHRESHOLD_UNUSED;\n\ndvClientConfig.1lRecordVolume = DVAECORDVOLUME_LAST;\n\nOVSOUNDDEVICECONFIG dvSDConfig;\n\nZeroMencry (&dvS0Config, sizeof (DVSOUNDDEVICECONFIG) );\n\ndvSbContig.dwSize = sizeof (DVSOQUNDDEVICECONFIG);\n\ndvSDContig.guidPlaybackDevice =\nDSDEVID_BDefaultVoicePlayback;\n\ndvSDConfig.guidCaptureDevice =\nDSDEVID_DefaultVoiceCapture;\n\ndvSDConfig .hwndAppWindow = hDl1g;\n\np¥oiceClient ->Connect (&dvSO0Config, &dvGlientConfig,0};\n\nDVID dvid = DVID_ALLPLAYERS;\n\np¥oiceCGlient->SetTransmitTargets(advid, 1, 9);\n\nDirectPlay Voice manipulates audio using DirectSound, allowing the developer to\ndo effects processing, such as voice warping or lip synching, on the receiving end of an\naudio stream. DirectPlay Voice also supports 3D positional audio, which can greatly\nenhance the realism of voice transmissions in 3D games.\n\nDirectPlay Voice can be set up in one of three different configurations:\n\n* A peer-to-peer configuration allows all players to send their voice data directly to\ntheir intended target. The advantage to this is that a dedicated server is not\nneeded to process the voice data. This method is great for games with a limited\namount of players, but it does not scale well at all.\n\n* A forwarding configuration sends the voice data to a central server, where it is for-\nwarded to the receiving players. With this configuration, a client only needs to\nsend one voice message out with a list of intended recipients, cutting down band-\nwidth requirements. Bandwidth requirements on the server, however, are much\nhigher, as it must send out several voice messages to different players.\n\n¢ The third configuration is the mixing server. This is the best choice if you have a\ndedicated piece of hardware available to perform mixing operations on incoming\nvoice data. A mixing server, like the forwarding server, allows clients to send one\nvoice stream out with a list of intended recipients; but where they differ is that a\nmixing server will combine all of the audio destined for one target together and\nsend it out as a single audio stream. This reduces the bandwidth requirements on\nthe client and server, but it requires more processing power.\n\nIf you want to use a peer-to-peer configuration with your voice data, you must\nhave a peer-to-peer DirectPlay session hosted. However, it is not required that it be\nthe same session that you are using to transport game data. Thus, Figure 5.8.2 shows\ntwo valid networking models for a client/server game with voice: one with a peer-to-\npeer voice configuration and the other with a separate voice-forwarding or voice-\nmixing configuration.",
      "content_length": 2759,
      "extraction_method": "OCR"
    },
    {
      "page_number": 557,
      "chapter": null,
      "content": "572 ion 5 Network and Multiplayer\n\nx\n\nGame Server\n\nGame Server Voice Server\n\n———s\n\n=\n\nFIGURE 5.8.2 Left: Peer-to-peer voice configuration. Right: Client/Server voice\nconfiguration.\n\nResources\n\nIf you are having trouble with some aspect of DirectPlay, there’s a likely chance that\nsomeone else has, too, There are many resources on the Internet that can provide help\nwith your DirectPlay networking layer, most notably the Web networking news-\ngroups at microsoft. public.directx.networking and microsoft.public.win32.program-\nmer.directx.networking. These newsgroups are frequently monitored by members of\nthe DirectPlay team and experienced users of the API, and can be an invaluable\nresource during the development of your game.",
      "content_length": 730,
      "extraction_method": "OCR"
    },
    {
      "page_number": 558,
      "chapter": null,
      "content": "Wireless Gaming Using the\nJava Micro Edition\n\nDavid Fox, Next Game\ndavidfox@ureach.com\n\nn an era of supercharged consoles, photo-realistic monsters, and rich 3D universes,\n\nwriting games for a wireless device can feel lackluster. The screen is miniscule—less\nthan 100 X 100 on most mobile phones. You have little dynamic memory to play\naround with—only a 32-KB heap on many phones. And there’s limited network con-\nnectivity; most second-generation wireless networks send data at 9.6 kbps (kilobits\nper second). The processors on wireless devices are also hundreds of times slower than\nan average desktop computer.\n\nOn the plus side, i’s becoming harder to find people who don't carry network-\nenabled devices with them. At the end of 2001, there were more than 600 million\nmobile phone users worldwide. If a compelling wireless game caught fire, it would\nfind a massive audience.\n\nWhile it might seem silly to try to achieve a rich, meaningful immersion on a tiny\nscreen, there's one thing mobile phone games offer chat even the best consoles can't\nprovide: They're always with you and can be played anywhere you go. Furthermore,\nmany wireless networks implement some form of mobile positioning. As this feature\nbecomes more accessible, a game can track exactly where a player is in the real world.\nWireless games are not only portable and convenient to play, but with some clever\ndesign, wholly new types of experiences can seamlessly meld virtual space with reality.\n\nAnother burgeoning field is in creating wireless extensions to existing games. For\nexample, a mobile interface can tap into a persistent multiplayer game world that is\nusually played in full visual splendor on a console. A mobile gamer could be instantly\nnotified of attacks and surreptitiously logon during meetings to tweak settings or\nmake important decisions.\n\nThe difficulty lies in achieving meaningful network interaction given extreme\nlimitations.\n\nNetwork Characteristics\n\nLatency is the time it takes for a packet of data to travel from one point to another,\nand is usually based on distance and number of hops between the two points.\n\n573",
      "content_length": 2120,
      "extraction_method": "OCR"
    },
    {
      "page_number": 559,
      "chapter": null,
      "content": "574\n\n_ | $eetion 5 Network and Multiplayer\n\n|\nBandwidth is the amount of data that can be sent per second, and is usually based on\nthe physical hardware being used to transfer data.\n\nMultiplayer game programmers struggle with the Internet's high latency and the\naverage home user's low bandwidth. Second-generation (2G) wireless networks, how-\never, make the Internet seem downright speedy.\n\nEuropean mobile phones primarily operate on the Global System for Mobile\nCommunication (GSM), which sends data at 9.6 kbps. Most networks in North and\nSouth America, Russia, Israel, Eastern Asia, and Centra! Africa transfer data based on\na standard called Code Division Multiple Access (CDMA), which runs at a peppier\n14.4 kbps. Some networks tise Time Division Multiple Access (TDMA), which is\nsimilar to GSM and has the same 9.6-kbps limit,\n\nProviders in Japan, Hong Kong, South Korea, and Singapore use what can be\nthought of as a 2.5-generation (2.5G) network. This is achieved using a vatiant of\nCDMA (IS-95B), which achieves a 64-kbps data transfer rate. In the United States,\nCDMA 2000 has been deployed in select markets, eventually hoping to offer speeds\nof up to 144 kbps. Furthermore, most GSM networks are being upgraded to use Gen-\neral Packet Radio Services (GPRS), which can theoretically reach speeds of 170 kbps.\n\nThird-generation (3G) networks are slowly being rolled out. Most 3G standards\nare built on top of Internet Protocol (IP) services, allowing for high-speed mobile\naccess. The plan is for networks to scale up gradually, starting with 2.5G technologies\nand ramping up to speeds of around 300 kbps, and finally reaching 2400 kbps (2.4\nMbps), which is even faster than today’s home DSL connections. Deployment of 3G,\nhowever, is extremely expensive and fraught with all sorts of challenges. We should\nnot expect to see widespread 3G networks anytime soon.\n\nWide area wireless networks are also high latency because of the inherent inter-\nference and noise of radio wave communications. Most wireless networks force data\npackets to hop over many high-latency routers. Satellite-based wireless networks gen-\nerally add even more latency. It is not rare to experience network delays of one or even\ntwo seconds.\n\nFor the time being, then, wireless game designers should assume that they are\nworking with a thoroughly high-latency, low-bandwidth connection.\n\nJava Micro Edition\n\nJava (Sun Microsystems) is emerging as a standard language for wireless devices. Java\nruns in a virtual machine, which means that as long as developers follow the right pro-\ncedures, the same Java byte code can run on any supporting platform. Java is also\nextremely easy to use. It is object-oriented with no pointers, no complicated memory\noperations, and automatic garbage collection. Most importantly, Java applets cannot\naccess functions or memory outside of their secure ‘sandbox,’ which means that it is\nvirtually impossible to write malicious code or viruses.\n\nJava 2 Micro Edition (J2ME) [{J2ME01) is an attempt to take the best aspects of\nstandard Java and pare them down for smaller devices, such as mobile phones, pagers,",
      "content_length": 3124,
      "extraction_method": "OCR"
    },
    {
      "page_number": 560,
      "chapter": null,
      "content": "5.9 Wireless Gaming Using the Java Micro Edition 575\n\nand handheld organizers. Most major mobile phone manufacturers have joined with\nSun to create the CLDC (Connected, Limited Device Configuration} [CLDC01],\nalong with the MIDP (Mobile Information Device Profile) [MIDP01]. A Java applet\nwritten for a mobile phone, therefore, is called a “MIDlet.”\n\nVarious device manufacturers have released extension APIs for J2ME. For exam-\nple, Siemens has an extensive game API that sits atop MIDP. NTT DoCoMo does\nnot use MIDP, but has a separate Java profile known as “I-Appli.”\n\nQualcomm has created a virtual machine and language called the Binary Run-\ntime Environment for Wireless (BREW), which is based on C++. Qualcomm has\nembedded BREW right onto the chipset for CDMA phones. While BREW is a J2ME\ncompetitor in some sense, a Java Virtual Machine can be written in BREW.\n\nMobile phone manufacturers have embraced Java in a way that not even PC man-\nufacturers have. Java is emerging as the platform of choice for mobile devices.\n\nJ2ME Networking Nutshell\n\nIn the world of Java Standard Edition, the large and intricate java.io.* and\njava.net .* packages are used to great effect. These packages contain most any type of\nnetworking class you want, such as Socket, DatagramSocket or ServerSocket. Each\nclass has different methods and different ways of being used.\n\nIn the world of J2ME, however, we don’t have the luxury of being so complete.\nFor starters, we have no idea what type of network transport protocol a phone is\nusing. Devices that work over circuit-switched networks can use streaming always-on\nconnections, such as the Transport Control Protocol (TCP). However, packet-\nswitched networks might only be able to handle its network data in discrete, nonguar-\nanteed packets using a protocol such as the User Datagram Protocol (UDP).\n\nThe CLDC’s Connection interface was created to be as general as possible. The\nConnection class is a catch-all that can, in theory, handle any kind of network con-\nnection. A special class known as the “Connector* can tap into any CLDC class that\nextends from the Connection interface.\n\nEvery Cennector’s open method accepts a string with the familiar syntax:\n“protocol:address: parameters”. For example, to open a typical HTTP connection:\n\nConnector .open{ “http: //java.sun.com/developer\");\nTo open a socket:\n\nConnector. open( \"socket: //123.123.111.000:9000\"} ;\nAnd to open a datagram connection:\n\nConnector.open(\"datagram: / /waw.myserver.com:9000\");\nYou can then create a datagram and send it as follows:\n\nDatagram dgram = dc.newDatagram({message, msglength,",
      "content_length": 2603,
      "extraction_method": "OCR"
    },
    {
      "page_number": 561,
      "chapter": null,
      "content": "576 Section 5 Network and Multiplayer\n“datagram: / /waw.myserver .com:;9000\") ;\ndc.send(dgram) ;\ndc.close();\n\nThe remote ‘server’ could, of course, be another mobile device. Most wireless\ndevices can easily communicate in a peer-to-peer fashion with each other. Peer-to-\npeer latencies ate lower—there’s no need to use a middleman. However, in peer-\nto-peer games, one of the peers generally acts as a server, and the other acts as a client.\nThe size of this extra server code could make such a scheme infeasible. To have a\nMiDlet deal with incoming traffic, just create an endless loop that listens to a port\nand waits for some data:\n\nDatagramConnection dc = (DatagramConnection) Connector. open\n(\"datagram: //:\"+receiveport} ;\nwhile (true)\ndgram = dc.newDatagram(dc.getMaximumLength{));\ndc. receive (dgram} ;\nreply = new String(dgram.getData(), 0,\ndgram.getLength());\n}\n\nSince the Datagram protocol is standard, we could write an extremely simple\nserver component in Java Standard Edition (or any other language), running on any\nPC. For instance:\n\nDatagramSocket receiveSocket = null;\n\nDatagramPacket receivePacket = new DatagramPacket (bytesReceived,\nbytesReceived. length};\n\nreceiveSocket .receive(receivePacket};\n\nAs you can see, the MIDP specification makes it extremely easy to pass data back\nand forth. Unfortunately, many wireless devices do not support datagrams. A Connec-\ntionNotFoundException will be returned if the device you are using does not support\nthe protocol you requested.\n\nThe only protocol that MIDP devices must support is HTTP. As such, it is rec-\nommended that you design wireless games for the lowest common denominator—\nusing HTTP.\n\nHTTP Limitations\n\nHTTP is a widely supported protocol. It is exceptionally easy to design Java servlets or\nother Web technologies to be able to deal with HTTP [Fox01]. Additionally, HTTP\nrides atop TCP, so there will be no out-of-order or missing packets. You will not need\nto bulk up your MIDlet with extra networking code.\n\nHowever, HTTP’s simplicity is also its downfall. HTTP is a request-response\nprotocol designed to deliver static content. A TCP connection is made, a browser asks\nfor a document (request), a Web server delivers it (response), and the connection is",
      "content_length": 2235,
      "extraction_method": "OCR"
    },
    {
      "page_number": 562,
      "chapter": null,
      "content": "5.9 Wireless Gaming Using the Java Micro Edition 577\n\nclosed. HTTP Version 1.1 is a little more advanced, allowing for arbitrary amounts of\nchunked data and for connections that stay alive. But HTTP is still very much a half-\nduplex protocol—you cannot transmit in two directions at the same time.\n\nIf your game is a simple turn-based game, you might not need full-duplex con-\nnections at all. Latency and bandwidth will not be much of a problem, either. Only\none player may make a move at a time. A player moves, the new game state is sent\ndown to all players, and then the next player can make a move.\n\nHowever, if your game is more advanced and has unpredictable data packets com-\ning in constantly, you're in trouble. And what if you want to tap into a complicated,\nfull-featured game server that uses UDP?\n\nUse Multiple Connections\n\nOne way to achieve full-duplex communication is by having your MIDlet client cre-\nate multiple connections—one that sends data to the server and one that stays alive,\nretrieving server data. The first connection should use chunked transfer encoding.\nThe server creates an open connection and assigns it some sort of unique ID. This ID\nis then sent down to the client.\n\nThe client can now create one client-to-server connection with an incredibly\nlarge “Content-length” heading, passing in the proper ID. The server can then handie\nrequest data as it flows in from the client and channel an appropriate response to the\nopen server-to-client connection.\n\nSome servers and proxies might not be able to handle a request with a long con-\ntent length, and might buffer the request and wait for it to be completed. In this case,\nthe client can break each message into a chunk and send it as an individual request.\nThe client should send the ID along with each request, either as a custom header ele-\nment or as part of the payload. The server can then parse this ID number and send\nthe appropriate response back to the client.\n\nProxy Power\n\nAnother way of creating robust wireless communications is to write your game server\nusing any protocol you wish. You can then tap into the game server via an HTTP\nproxy. This is a simple enough system——the MIDlet communicates with a proxy\ninstead of a game server. It will, of course, add extra latency. However, it will also\nallow you to create a better experience for devices that support better network proto-\ncols. For example, devices that support datagrams can try communicating directly\nwith your game server. If a GonnectionNotFoundexception is thrown, the game can\nrevert to using HTTP via a proxy instead.\n\nOptimizing Packets\n\nSo how do we create meaningful game traffic using HTTP over a high-latency, low-\nbandwidth network? In effect, the challenge of creating a wireless game is similar to",
      "content_length": 2775,
      "extraction_method": "OCR"
    },
    {
      "page_number": 563,
      "chapter": null,
      "content": "6738\n\nSection 5 Network and Multiplayer\n\nthat of any other multiplayer game: Packets must be as small as possible, and design-\ning the game around network limitations is tantamount.\n\nThere are many network programming subtleties and rules of thumb to deal with\nthe design of TCP/IP. For better or worse, a lot of these subtleties do not have to be\ndealt with in wireless games—tlatency and bandwidth are too limited to warrant being\nbothered.\n\nBetter Latency\n\nThe following game scenario illustrates a basic problem involving latency. Rat A and\nRat B spot a piece of cheese at the same time, and both make a mad dash for it.\nBecause it takes a second or more for each player to be notified of the other’s location,\nboth rats see themselves as the first one to grab the snack.\n\nThere are many techniques for dealing with this. Dead reckoning [Aronson01] is\na method to extrapolate and predict a game character’s movement. Latency can also\nbe dealt with by locking the game frames in step [Bettner01]. Both of these tech-\nniques, however, involve every client keeping a detailed simulation of every entity in\nthe game. This might require more memory than a witeless device offers.\n\nIt might also be wise to have your game server measure the latency of packets it\nreceives and deal accordingly. A typical multiplayer shooter-game server sends data at\na rate of 10 frames per second (fps). This will most likely be unfeasible for a wireless\ngame. Since animation rates for wireless devices are slower (often only 10 fps), net-\nwork rates of 2 fps to 3 fps are acceptable, given the general slowness.\n\nBetter Bandwidth\n\nBandwidth is usually not as much of an issue as latency, since game packets can often\nbe made quite small. The most important rule of thumb is that, like never before,\nevery bit adds up.\n\nRather than send the game state every frame, you should delta-compress your\ninformation, only transmitting the data that has changed. Additionally, MIDP does\nnot support floating-point operations. Most games that involve graphics will simulate\nfloating-point math using a long integer. Try to reduce and simplify such values to 8\nbits or 16 bits whenever possible. The simplest form of data compression is byte-\npacking—don’t waste a whole byte to send a boolean value. Instead, tweak individual\nbits to send eight flags at once.\n\nThere are more-advanced forms of data compression that can take large packets\nand reduce their size by 30% or more. These include gzip. The downside to com-\npressed packets, however, is that already-high latency will become even higher because\nof the time it cakes to compress and decompress. The code to handle compressing\nmight also take up too much room in the MIDlet. In most cases, simply packing your\ndata into bytes will be sufficient.\n\nThe game server should prioritize messages. Some messages are necessary for the\ngame to function properly. Others, such as a chat message or score update, are not as",
      "content_length": 2943,
      "extraction_method": "OCR"
    },
    {
      "page_number": 564,
      "chapter": null,
      "content": "5.9 Wireless Gaming Using the Java Micro Edition 579\n\nessential. If a message is not immediately relevant to a game scene, you should avoid\nsending it altogether.\n\nTry to tokenize messages as much as humanly possible. In other words, try not to\nsend the phrase “Your tank was hit!” Instead, send a single byte macro that is mapped\non the client to a hard-coded list of phrases.\n\nRetrieving Images from the Server\n\nVersion 1 MIDlets can only display graphics using the PNG file format. Unfortu-\nnately, there is no method to directly grab an image from the network, Rather, the\ncreateImage method accepts only two types of parameters: a string (for filenames) or\na byte array:\n\ncreateImage(byte[] imageData, int imageOffset, int imageLength) ;\n\nThe way to retrieve images using MIDP is to download the binary contents of an\nimage, and then feed that array directly into the createImage method:\n\npublic Image grabImge(String url}\n{\nInputStream is = null;\nHttpConnection he = null;\nImage img = null;\ntry {\nhe = (HttpConnection)Connector.open(url);\n// If we've got a connection...\nif (he .getResponseCade({) ==\nHttpConnection.HTTP_OK) {\n// Open the stream\nis = hc.openinputStream(};\n// How big is the file?\nint len = {int)hc.getLength();\n// Create a byte array that size\nbyte[} data = new byteflen];\n{/ Read in the file\nint actual = is.read(data};\n// Create an image from the raw data\nimg = Image.createImage(data, 0, len};\n}\n} catch (Exception e) {\nSystem.out.println(\"Id Exception+\"+e) ;\n} finally {\nif (is != null} {\ntry f\nis.clase{);\n\ncatch (Exception e} { }\n\n}\nif (c != null)\n{\n\ntry {\nc.close();",
      "content_length": 1596,
      "extraction_method": "OCR"
    },
    {
      "page_number": 565,
      "chapter": null,
      "content": "580 , Section6 Network and Multiplayer\n\n}\ncatch (Exception e}) { }\n}\n\nreturn img;\n\n}\n\nIf you want images to look as good as possible on various mobile devices, it is rec-\nommended that you create an image server. That way, your game can send the device's\nscreen size, color abilities, and other parameters. The image server can then take large,\ncolorful images and convert them on-the-fly into tiny, grayscale PNGs. The Java\nAdvanced Imaging API [Javalmage01} and other such packages can do most of this\nwork for you.\n\nConclusion\n\nThe biggest challenge in wireless networking, other than the limitations of the net-\nwork itself, is to balance limited device space, speed, and memory with advanced net-\nworking techniques. While using dead reckoning, frame locking, compressed packets,\nand other tricks might be effective in theory, many mobile devices only allow 10 KB\nto 50 KB of space for your byte code. Fitting both the game code and the networking\ncode into this box is often a harrowing experience.\n\nDesigning games cleverly in order to make the most of limitations is always the\nbest bet. For example, you might opt to use tanks instead of soldiers in a war game.\nTanks move slowly, can only fire a round occasionally, and take a long time to change\ntheir direction. Of course, there’s only so far this approach can take you. Ultimately,\nsome types of games will simply not be possible until better wireless networks and\ndevices are rolled out.\n\nBut if these challenges are faced, the results can be worth it. Wireless devices offer\nalways-on networking and in-pocket interactivity. Given the pervasiveness of hand-\nheld devices and the potential for reaching a wider audience than ever before, a truly\noriginal wireless game concept can revolutionize the face of entertainment.\n\n[Aronson01] Aronson, Jesse, “Dead Reckoning: Latency Hiding for Networked\nGames,” Gamasutra. Available online at hetp://www.gamasutra.com/fea-\ntures/19970919/aronson_01.htm, September 19, 1997.\n\n[Bettner01] Bettner, Paul and Mark Terrano, “1500 Archers on a 28.8: Network Pro-\ngramming in Age of Empires and Beyond,” Game Developer's Conference Pro-\nceedings, 2001. Available online at hetp://www.gdconference.com/archives/\nproceedings/2001/terrano_1500arch.doc.\n\n[CLDC01} Sun.com, “CLDC Information Page,” available online at hetp://java.\nsun.com/products/cldc/.\n\n[Fox01] Fox, David, “Creating Games Using J2ME,” Gamasutra. Available online at\nhep://www.gamasutra.com/resource_guide/20010917/fox_0O1.htm, September\n17, 2001.",
      "content_length": 2512,
      "extraction_method": "OCR"
    },
    {
      "page_number": 566,
      "chapter": null,
      "content": "&.9 Wireless Gaming Using the Java Micro Edition 581\n\n(J2ME01] Sun.com, “J2ME Information Page,” available online at herp://java.sun\n.com/j2me/.\n\n[Javalmage01] Sun.com, “Java Advanced Imaging API,” available online at hetp://\njava.sun.com/products/java-media/jai/.\n\n[MIDPOI] Sun.com, “MIDP Information Page,” available online at hetp://\njava.sun.com/products/midp/.",
      "content_length": 365,
      "extraction_method": "OCR"
    },
    {
      "page_number": 567,
      "chapter": null,
      "content": "6.1\n\nAudio Compression with\n\nOgg Vorbis\n\nJack Moffitt, Xiph.org Foundation\njack@xiph.org\n\nver since computers could produce sound, audio has been a part of games in\n\nsome form or another. Originally, beeps and bloops were all that were possible.\nMIDI was later used, as it contained a lot of information about the sound in a small\namount of space. Then, as sound cards became prevalent, MOD-type files became\nmore popular, offering a combination of sampled sounds with sequencing and limited\neffects. Once the CD-ROM became the standard media on which games shipped,\nRedbook audio (normal CD audio) started to become popular, and finally games\nused high-quality music.\n\nUnfortunately, as the music became better, music files also became larger. While\nCDs can easily hold an hour’s worth of great-quality audio, not much else will share\nthe same disc. ADPCM is one compression standard that has been used in commer-\ncial games to try and alleviate the size of music files while retaining the quality, but its\nsize savings are not fantastic. High-quality music is now a must for any game, and\nsince game developers are going to continue to push the envelope with respect to\naudio and music in games, music files will have to get smaller.\n\nEnter psychoacoustic compression.\n\nPsychoacoustic Compression\n\nPsychoacoustic compression works by eliminating all the parts of the sound that the\near can't hear or considers unimportant. Unlike some other forms of compression,\npsychoacoustic compressors are lossy. The original signal is irreversibly modified, even\nthough to most ears the sound remains the same.\n\nThe compression ratios for psychoacoustic compressors are generally between\n10:1 and 20:1. This is far better than the ratios offered by the other sound compres-\n\nsion alternatives.\n\nMow It Works\n\nThere are a few basic principles behind psychoacoustics. First, there is the absolute\nthreshold of hearing. This is represented by the graph in Figure 6.1.1.",
      "content_length": 1957,
      "extraction_method": "OCR"
    },
    {
      "page_number": 568,
      "chapter": null,
      "content": "588 Section 6 Audio\n\nBH\n1 HTS ME EH\nTON\niS\naoe HHVHVUE ARID asS800) THAT TAU\nsui att Hine est GEL HIN\nBH TH GY Noe aC TB\nBNbanE avesee et TT\nae 2 HHH BREAEEY AUANUEY EERERGE GASHEHY THEEEAY Unvscee cofltit UHI\n\na6\n\nFIGURE 6.1.1 The absolute threshold of hearing. The x-axis represents frequency, the y-axis\nrepresents loudness.\n\nThe absolute threshold of hearing represents how loud a sound has to be at a cer-\ntain frequency range in order for the human ear to perceive it. Any sounds that are\nbelow the curve can't be heard. If you take away all the sounds that fall under the\ncurve from the original sound, the resulting sound should be perceived identically.\n\nAnother basic concept of psychoacoustics is masking, Just as bright background\nlight sources will mask foreground objects, loud sounds will mask quieter ones. A\nstrong tone will mask weaker tones at higher and lower frequencies. Even after a\nstrong tone is gone, it will still mask some sounds, due to temporal masking. Since a\nfair amount of the sound is masked, psychoacoustic encodets won't include them, and\nthe human ear is none the wiser.\n\nHow Do Sound-Compression Techniques Compare?\n\nNow that we have a basic understanding of how psychoacoustic compression works,\nlet's take a look at how it compares to the other forms of audio compression that\nmight be more familiar. Audio is normally transmitted as raw PCM samples. These\nare uncompressed, so each stereo 16-bit sample takes 4 bytes. For CD-quality audio,\nthere are 44,100 of these every second, or around 10 MB of audio a minute.\n\nTypical ways of reducing the bulk of audio data include downmixing and resam-\npling. Downmixing reduces the stereo channels into one channel, cutting the total\nsize by half. Resampling uses fewer samples per second to represent the sound. Usual\nresampling rates are 22,050 Hz and 11,025 Hz. Both of these methods result in\ngreatly reduced file sizes, but they come at the cost of quality and the loss of stereo.",
      "content_length": 1969,
      "extraction_method": "OCR"
    },
    {
      "page_number": 569,
      "chapter": null,
      "content": "6.1 Audio Compression with Ogg Vorbis 589\n\nADPCM is a 4:1 compression format that encodes the differences between suc-\ncessive samples. It is sometimes used in games to shrink audio without the unaccept-\nable loss of quality that downmixing or resampling creates. ADPCM is also lossy,\nthough, and does degrade audio quality. It also only compresses audio to one quarter\nof the size, meaning that an hour’s worth of audio can still be almost 200 MB.\n\nThere are several lossless methods available as well. While these do not sacrifice\nany quality, their compression ratios are not very good. Typical lossless compressors\nget between 1.5:1 and 2:1 in the general case. Many of them can be quite slow, but\ntheir compression ratios alone make them unusable for most situations.\n\nWhy Ogg Vorbis\n\nPsychoacoustic compression seems to be the clear choice for music compression. High\ncompression ratios and almost no discernable quality loss makes it appealing, but che\nquestion still remains-—-which codec to use of the ones that are widely available?\n\nOgg Vorbis [Ogg Vorbis02] stands above the rest as the perfect fit for games and\nother applications. Its royalty-free licensing makes it a much cheaper alternative than\nthe rest of the codecs. Its open-source implementation gives developers the freedom\nto customize and tweak it if necessary. Also, its broad platform support ensures that\nthe same code will work on Windows, Macintosh (Classic and OS X), Linux, BeOS,\nand even console platforms.\n\nIn addition to these advantages, Ogg also has several unique features that make it\nspecifically appealing to game developers. It supports multiplexing the audio data\nwith other kinds of information. There are already implementations that intertwine\nMIDI with CD-quality audio for synchronized device control. It also supports multi-\nple channels, meaning that you can encode and play back in surround sound or even\nsomething more ambitious.\n\nFor example, using Ogg, a game developer could add synchronized mouth move-\n\n_ Ments to compressed vocals, to give a much more-realistic sense of talking or singing.\nWith other formats, this is more difficult and not directly supported.\n\nIf game developers want to keep advancing the current state of the art, the audio\nand sound will not only have to be compact, but also quite flexible. This is where a lot\nof the other codec options fall short, and this is where Ogg Vorbis shines,\n\nCompression Scenarios\n\nUsing Ogg Vorbis as the implementation choice, we can now cover how best to fit\ncompressed music into a game, considering several possibilities about speed require-\nments and the type of audio being used. Although Ogg Vorbis will be specifically dis-\ncussed, most of the ideas presented here should work with other codecs.\n\nThere are several things to consider when using a codec with a game. Most games\nhave tight speed requirements, so the amount of processor time necessary to decode\naudio is an important factor. Desktop computers can generally decode psychoacoustically",
      "content_length": 3016,
      "extraction_method": "OCR"
    },
    {
      "page_number": 570,
      "chapter": null,
      "content": "590\n\n/\n\ncompressed audio in about 2% to 5% of the total processor time on Pentium III-class\nmachines.\n\nAlso, the type of sound being decoded is important as well. For instance, back-\nground music generally only consists of one stereo track and switches between differ-\nent tracks. More-compiex music might layer tracks together, requiring the decoding\nof several files at once. Sound effects are generally short sounds and are keyed to\nevents. The latency between the time the event happens and the sound is played is\nvery important. Many sound effects might be playing simultaneously.\n\nWith these situations in mind, let’s outline some ways that compressed audio can\nbe effectively integrated into games.\n\nSection 6 Audio\n\nScenario 1; Decoding On-the-Fly\n\nThe most common method of using Ogg in a game would be to decode audio on-the-\nfly. This uses a lictle CPU time, but it allows the files to remain on a mass storage\ndevice, such as a hard drive.\n\nIn this scenario, an audio stream has been completely encoded in Ogg format and\nis decoded and played in real-time while the game is running. There is no need to\nmake the user wait for entire files to be decompressed before playback, and there's no\nlarge, uncompressed audio files sitting around on the player’s hard drive. In addition,\nallowing the player to add his or her own music to a game is simple with this method\nof integration.\n\nScenario 2: Decoding to Cache\n\nIn some situations, decoding to cache is a better fit. If there are many pieces of audio\nto be played at once, decoding all of them in real-time might not be possible or might\nuse up too much of the processor time. In this case, decoding the files to a cache on\nlevel changes or on startup might be the right solution. This allows a game imple-\nmentation to keep all audio data compressed that is not needed to be immediately\navailable by gameplay.\n\nThis is also a nice way to produce sound effects, The game could decode them\non-the-fly the first time they were used, and play the already decoded audio on subse-\nquent requests. If latency is a problem with decoding, the sound effects could be\ndecoded on level changes or at startup, as previously described, and then played back\nwith no decoding latency ar all.\n\nScenario 3: Compressed Transport\n\nIn cases where none of the previous scenarios make sense, compression can still be\nused for end-to-end transport. The game distribution CD-ROM and/or download-\nable packages can use Ogg to make the download smaller and leave more room for\ngraphics and code. When the game or demo is installed, all of the music can be\ndecompressed to the hard drive. This scenario would also apply well to game patches\nor additional packages to go along with the game.",
      "content_length": 2724,
      "extraction_method": "OCR"
    },
    {
      "page_number": 571,
      "chapter": null,
      "content": "6.1 Audio Compression with Ogg Vorbis 591\n\nCode Examples Using Ogg\n\nA few code examples will illustrate how easy it is to use Ogg Vorbis. To use the vorb-\nisfile library, the code will need to include the API headers:\n\n#include <vorbis/vorbisfile.h>\n\nand link against the vorbisfile, verbis, and ogg libraries. Under Windows, these can be\nstatically linked or dynamically linked, depending on personal preference (see the\nSDK files and API reference on the CD-ROM for details).\n\nUncompressing Files to Momory\n\nUncompressing files to memory is easy with the vorbisfile API. First, we declare the\nOggVorbis_File variable:\n\nOggVorbis File vf;\n\nThen, we must open the Ogg Vorbis file with an already open FILE*. Note that you\nmust open a file in binary mode for vorbisfile. On some platforms, binary files are\ndefault for calls like fopen(), but on Windows, this is not the case, and you must\nspecify binary mode explicitly.\n\nint err;\nerr = ov_open({fp, &vf, NULL, 0);\n\nThe fp is our FILE* to an already open file. The vf is the OggVorbis_File struct,\nand the other two parameters are typically set to NULL and zero, as in our example. (If\nyoure curious as to what these mean and when you should use them, please consult\nthe API reference.)\n\nThe ov_open will return zero on success or less than zero on failure. On failure,\nthe return value will map to one of the standard error codes of the API (which you can\nfind explained in the API reference).\n\nNow that the Ogg file has been opened by the vorbisfile library, the library owns\nthe file. It will close the file when it’s done, and you should no longer use that file\npointer in external file operations. Once the file is opened, the file info must be read:\n\nvorbis_info *vi;\nVi = ov_info(avf, -1);\n\nThe vorbis_info struct will contain information about the opened Ogg file, such\nas its sampling rate, the nominal bit rate, and its number of channels. The second\nparameter specifies which logical bitstream to return information for (-1 means the\ncurrent logical bitstream). Optionally, you can read the comments from the file with\nthe ov_comment() function.\n\nBefore we can decompress the Ogg to memory, we must first allocate some space\nfor it. To find out the total space required, we must call ov_pem_total() to find the",
      "content_length": 2271,
      "extraction_method": "OCR"
    },
    {
      "page_number": 572,
      "chapter": null,
      "content": "total number of PEM samples, and multiply this by the number of channels and che\nnumber of bytes per sample (usually 2 bytes for 16-bit audio).\n\nint $ize;\nchar *buffer;\n\nsize = vi->channels * 2 * ov_pem_total(avf, -+);\nbuffer = (char *)malloc(size);\n\nNow that we have a buffer allocated for the entire decoded output, ov_read() is\ncalled in a loop to retrieve PCM samples into the buffer.\n\nint eof = 0;\nchar *buf = buffer;\nint current_section;\n\nwhile (!eof) {\nlong ret = ov_read(&vf, buf, 1024, 0, 2, 1,\n&current_section} ;\n\nif (ret == 0) {\n/* 0 return value means end of file */\neof = 1;\n\n} else if (ret < 0) {\n/* <0 return value indicates an error */\n\n} else {\n/* advance the buffer pointer on success */\nbuf += ret;\n\n}\n\n}\n\nThe code is fairly simple. It doesn’t do any error checking (although when work-\ning with Ogg, most errors are normally benign and can be ignored) or overflow\nchecking, but all the hard work is done for you in the vorbisfile library.\n\nOnce a file is finished, you must cleanup with ov_clear():\n\nov_clear(avf);\n\nDecoding in Real-Time\n\nDecoding in real-time is very similar to the previous situation of decoding to a mem-\nory buffer, except that instead of decoding all at once, real-time decoding takes place\na piece at a time. After reading each block from ov_read{), the code then sends it to\nthe next stage of the pipeline. In the most common case, this is an audio output\ndevice.\n\nFor the sake of simplicity, system specifics of audio output won't be covered here.\nInstead, the code assumes that there is an audio_output() function that takes a buffer\nof samples and a size, and does the right thing.\n\nUsing the previous example as a base, the only thing that needs to be modified is\nthe decode loop. Ac the top of the loop, there is still the call to ov_read{):",
      "content_length": 1791,
      "extraction_method": "OCR"
    },
    {
      "page_number": 573,
      "chapter": null,
      "content": "6.1 Audio Compression with Ogg Vorbis 593\n\nchar pcmout[4096] ;\n\nwhile (leof) {\nlong ret = ov_read{&vf, pemout, sizeof (pemout),\n0, 2, 1, &current_section);\ni* a a]\n}\n\nNotice that the buffer is now a fixed size, since the code only processes output in\nsmall blocks.\n\nIn the success clause of the previous example’s if blocks, we advanced a buffer\npointer. Since we only process a block at a time for real-time decode, we just need to\nsend the current block to the audio_out:\n\naudio_out(pcmout, ret};\n\nOn success, ret will be the number of bytes placed into the buffer.\n\nEncoding\n\nThe last part to a fairly comprehensive understanding of using psychoacoustic com-\npression in your game is encoding and production. There are several knobs to tweak\nwhen making compressed Ogg files, and understanding these will lead to better-\nsounding music and sound effects in your game.\n\nQuality and size are integrally related in Ogg, and both are controlled by a single\nknob. In most codecs, you adjust the ‘size’ knob, which implicitly changes the quality.\nIn Ogg, you adjust the ‘quality’ knob, which implicitly changes the size. In general,\nthe bigger you're willing to make the file, the better it will sound; and conversely, the\nless quality you need, the smaller the file can be. There are some practical limits to this\nrelationship, though.\n\nThe size of compressed audio is measured by bit rate: the amount of bits used to\nstore one second of audio. The average gamer is not going to be able to hear subtle\nquality loss, so pushing the bic rate past a certain point will have diminishing returns.\nOgg files should sound quite good at 64 kbps (kilobits per second) and should hardly\nbe discernable from the original, which is around 128 kbps.\n\nSince, with most games, the music is not the primary focus of the gamer’s atten-\ntion; lower-bit-rate Ogg files should be more than enough to give gamers an excellent-\nquality experience.\n\nTwo other knobs are the number of channels and the sample rate of the audio.\nWhile these affect quality (e.g., mono sound is not as good as stereo), the rate of qual-\nity change to size change is not linear. If you halve the size by going from stereo sound\nto mono sound, the quality is only slightly diminished in most cases. Similarly, if you\nhalve the sample rate, the audio sounds worse, but possibly not much worse. If space\nis at a premium, you can downmix and resample before compressing with Ogg. This\n\nleads to smaller files with an acceptable loss of audio quality.",
      "content_length": 2500,
      "extraction_method": "OCR"
    },
    {
      "page_number": 574,
      "chapter": null,
      "content": "594 Section 6 Audio\n\nConclusion\n\nAs game audio grows in importance, it seems obvious that better forms of compres-\nsion must be utilized to reduce audio’s bulk. Since many games are developed on a\ntight financial budget, an open and royalty-free solution is the natural choice. So, on\n\nyour next project, consider psychoacoustic compression with Ogg Vorbis.\n\nReferences\n\n[Oge Vorbis02] Ogg Vorbis, available online at http://www.vorbis.com, June 2001.\n\n{XiphHome02] Xiphophorus, http://www.xiph.org, June 2001.\n\n[XiphName02] Xiphophorus names and logos, available online at http://www.xiph\n.org/xiphname.html, June 2001.",
      "content_length": 620,
      "extraction_method": "OCR"
    },
    {
      "page_number": 575,
      "chapter": null,
      "content": "Creating a Compelling 3D\nAudio Environment\n\nGarin Hiebert, Creative Labs, inc.\ngarinh@hibyte.com\n\nhis gem will provide you with techniques for creating compelling 3D audio in\n\nyour games by applying a few simple rules to your audio engine design and the\nsamples used. We will introduce some basic concepts of 3D audio rendering, provide\ntips on how to maximize the effectiveness of your audio engine, and offer examples of\nhow to apply these tips. DirectSound 3D and OpenAL are used as examples of promi-\nnent 3D audio APIs, but the concepts should be transferable if you are using another\nAPI. Complete sample code is included on the CD-ROM.\n\n3D Audio Core Concepts\n\nMany modern games are designed to take place in a 3D world, even in genres that\nin the past would have used two-dimensional representations of their world. The\nfundamental idea of a 3D audio engine is to provide a way to use the same three-\ndimensional world representation for all aspects of the game, with the same data\nbeing used for audio and video components. The following subjects are fundamental\nto 3D positional audio rendering and are critical to your audio engine design.\n\nSingle Listener\n\nThere is a single ‘listener’ object representing where the sound is heard in the 3D\nenvironment. The listener has a position and orientation in the game-world space,\n\nwhich is used to calculate the appropriate speaker output.\n\nMultiple Sources\n\nEach sound-producing object in the environment is represented by a source. All the\nsources are mixed and represented at the listener’s position, and each corresponds to a\nvoice on the sound card.\n\nMultiple Buffers\n\nA buffer object contains the actual audio data. In DirectSound 3D, a buffer and a\nsource are combined into one object. In OpenAL, the audio data is separated from",
      "content_length": 1791,
      "extraction_method": "OCR"
    },
    {
      "page_number": 576,
      "chapter": null,
      "content": "596 Section6 Audio\n\nthe sources, in which case there ate commonly more buffers allocated than there are\nsources.\n\nVoice Management\n\nThere must be a scheme implemented to allocate the audio data (in buffers) among\nthe available voices on the sound card. The game often needs to play more sounds\nconcurrently than the system can play. Voice management solves this problem by\ninvoking a method, based on distance and/or priority, to decide which sounds will be\nplayed at any given time. In DirectSound 3D, a buffer and a source are the same\nthing, and a voice-management scheme is used internally to determine which buffers\nate audible using the current hardware. In OpenAL, a source object directly corte-\nsponds with a voice on the audio hardware, and there can be a much latger number of\nbuffers that can be played on the limited number of sources. Voice allocation in this\ncase is done by any scheme the programmer decides to use.\n\nDetermination of Speaker Output\n\nThe end user might have any of a variety of speaker output configurations, any of\nwhich should convincingly portray the 3D audio world. To do this, the audio-render-\ning system (e.g., DirectSound, OpenAL) must minimally figure out what the panning\nand attenuation characteristics are for each source at the listener's position. The rela-\ntive positions and orientations of the listener, and each source can be used to figure\nout the panning of the speakers. The distance between each source and the listener\ndetermines the attenuation of each source, and the resulting audio is then mixed and\nplayed. For an even more compelling audio experience, reverberation and filtering can\nalso be applied (either globally or on a per-source basis) before the final mix.\n\nUsing Your Audio Engine Effectively\n\nThe following tips {in order of their application to the audio-processing chain) will\nhelp you maximize the quality of a 3D audio engine.\n\nTip #1: Use Normalized Samples\n\nBefore importing a sample into your engine, make sure it is taking full advantage of\nthe amplitude range of your sample bit depth by normalizing it. Otherwise, you\nmight find that a particular sample is always too soft, and then you might have to\nadjust the levels of everything else. This hassle is avoided by normalizing the sample\nto begin with.\n\nTip #2: Use ‘Dry’ Samples\n\nIf you intend to apply effects to your audio, make sure there are no effects applied to\nthe original sample. (Samples without effects are called “dry.”) Applying reverberation",
      "content_length": 2487,
      "extraction_method": "OCR"
    },
    {
      "page_number": 577,
      "chapter": null,
      "content": "6.2 Creating a Compoliing 3D Audio Environment 507\n\nor filtering at an early stage makes it impossible to recover from the effect during run-\ntime processing.\n\nTip #3: Deckie on Your Units\n\nMake sure you know what units are used in the design of the game world. It is critical\nto provide the correct information to the low-level API so that it can render the audio\nproperly, This means that the audio API needs to understand the physical parameters\nof the game world. If the audio world units are in meters, but the game world is in\nfeet, then certain audio effects (e.g., Doppler effects or air absorption) might not\nwork as intended, forcing you to recalibrate the effects for another set of units. Using\nconsistent units throughout the engine will allow the API to work the way it was\ndesigned.\n\nTip #4: Understand and Use the Capabilities of the\nLow-Level API\n\nDecide on a low-level API and plan to take advantage of its features. In addition to\n3D position, the low-level API {e.g., DirectSound 3D, OpenAL) will have global and\nper-source properties, such as roil-off factor or per-source gain. Plan on providing this\ndata to the low-level API. For example, if you followed Tip #1 and normalized your\naudio, then you will need to set per-source reference distance appropriately. Both\nOpenAL and DirectSound 3D have a notion of directional audio as well—an under-\nutilized feature of both APIs.\n\nTables 6.2.1 and 6.2.2 show a few of the global and per-source properties that can\nbe applied using OpenAL or DirectSound 3D.\n\nTable 6.2.1 Examples of Gichal Properties In OpenAL and DirectSound 3D\n\nDescription OpenAL Property DirectSound 3D Property\n\nMaster gain AL_GAIN Master Volume, set using mixer AP]\nSpeed of sound AL_ DOPPLER VELOCITY DistanceFactor, applied to listener\nDoppler effect AL_DOPPLER_FACTOR DopplerFactor, applied to listener\n\nTable 6.2.2 Examples of Per-Source Properties in OpenAL and DirectSound 3D\n\nDescription OpenAL Property DirectSound 3D Property\nPitch multiplier AL_PITCH Frequency\n\nGain AL_GAIN Volume\n\nPosition AL_POSITION Position\n\nVelocity AL_VELOCITY Velocity\n\nDirection AL_DIRECTION ConeOrientation\n\nHead relative/Absolute modes AL_SOURCE_RELATIVE Mode\n\nReference distance AL_REFERENCE_DISTANCE MinDistance",
      "content_length": 2242,
      "extraction_method": "OCR"
    },
    {
      "page_number": 578,
      "chapter": null,
      "content": "598 fo Section6 Audio\n\nTip #5: Add Effects\n\nProcess the audio to accommodate the game environment. Using an API such as\nEAX, occlusion, obstruction, reverberation panning, and other effects can be added\nto enhance the player's experience. A fallback scheme for lack of hardware-accelerated\neffects does not need to be limited to dry audio, either—filtering and additional\nattenuation can be applied. For example, in a first-person shooter, intervening walls\nshould muffle sounds. Applying occlusion via EAX or using a low-pass filter function\nwith additional attenuation can make this situation sound much more realistic and at\nthe same time provide the player with information about the environment.\n\nA demo program is provided on the CD-ROM with an audio engine incorporating\nthe above tips. The demo program is simple in many regards, but ir stil] illustrates\ntypical audio engine flow with four high-level events:\n\n1} Loading Audio Data\n\nAll the audio data is loaded once when the program starts. In most games, the audio\ndata is loaded for each level as part of the loading of that level’s other data (e.g., geom-\netry, textures, etc.). But in general, the loading of audio data is an infrequent event.\nTips #1 and #2 apply to this event. The audio data should be normalized and dry.\n\n2) Apply Global Parameters\n\nThe global parameters are all applied only once, and after the audio data is loaded. A\ngame might not be able to get away with only a single setting of the global parameters,\nbut this will normally be a very infrequent event compared to other audio events. For\nexample, the physical parameters of the game world, such as the Doppler factor and\nmaster volume, shouldn’t require constant adjusting.\n\nTips #3 and #4 apply to this event. The setting of any parameter should use the\ncorrect units, and the selection of parameters should make use of the APT's capabilities.\n\n3) Adjust Per-Source Parameters\n\nPer-source parameters are set once for every frame of graphics displayed, which is sim-\nilar to how most games will operate. Some games set the audio parameters less fre-\nquently than the video updates occur, but this event is still part of the main loop of\nthe program.\n\nTips #3 and #4 apply to this event. The setting of any parameter should use the\ncorrect units, and the selection of parameters should make use of the API's capabilities.",
      "content_length": 2361,
      "extraction_method": "OCR"
    },
    {
      "page_number": 579,
      "chapter": null,
      "content": "6.2 Creating a Compeiling 3D Audio Environment 599\n\n4} Adjust Effects Parameters\n\nBoth global and per-source effects are being used in the demo program. If EAX capa-\nbility is detected, the global EAX preset can be changed while the demo runs. In addi-\ntion, the demo program is also constantly looking for the opportunity to apply\nper-source EAX effects. Any game will need to apply both global and per-source\neffects, depending on the effects available. This event is part of the main loop of the\nprogram and takes place concurrently with the per-source parameter changes.\n\nTips #3 and #5 apply to this event. Some effects rely on the physical properties of\nthe game world being set correctly, and an appropriate level of effects should be used\nwhen available.\n\nConclusion\n\nCreating a compelling 3D audio environment for your game is a difficult job with\nmany subtleties. Using the five tips in this gem, the job will be less stressful, take less\ntime, and provide your players more compelling audio.\n\n[Creative02] Creative Technology, Ltd., “Creative Labs—Developer Central,” avail-\nable online at http://developer.creative.com, March 2002. The “Games” section\nhas information on EAX as well as OpenAL, including documentation and\nSDKs.\n\n[Loki01] Loki Entertainment Software, “OpenAL | Open Source Audio Library,”\navailable online at http://www.openal.org, March 2002. The OpenAL source -\ncode and a mailing list are hosted.",
      "content_length": 1427,
      "extraction_method": "OCR"
    },
    {
      "page_number": 580,
      "chapter": null,
      "content": "6.3\n\nObstruction Using Axis-\nAligned Bounding Boxes\n\nCarlo Vogelsang, Creative Labs inc.\ncvogelsang@creativelabs.com\n\nhis gem will describe how axis-aligned bounding boxes can be used to simplify\n\nthe calculations for proper sound obstruction caused by arbitrary objects in your\ngame. It will demonstrate actual techniques used by EAGLE™ and EAX-Manager,\ndeveloped. by Keith Charley at Creative Labs. The result is a good audio experience\nwith low calculation cost and enough flexibility for general usability.\n\nThe Problem\n\nWhen sound is heard indirectly, this means that the sound waves cannot travel\ndirectly from source to listener. We call this obstruction [Jot99] since the direct path is\nbeing obstructed, Figure 6.3.1 shows the unobstructed and obstructed sound source.\n\nWe want to obtain a value that represents the amount of this obstruction. It turns\nout that sounds waves with a bigger wavelength (or lower frequency) diffract around\nsolid objects berrer than sound waves with a smaller wavelength (or higher fre-\nquency). So once we have obtained a value that represents the amount of obstruction,\nwe can use that value to determine the gain of a low-pass filter applied to our sound\nsource [I3DL2]. This filter is used to simulate the attenuation of higher frequency\nsounds diffracting around solid objects.\n\nSource Source\n5\n\nListener\n\nFIGURE 6.3.1 An unobstructed (left) versus obstructed (right) sound source.",
      "content_length": 1425,
      "extraction_method": "OCR"
    },
    {
      "page_number": 581,
      "chapter": null,
      "content": "6.3 Obstruction Using Axis-Aligned Bounding Boxes 601\n\nIn the following section, an algorithm is explained that determines a value from 0\n(silent, the sound is completely obstructed) to 1 (full level, the sound is completely\nunobstructed).\n\nThe Solution\n\nThe solution proposed in this gem involves finding an approximation for the path\nthat sound must take to ‘bend’ around the corner of an obstruction. The corner we\nchoose to evaluate is the edge closest to the sound source. To calculate this bend, we\nbuild an angle, o, from the vectors that go from source to corner to listener. When\nthis angle is at a maximum (180°), there is no obstruction. The smaller the angle cal-\nculated, the more the sound is being obstructed [Kutt00}. You can see in Figure 6.3.2\nthat this results in a vector that intersects the obstruction object. An accurate path\naround the obstruction would not intersect, but we are trading accuracy for speed.\n\nTo speed up the process even further, we can use axis-aligned bounding boxes\n(AABB). A small error is still introduced, but the computational time is drastically\nreduced. You can see the error introduced by comparing Figure 6.3.2 and Figure\n6.3.3. Any object chat is not cubical and axis-aligned will accrue some error in &. Fig-\nure 6.3.3 shows the resulting & when using AABBs.\n\nTo calculate this angle given our source position, listener position, and obstruc-\ntion bounding box, we start by computing two bit vectors, one for the source and one\n\nListener\n\nFIGURE 6.3.2 Biggest angle/shortest path algorithm.",
      "content_length": 1544,
      "extraction_method": "OCR"
    },
    {
      "page_number": 582,
      "chapter": null,
      "content": "Section6 Audio\n\nSource\n\nBounding box\n\nListener\n\nFIGURE 6.3.3 Obstruction covered by axis-aligned bounding box.\n\nfor the listener. Six bits are used to represent each of the six planes of the 3D bound-\ning box. A set bit indicates that the source or listener is in front of that plane; this code\nexample computes the listener bits corresponding to the front and back (xy-) plane:\n\nif (ListenerPosition.Z < BoundingBox.vMin.Z)\nlListenerFlags |= 0x02;\n\nelse if (ListenerPosition.Z > BoundingBox.vMax.Z)\nlListenerFlags |= 0x01;\n\nUsing these two bit vectors, we can quickly determine if an obstruction is possi-\nble. If both bit fields share any true bits, then there cannot be an obstruction, because\nthe source and the listener are in front of the same plane. The check can be performed.\nby:\n\nif {lListenerFlags & 1SourceFlags}\ncontinue;\n\nIf we have determined that an obstruction is possible, we create a list of the bound-\ning-box planes closest to the source. This is accomplished by using the bit vector to\ndetermine the zone that the source is in (26 possible zones outside of the bounding box\nand 38 zones inside of the bounding box, adding up to a total of 2° = 64 zones). One of",
      "content_length": 1183,
      "extraction_method": "OCR"
    },
    {
      "page_number": 583,
      "chapter": null,
      "content": "6.3 Obstruction Using Axis-Aillgned Bounding Boxes 603\n\nthe valid 26 outside cases is shown in the switch statement code presented here. The 38\ninside cases are invalid and are handled by the default case statement.\n\nswitch (1SourceFlags & Ox3f)}\n\n{\n\ncase 0x01:// Behind bounding box\nvPlanePoint[0O] = BoundingBox. vMax\nvPlaneNormal[0] = {0, 6, 1};\n1PlaneType = BACK;\n1NumPlanes = 1;\nbreak;\n\ndefault: /7/ Invalid combination (inside)\n1NumPianes = 0G;\nbreak;\n\n}\n\nAfter this switch statement, we may have up to three bounding box planes speci-\nfied. For each plane, we check to see if it intersects the source/listener vector. If an\nintersection is found, we compute the intersection point:\n\nfor (i = 0; i < LNumPlanes; itt)\n\n{\nSVector svIntersection;\nFindPlaneIntersectionPoint{..,&svIntersection) ;\nif (PointInPlane(svIntersection, ..})}\n{\n}\n\n}\n\nNow that we know there is an intersection somewhere on the bounding box’s\nhull, we need to find and move the intersection point to the closest edge. The follow-\ning code block performs this.\n\nswitch (1PlaneType)\n{\ncase FRONT:\ncase BACK:\nif (Listener->fY < Box.vMin->fY¥ &&\nListener->fY¥ > Box.vMax->fY)\n\n{\nfMidPoint = Box.vMin->fX — Box. vMax->fX;\nfMidPoint /= 2;\nfMidPoint += Box. vMax->fX;\nif (svIntersection.fX < fMidPoint }\nsvintersection.fX = Box. vMax->fX;\nelse\nsvIntersection.fX = Box, vMin->fX;\n}\nelse",
      "content_length": 1355,
      "extraction_method": "OCR"
    },
    {
      "page_number": 584,
      "chapter": null,
      "content": "604 Section6 Audio\n\nfMidPoint = Box.vMin->TY — Box.vMax->TY;\nfMidPoint /= 2;\nfMidPoint += Box. vMax->TY;\nif (svIntersection.fY < fMidPoint }\nsvIntersection.fY = Box.vMax->TfY;\nelse\nsvintersection.f¥ = 80x.vMin->fY;\n\n}\n\nbreak;\ndefault:\n\nbreak;\n}\n\nWith the intersection point now on an edge of the bounding box, we can com-\npute the angle, a&, between the intersection point-to-source vector and the intersec-\ntion point-to-listener vector.\n\nlong lLevel = MAX_OBSTRUCTION;\n\nCVector cvListener(*psvListener) ;\ncvListener -= sviIntersection;\n\nCVector cvSource(*psvSource) ;\n¢vSource -= svIntersection;\n\ncvSource.Normalize();\ncvListener .Normalize();\n\nfloat fAngle = cvListaner.DotProduct (cvSource) ;\nif ( fAngle >= 0 )\nreturn ILeval;\n\nfAngle += 1;\n\nfloat fMaxAngle = {float}m_10ifAngle;\nfMaxAngle /= 90.0f;\n\nif ( fAngle >= fMaxAngle }\nraturn lLevel;\n\nHevel = (long) (((float)lLevel * fAngle) / fMaxAngle);\n\nNow that we know o: and, thus, the amount of obstruction imposed by the edge,\nwe will take the biggest value (meaning the /east amount of obstruction) found. Note\nthat this algorithm will only consider the closest edge to the source; if the bounding\nbox is fairly thin (¢.g., walls, crates, etc.), this will work fine. For larger bounding\n\nboxes, the influence of the edge closest to the listener can cause greater inaccuracies.",
      "content_length": 1332,
      "extraction_method": "OCR"
    },
    {
      "page_number": 585,
      "chapter": null,
      "content": "6.3 Obstruction Using Axis-Aligned Bounding Boxes 606\n\nimplementation\n\nA sample implementation that handles all the calculations needed for a single bound-\nZe ing box is on the CD-ROM. This is actual code from EAXMan, by Keith Charley at\nome Creative Labs, Inc.\n\nrhe\n\nConclusion\n\nIn this gem, we have shown how to simplify the obstruction calculations by using\naxis-aligned bounding boxes, This dramatically reduces the amount of computations\nrequired, yet the overall result is very convincing and adds an important audio cue to\ngive players a definite advantage.\n\nReferences\n\n[I3DL2] LASIG, “Interactive 3D Audio Rendering Guidelines Level 2.0,” available\nonline at hetp://www.iasig.org, Los es, CA, 1999.\n\n[Jor99] Jot, J. M., “EAX 4.0 Specification,” Creative Labs, Inc., Milpitas, CA, 2001.\n\n[Kutt00] Kurtruff, H., Room Acoustics, Fourth Edition, Spon Press, London, U.K.\n2000.",
      "content_length": 881,
      "extraction_method": "OCR"
    },
    {
      "page_number": 586,
      "chapter": null,
      "content": "6.4\n\nUsing the Biquad\nResonant Filter\n\nPhil Burk, SoftSynth.com\nphilburk@softsynth.com\n\nhis gem will discuss the biquad infinite impulse response (IIR) filter, which is a\n\nmultipurpose resonant filter. By changing the filter coefficients, it can perform\nvarious filter-pass operations, such as low pass, band pass, high pass, band stop, and\nothers. We will describe how digital filters work, how to implement an efficient\nbiquad filter, and how to calculate coefficients for various functions. Several examples\nof the sound-filtering techniques and synthesis tricks will be provided.\n\nYou can use a filter to change the character of a sound. Sounds can be thought of\nas being composed of sine waves at various frequencies. Filters change the amplitude\nof those sine waves, depending on their frequency. You can emphasize the high fre-\nquencies or the low frequencies to make something sound brighter or have more\nboom.\n\nThis is particularly handy when playing samples because they tend to always\nsound the same. However, if you pass a sample through a filter while changing para-\nmeters, you can vary the sound every time the sample is played. You can dynamically\nchange these filter parameters to track the state of the game. Changing a sound to\nappropriately match the current game state will make your game more realistic.\n(Examples of using a biquad filter to create complex sound effects are also given in\nGem 6.6, The Stochastic Synthesis of Complex Sounds, by Phil Burk.)\n\nHow Digital Filters Work\n\nWhen you add sine waves of the same frequency together, they can cancel each other\nout or reinforce each other, depending on their relative phase. Delaying a complex\nsignal by a fixed amount, say one sample period, will change the phase of all its fre-\nquency components by differing amounts. A one-sample period delay might cause a\nvery small phase change for a low frequency because it has a long period, while\na higher frequency sound will have a greater phase change because the time delay is a\nlarger fraction of the waveforms period. This gives us a mechanism by which we can\naffect different frequencies in different ways.",
      "content_length": 2135,
      "extraction_method": "OCR"
    },
    {
      "page_number": 587,
      "chapter": null,
      "content": "6.4 Using the Biquad Resonant Filter 607\n\nA typical digital filter contains a delay line made up of successive, one-sample\ndelays, or saps. The original input signal is called x,. So the taps are labeled x,.;, x2\nand so on. The taps are scaled and added or subtracted to cause cancellation or rein-\nforcement of various frequencies.\n\nAn averaging filter, for example, produces an output, y,, that is an average of the\ncurrent input sample and the previous input sample. The equation for a simple low-\npass filter is:\n\nIn = 0.5 * (Ky + X__ 1) (6.4.1)\n\nBecause low frequencies are not phase-shifted very much by this one-sample\ndelay, they remain relatively unaffected by this filter. However, high frequencies are\nshifted significantly in phase and can undergo cancellation. In fact, the higher the fre-\nquency, the greater the cancellation. Because this filter passes low frequencies more\nthan high frequencies, we call this simple averaging filter a /ow-pass filter.\n\nA high-pass filter can be constructed by changing the plus (+) sign in the equa-\ntion for the low-pass filter to a minus (—) sign. Then, low frequencies that are not\nshifted very much in phase cance! themselves out. The simple high-pass filter equa-\n\ntion is:\n\nIn = 9.5 * (x, 7 X_—1)- (6.4.2)\n\nliR Versus FIR Filters\n\nFinite impulse response (FIR) filters only process the incoming sound. So, when the\ninput goes to zero, the output goes to zero within a few samples, depending on how\nmany taps there are,\n\nInfinite impulse response (IIR) filters use delayed versions of both the incoming\nsound, and the resulting output. This feedback allows the filter to wiggle forever, even\nwhen the input goes to zero. The characteristic ringing filters of electronic music are\nIIR filters.\n\nThe Biquad Filter Implementation\n\nThe biquad filter has three taps on the input side and two on the output side\n[Dodge97, p. 214]. The equation for this filter is:\n\nIn = Ay” Xq_t Oy\" Xq_ 4 + Oy * x, 2 - by* yn, 1 - 82* Jn—2. (6.4.3)\n\nBy changing the coefficients, a, 2), 42, 6, and &, you can make the filter behave\nas a low-pass, high-pass, band-pass, band stop, peaking EQ, or other type of filter.\n\nThere are several things we can do to optimize the filter. The most optimal place\n\nfor the filter operation is in a loop. Most compilers will load the values into the regis-\nters once and then perform the loop calculations without having to reload them. The",
      "content_length": 2408,
      "extraction_method": "OCR"
    },
    {
      "page_number": 588,
      "chapter": null,
      "content": "608 Section6 Audio\n\nfollowing listing is an implementation of the biquad excerpted from the file\nUnit_BiquadFilter.cpp available on the CD-ROM.\n\nfor( i=0; i<GGSYNTH_FRAMES_PER_BLOCK; i++)\n{\n{/ Generate outputs by filtering inputs.\nxn = inputs[i];\nyn (aO * xn) + (at * xnt) + (a2 * xn2)\n- (b1 * ynt} - (b2 * yn2);\noutputs[i] = yn;\n\n// Delay input and output values.\n\nxn2 = xn1;\nxni = xn;\nyn2 = yni;\nyni = yn;\n\n}\n\nPermuting the Variables\n\nAnother optimization to the biquad filter is to reduce the data movement associated\nwith the delay lines by permuting the algorithm. First, we modify the loop so that we\nperform two filters per loop. Instead of moving data, we can just leave the data in\nplace and change the equation to use the right values. The following code is a per-\nmuted version of the previous code. To make this clearer, look at the second IIR equa-\ntion in the following code, where we multiply (a2 * xn1). We would normally have\nset xn2=xn1 to implement the delay line, and then done (a2 * xn2). However, we can\ntake a shortcut and just multiply (a2 * xn1), and get the same result. Some optimiz-\ning compilers will do this trick by themselves, but it doesn’t hurt to give the compiler\na hint.\n\nfor( i=0; i<GGSYNTH_FRAMES PER_BLOCK; 1+=2)\n{\n// Generate outputs by filtering inputs.\nxn = inputs[i];\nyn2 = (a0 * xn) + (ai * xni) + {a2 * xn2)\n- (bt * yn1) - (b2 * yn2);\noutputs[i}] = yn2;\n\n// Permute filter operations to reduce data movement.\n// Just substitute variables instead of xn1=xn, etc.\nxn2 = inputs[i+1];\nyni {a0 * xn2} + (a1 * xn} + (a2 * xnt}\n- {bi * yn2) - (b2 * yni};\noutputs[iti] = yn1;\n\n// Only move a little data.\nxnt = xn2;\nxn2 = xn;",
      "content_length": 1663,
      "extraction_method": "OCR"
    },
    {
      "page_number": 589,
      "chapter": null,
      "content": "6.4 Using the Biquad Resonant Filter 609\n\nAlso, many of the filter types have coefficients that are the same or zero; so, you\ncould eliminate one of the multiplications. If, for example, a0 equals a2, then the\nterm (a0 * xn2) + {a1 * xn) + (a2 * xn1) becomes (ad * xn2} + (a1 * xn) +\n(a0 * xnt), which can be shortened to (a0 * (xn2 + xn1)) + (at * xn).\n\nAvoiding Denormalization\n\nRecursive algorithms that operate on their previous output are subject to a vexing\nproblem. Imagine performing this calculation many times:\n\nx = 0,99 * x;\n\nThe value x will continue to get smaller and smaller, and will eventually become\ntoo small to represent as a valid floating-point number. This can happen in a game if\nyou leave it paused for a long time. When this happens, some FPUs will interrupt the\nCPU and ask for a fix, which could render a computer sluggish.\n\nLuckily, there is a simple solution. Just inject a little bit of energy into the filter to\nprevent it from decaying to such a small value. You can pulse it with a number so\nsmall that you will never hear the effect, but it is enough to prevent the interrupts.\nAfter you calculate a block of samples using the aforementioned loop, just add a very\nsmall number to one of the delayed values. The tiny spike will prevent the filter from\ndecaying too close to zero. The following is an example solution.\n\nyn += 1.0E-26; /* prevent denormalization */\n\nControlling the Filter\n\nThere are two parameters that control the behavior of the filter: the cutoff frequency\nand the resonance (Q). For a low-pass filter, frequencies above the cutoff frequency will\ngradually fall off. For a high-pass filter, frequencies below the cutoff frequency will\ngradually fall off. The resonance value (a) can be used to increase the amount of feed-\nback in the filter. This can cause frequencies near the cutoff to be emphasized. The fil-\nter can even be made to oscillate at a sufficiently high value of @. A Q value of 1.0 is\nconsidered normal resonance.\n\nCalculating Coefficients for the Filter\n\nThe coefficients that we are using for the various filter types are based on a cookbook\npublished by Robert Bristow-Johnston on the music-dsp mailing list [RBJ]. Note that\nthe A and B coefficient names are reversed relative to his document in order to be\nconsistent with many textbooks. Calculation of coefficients involves trigonometric\ncalculations, which are expensive and should only be performed when the input para-\nmeters change.\n\nDigital filters simply operate on a stream of numbers or samples. For a given set\nof coefficients and input samples, the output samples will be the same regardless of",
      "content_length": 2630,
      "extraction_method": "OCR"
    },
    {
      "page_number": 590,
      "chapter": null,
      "content": "610\n\nSection6 Audio\n\nthe actual sample rate. So before calculating the filter, we convert the cutoff frequency\n(in hertz) to a radial velocity, omega, that is proportional to the sample rate. The sine\nand cosine of omega are used several times in the calculations, so we only calculate\nthem once (sin_omega and cos_omega).\n\nomega = (2.0 * PI * frequency) / samplefate;\n\nsin_omega = sin{ omega );\ncos_omega = cos{ omega );\n\nAll of the coefficients are scaled by a common factor. We fold thar factor into the\ncoefficients instead of doing an extra multiply.\n\nalpha = sin_omega / (2.0 * Q);\nscalar = 1.0 / (1.0 + alpha);\n\nLow-Pass Fliters\n\nLow-pass filters reduce the high frequency content of a sound and pass the low-\nfrequency content.\n\n{* Coefficients for LowPass Filters */\nAO = 0.5 * (1,0 — cos_omega) * scalar;\n\nAil = (1.0 -— cos_omega) * scalar;\nA2 = AO;\n\nBi = -2.0 * cos_omaga * scalar;\nB2 = (1.0 - alpha) * scalar;\n\nLow-pass filters, when combined with reverberation, can make a sound seem\nmore distant. They can be used to make a sound seem muffled when it is behind a\nwall or inside a box or tunnel. Ringing low-pass filters can be use to create unusual |\nalien vocal chirps or synthetic-sounding weapon noises. A whistling wind sound can\nbe produced by passing white noise through a filter and slowly, randomly varying the\ncutoff frequency and @.\n\nHigh-pass filters reduce the low frequency content of a sound and pass the high-\nfrequency content.\n\n/* Goefficients for HighPass Filters */\n\nAQ = 0.5 * (1.0 + cos_omega) * scalar;\nAl = -(1.0 + cos_omega} * scalar;\nA2 = AQ;\n\nB1 = -2.0 * cos_omega * scalar;\n\nB2 = {1.0 - alpha} * scalar;\n\nHigh-pass filters can be used to make a voice sound tinny, like it is on a telephone\nor radio. It can also be used to brighten a sound.",
      "content_length": 1781,
      "extraction_method": "OCR"
    },
    {
      "page_number": 591,
      "chapter": null,
      "content": "6.4 Using the Biquad Resonant Filter 611\n\nBand-Pass Filters\n\nBand-pass filters reduce the frequencies on either side of a center frequency. We call it\na center frequency instead of a cutoff frequency because if you look at the frequency\nresponse curve of a band-pass filter, this frequency will be at the center of the peak.\n\n/* Coefficients for BandPass Filters */\nAO = alpha * scalar;\n\nAt = 0.0;\n\nA2 = -A0;\n\nBi = -2.0 * cos_omega * scalar;\nB2 = {1.0 - alpha) * scalar;\n\nCombining Filters in Serles\n\nYou can combine low-pass and high-pass filters in series by passing the output of one\nfilter to the input of another. Each filter will subtract from the previous filter. You can\nalso combine low-pass and high-pass filters to create custom band-pass filters with a\nbroad pass band.\n\nCombining Filters in Parailel\n\nSeveral filters can be placed in parallel by mixing or adding their outputs together.\nThis collection of filters is called a filter bank. An example is the set of band-pass fil-\nters in a graphical EQ that you might have on your stereo.\n\nCombining three or more band-pass filters can create formats that create vocal\nsounds. These may be useful for creating alien creature sounds.\n\nSoftware\n\nA keyboard-driven C++ program is provided on the CD-ROM thar enables you\nexperiment with all three of the filter types described in this gem. You can pass white\nnoise or an impulse train through the filters to hear how they sound, You can also\nchange the resonance of the filter. The filter frequency is slowly swept up and down\nusing a sine wave. Updates to this software will be posted on the Web at:\nhttp://www.softsynth.com/gamegems/.\n\nThe example program uses PortAudio, which is a simple, cross-platform audio\nAPI. The program should be abie to run on Win32, Macintosh, Unix with OSS, SGI,\nand other platforms. To check for updates to PortAudio for your platform, visit them\non the Web at: http://www.portaudio.com/,\n\nConclusion\n\nA biquad filter gives us a simple way to modify the character of a sound without using\na large amount of memory. It allows us to get more use out of a smaller number of\nsamples, or to generate interesting sounds without the use of any samples. This gem",
      "content_length": 2194,
      "extraction_method": "OCR"
    },
    {
      "page_number": 592,
      "chapter": null,
      "content": "612 Section 6 Audio\n\nshows us how to implement a filter efficiently, and the example software shows us\nhow to filter sounds and play the result.\n\nReferences\n\n[Dodge97] Dodge, Jerse, Computer Music Synthesis, Composition and Performance,\nSimon & Schuster, 1997.\n\n[Moore90] Moore, F. Richard, Elements of Computer Music, Prentice Hall, 1990.\n\n[RBJ] Bristow-Johnson, Robert, “Cookbook Formulae for Audio EQ Biquad Filter\nCoefficients,” available online at http:// http://www.musicdsp.org/.",
      "content_length": 486,
      "extraction_method": "OCR"
    },
    {
      "page_number": 593,
      "chapter": null,
      "content": "Linear Predictive Coding for\nVoice Compression and\nEffects\n\nEddie Edwards\neddie@tinyted.net\n\nvocoder is a device for altering speech, now made famous by that Cher song,\n\nLieve [Cher98]. Vocoders are best known for the robot voices they produce,\n\nfrom daleks in the Dr. Who series [Nation63] to the battle droids in Star Wars\n\n[Lucas99], but they can also produce bizarre alien voices, as well as “singing” guitars\n\nand similar effects. In addition, vocoders are used as the basis for several voice-com-\npression methods, including the GSM digital mobile phone standard [ETSIOO}.\n\nAlthough voice effects and voice compression seem like different problems, the\nsame approach can apply to both. The program on the CD-ROM demonstrates voice\neffects, but a side effect of the approach is that only 500 bytes of data are required per\nsecond—this is 350 times fess data than CD audio, which would allow us to store\nalmost three weeks of speech on one CD-ROM! The full GSM algorithm is available\nin the public domain [Degener00} and achieves about 200:1 compression over CD\naudio.\n\nThis sort of magic can happen because of the way a vocoder works. There are sev-\neral different types of vocoders, but they all work on the same basic principle: Split\nthe sound up into constituent parts (analysis), manipulate the parts, and then put\nthem back together again (resynthesis). We can then either play around with the data\nin the middle to create effects, or we can compress it. Clearly, we can also store and\nretrieve it, so the analysis and synthesis parts do not have to happen together—or\neven on the same machine. A vocoder is like any codec in this respect, with logically\ndistinct encoding and decoding phases (see Figure 6.5.1).\n\nConsider comparing this arrangement with the familiar set up of JPEG compres-\nsion. There, each block of pixels is transformed into the frequency domain (analysis),\nwhere it can be more easily compressed. The pixels are transformed back again (resyn-\nthesis) when the JPEG is decompressed.\n\nA vocoder is ultimately defined by which algorithm it uses for analysis and resyn-\nthesis. When that algorithm is the Fast Fourier Transform (FFT), we get a phase\n\n613",
      "content_length": 2183,
      "extraction_method": "OCR"
    },
    {
      "page_number": 594,
      "chapter": null,
      "content": "614 Section6 Audio\n‘eneoder | yr  hr7TC~<—~;<3OCU”; Decoder!\nFIGURE 6.5.1 A vocoder.\nvocoder. The algorithm we present here is called linear predictive coding (LPC) and\ngives us an LPC vocoder.\n\nModeling the Voice\n\nLPC attempts to model the way speech is produced in the human body, but in such a\ngeneral way that it can also model sound production under different circumstances.\nThe basic model has only two parts, which are usually termed the oscillator and the\n\nresonator (see Figure 6.5.2).\n\nOscillator Voice Signal\n\nFigure6.5.2 The LPC model.\n\nYou can't produce a sound without an oscillator—this is the physical object that\nvibrates, producing sound waves. Anything that makes a sound contains some kind of\noscillator, from a played violin (the strings) to a pencil dropped on a desk (the pencil\nvibrates). The human voice is no exception; the person's vocal chords is che oscillator.",
      "content_length": 890,
      "extraction_method": "OCR"
    },
    {
      "page_number": 595,
      "chapter": null,
      "content": "6.6 Linear Predictive Coding for Volce Compression and Effects 615\n\nOscillators are well understood, and simulating them on a computer provides little\nchallenge.\n\nMany systems make a sound of one form or another, but some are designed to do\nso (either by evolution or ingenuity). These systems are distinguished by the presence\nof a resonator. A resonator acts as a natural amplifier for the sound produced by the\noscillator. All musical instruments have them—for instance, an acoustic guitar has a\nhollow body that amplifies the strings (an electric guitar has a solid body, and its\nstrings are virtually inaudible until you plug the guitar into an amplifier). However,\nthe resonator isn’t a simple amplifier, by any means. It amplifies different frequencies\nby different amounts, depending on the characteristics of the resonator. In violins, the\nresonance helps to actually reduce inharmonic sounds from the strings. It is the qual-\nity of the resonator in a violin that distinguishes a Stradivarius from a Yamaha. In\nbrass instruments, the only way to produce different notes is to change the configura-\ntion of the resonator, since the oscillator (mouthpiece) is incapable of changing pitch.\nBy pressing a key, the player opens an air vent in the side of the resonator, changing its\ncharacteristics and producing a new note.\n\nThe resonator in the human voice is formed by the human head—-specifically, the\ninterior cavities of the head, through which the sound from the vocal chords travels\nbefore it reaches the mouth. This resonator is certainly not fixed, and by moving the\ntongue, jaw, and lips, the speaker can change the resonator’s characteristics quite\nquickly. If you hum with your vocal chords and make your mouth larger and smaller\nyou can hear the effect—clearly, most word sounds come from this mechanism and\nnot the vocal chords. (There are other mechanisms at work too, which we discuss\nlater.)\n\nSince the resonator can change its characteristics over time, we break the model-\ning process up into frames of around 20 ms each. The resonator is assumed to have\nfixed characteristics over a single frame. The size of each frame is a parameter to the\nLPC algorithm.\n\nA Software Simulation\n\nSimulating this model in software is actually fairly straightforward. The oscillator can\nbe simulated with a sample player, and the resonator is modeled with a digital filter.\nThe oscillator feeds samples to the filter, and speech is produced.\n\nThe digital filter is quite simple in principle. It takes a sequence of input samples\nand produces a sequence of filtered output samples. The filter works by calculating\neach output sample as a weighted sum of the previous NV input samples. The weights\ndetermine the filter’s characteristics. This is usually implemented as a function that\ntakes a single parameter (the most recent sample) and remembers the last N samples\nin an internal state vector.\n\nIn LPC, we use a slightly different formulation, which is more physical than\nmathematical in nature. We model the resonator as a long pipe made up of segments\nof different widths. When a sound wave travels between two segments, some is",
      "content_length": 3140,
      "extraction_method": "OCR"
    },
    {
      "page_number": 596,
      "chapter": null,
      "content": "616\n\nSection 6 Audio\n\nreflected. The amount that is reflected at each point is given by a reflection coefficient.\nA set of these coefficients describes the whole tube, and the number of coefficients is\na parameter of the LPC algorithm. The filter keeps a state vector corresponding to the\npressure in each segment. This allows reflected waves to actually travel back down\nthe simulated tube. The function given below does the work.\n\nff s = input sample\n\n// FFSE] = forward filter state\n\n// re[] = reflection coefficients\n\nfor {int ii = order; ii-;)\n\n{\n/{ s -= FFS[ii] * rcfii]\n// FFS'[ii + 1] = FFS[ii] + s * re[ii]\ns -= FFS[ii] * re[ii];\nFFS[ii + 1] = FFS{ii] + s * re[ii];\n}\nreturn 5;\n\nAn interesting note is that this function is invertible, and this is the key to LPC\n(see Figure 6.5.3). If we invert that filter and run the speech through it, we will get the\noscillator output signal. (When we run the filter this way, the oscillator signal is called\nthe residual.) The inverse of this function is listed here.\n\n// s = input sample\n/}/ IFS[] = inverse filter state\n// re{] = reflection coefficients\n\nfloat ifsp = s;\n\nfor (int ii = 0; ii < order; iit+)\n\n{\n// IFS'{ii + 1] = IFS[ii] + s * re[iil]\n// s += IFS{ii] * re[ii]\nfloat tmp = IFS[{ii] + s * rc[ii];\ns += IFS[ii] * re[ii];\nIFS[ii] = ifsp;\nifsp = tmp;\n}\nreturn s;\n\nThis is exactly what we need. In our analysis phase, we have the speech signal, but\nnot the oscillator signal. Now we can extract the oscillator signal (residual) to be used\nfor resynthesis. All we need are the reflection coefficients. The problem is that any set\nof coefficients will do. Each will produce some kind of “oscillator signal” when run\nthrough the code above. We need to choose the set of coefficients that gives us the\n“best” oscillator signal in some sense.\n\nLPC defines the best residual to be the one that has the least energy in it. This is\nreasonable, since it means that the inverse filter has removed the highest-energy parts",
      "content_length": 1970,
      "extraction_method": "OCR"
    },
    {
      "page_number": 597,
      "chapter": null,
      "content": "6.5 Linear Predictive Coding for Volce Compression and Effects 617\n\n| Sonia\n\nVoice Signal\n\nOscillator Signal\n\nFIGURE 6.5.3 Reversing the filter.\n\nof the signal—that is, che most important ones. The forward filter will then re-\nemphasize those parts of the signal.\n\nSolving this then becomes a matter of constructing a large, simultaneous linear\nequation and finding the least-squares solution to it. Describing this in detail is\nbeyond the scope of this gem, but the basics might be found in a suitable linear alge-\nbra text. The code on the CD-ROM uses Schur’s algorithm [Degener94], which is\nhighly optimized for this specific case. This is reproduced as follows:\n\n// G{), HI] = working arrays\n// AC{] = autocorrelation vector for input signal\n\nfi refi (output} reflection coefficients\nfor (ii = 0; ii < order; iit+)\n{\n\nG[ii] = H[ii) = AC[ii + 1];\n\n// one iteration per coefficient\n\nfor (ii = 0; ii < order; ii++}\n\nf\n// calculate re and update error\nfloat r = -H[O] / error;\n\nre[ii] = r;\nerror t= H[O] * Fr;\n\n// update G&H\nfor (int m = 0; m < order - ii; mtt+)\n\nH[m] = H{m + 1} + r * Gm];\nG[m] = H[m + 1] * r + G[m];",
      "content_length": 1118,
      "extraction_method": "OCR"
    },
    {
      "page_number": 598,
      "chapter": null,
      "content": "Section 6 Audio\n\nThe code in linearpredictor.cpp performs all these tasks and provides a black-box\nsolution for LPC coding. We are left with a two-step process—analysis plus synthe-\nsis—which (barring rounding errors) reproduces the original speech sample precisely.\nThe only parameters are frame time (in samples) and filter complexity (number of\nreflection coefficients). The test code uses frames of 20 ms (160 samples at 8 kHz)\nand eight reflection coefficients.\n\nReplacing the Vocal Chords\n\nOnce the LPC encoder has done its magic, we will want to play around a lictle to cre-\nate our robot or alien voices. The easiest thing to do is to replace the oscillator signal\nwith a synthesized sound. This synthesized sound is then filtered, and the end result is\nas if the synthesizer were in the speaker's throat instead of his own!\n\nThe important thing to remember here is that the synthesized sound is merely\nbeing filtered, so any frequencies that are not in the sound to begin with will not be in\nit afterwards. If we use a simple sine wave, it only contains a single frequency and will\nnot generate interesting sounds. It would be like illuminating a multicolored mural\nwith monochromatic laser light—only the single color is reflected back. So we must\ntry to use a sound that is rich in frequency content.\n\nThe best choices are a pulse waveform or a sawtooth waveform, since these con-\ntain all the harmonics, A square waveform contains all odd-numbered harmonics.\nThese choices all give relatively intelligible “robotic” speech, and they are all very\nquick to generate in code.\n\nAlternatively, a bass-heavy waveform will give a bass-heavy voice; and one with\nonly certain frequencies will remain tuned to those frequencies, which will be modu-\nlated. These choices give more alien-sounding voices, with weirder input waveforms\ngiving weirder speech sounds—although you can no longer hear what is being said!\nSlightly more complex waveforms can be obtained through FM synthesis.\n\nA sample can simply be played back as well. If that sample is the residual, we get\nexcellent-quality results (perfect, allowing for rounding errors). If it is something else,\nlike a guitar riff, we get a bizarre, “speaking-guitar” effect: an “all your base are belong\nto us” pedal instead of just a “wah” pedal!\n\nAnother interesting choice is simple white noise. When we whisper, we do not\nactivate our vocal chords at all, and the oscillator signal is just a hiss. We also seem to\ntone down our intonation. Using noise with a line spoken loudly produces a strange\nkind of hybrid “whisper” that sounds quite evil.\n\nControlling the Resynthesizer\n\nThe only difficult part of generating the new oscillator signal is getting the pitch and\nvolume right. These can be extracted (with some difficulty) from the residual.\n\nThe volume is the most important factor, since you need silence in the right\nplaces. It is also the easiest to calculate, by performing a root-mean-square calculation",
      "content_length": 2967,
      "extraction_method": "OCR"
    },
    {
      "page_number": 599,
      "chapter": null,
      "content": "6.5 Linear Predictive Coding for Voice Compression and Effects 619\n\nover the residual for each frame of the sound. In output, it is a good idea to interpo-\nlate this volume so the sound doesn't click or pop.\n\nPitch is more difficult. The method used on the CD-ROM works as follows.\nFirst, assume the pitch is less than 1 kHz, and filter the residual using a low-pass filter\nto remove any frequencies higher than this. Then, normalize the waveform and cen-\nter-clip it. This distorts the waveform so that it looks like a series of spikes. Next,\ncompare this waveform with a set of pulse waveforms of different frequencies, and\nchoose the best match (by a least-squares comparison). Finally, for each frame, choose\nthe median pitch calculated for the last three frames (this helps smooth the results\nout). The method is by no means perfect—it is just as much of a hack as it sounds!\nNevertheless, it gives reasonable results—the oscillator seems to follow the lilt of the\ninput speech quite well, and some amount of unrealism is actually desirable!\n\nThe production of each frame now progresses according to the diagram shown in\nFigure 6.5.4. The pitch and volume for each frame control the synthesizer, which is\ncreating a waveform according to the parameters chosen for a specific speaker. This\nwaveform then passes through the filter to give the resultant resynthesized speech.\nNote that another possibility is not shown on the diagram—the frame size on output\ncan be different to the frame size on the input. By doing this, the speech can be sped\nup or slowed down relative to the input speech.\n\nNote that the parameters of the speech (pitch, volume, and reflection coefficients)\nare separate from the parameters of the speaker (they control the synthesizer parame-\n\nDigital Filter Voice Signal\n\nSynthesizer\n\nSpeaker Parms\n\nFIGURE 6.5.4 The speech resynthesizer.",
      "content_length": 1863,
      "extraction_method": "OCR"
    },
    {
      "page_number": 600,
      "chapter": null,
      "content": "Section 6 Audio\n\nters and the speed). So, the same speech data can in principle be used with a variety of\nspeakers. For instance, every robot might have a different pitch so that the player can\ntell them apart, or some robots might speak more slowly than others. Damage might\neven affect this, so a broken robot might speak very fast!\n\nIncreasing the Depth of the Speaker\n\nSince our reflection coefficients reflect a physical model of a resonator, we can change\nthe resonator by changing the coefficients. The easiest thing to do is to make it longer,\nand hence deeper. If we begin with 8 reflection coefficients, we could generate 16\ncoefficients by inserting zeroes between the numbers. The result is a deeper resonance\n(one octave lower), which sounds more evil.\n\nAlternatively, by cropping reflection coefficients off, the filter becomes more\n‘shallow-—the speech becomes indistinct and sounds as if the speaker has just been to\nthe dentist. Processing the reflection coefficients is much less intuitive than processing\nthe residual, but many effects are possible in theory.\n\nEncoding the Data\n\nGiven the pitch, volume, and eight reflection coefficients, we now have 10 numbers\nper frame describing everything we need to generate a robotic or alien voice. If we\nquantize each number into a single byte, that translates to only 500 bytes per second,\nor 30 KB per minute, as quoted earlier.\n\nFor some games, this is as far as we need to go. Other games might require\nhigher-quality speech, or more natural, human-like speech. Perhaps we could try to\ngenerate a variety of male voices from a single source sample. It is the encoding that\nmust be addressed in these cases.\n\nThe residual signal is quite hard to encode, because it does contain a lot of\n“missed” information. For instance, most speech sounds use the vocal chords, but\nsome ate unvoiced, which means the vocal chords are relaxed, and just a hiss of air is\nreleased into the vocal cavity. The letter “s” is a good example. In these cases, the resid-\nual is like white noise. We could improve the encoding by trying to detect white noise\nin this case.\n\nOther sounds, like a “p”, are made by a different process altogether-—in this case,\nthe air “explodes” through the lips making the p-sound. These sounds are called\nplosives. The plosive is not well modeled by the vocal-chord-plus-filter model, so most\nof the information ends up in the residual. We might be able to model these sounds\ntoo, if we spent enough time on it.\n\nTo capture all these nuances simply, we should encode the entire residual. Then,\nthe recreated speech will be as near as possible to the real thing. There are many ways\nwe might do this—vector quantization, peak detection, or ADPCM coding for\ninstance. We might even happily store the entire residual as a PCM waveform. We\nwont have saved space (quite the opposite), but the cost might be worth it if we can",
      "content_length": 2894,
      "extraction_method": "OCR"
    },
    {
      "page_number": 601,
      "chapter": null,
      "content": "6.5 Linear Predictive Coding for Volce Compression and Effects 621\n\nperform special effects very cheaply. [Degener94] describes how GSM [ETSI00]\nencodes the residual into about 1.5 kbps (kilobits per second).\n\nSpeed\n\nNot only does the algorithm bless us with low data rates, it also performs admirably\n(even on consoles from two generations ago). While encoding is difficult to get into\nreal-time, decoding is very fast indeed.\n\nThe core of the replay algorithm is the filter. This performs two loads, two adds\nand two multiplies per coefficient per sample. Assuming eight reflection coefficients,\nthis is about 50 cycles per sample, or 400,000 cycles per second at eight kilohertz. An\nunoptimized version would, of course, be slower; while a vectorized version could be\na lot faster (if the hardware supports it).\n\nIn an optimized implementation, the waveform generator would be combined\nwith the filter in the inner loop, alongside the envelope generator, using only a few\ncycles per sample. The creation of speech therefore takes around 500,000 cycles per\nsecond—only 3% of a 16-MHz processor.\n\nEncoding is less critical for game purposes, unless you want to use LPC to transmit\nspeech across the Internet. In this case, some work would have to be done on the encod-\ning end, but a current-generation machine should be able to handle this fairly easily.\n\nExperiments\n\nThe program on the CD-ROM demonstrates almost everything this gem has\ndescribed, so please play with it for a while. You can load speech samples into the pro-\ngram (an example is supplied), which converts them using the LPC algorithm. These\ncan be played back using either the residual or a voice defined in the program. Several\nexample voices are supplied. The program includes full source code (Microsoft Visual\nC++), and full instructions are provided in the ReadMe.xxt file.\n\nReferences\n\n[Cher98] Cher, Befeve, WEA/Warner Bros., 1998.\n\n[Degener94] Degener, Jutta, “Digital Speech Compression,” Dr. Dobbs Journal\n(Wecember 1994), available online at http://www.ddj.com/documents/s=1012/\n\nj9412b/.\n\n[Degener00] Degener, Jutta, “GSM 06.10 Lossy Speech Compression,” available\nonline at hrep://kbs.cs.tu-berlin.de/~jutta/toast.html, July 2000.\n\n[ETSIOO] “Digital Cellular Telecommunications System (Phase 2+); Full Rate\nSpeech; Transcoding,” (GSM 06.10 version 5.2.1 Release 1996), Third Edition,\nEuropean Telecommunications Standards Institute, 2000. Available online (free\nregistration required) at heep:/ webapp <tsi.org/pday.\n\n[Lucas99] Lucas, George, The Phantom Menace, 20th Century Fox, 1999.\n\n[Nation63] Nation, Terry, Dr. Who: The Dead Planet, British Broadcasting Corpora-\ntion, 1963.",
      "content_length": 2665,
      "extraction_method": "OCR"
    },
    {
      "page_number": 602,
      "chapter": null,
      "content": "The Stochastic Synthesis of\nComplex Sounds\n\nPhil Burk, SoftSynth.com\nphilburk@softsynth.com\n\ntochastic synthesis is a type of audio synthesis that uses random numbers. You\n\ncan use random numbers at a low level to generate noise. This noise can be used\nas a sound source or a modulation source. You can also use random numbers at a\nhigher level to control sounds or to trigger sounds. These randomly controlled and\ntriggered sounds can then be used to create soundscapes.\n\nMost games use digital audio samples to create sounds. One advantage of using\nsamples is that they accurately reproduce the original sound. However, a disadvantage\nof using samples is that they can be repetitive. You can change the sample's playback\nrate and its amplitude, but that doesn’t eliminate the repetitiveness. Real-world\nsounds do not sound the same every time. Take, for example, a dog’s barking. Each\nbark is a little different. A dog that barked exactly the same every time would be\nsuspect.\n\nSamples are sometimes used to create continuous sounds, such as wind. However,\nthis method eventually requires samples to loop, and the repetition can be audible. A\nsolution to this problem is to synthesize the sounds directly. An advantage of using\nsynthesis is that the sound designer has control over many more parameters. You can\nchange the character of the synthesized wind by making it whistle, or you can make it\nfluctuate more rapidly. You are not limited to just amplitude and pitch changes.\n\nWe will provide examples including wind, sonar pings, rain, rocket engines, and\nhelicopter rotors. The examples will be constructed out of simple, atomic units called\nunit generators. These will include filters, noise generators, oscillators or tone genera-\ntors, and effects processors, such as reverbs.\n\nLinear Congruential Algorithm\n\nYou cannot generate truly random numbers using software. This is because comput-\ners generate reproducible, deterministic results, Like most game programmers, how-\never, we ate not above cheating. We can generate sequences of numbers, which will\nsound random, even if they aren't really random.",
      "content_length": 2113,
      "extraction_method": "OCR"
    },
    {
      "page_number": 603,
      "chapter": null,
      "content": "6.6 The Stochastic Synthesis of Comptex Sounds 623\n\nThe most common and cheapest pseudo-random number generator is the linear\ncongruential algorithm (LCA). It is based on doing multiplications and additions,\nand producing a numerical result that is so large that it overflows the word size of the\ncomputer. By carefully selecting the coefficients of the equation, we can generate a\nsequence of 2°? numbers before repeating the sequence [Chamberlin80]. If we gener-\nate a stream of samples at 44,100 Hz, then it would only repeat after 27 hours.\n\nTo use the LCA function described here, pass a starting value co the function,\nthen feed the result back into the function to generate a sequence of random\nnumbers.\n\n/* Calculate pseudo-random 32 bit number using\n* the linear congruential method. */\nstatic unsigned long GenerateRandomNumber (\nunsigned long previous }\n\nreturn ((previous * 196314165) + 907633515};\n}\n\nThe most significant bits of this function are more random than the lower bits.\nSo, if you want to generate 16-bit random numbers, shift right and use the top 16 bits\ninstead of masking off the lower 16 bits.\n\nTypes of Noise\n\nThe direct result of the Linear Congruential Algorithm is white noise, which sounds\nlike static (“shshshsh”). White noise contains equal energy across the entire frequency\nspectrum. By modifying the algorithm, you can generate noise with different spectra.\n\nYou can generate red noise by calculating a new random number every few sam-\nples and interpolating between them for the intervening samples. This method,\nwhich is demonstrated by the following code and Figure 6.6.1, gives you some very\nsimple control over the frequency content.\n\n// phase ranges from 0.0 to 1.0\nphase += phaseInc;\nif( phase >= 1.0 }\n{\n// grab a new random target whenever the phase wraps\nsource = target;\ntarget = randomFloat(};\ndelta = target - source;\nphase -= 1.0f;\n\n// linear interpolation between random values\noutputs[O) = source + {phase * delta);\n\nYou can also generate noisy signals using fractal mathematics {feedback on non-\nlinear functions). An example is a simple sine wave with feedback [Roads96]. Iterate\nover the following code to generate samples or a control signal.",
      "content_length": 2201,
      "extraction_method": "OCR"
    },
    {
      "page_number": 604,
      "chapter": null,
      "content": "Section 6 Audio\n\nFIGURE 6.8.1 (Left) White noise with new random values for every sample. (Right) Red\nnoise with samples interpolated between random values.\n\nPhase += phaseIncrement + (feedback * x );\nif( phase > 1.0 } phase -= 2.0;\n\nelse if( phase < -1.0 } phase t= 2.0;\n\nx = sin{ PI * phase );\n\nIn this example, phase ranges from —1.0 to 1.0. As you raise the feedback coeffi-\ncient, you will start to get a noisy, chaotic signal.\n\nSoftware Examples\n\nThe following sections describe actual examples using the techniques described. The\nsource code to the various components described is on the CD-ROM.\n\nGenerating a Wind Sound\n\nA wind sound can be generated using a white noise generator (WhiteNoise) as the\nsound source. The noise signal passes through a low-pass filter (LowPassFilter) with\na frequency of 1000 Hz. By increasing the @ of the filter to around 16, you can make\na good whistling wind sound.\n\nSee Figure 6.6.2 for an overview of the wind example. A red noise generator (Red -\nNoise) controls the cutoff frequency of the filter and mimics the random rising and\nfalling of the wind, The modRate parameter controls how rapidly the wind fluctuates.\nThe modDepth controls the size of the fluctuation. You then multiply the RedNoise\noutput by the modDepth and add the result to the frequency value to generate the\nactual cutoff frequency value for the filter, Mixing (or adding) together several of\nthese generators will create a more realistic sound. Try setting mo¢Rate to 0.6, and\nmodDepth to 350.\n\nGenerating a Sonar Ping\n\nA sonar ping sound consists of a short sine wave burst that echoes off various objects\nunderwater. The sound slowly fades away over time. We can generate the sine burst\nby hitting a resonant LowPass filter with an impulse spike, similar to hitting 2 bell",
      "content_length": 1791,
      "extraction_method": "OCR"
    },
    {
      "page_number": 605,
      "chapter": null,
      "content": "6.6 The Stochastic Synthesis of Complex Sounds 625\n\nFIGURE 6.6.2 A wind sound example.\n\nwith a hammer. To implement this, you want to set the filter cutoff frequency to\nabout 700 Hz. To make the filter ring for a longer time, set the @ to larger values, like\n1000. To increase the sound of the ‘ping’ try setting the Impulse amplitude to seven.\n\nThe sound we have so far is just a pure sound wave. To make it sound like it is\nreflecting off of submerged objects, we need to roughen it up a bit. We could add\nlarge amounts of reverb, but there is a cheaper trick, which should appeal to game\ndevelopers. We can modulate the LowPassFilter cutoff frequency by using a RedNoise\ngenerator. Set the RedNoise frequency to about 180 Hz and its amplitude to about 80\nfor the desired result.\n\nThe circuit is identical to the wind sound example shown in Figure 6.6.1, except\nthat an ImpulseOscillator replaces the WhiteNoise generator.\n\nGenerating the Sound of Rain\n\nThe sound of rain is composed of the sounds produced by millions of raindrops hit-\nting cars, trees, windows, dogs, etc. We cannot generate the sound of each individual\nraindrop, but we can come close. When each raindrop hits, it generates a little ‘plop’\nsound. We could. assign an oscillator to each plop sound, but we would need too\nmany oscillators. So, instead we use the familiar ringing filter to generate the plop. An\nadvantage to using a ringing filter is that we can hit one filter with lots of little\nimpulses and get the same result as if we had a filter per impulse. We set the filter fre-\nquency to 250 and the 0 to 2.\n\nThe ringing filter will always generate the same pitch every time we hit it unless\nwe modulate the frequency. We can frequency modulate the filter using a fast Red-",
      "content_length": 1754,
      "extraction_method": "OCR"
    },
    {
      "page_number": 606,
      "chapter": null,
      "content": "Section& Audio\n\nNoise generator, as we have in the previous examples. We set the modrate to 10 and\nthe modDepth to 90 to achieve the desired resule.\n\nThe next trick is to generate lots of randomly distributed impulses to feed the fil-\nter. We can use a comparator to look at a random signal, Whenever the signal exceeds\nthe threshold, we can output a random value, as in the code shown here. Otherwise,\nwe output zero. This will give us occasional random pulses that we can use to excite,\nor ping the filter (see Figure 6.6.3).\n\nthreshold = 1.0 — rates;\nexcitation = (nextRandom(} > threshold) 7\nNextRandom {) : 0.0;\n\nPoissonTrigger Lowpass Filter\n\nFIGURE 6.6.3 A rain example. Two raindrop generators share a reverb.\n\nWe can use the rate value above to adjust how hard it is raining.\n\nThe ringing filter will give us the sound of individual raindrops that are near to\nus. Now, we need to generate the millions of drops in the surrounding area that make\nup the dull roar of rain. We can use a reverb effects processor to echo the sound of a\nfew raindrops and create the sound of many raindrops. The reverb is constructed\nfrom six comb filters and an all-pass filter. [Moore90]. The comb filters include a low-\npass filter that muffles the sound of the other raindrops and makes them seem farther\naway. The reverb also uses a much longer delay than normal, between 200 ms and\n350 ms, so that the echo effect is less noticeable. We then mix the close raindrop\nsound with the reverberated sound to get a complete rain sound, as shown above in\nFigure 6.6.3.",
      "content_length": 1553,
      "extraction_method": "OCR"
    },
    {
      "page_number": 607,
      "chapter": null,
      "content": "6.6 The Stochastic Synthesis of Compiex Sounds 627\n\nYou could add different resonators to this patch to simulate the sound of rain hit-\nting a tin roof or a glass skylight. Just replace the low-pass filter with a more-complex\nformant filter bank or cross-coupled modal filters.\n\nGenerating a Rocket Engine Sound\n\nA decent rocket engine sound can be generated using just two RedNoise generators. A\nsingle RedNoise generator has a discernable pitch and doesn't have the crackle of a\ngood rocket sound. So we can use one RedNoise generator to medulate the frequency\nof another. You want to set the center frequency of the carrier, the RedNoise that you\nhear, to 1300 Hz, and set che modulator’s frequency to a value around 731 Hz. Avoid\nhaving the modulator frequencies be a simple ratio of the carrier, and set the modula-\ntor amplitude to about 600 Hz.\n\nWe also need a way to quickly ramp the sound’s amplitude up and down as we\nturn the rocket on and off. Imagine a thruster firing under a pilot’s control. We can do\nthis with a slew rate limiter. The limiter tracks its input but won't move faster than a\ngiven rate, as shown in the code that follows. This allows us to suddenly set the ampli-\ntude to zero, but the actual level will drop more slowly.\n\nif{ input > value )\n{\nvalue += increment;\nif{ value > input } value = input;\n\nelse if( input < value }\n\n{\n\nvalue -= increment;\n\nif( value < input ) value = input;\n\n}\n\nWe then control the output amplitude of the circuit by multiplying the RedNoise\nsignal by the SlewRateLimiter value. Figure 6.6.4 illustrates the rocket engine sound\nlogic.\n\nGenerating a Helicopter Rotor Sound\n\nThe noise from a helicopter has two main components, the engine noise and the rotor\nnoise. The rotors cut through the air, causing a whooshing sound. Because the rotors\nare spinning, they are sometimes going away from us and sometimes coming toward\nus. This causes a Doppler shift that raises and lowers the pitch of the whoosh. Imag-\nine a car driving past you on a road. It sounds higher pitched when it is approaching\nyou and lower pitched as it goes away. This is because the sound waves are compressed\nas the car moves toward you, and shorter wavelengths have a higher frequency.\n\nThis sound uses filtered white noise as the source sound as in the wind example.\nIt then passes the sound through two variable delays. The two delays are swept back\nand forth using a sine wave modulator, Set the sine waves 180° out of phase to model",
      "content_length": 2467,
      "extraction_method": "OCR"
    },
    {
      "page_number": 608,
      "chapter": null,
      "content": "FIGURE 6.6.4 Rocket engine sound using red noise pair and an envelope generated by a\nslew rate limiter.\n\ntwo blades opposite each other. So, as one delay is increasing, the other is decreasing.\nThis is illustrated in Figure 6.6.5.\n\nNext, we can tune the delay times to match the diameter of the rotor blades, The\nminimum delay time is when the blade is closest to us, and vice versa.\n\ndelayRange = rotorDiameter / speedOfSound;\nmodDepth = delayRange / 2.0;\n\nA UH-1 Huey helicopter has a rotor diameter of 48 feet. The speed of sound is\napproximately 1100 feet per second, so the modDepth for the Doppler shift is about\n0.022 seconds. The previous code example generates the proper modDepth.\n\nmodDepth\n\nFIGURE 6.6.5 Helicopter rotor sound created using Doppler shifts 180° out of phase.",
      "content_length": 785,
      "extraction_method": "OCR"
    },
    {
      "page_number": 609,
      "chapter": null,
      "content": "6.6 The Stochastic Synthesis of Complex Sounds 629\n\nSoftware\n\nA keyboard-driven C++ program is provided on the CD-ROM that enables you to\nexperiment with these sounds. You can turn sounds on and off, and change parame-\nters interactively. Look in the index.html file for more information on the software\ndesign. To check for updates to this software, visit [Softsynth02].\n\nThe example program uses PortAudio, which is a simple, cross-platform audio\nAPI. So, the program should be able to run on Win32, Macintosh, Unix with OSS,\nSGI, and other platforms. To check for updates to PortAudio or to get source code for\nyour platform, visit [PortAudio01).\n\nOM THE CD\n\nConclusion\n\nUsing just a few simple unit generators, you can synthesize a wide variety of sounds\nwithout the use of samples. This gives you more control over the sound parameters\nand helps you avoid the artifacts associated with sample loops. Stochastic functions\nare particularly useful because they can add a lot of complexity without adding a sig-\nnificant computational load. The technique of modulating a single filter with Red-\nNoise is particularly handy and can be used to replace multiple unmodulated filters.\nStochastic processes are also useful at a higher level to trigger short sound events, such\nas raindrops. Reverberation can be used to make it sound like there are many more\nsound generators than are actually present in the circuit. Hopefully, these techniques\ncan be used to add some sonic spice in your next game.\n\nReferences\n\n[Chamberlin80] Chamberlin, Hal, Musical Applications of Microprocessors, Hayden,\n1980.\n\n[Dodge97] Dodge, Jerse, Computer Music Synthesis, Composition and Performance,\nSimon & Schuster, 1997.\n\n[Moore90] Moore, FE. Richard, Elements of Computer Music, Prentice Hall, 1990.\n\n[PortAudio01] Bencina, Ross, “PortAudio—an Open-Source Cross-Platform Audio\nAPI,” available online at http://www.portaudio.com/, 2001.\n\n[Roads96] Roads, Curtis, The Computer Music Tutorial, MIT Press, 1996.\n\n[SoftsynthO2] Burk, Phil, “Biquad Filters and Stochastic Synthesis,” available online\nat http://www.softsynth.com/gamegems/, 2002.",
      "content_length": 2119,
      "extraction_method": "OCR"
    },
    {
      "page_number": 610,
      "chapter": null,
      "content": "6.7\n\nReal-Time Modular Audio\nProcessing for Games\n\nFrank Luchs, Visiomedia Software\n\nCorporation\ngemsaudio@visiomedia.com\n\nhis gem will describe how to incorporate modular audio processing into your\n\ngame to procedurally generate sounds in real-time, Often games use one-shot or\nlooped samples to play game sounds. While this can frequently be effective, these sta-\ntic one-shot or looped samples are limited in how they can change in response to user\nactions, Procedural sound generation with modular audio processing provides many\nmore controls and variations that offer greater realism of sound interaction through a\ngreater interaction berween gameplay and audio.\n\nSound can shape the picture as much as the picture can shape the sound. Real-\ntime procedural audio should become part of a continuum, changing dynamically\nover time—sometimes subliminal and sometimes impressive. It should resonate with\nthe game's environment and flow with the player's interaction.\n\nModular Audio Processing\n\nModular audio processing systems can be created in software using virtual modules\nand cables that are quite similar to those of vintage modular synthesizer systems. Both\nsystems have no fixed signal path. You create a sound by connecting units like oscilla-\ntors, filters, and envelope generators—building an audio chain. Using units makes it\npossible to synthesize various sounds with maximum flexibility, without the need for\nhard-coding all the countless possible connections.\n\nThe data flow of audio processing is determined by the connections that are cho-\nsen between the units. The units are encapsulated entities that perform specific opet-\nations on the data stream.\n\nForty years ago, synthesizers were so large that they filled up an entire room, and.\nthe only way to save a patch with all its connections was by shooting a Polaroid.\nToday pure-software systems allow you to create and save millions of patches on your\nhard disk. Patches are created by appending DSP units to a processing chain. Com-\nplex components can be built on top of simpler patches, using units that represent\nfamiliar mathematical operations,",
      "content_length": 2123,
      "extraction_method": "OCR"
    },
    {
      "page_number": 611,
      "chapter": null,
      "content": "6.7 Real-Time Modular Audio Processing for Games 631\n\nAs with the vintage hardware monsters, a deep knowledge of digital signal pro-\ncessing is not required, since you can learn by ear while experimenting with connec-\ntions between modules.\n\nProcedural Sound Generation\n\nThere is a great variety of procedural sound-generation methods, and many have a\nlong history in electronic synthesis. Here, we mention some of the common tech-\nniques used by many synthesizers that are both effective and practical for current real-\ntime software synthesis.\n\nClassical synthesizers are based on the idea of subtractive synthesis. The typical\nsubtractive synthesizer has an oscillator that generates the basic audio tone, mostly a\nharmonically rich waveform. This sound goes through a low-pass filter, truncating\nthe upper harmonics, and finally through an amplifier. Each stage can have its own\nmodulators; so over time, the sound changes dynamically in pitch, timbre, and\nloudness.\n\n‘Two types of modulators are common. One is the low-frequency oscillator\n(LFO), which is an oscillator running in the subaudio range (below 20 Hz). It pro-\nduces cyclic modulations. Connected to an audio oscillator, you will get vibrato. Con-\nnected to a filter, you get a kind of “wah-wah.” Connected to the amplifier, the result\nis a tremolo effect. The other modulator is the envelope generator (EG) for one-shot\nmodulations, often triggered by the keyboard. The EG gives the sound a shape.\n\nAnother important synthesis method is FM modulation, a frequency (or phase)\nmodulation in audio range. This is perfect for creating a rich spectrum from of a few\noscillators. Of course, oscillators can also provide simple linear-interpolated wavetable\nplayback. (For additional information on historical applications of synthesis, see\n[Smith91].}\n\nThe Sphinx MMOS System\n\nIn the following sections, we introduce a system called “Sphinx MMOS,” which can\nbe used to generate procedural sounds in your games. Source code and executables for\nthis system can be found on the CD-ROM.\n\nSphinx MMOS builds on the ideas of PD [PDRef}, MAX [MAXRef], and Gen-\nerator [GENRef], with an extensible object-oriented model that allows users to create\ninstruments at different levels. It simplifies development of audio applications using\nthe well-known patch model.\n\nDifferent terms are used for the individual elements of such a system. Table 6.7.1\ncompares the terminology used in Sphinx MMOS with other common terms.\n\nSphinx MMOS is a data flow-oriented system. In such a system, you build a data-\nprocessing network by connecting primitive units together. Each unit (here called a\n“processor”) has input pins that accept data from processors connected upstream and\none or more output pins that send processed results to the following downstream\nprocessor. For efficiency, all the data is processed blockwise, and the blocksize in",
      "content_length": 2884,
      "extraction_method": "OCR"
    },
    {
      "page_number": 612,
      "chapter": null,
      "content": "632 Section 6 Audio\n\nTable 6.7.1 Terminology Used In Sphinx MMOS\n\nName in Sphinx MMOS Other Names\n\nProcessor Unit, Filter, Block, Node, (DSP} Module\n\nPin Input/Output, Inlet/Oudet, Slot, Port\n\nSignal Data, Media, Stream, Samples, Payioad, Information\nPatch Graph, Chain, Network\n\nSphinx MMOS defaults to 256 samples. Having a sample rate of 44,100 Hz makes a\nbuffer duration of -6 ms, which corresponds to a frame rate of ~172 Hz.\n\nProcessors\n\nThere are many kinds of processors available in Sphinx MMOS. The most common\ntypes are oscillators, noise generators, envelopes, filters, and mixers. In order to con-\ntrol triggering of sounds, there are processors for impulse generation, sequencing, and\nselection. Each processor defines the particular connections that are available.\n\nTable 6.7.2 shows a list of some of the processors in the Sphinx MMOS system.\nWe will discuss how to connect these processors together in the next section.\n\nTable 6.7.2 Some of the Processors in Sphinx MMOS\n\nOscillators Noise Generators\nCGASineOscillator CGARandomGenerator\nCGATriangleOscillator CGANoiseGenerator\nCGASquareOscillator Miscellaneous\nCGASawtoothOscillator CGAAverager\nCGASinCosO0scillator CGAGlLide\nCGASinexOscillator CGAInterleaver\nCGASawtoothOscDSF CGAThreshold\nCGASawtoothOscBLit Trigger & Selection\nCGAWaveTableOscillator CGAImpulseGenerator\nEnvelopes CGASequencer16\nCGATriangleEnvelope CGASelector\nCGAHalfCosineEnvelope Mixers\nCGAGaussEnvelope CGAMixer2,3,4,6\nCGARampEnvelope CGABalance\n\nFilters\n\nCGAButterworthLPF\n\nCGAResonator",
      "content_length": 1528,
      "extraction_method": "OCR"
    },
    {
      "page_number": 613,
      "chapter": null,
      "content": "6.7 Real-Time Modular Audio Processing for Games 633\n\nPatch File introduction\n\nSphinx patch files are simple text files that you can edit with any text file editor. Let’s\nlook at a simple patch. It’s an oscillator with a base frequency of 200 Hz, modulated\nby an LFO at 3.5 Hz. FMAttenuation is set to 0.1, which limits the modulation depth\nto +/— one octave. All processors of the audio chain are listed inside the patch. Also,\nall parameters are contained inside the object's brackets.\n\nCGAPatch “Sine Oscillator with LFO Modulation\"\n\n{\nCGASineOscillator LFO\n{\nFrequency = 3.5;\n}\nCGASawtoothOscillator OSC\n{\nFrequency = 200;\nFMAttenuation = 0.1;\n}\nConnection = LFO, OSC, SampleOQut, FM;\n}\n\nThe last line of the patch connects the sample output of the LFO with the (bipo-\nlar) frequency modulation input of the VCO. This is what it looks like to hardcode\nthat patch right into your game:\n\nvoid SamplePatch()\n{\nIGAPatch* pPatch = CreatePatch(\n“Sine Oscillator with LFO Modulation\");\n\n// O modulator\n\n1GASineOscillator* pLFO =\nPCREATE (pPatch,SineOscillator);\npLFO ->SetFrequency(3.5T);\n\n/{ t oscillator\nIGASawtoothOscillator* pSaw2 =\nPCREATE (pPatch, SawtoothOscillator)} ;\npSaw2 ->SetFrequency (200. 0f};\npSaw2->SatFMAttenuation(0.1f};\n\n// connections\npPatch->Connect(0,1, SampleOut, FM);\n\n}\n\nThe first line creates a new patch and appends it to the application's patch list.\nWith the two PCREATE lines, we create the two processors. PCREATE is a convenient\nmacro that casts to the type of processor specified by the CID, creates the object, and",
      "content_length": 1546,
      "extraction_method": "OCR"
    },
    {
      "page_number": 614,
      "chapter": null,
      "content": "Section 6 Audio\n\nappends it to the list of processors in our patch. The order of creation is important,\nbecause it defines the order of processing in the chain. The last line connects the two\nprocessors, The arguments are the processor indices in the chain and their pins. Here\nwe connect the pin Samp1e0ut of oscillator zero with the input pin FM of oscillator one.\n\nShown next are the steps needed to initialize Sphinx MMOS, create and play the\npatch, and clean up.\n\ng_pGASystem->Initialize(}\n\nSamplePatch(};\n\ng_pGASystem->Start();\n\n// run application loop here and handle\n\n// start/stop and parameter setting somewhere\nff in your event handling\n\nRunLoop{);\n\ng_pGASystem->Terminate()\n\nThe g_pGaSystem is a global that represents the singleton audio object in our\napplication. If not specified otherwise, all rendering is done to the default stream. For\naudio rendering, the current version of Sphinx MMOS uses its own set of wrapper\nclasses that encapsulate the excellent PortAudio system [Burk01].\n\nPatch File Applications\n\nON THE CO\n\nNow that we have described the basic patch-definition language, we have the power\nto create complex sounds. Because any signal path can be formed by describing\nprocessors and their connections, an infinite variety of patches are possible. Also,\nthese patches can be controlled by games because we can choose game variables to\ntake the place of certain processors in a given patch, thus giving us organic control\nover digital sound generation and signal processing. We even can connect any\ndynamic value from our game data or user interface to a CGAController to modify the\naudio stream at the sample rate.\n\nTo show how we can apply this patch system to games, we will now describe how\npatch configurations can be designed to simulate engine sounds. Rather than covering\nall of the specific details of the patches, we will highlight some of the important fea-\ntures. We will also show how the complexity of patches can be incrementally\nincreased to improve the quality of engine simulation.\n\nThe patches described in the following subsections can be found in the patches\nprovided on the CD-ROM.\n\nMotor Vehicles\nA vehicle sound is a complex signal produced by several sources. Many deterministic\n\nand stochastic components occur simultaneously. The deterministic components are",
      "content_length": 2313,
      "extraction_method": "OCR"
    },
    {
      "page_number": 615,
      "chapter": null,
      "content": "6.7 Real-Time Modular Audio Processing for Games 635\n\ncorrelated to the revolutions per minute (RPM) of the engine. The stochastic compo-\nnents are primarily due to turbulent airflow from the air intake and exhaust systems.\nAt low speed, the sound signature is dominated by these deterministic components,\nwhile at high speed, the signature is dominated by the stochastic components,\n\nThe basic idea behind an engine patch is to simulate the alternating phases of a\nsound. In order to generate sophisticated and less-predictable sounds, we combine\nlooped and simple one-shot samples with synthesized sounds, We will use a sequencer\nto control the timing of the sounds. An impulse generator ttiggers a selector switch.\nEach impulse at the inpur of the selector selects che next sound source input, and it\nalso resets the sample start. This is somewhat like programming a drumbox. The dif-\nference lies in speed. We accelerate the cycle up into the audio range. While a drum\nsequence might groove at 120 beats per minute, our engine will climb to 4000-RPM\ncruising speed and higher.\n\n¢ The PowerStroke patch simulates the generic, four-cylinder, four-stroke engine.\nThese four repeating strokes are referred to as Intake, Compression, Power, and\nExhaust. We can simulate three of the engine phases with samples. At the begin-\nning of the patch file, we load the samples into the CGASignal objects and give\nthem appropriate names (Intake, Impulse, Exhaust). These names (not the file-\nnames) are used as a reference value for the WaveTable parameter of a\nCGAWavetableOQscillator.\n\nThe wavetable oscillator can play loops or one-shots. We want to trigger the\nwaves from a CGAImpulseGenerator, so we set the Repeat parameter to one. The\nspeed of the impulse generator, the RPM, is controlled by a low-frequency oscil-\nlator. Each impulse selects the next input at the CGASelector. To activate four\ninputs, we set the Selection parameter to 15 (1 + 2 + 4 + 8). We have no input\nfor the compression phase, which means this phase will be silent and the selector\nwill just fill in zeros.\n\n* The PowerStroke with Muffler patch has two additional filters of type CGARes-\nonator to simulate the muffler resonances. The original signal and the signals of\nthe resonators are mixed in a CGAMixer3 object. In order to get a roaring sound at\nhigher speed, we set the input gain of the resonances high, but control the AM by\nthe speed controller.\n\n¢ The PowerStroke 2 Cylinders with Muffler patch adds cross-fading between\nsounds over the range of RPMs. Across the RPM range, the sound components\nshould vary slightly to produce a convincing timbre change.\n\nHelicopters\n\n* The Turbine patch plays a turbine sample loop. The sample contains both\npitched and noisy components. In contrast to the common sample editing phi-\nlosophy, the loop points here are chosen to not suppress the cyclic character.\n\nThe cGAWavetableOscillator is frequency modulated by a smoothed LFO\nsource, In order to get a complex and bright sound with varying overtones, we",
      "content_length": 3028,
      "extraction_method": "OCR"
    },
    {
      "page_number": 616,
      "chapter": null,
      "content": "Section 6 Audio\n\nnow add a bit of audio FM to the CGAWavetableOscillator. We need a CGAMixer\nhere to combine the modulation signals from the LFO and the VCO. The result\nis the Turbine AudioFM1 patch. We can change the character in a more interest-\ning way if we add some FM modulation to the VCO that modulates the sample.\nIn lower ranges, this results in amplitude modulations, which enhance the slow\nrotating effect (Turbine AudioFM2).\n\n* The Rotor—Enveloped Sample patch demonstrates a looping sample that is\namplitude modulated by a CGAGaussEnve lope to give soft attack and release. The\nsample m_propeller01.wav consists of a strong noise component and a low-fre-\nquency distorted sine wave. The envelope is triggered by 2 CGAImpulseGenera-\ntor. The trigger points are independent of the loop start point, which results in\nlittle sound variations.\n\n* Turbine +-Rotor is a combination of the AudioFM2 Turbine and the enveloped\nrotor. The turbine’s frequency and the trigger speed of the envelope are controlled\n\n- by the same LFO.\n\n¢ The Helicopter with Turbine, Rotor and Flap Fx patch uses sequenced waveta-\nbies and feedback FM techniques to simulate engine and air chop. Exactly as with\nthe car engine, we use the balance parameter of the CGAMixer to cross-fade\nbetween its inputs. Components of this patch are the Jet/Turbine Engine with its\nIntake and Exhaust sounds, the basic main and tail rotor sounds with the blade\nparameters, an additional generator to intensify air noise at greater speeds, and\nthe flanging impulse for the characteristic flap effect.\n\nFar away, the helicopter sound has strong amplitude fluctuations and an indi-\nrect muffling effect caused by air turbulence. For short bursts, the sound some-\ntimes disappears completely or is just a single but strong impulse. In our patch,\nwe simulate this characteristic interference effect by adding a four-millisecond\ndelayed version to the original flap sample. The delay time is slowly modulated by\nan LFO. This results in moving notches in the audio spectrum and gives a nice\nflanging effect.\n¢ Turbine Controlled by Keypad is an interaction demo that shows how to\ncontrol the turbine sample by the keypad. The frequency of the loop is controlled\nby a value assigned to a key of the numpad. Play with the numbers one to nine in\norder to glide to different turbine speeds. For the gliding effect, we connect a\nCGAGLide between the CGANumPadController and the CGAWavetableOscillator.\n\nSubmarines\n\nThe tonal components of a submarine are machinery and equipment noise, hull reso-\nnances, and propeller-radiated noise. The broadband components are flow noise, cav-\nitation, and the background of the ocean's natural noises. In order to generate the\nsound signature of a submarine, we use two special oscillators to generate pink noise-\nmodulated sine waves. These simulate the combination of irregular and. stochastic",
      "content_length": 2890,
      "extraction_method": "OCR"
    },
    {
      "page_number": 617,
      "chapter": null,
      "content": "6.7 Real-Time Modular Audio Processing for Games 637\n\nprocesses of turbulent noisy bubbles and the tonal noise that contains the discrete res-\nonance frequencies of the ship’s hull. The continuous part of the spectrum is charac-\nterized by a maximum in the area of 50 Hz to 100 Hz, but convincing frequency\nvalues might have a range of up to 1000 Hz.\n\nThe propeller sound is simulated by a looped sample containing higher frequen-\ncies. When the propeller’s excitation frequency corresponds to the hull’s natural fre-\nquency, we get strong tonals from the huil. Also, singing can occur when the\nvortex-shedding frequency matches the blade’s natural frequency. This is a speed-\ndependent feedback effect in a narrow speed range and can happen at different\ns .\nAs the boat passes through the water, turbulent flow noise is generated along the\nhull. This hydrodynamic noise increases significantly as the speed rises. Cavitation\nand flow noise extend well beyond 10 kHz.\n\n* The Sonar—Noise Modulated Sine Patch is a sine wave of 2000 Hz, with\namplitude modulated by a descending ramp and frequency modulated by noise.\nThe noise modulation is shaped by an envelope to get a fade-in effect, thus the\ntone is clear at the beginning, but gets more and more distorted.\n\n* The Submarine—Engine Only is just an amplitude-modulated sample with an\nengine loop. A CGASinCosOscillator is used for fading. The next turbulence\npatches introduce two special oscillators for tonal noise generation, the\nCGANoiseMSineOsc with default settings and the CGASineXOscillator with a fre-\nquency setting of 860 Hz for turbulences in a higher range.\n\n* Submarine—Engine, Turbulences is a mix between the engine sample, the\nlower noise generated by the CGANoiseMSineOsc, and the higher noise generated\nby the CGASineXOscillator. We use a three-channel mixer, the CGAMixer3, and set\nthe gain of the higher part very low to get a convincing, filtered, underwater\neffect. No additional filter is used for this patch.\n\n¢ In the patch Submarine—Engine, Turbulences, Sonar, we include the elements\nof the above sonar patch and add frequency modulation on the engine sample to\nsimulate a Doppler effect. In conjunction with a low-pass filter at 400 Hz, this\nmakes the flow-by effect more convincing.\n\nSource Code\n\nOn the CD-ROM, you will find the Sphinx MMOS system source code, executables,\npatch files, and samples. Some patch files demonstrate the various processors, and\nsome contain the engine simulations discussed in the previous section. Updates are\navailable at the Visiomedia Web site [Visiomedia].\n\nThere are three methods for incorporating this audio system into your application:\n\n1. Write new C++ classes to handle audio processing and management, and\nbuild your own version of the library with customized source code.",
      "content_length": 2797,
      "extraction_method": "OCR"
    },
    {
      "page_number": 618,
      "chapter": null,
      "content": "638 Section 6 Audio\n\n2. Write a plug-in containing C++ classes using the Sphinx base interface,\nIGAProcessor, and load your plug-in along with the original Sphinx\nMMOS plug-in.\n\n3. Use the system as is, and only create new patch files.\n\nConclusion\n\nThis gem has provided insight into how to combine modular audio processing and\nprocedural generation of sounds to procedurally generate various vehicle sounds for\ngames. The main difference between real-time procedural audio and conventional\nplayback systems is the complexity management and the responsiveness of the\nprocessed sounds to the game context. The combination of samples sequenced at\naudio rate in conjunction with traditional synthesis techniques lets you build spectac-\nular sound transformations for your interactive applications.\n\nReferences\n\n[Ackermann94] Ackermann, Philipp, “Design and Implementation of an Object-ori-\nented Media Composition Framework.” available online at hwtp://citeseer.nj.\nnec.com/ackermann94design.html, 1994.\n\n[Burk01) Burk, Phil and Ross Bencina, “PortAudio - An Open-Source Cross-Plat-\nform Audio API,” available online at http://www.portaudio.com, 2001.\n\n[GENRef] Generator by Native Instruments, available online at hetp://www.native-\ninstruments.net/.\n\n[MAXRef] MAX / MSP by Cycling 74, available online at hitp://www.cycling74.\ncom/index.html.\n\n[PD Ref] Puckette, Miller, “Pure Data Dot Org,” available online at http://www.pure-\n\nta.org/,.\n\n[Rabin0O] Rabin, Steve, “Classic Super Mario 64 Third-Person Control and Anima-\ntion,” Game Programming Gems 2, Charles River Media, Inc., 2001.\n\n[Sim-Schmitz99] Sim, Ben and Fredric Schmitz, “Acoustic Phasing and Amplifica-\ntion Effects of Single-Rotor Helicopter Blade-Vortex,” Proceedings of the 55th\nAnnual National Forum American Helicopter Society, 1999.\n\n[Smith91] Smith, Julius O., “Viewpoints on the History of Digital Synthesis,” Pro-\nceedings of the International Computer Music Conference, October 1991: pp. 1-10.\n\n[Visiomedia] Updates to the Sphinx MMOS system, available online at hetp://\nwew.visiomedia.com/rooms/labor!/stc/sphinxmmos/index hem.\n\n[Wang99] Wang, Geng, “Prediction of Rotorcraft Noise with a Low-Dispersion\nFinite Volume Scheme,” available online at http://www.ae.gatech.edu/-Isankar/\n\nERT/ 1999.",
      "content_length": 2266,
      "extraction_method": "OCR"
    }
  ],
  "enrichment": {
    "version": "1.0.0",
    "generated_by": "generate_chapter_metadata.py",
    "contains": [
      "keywords",
      "concepts",
      "summary"
    ]
  }
}